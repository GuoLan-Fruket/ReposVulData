{"index": 7563, "cve_id": "CVE-2022-23607", "cwe_id": ["CWE-200", "CWE-601"], "cve_language": "Python", "cve_description": "treq is an HTTP library inspired by requests but written on top of Twisted's Agents. Treq's request methods (`treq.get`, `treq.post`, etc.) and `treq.client.HTTPClient` constructor accept cookies as a dictionary. Such cookies are not bound to a single domain, and are therefore sent to *every* domain (\"supercookies\"). This can potentially cause sensitive information to leak upon an HTTP redirect to a different domain., e.g. should `https://example.com` redirect to `http://cloudstorageprovider.com` the latter will receive the cookie `session`. Treq 2021.1.0 and later bind cookies given to request methods (`treq.request`, `treq.get`, `HTTPClient.request`, `HTTPClient.get`, etc.) to the origin of the *url* parameter. Users are advised to upgrade. For users unable to upgrade Instead of passing a dictionary as the *cookies* argument, pass a `http.cookiejar.CookieJar` instance with properly domain- and scheme-scoped cookies in it.", "cvss": "7.4", "publish_date": "February 1, 2022", "AV": "NETWORK", "AC": "NETWORK", "PR": "NONE", "UI": "REQUIRED", "S": "CHANGED", "C": "HIGH", "I": "NONE", "A": "NONE", "commit_id": "1da6022cc880bbcff59321abe02bf8498b89efb2", "commit_message": "Merge pull request from GHSA-fhpf-pp6p-55qc\n\nscope cookies by default", "commit_date": "2022-01-30T05:12:54Z", "project": "twisted/treq", "url": "https://api.github.com/repos/twisted/treq/commits/1da6022cc880bbcff59321abe02bf8498b89efb2", "html_url": "https://github.com/twisted/treq/commit/1da6022cc880bbcff59321abe02bf8498b89efb2", "windows_before": [{"commit_id": "8e2c4d9e9fdb495d9019f165019502a77e4a3e79", "commit_date": "Fri Jan 28 17:00:58 2022 -0800", "commit_message": "flake8", "files_name": ["src/treq/client.py", "src/treq/test/test_testing.py"]}, {"commit_id": "94af36effe70d39b576fcc884d7f71730f9ee06b", "commit_date": "Fri Jan 28 16:55:23 2022 -0800", "commit_message": "netscape", "files_name": ["src/treq/client.py", "src/treq/test/test_treq_integration.py"]}, {"commit_id": "da59847f06a875cd3e6784dc0f326d13e1a389ac", "commit_date": "Fri Jan 28 15:44:21 2022 -0800", "commit_message": "scope cookies by default", "files_name": ["src/treq/client.py", "src/treq/test/test_testing.py"]}, {"commit_id": "d89d553240f1c1e434bb137e5ce53877c54285e6", "commit_date": "Fri Jan 21 23:44:06 2022 -0800", "commit_message": "Merge pull request #337 from JamieSlome/master", "files_name": ["e6fd81c4eea1c85fe8e3b160436526525767a9a5 - Wed Jan 19 11:44:31 2022 +0000 : build: apply patch to master branch", "MANIFEST.in"]}, {"commit_id": "60bffde8b57243ae53ce8c6a9ae06f9855e7c87b", "commit_date": "Tue Jan 18 06:04:21 2022 +0000", "commit_message": "Create SECURITY.md", "files_name": ["SECURITY.md"]}, {"commit_id": "3d33835b52f92419ff7fe350f18e28a74c7cb48c", "commit_date": "Tue Dec 28 20:05:10 2021 -0800", "commit_message": "Merge pull request #277 from twisted/parallel-coverage", "files_name": ["f4a53d1b23612e3c1ce9fe7b685ba3475d3cc92d - Tue Dec 28 03:09:49 2021 -0800 : update depends list for current factors", "tox.ini"]}, {"commit_id": "a2e0b92775b6d094dcb8b8c05d694d376fece620", "commit_date": "Tue Dec 28 03:07:22 2021 -0800", "commit_message": "Merge branch 'master' into parallel-coverage", "files_name": ["7d6e9b77f1493bdd93d568ed5c6b8542689ae32e - Tue Dec 28 02:56:25 2021 -0800 : Merge pull request #330 from twm/document-files-324", "f2e268c1bf0bd5b2bb529dc7d09582417afe733d - Tue Dec 28 02:46:16 2021 -0800 : Merge branch 'master' into document-files-324", "b877958e6ffffa4ab65f2b3c00347a8a5d2bdef6 - Tue Dec 28 02:44:49 2021 -0800 : Merge pull request #332 from laggardkernel/bugfix/cleanup", "974a3bd399c0636305b4aa6b5bc77d6740812612 - Tue Jul 27 15:06:29 2021 +0800 : Fix typo in comment and doc", "docs/howto.rst", "docs/index.rst", "src/treq/multipart.py"]}, {"commit_id": "8b9590bd9334d4ed67db1980e3815f80ff178c98", "commit_date": "Fri Jun 25 20:37:25 2021 +0800", "commit_message": "Remove bytes decoding for quoted result", "files_name": ["src/treq/client.py"]}, {"commit_id": "e888b928051866ab5f4bd2db181c24155999bff6", "commit_date": "Fri Jul 23 22:57:58 2021 +0100", "commit_message": "Merge branch 'master' into document-files-324", "files_name": ["141a2014fbe3f9694ca139d51fcb4d952d98fec6 - Sat Jul 10 22:33:09 2021 -0700 : Merge pull request #333 from tristanlatr/patch-1", "c566d989d131a29c644ee32b338d67e6c311d658 - Thu Jul 8 10:06:38 2021 -0400 : Fix link", "README.rst"]}, {"commit_id": "a2cadbfaff432e530c583845f08ea8fbd798237d", "commit_date": "Mon May 24 13:24:14 2021 -0700", "commit_message": "Release 21.5.0", "files_name": ["CHANGELOG.rst", "changelog.d/296.doc.rst", "changelog.d/318.removal.rst", "changelog.d/327.bugfix.rst", "changelog.d/329.feature.rst", "src/treq/_version.py"]}, {"commit_id": "3fc5edbabca2fb3e32caa28cff5737d69b25648e", "commit_date": "Sun May 23 12:57:58 2021 -0700", "commit_message": "Merge pull request #331 from twm/prep-for-release", "files_name": ["4f73893f80914ab0a09743486e9d03ef0904eeb5 - Tue May 18 22:54:54 2021 -0700 : Minor revision", "src/treq/api.py"]}, {"commit_id": "894e00443ea8116c25709204030ffef678982e98", "commit_date": "Tue May 18 22:44:41 2021 -0700", "commit_message": "Merge branch 'master' into document-files-324", "files_name": ["631660d0f311930ebb1b7acf76e2b8b0e2428172 - Tue May 18 22:42:45 2021 -0700 : Update MANIFEST.in", "MANIFEST.in"]}, {"commit_id": "cf23f14dafb0164bc48df9ae67154f21b4891ade", "commit_date": "Tue May 18 22:39:33 2021 -0700", "commit_message": "Don't build universal wheels", "files_name": ["setup.cfg"]}, {"commit_id": "60464804a9604e6e92f544f01e65395cb10d3f37", "commit_date": "Tue May 18 22:39:09 2021 -0700", "commit_message": "Remove obsolete tox2travis.py script", "files_name": ["tox2travis.py"]}, {"commit_id": "15aff2830ca5420ba8d5acd63fd680ef3c10d9cd", "commit_date": "Wed May 12 21:08:59 2021 -0700", "commit_message": "Document the files argument", "files_name": ["src/treq/api.py", "src/treq/client.py"]}, {"commit_id": "b0c61728cdb31bfb297d9a8b41a22c7155763643", "commit_date": "Wed May 12 20:18:09 2021 -0700", "commit_message": "Merge pull request #328 from bennr01/fix_327", "files_name": ["bbf412cada94d0d311ce6331611cd6ba9380d930 - Wed May 12 13:02:53 2021 +0200 : treq.testing: fix lint error (E501)", "src/treq/testing.py"]}, {"commit_id": "3c2e82f0b108d278f8bfa3038c98abcff7dfb86c", "commit_date": "Tue May 11 22:49:33 2021 -0700", "commit_message": "Update browser_like_redirects for the new HTTP RFCs", "files_name": ["src/treq/api.py"]}, {"commit_id": "c31725638291f29df2b97de0b3af995566e6b6aa", "commit_date": "Mon Apr 26 11:57:16 2021 +0200", "commit_message": "treq.testing.RequestTraversalAgent: explicitly pass reactor to Site", "files_name": ["src/treq/test/test_testing.py", "src/treq/testing.py"]}, {"commit_id": "00f1b8243fa34a1907f35513d9fd779b2cc70973", "commit_date": "Wed Apr 21 12:59:45 2021 +0200", "commit_message": "Merge branch 'master' into fix_327", "files_name": ["f8b6e253658f9d87bd19f135365c17795fafdf17 - Wed Apr 21 12:56:08 2021 +0200 : remove .cleanSessions() again", "docs/api.rst", "docs/testing.rst", "src/treq/test/test_testing.py", "src/treq/testing.py"]}, {"commit_id": "4be2f69e32f39218f7ff593c7005d08071a128ef", "commit_date": "Tue Apr 20 21:12:21 2021 -0700", "commit_message": "Merge pull request #329 from twm/pyproject-toml", "files_name": ["138da366f838aaec425333e320544ac2524dbcb9 - Sat Apr 17 19:04:27 2021 -0700 : Add change fragment", "changelog.d/329.feature.rst"]}, {"commit_id": "129ab7c24b4e56bbd194284d75b73c507f55ef0c", "commit_date": "Sat Apr 17 18:22:12 2021 -0700", "commit_message": "Add PEP 517 / PEP 518 metadata", "files_name": ["pyproject.toml", "tox.ini"]}, {"commit_id": "30a10bbc036942c944101d88606914d13bbf0504", "commit_date": "Tue Apr 13 14:34:11 2021 +0200", "commit_message": "treq.testing.StubTreq: fix session persistence between requests", "files_name": ["changelog.d/327.bugfix.rst", "docs/api.rst", "docs/testing.rst", "src/treq/test/test_testing.py", "src/treq/testing.py"]}, {"commit_id": "49ef6bdbaecc3d7ab594c691878b98b97131727e", "commit_date": "Mon Feb 1 21:39:00 2021 -0800", "commit_message": "Merge pull request #319 from twm/kwargs-287", "files_name": ["96bd854955d9c126696ad1126e5509df6d83ba2f - Mon Feb 1 21:35:17 2021 -0800 : Address review feedback", "src/treq/test/test_multipart.py"]}, {"commit_id": "564a0213a81606cbec3f396e97a89e6f0d2b5397", "commit_date": "Sun Jan 24 23:28:40 2021 -0800", "commit_message": "Merge branch 'master' into kwargs-287", "files_name": ["321fb6e015bfcb806fe06d04a49a03965601a49b - Sun Jan 24 23:28:15 2021 -0800 : Merge pull request #321 from twm/rtd-conf", "8cc0a38728ef987d317797ea8bb48a199fe47acc - Sun Jan 24 23:15:46 2021 -0800 : Suggest how to view docs", "CONTRIBUTING.rst"]}, {"commit_id": "147f75baeeed6550a03559370125a41cf632b6db", "commit_date": "Sun Jan 24 15:12:00 2021 -0800", "commit_message": "Juice coverage", "files_name": ["src/treq/test/test_multipart.py"]}, {"commit_id": "d059f3ac02bcbfef4db80e6909e3204267b54253", "commit_date": "Sun Jan 24 14:59:32 2021 -0800", "commit_message": "Merge branch 'master' into kwargs-287", "files_name": ["8f71ac9abcaa09cfff832a5acf2274cec79802ac - Sun Jan 24 14:57:21 2021 -0800 : Update Git ignores for tox -p", ".gitignore"]}, {"commit_id": "64e18ee0450f150f161a2192d33bc0bdf1bccb4d", "commit_date": "Sun Jan 24 14:57:02 2021 -0800", "commit_message": "Update contribution docs for Tox", "files_name": ["CONTRIBUTING.rst"]}, {"commit_id": "5d5d990c4b4b16b1c867f87a2584dfae10b4aae8", "commit_date": "Sun Jan 24 14:42:55 2021 -0800", "commit_message": "Merge branch 'master' into rtd-conf", "files_name": ["f85ed5cfb17d1d9eb1fa34c677afe6270d85fc88 - Sun Jan 24 14:42:13 2021 -0800 : Update RTD config to use Python 3.7", ".readthedocs.yml", "changelog.d/296.doc.rst", "setup.py", "tox.ini"]}, {"commit_id": "e3a12f8407dc41350b3bca005d38dce449942c00", "commit_date": "Sun Jan 24 12:55:46 2021 -0800", "commit_message": "Merge pull request #320 from twm/bye-bye-py27,py35-318", "files_name": ["2a6238f6aae9caf6fadc63c90de7aa3f8fd75134 - Sun Jan 24 12:50:06 2021 -0800 : Merge branch 'master' into bye-bye-py27,py35-318", "68774be723d538a2b1124b57e140f9dc773aaf58 - Sun Jan 24 12:48:59 2021 -0800 : More review feedback", "src/treq/client.py", "src/treq/multipart.py"]}, {"commit_id": "a007f5d17e844823e0eaca50161fe00124104e1f", "commit_date": "Sun Jan 24 12:46:06 2021 -0800", "commit_message": "Remove inheritance from object", "files_name": ["src/treq/_agentspy.py", "src/treq/auth.py", "src/treq/client.py", "src/treq/multipart.py", "src/treq/test/local_httpbin/parent.py", "src/treq/test/local_httpbin/shared.py", "src/treq/test/test_api.py", "src/treq/test/test_multipart.py", "src/treq/test/test_response.py", "src/treq/testing.py"]}, {"commit_id": "b21531ae58a1718c9c7ca04e91b2e7ac06c98c36", "commit_date": "Sun Jan 24 12:24:04 2021 -0800", "commit_message": "Fix python_requires to 3.6+", "files_name": ["setup.py"]}, {"commit_id": "349c44e3ef5f52e635e56bb54727af63efdbeafc", "commit_date": "Sat Jan 16 18:10:37 2021 -0800", "commit_message": "Merge pull request #317 from twm/update-readme", "files_name": ["0699c5ff20244ea715154c160de6413aa7a1dd75 - Sat Jan 16 16:45:51 2021 -0800 : Fix RTD badge", "README.rst"]}, {"commit_id": "55c08d073a6cd1dc964ccd88ea49e7e59941d3c3", "commit_date": "Sat Jan 16 13:59:26 2021 -0800", "commit_message": "Remove six from treq.test.local_httpbin.test.test_child", "files_name": ["src/treq/test/local_httpbin/test/test_child.py"]}, {"commit_id": "ae892516784d91c64fc909c89fa6dec5bd107e0d", "commit_date": "Sat Jan 16 13:57:25 2021 -0800", "commit_message": "Remove six from treq.test.local_httpbin.child", "files_name": ["src/treq/test/local_httpbin/child.py"]}, {"commit_id": "ccadefb64116def66b25c27fa0556615a8878f6f", "commit_date": "Sat Jan 16 13:55:19 2021 -0800", "commit_message": "Add changelog entry", "files_name": ["changelog.d/318.removal.rst"]}, {"commit_id": "af0dbb5ce75cc2dedf6d28560aff235a355243ee", "commit_date": "Sat Jan 16 13:51:37 2021 -0800", "commit_message": "Remove mock dependency", "files_name": ["setup.py", "tox.ini"]}, {"commit_id": "6b72f6c6d6eca5cd4e60b3819136b01c2c513438", "commit_date": "Sat Jan 16 13:50:33 2021 -0800", "commit_message": "Use stdlib mock", "files_name": ["docs/testing.rst", "src/treq/test/test_client.py", "src/treq/test/test_content.py", "src/treq/test/test_testing.py", "src/treq/test/util.py"]}, {"commit_id": "22bdb399a03b0eebaa93023b80d348f584f567d5", "commit_date": "Sat Jan 16 13:48:13 2021 -0800", "commit_message": "Remove six dependency", "files_name": ["setup.py"]}, {"commit_id": "38d88757c7047204d7e31421a76415309c479a50", "commit_date": "Sat Jan 16 13:45:43 2021 -0800", "commit_message": "Remove six from treq.test.test_testing", "files_name": ["src/treq/test/test_testing.py"]}, {"commit_id": "74fd0144dfc248d5cb33c79dba1ef2ba8192ed3b", "commit_date": "Sat Jan 16 13:43:58 2021 -0800", "commit_message": "Remove six from treq.test.test_multipart", "files_name": ["src/treq/test/test_multipart.py"]}, {"commit_id": "e4e74a3a7fd6ef5e8c639f82c1e0de739176a318", "commit_date": "Sat Jan 16 13:24:56 2021 -0800", "commit_message": "Remove six from treq.client", "files_name": ["src/treq/client.py"]}, {"commit_id": "288536f8e23a1a24e91b0e068b197e9bbf46996a", "commit_date": "Sat Jan 16 13:11:23 2021 -0800", "commit_message": "Remove future imports from treq.content", "files_name": ["src/treq/content.py"]}, {"commit_id": "4ccd1388c5e73bbef90322a651ebd840181d9d4b", "commit_date": "Sat Jan 16 13:10:43 2021 -0800", "commit_message": "Remove six from treq.multipart", "files_name": ["src/treq/multipart.py"]}, {"commit_id": "4e740dfd5637ae0c5bf0b0a4640a2dac3dabb29c", "commit_date": "Sat Jan 16 13:08:40 2021 -0800", "commit_message": "Remove future imports from treq.response", "files_name": ["src/treq/response.py"]}, {"commit_id": "b465d0fb3ca377c333e0e91c8d7a333d1cb70cd5", "commit_date": "Sat Jan 16 13:07:28 2021 -0800", "commit_message": "Remove six from treq.testing", "files_name": ["src/treq/testing.py"]}, {"commit_id": "4fc36765af2e1f4dc343c6ea295b6af7f96a5a4d", "commit_date": "Sat Jan 16 13:04:29 2021 -0800", "commit_message": "Update package metadata", "files_name": ["setup.py"]}], "windows_after": [{"commit_id": "8ce557ad0be35b512ddd110fa77278add61ac8bc", "commit_date": "Fri Jan 28 22:10:22 2022 -0800", "commit_message": "Add Python 3.10 to the test matrix", "files_name": [".github/workflows/ci.yaml", "setup.py", "tox.ini"]}, {"commit_id": "8292e5fa119163c601864ba534e6c2bcbc417abd", "commit_date": "Fri Jan 28 22:12:22 2022 -0800", "commit_message": "Add changefragment", "files_name": ["changelog.d/338.feature.rst"]}, {"commit_id": "58cb9e609e3325bf0c6148ba93a6e27aac05f5a0", "commit_date": "Fri Jan 28 22:16:35 2022 -0800", "commit_message": "Add PyPy 3.8 to the test matrix", "files_name": [".github/workflows/ci.yaml", "changelog.d/338.feature.rst"]}, {"commit_id": "af8494ea5600c62bb6e1e0456401da420d5388d7", "commit_date": "Fri Jan 28 22:18:15 2022 -0800", "commit_message": "Note that Python 3.6 is EOL", "files_name": ["changelog.d/338.removal.rst"]}, {"commit_id": "439b89e55186dd55d9801c4fd6377b02d68b9af3", "commit_date": "Fri Feb 4 21:55:29 2022 -0800", "commit_message": "Note non-support of Python 2.7", "files_name": ["docs/index.rst"]}, {"commit_id": "cd754f7eea83fc10faff824deab69dd8a1937f48", "commit_date": "Tue Feb 8 08:55:48 2022 -0800", "commit_message": "Fix cookie scoping for HTTPS urls.", "files_name": ["src/treq/client.py", "src/treq/test/test_testing.py"]}, {"commit_id": "cdc08dfe0406ae52655e45835ff5718808d09768", "commit_date": "Tue Feb 8 09:35:07 2022 -0800", "commit_message": "Build on trunk and PRs that target trunk", "files_name": [".github/workflows/ci.yaml"]}, {"commit_id": "da889ea7a3dc58259f3d58e8476c972382337886", "commit_date": "Tue Feb 8 11:27:55 2022 -0800", "commit_message": "Merge pull request #344 from dreid/patch-1", "files_name": ["7661b63f160cc1f57dc2bfeda06a59f4173cbe28 - Tue Feb 8 11:28:12 2022 -0800 : Merge branch 'trunk' into dreid/fix-cookie-scoping-for-https", "c13e2516c76ef9e094fda83dfb21b6485f5c1c52 - Tue Feb 8 11:30:17 2022 -0800 : Merge branch 'trunk' into new-pythons", "226ed2d8e428405b7fb12eb278329e97d1a8538c - Tue Feb 8 11:31:07 2022 -0800 : Merge pull request #343 from dreid/dreid/fix-cookie-scoping-for-https", "7f72f354aca00f9d7229ed9d9767f29777c46fd0 - Tue Feb 8 11:31:28 2022 -0800 : Merge branch 'trunk' into new-pythons", "8a92360850de93b620082a5b39782edd93e15b18 - Tue Feb 8 22:55:13 2022 -0800 : Merge pull request #338 from twisted/new-pythons", "249206c17bcd9d055a96d52ba61e0e2f11a0e3a8 - Tue Feb 8 23:03:38 2022 -0800 : Add a newsfragment for #343", "changelog.d/343.bugfix.rst"]}, {"commit_id": "9687e1ac909bcb5b52cfea7941c1b8232b37bc5d", "commit_date": "Tue Feb 8 23:04:27 2022 -0800", "commit_message": "Add CVE number to changelog", "files_name": ["CHANGELOG.rst"]}, {"commit_id": "d67fb48c0ff12177454ce3fa65e6f8cc92a718e1", "commit_date": "Tue Feb 8 23:17:10 2022 -0800", "commit_message": "Release 22.2.0", "files_name": ["CHANGELOG.rst", "changelog.d/338.feature.rst", "changelog.d/338.removal.rst", "changelog.d/343.bugfix.rst", "src/treq/_version.py"]}, {"commit_id": "33c25972337923198bd80161863b7f97f33edde2", "commit_date": "Sat Aug 13 18:10:24 2022 -0700", "commit_message": "httpbin 0.7.0 and werkzeug 2.0.3", "files_name": ["changelog.d/352.misc.rst", "setup.py"]}, {"commit_id": "54ec4731e3c6123fd56a642237a52ce86ea0e777", "commit_date": "Sun Aug 21 13:16:34 2022 -0700", "commit_message": "Merge pull request #353 from twisted/352-werkzeug-import-error", "files_name": ["1696227c5e04178bf39b3debbf039d5f2773ace3 - Sat Jul 16 15:49:47 2022 +1000 : docs: Fix a few typos", "src/treq/test/test_multipart.py"]}, {"commit_id": "f7a6932f475292303ba87b528bebd40c85123628", "commit_date": "Mon Sep 5 16:30:10 2022 -0700", "commit_message": "Add a change fragment", "files_name": ["changelog.d/349.misc.rst"]}, {"commit_id": "4b09044b38f4502de3d3dd00b62d6d9717b2fbc1", "commit_date": "Mon Sep 5 16:42:27 2022 -0700", "commit_message": "Merge pull request #349 from timgates42/bugfix_typos", "files_name": ["b03ff7df1d0105d783ce64848ef5da883df08565 - Fri Jul 15 11:27:53 2022 -0400 : Handle exceptions raised from the collector.", "changelog.d/347.feature.rst", "src/treq/content.py", "src/treq/test/test_content.py"]}, {"commit_id": "8868515eae3e7ea9ff4c917f0d2cd2ebe0b2fdea", "commit_date": "Fri Jul 15 11:32:01 2022 -0400", "commit_message": "Better grammar.", "files_name": ["src/treq/test/test_content.py"]}, {"commit_id": "c45536cfbd9bf8cdb6ef12d16c669c4aa2b8c071", "commit_date": "Mon Jul 18 12:41:04 2022 -0400", "commit_message": "Update src/treq/test/test_content.py", "files_name": ["src/treq/test/test_content.py"]}, {"commit_id": "03ddda39d50a9ae0c00e2f6d8cee476b39c71b26", "commit_date": "Wed Sep 7 17:36:26 2022 -0400", "commit_message": "Use public APIs to test disconnection.", "files_name": ["src/treq/test/test_content.py"]}, {"commit_id": "2cf25d791d5eb66043a12bc391a3beddd32225df", "commit_date": "Wed Sep 7 17:36:36 2022 -0400", "commit_message": "Don't use bare except.", "files_name": ["src/treq/content.py"]}, {"commit_id": "5d6469b9b956b626554f6db25f396b9425a3a951", "commit_date": "Wed Sep 7 18:53:07 2022 -0400", "commit_message": "Merge pull request #348 from itamarst/347-close-transport-on-failed-collector", "files_name": ["b9eb3e1b1285a9fceb884e3d802afe88915a1593 - Sat Aug 13 17:07:59 2022 -0700 : Link to docs.twisted.org", "changelog.d/350.misc.rst", "docs/conf.py"]}, {"commit_id": "0cf19207f46fb30fa18bc4e3505099743773e5a7", "commit_date": "Sat Sep 10 12:23:23 2022 -0700", "commit_message": "Merge pull request #351 from twisted/350-docs.twisted.org", "files_name": ["449eee75b75deed974fd552199f5c29fc2e44e55 - Mon Apr 17 21:50:27 2023 -0700 : Drop Python 3.6 support", ".github/workflows/ci.yaml", "changelog.d/363.removal.rst", "tox.ini"]}, {"commit_id": "eaebe0eb14a011d852c749802ba1527077b545fa", "commit_date": "Sun Apr 30 13:52:39 2023 -0700", "commit_message": "Temporarily ignore imports until typing lands", "files_name": ["src/treq/_agentspy.py", "src/treq/auth.py"]}, {"commit_id": "e7625f0cfecd8582dbafe0069f68e4af0d5d69c3", "commit_date": "Sun Apr 30 14:13:18 2023 -0700", "commit_message": "Fix the docs build", "files_name": [".readthedocs.yml", "setup.py", "tox.ini"]}, {"commit_id": "68300c62ff329f2003cf30a728d17f8ae7646a53", "commit_date": "Sun Apr 30 14:18:32 2023 -0700", "commit_message": "Fix tox -e twine", "files_name": [".github/workflows/ci.yaml", "CONTRIBUTING.rst"]}, {"commit_id": "9f0f0e5c884d9e56ce201ecee3b23d7a48d30215", "commit_date": "Sun Apr 30 15:36:18 2023 -0700", "commit_message": "Drop EoL pypy-3.7, add pypy-3.9", "files_name": [".github/workflows/ci.yaml"]}, {"commit_id": "e3b8cdd7d6396a6dd04694a99d17b8c9e35e4952", "commit_date": "Sun Apr 30 15:47:58 2023 -0700", "commit_message": "More change fragments", "files_name": ["changelog.d/365.feature.rst", "changelog.d/365.removal.rst"]}, {"commit_id": "5267b9e9c0a7e1c8790137796ef2739f52507dce", "commit_date": "Mon Sep 5 18:58:06 2022 -0700", "commit_message": "Begin the typing", "files_name": ["MANIFEST.in", "mypy.ini", "setup.py", "src/treq/py.typed", "tox.ini"]}, {"commit_id": "19a95ac079d9d51a51fa270181fd445fa8c3cf2f", "commit_date": "Tue Dec 20 12:47:24 2022 -0800", "commit_message": "Ignore per-process Coverage files", "files_name": [".gitignore"]}, {"commit_id": "a0c3a2931dc09b389c8c4d6edf4ce2a1e7425ea0", "commit_date": "Tue Dec 20 21:54:54 2022 -0800", "commit_message": "Bump MyPy", "files_name": ["tox.ini"]}, {"commit_id": "0d892777263b4308dc66bb24e5dc1d046d57f7b9", "commit_date": "Mon Sep 5 23:26:43 2022 -0700", "commit_message": "MyPy clean", "files_name": ["mypy.ini", "pyproject.toml", "src/treq/__init__.py", "src/treq/_agentspy.py", "src/treq/_types.py", "src/treq/client.py", "src/treq/multipart.py", "src/treq/response.py", "src/treq/test/local_httpbin/child.py", "src/treq/test/local_httpbin/test/test_child.py", "src/treq/test/test_agentspy.py", "src/treq/test/test_api.py", "src/treq/testing.py"]}, {"commit_id": "2277b903de568ff43c812a260639a99c48027c4a", "commit_date": "Mon Apr 17 20:46:28 2023 -0700", "commit_message": "Really clean", "files_name": ["src/treq/_agentspy.py", "src/treq/auth.py", "src/treq/test/test_api.py"]}, {"commit_id": "1288960612a0bc8434749984c0bb9bb6b63561a9", "commit_date": "Mon Apr 17 20:50:00 2023 -0700", "commit_message": "Update to MyPy 1.0.1", "files_name": ["src/treq/multipart.py", "tox.ini"]}, {"commit_id": "c48ea18fb7207e2d3b14d29b87f0a53d78c6934f", "commit_date": "Mon Apr 17 21:37:09 2023 -0700", "commit_message": "Type some multipart tests", "files_name": ["src/treq/multipart.py", "src/treq/test/test_multipart.py"]}, {"commit_id": "80f778123265ddc36f8bff9bec57978947ea5143", "commit_date": "Mon Apr 17 22:05:12 2023 -0700", "commit_message": "Drop deprecated behaviors", "files_name": ["changelog.d/297.removal.rst", "changelog.d/302.removal.rst", "src/treq/test/test_client.py"]}, {"commit_id": "d777c00df6352ce9f7466b42c07f137dc109d727", "commit_date": "Mon Apr 17 22:21:52 2023 -0700", "commit_message": "Allow bytes to pass through", "files_name": ["src/treq/test/test_multipart.py"]}, {"commit_id": "da9a4643564d7bfe2e0da5d5a2c50423bf07a24d", "commit_date": "Mon Apr 17 22:29:12 2023 -0700", "commit_message": "Run MyPy in CI", "files_name": [".github/workflows/ci.yaml"]}, {"commit_id": "bbd077572d2773c4e2e8cd0814deccc442d615c3", "commit_date": "Mon Apr 17 22:33:43 2023 -0700", "commit_message": "Add change fragment", "files_name": ["changelog.d/366.feature.rst"]}, {"commit_id": "9636b5224388bd20fac271e6e7cccc03f645d672", "commit_date": "Mon Apr 17 22:38:58 2023 -0700", "commit_message": "Run MyPy on Python 3.8", "files_name": [".github/workflows/ci.yaml", "tox.ini"]}, {"commit_id": "9e51b02cb8ec0adc5674f5376d0e7994e8fef115", "commit_date": "Mon Apr 17 22:44:56 2023 -0700", "commit_message": "Backport annotations to 3.8", "files_name": ["src/treq/_agentspy.py", "src/treq/_types.py", "src/treq/client.py", "src/treq/multipart.py"]}, {"commit_id": "e386f03e2ea30dd731f9b9f9c730b4172ffd226e", "commit_date": "Mon Apr 17 22:46:49 2023 -0700", "commit_message": "Nevermind mypy.ini, long live pyproject.toml", "files_name": ["MANIFEST.in"]}, {"commit_id": "a0c764a4f0625429e8fc0b87cd14d1e2e1560d14", "commit_date": "Mon Apr 17 22:52:10 2023 -0700", "commit_message": "Fix lint", "files_name": ["src/treq/client.py"]}, {"commit_id": "c09df9f97f4a14210322cbb569214efd0fe79e16", "commit_date": "Fri Apr 28 22:52:52 2023 -0700", "commit_message": "Literally fix it?", "files_name": ["src/treq/multipart.py"]}, {"commit_id": "08bb4d3f878e79c6d0755fd80b74ffd9ccdc2726", "commit_date": "Sun Apr 30 15:55:27 2023 -0700", "commit_message": "Merge pull request #365 from twisted/363-drop-3.6", "files_name": ["a5799b6deb9c36a7f9c940ddf21b97d340e8649a - Sun Apr 30 16:01:52 2023 -0700 : Quote Deferred annotations", "src/treq/_agentspy.py", "src/treq/client.py", "src/treq/multipart.py"]}, {"commit_id": "f6c633e224508aa1e3b35d779cc09af1f92ee579", "commit_date": "Sun Apr 30 16:10:33 2023 -0700", "commit_message": "Update package metadata", "files_name": ["setup.py"]}, {"commit_id": "b83d3d27bfb77f496b46ec1217da428cf64e6c2a", "commit_date": "Sun Apr 30 16:31:08 2023 -0700", "commit_message": "Up Twisted dep to 22.10.0", "files_name": ["setup.py", "tox.ini"]}, {"commit_id": "3a89b1de94d3c4eb159f06fdc82b72401b71caac", "commit_date": "Sun Apr 30 17:01:02 2023 -0700", "commit_message": "Enable Dependabot for GitHub Actions", "files_name": [".github/dependabot.yml"]}], "parents": [{"commit_id_before": "d89d553240f1c1e434bb137e5ce53877c54285e6", "url_before": "https://api.github.com/repos/twisted/treq/commits/d89d553240f1c1e434bb137e5ce53877c54285e6", "html_url_before": "https://github.com/twisted/treq/commit/d89d553240f1c1e434bb137e5ce53877c54285e6"}, {"commit_id_before": "b1c33ca5df97488c569ceda984662ec92a9280cd", "url_before": "https://api.github.com/repos/twisted/treq/commits/b1c33ca5df97488c569ceda984662ec92a9280cd", "html_url_before": "https://github.com/twisted/treq/commit/b1c33ca5df97488c569ceda984662ec92a9280cd"}], "details": [{"raw_url": "https://github.com/twisted/treq/raw/1da6022cc880bbcff59321abe02bf8498b89efb2/changelog.d%2F339.bugfix.rst", "code": "Cookies specified as a dict were sent to every domain, not just the domain of the request, potentially exposing them on redirect. See `GHSA-fhpf-pp6p-55qc <https://github.com/twisted/treq/security/advisories/GHSA-fhpf-pp6p-55qc>`_.\n", "code_before": "Cookies specified as a dict were sent to every domain, not just the domain of the request, potentially exposing them on redirect. See `GHSA-fhpf-pp6p-55qc <https://github.com/twisted/treq/security/advisories/GHSA-fhpf-pp6p-55qc>`_.\n", "patch": "@@ -0,0 +1 @@\n+Cookies specified as a dict were sent to every domain, not just the domain of the request, potentially exposing them on redirect. See `GHSA-fhpf-pp6p-55qc <https://github.com/twisted/treq/security/advisories/GHSA-fhpf-pp6p-55qc>`_.", "file_path": "files/2022_2/1003", "file_language": "rst", "file_name": "changelog.d/339.bugfix.rst", "outdated_file_modify": 0, "outdated_file_before": 0, "outdated_file_after": 0}, {"raw_url": "https://github.com/twisted/treq/raw/1da6022cc880bbcff59321abe02bf8498b89efb2/src%2Ftreq%2Fclient.py", "code": "import io\nimport mimetypes\nimport uuid\nimport warnings\nfrom collections.abc import Mapping\nfrom http.cookiejar import CookieJar, Cookie\nfrom urllib.parse import quote_plus, urlencode as _urlencode\n\nfrom twisted.internet.interfaces import IProtocol\nfrom twisted.internet.defer import Deferred\nfrom twisted.python.components import proxyForInterface\nfrom twisted.python.filepath import FilePath\nfrom hyperlink import DecodedURL, EncodedURL\n\nfrom twisted.web.http_headers import Headers\nfrom twisted.web.iweb import IBodyProducer, IResponse\n\nfrom twisted.web.client import (\n    FileBodyProducer,\n    RedirectAgent,\n    BrowserLikeRedirectAgent,\n    ContentDecoderAgent,\n    GzipDecoder,\n    CookieAgent\n)\n\nfrom twisted.python.components import registerAdapter\nfrom json import dumps as json_dumps\n\nfrom treq.auth import add_auth\nfrom treq import multipart\nfrom treq.response import _Response\nfrom requests.cookies import merge_cookies\n\n\n_NOTHING = object()\n\n\ndef urlencode(query, doseq):\n    s = _urlencode(query, doseq)\n    if not isinstance(s, bytes):\n        s = s.encode(\"ascii\")\n    return s\n\n\ndef _scoped_cookiejar_from_dict(url_object, cookie_dict):\n    \"\"\"\n    Create a CookieJar from a dictionary whose cookies are all scoped to the\n    given URL's origin.\n\n    @note: This does not scope the cookies to any particular path, only the\n        host, port, and scheme of the given URL.\n    \"\"\"\n    cookie_jar = CookieJar()\n    if cookie_dict is None:\n        return cookie_jar\n    for k, v in cookie_dict.items():\n        secure = url_object.scheme == 'https'\n        port_specified = not (\n            (url_object.scheme == \"https\" and url_object.port == 443)\n            or (url_object.scheme == \"http\" and url_object.port == 80)\n        )\n        port = str(url_object.port)\n        domain = url_object.host\n        netscape_domain = domain if '.' in domain else domain + '.local'\n\n        cookie_jar.set_cookie(\n            Cookie(\n                # Scoping\n                domain=netscape_domain,\n                port=port,\n                secure=secure,\n                port_specified=port_specified,\n\n                # Contents\n                name=k,\n                value=v,\n\n                # Constant/always-the-same stuff\n                version=0,\n                path=\"/\",\n                expires=None,\n                discard=False,\n                comment=None,\n                comment_url=None,\n                rfc2109=False,\n                path_specified=False,\n                domain_specified=False,\n                domain_initial_dot=False,\n                rest=[],\n            )\n        )\n    return cookie_jar\n\n\nclass _BodyBufferingProtocol(proxyForInterface(IProtocol)):\n    def __init__(self, original, buffer, finished):\n        self.original = original\n        self.buffer = buffer\n        self.finished = finished\n\n    def dataReceived(self, data):\n        self.buffer.append(data)\n        self.original.dataReceived(data)\n\n    def connectionLost(self, reason):\n        self.original.connectionLost(reason)\n        self.finished.errback(reason)\n\n\nclass _BufferedResponse(proxyForInterface(IResponse)):\n    def __init__(self, original):\n        self.original = original\n        self._buffer = []\n        self._waiters = []\n        self._waiting = None\n        self._finished = False\n        self._reason = None\n\n    def _deliverWaiting(self, reason):\n        self._reason = reason\n        self._finished = True\n        for waiter in self._waiters:\n            for segment in self._buffer:\n                waiter.dataReceived(segment)\n            waiter.connectionLost(reason)\n\n    def deliverBody(self, protocol):\n        if self._waiting is None and not self._finished:\n            self._waiting = Deferred()\n            self._waiting.addBoth(self._deliverWaiting)\n            self.original.deliverBody(\n                _BodyBufferingProtocol(\n                    protocol,\n                    self._buffer,\n                    self._waiting\n                )\n            )\n        elif self._finished:\n            for segment in self._buffer:\n                protocol.dataReceived(segment)\n            protocol.connectionLost(self._reason)\n        else:\n            self._waiters.append(protocol)\n\n\nclass HTTPClient:\n    def __init__(self, agent, cookiejar=None,\n                 data_to_body_producer=IBodyProducer):\n        self._agent = agent\n        if cookiejar is None:\n            cookiejar = CookieJar()\n        self._cookiejar = cookiejar\n        self._data_to_body_producer = data_to_body_producer\n\n    def get(self, url, **kwargs):\n        \"\"\"\n        See :func:`treq.get()`.\n        \"\"\"\n        kwargs.setdefault('_stacklevel', 3)\n        return self.request('GET', url, **kwargs)\n\n    def put(self, url, data=None, **kwargs):\n        \"\"\"\n        See :func:`treq.put()`.\n        \"\"\"\n        kwargs.setdefault('_stacklevel', 3)\n        return self.request('PUT', url, data=data, **kwargs)\n\n    def patch(self, url, data=None, **kwargs):\n        \"\"\"\n        See :func:`treq.patch()`.\n        \"\"\"\n        kwargs.setdefault('_stacklevel', 3)\n        return self.request('PATCH', url, data=data, **kwargs)\n\n    def post(self, url, data=None, **kwargs):\n        \"\"\"\n        See :func:`treq.post()`.\n        \"\"\"\n        kwargs.setdefault('_stacklevel', 3)\n        return self.request('POST', url, data=data, **kwargs)\n\n    def head(self, url, **kwargs):\n        \"\"\"\n        See :func:`treq.head()`.\n        \"\"\"\n        kwargs.setdefault('_stacklevel', 3)\n        return self.request('HEAD', url, **kwargs)\n\n    def delete(self, url, **kwargs):\n        \"\"\"\n        See :func:`treq.delete()`.\n        \"\"\"\n        kwargs.setdefault('_stacklevel', 3)\n        return self.request('DELETE', url, **kwargs)\n\n    def request(\n        self,\n        method,\n        url,\n        *,\n        params=None,\n        headers=None,\n        data=None,\n        files=None,\n        json=_NOTHING,\n        auth=None,\n        cookies=None,\n        allow_redirects=True,\n        browser_like_redirects=False,\n        unbuffered=False,\n        reactor=None,\n        timeout=None,\n        _stacklevel=2,\n    ):\n        \"\"\"\n        See :func:`treq.request()`.\n        \"\"\"\n        method = method.encode('ascii').upper()\n\n        if isinstance(url, DecodedURL):\n            parsed_url = url.encoded_url\n        elif isinstance(url, EncodedURL):\n            parsed_url = url\n        elif isinstance(url, str):\n            # We use hyperlink in lazy mode so that users can pass arbitrary\n            # bytes in the path and querystring.\n            parsed_url = EncodedURL.from_text(url)\n        else:\n            parsed_url = EncodedURL.from_text(url.decode('ascii'))\n\n        # Join parameters provided in the URL\n        # and the ones passed as argument.\n        if params:\n            parsed_url = parsed_url.replace(\n                query=parsed_url.query + tuple(_coerced_query_params(params))\n            )\n\n        url = parsed_url.to_uri().to_text().encode('ascii')\n\n        headers = self._request_headers(headers, _stacklevel + 1)\n\n        bodyProducer, contentType = self._request_body(data, files, json,\n                                                       stacklevel=_stacklevel + 1)\n        if contentType is not None:\n            headers.setRawHeaders(b'Content-Type', [contentType])\n\n        if not isinstance(cookies, CookieJar):\n            cookies = _scoped_cookiejar_from_dict(parsed_url, cookies)\n\n        cookies = merge_cookies(self._cookiejar, cookies)\n        wrapped_agent = CookieAgent(self._agent, cookies)\n\n        if allow_redirects:\n            if browser_like_redirects:\n                wrapped_agent = BrowserLikeRedirectAgent(wrapped_agent)\n            else:\n                wrapped_agent = RedirectAgent(wrapped_agent)\n\n        wrapped_agent = ContentDecoderAgent(wrapped_agent,\n                                            [(b'gzip', GzipDecoder)])\n\n        if auth:\n            wrapped_agent = add_auth(wrapped_agent, auth)\n\n        d = wrapped_agent.request(\n            method, url, headers=headers,\n            bodyProducer=bodyProducer)\n\n        if reactor is None:\n            from twisted.internet import reactor\n        if timeout:\n            delayedCall = reactor.callLater(timeout, d.cancel)\n\n            def gotResult(result):\n                if delayedCall.active():\n                    delayedCall.cancel()\n                return result\n\n            d.addBoth(gotResult)\n\n        if not unbuffered:\n            d.addCallback(_BufferedResponse)\n\n        return d.addCallback(_Response, cookies)\n\n    def _request_headers(self, headers, stacklevel):\n        \"\"\"\n        Convert the *headers* argument to a :class:`Headers` instance\n\n        :returns:\n            :class:`twisted.web.http_headers.Headers`\n        \"\"\"\n        if isinstance(headers, dict):\n            h = Headers({})\n            for k, v in headers.items():\n                if isinstance(v, (bytes, str)):\n                    h.addRawHeader(k, v)\n                elif isinstance(v, list):\n                    h.setRawHeaders(k, v)\n                else:\n                    warnings.warn(\n                        (\n                            \"The value of headers key {!r} has non-string type {}\"\n                            \" and will be dropped.\"\n                            \" This will raise TypeError in the next treq release.\"\n                        ).format(k, type(v)),\n                        DeprecationWarning,\n                        stacklevel=stacklevel,\n                    )\n            return h\n        if isinstance(headers, Headers):\n            return headers\n        if headers is None:\n            return Headers({})\n\n        warnings.warn(\n            (\n                \"headers must be a dict, twisted.web.http_headers.Headers, or None,\"\n                \" but found {}, which will be ignored.\"\n                \" This will raise TypeError in the next treq release.\"\n            ).format(type(headers)),\n            DeprecationWarning,\n            stacklevel=stacklevel,\n        )\n        return Headers({})\n\n    def _request_body(self, data, files, json, stacklevel):\n        \"\"\"\n        Here we choose a right producer based on the parameters passed in.\n\n        :params data:\n            Arbitrary request body data.\n\n            If *files* is also passed this must be a :class:`dict`,\n            a :class:`tuple` or :class:`list` of field tuples as accepted by\n            :class:`MultiPartProducer`. The request is assigned a Content-Type\n            of ``multipart/form-data``.\n\n            If a :class:`dict`, :class:`list`, or :class:`tuple` it is\n            URL-encoded and the request assigned a Content-Type of\n            ``application/x-www-form-urlencoded``.\n\n            Otherwise, any non-``None`` value is passed to the client's\n            *data_to_body_producer* callable (by default,\n            :class:`IBodyProducer`), which accepts file-like objects.\n\n        :params files:\n            Files to include in the request body, in any of the several formats\n            described in :func:`_convert_files()`.\n\n        :params json:\n            JSON-encodable data, or the sentinel `_NOTHING`. The sentinel is\n            necessary because ``None`` is a valid JSON value.\n        \"\"\"\n        if json is not _NOTHING and (files or data):\n            warnings.warn(\n                (\n                    \"Argument 'json' will be ignored because '{}' was also passed.\"\n                    \" This will raise TypeError in the next treq release.\"\n                ).format(\"data\" if data else \"files\"),\n                DeprecationWarning,\n                stacklevel=stacklevel,\n            )\n\n        if files:\n            # If the files keyword is present we will issue a\n            # multipart/form-data request as it suits better for cases\n            # with files and/or large objects.\n            files = list(_convert_files(files))\n            boundary = str(uuid.uuid4()).encode('ascii')\n            if data:\n                data = _convert_params(data)\n            else:\n                data = []\n\n            return (\n                multipart.MultiPartProducer(data + files, boundary=boundary),\n                b'multipart/form-data; boundary=' + boundary,\n            )\n\n        # Otherwise stick to x-www-form-urlencoded format\n        # as it's generally faster for smaller requests.\n        if isinstance(data, (dict, list, tuple)):\n            return (\n                self._data_to_body_producer(urlencode(data, doseq=True)),\n                b'application/x-www-form-urlencoded',\n            )\n        elif data:\n            return (\n                self._data_to_body_producer(data),\n                None,\n            )\n\n        if json is not _NOTHING:\n            return (\n                self._data_to_body_producer(\n                    json_dumps(json, separators=(u',', u':')).encode('utf-8'),\n                ),\n                b'application/json; charset=UTF-8',\n            )\n\n        return None, None\n\n\ndef _convert_params(params):\n    if hasattr(params, \"iteritems\"):\n        return list(sorted(params.iteritems()))\n    elif hasattr(params, \"items\"):\n        return list(sorted(params.items()))\n    elif isinstance(params, (tuple, list)):\n        return list(params)\n    else:\n        raise ValueError(\"Unsupported format\")\n\n\ndef _convert_files(files):\n    \"\"\"\n    Files can be passed in a variety of formats:\n\n    * {\"fieldname\": open(\"bla.f\", \"rb\")}\n    * {\"fieldname\": (\"filename\", open(\"bla.f\", \"rb\"))}\n    * {\"fieldname\": (\"filename\", \"content-type\", open(\"bla.f\", \"rb\"))}\n    * Anything that has iteritems method, e.g. MultiDict:\n      MultiDict([(name, open()), (name, open())]\n\n    Our goal is to standardize it to unified form of:\n\n    * [(param, (file name, content type, producer))]\n    \"\"\"\n\n    if hasattr(files, \"iteritems\"):\n        files = files.iteritems()\n    elif hasattr(files, \"items\"):\n        files = files.items()\n\n    for param, val in files:\n        file_name, content_type, fobj = (None, None, None)\n        if isinstance(val, tuple):\n            if len(val) == 2:\n                file_name, fobj = val\n            elif len(val) == 3:\n                file_name, content_type, fobj = val\n            else:\n                # NB: This is TypeError for backward compatibility. This case\n                # used to fall through to `IBodyProducer`, below, which raised\n                # TypeError about being unable to coerce None.\n                raise TypeError(\n                    (\n                        \"`files` argument must be a sequence of tuples of\"\n                        \" (file_name, file_obj) or\"\n                        \" (file_name, content_type, file_obj),\"\n                        \" but the {!r} tuple has length {}: {!r}\"\n                    ).format(param, len(val), val),\n                )\n        else:\n            fobj = val\n            if hasattr(fobj, \"name\"):\n                file_name = FilePath(fobj.name).basename()\n\n        if not content_type:\n            content_type = _guess_content_type(file_name)\n\n        # XXX: Shouldn't this call self._data_to_body_producer?\n        yield (param, (file_name, content_type, IBodyProducer(fobj)))\n\n\ndef _query_quote(v):\n    # (Any) -> Text\n    \"\"\"\n    Percent-encode a querystring name or value.\n\n    :param v: A value.\n\n    :returns:\n        The value, coerced to a string and percent-encoded as appropriate for\n        a querystring (with space as ``+``).\n    \"\"\"\n    if not isinstance(v, (str, bytes)):\n        v = str(v)\n    if not isinstance(v, bytes):\n        v = v.encode(\"utf-8\")\n    q = quote_plus(v)\n    return q\n\n\ndef _coerced_query_params(params):\n    \"\"\"\n    Carefully coerce *params* in the same way as `urllib.parse.urlencode()`\n\n    Parameter names and values are coerced to unicode, which is encoded as\n    UTF-8 and then percent-encoded. As a special case, `bytes` are directly\n    percent-encoded.\n\n    :param params:\n        A mapping or sequence of (name, value) two-tuples. The value may be\n        a list or tuple of multiple values. Names and values may be pretty much\n        any type.\n\n    :returns:\n        A generator that yields two-tuples containing percent-encoded text\n        strings.\n    :rtype:\n        Iterator[Tuple[Text, Text]]\n    \"\"\"\n    if isinstance(params, Mapping):\n        items = params.items()\n    else:\n        items = params\n\n    for key, values in items:\n        key_quoted = _query_quote(key)\n\n        if not isinstance(values, (list, tuple)):\n            values = (values,)\n        for value in values:\n            yield key_quoted, _query_quote(value)\n\n\ndef _from_bytes(orig_bytes):\n    return FileBodyProducer(io.BytesIO(orig_bytes))\n\n\ndef _from_file(orig_file):\n    return FileBodyProducer(orig_file)\n\n\ndef _guess_content_type(filename):\n    if filename:\n        guessed = mimetypes.guess_type(filename)[0]\n    else:\n        guessed = None\n    return guessed or 'application/octet-stream'\n\n\nregisterAdapter(_from_bytes, bytes, IBodyProducer)\nregisterAdapter(_from_file, io.BytesIO, IBodyProducer)\n\n# file()/open() equiv\nregisterAdapter(_from_file, io.BufferedReader, IBodyProducer)\n", "code_before": "import io\nimport mimetypes\nimport uuid\nimport warnings\nfrom collections.abc import Mapping\nfrom http.cookiejar import CookieJar, Cookie\nfrom urllib.parse import quote_plus, urlencode as _urlencode\n\nfrom twisted.internet.interfaces import IProtocol\nfrom twisted.internet.defer import Deferred\nfrom twisted.python.components import proxyForInterface\nfrom twisted.python.filepath import FilePath\nfrom hyperlink import DecodedURL, EncodedURL\n\nfrom twisted.web.http_headers import Headers\nfrom twisted.web.iweb import IBodyProducer, IResponse\n\nfrom twisted.web.client import (\n    FileBodyProducer,\n    RedirectAgent,\n    BrowserLikeRedirectAgent,\n    ContentDecoderAgent,\n    GzipDecoder,\n    CookieAgent\n)\n\nfrom twisted.python.components import registerAdapter\nfrom json import dumps as json_dumps\n\nfrom treq.auth import add_auth\nfrom treq import multipart\nfrom treq.response import _Response\nfrom requests.cookies import merge_cookies\n\n\n_NOTHING = object()\n\n\ndef urlencode(query, doseq):\n    s = _urlencode(query, doseq)\n    if not isinstance(s, bytes):\n        s = s.encode(\"ascii\")\n    return s\n\n\ndef _scoped_cookiejar_from_dict(url_object, cookie_dict):\n    \"\"\"\n    Create a CookieJar from a dictionary whose cookies are all scoped to the\n    given URL's origin.\n\n    @note: This does not scope the cookies to any particular path, only the\n        host, port, and scheme of the given URL.\n    \"\"\"\n    cookie_jar = CookieJar()\n    if cookie_dict is None:\n        return cookie_jar\n    for k, v in cookie_dict.items():\n        secure = url_object.scheme == 'https'\n        port_specified = not (\n            (url_object.scheme == \"https\" and url_object.port == 443)\n            or (url_object.scheme == \"http\" and url_object.port == 80)\n        )\n        port = str(url_object.port)\n        domain = url_object.host\n        netscape_domain = domain if '.' in domain else domain + '.local'\n\n        cookie_jar.set_cookie(\n            Cookie(\n                # Scoping\n                domain=netscape_domain,\n                port=port,\n                secure=secure,\n                port_specified=port_specified,\n\n                # Contents\n                name=k,\n                value=v,\n\n                # Constant/always-the-same stuff\n                version=0,\n                path=\"/\",\n                expires=None,\n                discard=False,\n                comment=None,\n                comment_url=None,\n                rfc2109=False,\n                path_specified=False,\n                domain_specified=False,\n                domain_initial_dot=False,\n                rest=[],\n            )\n        )\n    return cookie_jar\n\n\nclass _BodyBufferingProtocol(proxyForInterface(IProtocol)):\n    def __init__(self, original, buffer, finished):\n        self.original = original\n        self.buffer = buffer\n        self.finished = finished\n\n    def dataReceived(self, data):\n        self.buffer.append(data)\n        self.original.dataReceived(data)\n\n    def connectionLost(self, reason):\n        self.original.connectionLost(reason)\n        self.finished.errback(reason)\n\n\nclass _BufferedResponse(proxyForInterface(IResponse)):\n    def __init__(self, original):\n        self.original = original\n        self._buffer = []\n        self._waiters = []\n        self._waiting = None\n        self._finished = False\n        self._reason = None\n\n    def _deliverWaiting(self, reason):\n        self._reason = reason\n        self._finished = True\n        for waiter in self._waiters:\n            for segment in self._buffer:\n                waiter.dataReceived(segment)\n            waiter.connectionLost(reason)\n\n    def deliverBody(self, protocol):\n        if self._waiting is None and not self._finished:\n            self._waiting = Deferred()\n            self._waiting.addBoth(self._deliverWaiting)\n            self.original.deliverBody(\n                _BodyBufferingProtocol(\n                    protocol,\n                    self._buffer,\n                    self._waiting\n                )\n            )\n        elif self._finished:\n            for segment in self._buffer:\n                protocol.dataReceived(segment)\n            protocol.connectionLost(self._reason)\n        else:\n            self._waiters.append(protocol)\n\n\nclass HTTPClient:\n    def __init__(self, agent, cookiejar=None,\n                 data_to_body_producer=IBodyProducer):\n        self._agent = agent\n        if cookiejar is None:\n            cookiejar = CookieJar()\n        self._cookiejar = cookiejar\n        self._data_to_body_producer = data_to_body_producer\n\n    def get(self, url, **kwargs):\n        \"\"\"\n        See :func:`treq.get()`.\n        \"\"\"\n        kwargs.setdefault('_stacklevel', 3)\n        return self.request('GET', url, **kwargs)\n\n    def put(self, url, data=None, **kwargs):\n        \"\"\"\n        See :func:`treq.put()`.\n        \"\"\"\n        kwargs.setdefault('_stacklevel', 3)\n        return self.request('PUT', url, data=data, **kwargs)\n\n    def patch(self, url, data=None, **kwargs):\n        \"\"\"\n        See :func:`treq.patch()`.\n        \"\"\"\n        kwargs.setdefault('_stacklevel', 3)\n        return self.request('PATCH', url, data=data, **kwargs)\n\n    def post(self, url, data=None, **kwargs):\n        \"\"\"\n        See :func:`treq.post()`.\n        \"\"\"\n        kwargs.setdefault('_stacklevel', 3)\n        return self.request('POST', url, data=data, **kwargs)\n\n    def head(self, url, **kwargs):\n        \"\"\"\n        See :func:`treq.head()`.\n        \"\"\"\n        kwargs.setdefault('_stacklevel', 3)\n        return self.request('HEAD', url, **kwargs)\n\n    def delete(self, url, **kwargs):\n        \"\"\"\n        See :func:`treq.delete()`.\n        \"\"\"\n        kwargs.setdefault('_stacklevel', 3)\n        return self.request('DELETE', url, **kwargs)\n\n    def request(\n        self,\n        method,\n        url,\n        *,\n        params=None,\n        headers=None,\n        data=None,\n        files=None,\n        json=_NOTHING,\n        auth=None,\n        cookies=None,\n        allow_redirects=True,\n        browser_like_redirects=False,\n        unbuffered=False,\n        reactor=None,\n        timeout=None,\n        _stacklevel=2,\n    ):\n        \"\"\"\n        See :func:`treq.request()`.\n        \"\"\"\n        method = method.encode('ascii').upper()\n\n        if isinstance(url, DecodedURL):\n            parsed_url = url.encoded_url\n        elif isinstance(url, EncodedURL):\n            parsed_url = url\n        elif isinstance(url, str):\n            # We use hyperlink in lazy mode so that users can pass arbitrary\n            # bytes in the path and querystring.\n            parsed_url = EncodedURL.from_text(url)\n        else:\n            parsed_url = EncodedURL.from_text(url.decode('ascii'))\n\n        # Join parameters provided in the URL\n        # and the ones passed as argument.\n        if params:\n            parsed_url = parsed_url.replace(\n                query=parsed_url.query + tuple(_coerced_query_params(params))\n            )\n\n        url = parsed_url.to_uri().to_text().encode('ascii')\n\n        headers = self._request_headers(headers, _stacklevel + 1)\n\n        bodyProducer, contentType = self._request_body(data, files, json,\n                                                       stacklevel=_stacklevel + 1)\n        if contentType is not None:\n            headers.setRawHeaders(b'Content-Type', [contentType])\n\n        if not isinstance(cookies, CookieJar):\n            cookies = _scoped_cookiejar_from_dict(parsed_url, cookies)\n\n        cookies = merge_cookies(self._cookiejar, cookies)\n        wrapped_agent = CookieAgent(self._agent, cookies)\n\n        if allow_redirects:\n            if browser_like_redirects:\n                wrapped_agent = BrowserLikeRedirectAgent(wrapped_agent)\n            else:\n                wrapped_agent = RedirectAgent(wrapped_agent)\n\n        wrapped_agent = ContentDecoderAgent(wrapped_agent,\n                                            [(b'gzip', GzipDecoder)])\n\n        if auth:\n            wrapped_agent = add_auth(wrapped_agent, auth)\n\n        d = wrapped_agent.request(\n            method, url, headers=headers,\n            bodyProducer=bodyProducer)\n\n        if reactor is None:\n            from twisted.internet import reactor\n        if timeout:\n            delayedCall = reactor.callLater(timeout, d.cancel)\n\n            def gotResult(result):\n                if delayedCall.active():\n                    delayedCall.cancel()\n                return result\n\n            d.addBoth(gotResult)\n\n        if not unbuffered:\n            d.addCallback(_BufferedResponse)\n\n        return d.addCallback(_Response, cookies)\n\n    def _request_headers(self, headers, stacklevel):\n        \"\"\"\n        Convert the *headers* argument to a :class:`Headers` instance\n\n        :returns:\n            :class:`twisted.web.http_headers.Headers`\n        \"\"\"\n        if isinstance(headers, dict):\n            h = Headers({})\n            for k, v in headers.items():\n                if isinstance(v, (bytes, str)):\n                    h.addRawHeader(k, v)\n                elif isinstance(v, list):\n                    h.setRawHeaders(k, v)\n                else:\n                    warnings.warn(\n                        (\n                            \"The value of headers key {!r} has non-string type {}\"\n                            \" and will be dropped.\"\n                            \" This will raise TypeError in the next treq release.\"\n                        ).format(k, type(v)),\n                        DeprecationWarning,\n                        stacklevel=stacklevel,\n                    )\n            return h\n        if isinstance(headers, Headers):\n            return headers\n        if headers is None:\n            return Headers({})\n\n        warnings.warn(\n            (\n                \"headers must be a dict, twisted.web.http_headers.Headers, or None,\"\n                \" but found {}, which will be ignored.\"\n                \" This will raise TypeError in the next treq release.\"\n            ).format(type(headers)),\n            DeprecationWarning,\n            stacklevel=stacklevel,\n        )\n        return Headers({})\n\n    def _request_body(self, data, files, json, stacklevel):\n        \"\"\"\n        Here we choose a right producer based on the parameters passed in.\n\n        :params data:\n            Arbitrary request body data.\n\n            If *files* is also passed this must be a :class:`dict`,\n            a :class:`tuple` or :class:`list` of field tuples as accepted by\n            :class:`MultiPartProducer`. The request is assigned a Content-Type\n            of ``multipart/form-data``.\n\n            If a :class:`dict`, :class:`list`, or :class:`tuple` it is\n            URL-encoded and the request assigned a Content-Type of\n            ``application/x-www-form-urlencoded``.\n\n            Otherwise, any non-``None`` value is passed to the client's\n            *data_to_body_producer* callable (by default,\n            :class:`IBodyProducer`), which accepts file-like objects.\n\n        :params files:\n            Files to include in the request body, in any of the several formats\n            described in :func:`_convert_files()`.\n\n        :params json:\n            JSON-encodable data, or the sentinel `_NOTHING`. The sentinel is\n            necessary because ``None`` is a valid JSON value.\n        \"\"\"\n        if json is not _NOTHING and (files or data):\n            warnings.warn(\n                (\n                    \"Argument 'json' will be ignored because '{}' was also passed.\"\n                    \" This will raise TypeError in the next treq release.\"\n                ).format(\"data\" if data else \"files\"),\n                DeprecationWarning,\n                stacklevel=stacklevel,\n            )\n\n        if files:\n            # If the files keyword is present we will issue a\n            # multipart/form-data request as it suits better for cases\n            # with files and/or large objects.\n            files = list(_convert_files(files))\n            boundary = str(uuid.uuid4()).encode('ascii')\n            if data:\n                data = _convert_params(data)\n            else:\n                data = []\n\n            return (\n                multipart.MultiPartProducer(data + files, boundary=boundary),\n                b'multipart/form-data; boundary=' + boundary,\n            )\n\n        # Otherwise stick to x-www-form-urlencoded format\n        # as it's generally faster for smaller requests.\n        if isinstance(data, (dict, list, tuple)):\n            return (\n                self._data_to_body_producer(urlencode(data, doseq=True)),\n                b'application/x-www-form-urlencoded',\n            )\n        elif data:\n            return (\n                self._data_to_body_producer(data),\n                None,\n            )\n\n        if json is not _NOTHING:\n            return (\n                self._data_to_body_producer(\n                    json_dumps(json, separators=(u',', u':')).encode('utf-8'),\n                ),\n                b'application/json; charset=UTF-8',\n            )\n\n        return None, None\n\n\ndef _convert_params(params):\n    if hasattr(params, \"iteritems\"):\n        return list(sorted(params.iteritems()))\n    elif hasattr(params, \"items\"):\n        return list(sorted(params.items()))\n    elif isinstance(params, (tuple, list)):\n        return list(params)\n    else:\n        raise ValueError(\"Unsupported format\")\n\n\ndef _convert_files(files):\n    \"\"\"\n    Files can be passed in a variety of formats:\n\n    * {\"fieldname\": open(\"bla.f\", \"rb\")}\n    * {\"fieldname\": (\"filename\", open(\"bla.f\", \"rb\"))}\n    * {\"fieldname\": (\"filename\", \"content-type\", open(\"bla.f\", \"rb\"))}\n    * Anything that has iteritems method, e.g. MultiDict:\n      MultiDict([(name, open()), (name, open())]\n\n    Our goal is to standardize it to unified form of:\n\n    * [(param, (file name, content type, producer))]\n    \"\"\"\n\n    if hasattr(files, \"iteritems\"):\n        files = files.iteritems()\n    elif hasattr(files, \"items\"):\n        files = files.items()\n\n    for param, val in files:\n        file_name, content_type, fobj = (None, None, None)\n        if isinstance(val, tuple):\n            if len(val) == 2:\n                file_name, fobj = val\n            elif len(val) == 3:\n                file_name, content_type, fobj = val\n            else:\n                # NB: This is TypeError for backward compatibility. This case\n                # used to fall through to `IBodyProducer`, below, which raised\n                # TypeError about being unable to coerce None.\n                raise TypeError(\n                    (\n                        \"`files` argument must be a sequence of tuples of\"\n                        \" (file_name, file_obj) or\"\n                        \" (file_name, content_type, file_obj),\"\n                        \" but the {!r} tuple has length {}: {!r}\"\n                    ).format(param, len(val), val),\n                )\n        else:\n            fobj = val\n            if hasattr(fobj, \"name\"):\n                file_name = FilePath(fobj.name).basename()\n\n        if not content_type:\n            content_type = _guess_content_type(file_name)\n\n        # XXX: Shouldn't this call self._data_to_body_producer?\n        yield (param, (file_name, content_type, IBodyProducer(fobj)))\n\n\ndef _query_quote(v):\n    # (Any) -> Text\n    \"\"\"\n    Percent-encode a querystring name or value.\n\n    :param v: A value.\n\n    :returns:\n        The value, coerced to a string and percent-encoded as appropriate for\n        a querystring (with space as ``+``).\n    \"\"\"\n    if not isinstance(v, (str, bytes)):\n        v = str(v)\n    if not isinstance(v, bytes):\n        v = v.encode(\"utf-8\")\n    q = quote_plus(v)\n    return q\n\n\ndef _coerced_query_params(params):\n    \"\"\"\n    Carefully coerce *params* in the same way as `urllib.parse.urlencode()`\n\n    Parameter names and values are coerced to unicode, which is encoded as\n    UTF-8 and then percent-encoded. As a special case, `bytes` are directly\n    percent-encoded.\n\n    :param params:\n        A mapping or sequence of (name, value) two-tuples. The value may be\n        a list or tuple of multiple values. Names and values may be pretty much\n        any type.\n\n    :returns:\n        A generator that yields two-tuples containing percent-encoded text\n        strings.\n    :rtype:\n        Iterator[Tuple[Text, Text]]\n    \"\"\"\n    if isinstance(params, Mapping):\n        items = params.items()\n    else:\n        items = params\n\n    for key, values in items:\n        key_quoted = _query_quote(key)\n\n        if not isinstance(values, (list, tuple)):\n            values = (values,)\n        for value in values:\n            yield key_quoted, _query_quote(value)\n\n\ndef _from_bytes(orig_bytes):\n    return FileBodyProducer(io.BytesIO(orig_bytes))\n\n\ndef _from_file(orig_file):\n    return FileBodyProducer(orig_file)\n\n\ndef _guess_content_type(filename):\n    if filename:\n        guessed = mimetypes.guess_type(filename)[0]\n    else:\n        guessed = None\n    return guessed or 'application/octet-stream'\n\n\nregisterAdapter(_from_bytes, bytes, IBodyProducer)\nregisterAdapter(_from_file, io.BytesIO, IBodyProducer)\n\n# file()/open() equiv\nregisterAdapter(_from_file, io.BufferedReader, IBodyProducer)\n", "patch": "@@ -3,7 +3,7 @@\n import uuid\n import warnings\n from collections.abc import Mapping\n-from http.cookiejar import CookieJar\n+from http.cookiejar import CookieJar, Cookie\n from urllib.parse import quote_plus, urlencode as _urlencode\n \n from twisted.internet.interfaces import IProtocol\n@@ -30,7 +30,7 @@\n from treq.auth import add_auth\n from treq import multipart\n from treq.response import _Response\n-from requests.cookies import cookiejar_from_dict, merge_cookies\n+from requests.cookies import merge_cookies\n \n \n _NOTHING = object()\n@@ -43,6 +43,56 @@ def urlencode(query, doseq):\n     return s\n \n \n+def _scoped_cookiejar_from_dict(url_object, cookie_dict):\n+    \"\"\"\n+    Create a CookieJar from a dictionary whose cookies are all scoped to the\n+    given URL's origin.\n+\n+    @note: This does not scope the cookies to any particular path, only the\n+        host, port, and scheme of the given URL.\n+    \"\"\"\n+    cookie_jar = CookieJar()\n+    if cookie_dict is None:\n+        return cookie_jar\n+    for k, v in cookie_dict.items():\n+        secure = url_object.scheme == 'https'\n+        port_specified = not (\n+            (url_object.scheme == \"https\" and url_object.port == 443)\n+            or (url_object.scheme == \"http\" and url_object.port == 80)\n+        )\n+        port = str(url_object.port)\n+        domain = url_object.host\n+        netscape_domain = domain if '.' in domain else domain + '.local'\n+\n+        cookie_jar.set_cookie(\n+            Cookie(\n+                # Scoping\n+                domain=netscape_domain,\n+                port=port,\n+                secure=secure,\n+                port_specified=port_specified,\n+\n+                # Contents\n+                name=k,\n+                value=v,\n+\n+                # Constant/always-the-same stuff\n+                version=0,\n+                path=\"/\",\n+                expires=None,\n+                discard=False,\n+                comment=None,\n+                comment_url=None,\n+                rfc2109=False,\n+                path_specified=False,\n+                domain_specified=False,\n+                domain_initial_dot=False,\n+                rest=[],\n+            )\n+        )\n+    return cookie_jar\n+\n+\n class _BodyBufferingProtocol(proxyForInterface(IProtocol)):\n     def __init__(self, original, buffer, finished):\n         self.original = original\n@@ -98,7 +148,9 @@ class HTTPClient:\n     def __init__(self, agent, cookiejar=None,\n                  data_to_body_producer=IBodyProducer):\n         self._agent = agent\n-        self._cookiejar = cookiejar or cookiejar_from_dict({})\n+        if cookiejar is None:\n+            cookiejar = CookieJar()\n+        self._cookiejar = cookiejar\n         self._data_to_body_producer = data_to_body_producer\n \n     def get(self, url, **kwargs):\n@@ -195,7 +247,7 @@ def request(\n             headers.setRawHeaders(b'Content-Type', [contentType])\n \n         if not isinstance(cookies, CookieJar):\n-            cookies = cookiejar_from_dict(cookies)\n+            cookies = _scoped_cookiejar_from_dict(parsed_url, cookies)\n \n         cookies = merge_cookies(self._cookiejar, cookies)\n         wrapped_agent = CookieAgent(self._agent, cookies)", "file_path": "files/2022_2/1004", "file_language": "py", "file_name": "src/treq/client.py", "outdated_file_modify": 0, "outdated_file_before": 1, "outdated_file_after": 0, "llm_check": 0, "static_check": 0, "static": {"rats": [false, []], "semgrep": [false, []]}, "target": 0, "function_before": [{"function": "def urlencode(query, doseq):\n    s = _urlencode(query, doseq)\n    if not isinstance(s, bytes):\n        s = s.encode(\"ascii\")\n    return s", "target": 0}, {"function": "def _scoped_cookiejar_from_dict(url_object, cookie_dict):\n    \"\"\"\n    Create a CookieJar from a dictionary whose cookies are all scoped to the\n    given URL's origin.\n\n    @note: This does not scope the cookies to any particular path, only the\n        host, port, and scheme of the given URL.\n    \"\"\"\n    cookie_jar = CookieJar()\n    if cookie_dict is None:\n        return cookie_jar\n    for k, v in cookie_dict.items():\n        secure = url_object.scheme == 'https'\n        port_specified = not (\n            (url_object.scheme == \"https\" and url_object.port == 443)\n            or (url_object.scheme == \"http\" and url_object.port == 80)\n        )\n        port = str(url_object.port)\n        domain = url_object.host\n        netscape_domain = domain if '.' in domain else domain + '.local'\n\n        cookie_jar.set_cookie(\n            Cookie(\n                # Scoping\n                domain=netscape_domain,\n                port=port,\n                secure=secure,\n                port_specified=port_specified,\n\n                # Contents\n                name=k,\n                value=v,\n\n                # Constant/always-the-same stuff\n                version=0,\n                path=\"/\",\n                expires=None,\n                discard=False,\n                comment=None,\n                comment_url=None,\n                rfc2109=False,\n                path_specified=False,\n                domain_specified=False,\n                domain_initial_dot=False,\n                rest=[],\n            )\n        )\n    return cookie_jar", "target": 0}, {"function": "class _BodyBufferingProtocol(proxyForInterface(IProtocol)):\n    def __init__(self, original, buffer, finished):\n        self.original = original\n        self.buffer = buffer\n        self.finished = finished\n\n    def dataReceived(self, data):\n        self.buffer.append(data)\n        self.original.dataReceived(data)\n\n    def connectionLost(self, reason):\n        self.original.connectionLost(reason)\n        self.finished.errback(reason)", "target": 0}, {"function": "class _BufferedResponse(proxyForInterface(IResponse)):\n    def __init__(self, original):\n        self.original = original\n        self._buffer = []\n        self._waiters = []\n        self._waiting = None\n        self._finished = False\n        self._reason = None\n\n    def _deliverWaiting(self, reason):\n        self._reason = reason\n        self._finished = True\n        for waiter in self._waiters:\n            for segment in self._buffer:\n                waiter.dataReceived(segment)\n            waiter.connectionLost(reason)\n\n    def deliverBody(self, protocol):\n        if self._waiting is None and not self._finished:\n            self._waiting = Deferred()\n            self._waiting.addBoth(self._deliverWaiting)\n            self.original.deliverBody(\n                _BodyBufferingProtocol(\n                    protocol,\n                    self._buffer,\n                    self._waiting\n                )\n            )\n        elif self._finished:\n            for segment in self._buffer:\n                protocol.dataReceived(segment)\n            protocol.connectionLost(self._reason)\n        else:\n            self._waiters.append(protocol)", "target": 0}, {"function": "class HTTPClient:\n    def __init__(self, agent, cookiejar=None,\n                 data_to_body_producer=IBodyProducer):\n        self._agent = agent\n        if cookiejar is None:\n            cookiejar = CookieJar()\n        self._cookiejar = cookiejar\n        self._data_to_body_producer = data_to_body_producer\n\n    def get(self, url, **kwargs):\n        \"\"\"\n        See :func:`treq.get()`.\n        \"\"\"\n        kwargs.setdefault('_stacklevel', 3)\n        return self.request('GET', url, **kwargs)\n\n    def put(self, url, data=None, **kwargs):\n        \"\"\"\n        See :func:`treq.put()`.\n        \"\"\"\n        kwargs.setdefault('_stacklevel', 3)\n        return self.request('PUT', url, data=data, **kwargs)\n\n    def patch(self, url, data=None, **kwargs):\n        \"\"\"\n        See :func:`treq.patch()`.\n        \"\"\"\n        kwargs.setdefault('_stacklevel', 3)\n        return self.request('PATCH', url, data=data, **kwargs)\n\n    def post(self, url, data=None, **kwargs):\n        \"\"\"\n        See :func:`treq.post()`.\n        \"\"\"\n        kwargs.setdefault('_stacklevel', 3)\n        return self.request('POST', url, data=data, **kwargs)\n\n    def head(self, url, **kwargs):\n        \"\"\"\n        See :func:`treq.head()`.\n        \"\"\"\n        kwargs.setdefault('_stacklevel', 3)\n        return self.request('HEAD', url, **kwargs)\n\n    def delete(self, url, **kwargs):\n        \"\"\"\n        See :func:`treq.delete()`.\n        \"\"\"\n        kwargs.setdefault('_stacklevel', 3)\n        return self.request('DELETE', url, **kwargs)\n\n    def request(\n        self,\n        method,\n        url,\n        *,\n        params=None,\n        headers=None,\n        data=None,\n        files=None,\n        json=_NOTHING,\n        auth=None,\n        cookies=None,\n        allow_redirects=True,\n        browser_like_redirects=False,\n        unbuffered=False,\n        reactor=None,\n        timeout=None,\n        _stacklevel=2,\n    ):\n        \"\"\"\n        See :func:`treq.request()`.\n        \"\"\"\n        method = method.encode('ascii').upper()\n\n        if isinstance(url, DecodedURL):\n            parsed_url = url.encoded_url\n        elif isinstance(url, EncodedURL):\n            parsed_url = url\n        elif isinstance(url, str):\n            # We use hyperlink in lazy mode so that users can pass arbitrary\n            # bytes in the path and querystring.\n            parsed_url = EncodedURL.from_text(url)\n        else:\n            parsed_url = EncodedURL.from_text(url.decode('ascii'))\n\n        # Join parameters provided in the URL\n        # and the ones passed as argument.\n        if params:\n            parsed_url = parsed_url.replace(\n                query=parsed_url.query + tuple(_coerced_query_params(params))\n            )\n\n        url = parsed_url.to_uri().to_text().encode('ascii')\n\n        headers = self._request_headers(headers, _stacklevel + 1)\n\n        bodyProducer, contentType = self._request_body(data, files, json,\n                                                       stacklevel=_stacklevel + 1)\n        if contentType is not None:\n            headers.setRawHeaders(b'Content-Type', [contentType])\n\n        if not isinstance(cookies, CookieJar):\n            cookies = _scoped_cookiejar_from_dict(parsed_url, cookies)\n\n        cookies = merge_cookies(self._cookiejar, cookies)\n        wrapped_agent = CookieAgent(self._agent, cookies)\n\n        if allow_redirects:\n            if browser_like_redirects:\n                wrapped_agent = BrowserLikeRedirectAgent(wrapped_agent)\n            else:\n                wrapped_agent = RedirectAgent(wrapped_agent)\n\n        wrapped_agent = ContentDecoderAgent(wrapped_agent,\n                                            [(b'gzip', GzipDecoder)])\n\n        if auth:\n            wrapped_agent = add_auth(wrapped_agent, auth)\n\n        d = wrapped_agent.request(\n            method, url, headers=headers,\n            bodyProducer=bodyProducer)\n\n        if reactor is None:\n            from twisted.internet import reactor\n        if timeout:\n            delayedCall = reactor.callLater(timeout, d.cancel)\n\n            def gotResult(result):\n                if delayedCall.active():\n                    delayedCall.cancel()\n                return result\n\n            d.addBoth(gotResult)\n\n        if not unbuffered:\n            d.addCallback(_BufferedResponse)\n\n        return d.addCallback(_Response, cookies)\n\n    def _request_headers(self, headers, stacklevel):\n        \"\"\"\n        Convert the *headers* argument to a :class:`Headers` instance\n\n        :returns:\n            :class:`twisted.web.http_headers.Headers`\n        \"\"\"\n        if isinstance(headers, dict):\n            h = Headers({})\n            for k, v in headers.items():\n                if isinstance(v, (bytes, str)):\n                    h.addRawHeader(k, v)\n                elif isinstance(v, list):\n                    h.setRawHeaders(k, v)\n                else:\n                    warnings.warn(\n                        (\n                            \"The value of headers key {!r} has non-string type {}\"\n                            \" and will be dropped.\"\n                            \" This will raise TypeError in the next treq release.\"\n                        ).format(k, type(v)),\n                        DeprecationWarning,\n                        stacklevel=stacklevel,\n                    )\n            return h\n        if isinstance(headers, Headers):\n            return headers\n        if headers is None:\n            return Headers({})\n\n        warnings.warn(\n            (\n                \"headers must be a dict, twisted.web.http_headers.Headers, or None,\"\n                \" but found {}, which will be ignored.\"\n                \" This will raise TypeError in the next treq release.\"\n            ).format(type(headers)),\n            DeprecationWarning,\n            stacklevel=stacklevel,\n        )\n        return Headers({})\n\n    def _request_body(self, data, files, json, stacklevel):\n        \"\"\"\n        Here we choose a right producer based on the parameters passed in.\n\n        :params data:\n            Arbitrary request body data.\n\n            If *files* is also passed this must be a :class:`dict`,\n            a :class:`tuple` or :class:`list` of field tuples as accepted by\n            :class:`MultiPartProducer`. The request is assigned a Content-Type\n            of ``multipart/form-data``.\n\n            If a :class:`dict`, :class:`list`, or :class:`tuple` it is\n            URL-encoded and the request assigned a Content-Type of\n            ``application/x-www-form-urlencoded``.\n\n            Otherwise, any non-``None`` value is passed to the client's\n            *data_to_body_producer* callable (by default,\n            :class:`IBodyProducer`), which accepts file-like objects.\n\n        :params files:\n            Files to include in the request body, in any of the several formats\n            described in :func:`_convert_files()`.\n\n        :params json:\n            JSON-encodable data, or the sentinel `_NOTHING`. The sentinel is\n            necessary because ``None`` is a valid JSON value.\n        \"\"\"\n        if json is not _NOTHING and (files or data):\n            warnings.warn(\n                (\n                    \"Argument 'json' will be ignored because '{}' was also passed.\"\n                    \" This will raise TypeError in the next treq release.\"\n                ).format(\"data\" if data else \"files\"),\n                DeprecationWarning,\n                stacklevel=stacklevel,\n            )\n\n        if files:\n            # If the files keyword is present we will issue a\n            # multipart/form-data request as it suits better for cases\n            # with files and/or large objects.\n            files = list(_convert_files(files))\n            boundary = str(uuid.uuid4()).encode('ascii')\n            if data:\n                data = _convert_params(data)\n            else:\n                data = []\n\n            return (\n                multipart.MultiPartProducer(data + files, boundary=boundary),\n                b'multipart/form-data; boundary=' + boundary,\n            )\n\n        # Otherwise stick to x-www-form-urlencoded format\n        # as it's generally faster for smaller requests.\n        if isinstance(data, (dict, list, tuple)):\n            return (\n                self._data_to_body_producer(urlencode(data, doseq=True)),\n                b'application/x-www-form-urlencoded',\n            )\n        elif data:\n            return (\n                self._data_to_body_producer(data),\n                None,\n            )\n\n        if json is not _NOTHING:\n            return (\n                self._data_to_body_producer(\n                    json_dumps(json, separators=(u',', u':')).encode('utf-8'),\n                ),\n                b'application/json; charset=UTF-8',\n            )\n\n        return None, None", "target": 0}, {"function": "def _convert_params(params):\n    if hasattr(params, \"iteritems\"):\n        return list(sorted(params.iteritems()))\n    elif hasattr(params, \"items\"):\n        return list(sorted(params.items()))\n    elif isinstance(params, (tuple, list)):\n        return list(params)\n    else:\n        raise ValueError(\"Unsupported format\")", "target": 0}, {"function": "def _convert_files(files):\n    \"\"\"\n    Files can be passed in a variety of formats:\n\n    * {\"fieldname\": open(\"bla.f\", \"rb\")}\n    * {\"fieldname\": (\"filename\", open(\"bla.f\", \"rb\"))}\n    * {\"fieldname\": (\"filename\", \"content-type\", open(\"bla.f\", \"rb\"))}\n    * Anything that has iteritems method, e.g. MultiDict:\n      MultiDict([(name, open()), (name, open())]\n\n    Our goal is to standardize it to unified form of:\n\n    * [(param, (file name, content type, producer))]\n    \"\"\"\n\n    if hasattr(files, \"iteritems\"):\n        files = files.iteritems()\n    elif hasattr(files, \"items\"):\n        files = files.items()\n\n    for param, val in files:\n        file_name, content_type, fobj = (None, None, None)\n        if isinstance(val, tuple):\n            if len(val) == 2:\n                file_name, fobj = val\n            elif len(val) == 3:\n                file_name, content_type, fobj = val\n            else:\n                # NB: This is TypeError for backward compatibility. This case\n                # used to fall through to `IBodyProducer`, below, which raised\n                # TypeError about being unable to coerce None.\n                raise TypeError(\n                    (\n                        \"`files` argument must be a sequence of tuples of\"\n                        \" (file_name, file_obj) or\"\n                        \" (file_name, content_type, file_obj),\"\n                        \" but the {!r} tuple has length {}: {!r}\"\n                    ).format(param, len(val), val),\n                )\n        else:\n            fobj = val\n            if hasattr(fobj, \"name\"):\n                file_name = FilePath(fobj.name).basename()\n\n        if not content_type:\n            content_type = _guess_content_type(file_name)\n\n        # XXX: Shouldn't this call self._data_to_body_producer?\n        yield (param, (file_name, content_type, IBodyProducer(fobj)))", "target": 0}, {"function": "def _query_quote(v):\n    # (Any) -> Text\n    \"\"\"\n    Percent-encode a querystring name or value.\n\n    :param v: A value.\n\n    :returns:\n        The value, coerced to a string and percent-encoded as appropriate for\n        a querystring (with space as ``+``).\n    \"\"\"\n    if not isinstance(v, (str, bytes)):\n        v = str(v)\n    if not isinstance(v, bytes):\n        v = v.encode(\"utf-8\")\n    q = quote_plus(v)\n    return q", "target": 0}, {"function": "def _coerced_query_params(params):\n    \"\"\"\n    Carefully coerce *params* in the same way as `urllib.parse.urlencode()`\n\n    Parameter names and values are coerced to unicode, which is encoded as\n    UTF-8 and then percent-encoded. As a special case, `bytes` are directly\n    percent-encoded.\n\n    :param params:\n        A mapping or sequence of (name, value) two-tuples. The value may be\n        a list or tuple of multiple values. Names and values may be pretty much\n        any type.\n\n    :returns:\n        A generator that yields two-tuples containing percent-encoded text\n        strings.\n    :rtype:\n        Iterator[Tuple[Text, Text]]\n    \"\"\"\n    if isinstance(params, Mapping):\n        items = params.items()\n    else:\n        items = params\n\n    for key, values in items:\n        key_quoted = _query_quote(key)\n\n        if not isinstance(values, (list, tuple)):\n            values = (values,)\n        for value in values:\n            yield key_quoted, _query_quote(value)", "target": 0}, {"function": "def _from_bytes(orig_bytes):\n    return FileBodyProducer(io.BytesIO(orig_bytes))", "target": 0}, {"function": "def _from_file(orig_file):\n    return FileBodyProducer(orig_file)", "target": 0}, {"function": "def _guess_content_type(filename):\n    if filename:\n        guessed = mimetypes.guess_type(filename)[0]\n    else:\n        guessed = None\n    return guessed or 'application/octet-stream'", "target": 0}], "function_after": [{"function": "def urlencode(query, doseq):\n    s = _urlencode(query, doseq)\n    if not isinstance(s, bytes):\n        s = s.encode(\"ascii\")\n    return s", "target": 0}, {"function": "def _scoped_cookiejar_from_dict(url_object, cookie_dict):\n    \"\"\"\n    Create a CookieJar from a dictionary whose cookies are all scoped to the\n    given URL's origin.\n\n    @note: This does not scope the cookies to any particular path, only the\n        host, port, and scheme of the given URL.\n    \"\"\"\n    cookie_jar = CookieJar()\n    if cookie_dict is None:\n        return cookie_jar\n    for k, v in cookie_dict.items():\n        secure = url_object.scheme == 'https'\n        port_specified = not (\n            (url_object.scheme == \"https\" and url_object.port == 443)\n            or (url_object.scheme == \"http\" and url_object.port == 80)\n        )\n        port = str(url_object.port)\n        domain = url_object.host\n        netscape_domain = domain if '.' in domain else domain + '.local'\n\n        cookie_jar.set_cookie(\n            Cookie(\n                # Scoping\n                domain=netscape_domain,\n                port=port,\n                secure=secure,\n                port_specified=port_specified,\n\n                # Contents\n                name=k,\n                value=v,\n\n                # Constant/always-the-same stuff\n                version=0,\n                path=\"/\",\n                expires=None,\n                discard=False,\n                comment=None,\n                comment_url=None,\n                rfc2109=False,\n                path_specified=False,\n                domain_specified=False,\n                domain_initial_dot=False,\n                rest=[],\n            )\n        )\n    return cookie_jar", "target": 0}, {"function": "class _BodyBufferingProtocol(proxyForInterface(IProtocol)):\n    def __init__(self, original, buffer, finished):\n        self.original = original\n        self.buffer = buffer\n        self.finished = finished\n\n    def dataReceived(self, data):\n        self.buffer.append(data)\n        self.original.dataReceived(data)\n\n    def connectionLost(self, reason):\n        self.original.connectionLost(reason)\n        self.finished.errback(reason)", "target": 0}, {"function": "class _BufferedResponse(proxyForInterface(IResponse)):\n    def __init__(self, original):\n        self.original = original\n        self._buffer = []\n        self._waiters = []\n        self._waiting = None\n        self._finished = False\n        self._reason = None\n\n    def _deliverWaiting(self, reason):\n        self._reason = reason\n        self._finished = True\n        for waiter in self._waiters:\n            for segment in self._buffer:\n                waiter.dataReceived(segment)\n            waiter.connectionLost(reason)\n\n    def deliverBody(self, protocol):\n        if self._waiting is None and not self._finished:\n            self._waiting = Deferred()\n            self._waiting.addBoth(self._deliverWaiting)\n            self.original.deliverBody(\n                _BodyBufferingProtocol(\n                    protocol,\n                    self._buffer,\n                    self._waiting\n                )\n            )\n        elif self._finished:\n            for segment in self._buffer:\n                protocol.dataReceived(segment)\n            protocol.connectionLost(self._reason)\n        else:\n            self._waiters.append(protocol)", "target": 0}, {"function": "class HTTPClient:\n    def __init__(self, agent, cookiejar=None,\n                 data_to_body_producer=IBodyProducer):\n        self._agent = agent\n        if cookiejar is None:\n            cookiejar = CookieJar()\n        self._cookiejar = cookiejar\n        self._data_to_body_producer = data_to_body_producer\n\n    def get(self, url, **kwargs):\n        \"\"\"\n        See :func:`treq.get()`.\n        \"\"\"\n        kwargs.setdefault('_stacklevel', 3)\n        return self.request('GET', url, **kwargs)\n\n    def put(self, url, data=None, **kwargs):\n        \"\"\"\n        See :func:`treq.put()`.\n        \"\"\"\n        kwargs.setdefault('_stacklevel', 3)\n        return self.request('PUT', url, data=data, **kwargs)\n\n    def patch(self, url, data=None, **kwargs):\n        \"\"\"\n        See :func:`treq.patch()`.\n        \"\"\"\n        kwargs.setdefault('_stacklevel', 3)\n        return self.request('PATCH', url, data=data, **kwargs)\n\n    def post(self, url, data=None, **kwargs):\n        \"\"\"\n        See :func:`treq.post()`.\n        \"\"\"\n        kwargs.setdefault('_stacklevel', 3)\n        return self.request('POST', url, data=data, **kwargs)\n\n    def head(self, url, **kwargs):\n        \"\"\"\n        See :func:`treq.head()`.\n        \"\"\"\n        kwargs.setdefault('_stacklevel', 3)\n        return self.request('HEAD', url, **kwargs)\n\n    def delete(self, url, **kwargs):\n        \"\"\"\n        See :func:`treq.delete()`.\n        \"\"\"\n        kwargs.setdefault('_stacklevel', 3)\n        return self.request('DELETE', url, **kwargs)\n\n    def request(\n        self,\n        method,\n        url,\n        *,\n        params=None,\n        headers=None,\n        data=None,\n        files=None,\n        json=_NOTHING,\n        auth=None,\n        cookies=None,\n        allow_redirects=True,\n        browser_like_redirects=False,\n        unbuffered=False,\n        reactor=None,\n        timeout=None,\n        _stacklevel=2,\n    ):\n        \"\"\"\n        See :func:`treq.request()`.\n        \"\"\"\n        method = method.encode('ascii').upper()\n\n        if isinstance(url, DecodedURL):\n            parsed_url = url.encoded_url\n        elif isinstance(url, EncodedURL):\n            parsed_url = url\n        elif isinstance(url, str):\n            # We use hyperlink in lazy mode so that users can pass arbitrary\n            # bytes in the path and querystring.\n            parsed_url = EncodedURL.from_text(url)\n        else:\n            parsed_url = EncodedURL.from_text(url.decode('ascii'))\n\n        # Join parameters provided in the URL\n        # and the ones passed as argument.\n        if params:\n            parsed_url = parsed_url.replace(\n                query=parsed_url.query + tuple(_coerced_query_params(params))\n            )\n\n        url = parsed_url.to_uri().to_text().encode('ascii')\n\n        headers = self._request_headers(headers, _stacklevel + 1)\n\n        bodyProducer, contentType = self._request_body(data, files, json,\n                                                       stacklevel=_stacklevel + 1)\n        if contentType is not None:\n            headers.setRawHeaders(b'Content-Type', [contentType])\n\n        if not isinstance(cookies, CookieJar):\n            cookies = _scoped_cookiejar_from_dict(parsed_url, cookies)\n\n        cookies = merge_cookies(self._cookiejar, cookies)\n        wrapped_agent = CookieAgent(self._agent, cookies)\n\n        if allow_redirects:\n            if browser_like_redirects:\n                wrapped_agent = BrowserLikeRedirectAgent(wrapped_agent)\n            else:\n                wrapped_agent = RedirectAgent(wrapped_agent)\n\n        wrapped_agent = ContentDecoderAgent(wrapped_agent,\n                                            [(b'gzip', GzipDecoder)])\n\n        if auth:\n            wrapped_agent = add_auth(wrapped_agent, auth)\n\n        d = wrapped_agent.request(\n            method, url, headers=headers,\n            bodyProducer=bodyProducer)\n\n        if reactor is None:\n            from twisted.internet import reactor\n        if timeout:\n            delayedCall = reactor.callLater(timeout, d.cancel)\n\n            def gotResult(result):\n                if delayedCall.active():\n                    delayedCall.cancel()\n                return result\n\n            d.addBoth(gotResult)\n\n        if not unbuffered:\n            d.addCallback(_BufferedResponse)\n\n        return d.addCallback(_Response, cookies)\n\n    def _request_headers(self, headers, stacklevel):\n        \"\"\"\n        Convert the *headers* argument to a :class:`Headers` instance\n\n        :returns:\n            :class:`twisted.web.http_headers.Headers`\n        \"\"\"\n        if isinstance(headers, dict):\n            h = Headers({})\n            for k, v in headers.items():\n                if isinstance(v, (bytes, str)):\n                    h.addRawHeader(k, v)\n                elif isinstance(v, list):\n                    h.setRawHeaders(k, v)\n                else:\n                    warnings.warn(\n                        (\n                            \"The value of headers key {!r} has non-string type {}\"\n                            \" and will be dropped.\"\n                            \" This will raise TypeError in the next treq release.\"\n                        ).format(k, type(v)),\n                        DeprecationWarning,\n                        stacklevel=stacklevel,\n                    )\n            return h\n        if isinstance(headers, Headers):\n            return headers\n        if headers is None:\n            return Headers({})\n\n        warnings.warn(\n            (\n                \"headers must be a dict, twisted.web.http_headers.Headers, or None,\"\n                \" but found {}, which will be ignored.\"\n                \" This will raise TypeError in the next treq release.\"\n            ).format(type(headers)),\n            DeprecationWarning,\n            stacklevel=stacklevel,\n        )\n        return Headers({})\n\n    def _request_body(self, data, files, json, stacklevel):\n        \"\"\"\n        Here we choose a right producer based on the parameters passed in.\n\n        :params data:\n            Arbitrary request body data.\n\n            If *files* is also passed this must be a :class:`dict`,\n            a :class:`tuple` or :class:`list` of field tuples as accepted by\n            :class:`MultiPartProducer`. The request is assigned a Content-Type\n            of ``multipart/form-data``.\n\n            If a :class:`dict`, :class:`list`, or :class:`tuple` it is\n            URL-encoded and the request assigned a Content-Type of\n            ``application/x-www-form-urlencoded``.\n\n            Otherwise, any non-``None`` value is passed to the client's\n            *data_to_body_producer* callable (by default,\n            :class:`IBodyProducer`), which accepts file-like objects.\n\n        :params files:\n            Files to include in the request body, in any of the several formats\n            described in :func:`_convert_files()`.\n\n        :params json:\n            JSON-encodable data, or the sentinel `_NOTHING`. The sentinel is\n            necessary because ``None`` is a valid JSON value.\n        \"\"\"\n        if json is not _NOTHING and (files or data):\n            warnings.warn(\n                (\n                    \"Argument 'json' will be ignored because '{}' was also passed.\"\n                    \" This will raise TypeError in the next treq release.\"\n                ).format(\"data\" if data else \"files\"),\n                DeprecationWarning,\n                stacklevel=stacklevel,\n            )\n\n        if files:\n            # If the files keyword is present we will issue a\n            # multipart/form-data request as it suits better for cases\n            # with files and/or large objects.\n            files = list(_convert_files(files))\n            boundary = str(uuid.uuid4()).encode('ascii')\n            if data:\n                data = _convert_params(data)\n            else:\n                data = []\n\n            return (\n                multipart.MultiPartProducer(data + files, boundary=boundary),\n                b'multipart/form-data; boundary=' + boundary,\n            )\n\n        # Otherwise stick to x-www-form-urlencoded format\n        # as it's generally faster for smaller requests.\n        if isinstance(data, (dict, list, tuple)):\n            return (\n                self._data_to_body_producer(urlencode(data, doseq=True)),\n                b'application/x-www-form-urlencoded',\n            )\n        elif data:\n            return (\n                self._data_to_body_producer(data),\n                None,\n            )\n\n        if json is not _NOTHING:\n            return (\n                self._data_to_body_producer(\n                    json_dumps(json, separators=(u',', u':')).encode('utf-8'),\n                ),\n                b'application/json; charset=UTF-8',\n            )\n\n        return None, None", "target": 0}, {"function": "def _convert_params(params):\n    if hasattr(params, \"iteritems\"):\n        return list(sorted(params.iteritems()))\n    elif hasattr(params, \"items\"):\n        return list(sorted(params.items()))\n    elif isinstance(params, (tuple, list)):\n        return list(params)\n    else:\n        raise ValueError(\"Unsupported format\")", "target": 0}, {"function": "def _convert_files(files):\n    \"\"\"\n    Files can be passed in a variety of formats:\n\n    * {\"fieldname\": open(\"bla.f\", \"rb\")}\n    * {\"fieldname\": (\"filename\", open(\"bla.f\", \"rb\"))}\n    * {\"fieldname\": (\"filename\", \"content-type\", open(\"bla.f\", \"rb\"))}\n    * Anything that has iteritems method, e.g. MultiDict:\n      MultiDict([(name, open()), (name, open())]\n\n    Our goal is to standardize it to unified form of:\n\n    * [(param, (file name, content type, producer))]\n    \"\"\"\n\n    if hasattr(files, \"iteritems\"):\n        files = files.iteritems()\n    elif hasattr(files, \"items\"):\n        files = files.items()\n\n    for param, val in files:\n        file_name, content_type, fobj = (None, None, None)\n        if isinstance(val, tuple):\n            if len(val) == 2:\n                file_name, fobj = val\n            elif len(val) == 3:\n                file_name, content_type, fobj = val\n            else:\n                # NB: This is TypeError for backward compatibility. This case\n                # used to fall through to `IBodyProducer`, below, which raised\n                # TypeError about being unable to coerce None.\n                raise TypeError(\n                    (\n                        \"`files` argument must be a sequence of tuples of\"\n                        \" (file_name, file_obj) or\"\n                        \" (file_name, content_type, file_obj),\"\n                        \" but the {!r} tuple has length {}: {!r}\"\n                    ).format(param, len(val), val),\n                )\n        else:\n            fobj = val\n            if hasattr(fobj, \"name\"):\n                file_name = FilePath(fobj.name).basename()\n\n        if not content_type:\n            content_type = _guess_content_type(file_name)\n\n        # XXX: Shouldn't this call self._data_to_body_producer?\n        yield (param, (file_name, content_type, IBodyProducer(fobj)))", "target": 0}, {"function": "def _query_quote(v):\n    # (Any) -> Text\n    \"\"\"\n    Percent-encode a querystring name or value.\n\n    :param v: A value.\n\n    :returns:\n        The value, coerced to a string and percent-encoded as appropriate for\n        a querystring (with space as ``+``).\n    \"\"\"\n    if not isinstance(v, (str, bytes)):\n        v = str(v)\n    if not isinstance(v, bytes):\n        v = v.encode(\"utf-8\")\n    q = quote_plus(v)\n    return q", "target": 0}, {"function": "def _coerced_query_params(params):\n    \"\"\"\n    Carefully coerce *params* in the same way as `urllib.parse.urlencode()`\n\n    Parameter names and values are coerced to unicode, which is encoded as\n    UTF-8 and then percent-encoded. As a special case, `bytes` are directly\n    percent-encoded.\n\n    :param params:\n        A mapping or sequence of (name, value) two-tuples. The value may be\n        a list or tuple of multiple values. Names and values may be pretty much\n        any type.\n\n    :returns:\n        A generator that yields two-tuples containing percent-encoded text\n        strings.\n    :rtype:\n        Iterator[Tuple[Text, Text]]\n    \"\"\"\n    if isinstance(params, Mapping):\n        items = params.items()\n    else:\n        items = params\n\n    for key, values in items:\n        key_quoted = _query_quote(key)\n\n        if not isinstance(values, (list, tuple)):\n            values = (values,)\n        for value in values:\n            yield key_quoted, _query_quote(value)", "target": 0}, {"function": "def _from_bytes(orig_bytes):\n    return FileBodyProducer(io.BytesIO(orig_bytes))", "target": 0}, {"function": "def _from_file(orig_file):\n    return FileBodyProducer(orig_file)", "target": 0}, {"function": "def _guess_content_type(filename):\n    if filename:\n        guessed = mimetypes.guess_type(filename)[0]\n    else:\n        guessed = None\n    return guessed or 'application/octet-stream'", "target": 0}]}, {"raw_url": "https://github.com/twisted/treq/raw/1da6022cc880bbcff59321abe02bf8498b89efb2/src%2Ftreq%2Ftest%2Ftest_testing.py", "code": "\"\"\"\nIn-memory treq returns stubbed responses.\n\"\"\"\nfrom functools import partial\nfrom inspect import getmembers, isfunction\nfrom json import dumps\n\nfrom unittest.mock import ANY\n\nfrom twisted.trial.unittest import TestCase\nfrom twisted.web.client import ResponseFailed\nfrom twisted.web.error import SchemeNotSupported\nfrom twisted.web.resource import Resource\nfrom twisted.web.server import NOT_DONE_YET\n\nimport treq\n\nfrom treq.testing import (\n    HasHeaders,\n    RequestSequence,\n    StringStubbingResource,\n    StubTreq\n)\n\n\nclass _StaticTestResource(Resource):\n    \"\"\"Resource that always returns 418 \"I'm a teapot\"\"\"\n    isLeaf = True\n\n    def render(self, request):\n        request.setResponseCode(418)\n        request.setHeader(b\"x-teapot\", b\"teapot!\")\n        return b\"I'm a teapot\"\n\n\nclass _RedirectResource(Resource):\n    \"\"\"\n    Resource that redirects to a different domain.\n    \"\"\"\n    isLeaf = True\n\n    def render(self, request):\n        if b'redirected' not in request.uri:\n            request.redirect(b'https://example.org/redirected')\n        return dumps(\n            {\n                key.decode(\"charmap\"): [\n                    value.decode(\"charmap\")\n                    for value in values\n                ]\n                for key, values in\n                request.requestHeaders.getAllRawHeaders()}\n        ).encode(\"utf-8\")\n\n\nclass _NonResponsiveTestResource(Resource):\n    \"\"\"Resource that returns NOT_DONE_YET and never finishes the request\"\"\"\n    isLeaf = True\n\n    def render(self, request):\n        return NOT_DONE_YET\n\n\nclass _EventuallyResponsiveTestResource(Resource):\n    \"\"\"\n    Resource that returns NOT_DONE_YET and stores the request so that something\n    else can finish the response later.\n    \"\"\"\n    isLeaf = True\n\n    def render(self, request):\n        self.stored_request = request\n        return NOT_DONE_YET\n\n\nclass _SessionIdTestResource(Resource):\n    \"\"\"\n    Resource that returns the current session ID.\n    \"\"\"\n    isLeaf = True\n\n    def __init__(self):\n        super().__init__()\n        # keep track of all sessions created, so we can manually expire them later\n        self.sessions = []\n\n    def render(self, request):\n        session = request.getSession()\n        if session not in self.sessions:\n            # new session, add to internal list\n            self.sessions.append(session)\n        uid = session.uid\n        return uid\n\n    def expire_sessions(self):\n        \"\"\"\n        Manually expire all sessions created by this resource.\n        \"\"\"\n        for session in self.sessions:\n            session.expire()\n        self.sessions = []\n\n\nclass StubbingTests(TestCase):\n    \"\"\"\n    Tests for :class:`StubTreq`.\n    \"\"\"\n    def test_stubtreq_provides_all_functions_in_treq_all(self):\n        \"\"\"\n        Every single function and attribute exposed by :obj:`treq.__all__` is\n        provided by :obj:`StubTreq`.\n        \"\"\"\n        treq_things = [(name, obj) for name, obj in getmembers(treq)\n                       if name in treq.__all__]\n        stub = StubTreq(_StaticTestResource())\n\n        api_things = [(name, obj) for name, obj in treq_things\n                      if obj.__module__ == \"treq.api\"]\n        content_things = [(name, obj) for name, obj in treq_things\n                          if obj.__module__ == \"treq.content\"]\n\n        # sanity checks - this test should fail if treq exposes a new API\n        # without changes being made to StubTreq and this test.\n        msg = (\"At the time this test was written, StubTreq only knew about \"\n               \"treq exposing functions from treq.api and treq.content.  If \"\n               \"this has changed, StubTreq will need to be updated, as will \"\n               \"this test.\")\n        self.assertTrue(all(isfunction(obj) for name, obj in treq_things), msg)\n        self.assertEqual(set(treq_things), set(api_things + content_things),\n                         msg)\n\n        for name, obj in api_things:\n            self.assertTrue(\n                isfunction(getattr(stub, name, None)),\n                \"StubTreq.{0} should be a function.\".format(name))\n\n        for name, obj in content_things:\n            self.assertIs(\n                getattr(stub, name, None), obj,\n                \"StubTreq.{0} should just expose treq.{0}\".format(name))\n\n    def test_providing_resource_to_stub_treq(self):\n        \"\"\"\n        The resource provided to StubTreq responds to every request no\n        matter what the URI or parameters or data.\n        \"\"\"\n        verbs = ('GET', 'PUT', 'HEAD', 'PATCH', 'DELETE', 'POST')\n        urls = (\n            'http://supports-http.com',\n            'https://supports-https.com',\n            'http://this/has/a/path/and/invalid/domain/name',\n            'https://supports-https.com:8080',\n            'http://supports-http.com:8080',\n        )\n        params = (None, {}, {b'page': [1]})\n        headers = (None, {}, {b'x-random-header': [b'value', b'value2']})\n        data = (None, b\"\", b'some data', b'{\"some\": \"json\"}')\n\n        stub = StubTreq(_StaticTestResource())\n\n        combos = (\n            (verb, {\"url\": url, \"params\": p, \"headers\": h, \"data\": d})\n            for verb in verbs\n            for url in urls\n            for p in params\n            for h in headers\n            for d in data\n        )\n        for combo in combos:\n            verb, kwargs = combo\n            deferreds = (stub.request(verb, **kwargs),\n                         getattr(stub, verb.lower())(**kwargs))\n            for d in deferreds:\n                resp = self.successResultOf(d)\n                self.assertEqual(418, resp.code)\n                self.assertEqual([b'teapot!'],\n                                 resp.headers.getRawHeaders(b'x-teapot'))\n                self.assertEqual(b\"\" if verb == \"HEAD\" else b\"I'm a teapot\",\n                                 self.successResultOf(stub.content(resp)))\n\n    def test_handles_invalid_schemes(self):\n        \"\"\"\n        Invalid URLs errback with a :obj:`SchemeNotSupported` failure, and does\n        so even after a successful request.\n        \"\"\"\n        stub = StubTreq(_StaticTestResource())\n        self.failureResultOf(stub.get(\"x-unknown-1:\"), SchemeNotSupported)\n        self.successResultOf(stub.get(\"http://url.com\"))\n        self.failureResultOf(stub.get(\"x-unknown-2:\"), SchemeNotSupported)\n\n    def test_files_are_rejected(self):\n        \"\"\"\n        StubTreq does not handle files yet - it should reject requests which\n        attempt to pass files.\n        \"\"\"\n        stub = StubTreq(_StaticTestResource())\n        self.assertRaises(\n            AssertionError, stub.request,\n            'method', 'http://url', files=b'some file')\n\n    def test_passing_in_strange_data_is_rejected(self):\n        \"\"\"\n        StubTreq rejects data that isn't list/dictionary/tuple/bytes/unicode.\n        \"\"\"\n        stub = StubTreq(_StaticTestResource())\n        self.assertRaises(\n            AssertionError, stub.request, 'method', 'http://url',\n            data=object())\n        self.successResultOf(stub.request('method', 'http://url', data={}))\n        self.successResultOf(stub.request('method', 'http://url', data=[]))\n        self.successResultOf(stub.request('method', 'http://url', data=()))\n        self.successResultOf(\n            stub.request('method', 'http://url', data=b\"\"))\n        self.successResultOf(\n            stub.request('method', 'http://url', data=\"\"))\n\n    def test_handles_failing_asynchronous_requests(self):\n        \"\"\"\n        Handle a resource returning NOT_DONE_YET and then canceling the\n        request.\n        \"\"\"\n        stub = StubTreq(_NonResponsiveTestResource())\n        d = stub.request('method', 'http://url', data=b\"1234\")\n        self.assertNoResult(d)\n        d.cancel()\n        self.failureResultOf(d, ResponseFailed)\n\n    def test_handles_successful_asynchronous_requests(self):\n        \"\"\"\n        Handle a resource returning NOT_DONE_YET and then later finishing the\n        response.\n        \"\"\"\n        rsrc = _EventuallyResponsiveTestResource()\n        stub = StubTreq(rsrc)\n        d = stub.request('method', 'http://example.com/', data=b\"1234\")\n        self.assertNoResult(d)\n        rsrc.stored_request.finish()\n        stub.flush()\n        resp = self.successResultOf(d)\n        self.assertEqual(resp.code, 200)\n\n    def test_handles_successful_asynchronous_requests_with_response_data(self):\n        \"\"\"\n        Handle a resource returning NOT_DONE_YET and then sending some data in\n        the response.\n        \"\"\"\n        rsrc = _EventuallyResponsiveTestResource()\n        stub = StubTreq(rsrc)\n        d = stub.request('method', 'http://example.com/', data=b\"1234\")\n        self.assertNoResult(d)\n\n        chunks = []\n        rsrc.stored_request.write(b'spam ')\n        rsrc.stored_request.write(b'eggs')\n        stub.flush()\n        resp = self.successResultOf(d)\n        d = stub.collect(resp, chunks.append)\n        self.assertNoResult(d)\n        self.assertEqual(b''.join(chunks), b'spam eggs')\n\n        rsrc.stored_request.finish()\n        stub.flush()\n        self.successResultOf(d)\n\n    def test_handles_successful_asynchronous_requests_with_streaming(self):\n        \"\"\"\n        Handle a resource returning NOT_DONE_YET and then streaming data back\n        gradually over time.\n        \"\"\"\n        rsrc = _EventuallyResponsiveTestResource()\n        stub = StubTreq(rsrc)\n        d = stub.request('method', 'http://example.com/', data=\"1234\")\n        self.assertNoResult(d)\n\n        chunks = []\n        rsrc.stored_request.write(b'spam ')\n        rsrc.stored_request.write(b'eggs')\n        stub.flush()\n        resp = self.successResultOf(d)\n        d = stub.collect(resp, chunks.append)\n        self.assertNoResult(d)\n        self.assertEqual(b''.join(chunks), b'spam eggs')\n\n        del chunks[:]\n        rsrc.stored_request.write(b'eggs\\r\\nspam\\r\\n')\n        stub.flush()\n        self.assertNoResult(d)\n        self.assertEqual(b''.join(chunks), b'eggs\\r\\nspam\\r\\n')\n\n        rsrc.stored_request.finish()\n        stub.flush()\n        self.successResultOf(d)\n\n    def test_session_persistence_between_requests(self):\n        \"\"\"\n        Calling request.getSession() in the wrapped resource will return a\n        session with the same ID, until the sessions are cleaned; in other\n        words, cookies are propagated between requests when the result of\n        C{response.cookies()} is passed to the next request.\n        \"\"\"\n        rsrc = _SessionIdTestResource()\n        stub = StubTreq(rsrc)\n        # request 1, getting original session ID\n        d = stub.request(\"method\", \"http://example.com/\")\n        resp = self.successResultOf(d)\n        cookies = resp.cookies()\n        sid_1 = self.successResultOf(resp.content())\n        # request 2, ensuring session ID stays the same\n        d = stub.request(\"method\", \"http://example.com/\", cookies=cookies)\n        resp = self.successResultOf(d)\n        sid_2 = self.successResultOf(resp.content())\n        self.assertEqual(sid_1, sid_2)\n        # request 3, ensuring the session IDs are different after cleaning\n        # or expiring the sessions\n\n        # manually expire the sessions.\n        rsrc.expire_sessions()\n\n        d = stub.request(\"method\", \"http://example.com/\")\n        resp = self.successResultOf(d)\n        cookies = resp.cookies()\n        sid_3 = self.successResultOf(resp.content())\n        self.assertNotEqual(sid_1, sid_3)\n        # request 4, ensuring that once again the session IDs are the same\n        d = stub.request(\"method\", \"http://example.com/\", cookies=cookies)\n        resp = self.successResultOf(d)\n        sid_4 = self.successResultOf(resp.content())\n        self.assertEqual(sid_3, sid_4)\n\n    def test_different_domains(self):\n        \"\"\"\n        Cookies manually specified as part of a dictionary are not relayed\n        through redirects.\n\n        (This is really more of a test for scoping of cookies within treq\n        itself, rather than just for testing.)\n        \"\"\"\n        rsrc = _RedirectResource()\n        stub = StubTreq(rsrc)\n        d = stub.request(\n            \"GET\", \"http://example.com/\",\n            cookies={\"not-across-redirect\": \"nope\"}\n        )\n        resp = self.successResultOf(d)\n        received = self.successResultOf(resp.json())\n        self.assertNotIn('not-across-redirect', received.get('Cookie', [''])[0])\n\n\nclass HasHeadersTests(TestCase):\n    \"\"\"\n    Tests for :obj:`HasHeaders`.\n    \"\"\"\n    def test_equality_and_strict_subsets_succeed(self):\n        \"\"\"\n        The :obj:`HasHeaders` returns True if both sets of headers are\n        equivalent, or the first is a strict subset of the second.\n        \"\"\"\n        self.assertEqual(HasHeaders({'one': ['two', 'three']}),\n                         {'one': ['two', 'three']},\n                         \"Equivalent headers do not match.\")\n        self.assertEqual(HasHeaders({'one': ['two', 'three']}),\n                         {'one': ['two', 'three', 'four'],\n                          'ten': ['six']},\n                         \"Strict subset headers do not match\")\n\n    def test_partial_or_zero_intersection_subsets_fail(self):\n        \"\"\"\n        The :obj:`HasHeaders` returns False if both sets of headers overlap\n        but the first is not a strict subset of the second.  It also returns\n        False if there is no overlap.\n        \"\"\"\n        self.assertNotEqual(HasHeaders({'one': ['two', 'three']}),\n                            {'one': ['three', 'four']},\n                            \"Partial value overlap matches\")\n        self.assertNotEqual(HasHeaders({'one': ['two', 'three']}),\n                            {'one': ['two']},\n                            \"Missing value matches\")\n        self.assertNotEqual(HasHeaders({'one': ['two', 'three']}),\n                            {'ten': ['six']},\n                            \"Complete inequality matches\")\n\n    def test_case_insensitive_keys(self):\n        \"\"\"\n        The :obj:`HasHeaders` equality function ignores the case of the header\n        keys.\n        \"\"\"\n        self.assertEqual(HasHeaders({b'A': [b'1'], b'b': [b'2']}),\n                         {b'a': [b'1'], b'B': [b'2']})\n\n    def test_case_sensitive_values(self):\n        \"\"\"\n        The :obj:`HasHeaders` equality function does care about the case of\n        the header value.\n        \"\"\"\n        self.assertNotEqual(HasHeaders({b'a': [b'a']}), {b'a': [b'A']})\n\n    def test_bytes_encoded_forms(self):\n        \"\"\"\n        The :obj:`HasHeaders` equality function compares the bytes-encoded\n        forms of both sets of headers.\n        \"\"\"\n        self.assertEqual(HasHeaders({b'a': [b'a']}), {u'a': [u'a']})\n\n        self.assertEqual(HasHeaders({u'b': [u'b']}), {b'b': [b'b']})\n\n    def test_repr(self):\n        \"\"\"\n        :obj:`HasHeaders` returns a nice string repr.\n        \"\"\"\n        self.assertEqual(\n            \"HasHeaders({b'a': [b'b']})\",\n            repr(HasHeaders({b\"A\": [b\"b\"]})),\n        )\n\n\nclass StringStubbingTests(TestCase):\n    \"\"\"\n    Tests for :obj:`StringStubbingResource`.\n    \"\"\"\n    def _get_response_for(self, expected_args, response):\n        \"\"\"\n        Make a :obj:`IStringResponseStubs` that checks the expected args and\n        returns the given response.\n        \"\"\"\n        method, url, params, headers, data = expected_args\n\n        def get_response_for(_method, _url, _params, _headers, _data):\n            self.assertEqual((method, url, params, data),\n                             (_method, _url, _params, _data))\n            self.assertEqual(HasHeaders(headers), _headers)\n            return response\n\n        return get_response_for\n\n    def test_interacts_successfully_with_istub(self):\n        \"\"\"\n        The :obj:`IStringResponseStubs` is passed the correct parameters with\n        which to evaluate the response, and the response is returned.\n        \"\"\"\n        resource = StringStubbingResource(self._get_response_for(\n            (b'DELETE', 'http://what/a/thing', {b'page': [b'1']},\n             {b'x-header': [b'eh']}, b'datastr'),\n            (418, {b'x-response': b'responseheader'}, b'response body')))\n\n        stub = StubTreq(resource)\n\n        d = stub.delete('http://what/a/thing', headers={b'x-header': b'eh'},\n                        params={b'page': b'1'}, data=b'datastr')\n        resp = self.successResultOf(d)\n        self.assertEqual(418, resp.code)\n        self.assertEqual([b'responseheader'],\n                         resp.headers.getRawHeaders(b'x-response'))\n        self.assertEqual(b'response body',\n                         self.successResultOf(stub.content(resp)))\n\n\nclass RequestSequenceTests(TestCase):\n    \"\"\"\n    Tests for :obj:`RequestSequence`.\n    \"\"\"\n    def setUp(self):\n        \"\"\"\n        Set up a way to report failures asynchronously.\n        \"\"\"\n        self.async_failures = []\n\n    def test_mismatched_request_causes_failure(self):\n        \"\"\"\n        If a request is made that is not expected as the next request,\n        causes a failure.\n        \"\"\"\n        sequence = RequestSequence(\n            [((b'get', 'https://anything/', {b'1': [b'2']},\n               HasHeaders({b'1': [b'1']}), b'what'),\n              (418, {}, b'body')),\n             ((b'get', 'http://anything', {},\n               HasHeaders({b'2': [b'1']}), b'what'),\n              (202, {}, b'deleted'))],\n            async_failure_reporter=self.async_failures.append)\n\n        stub = StubTreq(StringStubbingResource(sequence))\n        get = partial(stub.get, 'https://anything?1=2', data=b'what',\n                      headers={b'1': b'1'})\n\n        resp = self.successResultOf(get())\n\n        self.assertEqual(418, resp.code)\n        self.assertEqual(b'body', self.successResultOf(stub.content(resp)))\n        self.assertEqual([], self.async_failures)\n\n        resp = self.successResultOf(get())\n        self.assertEqual(500, resp.code)\n        self.assertEqual(1, len(self.async_failures))\n        self.assertIn(\"Expected the next request to be\",\n                      self.async_failures[0])\n\n        self.assertFalse(sequence.consumed())\n\n    def test_unexpected_number_of_request_causes_failure(self):\n        \"\"\"\n        If there are no more expected requests, making a request causes a\n        failure.\n        \"\"\"\n        sequence = RequestSequence(\n            [],\n            async_failure_reporter=self.async_failures.append)\n        stub = StubTreq(StringStubbingResource(sequence))\n        d = stub.get('https://anything', data=b'what', headers={b'1': b'1'})\n        resp = self.successResultOf(d)\n        self.assertEqual(500, resp.code)\n        self.assertEqual(b'StubbingError',\n                         self.successResultOf(resp.content()))\n        self.assertEqual(1, len(self.async_failures))\n        self.assertIn(\"No more requests expected, but request\",\n                      self.async_failures[0])\n\n        # the expected requests have all been made\n        self.assertTrue(sequence.consumed())\n\n    def test_works_with_mock_any(self):\n        \"\"\"\n        :obj:`mock.ANY` can be used with the request parameters.\n        \"\"\"\n        sequence = RequestSequence(\n            [((ANY, ANY, ANY, ANY, ANY), (418, {}, b'body'))],\n            async_failure_reporter=self.async_failures.append)\n        stub = StubTreq(StringStubbingResource(sequence))\n\n        with sequence.consume(sync_failure_reporter=self.fail):\n            d = stub.get('https://anything', data=b'what',\n                         headers={b'1': b'1'})\n            resp = self.successResultOf(d)\n            self.assertEqual(418, resp.code)\n            self.assertEqual(b'body', self.successResultOf(stub.content(resp)))\n\n        self.assertEqual([], self.async_failures)\n\n        # the expected requests have all been made\n        self.assertTrue(sequence.consumed())\n\n    def test_consume_context_manager_fails_on_remaining_requests(self):\n        \"\"\"\n        If the `consume` context manager is used, if there are any remaining\n        expecting requests, the test case will be failed.\n        \"\"\"\n        sequence = RequestSequence(\n            [((ANY, ANY, ANY, ANY, ANY), (418, {}, b'body'))] * 2,\n            async_failure_reporter=self.async_failures.append)\n        stub = StubTreq(StringStubbingResource(sequence))\n\n        consume_failures = []\n        with sequence.consume(sync_failure_reporter=consume_failures.append):\n\n            self.successResultOf(stub.get('https://anything', data=b'what',\n                                          headers={b'1': b'1'}))\n\n        self.assertEqual(1, len(consume_failures))\n        self.assertIn(\n            \"Not all expected requests were made.  Still expecting:\",\n            consume_failures[0])\n        self.assertIn(\n            \"{0}(url={0}, params={0}, headers={0}, data={0})\".format(\n                repr(ANY)),\n            consume_failures[0])\n\n        # no asynchronous failures (mismatches, etc.)\n        self.assertEqual([], self.async_failures)\n\n    def test_async_failures_logged(self):\n        \"\"\"\n        When no `async_failure_reporter` is passed async failures are logged by\n        default.\n        \"\"\"\n        sequence = RequestSequence([])\n        stub = StubTreq(StringStubbingResource(sequence))\n\n        with sequence.consume(self.fail):\n            self.successResultOf(stub.get('https://example.com'))\n\n        [failure] = self.flushLoggedErrors()\n        self.assertIsInstance(failure.value, AssertionError)\n", "code_before": "\"\"\"\nIn-memory treq returns stubbed responses.\n\"\"\"\nfrom functools import partial\nfrom inspect import getmembers, isfunction\nfrom json import dumps\n\nfrom unittest.mock import ANY\n\nfrom twisted.trial.unittest import TestCase\nfrom twisted.web.client import ResponseFailed\nfrom twisted.web.error import SchemeNotSupported\nfrom twisted.web.resource import Resource\nfrom twisted.web.server import NOT_DONE_YET\n\nimport treq\n\nfrom treq.testing import (\n    HasHeaders,\n    RequestSequence,\n    StringStubbingResource,\n    StubTreq\n)\n\n\nclass _StaticTestResource(Resource):\n    \"\"\"Resource that always returns 418 \"I'm a teapot\"\"\"\n    isLeaf = True\n\n    def render(self, request):\n        request.setResponseCode(418)\n        request.setHeader(b\"x-teapot\", b\"teapot!\")\n        return b\"I'm a teapot\"\n\n\nclass _RedirectResource(Resource):\n    \"\"\"\n    Resource that redirects to a different domain.\n    \"\"\"\n    isLeaf = True\n\n    def render(self, request):\n        if b'redirected' not in request.uri:\n            request.redirect(b'https://example.org/redirected')\n        return dumps(\n            {\n                key.decode(\"charmap\"): [\n                    value.decode(\"charmap\")\n                    for value in values\n                ]\n                for key, values in\n                request.requestHeaders.getAllRawHeaders()}\n        ).encode(\"utf-8\")\n\n\nclass _NonResponsiveTestResource(Resource):\n    \"\"\"Resource that returns NOT_DONE_YET and never finishes the request\"\"\"\n    isLeaf = True\n\n    def render(self, request):\n        return NOT_DONE_YET\n\n\nclass _EventuallyResponsiveTestResource(Resource):\n    \"\"\"\n    Resource that returns NOT_DONE_YET and stores the request so that something\n    else can finish the response later.\n    \"\"\"\n    isLeaf = True\n\n    def render(self, request):\n        self.stored_request = request\n        return NOT_DONE_YET\n\n\nclass _SessionIdTestResource(Resource):\n    \"\"\"\n    Resource that returns the current session ID.\n    \"\"\"\n    isLeaf = True\n\n    def __init__(self):\n        super().__init__()\n        # keep track of all sessions created, so we can manually expire them later\n        self.sessions = []\n\n    def render(self, request):\n        session = request.getSession()\n        if session not in self.sessions:\n            # new session, add to internal list\n            self.sessions.append(session)\n        uid = session.uid\n        return uid\n\n    def expire_sessions(self):\n        \"\"\"\n        Manually expire all sessions created by this resource.\n        \"\"\"\n        for session in self.sessions:\n            session.expire()\n        self.sessions = []\n\n\nclass StubbingTests(TestCase):\n    \"\"\"\n    Tests for :class:`StubTreq`.\n    \"\"\"\n    def test_stubtreq_provides_all_functions_in_treq_all(self):\n        \"\"\"\n        Every single function and attribute exposed by :obj:`treq.__all__` is\n        provided by :obj:`StubTreq`.\n        \"\"\"\n        treq_things = [(name, obj) for name, obj in getmembers(treq)\n                       if name in treq.__all__]\n        stub = StubTreq(_StaticTestResource())\n\n        api_things = [(name, obj) for name, obj in treq_things\n                      if obj.__module__ == \"treq.api\"]\n        content_things = [(name, obj) for name, obj in treq_things\n                          if obj.__module__ == \"treq.content\"]\n\n        # sanity checks - this test should fail if treq exposes a new API\n        # without changes being made to StubTreq and this test.\n        msg = (\"At the time this test was written, StubTreq only knew about \"\n               \"treq exposing functions from treq.api and treq.content.  If \"\n               \"this has changed, StubTreq will need to be updated, as will \"\n               \"this test.\")\n        self.assertTrue(all(isfunction(obj) for name, obj in treq_things), msg)\n        self.assertEqual(set(treq_things), set(api_things + content_things),\n                         msg)\n\n        for name, obj in api_things:\n            self.assertTrue(\n                isfunction(getattr(stub, name, None)),\n                \"StubTreq.{0} should be a function.\".format(name))\n\n        for name, obj in content_things:\n            self.assertIs(\n                getattr(stub, name, None), obj,\n                \"StubTreq.{0} should just expose treq.{0}\".format(name))\n\n    def test_providing_resource_to_stub_treq(self):\n        \"\"\"\n        The resource provided to StubTreq responds to every request no\n        matter what the URI or parameters or data.\n        \"\"\"\n        verbs = ('GET', 'PUT', 'HEAD', 'PATCH', 'DELETE', 'POST')\n        urls = (\n            'http://supports-http.com',\n            'https://supports-https.com',\n            'http://this/has/a/path/and/invalid/domain/name',\n            'https://supports-https.com:8080',\n            'http://supports-http.com:8080',\n        )\n        params = (None, {}, {b'page': [1]})\n        headers = (None, {}, {b'x-random-header': [b'value', b'value2']})\n        data = (None, b\"\", b'some data', b'{\"some\": \"json\"}')\n\n        stub = StubTreq(_StaticTestResource())\n\n        combos = (\n            (verb, {\"url\": url, \"params\": p, \"headers\": h, \"data\": d})\n            for verb in verbs\n            for url in urls\n            for p in params\n            for h in headers\n            for d in data\n        )\n        for combo in combos:\n            verb, kwargs = combo\n            deferreds = (stub.request(verb, **kwargs),\n                         getattr(stub, verb.lower())(**kwargs))\n            for d in deferreds:\n                resp = self.successResultOf(d)\n                self.assertEqual(418, resp.code)\n                self.assertEqual([b'teapot!'],\n                                 resp.headers.getRawHeaders(b'x-teapot'))\n                self.assertEqual(b\"\" if verb == \"HEAD\" else b\"I'm a teapot\",\n                                 self.successResultOf(stub.content(resp)))\n\n    def test_handles_invalid_schemes(self):\n        \"\"\"\n        Invalid URLs errback with a :obj:`SchemeNotSupported` failure, and does\n        so even after a successful request.\n        \"\"\"\n        stub = StubTreq(_StaticTestResource())\n        self.failureResultOf(stub.get(\"x-unknown-1:\"), SchemeNotSupported)\n        self.successResultOf(stub.get(\"http://url.com\"))\n        self.failureResultOf(stub.get(\"x-unknown-2:\"), SchemeNotSupported)\n\n    def test_files_are_rejected(self):\n        \"\"\"\n        StubTreq does not handle files yet - it should reject requests which\n        attempt to pass files.\n        \"\"\"\n        stub = StubTreq(_StaticTestResource())\n        self.assertRaises(\n            AssertionError, stub.request,\n            'method', 'http://url', files=b'some file')\n\n    def test_passing_in_strange_data_is_rejected(self):\n        \"\"\"\n        StubTreq rejects data that isn't list/dictionary/tuple/bytes/unicode.\n        \"\"\"\n        stub = StubTreq(_StaticTestResource())\n        self.assertRaises(\n            AssertionError, stub.request, 'method', 'http://url',\n            data=object())\n        self.successResultOf(stub.request('method', 'http://url', data={}))\n        self.successResultOf(stub.request('method', 'http://url', data=[]))\n        self.successResultOf(stub.request('method', 'http://url', data=()))\n        self.successResultOf(\n            stub.request('method', 'http://url', data=b\"\"))\n        self.successResultOf(\n            stub.request('method', 'http://url', data=\"\"))\n\n    def test_handles_failing_asynchronous_requests(self):\n        \"\"\"\n        Handle a resource returning NOT_DONE_YET and then canceling the\n        request.\n        \"\"\"\n        stub = StubTreq(_NonResponsiveTestResource())\n        d = stub.request('method', 'http://url', data=b\"1234\")\n        self.assertNoResult(d)\n        d.cancel()\n        self.failureResultOf(d, ResponseFailed)\n\n    def test_handles_successful_asynchronous_requests(self):\n        \"\"\"\n        Handle a resource returning NOT_DONE_YET and then later finishing the\n        response.\n        \"\"\"\n        rsrc = _EventuallyResponsiveTestResource()\n        stub = StubTreq(rsrc)\n        d = stub.request('method', 'http://example.com/', data=b\"1234\")\n        self.assertNoResult(d)\n        rsrc.stored_request.finish()\n        stub.flush()\n        resp = self.successResultOf(d)\n        self.assertEqual(resp.code, 200)\n\n    def test_handles_successful_asynchronous_requests_with_response_data(self):\n        \"\"\"\n        Handle a resource returning NOT_DONE_YET and then sending some data in\n        the response.\n        \"\"\"\n        rsrc = _EventuallyResponsiveTestResource()\n        stub = StubTreq(rsrc)\n        d = stub.request('method', 'http://example.com/', data=b\"1234\")\n        self.assertNoResult(d)\n\n        chunks = []\n        rsrc.stored_request.write(b'spam ')\n        rsrc.stored_request.write(b'eggs')\n        stub.flush()\n        resp = self.successResultOf(d)\n        d = stub.collect(resp, chunks.append)\n        self.assertNoResult(d)\n        self.assertEqual(b''.join(chunks), b'spam eggs')\n\n        rsrc.stored_request.finish()\n        stub.flush()\n        self.successResultOf(d)\n\n    def test_handles_successful_asynchronous_requests_with_streaming(self):\n        \"\"\"\n        Handle a resource returning NOT_DONE_YET and then streaming data back\n        gradually over time.\n        \"\"\"\n        rsrc = _EventuallyResponsiveTestResource()\n        stub = StubTreq(rsrc)\n        d = stub.request('method', 'http://example.com/', data=\"1234\")\n        self.assertNoResult(d)\n\n        chunks = []\n        rsrc.stored_request.write(b'spam ')\n        rsrc.stored_request.write(b'eggs')\n        stub.flush()\n        resp = self.successResultOf(d)\n        d = stub.collect(resp, chunks.append)\n        self.assertNoResult(d)\n        self.assertEqual(b''.join(chunks), b'spam eggs')\n\n        del chunks[:]\n        rsrc.stored_request.write(b'eggs\\r\\nspam\\r\\n')\n        stub.flush()\n        self.assertNoResult(d)\n        self.assertEqual(b''.join(chunks), b'eggs\\r\\nspam\\r\\n')\n\n        rsrc.stored_request.finish()\n        stub.flush()\n        self.successResultOf(d)\n\n    def test_session_persistence_between_requests(self):\n        \"\"\"\n        Calling request.getSession() in the wrapped resource will return a\n        session with the same ID, until the sessions are cleaned; in other\n        words, cookies are propagated between requests when the result of\n        C{response.cookies()} is passed to the next request.\n        \"\"\"\n        rsrc = _SessionIdTestResource()\n        stub = StubTreq(rsrc)\n        # request 1, getting original session ID\n        d = stub.request(\"method\", \"http://example.com/\")\n        resp = self.successResultOf(d)\n        cookies = resp.cookies()\n        sid_1 = self.successResultOf(resp.content())\n        # request 2, ensuring session ID stays the same\n        d = stub.request(\"method\", \"http://example.com/\", cookies=cookies)\n        resp = self.successResultOf(d)\n        sid_2 = self.successResultOf(resp.content())\n        self.assertEqual(sid_1, sid_2)\n        # request 3, ensuring the session IDs are different after cleaning\n        # or expiring the sessions\n\n        # manually expire the sessions.\n        rsrc.expire_sessions()\n\n        d = stub.request(\"method\", \"http://example.com/\")\n        resp = self.successResultOf(d)\n        cookies = resp.cookies()\n        sid_3 = self.successResultOf(resp.content())\n        self.assertNotEqual(sid_1, sid_3)\n        # request 4, ensuring that once again the session IDs are the same\n        d = stub.request(\"method\", \"http://example.com/\", cookies=cookies)\n        resp = self.successResultOf(d)\n        sid_4 = self.successResultOf(resp.content())\n        self.assertEqual(sid_3, sid_4)\n\n    def test_different_domains(self):\n        \"\"\"\n        Cookies manually specified as part of a dictionary are not relayed\n        through redirects.\n\n        (This is really more of a test for scoping of cookies within treq\n        itself, rather than just for testing.)\n        \"\"\"\n        rsrc = _RedirectResource()\n        stub = StubTreq(rsrc)\n        d = stub.request(\n            \"GET\", \"http://example.com/\",\n            cookies={\"not-across-redirect\": \"nope\"}\n        )\n        resp = self.successResultOf(d)\n        received = self.successResultOf(resp.json())\n        self.assertNotIn('not-across-redirect', received.get('Cookie', [''])[0])\n\n\nclass HasHeadersTests(TestCase):\n    \"\"\"\n    Tests for :obj:`HasHeaders`.\n    \"\"\"\n    def test_equality_and_strict_subsets_succeed(self):\n        \"\"\"\n        The :obj:`HasHeaders` returns True if both sets of headers are\n        equivalent, or the first is a strict subset of the second.\n        \"\"\"\n        self.assertEqual(HasHeaders({'one': ['two', 'three']}),\n                         {'one': ['two', 'three']},\n                         \"Equivalent headers do not match.\")\n        self.assertEqual(HasHeaders({'one': ['two', 'three']}),\n                         {'one': ['two', 'three', 'four'],\n                          'ten': ['six']},\n                         \"Strict subset headers do not match\")\n\n    def test_partial_or_zero_intersection_subsets_fail(self):\n        \"\"\"\n        The :obj:`HasHeaders` returns False if both sets of headers overlap\n        but the first is not a strict subset of the second.  It also returns\n        False if there is no overlap.\n        \"\"\"\n        self.assertNotEqual(HasHeaders({'one': ['two', 'three']}),\n                            {'one': ['three', 'four']},\n                            \"Partial value overlap matches\")\n        self.assertNotEqual(HasHeaders({'one': ['two', 'three']}),\n                            {'one': ['two']},\n                            \"Missing value matches\")\n        self.assertNotEqual(HasHeaders({'one': ['two', 'three']}),\n                            {'ten': ['six']},\n                            \"Complete inequality matches\")\n\n    def test_case_insensitive_keys(self):\n        \"\"\"\n        The :obj:`HasHeaders` equality function ignores the case of the header\n        keys.\n        \"\"\"\n        self.assertEqual(HasHeaders({b'A': [b'1'], b'b': [b'2']}),\n                         {b'a': [b'1'], b'B': [b'2']})\n\n    def test_case_sensitive_values(self):\n        \"\"\"\n        The :obj:`HasHeaders` equality function does care about the case of\n        the header value.\n        \"\"\"\n        self.assertNotEqual(HasHeaders({b'a': [b'a']}), {b'a': [b'A']})\n\n    def test_bytes_encoded_forms(self):\n        \"\"\"\n        The :obj:`HasHeaders` equality function compares the bytes-encoded\n        forms of both sets of headers.\n        \"\"\"\n        self.assertEqual(HasHeaders({b'a': [b'a']}), {u'a': [u'a']})\n\n        self.assertEqual(HasHeaders({u'b': [u'b']}), {b'b': [b'b']})\n\n    def test_repr(self):\n        \"\"\"\n        :obj:`HasHeaders` returns a nice string repr.\n        \"\"\"\n        self.assertEqual(\n            \"HasHeaders({b'a': [b'b']})\",\n            repr(HasHeaders({b\"A\": [b\"b\"]})),\n        )\n\n\nclass StringStubbingTests(TestCase):\n    \"\"\"\n    Tests for :obj:`StringStubbingResource`.\n    \"\"\"\n    def _get_response_for(self, expected_args, response):\n        \"\"\"\n        Make a :obj:`IStringResponseStubs` that checks the expected args and\n        returns the given response.\n        \"\"\"\n        method, url, params, headers, data = expected_args\n\n        def get_response_for(_method, _url, _params, _headers, _data):\n            self.assertEqual((method, url, params, data),\n                             (_method, _url, _params, _data))\n            self.assertEqual(HasHeaders(headers), _headers)\n            return response\n\n        return get_response_for\n\n    def test_interacts_successfully_with_istub(self):\n        \"\"\"\n        The :obj:`IStringResponseStubs` is passed the correct parameters with\n        which to evaluate the response, and the response is returned.\n        \"\"\"\n        resource = StringStubbingResource(self._get_response_for(\n            (b'DELETE', 'http://what/a/thing', {b'page': [b'1']},\n             {b'x-header': [b'eh']}, b'datastr'),\n            (418, {b'x-response': b'responseheader'}, b'response body')))\n\n        stub = StubTreq(resource)\n\n        d = stub.delete('http://what/a/thing', headers={b'x-header': b'eh'},\n                        params={b'page': b'1'}, data=b'datastr')\n        resp = self.successResultOf(d)\n        self.assertEqual(418, resp.code)\n        self.assertEqual([b'responseheader'],\n                         resp.headers.getRawHeaders(b'x-response'))\n        self.assertEqual(b'response body',\n                         self.successResultOf(stub.content(resp)))\n\n\nclass RequestSequenceTests(TestCase):\n    \"\"\"\n    Tests for :obj:`RequestSequence`.\n    \"\"\"\n    def setUp(self):\n        \"\"\"\n        Set up a way to report failures asynchronously.\n        \"\"\"\n        self.async_failures = []\n\n    def test_mismatched_request_causes_failure(self):\n        \"\"\"\n        If a request is made that is not expected as the next request,\n        causes a failure.\n        \"\"\"\n        sequence = RequestSequence(\n            [((b'get', 'https://anything/', {b'1': [b'2']},\n               HasHeaders({b'1': [b'1']}), b'what'),\n              (418, {}, b'body')),\n             ((b'get', 'http://anything', {},\n               HasHeaders({b'2': [b'1']}), b'what'),\n              (202, {}, b'deleted'))],\n            async_failure_reporter=self.async_failures.append)\n\n        stub = StubTreq(StringStubbingResource(sequence))\n        get = partial(stub.get, 'https://anything?1=2', data=b'what',\n                      headers={b'1': b'1'})\n\n        resp = self.successResultOf(get())\n\n        self.assertEqual(418, resp.code)\n        self.assertEqual(b'body', self.successResultOf(stub.content(resp)))\n        self.assertEqual([], self.async_failures)\n\n        resp = self.successResultOf(get())\n        self.assertEqual(500, resp.code)\n        self.assertEqual(1, len(self.async_failures))\n        self.assertIn(\"Expected the next request to be\",\n                      self.async_failures[0])\n\n        self.assertFalse(sequence.consumed())\n\n    def test_unexpected_number_of_request_causes_failure(self):\n        \"\"\"\n        If there are no more expected requests, making a request causes a\n        failure.\n        \"\"\"\n        sequence = RequestSequence(\n            [],\n            async_failure_reporter=self.async_failures.append)\n        stub = StubTreq(StringStubbingResource(sequence))\n        d = stub.get('https://anything', data=b'what', headers={b'1': b'1'})\n        resp = self.successResultOf(d)\n        self.assertEqual(500, resp.code)\n        self.assertEqual(b'StubbingError',\n                         self.successResultOf(resp.content()))\n        self.assertEqual(1, len(self.async_failures))\n        self.assertIn(\"No more requests expected, but request\",\n                      self.async_failures[0])\n\n        # the expected requests have all been made\n        self.assertTrue(sequence.consumed())\n\n    def test_works_with_mock_any(self):\n        \"\"\"\n        :obj:`mock.ANY` can be used with the request parameters.\n        \"\"\"\n        sequence = RequestSequence(\n            [((ANY, ANY, ANY, ANY, ANY), (418, {}, b'body'))],\n            async_failure_reporter=self.async_failures.append)\n        stub = StubTreq(StringStubbingResource(sequence))\n\n        with sequence.consume(sync_failure_reporter=self.fail):\n            d = stub.get('https://anything', data=b'what',\n                         headers={b'1': b'1'})\n            resp = self.successResultOf(d)\n            self.assertEqual(418, resp.code)\n            self.assertEqual(b'body', self.successResultOf(stub.content(resp)))\n\n        self.assertEqual([], self.async_failures)\n\n        # the expected requests have all been made\n        self.assertTrue(sequence.consumed())\n\n    def test_consume_context_manager_fails_on_remaining_requests(self):\n        \"\"\"\n        If the `consume` context manager is used, if there are any remaining\n        expecting requests, the test case will be failed.\n        \"\"\"\n        sequence = RequestSequence(\n            [((ANY, ANY, ANY, ANY, ANY), (418, {}, b'body'))] * 2,\n            async_failure_reporter=self.async_failures.append)\n        stub = StubTreq(StringStubbingResource(sequence))\n\n        consume_failures = []\n        with sequence.consume(sync_failure_reporter=consume_failures.append):\n\n            self.successResultOf(stub.get('https://anything', data=b'what',\n                                          headers={b'1': b'1'}))\n\n        self.assertEqual(1, len(consume_failures))\n        self.assertIn(\n            \"Not all expected requests were made.  Still expecting:\",\n            consume_failures[0])\n        self.assertIn(\n            \"{0}(url={0}, params={0}, headers={0}, data={0})\".format(\n                repr(ANY)),\n            consume_failures[0])\n\n        # no asynchronous failures (mismatches, etc.)\n        self.assertEqual([], self.async_failures)\n\n    def test_async_failures_logged(self):\n        \"\"\"\n        When no `async_failure_reporter` is passed async failures are logged by\n        default.\n        \"\"\"\n        sequence = RequestSequence([])\n        stub = StubTreq(StringStubbingResource(sequence))\n\n        with sequence.consume(self.fail):\n            self.successResultOf(stub.get('https://example.com'))\n\n        [failure] = self.flushLoggedErrors()\n        self.assertIsInstance(failure.value, AssertionError)\n", "patch": "@@ -3,6 +3,7 @@\n \"\"\"\n from functools import partial\n from inspect import getmembers, isfunction\n+from json import dumps\n \n from unittest.mock import ANY\n \n@@ -32,6 +33,26 @@ def render(self, request):\n         return b\"I'm a teapot\"\n \n \n+class _RedirectResource(Resource):\n+    \"\"\"\n+    Resource that redirects to a different domain.\n+    \"\"\"\n+    isLeaf = True\n+\n+    def render(self, request):\n+        if b'redirected' not in request.uri:\n+            request.redirect(b'https://example.org/redirected')\n+        return dumps(\n+            {\n+                key.decode(\"charmap\"): [\n+                    value.decode(\"charmap\")\n+                    for value in values\n+                ]\n+                for key, values in\n+                request.requestHeaders.getAllRawHeaders()}\n+        ).encode(\"utf-8\")\n+\n+\n class _NonResponsiveTestResource(Resource):\n     \"\"\"Resource that returns NOT_DONE_YET and never finishes the request\"\"\"\n     isLeaf = True\n@@ -272,8 +293,10 @@ def test_handles_successful_asynchronous_requests_with_streaming(self):\n \n     def test_session_persistence_between_requests(self):\n         \"\"\"\n-        Calling request.getSession() in the wrapped resource will return\n-        a session with the same ID, until the sessions are cleaned.\n+        Calling request.getSession() in the wrapped resource will return a\n+        session with the same ID, until the sessions are cleaned; in other\n+        words, cookies are propagated between requests when the result of\n+        C{response.cookies()} is passed to the next request.\n         \"\"\"\n         rsrc = _SessionIdTestResource()\n         stub = StubTreq(rsrc)\n@@ -304,6 +327,24 @@ def test_session_persistence_between_requests(self):\n         sid_4 = self.successResultOf(resp.content())\n         self.assertEqual(sid_3, sid_4)\n \n+    def test_different_domains(self):\n+        \"\"\"\n+        Cookies manually specified as part of a dictionary are not relayed\n+        through redirects.\n+\n+        (This is really more of a test for scoping of cookies within treq\n+        itself, rather than just for testing.)\n+        \"\"\"\n+        rsrc = _RedirectResource()\n+        stub = StubTreq(rsrc)\n+        d = stub.request(\n+            \"GET\", \"http://example.com/\",\n+            cookies={\"not-across-redirect\": \"nope\"}\n+        )\n+        resp = self.successResultOf(d)\n+        received = self.successResultOf(resp.json())\n+        self.assertNotIn('not-across-redirect', received.get('Cookie', [''])[0])\n+\n \n class HasHeadersTests(TestCase):\n     \"\"\"", "file_path": "files/2022_2/1005", "file_language": "py", "file_name": "src/treq/test/test_testing.py", "outdated_file_modify": 0, "outdated_file_before": 1, "outdated_file_after": 0, "llm_check": 0, "static_check": 0, "static": {"rats": [false, []], "semgrep": [false, []]}, "target": 0, "function_before": [{"function": "class _StaticTestResource(Resource):\n    \"\"\"Resource that always returns 418 \"I'm a teapot\"\"\"\n    isLeaf = True\n\n    def render(self, request):\n        request.setResponseCode(418)\n        request.setHeader(b\"x-teapot\", b\"teapot!\")\n        return b\"I'm a teapot\"", "target": 0}, {"function": "class _RedirectResource(Resource):\n    \"\"\"\n    Resource that redirects to a different domain.\n    \"\"\"\n    isLeaf = True\n\n    def render(self, request):\n        if b'redirected' not in request.uri:\n            request.redirect(b'https://example.org/redirected')\n        return dumps(\n            {\n                key.decode(\"charmap\"): [\n                    value.decode(\"charmap\")\n                    for value in values\n                ]\n                for key, values in\n                request.requestHeaders.getAllRawHeaders()}\n        ).encode(\"utf-8\")", "target": 0}, {"function": "class _NonResponsiveTestResource(Resource):\n    \"\"\"Resource that returns NOT_DONE_YET and never finishes the request\"\"\"\n    isLeaf = True\n\n    def render(self, request):\n        return NOT_DONE_YET", "target": 0}, {"function": "class _EventuallyResponsiveTestResource(Resource):\n    \"\"\"\n    Resource that returns NOT_DONE_YET and stores the request so that something\n    else can finish the response later.\n    \"\"\"\n    isLeaf = True\n\n    def render(self, request):\n        self.stored_request = request\n        return NOT_DONE_YET", "target": 0}, {"function": "class _SessionIdTestResource(Resource):\n    \"\"\"\n    Resource that returns the current session ID.\n    \"\"\"\n    isLeaf = True\n\n    def __init__(self):\n        super().__init__()\n        # keep track of all sessions created, so we can manually expire them later\n        self.sessions = []\n\n    def render(self, request):\n        session = request.getSession()\n        if session not in self.sessions:\n            # new session, add to internal list\n            self.sessions.append(session)\n        uid = session.uid\n        return uid\n\n    def expire_sessions(self):\n        \"\"\"\n        Manually expire all sessions created by this resource.\n        \"\"\"\n        for session in self.sessions:\n            session.expire()\n        self.sessions = []", "target": 0}, {"function": "class StubbingTests(TestCase):\n    \"\"\"\n    Tests for :class:`StubTreq`.\n    \"\"\"\n    def test_stubtreq_provides_all_functions_in_treq_all(self):\n        \"\"\"\n        Every single function and attribute exposed by :obj:`treq.__all__` is\n        provided by :obj:`StubTreq`.\n        \"\"\"\n        treq_things = [(name, obj) for name, obj in getmembers(treq)\n                       if name in treq.__all__]\n        stub = StubTreq(_StaticTestResource())\n\n        api_things = [(name, obj) for name, obj in treq_things\n                      if obj.__module__ == \"treq.api\"]\n        content_things = [(name, obj) for name, obj in treq_things\n                          if obj.__module__ == \"treq.content\"]\n\n        # sanity checks - this test should fail if treq exposes a new API\n        # without changes being made to StubTreq and this test.\n        msg = (\"At the time this test was written, StubTreq only knew about \"\n               \"treq exposing functions from treq.api and treq.content.  If \"\n               \"this has changed, StubTreq will need to be updated, as will \"\n               \"this test.\")\n        self.assertTrue(all(isfunction(obj) for name, obj in treq_things), msg)\n        self.assertEqual(set(treq_things), set(api_things + content_things),\n                         msg)\n\n        for name, obj in api_things:\n            self.assertTrue(\n                isfunction(getattr(stub, name, None)),\n                \"StubTreq.{0} should be a function.\".format(name))\n\n        for name, obj in content_things:\n            self.assertIs(\n                getattr(stub, name, None), obj,\n                \"StubTreq.{0} should just expose treq.{0}\".format(name))\n\n    def test_providing_resource_to_stub_treq(self):\n        \"\"\"\n        The resource provided to StubTreq responds to every request no\n        matter what the URI or parameters or data.\n        \"\"\"\n        verbs = ('GET', 'PUT', 'HEAD', 'PATCH', 'DELETE', 'POST')\n        urls = (\n            'http://supports-http.com',\n            'https://supports-https.com',\n            'http://this/has/a/path/and/invalid/domain/name',\n            'https://supports-https.com:8080',\n            'http://supports-http.com:8080',\n        )\n        params = (None, {}, {b'page': [1]})\n        headers = (None, {}, {b'x-random-header': [b'value', b'value2']})\n        data = (None, b\"\", b'some data', b'{\"some\": \"json\"}')\n\n        stub = StubTreq(_StaticTestResource())\n\n        combos = (\n            (verb, {\"url\": url, \"params\": p, \"headers\": h, \"data\": d})\n            for verb in verbs\n            for url in urls\n            for p in params\n            for h in headers\n            for d in data\n        )\n        for combo in combos:\n            verb, kwargs = combo\n            deferreds = (stub.request(verb, **kwargs),\n                         getattr(stub, verb.lower())(**kwargs))\n            for d in deferreds:\n                resp = self.successResultOf(d)\n                self.assertEqual(418, resp.code)\n                self.assertEqual([b'teapot!'],\n                                 resp.headers.getRawHeaders(b'x-teapot'))\n                self.assertEqual(b\"\" if verb == \"HEAD\" else b\"I'm a teapot\",\n                                 self.successResultOf(stub.content(resp)))\n\n    def test_handles_invalid_schemes(self):\n        \"\"\"\n        Invalid URLs errback with a :obj:`SchemeNotSupported` failure, and does\n        so even after a successful request.\n        \"\"\"\n        stub = StubTreq(_StaticTestResource())\n        self.failureResultOf(stub.get(\"x-unknown-1:\"), SchemeNotSupported)\n        self.successResultOf(stub.get(\"http://url.com\"))\n        self.failureResultOf(stub.get(\"x-unknown-2:\"), SchemeNotSupported)\n\n    def test_files_are_rejected(self):\n        \"\"\"\n        StubTreq does not handle files yet - it should reject requests which\n        attempt to pass files.\n        \"\"\"\n        stub = StubTreq(_StaticTestResource())\n        self.assertRaises(\n            AssertionError, stub.request,\n            'method', 'http://url', files=b'some file')\n\n    def test_passing_in_strange_data_is_rejected(self):\n        \"\"\"\n        StubTreq rejects data that isn't list/dictionary/tuple/bytes/unicode.\n        \"\"\"\n        stub = StubTreq(_StaticTestResource())\n        self.assertRaises(\n            AssertionError, stub.request, 'method', 'http://url',\n            data=object())\n        self.successResultOf(stub.request('method', 'http://url', data={}))\n        self.successResultOf(stub.request('method', 'http://url', data=[]))\n        self.successResultOf(stub.request('method', 'http://url', data=()))\n        self.successResultOf(\n            stub.request('method', 'http://url', data=b\"\"))\n        self.successResultOf(\n            stub.request('method', 'http://url', data=\"\"))\n\n    def test_handles_failing_asynchronous_requests(self):\n        \"\"\"\n        Handle a resource returning NOT_DONE_YET and then canceling the\n        request.\n        \"\"\"\n        stub = StubTreq(_NonResponsiveTestResource())\n        d = stub.request('method', 'http://url', data=b\"1234\")\n        self.assertNoResult(d)\n        d.cancel()\n        self.failureResultOf(d, ResponseFailed)\n\n    def test_handles_successful_asynchronous_requests(self):\n        \"\"\"\n        Handle a resource returning NOT_DONE_YET and then later finishing the\n        response.\n        \"\"\"\n        rsrc = _EventuallyResponsiveTestResource()\n        stub = StubTreq(rsrc)\n        d = stub.request('method', 'http://example.com/', data=b\"1234\")\n        self.assertNoResult(d)\n        rsrc.stored_request.finish()\n        stub.flush()\n        resp = self.successResultOf(d)\n        self.assertEqual(resp.code, 200)\n\n    def test_handles_successful_asynchronous_requests_with_response_data(self):\n        \"\"\"\n        Handle a resource returning NOT_DONE_YET and then sending some data in\n        the response.\n        \"\"\"\n        rsrc = _EventuallyResponsiveTestResource()\n        stub = StubTreq(rsrc)\n        d = stub.request('method', 'http://example.com/', data=b\"1234\")\n        self.assertNoResult(d)\n\n        chunks = []\n        rsrc.stored_request.write(b'spam ')\n        rsrc.stored_request.write(b'eggs')\n        stub.flush()\n        resp = self.successResultOf(d)\n        d = stub.collect(resp, chunks.append)\n        self.assertNoResult(d)\n        self.assertEqual(b''.join(chunks), b'spam eggs')\n\n        rsrc.stored_request.finish()\n        stub.flush()\n        self.successResultOf(d)\n\n    def test_handles_successful_asynchronous_requests_with_streaming(self):\n        \"\"\"\n        Handle a resource returning NOT_DONE_YET and then streaming data back\n        gradually over time.\n        \"\"\"\n        rsrc = _EventuallyResponsiveTestResource()\n        stub = StubTreq(rsrc)\n        d = stub.request('method', 'http://example.com/', data=\"1234\")\n        self.assertNoResult(d)\n\n        chunks = []\n        rsrc.stored_request.write(b'spam ')\n        rsrc.stored_request.write(b'eggs')\n        stub.flush()\n        resp = self.successResultOf(d)\n        d = stub.collect(resp, chunks.append)\n        self.assertNoResult(d)\n        self.assertEqual(b''.join(chunks), b'spam eggs')\n\n        del chunks[:]\n        rsrc.stored_request.write(b'eggs\\r\\nspam\\r\\n')\n        stub.flush()\n        self.assertNoResult(d)\n        self.assertEqual(b''.join(chunks), b'eggs\\r\\nspam\\r\\n')\n\n        rsrc.stored_request.finish()\n        stub.flush()\n        self.successResultOf(d)\n\n    def test_session_persistence_between_requests(self):\n        \"\"\"\n        Calling request.getSession() in the wrapped resource will return a\n        session with the same ID, until the sessions are cleaned; in other\n        words, cookies are propagated between requests when the result of\n        C{response.cookies()} is passed to the next request.\n        \"\"\"\n        rsrc = _SessionIdTestResource()\n        stub = StubTreq(rsrc)\n        # request 1, getting original session ID\n        d = stub.request(\"method\", \"http://example.com/\")\n        resp = self.successResultOf(d)\n        cookies = resp.cookies()\n        sid_1 = self.successResultOf(resp.content())\n        # request 2, ensuring session ID stays the same\n        d = stub.request(\"method\", \"http://example.com/\", cookies=cookies)\n        resp = self.successResultOf(d)\n        sid_2 = self.successResultOf(resp.content())\n        self.assertEqual(sid_1, sid_2)\n        # request 3, ensuring the session IDs are different after cleaning\n        # or expiring the sessions\n\n        # manually expire the sessions.\n        rsrc.expire_sessions()\n\n        d = stub.request(\"method\", \"http://example.com/\")\n        resp = self.successResultOf(d)\n        cookies = resp.cookies()\n        sid_3 = self.successResultOf(resp.content())\n        self.assertNotEqual(sid_1, sid_3)\n        # request 4, ensuring that once again the session IDs are the same\n        d = stub.request(\"method\", \"http://example.com/\", cookies=cookies)\n        resp = self.successResultOf(d)\n        sid_4 = self.successResultOf(resp.content())\n        self.assertEqual(sid_3, sid_4)\n\n    def test_different_domains(self):\n        \"\"\"\n        Cookies manually specified as part of a dictionary are not relayed\n        through redirects.\n\n        (This is really more of a test for scoping of cookies within treq\n        itself, rather than just for testing.)\n        \"\"\"\n        rsrc = _RedirectResource()\n        stub = StubTreq(rsrc)\n        d = stub.request(\n            \"GET\", \"http://example.com/\",\n            cookies={\"not-across-redirect\": \"nope\"}\n        )\n        resp = self.successResultOf(d)\n        received = self.successResultOf(resp.json())\n        self.assertNotIn('not-across-redirect', received.get('Cookie', [''])[0])", "target": 0}, {"function": "class HasHeadersTests(TestCase):\n    \"\"\"\n    Tests for :obj:`HasHeaders`.\n    \"\"\"\n    def test_equality_and_strict_subsets_succeed(self):\n        \"\"\"\n        The :obj:`HasHeaders` returns True if both sets of headers are\n        equivalent, or the first is a strict subset of the second.\n        \"\"\"\n        self.assertEqual(HasHeaders({'one': ['two', 'three']}),\n                         {'one': ['two', 'three']},\n                         \"Equivalent headers do not match.\")\n        self.assertEqual(HasHeaders({'one': ['two', 'three']}),\n                         {'one': ['two', 'three', 'four'],\n                          'ten': ['six']},\n                         \"Strict subset headers do not match\")\n\n    def test_partial_or_zero_intersection_subsets_fail(self):\n        \"\"\"\n        The :obj:`HasHeaders` returns False if both sets of headers overlap\n        but the first is not a strict subset of the second.  It also returns\n        False if there is no overlap.\n        \"\"\"\n        self.assertNotEqual(HasHeaders({'one': ['two', 'three']}),\n                            {'one': ['three', 'four']},\n                            \"Partial value overlap matches\")\n        self.assertNotEqual(HasHeaders({'one': ['two', 'three']}),\n                            {'one': ['two']},\n                            \"Missing value matches\")\n        self.assertNotEqual(HasHeaders({'one': ['two', 'three']}),\n                            {'ten': ['six']},\n                            \"Complete inequality matches\")\n\n    def test_case_insensitive_keys(self):\n        \"\"\"\n        The :obj:`HasHeaders` equality function ignores the case of the header\n        keys.\n        \"\"\"\n        self.assertEqual(HasHeaders({b'A': [b'1'], b'b': [b'2']}),\n                         {b'a': [b'1'], b'B': [b'2']})\n\n    def test_case_sensitive_values(self):\n        \"\"\"\n        The :obj:`HasHeaders` equality function does care about the case of\n        the header value.\n        \"\"\"\n        self.assertNotEqual(HasHeaders({b'a': [b'a']}), {b'a': [b'A']})\n\n    def test_bytes_encoded_forms(self):\n        \"\"\"\n        The :obj:`HasHeaders` equality function compares the bytes-encoded\n        forms of both sets of headers.\n        \"\"\"\n        self.assertEqual(HasHeaders({b'a': [b'a']}), {u'a': [u'a']})\n\n        self.assertEqual(HasHeaders({u'b': [u'b']}), {b'b': [b'b']})\n\n    def test_repr(self):\n        \"\"\"\n        :obj:`HasHeaders` returns a nice string repr.\n        \"\"\"\n        self.assertEqual(\n            \"HasHeaders({b'a': [b'b']})\",\n            repr(HasHeaders({b\"A\": [b\"b\"]})),\n        )", "target": 0}, {"function": "class StringStubbingTests(TestCase):\n    \"\"\"\n    Tests for :obj:`StringStubbingResource`.\n    \"\"\"\n    def _get_response_for(self, expected_args, response):\n        \"\"\"\n        Make a :obj:`IStringResponseStubs` that checks the expected args and\n        returns the given response.\n        \"\"\"\n        method, url, params, headers, data = expected_args\n\n        def get_response_for(_method, _url, _params, _headers, _data):\n            self.assertEqual((method, url, params, data),\n                             (_method, _url, _params, _data))\n            self.assertEqual(HasHeaders(headers), _headers)\n            return response\n\n        return get_response_for\n\n    def test_interacts_successfully_with_istub(self):\n        \"\"\"\n        The :obj:`IStringResponseStubs` is passed the correct parameters with\n        which to evaluate the response, and the response is returned.\n        \"\"\"\n        resource = StringStubbingResource(self._get_response_for(\n            (b'DELETE', 'http://what/a/thing', {b'page': [b'1']},\n             {b'x-header': [b'eh']}, b'datastr'),\n            (418, {b'x-response': b'responseheader'}, b'response body')))\n\n        stub = StubTreq(resource)\n\n        d = stub.delete('http://what/a/thing', headers={b'x-header': b'eh'},\n                        params={b'page': b'1'}, data=b'datastr')\n        resp = self.successResultOf(d)\n        self.assertEqual(418, resp.code)\n        self.assertEqual([b'responseheader'],\n                         resp.headers.getRawHeaders(b'x-response'))\n        self.assertEqual(b'response body',\n                         self.successResultOf(stub.content(resp)))", "target": 0}, {"function": "class RequestSequenceTests(TestCase):\n    \"\"\"\n    Tests for :obj:`RequestSequence`.\n    \"\"\"\n    def setUp(self):\n        \"\"\"\n        Set up a way to report failures asynchronously.\n        \"\"\"\n        self.async_failures = []\n\n    def test_mismatched_request_causes_failure(self):\n        \"\"\"\n        If a request is made that is not expected as the next request,\n        causes a failure.\n        \"\"\"\n        sequence = RequestSequence(\n            [((b'get', 'https://anything/', {b'1': [b'2']},\n               HasHeaders({b'1': [b'1']}), b'what'),\n              (418, {}, b'body')),\n             ((b'get', 'http://anything', {},\n               HasHeaders({b'2': [b'1']}), b'what'),\n              (202, {}, b'deleted'))],\n            async_failure_reporter=self.async_failures.append)\n\n        stub = StubTreq(StringStubbingResource(sequence))\n        get = partial(stub.get, 'https://anything?1=2', data=b'what',\n                      headers={b'1': b'1'})\n\n        resp = self.successResultOf(get())\n\n        self.assertEqual(418, resp.code)\n        self.assertEqual(b'body', self.successResultOf(stub.content(resp)))\n        self.assertEqual([], self.async_failures)\n\n        resp = self.successResultOf(get())\n        self.assertEqual(500, resp.code)\n        self.assertEqual(1, len(self.async_failures))\n        self.assertIn(\"Expected the next request to be\",\n                      self.async_failures[0])\n\n        self.assertFalse(sequence.consumed())\n\n    def test_unexpected_number_of_request_causes_failure(self):\n        \"\"\"\n        If there are no more expected requests, making a request causes a\n        failure.\n        \"\"\"\n        sequence = RequestSequence(\n            [],\n            async_failure_reporter=self.async_failures.append)\n        stub = StubTreq(StringStubbingResource(sequence))\n        d = stub.get('https://anything', data=b'what', headers={b'1': b'1'})\n        resp = self.successResultOf(d)\n        self.assertEqual(500, resp.code)\n        self.assertEqual(b'StubbingError',\n                         self.successResultOf(resp.content()))\n        self.assertEqual(1, len(self.async_failures))\n        self.assertIn(\"No more requests expected, but request\",\n                      self.async_failures[0])\n\n        # the expected requests have all been made\n        self.assertTrue(sequence.consumed())\n\n    def test_works_with_mock_any(self):\n        \"\"\"\n        :obj:`mock.ANY` can be used with the request parameters.\n        \"\"\"\n        sequence = RequestSequence(\n            [((ANY, ANY, ANY, ANY, ANY), (418, {}, b'body'))],\n            async_failure_reporter=self.async_failures.append)\n        stub = StubTreq(StringStubbingResource(sequence))\n\n        with sequence.consume(sync_failure_reporter=self.fail):\n            d = stub.get('https://anything', data=b'what',\n                         headers={b'1': b'1'})\n            resp = self.successResultOf(d)\n            self.assertEqual(418, resp.code)\n            self.assertEqual(b'body', self.successResultOf(stub.content(resp)))\n\n        self.assertEqual([], self.async_failures)\n\n        # the expected requests have all been made\n        self.assertTrue(sequence.consumed())\n\n    def test_consume_context_manager_fails_on_remaining_requests(self):\n        \"\"\"\n        If the `consume` context manager is used, if there are any remaining\n        expecting requests, the test case will be failed.\n        \"\"\"\n        sequence = RequestSequence(\n            [((ANY, ANY, ANY, ANY, ANY), (418, {}, b'body'))] * 2,\n            async_failure_reporter=self.async_failures.append)\n        stub = StubTreq(StringStubbingResource(sequence))\n\n        consume_failures = []\n        with sequence.consume(sync_failure_reporter=consume_failures.append):\n\n            self.successResultOf(stub.get('https://anything', data=b'what',\n                                          headers={b'1': b'1'}))\n\n        self.assertEqual(1, len(consume_failures))\n        self.assertIn(\n            \"Not all expected requests were made.  Still expecting:\",\n            consume_failures[0])\n        self.assertIn(\n            \"{0}(url={0}, params={0}, headers={0}, data={0})\".format(\n                repr(ANY)),\n            consume_failures[0])\n\n        # no asynchronous failures (mismatches, etc.)\n        self.assertEqual([], self.async_failures)\n\n    def test_async_failures_logged(self):\n        \"\"\"\n        When no `async_failure_reporter` is passed async failures are logged by\n        default.\n        \"\"\"\n        sequence = RequestSequence([])\n        stub = StubTreq(StringStubbingResource(sequence))\n\n        with sequence.consume(self.fail):\n            self.successResultOf(stub.get('https://example.com'))\n\n        [failure] = self.flushLoggedErrors()\n        self.assertIsInstance(failure.value, AssertionError)", "target": 0}], "function_after": [{"function": "class _StaticTestResource(Resource):\n    \"\"\"Resource that always returns 418 \"I'm a teapot\"\"\"\n    isLeaf = True\n\n    def render(self, request):\n        request.setResponseCode(418)\n        request.setHeader(b\"x-teapot\", b\"teapot!\")\n        return b\"I'm a teapot\"", "target": 0}, {"function": "class _RedirectResource(Resource):\n    \"\"\"\n    Resource that redirects to a different domain.\n    \"\"\"\n    isLeaf = True\n\n    def render(self, request):\n        if b'redirected' not in request.uri:\n            request.redirect(b'https://example.org/redirected')\n        return dumps(\n            {\n                key.decode(\"charmap\"): [\n                    value.decode(\"charmap\")\n                    for value in values\n                ]\n                for key, values in\n                request.requestHeaders.getAllRawHeaders()}\n        ).encode(\"utf-8\")", "target": 0}, {"function": "class _NonResponsiveTestResource(Resource):\n    \"\"\"Resource that returns NOT_DONE_YET and never finishes the request\"\"\"\n    isLeaf = True\n\n    def render(self, request):\n        return NOT_DONE_YET", "target": 0}, {"function": "class _EventuallyResponsiveTestResource(Resource):\n    \"\"\"\n    Resource that returns NOT_DONE_YET and stores the request so that something\n    else can finish the response later.\n    \"\"\"\n    isLeaf = True\n\n    def render(self, request):\n        self.stored_request = request\n        return NOT_DONE_YET", "target": 0}, {"function": "class _SessionIdTestResource(Resource):\n    \"\"\"\n    Resource that returns the current session ID.\n    \"\"\"\n    isLeaf = True\n\n    def __init__(self):\n        super().__init__()\n        # keep track of all sessions created, so we can manually expire them later\n        self.sessions = []\n\n    def render(self, request):\n        session = request.getSession()\n        if session not in self.sessions:\n            # new session, add to internal list\n            self.sessions.append(session)\n        uid = session.uid\n        return uid\n\n    def expire_sessions(self):\n        \"\"\"\n        Manually expire all sessions created by this resource.\n        \"\"\"\n        for session in self.sessions:\n            session.expire()\n        self.sessions = []", "target": 0}, {"function": "class StubbingTests(TestCase):\n    \"\"\"\n    Tests for :class:`StubTreq`.\n    \"\"\"\n    def test_stubtreq_provides_all_functions_in_treq_all(self):\n        \"\"\"\n        Every single function and attribute exposed by :obj:`treq.__all__` is\n        provided by :obj:`StubTreq`.\n        \"\"\"\n        treq_things = [(name, obj) for name, obj in getmembers(treq)\n                       if name in treq.__all__]\n        stub = StubTreq(_StaticTestResource())\n\n        api_things = [(name, obj) for name, obj in treq_things\n                      if obj.__module__ == \"treq.api\"]\n        content_things = [(name, obj) for name, obj in treq_things\n                          if obj.__module__ == \"treq.content\"]\n\n        # sanity checks - this test should fail if treq exposes a new API\n        # without changes being made to StubTreq and this test.\n        msg = (\"At the time this test was written, StubTreq only knew about \"\n               \"treq exposing functions from treq.api and treq.content.  If \"\n               \"this has changed, StubTreq will need to be updated, as will \"\n               \"this test.\")\n        self.assertTrue(all(isfunction(obj) for name, obj in treq_things), msg)\n        self.assertEqual(set(treq_things), set(api_things + content_things),\n                         msg)\n\n        for name, obj in api_things:\n            self.assertTrue(\n                isfunction(getattr(stub, name, None)),\n                \"StubTreq.{0} should be a function.\".format(name))\n\n        for name, obj in content_things:\n            self.assertIs(\n                getattr(stub, name, None), obj,\n                \"StubTreq.{0} should just expose treq.{0}\".format(name))\n\n    def test_providing_resource_to_stub_treq(self):\n        \"\"\"\n        The resource provided to StubTreq responds to every request no\n        matter what the URI or parameters or data.\n        \"\"\"\n        verbs = ('GET', 'PUT', 'HEAD', 'PATCH', 'DELETE', 'POST')\n        urls = (\n            'http://supports-http.com',\n            'https://supports-https.com',\n            'http://this/has/a/path/and/invalid/domain/name',\n            'https://supports-https.com:8080',\n            'http://supports-http.com:8080',\n        )\n        params = (None, {}, {b'page': [1]})\n        headers = (None, {}, {b'x-random-header': [b'value', b'value2']})\n        data = (None, b\"\", b'some data', b'{\"some\": \"json\"}')\n\n        stub = StubTreq(_StaticTestResource())\n\n        combos = (\n            (verb, {\"url\": url, \"params\": p, \"headers\": h, \"data\": d})\n            for verb in verbs\n            for url in urls\n            for p in params\n            for h in headers\n            for d in data\n        )\n        for combo in combos:\n            verb, kwargs = combo\n            deferreds = (stub.request(verb, **kwargs),\n                         getattr(stub, verb.lower())(**kwargs))\n            for d in deferreds:\n                resp = self.successResultOf(d)\n                self.assertEqual(418, resp.code)\n                self.assertEqual([b'teapot!'],\n                                 resp.headers.getRawHeaders(b'x-teapot'))\n                self.assertEqual(b\"\" if verb == \"HEAD\" else b\"I'm a teapot\",\n                                 self.successResultOf(stub.content(resp)))\n\n    def test_handles_invalid_schemes(self):\n        \"\"\"\n        Invalid URLs errback with a :obj:`SchemeNotSupported` failure, and does\n        so even after a successful request.\n        \"\"\"\n        stub = StubTreq(_StaticTestResource())\n        self.failureResultOf(stub.get(\"x-unknown-1:\"), SchemeNotSupported)\n        self.successResultOf(stub.get(\"http://url.com\"))\n        self.failureResultOf(stub.get(\"x-unknown-2:\"), SchemeNotSupported)\n\n    def test_files_are_rejected(self):\n        \"\"\"\n        StubTreq does not handle files yet - it should reject requests which\n        attempt to pass files.\n        \"\"\"\n        stub = StubTreq(_StaticTestResource())\n        self.assertRaises(\n            AssertionError, stub.request,\n            'method', 'http://url', files=b'some file')\n\n    def test_passing_in_strange_data_is_rejected(self):\n        \"\"\"\n        StubTreq rejects data that isn't list/dictionary/tuple/bytes/unicode.\n        \"\"\"\n        stub = StubTreq(_StaticTestResource())\n        self.assertRaises(\n            AssertionError, stub.request, 'method', 'http://url',\n            data=object())\n        self.successResultOf(stub.request('method', 'http://url', data={}))\n        self.successResultOf(stub.request('method', 'http://url', data=[]))\n        self.successResultOf(stub.request('method', 'http://url', data=()))\n        self.successResultOf(\n            stub.request('method', 'http://url', data=b\"\"))\n        self.successResultOf(\n            stub.request('method', 'http://url', data=\"\"))\n\n    def test_handles_failing_asynchronous_requests(self):\n        \"\"\"\n        Handle a resource returning NOT_DONE_YET and then canceling the\n        request.\n        \"\"\"\n        stub = StubTreq(_NonResponsiveTestResource())\n        d = stub.request('method', 'http://url', data=b\"1234\")\n        self.assertNoResult(d)\n        d.cancel()\n        self.failureResultOf(d, ResponseFailed)\n\n    def test_handles_successful_asynchronous_requests(self):\n        \"\"\"\n        Handle a resource returning NOT_DONE_YET and then later finishing the\n        response.\n        \"\"\"\n        rsrc = _EventuallyResponsiveTestResource()\n        stub = StubTreq(rsrc)\n        d = stub.request('method', 'http://example.com/', data=b\"1234\")\n        self.assertNoResult(d)\n        rsrc.stored_request.finish()\n        stub.flush()\n        resp = self.successResultOf(d)\n        self.assertEqual(resp.code, 200)\n\n    def test_handles_successful_asynchronous_requests_with_response_data(self):\n        \"\"\"\n        Handle a resource returning NOT_DONE_YET and then sending some data in\n        the response.\n        \"\"\"\n        rsrc = _EventuallyResponsiveTestResource()\n        stub = StubTreq(rsrc)\n        d = stub.request('method', 'http://example.com/', data=b\"1234\")\n        self.assertNoResult(d)\n\n        chunks = []\n        rsrc.stored_request.write(b'spam ')\n        rsrc.stored_request.write(b'eggs')\n        stub.flush()\n        resp = self.successResultOf(d)\n        d = stub.collect(resp, chunks.append)\n        self.assertNoResult(d)\n        self.assertEqual(b''.join(chunks), b'spam eggs')\n\n        rsrc.stored_request.finish()\n        stub.flush()\n        self.successResultOf(d)\n\n    def test_handles_successful_asynchronous_requests_with_streaming(self):\n        \"\"\"\n        Handle a resource returning NOT_DONE_YET and then streaming data back\n        gradually over time.\n        \"\"\"\n        rsrc = _EventuallyResponsiveTestResource()\n        stub = StubTreq(rsrc)\n        d = stub.request('method', 'http://example.com/', data=\"1234\")\n        self.assertNoResult(d)\n\n        chunks = []\n        rsrc.stored_request.write(b'spam ')\n        rsrc.stored_request.write(b'eggs')\n        stub.flush()\n        resp = self.successResultOf(d)\n        d = stub.collect(resp, chunks.append)\n        self.assertNoResult(d)\n        self.assertEqual(b''.join(chunks), b'spam eggs')\n\n        del chunks[:]\n        rsrc.stored_request.write(b'eggs\\r\\nspam\\r\\n')\n        stub.flush()\n        self.assertNoResult(d)\n        self.assertEqual(b''.join(chunks), b'eggs\\r\\nspam\\r\\n')\n\n        rsrc.stored_request.finish()\n        stub.flush()\n        self.successResultOf(d)\n\n    def test_session_persistence_between_requests(self):\n        \"\"\"\n        Calling request.getSession() in the wrapped resource will return a\n        session with the same ID, until the sessions are cleaned; in other\n        words, cookies are propagated between requests when the result of\n        C{response.cookies()} is passed to the next request.\n        \"\"\"\n        rsrc = _SessionIdTestResource()\n        stub = StubTreq(rsrc)\n        # request 1, getting original session ID\n        d = stub.request(\"method\", \"http://example.com/\")\n        resp = self.successResultOf(d)\n        cookies = resp.cookies()\n        sid_1 = self.successResultOf(resp.content())\n        # request 2, ensuring session ID stays the same\n        d = stub.request(\"method\", \"http://example.com/\", cookies=cookies)\n        resp = self.successResultOf(d)\n        sid_2 = self.successResultOf(resp.content())\n        self.assertEqual(sid_1, sid_2)\n        # request 3, ensuring the session IDs are different after cleaning\n        # or expiring the sessions\n\n        # manually expire the sessions.\n        rsrc.expire_sessions()\n\n        d = stub.request(\"method\", \"http://example.com/\")\n        resp = self.successResultOf(d)\n        cookies = resp.cookies()\n        sid_3 = self.successResultOf(resp.content())\n        self.assertNotEqual(sid_1, sid_3)\n        # request 4, ensuring that once again the session IDs are the same\n        d = stub.request(\"method\", \"http://example.com/\", cookies=cookies)\n        resp = self.successResultOf(d)\n        sid_4 = self.successResultOf(resp.content())\n        self.assertEqual(sid_3, sid_4)\n\n    def test_different_domains(self):\n        \"\"\"\n        Cookies manually specified as part of a dictionary are not relayed\n        through redirects.\n\n        (This is really more of a test for scoping of cookies within treq\n        itself, rather than just for testing.)\n        \"\"\"\n        rsrc = _RedirectResource()\n        stub = StubTreq(rsrc)\n        d = stub.request(\n            \"GET\", \"http://example.com/\",\n            cookies={\"not-across-redirect\": \"nope\"}\n        )\n        resp = self.successResultOf(d)\n        received = self.successResultOf(resp.json())\n        self.assertNotIn('not-across-redirect', received.get('Cookie', [''])[0])", "target": 0}, {"function": "class HasHeadersTests(TestCase):\n    \"\"\"\n    Tests for :obj:`HasHeaders`.\n    \"\"\"\n    def test_equality_and_strict_subsets_succeed(self):\n        \"\"\"\n        The :obj:`HasHeaders` returns True if both sets of headers are\n        equivalent, or the first is a strict subset of the second.\n        \"\"\"\n        self.assertEqual(HasHeaders({'one': ['two', 'three']}),\n                         {'one': ['two', 'three']},\n                         \"Equivalent headers do not match.\")\n        self.assertEqual(HasHeaders({'one': ['two', 'three']}),\n                         {'one': ['two', 'three', 'four'],\n                          'ten': ['six']},\n                         \"Strict subset headers do not match\")\n\n    def test_partial_or_zero_intersection_subsets_fail(self):\n        \"\"\"\n        The :obj:`HasHeaders` returns False if both sets of headers overlap\n        but the first is not a strict subset of the second.  It also returns\n        False if there is no overlap.\n        \"\"\"\n        self.assertNotEqual(HasHeaders({'one': ['two', 'three']}),\n                            {'one': ['three', 'four']},\n                            \"Partial value overlap matches\")\n        self.assertNotEqual(HasHeaders({'one': ['two', 'three']}),\n                            {'one': ['two']},\n                            \"Missing value matches\")\n        self.assertNotEqual(HasHeaders({'one': ['two', 'three']}),\n                            {'ten': ['six']},\n                            \"Complete inequality matches\")\n\n    def test_case_insensitive_keys(self):\n        \"\"\"\n        The :obj:`HasHeaders` equality function ignores the case of the header\n        keys.\n        \"\"\"\n        self.assertEqual(HasHeaders({b'A': [b'1'], b'b': [b'2']}),\n                         {b'a': [b'1'], b'B': [b'2']})\n\n    def test_case_sensitive_values(self):\n        \"\"\"\n        The :obj:`HasHeaders` equality function does care about the case of\n        the header value.\n        \"\"\"\n        self.assertNotEqual(HasHeaders({b'a': [b'a']}), {b'a': [b'A']})\n\n    def test_bytes_encoded_forms(self):\n        \"\"\"\n        The :obj:`HasHeaders` equality function compares the bytes-encoded\n        forms of both sets of headers.\n        \"\"\"\n        self.assertEqual(HasHeaders({b'a': [b'a']}), {u'a': [u'a']})\n\n        self.assertEqual(HasHeaders({u'b': [u'b']}), {b'b': [b'b']})\n\n    def test_repr(self):\n        \"\"\"\n        :obj:`HasHeaders` returns a nice string repr.\n        \"\"\"\n        self.assertEqual(\n            \"HasHeaders({b'a': [b'b']})\",\n            repr(HasHeaders({b\"A\": [b\"b\"]})),\n        )", "target": 0}, {"function": "class StringStubbingTests(TestCase):\n    \"\"\"\n    Tests for :obj:`StringStubbingResource`.\n    \"\"\"\n    def _get_response_for(self, expected_args, response):\n        \"\"\"\n        Make a :obj:`IStringResponseStubs` that checks the expected args and\n        returns the given response.\n        \"\"\"\n        method, url, params, headers, data = expected_args\n\n        def get_response_for(_method, _url, _params, _headers, _data):\n            self.assertEqual((method, url, params, data),\n                             (_method, _url, _params, _data))\n            self.assertEqual(HasHeaders(headers), _headers)\n            return response\n\n        return get_response_for\n\n    def test_interacts_successfully_with_istub(self):\n        \"\"\"\n        The :obj:`IStringResponseStubs` is passed the correct parameters with\n        which to evaluate the response, and the response is returned.\n        \"\"\"\n        resource = StringStubbingResource(self._get_response_for(\n            (b'DELETE', 'http://what/a/thing', {b'page': [b'1']},\n             {b'x-header': [b'eh']}, b'datastr'),\n            (418, {b'x-response': b'responseheader'}, b'response body')))\n\n        stub = StubTreq(resource)\n\n        d = stub.delete('http://what/a/thing', headers={b'x-header': b'eh'},\n                        params={b'page': b'1'}, data=b'datastr')\n        resp = self.successResultOf(d)\n        self.assertEqual(418, resp.code)\n        self.assertEqual([b'responseheader'],\n                         resp.headers.getRawHeaders(b'x-response'))\n        self.assertEqual(b'response body',\n                         self.successResultOf(stub.content(resp)))", "target": 0}, {"function": "class RequestSequenceTests(TestCase):\n    \"\"\"\n    Tests for :obj:`RequestSequence`.\n    \"\"\"\n    def setUp(self):\n        \"\"\"\n        Set up a way to report failures asynchronously.\n        \"\"\"\n        self.async_failures = []\n\n    def test_mismatched_request_causes_failure(self):\n        \"\"\"\n        If a request is made that is not expected as the next request,\n        causes a failure.\n        \"\"\"\n        sequence = RequestSequence(\n            [((b'get', 'https://anything/', {b'1': [b'2']},\n               HasHeaders({b'1': [b'1']}), b'what'),\n              (418, {}, b'body')),\n             ((b'get', 'http://anything', {},\n               HasHeaders({b'2': [b'1']}), b'what'),\n              (202, {}, b'deleted'))],\n            async_failure_reporter=self.async_failures.append)\n\n        stub = StubTreq(StringStubbingResource(sequence))\n        get = partial(stub.get, 'https://anything?1=2', data=b'what',\n                      headers={b'1': b'1'})\n\n        resp = self.successResultOf(get())\n\n        self.assertEqual(418, resp.code)\n        self.assertEqual(b'body', self.successResultOf(stub.content(resp)))\n        self.assertEqual([], self.async_failures)\n\n        resp = self.successResultOf(get())\n        self.assertEqual(500, resp.code)\n        self.assertEqual(1, len(self.async_failures))\n        self.assertIn(\"Expected the next request to be\",\n                      self.async_failures[0])\n\n        self.assertFalse(sequence.consumed())\n\n    def test_unexpected_number_of_request_causes_failure(self):\n        \"\"\"\n        If there are no more expected requests, making a request causes a\n        failure.\n        \"\"\"\n        sequence = RequestSequence(\n            [],\n            async_failure_reporter=self.async_failures.append)\n        stub = StubTreq(StringStubbingResource(sequence))\n        d = stub.get('https://anything', data=b'what', headers={b'1': b'1'})\n        resp = self.successResultOf(d)\n        self.assertEqual(500, resp.code)\n        self.assertEqual(b'StubbingError',\n                         self.successResultOf(resp.content()))\n        self.assertEqual(1, len(self.async_failures))\n        self.assertIn(\"No more requests expected, but request\",\n                      self.async_failures[0])\n\n        # the expected requests have all been made\n        self.assertTrue(sequence.consumed())\n\n    def test_works_with_mock_any(self):\n        \"\"\"\n        :obj:`mock.ANY` can be used with the request parameters.\n        \"\"\"\n        sequence = RequestSequence(\n            [((ANY, ANY, ANY, ANY, ANY), (418, {}, b'body'))],\n            async_failure_reporter=self.async_failures.append)\n        stub = StubTreq(StringStubbingResource(sequence))\n\n        with sequence.consume(sync_failure_reporter=self.fail):\n            d = stub.get('https://anything', data=b'what',\n                         headers={b'1': b'1'})\n            resp = self.successResultOf(d)\n            self.assertEqual(418, resp.code)\n            self.assertEqual(b'body', self.successResultOf(stub.content(resp)))\n\n        self.assertEqual([], self.async_failures)\n\n        # the expected requests have all been made\n        self.assertTrue(sequence.consumed())\n\n    def test_consume_context_manager_fails_on_remaining_requests(self):\n        \"\"\"\n        If the `consume` context manager is used, if there are any remaining\n        expecting requests, the test case will be failed.\n        \"\"\"\n        sequence = RequestSequence(\n            [((ANY, ANY, ANY, ANY, ANY), (418, {}, b'body'))] * 2,\n            async_failure_reporter=self.async_failures.append)\n        stub = StubTreq(StringStubbingResource(sequence))\n\n        consume_failures = []\n        with sequence.consume(sync_failure_reporter=consume_failures.append):\n\n            self.successResultOf(stub.get('https://anything', data=b'what',\n                                          headers={b'1': b'1'}))\n\n        self.assertEqual(1, len(consume_failures))\n        self.assertIn(\n            \"Not all expected requests were made.  Still expecting:\",\n            consume_failures[0])\n        self.assertIn(\n            \"{0}(url={0}, params={0}, headers={0}, data={0})\".format(\n                repr(ANY)),\n            consume_failures[0])\n\n        # no asynchronous failures (mismatches, etc.)\n        self.assertEqual([], self.async_failures)\n\n    def test_async_failures_logged(self):\n        \"\"\"\n        When no `async_failure_reporter` is passed async failures are logged by\n        default.\n        \"\"\"\n        sequence = RequestSequence([])\n        stub = StubTreq(StringStubbingResource(sequence))\n\n        with sequence.consume(self.fail):\n            self.successResultOf(stub.get('https://example.com'))\n\n        [failure] = self.flushLoggedErrors()\n        self.assertIsInstance(failure.value, AssertionError)", "target": 0}]}, {"raw_url": "https://github.com/twisted/treq/raw/1da6022cc880bbcff59321abe02bf8498b89efb2/src%2Ftreq%2Ftest%2Ftest_treq_integration.py", "code": "from io import BytesIO\n\nfrom twisted.python.url import URL\n\nfrom twisted.trial.unittest import TestCase\nfrom twisted.internet.defer import CancelledError, inlineCallbacks\nfrom twisted.internet.task import deferLater\nfrom twisted.internet import reactor\nfrom twisted.internet.tcp import Client\nfrom twisted.internet.ssl import Certificate, trustRootFromCertificates\n\nfrom twisted.web.client import (Agent, BrowserLikePolicyForHTTPS,\n                                HTTPConnectionPool, ResponseFailed)\n\nfrom treq.test.util import DEBUG, skip_on_windows_because_of_199\n\nfrom .local_httpbin.parent import _HTTPBinProcess\n\nimport treq\n\n\nskip = skip_on_windows_because_of_199()\n\n\n@inlineCallbacks\ndef print_response(response):\n    if DEBUG:\n        print()\n        print('---')\n        print(response.code)\n        print(response.headers)\n        print(response.request.headers)\n        text = yield treq.text_content(response)\n        print(text)\n        print('---')\n\n\ndef with_baseurl(method):\n    def _request(self, url, *args, **kwargs):\n        return method(self.baseurl + url,\n                      *args,\n                      agent=self.agent,\n                      pool=self.pool,\n                      **kwargs)\n\n    return _request\n\n\nclass TreqIntegrationTests(TestCase):\n    get = with_baseurl(treq.get)\n    head = with_baseurl(treq.head)\n    post = with_baseurl(treq.post)\n    put = with_baseurl(treq.put)\n    patch = with_baseurl(treq.patch)\n    delete = with_baseurl(treq.delete)\n\n    _httpbin_process = _HTTPBinProcess(https=False)\n\n    @inlineCallbacks\n    def setUp(self):\n        description = yield self._httpbin_process.server_description(\n            reactor)\n        self.baseurl = URL(scheme=u\"http\",\n                           host=description.host,\n                           port=description.port).asText()\n        self.agent = Agent(reactor)\n        self.pool = HTTPConnectionPool(reactor, False)\n\n    def tearDown(self):\n        def _check_fds(_):\n            # This appears to only be necessary for HTTPS tests.\n            # For the normal HTTP tests then closeCachedConnections is\n            # sufficient.\n            fds = set(reactor.getReaders() + reactor.getReaders())\n            if not [fd for fd in fds if isinstance(fd, Client)]:\n                return\n\n            return deferLater(reactor, 0, _check_fds, None)\n\n        return self.pool.closeCachedConnections().addBoth(_check_fds)\n\n    @inlineCallbacks\n    def assert_data(self, response, expected_data):\n        body = yield treq.json_content(response)\n        self.assertIn('data', body)\n        self.assertEqual(body['data'], expected_data)\n\n    @inlineCallbacks\n    def assert_sent_header(self, response, header, expected_value):\n        body = yield treq.json_content(response)\n        self.assertIn(header, body['headers'])\n        self.assertEqual(body['headers'][header], expected_value)\n\n    @inlineCallbacks\n    def test_get(self):\n        response = yield self.get('/get')\n        self.assertEqual(response.code, 200)\n        yield print_response(response)\n\n    @inlineCallbacks\n    def test_get_headers(self):\n        response = yield self.get('/get', {b'X-Blah': [b'Foo', b'Bar']})\n        self.assertEqual(response.code, 200)\n        yield self.assert_sent_header(response, 'X-Blah', 'Foo,Bar')\n        yield print_response(response)\n\n    @inlineCallbacks\n    def test_get_headers_unicode(self):\n        response = yield self.get('/get', {u'X-Blah': [u'Foo', b'Bar']})\n        self.assertEqual(response.code, 200)\n        yield self.assert_sent_header(response, 'X-Blah', 'Foo,Bar')\n        yield print_response(response)\n\n    @inlineCallbacks\n    def test_get_302_absolute_redirect(self):\n        response = yield self.get(\n            '/redirect-to?url={0}/get'.format(self.baseurl))\n        self.assertEqual(response.code, 200)\n        yield print_response(response)\n\n    @inlineCallbacks\n    def test_get_302_relative_redirect(self):\n        response = yield self.get('/relative-redirect/1')\n        self.assertEqual(response.code, 200)\n        yield print_response(response)\n\n    @inlineCallbacks\n    def test_get_302_redirect_disallowed(self):\n        response = yield self.get('/redirect/1', allow_redirects=False)\n        self.assertEqual(response.code, 302)\n        yield print_response(response)\n\n    @inlineCallbacks\n    def test_head(self):\n        response = yield self.head('/get')\n        body = yield treq.content(response)\n        self.assertEqual(b'', body)\n        yield print_response(response)\n\n    @inlineCallbacks\n    def test_head_302_absolute_redirect(self):\n        response = yield self.head(\n            '/redirect-to?url={0}/get'.format(self.baseurl))\n        self.assertEqual(response.code, 200)\n        yield print_response(response)\n\n    @inlineCallbacks\n    def test_head_302_relative_redirect(self):\n        response = yield self.head('/relative-redirect/1')\n        self.assertEqual(response.code, 200)\n        yield print_response(response)\n\n    @inlineCallbacks\n    def test_head_302_redirect_disallowed(self):\n        response = yield self.head('/redirect/1', allow_redirects=False)\n        self.assertEqual(response.code, 302)\n        yield print_response(response)\n\n    @inlineCallbacks\n    def test_post(self):\n        response = yield self.post('/post', b'Hello!')\n        self.assertEqual(response.code, 200)\n        yield self.assert_data(response, 'Hello!')\n        yield print_response(response)\n\n    @inlineCallbacks\n    def test_multipart_post(self):\n        class FileLikeObject(BytesIO):\n            def __init__(self, val):\n                BytesIO.__init__(self, val)\n                self.name = \"david.png\"\n\n            def read(*args, **kwargs):\n                return BytesIO.read(*args, **kwargs)\n\n        response = yield self.post(\n            '/post',\n            data={\"a\": \"b\"},\n            files={\"file1\": FileLikeObject(b\"file\")})\n        self.assertEqual(response.code, 200)\n\n        body = yield treq.json_content(response)\n        self.assertEqual('b', body['form']['a'])\n        self.assertEqual('file', body['files']['file1'])\n        yield print_response(response)\n\n    @inlineCallbacks\n    def test_post_headers(self):\n        response = yield self.post(\n            '/post',\n            b'{msg: \"Hello!\"}',\n            headers={'Content-Type': ['application/json']}\n        )\n\n        self.assertEqual(response.code, 200)\n        yield self.assert_sent_header(\n            response, 'Content-Type', 'application/json')\n        yield self.assert_data(response, '{msg: \"Hello!\"}')\n        yield print_response(response)\n\n    @inlineCallbacks\n    def test_put(self):\n        response = yield self.put('/put', data=b'Hello!')\n        yield print_response(response)\n\n    @inlineCallbacks\n    def test_patch(self):\n        response = yield self.patch('/patch', data=b'Hello!')\n        self.assertEqual(response.code, 200)\n        yield self.assert_data(response, 'Hello!')\n        yield print_response(response)\n\n    @inlineCallbacks\n    def test_delete(self):\n        response = yield self.delete('/delete')\n        self.assertEqual(response.code, 200)\n        yield print_response(response)\n\n    @inlineCallbacks\n    def test_gzip(self):\n        response = yield self.get('/gzip')\n        self.assertEqual(response.code, 200)\n        yield print_response(response)\n        json = yield treq.json_content(response)\n        self.assertTrue(json['gzipped'])\n\n    @inlineCallbacks\n    def test_basic_auth(self):\n        response = yield self.get('/basic-auth/treq/treq',\n                                  auth=('treq', 'treq'))\n        self.assertEqual(response.code, 200)\n        yield print_response(response)\n        json = yield treq.json_content(response)\n        self.assertTrue(json['authenticated'])\n        self.assertEqual(json['user'], 'treq')\n\n    @inlineCallbacks\n    def test_failed_basic_auth(self):\n        response = yield self.get('/basic-auth/treq/treq',\n                                  auth=('not-treq', 'not-treq'))\n        self.assertEqual(response.code, 401)\n        yield print_response(response)\n\n    @inlineCallbacks\n    def test_timeout(self):\n        \"\"\"\n        Verify a timeout fires if a request takes too long.\n        \"\"\"\n        yield self.assertFailure(self.get('/delay/2', timeout=1),\n                                 CancelledError,\n                                 ResponseFailed)\n\n    @inlineCallbacks\n    def test_cookie(self):\n        response = yield self.get('/cookies', cookies={'hello': 'there'})\n        self.assertEqual(response.code, 200)\n        yield print_response(response)\n        json = yield treq.json_content(response)\n        self.assertEqual(json['cookies']['hello'], 'there')\n\n    @inlineCallbacks\n    def test_set_cookie(self):\n        response = yield self.get('/cookies/set',\n                                  allow_redirects=False,\n                                  params={'hello': 'there'})\n        # self.assertEqual(response.code, 200)\n        yield print_response(response)\n        self.assertEqual(response.cookies()['hello'], 'there')\n\n\nclass HTTPSTreqIntegrationTests(TreqIntegrationTests):\n    _httpbin_process = _HTTPBinProcess(https=True)\n\n    @inlineCallbacks\n    def setUp(self):\n        description = yield self._httpbin_process.server_description(\n            reactor)\n        self.baseurl = URL(scheme=u\"https\",\n                           host=description.host,\n                           port=description.port).asText()\n\n        root = trustRootFromCertificates(\n            [Certificate.loadPEM(description.cacert)],\n        )\n        self.agent = Agent(\n            reactor,\n            contextFactory=BrowserLikePolicyForHTTPS(root),\n        )\n\n        self.pool = HTTPConnectionPool(reactor, False)\n", "code_before": "from io import BytesIO\n\nfrom twisted.python.url import URL\n\nfrom twisted.trial.unittest import TestCase\nfrom twisted.internet.defer import CancelledError, inlineCallbacks\nfrom twisted.internet.task import deferLater\nfrom twisted.internet import reactor\nfrom twisted.internet.tcp import Client\nfrom twisted.internet.ssl import Certificate, trustRootFromCertificates\n\nfrom twisted.web.client import (Agent, BrowserLikePolicyForHTTPS,\n                                HTTPConnectionPool, ResponseFailed)\n\nfrom treq.test.util import DEBUG, skip_on_windows_because_of_199\n\nfrom .local_httpbin.parent import _HTTPBinProcess\n\nimport treq\n\n\nskip = skip_on_windows_because_of_199()\n\n\n@inlineCallbacks\ndef print_response(response):\n    if DEBUG:\n        print()\n        print('---')\n        print(response.code)\n        print(response.headers)\n        print(response.request.headers)\n        text = yield treq.text_content(response)\n        print(text)\n        print('---')\n\n\ndef with_baseurl(method):\n    def _request(self, url, *args, **kwargs):\n        return method(self.baseurl + url,\n                      *args,\n                      agent=self.agent,\n                      pool=self.pool,\n                      **kwargs)\n\n    return _request\n\n\nclass TreqIntegrationTests(TestCase):\n    get = with_baseurl(treq.get)\n    head = with_baseurl(treq.head)\n    post = with_baseurl(treq.post)\n    put = with_baseurl(treq.put)\n    patch = with_baseurl(treq.patch)\n    delete = with_baseurl(treq.delete)\n\n    _httpbin_process = _HTTPBinProcess(https=False)\n\n    @inlineCallbacks\n    def setUp(self):\n        description = yield self._httpbin_process.server_description(\n            reactor)\n        self.baseurl = URL(scheme=u\"http\",\n                           host=description.host,\n                           port=description.port).asText()\n        self.agent = Agent(reactor)\n        self.pool = HTTPConnectionPool(reactor, False)\n\n    def tearDown(self):\n        def _check_fds(_):\n            # This appears to only be necessary for HTTPS tests.\n            # For the normal HTTP tests then closeCachedConnections is\n            # sufficient.\n            fds = set(reactor.getReaders() + reactor.getReaders())\n            if not [fd for fd in fds if isinstance(fd, Client)]:\n                return\n\n            return deferLater(reactor, 0, _check_fds, None)\n\n        return self.pool.closeCachedConnections().addBoth(_check_fds)\n\n    @inlineCallbacks\n    def assert_data(self, response, expected_data):\n        body = yield treq.json_content(response)\n        self.assertIn('data', body)\n        self.assertEqual(body['data'], expected_data)\n\n    @inlineCallbacks\n    def assert_sent_header(self, response, header, expected_value):\n        body = yield treq.json_content(response)\n        self.assertIn(header, body['headers'])\n        self.assertEqual(body['headers'][header], expected_value)\n\n    @inlineCallbacks\n    def test_get(self):\n        response = yield self.get('/get')\n        self.assertEqual(response.code, 200)\n        yield print_response(response)\n\n    @inlineCallbacks\n    def test_get_headers(self):\n        response = yield self.get('/get', {b'X-Blah': [b'Foo', b'Bar']})\n        self.assertEqual(response.code, 200)\n        yield self.assert_sent_header(response, 'X-Blah', 'Foo,Bar')\n        yield print_response(response)\n\n    @inlineCallbacks\n    def test_get_headers_unicode(self):\n        response = yield self.get('/get', {u'X-Blah': [u'Foo', b'Bar']})\n        self.assertEqual(response.code, 200)\n        yield self.assert_sent_header(response, 'X-Blah', 'Foo,Bar')\n        yield print_response(response)\n\n    @inlineCallbacks\n    def test_get_302_absolute_redirect(self):\n        response = yield self.get(\n            '/redirect-to?url={0}/get'.format(self.baseurl))\n        self.assertEqual(response.code, 200)\n        yield print_response(response)\n\n    @inlineCallbacks\n    def test_get_302_relative_redirect(self):\n        response = yield self.get('/relative-redirect/1')\n        self.assertEqual(response.code, 200)\n        yield print_response(response)\n\n    @inlineCallbacks\n    def test_get_302_redirect_disallowed(self):\n        response = yield self.get('/redirect/1', allow_redirects=False)\n        self.assertEqual(response.code, 302)\n        yield print_response(response)\n\n    @inlineCallbacks\n    def test_head(self):\n        response = yield self.head('/get')\n        body = yield treq.content(response)\n        self.assertEqual(b'', body)\n        yield print_response(response)\n\n    @inlineCallbacks\n    def test_head_302_absolute_redirect(self):\n        response = yield self.head(\n            '/redirect-to?url={0}/get'.format(self.baseurl))\n        self.assertEqual(response.code, 200)\n        yield print_response(response)\n\n    @inlineCallbacks\n    def test_head_302_relative_redirect(self):\n        response = yield self.head('/relative-redirect/1')\n        self.assertEqual(response.code, 200)\n        yield print_response(response)\n\n    @inlineCallbacks\n    def test_head_302_redirect_disallowed(self):\n        response = yield self.head('/redirect/1', allow_redirects=False)\n        self.assertEqual(response.code, 302)\n        yield print_response(response)\n\n    @inlineCallbacks\n    def test_post(self):\n        response = yield self.post('/post', b'Hello!')\n        self.assertEqual(response.code, 200)\n        yield self.assert_data(response, 'Hello!')\n        yield print_response(response)\n\n    @inlineCallbacks\n    def test_multipart_post(self):\n        class FileLikeObject(BytesIO):\n            def __init__(self, val):\n                BytesIO.__init__(self, val)\n                self.name = \"david.png\"\n\n            def read(*args, **kwargs):\n                return BytesIO.read(*args, **kwargs)\n\n        response = yield self.post(\n            '/post',\n            data={\"a\": \"b\"},\n            files={\"file1\": FileLikeObject(b\"file\")})\n        self.assertEqual(response.code, 200)\n\n        body = yield treq.json_content(response)\n        self.assertEqual('b', body['form']['a'])\n        self.assertEqual('file', body['files']['file1'])\n        yield print_response(response)\n\n    @inlineCallbacks\n    def test_post_headers(self):\n        response = yield self.post(\n            '/post',\n            b'{msg: \"Hello!\"}',\n            headers={'Content-Type': ['application/json']}\n        )\n\n        self.assertEqual(response.code, 200)\n        yield self.assert_sent_header(\n            response, 'Content-Type', 'application/json')\n        yield self.assert_data(response, '{msg: \"Hello!\"}')\n        yield print_response(response)\n\n    @inlineCallbacks\n    def test_put(self):\n        response = yield self.put('/put', data=b'Hello!')\n        yield print_response(response)\n\n    @inlineCallbacks\n    def test_patch(self):\n        response = yield self.patch('/patch', data=b'Hello!')\n        self.assertEqual(response.code, 200)\n        yield self.assert_data(response, 'Hello!')\n        yield print_response(response)\n\n    @inlineCallbacks\n    def test_delete(self):\n        response = yield self.delete('/delete')\n        self.assertEqual(response.code, 200)\n        yield print_response(response)\n\n    @inlineCallbacks\n    def test_gzip(self):\n        response = yield self.get('/gzip')\n        self.assertEqual(response.code, 200)\n        yield print_response(response)\n        json = yield treq.json_content(response)\n        self.assertTrue(json['gzipped'])\n\n    @inlineCallbacks\n    def test_basic_auth(self):\n        response = yield self.get('/basic-auth/treq/treq',\n                                  auth=('treq', 'treq'))\n        self.assertEqual(response.code, 200)\n        yield print_response(response)\n        json = yield treq.json_content(response)\n        self.assertTrue(json['authenticated'])\n        self.assertEqual(json['user'], 'treq')\n\n    @inlineCallbacks\n    def test_failed_basic_auth(self):\n        response = yield self.get('/basic-auth/treq/treq',\n                                  auth=('not-treq', 'not-treq'))\n        self.assertEqual(response.code, 401)\n        yield print_response(response)\n\n    @inlineCallbacks\n    def test_timeout(self):\n        \"\"\"\n        Verify a timeout fires if a request takes too long.\n        \"\"\"\n        yield self.assertFailure(self.get('/delay/2', timeout=1),\n                                 CancelledError,\n                                 ResponseFailed)\n\n    @inlineCallbacks\n    def test_cookie(self):\n        response = yield self.get('/cookies', cookies={'hello': 'there'})\n        self.assertEqual(response.code, 200)\n        yield print_response(response)\n        json = yield treq.json_content(response)\n        self.assertEqual(json['cookies']['hello'], 'there')\n\n    @inlineCallbacks\n    def test_set_cookie(self):\n        response = yield self.get('/cookies/set',\n                                  allow_redirects=False,\n                                  params={'hello': 'there'})\n        # self.assertEqual(response.code, 200)\n        yield print_response(response)\n        self.assertEqual(response.cookies()['hello'], 'there')\n\n\nclass HTTPSTreqIntegrationTests(TreqIntegrationTests):\n    _httpbin_process = _HTTPBinProcess(https=True)\n\n    @inlineCallbacks\n    def setUp(self):\n        description = yield self._httpbin_process.server_description(\n            reactor)\n        self.baseurl = URL(scheme=u\"https\",\n                           host=description.host,\n                           port=description.port).asText()\n\n        root = trustRootFromCertificates(\n            [Certificate.loadPEM(description.cacert)],\n        )\n        self.agent = Agent(\n            reactor,\n            contextFactory=BrowserLikePolicyForHTTPS(root),\n        )\n\n        self.pool = HTTPConnectionPool(reactor, False)\n", "patch": "@@ -29,6 +29,7 @@ def print_response(response):\n         print('---')\n         print(response.code)\n         print(response.headers)\n+        print(response.request.headers)\n         text = yield treq.text_content(response)\n         print(text)\n         print('---')", "file_path": "files/2022_2/1006", "file_language": "py", "file_name": "src/treq/test/test_treq_integration.py", "outdated_file_modify": 0, "outdated_file_before": 0, "outdated_file_after": 0, "llm_check": 0, "static_check": 0, "static": {"rats": [false, []], "semgrep": [false, []]}, "target": 0, "function_before": [{"function": "def with_baseurl(method):\n    def _request(self, url, *args, **kwargs):\n        return method(self.baseurl + url,\n                      *args,\n                      agent=self.agent,\n                      pool=self.pool,\n                      **kwargs)\n\n    return _request", "target": 0}, {"function": "class TreqIntegrationTests(TestCase):\n    get = with_baseurl(treq.get)\n    head = with_baseurl(treq.head)\n    post = with_baseurl(treq.post)\n    put = with_baseurl(treq.put)\n    patch = with_baseurl(treq.patch)\n    delete = with_baseurl(treq.delete)\n\n    _httpbin_process = _HTTPBinProcess(https=False)\n\n    @inlineCallbacks\n    def setUp(self):\n        description = yield self._httpbin_process.server_description(\n            reactor)\n        self.baseurl = URL(scheme=u\"http\",\n                           host=description.host,\n                           port=description.port).asText()\n        self.agent = Agent(reactor)\n        self.pool = HTTPConnectionPool(reactor, False)\n\n    def tearDown(self):\n        def _check_fds(_):\n            # This appears to only be necessary for HTTPS tests.\n            # For the normal HTTP tests then closeCachedConnections is\n            # sufficient.\n            fds = set(reactor.getReaders() + reactor.getReaders())\n            if not [fd for fd in fds if isinstance(fd, Client)]:\n                return\n\n            return deferLater(reactor, 0, _check_fds, None)\n\n        return self.pool.closeCachedConnections().addBoth(_check_fds)\n\n    @inlineCallbacks\n    def assert_data(self, response, expected_data):\n        body = yield treq.json_content(response)\n        self.assertIn('data', body)\n        self.assertEqual(body['data'], expected_data)\n\n    @inlineCallbacks\n    def assert_sent_header(self, response, header, expected_value):\n        body = yield treq.json_content(response)\n        self.assertIn(header, body['headers'])\n        self.assertEqual(body['headers'][header], expected_value)\n\n    @inlineCallbacks\n    def test_get(self):\n        response = yield self.get('/get')\n        self.assertEqual(response.code, 200)\n        yield print_response(response)\n\n    @inlineCallbacks\n    def test_get_headers(self):\n        response = yield self.get('/get', {b'X-Blah': [b'Foo', b'Bar']})\n        self.assertEqual(response.code, 200)\n        yield self.assert_sent_header(response, 'X-Blah', 'Foo,Bar')\n        yield print_response(response)\n\n    @inlineCallbacks\n    def test_get_headers_unicode(self):\n        response = yield self.get('/get', {u'X-Blah': [u'Foo', b'Bar']})\n        self.assertEqual(response.code, 200)\n        yield self.assert_sent_header(response, 'X-Blah', 'Foo,Bar')\n        yield print_response(response)\n\n    @inlineCallbacks\n    def test_get_302_absolute_redirect(self):\n        response = yield self.get(\n            '/redirect-to?url={0}/get'.format(self.baseurl))\n        self.assertEqual(response.code, 200)\n        yield print_response(response)\n\n    @inlineCallbacks\n    def test_get_302_relative_redirect(self):\n        response = yield self.get('/relative-redirect/1')\n        self.assertEqual(response.code, 200)\n        yield print_response(response)\n\n    @inlineCallbacks\n    def test_get_302_redirect_disallowed(self):\n        response = yield self.get('/redirect/1', allow_redirects=False)\n        self.assertEqual(response.code, 302)\n        yield print_response(response)\n\n    @inlineCallbacks\n    def test_head(self):\n        response = yield self.head('/get')\n        body = yield treq.content(response)\n        self.assertEqual(b'', body)\n        yield print_response(response)\n\n    @inlineCallbacks\n    def test_head_302_absolute_redirect(self):\n        response = yield self.head(\n            '/redirect-to?url={0}/get'.format(self.baseurl))\n        self.assertEqual(response.code, 200)\n        yield print_response(response)\n\n    @inlineCallbacks\n    def test_head_302_relative_redirect(self):\n        response = yield self.head('/relative-redirect/1')\n        self.assertEqual(response.code, 200)\n        yield print_response(response)\n\n    @inlineCallbacks\n    def test_head_302_redirect_disallowed(self):\n        response = yield self.head('/redirect/1', allow_redirects=False)\n        self.assertEqual(response.code, 302)\n        yield print_response(response)\n\n    @inlineCallbacks\n    def test_post(self):\n        response = yield self.post('/post', b'Hello!')\n        self.assertEqual(response.code, 200)\n        yield self.assert_data(response, 'Hello!')\n        yield print_response(response)\n\n    @inlineCallbacks\n    def test_multipart_post(self):\n        class FileLikeObject(BytesIO):\n            def __init__(self, val):\n                BytesIO.__init__(self, val)\n                self.name = \"david.png\"\n\n            def read(*args, **kwargs):\n                return BytesIO.read(*args, **kwargs)\n\n        response = yield self.post(\n            '/post',\n            data={\"a\": \"b\"},\n            files={\"file1\": FileLikeObject(b\"file\")})\n        self.assertEqual(response.code, 200)\n\n        body = yield treq.json_content(response)\n        self.assertEqual('b', body['form']['a'])\n        self.assertEqual('file', body['files']['file1'])\n        yield print_response(response)\n\n    @inlineCallbacks\n    def test_post_headers(self):\n        response = yield self.post(\n            '/post',\n            b'{msg: \"Hello!\"}',\n            headers={'Content-Type': ['application/json']}\n        )\n\n        self.assertEqual(response.code, 200)\n        yield self.assert_sent_header(\n            response, 'Content-Type', 'application/json')\n        yield self.assert_data(response, '{msg: \"Hello!\"}')\n        yield print_response(response)\n\n    @inlineCallbacks\n    def test_put(self):\n        response = yield self.put('/put', data=b'Hello!')\n        yield print_response(response)\n\n    @inlineCallbacks\n    def test_patch(self):\n        response = yield self.patch('/patch', data=b'Hello!')\n        self.assertEqual(response.code, 200)\n        yield self.assert_data(response, 'Hello!')\n        yield print_response(response)\n\n    @inlineCallbacks\n    def test_delete(self):\n        response = yield self.delete('/delete')\n        self.assertEqual(response.code, 200)\n        yield print_response(response)\n\n    @inlineCallbacks\n    def test_gzip(self):\n        response = yield self.get('/gzip')\n        self.assertEqual(response.code, 200)\n        yield print_response(response)\n        json = yield treq.json_content(response)\n        self.assertTrue(json['gzipped'])\n\n    @inlineCallbacks\n    def test_basic_auth(self):\n        response = yield self.get('/basic-auth/treq/treq',\n                                  auth=('treq', 'treq'))\n        self.assertEqual(response.code, 200)\n        yield print_response(response)\n        json = yield treq.json_content(response)\n        self.assertTrue(json['authenticated'])\n        self.assertEqual(json['user'], 'treq')\n\n    @inlineCallbacks\n    def test_failed_basic_auth(self):\n        response = yield self.get('/basic-auth/treq/treq',\n                                  auth=('not-treq', 'not-treq'))\n        self.assertEqual(response.code, 401)\n        yield print_response(response)\n\n    @inlineCallbacks\n    def test_timeout(self):\n        \"\"\"\n        Verify a timeout fires if a request takes too long.\n        \"\"\"\n        yield self.assertFailure(self.get('/delay/2', timeout=1),\n                                 CancelledError,\n                                 ResponseFailed)\n\n    @inlineCallbacks\n    def test_cookie(self):\n        response = yield self.get('/cookies', cookies={'hello': 'there'})\n        self.assertEqual(response.code, 200)\n        yield print_response(response)\n        json = yield treq.json_content(response)\n        self.assertEqual(json['cookies']['hello'], 'there')\n\n    @inlineCallbacks\n    def test_set_cookie(self):\n        response = yield self.get('/cookies/set',\n                                  allow_redirects=False,\n                                  params={'hello': 'there'})\n        # self.assertEqual(response.code, 200)\n        yield print_response(response)\n        self.assertEqual(response.cookies()['hello'], 'there')", "target": 0}, {"function": "class HTTPSTreqIntegrationTests(TreqIntegrationTests):\n    _httpbin_process = _HTTPBinProcess(https=True)\n\n    @inlineCallbacks\n    def setUp(self):\n        description = yield self._httpbin_process.server_description(\n            reactor)\n        self.baseurl = URL(scheme=u\"https\",\n                           host=description.host,\n                           port=description.port).asText()\n\n        root = trustRootFromCertificates(\n            [Certificate.loadPEM(description.cacert)],\n        )\n        self.agent = Agent(\n            reactor,\n            contextFactory=BrowserLikePolicyForHTTPS(root),\n        )\n\n        self.pool = HTTPConnectionPool(reactor, False)", "target": 0}], "function_after": [{"function": "def with_baseurl(method):\n    def _request(self, url, *args, **kwargs):\n        return method(self.baseurl + url,\n                      *args,\n                      agent=self.agent,\n                      pool=self.pool,\n                      **kwargs)\n\n    return _request", "target": 0}, {"function": "class TreqIntegrationTests(TestCase):\n    get = with_baseurl(treq.get)\n    head = with_baseurl(treq.head)\n    post = with_baseurl(treq.post)\n    put = with_baseurl(treq.put)\n    patch = with_baseurl(treq.patch)\n    delete = with_baseurl(treq.delete)\n\n    _httpbin_process = _HTTPBinProcess(https=False)\n\n    @inlineCallbacks\n    def setUp(self):\n        description = yield self._httpbin_process.server_description(\n            reactor)\n        self.baseurl = URL(scheme=u\"http\",\n                           host=description.host,\n                           port=description.port).asText()\n        self.agent = Agent(reactor)\n        self.pool = HTTPConnectionPool(reactor, False)\n\n    def tearDown(self):\n        def _check_fds(_):\n            # This appears to only be necessary for HTTPS tests.\n            # For the normal HTTP tests then closeCachedConnections is\n            # sufficient.\n            fds = set(reactor.getReaders() + reactor.getReaders())\n            if not [fd for fd in fds if isinstance(fd, Client)]:\n                return\n\n            return deferLater(reactor, 0, _check_fds, None)\n\n        return self.pool.closeCachedConnections().addBoth(_check_fds)\n\n    @inlineCallbacks\n    def assert_data(self, response, expected_data):\n        body = yield treq.json_content(response)\n        self.assertIn('data', body)\n        self.assertEqual(body['data'], expected_data)\n\n    @inlineCallbacks\n    def assert_sent_header(self, response, header, expected_value):\n        body = yield treq.json_content(response)\n        self.assertIn(header, body['headers'])\n        self.assertEqual(body['headers'][header], expected_value)\n\n    @inlineCallbacks\n    def test_get(self):\n        response = yield self.get('/get')\n        self.assertEqual(response.code, 200)\n        yield print_response(response)\n\n    @inlineCallbacks\n    def test_get_headers(self):\n        response = yield self.get('/get', {b'X-Blah': [b'Foo', b'Bar']})\n        self.assertEqual(response.code, 200)\n        yield self.assert_sent_header(response, 'X-Blah', 'Foo,Bar')\n        yield print_response(response)\n\n    @inlineCallbacks\n    def test_get_headers_unicode(self):\n        response = yield self.get('/get', {u'X-Blah': [u'Foo', b'Bar']})\n        self.assertEqual(response.code, 200)\n        yield self.assert_sent_header(response, 'X-Blah', 'Foo,Bar')\n        yield print_response(response)\n\n    @inlineCallbacks\n    def test_get_302_absolute_redirect(self):\n        response = yield self.get(\n            '/redirect-to?url={0}/get'.format(self.baseurl))\n        self.assertEqual(response.code, 200)\n        yield print_response(response)\n\n    @inlineCallbacks\n    def test_get_302_relative_redirect(self):\n        response = yield self.get('/relative-redirect/1')\n        self.assertEqual(response.code, 200)\n        yield print_response(response)\n\n    @inlineCallbacks\n    def test_get_302_redirect_disallowed(self):\n        response = yield self.get('/redirect/1', allow_redirects=False)\n        self.assertEqual(response.code, 302)\n        yield print_response(response)\n\n    @inlineCallbacks\n    def test_head(self):\n        response = yield self.head('/get')\n        body = yield treq.content(response)\n        self.assertEqual(b'', body)\n        yield print_response(response)\n\n    @inlineCallbacks\n    def test_head_302_absolute_redirect(self):\n        response = yield self.head(\n            '/redirect-to?url={0}/get'.format(self.baseurl))\n        self.assertEqual(response.code, 200)\n        yield print_response(response)\n\n    @inlineCallbacks\n    def test_head_302_relative_redirect(self):\n        response = yield self.head('/relative-redirect/1')\n        self.assertEqual(response.code, 200)\n        yield print_response(response)\n\n    @inlineCallbacks\n    def test_head_302_redirect_disallowed(self):\n        response = yield self.head('/redirect/1', allow_redirects=False)\n        self.assertEqual(response.code, 302)\n        yield print_response(response)\n\n    @inlineCallbacks\n    def test_post(self):\n        response = yield self.post('/post', b'Hello!')\n        self.assertEqual(response.code, 200)\n        yield self.assert_data(response, 'Hello!')\n        yield print_response(response)\n\n    @inlineCallbacks\n    def test_multipart_post(self):\n        class FileLikeObject(BytesIO):\n            def __init__(self, val):\n                BytesIO.__init__(self, val)\n                self.name = \"david.png\"\n\n            def read(*args, **kwargs):\n                return BytesIO.read(*args, **kwargs)\n\n        response = yield self.post(\n            '/post',\n            data={\"a\": \"b\"},\n            files={\"file1\": FileLikeObject(b\"file\")})\n        self.assertEqual(response.code, 200)\n\n        body = yield treq.json_content(response)\n        self.assertEqual('b', body['form']['a'])\n        self.assertEqual('file', body['files']['file1'])\n        yield print_response(response)\n\n    @inlineCallbacks\n    def test_post_headers(self):\n        response = yield self.post(\n            '/post',\n            b'{msg: \"Hello!\"}',\n            headers={'Content-Type': ['application/json']}\n        )\n\n        self.assertEqual(response.code, 200)\n        yield self.assert_sent_header(\n            response, 'Content-Type', 'application/json')\n        yield self.assert_data(response, '{msg: \"Hello!\"}')\n        yield print_response(response)\n\n    @inlineCallbacks\n    def test_put(self):\n        response = yield self.put('/put', data=b'Hello!')\n        yield print_response(response)\n\n    @inlineCallbacks\n    def test_patch(self):\n        response = yield self.patch('/patch', data=b'Hello!')\n        self.assertEqual(response.code, 200)\n        yield self.assert_data(response, 'Hello!')\n        yield print_response(response)\n\n    @inlineCallbacks\n    def test_delete(self):\n        response = yield self.delete('/delete')\n        self.assertEqual(response.code, 200)\n        yield print_response(response)\n\n    @inlineCallbacks\n    def test_gzip(self):\n        response = yield self.get('/gzip')\n        self.assertEqual(response.code, 200)\n        yield print_response(response)\n        json = yield treq.json_content(response)\n        self.assertTrue(json['gzipped'])\n\n    @inlineCallbacks\n    def test_basic_auth(self):\n        response = yield self.get('/basic-auth/treq/treq',\n                                  auth=('treq', 'treq'))\n        self.assertEqual(response.code, 200)\n        yield print_response(response)\n        json = yield treq.json_content(response)\n        self.assertTrue(json['authenticated'])\n        self.assertEqual(json['user'], 'treq')\n\n    @inlineCallbacks\n    def test_failed_basic_auth(self):\n        response = yield self.get('/basic-auth/treq/treq',\n                                  auth=('not-treq', 'not-treq'))\n        self.assertEqual(response.code, 401)\n        yield print_response(response)\n\n    @inlineCallbacks\n    def test_timeout(self):\n        \"\"\"\n        Verify a timeout fires if a request takes too long.\n        \"\"\"\n        yield self.assertFailure(self.get('/delay/2', timeout=1),\n                                 CancelledError,\n                                 ResponseFailed)\n\n    @inlineCallbacks\n    def test_cookie(self):\n        response = yield self.get('/cookies', cookies={'hello': 'there'})\n        self.assertEqual(response.code, 200)\n        yield print_response(response)\n        json = yield treq.json_content(response)\n        self.assertEqual(json['cookies']['hello'], 'there')\n\n    @inlineCallbacks\n    def test_set_cookie(self):\n        response = yield self.get('/cookies/set',\n                                  allow_redirects=False,\n                                  params={'hello': 'there'})\n        # self.assertEqual(response.code, 200)\n        yield print_response(response)\n        self.assertEqual(response.cookies()['hello'], 'there')", "target": 0}, {"function": "class HTTPSTreqIntegrationTests(TreqIntegrationTests):\n    _httpbin_process = _HTTPBinProcess(https=True)\n\n    @inlineCallbacks\n    def setUp(self):\n        description = yield self._httpbin_process.server_description(\n            reactor)\n        self.baseurl = URL(scheme=u\"https\",\n                           host=description.host,\n                           port=description.port).asText()\n\n        root = trustRootFromCertificates(\n            [Certificate.loadPEM(description.cacert)],\n        )\n        self.agent = Agent(\n            reactor,\n            contextFactory=BrowserLikePolicyForHTTPS(root),\n        )\n\n        self.pool = HTTPConnectionPool(reactor, False)", "target": 0}]}], "outdated": 0, "cwe_descripiton": "", "cwe_consequence": "", "cwe_method": "", "cwe_solution": ""}
