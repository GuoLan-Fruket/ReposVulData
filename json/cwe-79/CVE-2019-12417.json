{"index": 3928, "cve_id": "CVE-2019-12417", "cwe_id": ["CWE-79"], "cve_language": "Python", "cve_description": "A malicious admin user could edit the state of objects in the Airflow metadata database to execute arbitrary javascript on certain page views. This also presented a Local File Disclosure vulnerability to any file readable by the webserver process.", "cvss": "4.8", "publish_date": "October 30, 2019", "AV": "NETWORK", "AC": "NETWORK", "PR": "HIGH", "UI": "REQUIRED", "S": "CHANGED", "C": "LOW", "I": "LOW", "A": "NONE", "commit_id": "c082065f3be07e1c5f39bb86e2b4a06413238631", "commit_message": "[AIRFLOW-5634] Don't allow editing of DagModelView (#6308)\n\nMost/all of these fields are not fur user editing, with the exception of\r\nPause which is set in other ways, and if a user edits these it will just\r\nconfuse the system.\r\n\r\nSo lets disable the FAB edit form.\r\n\r\n(Not to mention that the form was broken because it didn't accept the\r\nlast_scheduler_run as filled out.)", "commit_date": "2019-10-14T11:40:45Z", "project": "apache/airflow", "url": "https://api.github.com/repos/apache/airflow/commits/c082065f3be07e1c5f39bb86e2b4a06413238631", "html_url": "https://github.com/apache/airflow/commit/c082065f3be07e1c5f39bb86e2b4a06413238631", "windows_before": [{"commit_id": "0a99aad6c282aebcc178326a2e0cd41f67d8cd52", "commit_date": "Mon Oct 14 12:23:52 2019 +0200", "commit_message": "[AIRFLOW-XXX] Fixed case problem with CONTRIBUTING.rst (#6329)", "files_name": ["CONTRIBUTING.md"]}, {"commit_id": "ab34610ae7b48f910ab55d304e776aa801daf1f3", "commit_date": "Mon Oct 14 11:27:50 2019 +0200", "commit_message": "[AIRFLOW-5652] Add provider package to lint rules (#6326)", "files_name": ["docs/build.sh"]}, {"commit_id": "8cbfd930599aa437c7ffb06301ad24c8eddb280a", "commit_date": "Mon Oct 14 11:16:37 2019 +0200", "commit_message": "[AIRFLOW-4661] Make airflow/config_templates Pylint compatible (#6300)", "files_name": ["airflow/config_templates/airflow_local_settings.py", "scripts/ci/pylint_todo.txt"]}, {"commit_id": "3ed7b32775cf8328836cfb36af8e65cab01e221b", "commit_date": "Mon Oct 14 11:00:44 2019 +0200", "commit_message": "[AIRFLOW-3783] Speed up Redshift to S3 UNload with HEADERs (#6309)", "files_name": ["airflow/operators/redshift_to_s3_operator.py", "scripts/ci/pylint_todo.txt", "tests/operators/test_redshift_to_s3_operator.py"]}, {"commit_id": "55facada631b826440ed8c8c77f6408d12c91021", "commit_date": "Mon Oct 14 10:47:56 2019 +0200", "commit_message": "[AIRFLOW-5651] Replace GCP depreccated imports (#6325)", "files_name": ["airflow/gcp/operators/kubernetes_engine.py", "airflow/operators/gcs_to_s3.py"]}, {"commit_id": "c935023739864182886593e00ffe7c7105129e88", "commit_date": "Mon Oct 14 01:47:22 2019 -0700", "commit_message": "[AIRFLOW-5650] remove githubhandle (#6328)", "files_name": ["README.md"]}, {"commit_id": "13acdd1039d7e40a77ca2505f61fe3fb915a4bab", "commit_date": "Mon Oct 14 10:46:02 2019 +0200", "commit_message": "[AIRFLOW-5626] Add labels to MLEngine resources (#6296)", "files_name": ["airflow/gcp/hooks/mlengine.py", "tests/gcp/hooks/test_mlengine.py"]}, {"commit_id": "10d39eff25657c78c2e4d99eb8f4a4779938b5c8", "commit_date": "Sun Oct 13 22:20:31 2019 +0200", "commit_message": "[AIRFLOW-XXXX] Google Season of Docs updates to CONTRIBUTING doc (#6283)", "files_name": ["CONTRIBUTING.md", "CONTRIBUTING.rst", "README.md", "dev/README.md", "scripts/ci/in_container/_in_container_utils.sh"]}, {"commit_id": "10b61e430169875f52968a13f7849f0643e4f76f", "commit_date": "Sun Oct 13 12:44:48 2019 -0700", "commit_message": "[AIRFLOW-5650] Add GSN Games into airflow users in README.md (#6323)", "files_name": ["README.md"]}, {"commit_id": "51f8bbce854117fc12a01c0d922df44d3b696418", "commit_date": "Sun Oct 13 17:57:56 2019 +0200", "commit_message": "[AIRFLOW-5630] Improve BigQueryGetDataOperator to handle no rows (#6298)", "files_name": ["airflow/gcp/operators/bigquery.py"]}, {"commit_id": "dfcf489afcfbd69abda91999fc9d9526023de4b5", "commit_date": "Sun Oct 13 14:43:01 2019 +0200", "commit_message": "[AIRFLOW-XXX] Fix typo - AWS DynamoDB Hook (#6319)", "files_name": ["airflow/contrib/hooks/aws_dynamodb_hook.py"]}, {"commit_id": "9c74ecbb9308edb149a93141c04b2c051214185c", "commit_date": "Sun Oct 13 11:57:22 2019 +0200", "commit_message": "[AIRFLOW-5625] Update MLEngine integration doc and typehint (#6293)", "files_name": ["airflow/gcp/hooks/cloud_build.py", "airflow/gcp/hooks/mlengine.py", "airflow/gcp/operators/mlengine.py"]}, {"commit_id": "c0d98a72394b68df27db4d1cab4a94021980e0fb", "commit_date": "Fri Oct 11 16:02:30 2019 +0200", "commit_message": "[AIRFLOW-5624] Use mock decorator in MLEngine operators tests (#6292)", "files_name": ["tests/gcp/operators/test_mlengine.py"]}, {"commit_id": "ec3cc2dc76f48a6c8dc3e1db127164113dd5e807", "commit_date": "Fri Oct 11 15:15:32 2019 +0200", "commit_message": "[AIRFLOW-4970] Add Google Campaign Manager integration (#6169)", "files_name": ["airflow/gcp/operators/bigquery.py", "airflow/provider/__init__.py", "airflow/provider/google/__init__.py", "airflow/provider/google/marketing_platform/__init__.py", "airflow/provider/google/marketing_platform/example_dags/__init__.py", "airflow/provider/google/marketing_platform/example_dags/example_campaign_manager.py", "airflow/provider/google/marketing_platform/hooks/__init__.py", "airflow/provider/google/marketing_platform/hooks/campaign_manager.py", "airflow/provider/google/marketing_platform/operators/__init__.py", "airflow/provider/google/marketing_platform/operators/campaign_manager.py", "airflow/provider/google/marketing_platform/sensors/__init__.py", "airflow/provider/google/marketing_platform/sensors/campaign_manager.py", "docs/autoapi_templates/index.rst", "docs/conf.py", "docs/howto/operator/gcp/campaign_manager.rst", "docs/operators-and-hooks-ref.rst", "tests/gcp/utils/gcp_authenticator.py", "tests/provider/__init__.py", "tests/provider/google/__init__.py", "tests/provider/google/marketing_platform/__init__.py", "tests/provider/google/marketing_platform/hooks/__init__.py", "tests/provider/google/marketing_platform/hooks/test_campaign_manager.py", "tests/provider/google/marketing_platform/operators/__init__.py", "tests/provider/google/marketing_platform/operators/test_campaign_manager.py", "tests/provider/google/marketing_platform/operators/test_campaign_manager_system.py", "tests/provider/google/marketing_platform/operators/test_campaign_manager_system_helper.py", "tests/provider/google/marketing_platform/sensors/__init__.py", "tests/provider/google/marketing_platform/sensors/test_campaign_manager.py"]}, {"commit_id": "12f916a432e7937f6f72d1b556196e863920f334", "commit_date": "Fri Oct 11 07:06:26 2019 -0400", "commit_message": "[AIRFLOW-5581] Cleanly shutdown KubernetesJobWatcher for safe Scheduler shutdown on SIGTERM (#6237)", "files_name": ["airflow/executors/kubernetes_executor.py"]}, {"commit_id": "c7a5f1fc912c8d2a6b143e2356d14107c8c2c4bf", "commit_date": "Fri Oct 11 11:15:33 2019 +0200", "commit_message": "[AIRFLOW-5584] Initialise hook in execute in Cloud SQL operators (#6236)", "files_name": ["airflow/gcp/operators/cloud_sql.py", "tests/gcp/hooks/test_cloud_sql.py", "tests/gcp/operators/test_cloud_sql.py"]}, {"commit_id": "568d8049a8ab2c54d4d9d528ff0f07df45b2fa83", "commit_date": "Fri Oct 11 09:39:04 2019 +0100", "commit_message": "[AIRFLOW-XXX] Fix Documentation for adding extra Operator Links (#6301)", "files_name": ["docs/howto/define_extra_link.rst"]}, {"commit_id": "7c9b44dbfc72df951aadbda006229977beb6d47c", "commit_date": "Thu Oct 10 08:11:34 2019 -0400", "commit_message": "AIRFLOW-5608: Gracefully stop executor when SIGTERM is received by SchedulerJib (#6274)", "files_name": ["airflow/jobs/scheduler_job.py"]}, {"commit_id": "0261ed755b88b3787ed9dd43e63a4e9ae87acada", "commit_date": "Thu Oct 10 08:16:09 2019 +0200", "commit_message": "[AIRFLOW-5617] Add fallback for connection's project id in MLEngine hook (#6286)", "files_name": ["UPDATING.md", "airflow/gcp/hooks/mlengine.py", "airflow/gcp/operators/mlengine.py", "tests/gcp/hooks/test_mlengine.py", "tests/gcp/operators/test_mlengine.py", "tests/gcp/operators/test_mlengine_utils.py", "tests/gcp/utils/base_gcp_mock.py"]}, {"commit_id": "032200a4957724f94abf02198edf0c8448a27278", "commit_date": "Thu Oct 10 04:07:53 2019 +0200", "commit_message": "[AIRFLOW-5622] Improve creating directories in SFTPHook (#6287)", "files_name": ["airflow/contrib/hooks/sftp_hook.py", "tests/contrib/hooks/test_sftp_hook.py"]}, {"commit_id": "8097006468f5a5928612a3277d6f18b6a28fd51a", "commit_date": "Wed Oct 9 19:52:50 2019 +0200", "commit_message": "[AIRFLOW-5588] Add Celery's architecture diagram (#6247)", "files_name": ["Dockerfile", "docs/conf.py", "docs/executor/celery.rst"]}, {"commit_id": "00ef8cb92857fa2837112b6480a4a7c152073099", "commit_date": "Wed Oct 9 15:23:12 2019 +0200", "commit_message": "[AIRFLOW-4660] Make airflow/bin Pylint compatible (#6294)", "files_name": ["airflow/bin/airflow", "airflow/bin/cli.py", "scripts/ci/pylint_todo.txt", "tests/cli/test_cli.py"]}, {"commit_id": "31db280fef27bd60c2da39a2e9b8d5448da82f4f", "commit_date": "Wed Oct 9 14:18:51 2019 +0200", "commit_message": "[AIRFLOW-5614] Enable Fernet by default (#6282)", "files_name": ["UPDATING.md", "airflow/configuration.py", "airflow/models/crypto.py", "airflow/models/variable.py", "docs/faq.rst", "docs/howto/connection/gcp.rst", "docs/howto/index.rst", "docs/howto/secure-connections.rst", "docs/installation.rst", "docs/security.rst", "setup.py"]}, {"commit_id": "319b5251d8ce14a6907a5ed5c9703b5ecd730846", "commit_date": "Wed Oct 9 11:04:30 2019 +0200", "commit_message": "[AIRFLOW-5609] Add MLEngine models operators (#6279)", "files_name": ["airflow/gcp/example_dags/example_mlengine.py", "airflow/gcp/hooks/mlengine.py", "airflow/gcp/operators/mlengine.py", "tests/gcp/hooks/test_mlengine.py", "tests/gcp/operators/test_mlengine.py"]}, {"commit_id": "824f264ed3f82c66e8e78640da76501159d722e0", "commit_date": "Wed Oct 9 00:09:43 2019 -0700", "commit_message": "[AIRFLOW-XXX] Typo in FAQ - schedule_interval (#6291)", "files_name": ["docs/faq.rst"]}, {"commit_id": "ca24fdf114de82d93da41a5eea967b41ef6586b5", "commit_date": "Wed Oct 9 07:29:29 2019 +0200", "commit_message": "[AIRFLOW-5572] Clear task reschedules when clearing task instances (#6217)", "files_name": ["airflow/models/taskinstance.py", "tests/models/test_taskinstance.py"]}, {"commit_id": "c62b292a9a9c6f7ecac8f7c43c6969b14766ee1f", "commit_date": "Wed Oct 9 10:58:17 2019 +0530", "commit_message": "Passing job location when initializing the operator (#6258)", "files_name": ["airflow/operators/gcs_to_bq.py"]}, {"commit_id": "55bb579a135f37d651cedf8f208c98baa6e78217", "commit_date": "Tue Oct 8 11:35:37 2019 -0700", "commit_message": "[AIRFLOW-5597] Linkify urls in task instance log (#6265)", "files_name": ["airflow/www/templates/airflow/ti_log.html"]}, {"commit_id": "68b8ec5f415795e4fa4ff7df35a3e75c712a7bad", "commit_date": "Tue Oct 8 17:00:15 2019 +0100", "commit_message": "[AIRFLOW-5102] Worker jobs should terminate themselves if they can't heartbeat (#6284)", "files_name": ["airflow/jobs/base_job.py", "airflow/jobs/local_task_job.py", "tests/jobs/test_base_job.py", "tests/jobs/test_local_task_job.py"]}, {"commit_id": "93bb5e44d8ede09d3301f29de15121901ba010f4", "commit_date": "Tue Oct 8 17:54:36 2019 +0200", "commit_message": "[AIRFLOW-5387] Fix show paused pagination bug (#6100)", "files_name": ["airflow/www/utils.py", "tests/www/test_utils.py"]}, {"commit_id": "ec8dd34af8deacaf456fcb6e0e866941437ed383", "commit_date": "Tue Oct 8 17:00:03 2019 +0200", "commit_message": "[AIRFLOW-XXX] Fix heading levels (#6275)", "files_name": ["docs/operators-and-hooks-ref.rst"]}, {"commit_id": "0d71f335561800f117be41c575b20770f2345d50", "commit_date": "Tue Oct 8 05:40:03 2019 +0200", "commit_message": "[AIRFLOW-5603] Add MLEngine version operators (#6271)", "files_name": ["airflow/gcp/example_dags/example_mlengine.py", "airflow/gcp/operators/mlengine.py", "tests/gcp/operators/test_mlengine.py"]}, {"commit_id": "4e245149e4dc8d9be5aa17afec2e00e858a6484e", "commit_date": "Tue Oct 8 05:17:31 2019 +0200", "commit_message": "[AIRFLOW-XXX] Fix extra-packages tables (#6280)", "files_name": ["docs/installation.rst"]}, {"commit_id": "df5fbcb5160f9ad985ce0361941ad15ab91e930f", "commit_date": "Tue Oct 8 00:15:20 2019 +0100", "commit_message": "[AIRFLOW-XXX] Fix missing backtick in Breeze.rst (#6278)", "files_name": ["BREEZE.rst"]}, {"commit_id": "d4ff0d73443718748e098ae4c323d864bdd55ab1", "commit_date": "Tue Oct 8 00:02:02 2019 +0200", "commit_message": "[AIRFLOW-XXX] Split extra packages table in multiple (#6257)", "files_name": ["docs/installation.rst"]}, {"commit_id": "b2dc1636855dcd3ad6957745e5426cd4f5f10c70", "commit_date": "Mon Oct 7 21:04:51 2019 +0200", "commit_message": "[AIRFLOW-5602] Use unittest.mock in MLEngine hook tests (#6268)", "files_name": ["tests/gcp/hooks/test_mlengine.py"]}, {"commit_id": "1347b77970b86503adc1f9b54f766c4dce89bc59", "commit_date": "Mon Oct 7 17:30:29 2019 +0200", "commit_message": "[AIRFLOW-5600] Add MLEngine system tests (#6264)", "files_name": ["airflow/gcp/example_dags/example_mlengine.py", "tests/gcp/operators/test_mlengine_system.py", "tests/gcp/operators/test_mlengine_system_helper.py"]}, {"commit_id": "0f0a7911ec9457373fca971a4059884fde2e9e5e", "commit_date": "Mon Oct 7 16:33:33 2019 +0200", "commit_message": "[AIRFLOW-5601] Use built-in pagination mechanism in MLEngine hook (#6267)", "files_name": ["airflow/gcp/hooks/mlengine.py", "tests/gcp/hooks/test_mlengine.py"]}, {"commit_id": "965c902cdbac74862b6140f251561a69e140412b", "commit_date": "Mon Oct 7 14:57:22 2019 +0200", "commit_message": "[AIRFLOW-5580] Add base class for system test (#6229)", "files_name": ["tests/test_example_dags_system.py", "tests/test_utils/system_tests_class.py"]}, {"commit_id": "41d6ca56f0179384470f48cc652dda17f49fef82", "commit_date": "Mon Oct 7 14:30:22 2019 +0200", "commit_message": "[AIRFLOW-5598] Improve MLEngine typehint (#6263)", "files_name": ["airflow/gcp/operators/mlengine.py"]}], "windows_after": [{"commit_id": "1a4c16432b8718189269e63c3afcd2709eed7379", "commit_date": "Tue Oct 15 00:05:28 2019 +0530", "commit_message": "[AIRFLOW-5653] Log caught AirflowSkipException in task instance log (#6330)", "files_name": ["airflow/models/taskinstance.py"]}, {"commit_id": "bb93a7551e4f5ea88c18aebc95f69869892b690a", "commit_date": "Mon Oct 14 22:51:04 2019 +0200", "commit_message": "[AIRFLOW-5497] Update docstring in airflow/utils/dag_processing.py (#6314)", "files_name": ["airflow/utils/dag_processing.py"]}, {"commit_id": "897960736eeafa03f18297fc113f2c321be3bcb5", "commit_date": "Sat Aug 24 09:53:26 2019 -0700", "commit_message": "Revert \"[AIRFLOW-4797] Improve performance and behaviour of zombie detection (#5511)\"", "files_name": ["airflow/jobs/scheduler_job.py", "airflow/models/dagbag.py", "airflow/utils/dag_processing.py", "tests/models/test_dagbag.py", "tests/utils/test_dag_processing.py"]}, {"commit_id": "cb0dbe309b518813529ddf7545ae942e5767f5e5", "commit_date": "Sat Sep 7 01:51:15 2019 -0700", "commit_message": "[AIRFLOW-4797] Use same zombies in all DAG file processors", "files_name": ["airflow/models/dagbag.py", "airflow/utils/dag_processing.py", "tests/models/test_dagbag.py", "tests/utils/test_dag_processing.py"]}, {"commit_id": "e62056b2254e1447e20179f8d2911a93462cddc5", "commit_date": "Tue Oct 15 21:56:09 2019 +1100", "commit_message": "[AIRFLOW-5223] Use kind for Kubernetes in CI (#5837)", "files_name": [".pre-commit-config.yaml", ".travis.yml", "Dockerfile", "scripts/ci/ci_before_install.sh", "scripts/ci/ci_run_airflow_testing.sh", "scripts/ci/docker-compose.yml", "scripts/ci/in_container/entrypoint_ci.sh", "scripts/ci/kubernetes/README.md", "scripts/ci/kubernetes/app/deploy_app.sh", "scripts/ci/kubernetes/app/postgres.yaml", "scripts/ci/kubernetes/app/secrets.yaml", "scripts/ci/kubernetes/app/templates/airflow.template.yaml", "scripts/ci/kubernetes/app/templates/configmaps.template.yaml", "scripts/ci/kubernetes/app/templates/init_git_sync.template.yaml", "scripts/ci/kubernetes/app/volumes.yaml", "scripts/ci/kubernetes/docker/Dockerfile", "scripts/ci/kubernetes/docker/airflow-test-env-init.sh", "scripts/ci/kubernetes/docker/build.sh", "scripts/ci/kubernetes/kind-cluster-conf.yaml", "scripts/ci/kubernetes/minikube/_k8s.sh", "scripts/ci/kubernetes/minikube/start_minikube.sh", "scripts/ci/kubernetes/minikube/stop_minikube.sh", "scripts/ci/kubernetes/setup_kubernetes.sh", "scripts/ci/local_ci_stop_environment.sh", "tests/integration/__init__.py", "tests/integration/kubernetes/__init__.py", "tests/integration/kubernetes/test_kubernetes_executor.py", "tests/integration/kubernetes/test_kubernetes_pod_operator.py"]}, {"commit_id": "133085eb47e04683ce3dca52b967aa41f8139613", "commit_date": "Tue Oct 15 03:58:31 2019 -0700", "commit_message": "[AIRFLOW-5641] Support running git sync container as root (#6312)", "files_name": ["airflow/executors/kubernetes_executor.py", "airflow/kubernetes/worker_configuration.py", "tests/executors/test_kubernetes_executor.py", "tests/kubernetes/test_worker_configuration.py"]}, {"commit_id": "1de210b8a96b8fff0ef59b1e740c8a08c14b6394", "commit_date": "Tue Oct 15 15:12:45 2019 +0100", "commit_message": "[AIRFLOW-5636] Allow adding or overriding existing Operator Links (#6302)", "files_name": ["airflow/models/baseoperator.py", "airflow/plugins_manager.py", "airflow/utils/tests.py", "docs/howto/define_extra_link.rst", "docs/plugins.rst", "tests/plugins/test_plugin.py", "tests/www/test_views.py"]}, {"commit_id": "76fe5e2cc059f738132550c376e97344d63d6a52", "commit_date": "Tue Oct 15 10:40:56 2019 -0700", "commit_message": "[AIRFLOW-5657] Update the upper bound for dill (#6334)", "files_name": ["setup.py"]}, {"commit_id": "8b0c9cbb555bf6d43bfb901b8c5fda5e2da48031", "commit_date": "Wed Oct 16 05:15:11 2019 +0200", "commit_message": "[AIRFLOW-5224] Add encoding parameter to GoogleCloudStorageToBigQuery\u2026 (#6297)", "files_name": ["airflow/gcp/hooks/bigquery.py", "airflow/operators/gcs_to_bq.py", "tests/gcp/hooks/test_bigquery.py"]}, {"commit_id": "d4e282d9b23f0843ac390f34ec4b0185cd6bddf3", "commit_date": "Wed Oct 16 17:22:07 2019 +0200", "commit_message": "[AIRFLOW-5126] Read aws_session_token in extra_config of the aws hook (#6303)", "files_name": ["airflow/contrib/hooks/aws_hook.py", "docs/howto/connection/aws.rst", "tests/contrib/hooks/test_aws_hook.py"]}, {"commit_id": "ac42428bf530c259ab1b0dca08458c1ebf49b04a", "commit_date": "Wed Oct 16 18:49:59 2019 +0200", "commit_message": "[AIRFLOW-5643] Reduce duplicated logic in S3Hook (#6313)", "files_name": ["airflow/hooks/S3_hook.py"]}, {"commit_id": "f8794d888fcb032fd620a27c1c54312145e9ffb6", "commit_date": "Thu Oct 17 14:54:19 2019 +0200", "commit_message": "[AIRFLOW-5684] docker-compose-kubernetes still used (#6353)", "files_name": ["breeze"]}, {"commit_id": "e35829e472c4f0b014dcbb71d1f35785fef6ca8b", "commit_date": "Thu Oct 17 15:45:39 2019 +0100", "commit_message": "Revert \"AIRFLOW-5608: Gracefully stop executor when SIGTERM is received by SchedulerJib (#6274)\" (#6357)", "files_name": ["airflow/jobs/scheduler_job.py"]}, {"commit_id": "f2b7f5a85aa9cb454836c66614465d7e048820a3", "commit_date": "Thu Oct 17 21:37:51 2019 +0100", "commit_message": "[AIRFLOW-5687] Upgrade pip to 19.0.2 (#6358)", "files_name": ["Dockerfile"]}, {"commit_id": "dde65a609a9de7038670b33cbc9d9d46811f8b1a", "commit_date": "Thu Oct 17 15:49:11 2019 -0700", "commit_message": "[AIRFLOW-XXXX] Include code tags for sample file names (#6360)", "files_name": ["docs/concepts.rst"]}, {"commit_id": "a8babec8086b5eed2c940180ec0a6ddba992b707", "commit_date": "Fri Oct 18 16:46:57 2019 +0900", "commit_message": "[AIRFLOW-5339] Fix infinite wait for Spark subprocess", "files_name": ["airflow/contrib/hooks/spark_sql_hook.py", "airflow/contrib/hooks/spark_submit_hook.py"]}, {"commit_id": "489e7fe9a77404cd8fe168627e5ddcb4b9152e25", "commit_date": "Fri Oct 18 09:45:12 2019 +0100", "commit_message": "[AIRFLOW-5687] Fix Upgrade pip to 19.0.2 in CI build pipeline (#6361)", "files_name": ["Dockerfile"]}, {"commit_id": "10c3f7f0eda199355d32165c148e714459d51c2e", "commit_date": "Fri Oct 18 10:49:58 2019 +0200", "commit_message": "[AIRFLOW-5649] Skips tests when relevant .py files are not changed (#6321)", "files_name": ["scripts/ci/_utils.sh", "scripts/ci/ci_run_airflow_testing.sh", "scripts/ci/ci_run_all_static_tests.sh", "scripts/ci/ci_run_all_static_tests_except_pylint.sh", "scripts/ci/ci_run_all_static_tests_except_pylint_licence.sh", "scripts/ci/ci_run_all_static_tests_pylint.sh"]}, {"commit_id": "0790ede70270ceb8b92f8c8df530361749221053", "commit_date": "Fri Oct 18 02:34:08 2019 -0700", "commit_message": "[AIRFLOW-4574] SSHHook private_key may only be supplied in extras (#6163)", "files_name": ["airflow/contrib/hooks/ssh_hook.py", "tests/contrib/hooks/test_ssh_hook.py"]}, {"commit_id": "7bdc063fa39d11662dcaae281d52e2014b6dfaaa", "commit_date": "Fri Oct 18 07:52:20 2019 -0400", "commit_message": "[AIRFLOW-5415] Enable authentication for Druid hook (#5967)", "files_name": ["airflow/hooks/druid_hook.py"]}, {"commit_id": "19e32b4e2c798f662e5d8d1e7c65036c5e7ac125", "commit_date": "Fri Oct 18 14:54:30 2019 +0200", "commit_message": "[AIRFLOW-5656] Rename provider to providers module (#6333)", "files_name": ["airflow/providers/__init__.py", "airflow/providers/google/__init__.py", "airflow/providers/google/marketing_platform/__init__.py", "airflow/providers/google/marketing_platform/example_dags/__init__.py", "airflow/providers/google/marketing_platform/example_dags/example_campaign_manager.py", "airflow/providers/google/marketing_platform/hooks/__init__.py", "airflow/providers/google/marketing_platform/hooks/campaign_manager.py", "airflow/providers/google/marketing_platform/operators/__init__.py", "airflow/providers/google/marketing_platform/operators/campaign_manager.py", "airflow/providers/google/marketing_platform/sensors/__init__.py", "airflow/providers/google/marketing_platform/sensors/campaign_manager.py", "docs/autoapi_templates/index.rst", "docs/conf.py", "docs/howto/operator/gcp/campaign_manager.rst", "docs/operators-and-hooks-ref.rst", "tests/providers/__init__.py", "tests/providers/google/__init__.py", "tests/providers/google/marketing_platform/__init__.py", "tests/providers/google/marketing_platform/hooks/__init__.py", "tests/providers/google/marketing_platform/hooks/test_campaign_manager.py", "tests/providers/google/marketing_platform/operators/__init__.py", "tests/providers/google/marketing_platform/operators/test_campaign_manager.py", "tests/providers/google/marketing_platform/operators/test_campaign_manager_system.py", "tests/providers/google/marketing_platform/operators/test_campaign_manager_system_helper.py", "tests/providers/google/marketing_platform/sensors/__init__.py", "tests/providers/google/marketing_platform/sensors/test_campaign_manager.py"]}, {"commit_id": "9ec562f88ef8e690f0b17526878b46847f0422e7", "commit_date": "Fri Oct 18 15:35:15 2019 +0200", "commit_message": "[AIRFLOW-5640] Document and test `email` parameters of BaseOperator (#6315)", "files_name": ["airflow/models/baseoperator.py", "airflow/utils/email.py", "tests/utils/test_email.py"]}, {"commit_id": "9c57dd8d4ad67303584447adf7d431cac28160f9", "commit_date": "Fri Oct 18 18:23:01 2019 +0200", "commit_message": "[AIRFLOW-5688] Merge multiple heads in alembic migrations (#6362)", "files_name": ["airflow/migrations/versions/b0125267960b_merge_004c1210f153_and_74effc47d867.py"]}, {"commit_id": "b8c02632136320b8379956411134246cd2f6eb47", "commit_date": "Fri Oct 18 21:18:44 2019 +0200", "commit_message": "Add logo info to readme (#6349)", "files_name": ["README.md"]}, {"commit_id": "c19a60c23df9dd4fab42e68e9a1992f7f89c281c", "commit_date": "Sat Oct 19 21:40:59 2019 +0200", "commit_message": "[AIRFLOW-5680] Fixes Kubernetes hangs (#6347)", "files_name": [".travis.yml", "airflow/kubernetes/k8s_model.py"]}, {"commit_id": "c72c42730236fee1526fcc03dca7f88e1778ee94", "commit_date": "Sat Oct 19 22:16:26 2019 -0400", "commit_message": "[AIRFLOW-5694] Check for blinker in Sentry setup (#6365)", "files_name": ["airflow/sentry.py"]}, {"commit_id": "4903c9730c09f8a98bdf1d891479be0b1cd238c8", "commit_date": "Sun Oct 20 07:28:29 2019 +0200", "commit_message": "[AIRFLOW-5702] Fix common docstring issues (#6372)", "files_name": ["airflow/api/common/experimental/get_dag_runs.py", "airflow/api/common/experimental/mark_tasks.py", "airflow/bin/cli.py", "airflow/configuration.py", "airflow/contrib/hooks/aws_athena_hook.py", "airflow/contrib/hooks/aws_firehose_hook.py", "airflow/contrib/hooks/grpc_hook.py", "airflow/contrib/hooks/qubole_hook.py", "airflow/contrib/hooks/sftp_hook.py", "airflow/contrib/hooks/slack_webhook_hook.py", "airflow/contrib/hooks/spark_submit_hook.py", "airflow/executors/kubernetes_executor.py", "airflow/executors/local_executor.py", "airflow/gcp/hooks/dataproc.py", "airflow/gcp/hooks/kms.py", "airflow/gcp/hooks/text_to_speech.py", "airflow/gcp/operators/bigtable.py", "airflow/gcp/operators/natural_language.py", "airflow/hooks/base_hook.py", "airflow/jobs/backfill_job.py", "airflow/jobs/scheduler_job.py", "airflow/kubernetes/pod_generator.py", "airflow/kubernetes/secret.py", "airflow/lineage/backend/__init__.py", "airflow/migrations/versions/74effc47d867_change_datetime_to_datetime2_6_on_mssql_.py", "airflow/models/baseoperator.py", "airflow/models/dagrun.py", "airflow/task/task_runner/base_task_runner.py", "airflow/ti_deps/deps/dagrun_id_dep.py", "airflow/ti_deps/deps/pool_slots_available_dep.py", "airflow/utils/cli.py", "airflow/utils/cli_action_loggers.py", "airflow/utils/dag_processing.py", "airflow/utils/log/es_task_handler.py", "airflow/utils/log/file_processor_handler.py"]}], "parents": [{"commit_id_before": "0a99aad6c282aebcc178326a2e0cd41f67d8cd52", "url_before": "https://api.github.com/repos/apache/airflow/commits/0a99aad6c282aebcc178326a2e0cd41f67d8cd52", "html_url_before": "https://github.com/apache/airflow/commit/0a99aad6c282aebcc178326a2e0cd41f67d8cd52"}], "details": [{"raw_url": "https://github.com/apache/airflow/raw/c082065f3be07e1c5f39bb86e2b4a06413238631/airflow%2Fwww%2Fviews.py", "code": "# -*- coding: utf-8 -*-\n#\n# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \"License\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n#\n\nimport copy\nimport itertools\nimport json\nimport logging\nimport math\nimport os\nimport socket\nimport traceback\nfrom collections import defaultdict\nfrom datetime import timedelta\nfrom urllib.parse import quote\n\nimport lazy_object_proxy\nimport markdown\nimport pendulum\nimport sqlalchemy as sqla\nfrom flask import Markup, Response, flash, jsonify, make_response, redirect, render_template, request, url_for\nfrom flask_appbuilder import BaseView, ModelView, expose, has_access\nfrom flask_appbuilder.actions import action\nfrom flask_appbuilder.models.sqla.filters import BaseFilter\nfrom flask_babel import lazy_gettext\nfrom pygments import highlight, lexers\nfrom pygments.formatters import HtmlFormatter\nfrom sqlalchemy import and_, desc, or_, union_all\nfrom wtforms import SelectField, validators\n\nimport airflow\nfrom airflow import jobs, models, settings\nfrom airflow._vendor import nvd3\nfrom airflow.api.common.experimental.mark_tasks import (\n    set_dag_run_state_to_failed, set_dag_run_state_to_success,\n)\nfrom airflow.configuration import AIRFLOW_CONFIG, conf\nfrom airflow.models import Connection, DagModel, DagRun, Log, SlaMiss, TaskFail, XCom, errors\nfrom airflow.ti_deps.dep_context import SCHEDULER_QUEUED_DEPS, DepContext\nfrom airflow.utils import timezone\nfrom airflow.utils.dates import infer_time_unit, scale_time_units\nfrom airflow.utils.db import create_session, provide_session\nfrom airflow.utils.helpers import alchemy_to_dict, render_log_filename\nfrom airflow.utils.state import State\nfrom airflow.www import utils as wwwutils\nfrom airflow.www.app import app, appbuilder\nfrom airflow.www.decorators import action_logging, gzipped, has_dag_access\nfrom airflow.www.forms import (\n    ConnectionForm, DagRunForm, DateTimeForm, DateTimeWithNumRunsForm, DateTimeWithNumRunsWithDagRunsForm,\n)\nfrom airflow.www.widgets import AirflowModelListWidget\n\nPAGE_SIZE = conf.getint('webserver', 'page_size')\nif os.environ.get('SKIP_DAGS_PARSING') != 'True':\n    dagbag = models.DagBag(settings.DAGS_FOLDER)\nelse:\n    dagbag = models.DagBag(os.devnull, include_examples=False)\n\n\ndef get_date_time_num_runs_dag_runs_form_data(request, session, dag):\n    dttm = request.args.get('execution_date')\n    if dttm:\n        dttm = pendulum.parse(dttm)\n    else:\n        dttm = dag.latest_execution_date or timezone.utcnow()\n\n    base_date = request.args.get('base_date')\n    if base_date:\n        base_date = timezone.parse(base_date)\n    else:\n        # The DateTimeField widget truncates milliseconds and would loose\n        # the first dag run. Round to next second.\n        base_date = (dttm + timedelta(seconds=1)).replace(microsecond=0)\n\n    default_dag_run = conf.getint('webserver', 'default_dag_run_display_number')\n    num_runs = request.args.get('num_runs')\n    num_runs = int(num_runs) if num_runs else default_dag_run\n\n    DR = models.DagRun\n    drs = (\n        session.query(DR)\n        .filter(\n            DR.dag_id == dag.dag_id,\n            DR.execution_date <= base_date)\n        .order_by(desc(DR.execution_date))\n        .limit(num_runs)\n        .all()\n    )\n    dr_choices = []\n    dr_state = None\n    for dr in drs:\n        dr_choices.append((dr.execution_date.isoformat(), dr.run_id))\n        if dttm == dr.execution_date:\n            dr_state = dr.state\n\n    # Happens if base_date was changed and the selected dag run is not in result\n    if not dr_state and drs:\n        dr = drs[0]\n        dttm = dr.execution_date\n        dr_state = dr.state\n\n    return {\n        'dttm': dttm,\n        'base_date': base_date,\n        'num_runs': num_runs,\n        'execution_date': dttm.isoformat(),\n        'dr_choices': dr_choices,\n        'dr_state': dr_state,\n    }\n\n\n######################################################################################\n#                                    BaseViews\n######################################################################################\n\n@app.errorhandler(404)\ndef circles(error):\n    return render_template(\n        'airflow/circles.html', hostname=socket.getfqdn()), 404\n\n\n@app.errorhandler(500)\ndef show_traceback(error):\n    from airflow.utils import asciiart as ascii_\n    return render_template(\n        'airflow/traceback.html',\n        hostname=socket.getfqdn(),\n        nukular=ascii_.nukular,\n        info=traceback.format_exc()), 500\n\n\nclass AirflowBaseView(BaseView):\n    route_base = ''\n\n    # Make our macros available to our UI templates too.\n    extra_args = {\n        'macros': airflow.macros,\n    }\n\n    def render_template(self, *args, **kwargs):\n        return super().render_template(\n            *args,\n            # Cache this at most once per request, not for the lifetime of the view instance\n            scheduler_job=lazy_object_proxy.Proxy(jobs.SchedulerJob.most_recent_job),\n            **kwargs\n        )\n\n\nclass Airflow(AirflowBaseView):\n    @expose('/health')\n    def health(self):\n        \"\"\"\n        An endpoint helping check the health status of the Airflow instance,\n        including metadatabase and scheduler.\n        \"\"\"\n\n        payload = {\n            'metadatabase': {'status': 'unhealthy'}\n        }\n\n        latest_scheduler_heartbeat = None\n        scheduler_status = 'unhealthy'\n        payload['metadatabase'] = {'status': 'healthy'}\n        try:\n            scheduler_job = jobs.SchedulerJob.most_recent_job()\n\n            if scheduler_job:\n                latest_scheduler_heartbeat = scheduler_job.latest_heartbeat.isoformat()\n                if scheduler_job.is_alive():\n                    scheduler_status = 'healthy'\n        except Exception:\n            payload['metadatabase']['status'] = 'unhealthy'\n\n        payload['scheduler'] = {'status': scheduler_status,\n                                'latest_scheduler_heartbeat': latest_scheduler_heartbeat}\n\n        return wwwutils.json_response(payload)\n\n    @expose('/home')\n    @has_access\n    def index(self):\n        hide_paused_dags_by_default = conf.getboolean('webserver',\n                                                      'hide_paused_dags_by_default')\n        show_paused_arg = request.args.get('showPaused', 'None')\n\n        default_dag_run = conf.getint('webserver', 'default_dag_run_display_number')\n        num_runs = request.args.get('num_runs')\n        num_runs = int(num_runs) if num_runs else default_dag_run\n\n        def get_int_arg(value, default=0):\n            try:\n                return int(value)\n            except ValueError:\n                return default\n\n        arg_current_page = request.args.get('page', '0')\n        arg_search_query = request.args.get('search', None)\n\n        dags_per_page = PAGE_SIZE\n        current_page = get_int_arg(arg_current_page, default=0)\n\n        if show_paused_arg.strip().lower() == 'false':\n            hide_paused = True\n        elif show_paused_arg.strip().lower() == 'true':\n            hide_paused = False\n        else:\n            hide_paused = hide_paused_dags_by_default\n\n        start = current_page * dags_per_page\n        end = start + dags_per_page\n\n        # Get all the dag id the user could access\n        filter_dag_ids = appbuilder.sm.get_accessible_dag_ids()\n\n        with create_session() as session:\n            # read orm_dags from the db\n            dags_query = session.query(DagModel).filter(\n                ~DagModel.is_subdag, DagModel.is_active\n            )\n\n            # optionally filter out \"paused\" dags\n            if hide_paused:\n                dags_query = dags_query.filter(~DagModel.is_paused)\n\n            if arg_search_query:\n                dags_query = dags_query.filter(\n                    DagModel.dag_id.ilike('%' + arg_search_query + '%') |\n                    DagModel.owners.ilike('%' + arg_search_query + '%')\n                )\n\n            if 'all_dags' not in filter_dag_ids:\n                dags_query = dags_query.filter(DagModel.dag_id.in_(filter_dag_ids))\n\n            dags = dags_query.order_by(DagModel.dag_id).offset(start).limit(dags_per_page).all()\n\n            import_errors = session.query(errors.ImportError).all()\n\n        for ie in import_errors:\n            flash(\n                \"Broken DAG: [{ie.filename}] {ie.stacktrace}\".format(ie=ie),\n                \"dag_import_error\")\n\n        from airflow.plugins_manager import import_errors as plugin_import_errors\n        for filename, stacktrace in plugin_import_errors.items():\n            flash(\n                \"Broken plugin: [{filename}] {stacktrace}\".format(\n                    stacktrace=stacktrace,\n                    filename=filename),\n                \"error\")\n\n        num_of_all_dags = dags_query.count()\n        num_of_pages = int(math.ceil(num_of_all_dags / float(dags_per_page)))\n\n        auto_complete_data = set()\n        for row in dags_query.with_entities(DagModel.dag_id, DagModel.owners):\n            auto_complete_data.add(row.dag_id)\n            auto_complete_data.add(row.owners)\n\n        return self.render_template(\n            'airflow/dags.html',\n            dags=dags,\n            hide_paused=hide_paused,\n            current_page=current_page,\n            search_query=arg_search_query if arg_search_query else '',\n            page_size=dags_per_page,\n            num_of_pages=num_of_pages,\n            num_dag_from=min(start + 1, num_of_all_dags),\n            num_dag_to=min(end, num_of_all_dags),\n            num_of_all_dags=num_of_all_dags,\n            paging=wwwutils.generate_pages(current_page, num_of_pages,\n                                           search=arg_search_query,\n                                           showPaused=not hide_paused),\n            auto_complete_data=auto_complete_data,\n            num_runs=num_runs)\n\n    @expose('/dag_stats')\n    @has_access\n    @provide_session\n    def dag_stats(self, session=None):\n        dr = models.DagRun\n\n        filter_dag_ids = appbuilder.sm.get_accessible_dag_ids()\n\n        dag_state_stats = session.query(dr.dag_id, dr.state, sqla.func.count(dr.state))\\\n            .group_by(dr.dag_id, dr.state)\n\n        payload = {}\n        if filter_dag_ids:\n            if 'all_dags' not in filter_dag_ids:\n                dag_state_stats = dag_state_stats.filter(dr.dag_id.in_(filter_dag_ids))\n            data = {}\n            for dag_id, state, count in dag_state_stats:\n                if dag_id not in data:\n                    data[dag_id] = {}\n                data[dag_id][state] = count\n\n            if 'all_dags' in filter_dag_ids:\n                filter_dag_ids = [dag_id for dag_id, in session.query(models.DagModel.dag_id)]\n\n            for dag_id in filter_dag_ids:\n                payload[dag_id] = []\n                for state in State.dag_states:\n                    count = data.get(dag_id, {}).get(state, 0)\n                    payload[dag_id].append({\n                        'state': state,\n                        'count': count,\n                        'dag_id': dag_id,\n                        'color': State.color(state)\n                    })\n        return wwwutils.json_response(payload)\n\n    @expose('/task_stats')\n    @has_access\n    @provide_session\n    def task_stats(self, session=None):\n        TI = models.TaskInstance\n        DagRun = models.DagRun\n        Dag = models.DagModel\n\n        filter_dag_ids = appbuilder.sm.get_accessible_dag_ids()\n\n        payload = {}\n        if not filter_dag_ids:\n            return\n\n        LastDagRun = (\n            session.query(\n                DagRun.dag_id,\n                sqla.func.max(DagRun.execution_date).label('execution_date')\n            )\n            .join(Dag, Dag.dag_id == DagRun.dag_id)\n            .filter(DagRun.state != State.RUNNING, Dag.is_active)\n            .group_by(DagRun.dag_id)\n            .subquery('last_dag_run')\n        )\n        RunningDagRun = (\n            session.query(DagRun.dag_id, DagRun.execution_date)\n                   .join(Dag, Dag.dag_id == DagRun.dag_id)\n                   .filter(DagRun.state == State.RUNNING, Dag.is_active)\n                   .subquery('running_dag_run')\n        )\n\n        # Select all task_instances from active dag_runs.\n        # If no dag_run is active, return task instances from most recent dag_run.\n        LastTI = (\n            session.query(TI.dag_id.label('dag_id'), TI.state.label('state'))\n                   .join(LastDagRun,\n                         and_(LastDagRun.c.dag_id == TI.dag_id,\n                              LastDagRun.c.execution_date == TI.execution_date))\n        )\n        RunningTI = (\n            session.query(TI.dag_id.label('dag_id'), TI.state.label('state'))\n                   .join(RunningDagRun,\n                         and_(RunningDagRun.c.dag_id == TI.dag_id,\n                              RunningDagRun.c.execution_date == TI.execution_date))\n        )\n\n        UnionTI = union_all(LastTI, RunningTI).alias('union_ti')\n        qry = (\n            session.query(UnionTI.c.dag_id, UnionTI.c.state, sqla.func.count())\n                   .group_by(UnionTI.c.dag_id, UnionTI.c.state)\n        )\n\n        data = {}\n        for dag_id, state, count in qry:\n            if 'all_dags' in filter_dag_ids or dag_id in filter_dag_ids:\n                if dag_id not in data:\n                    data[dag_id] = {}\n                data[dag_id][state] = count\n        session.commit()\n\n        if 'all_dags' in filter_dag_ids:\n            filter_dag_ids = [dag_id for dag_id, in session.query(models.DagModel.dag_id)]\n        for dag_id in filter_dag_ids:\n            payload[dag_id] = []\n            for state in State.task_states:\n                count = data.get(dag_id, {}).get(state, 0)\n                payload[dag_id].append({\n                    'state': state,\n                    'count': count,\n                    'dag_id': dag_id,\n                    'color': State.color(state)\n                })\n        return wwwutils.json_response(payload)\n\n    @expose('/last_dagruns')\n    @has_access\n    @provide_session\n    def last_dagruns(self, session=None):\n        DagRun = models.DagRun\n\n        filter_dag_ids = appbuilder.sm.get_accessible_dag_ids()\n\n        if not filter_dag_ids:\n            return\n\n        dags_to_latest_runs = dict(session.query(\n            DagRun.dag_id, sqla.func.max(DagRun.execution_date).label('execution_date'))\n            .group_by(DagRun.dag_id).all())\n\n        payload = {}\n        for dag in dagbag.dags.values():\n            dag_accessible = 'all_dags' in filter_dag_ids or dag.dag_id in filter_dag_ids\n            if (dag_accessible and dag.dag_id in dags_to_latest_runs and\n                    dags_to_latest_runs[dag.dag_id]):\n                payload[dag.safe_dag_id] = {\n                    'dag_id': dag.dag_id,\n                    'last_run': dags_to_latest_runs[dag.dag_id].strftime(\"%Y-%m-%d %H:%M\")\n                }\n\n        return wwwutils.json_response(payload)\n\n    @expose('/code')\n    @has_dag_access(can_dag_read=True)\n    @has_access\n    @provide_session\n    def code(self, session=None):\n        dm = models.DagModel\n        dag_id = request.args.get('dag_id')\n        dag = session.query(dm).filter(dm.dag_id == dag_id).first()\n        try:\n            with wwwutils.open_maybe_zipped(dag.fileloc, 'r') as f:\n                code = f.read()\n            html_code = highlight(\n                code, lexers.PythonLexer(), HtmlFormatter(linenos=True))\n        except OSError as e:\n            html_code = str(e)\n\n        return self.render_template(\n            'airflow/dag_code.html', html_code=html_code, dag=dag, title=dag_id,\n            root=request.args.get('root'),\n            demo_mode=conf.getboolean('webserver', 'demo_mode'),\n            wrapped=conf.getboolean('webserver', 'default_wrap'))\n\n    @expose('/dag_details')\n    @has_dag_access(can_dag_read=True)\n    @has_access\n    @provide_session\n    def dag_details(self, session=None):\n        dag_id = request.args.get('dag_id')\n        dag_orm = DagModel.get_dagmodel(dag_id)\n        # FIXME: items needed for this view should move to the database\n        dag = dag_orm.get_dag()\n        title = \"DAG details\"\n        root = request.args.get('root', '')\n\n        TI = models.TaskInstance\n        states = (\n            session.query(TI.state, sqla.func.count(TI.dag_id))\n                   .filter(TI.dag_id == dag_id)\n                   .group_by(TI.state)\n                   .all()\n        )\n\n        active_runs = models.DagRun.find(\n            dag_id=dag_id,\n            state=State.RUNNING,\n            external_trigger=False\n        )\n\n        return self.render_template(\n            'airflow/dag_details.html',\n            dag=dag, title=title, root=root, states=states, State=State, active_runs=active_runs)\n\n    @expose('/rendered')\n    @has_dag_access(can_dag_read=True)\n    @has_access\n    @action_logging\n    def rendered(self):\n        dag_id = request.args.get('dag_id')\n        task_id = request.args.get('task_id')\n        execution_date = request.args.get('execution_date')\n        dttm = pendulum.parse(execution_date)\n        form = DateTimeForm(data={'execution_date': dttm})\n        root = request.args.get('root', '')\n        dag = dagbag.get_dag(dag_id)\n        task = copy.copy(dag.get_task(task_id))\n        ti = models.TaskInstance(task=task, execution_date=dttm)\n        try:\n            ti.render_templates()\n        except Exception as e:\n            flash(\"Error rendering template: \" + str(e), \"error\")\n        title = \"Rendered Template\"\n        html_dict = {}\n        for template_field in task.__class__.template_fields:\n            content = getattr(task, template_field)\n            if template_field in wwwutils.get_attr_renderer():\n                html_dict[template_field] = \\\n                    wwwutils.get_attr_renderer()[template_field](content)\n            else:\n                html_dict[template_field] = (\n                    \"<pre><code>\" + str(content) + \"</pre></code>\")\n\n        return self.render_template(\n            'airflow/ti_code.html',\n            html_dict=html_dict,\n            dag=dag,\n            task_id=task_id,\n            execution_date=execution_date,\n            form=form,\n            root=root,\n            title=title)\n\n    @expose('/get_logs_with_metadata')\n    @has_dag_access(can_dag_read=True)\n    @has_access\n    @action_logging\n    @provide_session\n    def get_logs_with_metadata(self, session=None):\n        dag_id = request.args.get('dag_id')\n        task_id = request.args.get('task_id')\n        execution_date = request.args.get('execution_date')\n        dttm = pendulum.parse(execution_date)\n        if request.args.get('try_number') is not None:\n            try_number = int(request.args.get('try_number'))\n        else:\n            try_number = None\n        metadata = request.args.get('metadata')\n        metadata = json.loads(metadata)\n        response_format = request.args.get('format', 'json')\n\n        # metadata may be null\n        if not metadata:\n            metadata = {}\n\n        # Convert string datetime into actual datetime\n        try:\n            execution_date = timezone.parse(execution_date)\n        except ValueError:\n            error_message = (\n                'Given execution date, {}, could not be identified '\n                'as a date. Example date format: 2015-11-16T14:34:15+00:00'.format(\n                    execution_date))\n            response = jsonify({'error': error_message})\n            response.status_code = 400\n\n            return response\n\n        logger = logging.getLogger('airflow.task')\n        task_log_reader = conf.get('core', 'task_log_reader')\n        handler = next((handler for handler in logger.handlers\n                        if handler.name == task_log_reader), None)\n\n        ti = session.query(models.TaskInstance).filter(\n            models.TaskInstance.dag_id == dag_id,\n            models.TaskInstance.task_id == task_id,\n            models.TaskInstance.execution_date == dttm).first()\n\n        def _get_logs_with_metadata(try_number, metadata):\n            if ti is None:\n                logs = [\"*** Task instance did not exist in the DB\\n\"]\n                metadata['end_of_log'] = True\n            else:\n                logs, metadatas = handler.read(ti, try_number, metadata=metadata)\n                metadata = metadatas[0]\n            return logs, metadata\n\n        try:\n            if ti is not None:\n                dag = dagbag.get_dag(dag_id)\n                ti.task = dag.get_task(ti.task_id)\n            if response_format == 'json':\n                logs, metadata = _get_logs_with_metadata(try_number, metadata)\n                message = logs[0] if try_number is not None else logs\n                return jsonify(message=message, metadata=metadata)\n\n            filename_template = conf.get('core', 'LOG_FILENAME_TEMPLATE')\n            attachment_filename = render_log_filename(\n                ti=ti,\n                try_number=\"all\" if try_number is None else try_number,\n                filename_template=filename_template)\n            metadata['download_logs'] = True\n\n            def _generate_log_stream(try_number, metadata):\n                if try_number is None and ti is not None:\n                    next_try = ti.next_try_number\n                    try_numbers = list(range(1, next_try))\n                else:\n                    try_numbers = [try_number]\n                for try_number in try_numbers:\n                    metadata.pop('end_of_log', None)\n                    metadata.pop('max_offset', None)\n                    metadata.pop('offset', None)\n                    while 'end_of_log' not in metadata or not metadata['end_of_log']:\n                        logs, metadata = _get_logs_with_metadata(try_number, metadata)\n                        yield \"\\n\".join(logs) + \"\\n\"\n            return Response(_generate_log_stream(try_number, metadata),\n                            mimetype=\"text/plain\",\n                            headers={\"Content-Disposition\": \"attachment; filename={}\".format(\n                                attachment_filename)})\n        except AttributeError as e:\n            error_message = [\"Task log handler {} does not support read logs.\\n{}\\n\"\n                             .format(task_log_reader, str(e))]\n            metadata['end_of_log'] = True\n            return jsonify(message=error_message, error=True, metadata=metadata)\n\n    @expose('/log')\n    @has_dag_access(can_dag_read=True)\n    @has_access\n    @action_logging\n    @provide_session\n    def log(self, session=None):\n        dag_id = request.args.get('dag_id')\n        task_id = request.args.get('task_id')\n        execution_date = request.args.get('execution_date')\n        dttm = pendulum.parse(execution_date)\n        form = DateTimeForm(data={'execution_date': dttm})\n        dag_model = DagModel.get_dagmodel(dag_id)\n\n        ti = session.query(models.TaskInstance).filter(\n            models.TaskInstance.dag_id == dag_id,\n            models.TaskInstance.task_id == task_id,\n            models.TaskInstance.execution_date == dttm).first()\n\n        num_logs = 0\n        if ti is not None:\n            num_logs = ti.next_try_number - 1\n            if ti.state == State.UP_FOR_RESCHEDULE:\n                # Tasks in reschedule state decremented the try number\n                num_logs += 1\n        logs = [''] * num_logs\n        root = request.args.get('root', '')\n        return self.render_template(\n            'airflow/ti_log.html',\n            logs=logs, dag=dag_model, title=\"Log by attempts\",\n            dag_id=dag_id, task_id=task_id,\n            execution_date=execution_date, form=form,\n            root=root, wrapped=conf.getboolean('webserver', 'default_wrap'))\n\n    @expose('/elasticsearch')\n    @has_dag_access(can_dag_read=True)\n    @has_access\n    @action_logging\n    @provide_session\n    def elasticsearch(self, session=None):\n        dag_id = request.args.get('dag_id')\n        task_id = request.args.get('task_id')\n        execution_date = request.args.get('execution_date')\n        try_number = request.args.get('try_number', 1)\n        elasticsearch_frontend = conf.get('elasticsearch', 'frontend')\n        log_id_template = conf.get('elasticsearch', 'log_id_template')\n        log_id = log_id_template.format(\n            dag_id=dag_id, task_id=task_id,\n            execution_date=execution_date, try_number=try_number)\n        url = 'https://' + elasticsearch_frontend.format(log_id=quote(log_id))\n        return redirect(url)\n\n    @expose('/task')\n    @has_dag_access(can_dag_read=True)\n    @has_access\n    @action_logging\n    def task(self):\n        TI = models.TaskInstance\n\n        dag_id = request.args.get('dag_id')\n        task_id = request.args.get('task_id')\n        # Carrying execution_date through, even though it's irrelevant for\n        # this context\n        execution_date = request.args.get('execution_date')\n        dttm = pendulum.parse(execution_date)\n        form = DateTimeForm(data={'execution_date': dttm})\n        root = request.args.get('root', '')\n        dag = dagbag.get_dag(dag_id)\n\n        if not dag or task_id not in dag.task_ids:\n            flash(\n                \"Task [{}.{}] doesn't seem to exist\"\n                \" at the moment\".format(dag_id, task_id),\n                \"error\")\n            return redirect(url_for('Airflow.index'))\n        task = copy.copy(dag.get_task(task_id))\n        task.resolve_template_files()\n        ti = TI(task=task, execution_date=dttm)\n        ti.refresh_from_db()\n\n        ti_attrs = []\n        for attr_name in dir(ti):\n            if not attr_name.startswith('_'):\n                attr = getattr(ti, attr_name)\n                if type(attr) != type(self.task):  # noqa\n                    ti_attrs.append((attr_name, str(attr)))\n\n        task_attrs = []\n        for attr_name in dir(task):\n            if not attr_name.startswith('_'):\n                attr = getattr(task, attr_name)\n                if type(attr) != type(self.task) and \\\n                        attr_name not in wwwutils.get_attr_renderer():  # noqa\n                    task_attrs.append((attr_name, str(attr)))\n\n        # Color coding the special attributes that are code\n        special_attrs_rendered = {}\n        for attr_name in wwwutils.get_attr_renderer():\n            if hasattr(task, attr_name):\n                source = getattr(task, attr_name)\n                special_attrs_rendered[attr_name] = \\\n                    wwwutils.get_attr_renderer()[attr_name](source)\n\n        no_failed_deps_result = [(\n            \"Unknown\",\n            \"All dependencies are met but the task instance is not running. In most \"\n            \"cases this just means that the task will probably be scheduled soon \"\n            \"unless:<br/>\\n- The scheduler is down or under heavy load<br/>\\n{}\\n\"\n            \"<br/>\\nIf this task instance does not start soon please contact your \"\n            \"Airflow administrator for assistance.\".format(\n                \"- This task instance already ran and had it's state changed manually \"\n                \"(e.g. cleared in the UI)<br/>\" if ti.state == State.NONE else \"\"))]\n\n        # Use the scheduler's context to figure out which dependencies are not met\n        dep_context = DepContext(SCHEDULER_QUEUED_DEPS)\n        failed_dep_reasons = [(dep.dep_name, dep.reason) for dep in\n                              ti.get_failed_dep_statuses(\n                                  dep_context=dep_context)]\n\n        title = \"Task Instance Details\"\n        return self.render_template(\n            'airflow/task.html',\n            task_attrs=task_attrs,\n            ti_attrs=ti_attrs,\n            failed_dep_reasons=failed_dep_reasons or no_failed_deps_result,\n            task_id=task_id,\n            execution_date=execution_date,\n            special_attrs_rendered=special_attrs_rendered,\n            form=form,\n            root=root,\n            dag=dag, title=title)\n\n    @expose('/xcom')\n    @has_dag_access(can_dag_read=True)\n    @has_access\n    @action_logging\n    @provide_session\n    def xcom(self, session=None):\n        dag_id = request.args.get('dag_id')\n        task_id = request.args.get('task_id')\n        # Carrying execution_date through, even though it's irrelevant for\n        # this context\n        execution_date = request.args.get('execution_date')\n        dttm = pendulum.parse(execution_date)\n        form = DateTimeForm(data={'execution_date': dttm})\n        root = request.args.get('root', '')\n        dm_db = models.DagModel\n        ti_db = models.TaskInstance\n        dag = session.query(dm_db).filter(dm_db.dag_id == dag_id).first()\n        ti = session.query(ti_db).filter(ti_db.dag_id == dag_id and ti_db.task_id == task_id).first()\n\n        if not ti:\n            flash(\n                \"Task [{}.{}] doesn't seem to exist\"\n                \" at the moment\".format(dag_id, task_id),\n                \"error\")\n            return redirect(url_for('Airflow.index'))\n\n        xcomlist = session.query(XCom).filter(\n            XCom.dag_id == dag_id, XCom.task_id == task_id,\n            XCom.execution_date == dttm).all()\n\n        attributes = []\n        for xcom in xcomlist:\n            if not xcom.key.startswith('_'):\n                attributes.append((xcom.key, xcom.value))\n\n        title = \"XCom\"\n        return self.render_template(\n            'airflow/xcom.html',\n            attributes=attributes,\n            task_id=task_id,\n            execution_date=execution_date,\n            form=form,\n            root=root,\n            dag=dag, title=title)\n\n    @expose('/run', methods=['POST'])\n    @has_dag_access(can_dag_edit=True)\n    @has_access\n    @action_logging\n    def run(self):\n        dag_id = request.form.get('dag_id')\n        task_id = request.form.get('task_id')\n        origin = request.form.get('origin')\n        dag = dagbag.get_dag(dag_id)\n        task = dag.get_task(task_id)\n\n        execution_date = request.form.get('execution_date')\n        execution_date = pendulum.parse(execution_date)\n        ignore_all_deps = request.form.get('ignore_all_deps') == \"true\"\n        ignore_task_deps = request.form.get('ignore_task_deps') == \"true\"\n        ignore_ti_state = request.form.get('ignore_ti_state') == \"true\"\n\n        from airflow.executors import get_default_executor\n        executor = get_default_executor()\n        valid_celery_config = False\n        valid_kubernetes_config = False\n\n        try:\n            from airflow.executors.celery_executor import CeleryExecutor\n            valid_celery_config = isinstance(executor, CeleryExecutor)\n        except ImportError:\n            pass\n\n        try:\n            from airflow.executors.kubernetes_executor import KubernetesExecutor\n            valid_kubernetes_config = isinstance(executor, KubernetesExecutor)\n        except ImportError:\n            pass\n\n        if not valid_celery_config and not valid_kubernetes_config:\n            flash(\"Only works with the Celery or Kubernetes executors, sorry\", \"error\")\n            return redirect(origin)\n\n        ti = models.TaskInstance(task=task, execution_date=execution_date)\n        ti.refresh_from_db()\n\n        # Make sure the task instance can be queued\n        dep_context = DepContext(\n            deps=SCHEDULER_QUEUED_DEPS,\n            ignore_all_deps=ignore_all_deps,\n            ignore_task_deps=ignore_task_deps,\n            ignore_ti_state=ignore_ti_state)\n        failed_deps = list(ti.get_failed_dep_statuses(dep_context=dep_context))\n        if failed_deps:\n            failed_deps_str = \", \".join(\n                [\"{}: {}\".format(dep.dep_name, dep.reason) for dep in failed_deps])\n            flash(\"Could not queue task instance for execution, dependencies not met: \"\n                  \"{}\".format(failed_deps_str),\n                  \"error\")\n            return redirect(origin)\n\n        executor.start()\n        executor.queue_task_instance(\n            ti,\n            ignore_all_deps=ignore_all_deps,\n            ignore_task_deps=ignore_task_deps,\n            ignore_ti_state=ignore_ti_state)\n        executor.heartbeat()\n        flash(\n            \"Sent {} to the message queue, \"\n            \"it should start any moment now.\".format(ti))\n        return redirect(origin)\n\n    @expose('/delete', methods=['POST'])\n    @has_dag_access(can_dag_edit=True)\n    @has_access\n    @action_logging\n    def delete(self):\n        from airflow.api.common.experimental import delete_dag\n        from airflow.exceptions import DagNotFound, DagFileExists\n\n        dag_id = request.values.get('dag_id')\n        origin = request.values.get('origin') or url_for('Airflow.index')\n\n        try:\n            delete_dag.delete_dag(dag_id)\n        except DagNotFound:\n            flash(\"DAG with id {} not found. Cannot delete\".format(dag_id), 'error')\n            return redirect(request.referrer)\n        except DagFileExists:\n            flash(\"Dag id {} is still in DagBag. \"\n                  \"Remove the DAG file first.\".format(dag_id),\n                  'error')\n            return redirect(request.referrer)\n\n        flash(\"Deleting DAG with id {}. May take a couple minutes to fully\"\n              \" disappear.\".format(dag_id))\n\n        # Upon success return to origin.\n        return redirect(origin)\n\n    @expose('/trigger', methods=['POST'])\n    @has_dag_access(can_dag_edit=True)\n    @has_access\n    @action_logging\n    @provide_session\n    def trigger(self, session=None):\n        dag_id = request.values.get('dag_id')\n        origin = request.values.get('origin') or url_for('Airflow.index')\n        dag = session.query(models.DagModel).filter(models.DagModel.dag_id == dag_id).first()\n        if not dag:\n            flash(\"Cannot find dag {}\".format(dag_id))\n            return redirect(origin)\n\n        execution_date = timezone.utcnow()\n        run_id = \"manual__{0}\".format(execution_date.isoformat())\n\n        dr = DagRun.find(dag_id=dag_id, run_id=run_id)\n        if dr:\n            flash(\"This run_id {} already exists\".format(run_id))\n            return redirect(origin)\n\n        run_conf = {}\n\n        dag.create_dagrun(\n            run_id=run_id,\n            execution_date=execution_date,\n            state=State.RUNNING,\n            conf=run_conf,\n            external_trigger=True\n        )\n\n        flash(\n            \"Triggered {}, \"\n            \"it should start any moment now.\".format(dag_id))\n        return redirect(origin)\n\n    def _clear_dag_tis(self, dag, start_date, end_date, origin,\n                       recursive=False, confirmed=False, only_failed=False):\n        if confirmed:\n            count = dag.clear(\n                start_date=start_date,\n                end_date=end_date,\n                include_subdags=recursive,\n                include_parentdag=recursive,\n                only_failed=only_failed,\n            )\n\n            flash(\"{0} task instances have been cleared\".format(count))\n            return redirect(origin)\n\n        tis = dag.clear(\n            start_date=start_date,\n            end_date=end_date,\n            include_subdags=recursive,\n            include_parentdag=recursive,\n            only_failed=only_failed,\n            dry_run=True,\n        )\n        if not tis:\n            flash(\"No task instances to clear\", 'error')\n            response = redirect(origin)\n        else:\n            details = \"\\n\".join([str(t) for t in tis])\n\n            response = self.render_template(\n                'airflow/confirm.html',\n                message=(\"Here's the list of task instances you are about \"\n                         \"to clear:\"),\n                details=details)\n\n        return response\n\n    @expose('/clear', methods=['POST'])\n    @has_dag_access(can_dag_edit=True)\n    @has_access\n    @action_logging\n    def clear(self):\n        dag_id = request.form.get('dag_id')\n        task_id = request.form.get('task_id')\n        origin = request.form.get('origin')\n        dag = dagbag.get_dag(dag_id)\n\n        execution_date = request.form.get('execution_date')\n        execution_date = pendulum.parse(execution_date)\n        confirmed = request.form.get('confirmed') == \"true\"\n        upstream = request.form.get('upstream') == \"true\"\n        downstream = request.form.get('downstream') == \"true\"\n        future = request.form.get('future') == \"true\"\n        past = request.form.get('past') == \"true\"\n        recursive = request.form.get('recursive') == \"true\"\n        only_failed = request.form.get('only_failed') == \"true\"\n\n        dag = dag.sub_dag(\n            task_regex=r\"^{0}$\".format(task_id),\n            include_downstream=downstream,\n            include_upstream=upstream)\n\n        end_date = execution_date if not future else None\n        start_date = execution_date if not past else None\n\n        return self._clear_dag_tis(dag, start_date, end_date, origin,\n                                   recursive=recursive, confirmed=confirmed, only_failed=only_failed)\n\n    @expose('/dagrun_clear', methods=['POST'])\n    @has_dag_access(can_dag_edit=True)\n    @has_access\n    @action_logging\n    def dagrun_clear(self):\n        dag_id = request.form.get('dag_id')\n        origin = request.form.get('origin')\n        execution_date = request.form.get('execution_date')\n        confirmed = request.form.get('confirmed') == \"true\"\n\n        dag = dagbag.get_dag(dag_id)\n        execution_date = pendulum.parse(execution_date)\n        start_date = execution_date\n        end_date = execution_date\n\n        return self._clear_dag_tis(dag, start_date, end_date, origin,\n                                   recursive=True, confirmed=confirmed)\n\n    @expose('/blocked')\n    @has_access\n    @provide_session\n    def blocked(self, session=None):\n        DR = models.DagRun\n        filter_dag_ids = appbuilder.sm.get_accessible_dag_ids()\n\n        payload = []\n        if filter_dag_ids:\n            dags = (\n                session.query(DR.dag_id, sqla.func.count(DR.id))\n                       .filter(DR.state == State.RUNNING)\n                       .group_by(DR.dag_id)\n\n            )\n            if 'all_dags' not in filter_dag_ids:\n                dags = dags.filter(DR.dag_id.in_(filter_dag_ids))\n            dags = dags.all()\n\n            for dag_id, active_dag_runs in dags:\n                max_active_runs = 0\n                if dag_id in dagbag.dags:\n                    max_active_runs = dagbag.dags[dag_id].max_active_runs\n                payload.append({\n                    'dag_id': dag_id,\n                    'active_dag_run': active_dag_runs,\n                    'max_active_runs': max_active_runs,\n                })\n        return wwwutils.json_response(payload)\n\n    def _mark_dagrun_state_as_failed(self, dag_id, execution_date, confirmed, origin):\n        if not execution_date:\n            flash('Invalid execution date', 'error')\n            return redirect(origin)\n\n        execution_date = pendulum.parse(execution_date)\n        dag = dagbag.get_dag(dag_id)\n\n        if not dag:\n            flash('Cannot find DAG: {}'.format(dag_id), 'error')\n            return redirect(origin)\n\n        new_dag_state = set_dag_run_state_to_failed(dag, execution_date, commit=confirmed)\n\n        if confirmed:\n            flash('Marked failed on {} task instances'.format(len(new_dag_state)))\n            return redirect(origin)\n\n        else:\n            details = '\\n'.join([str(t) for t in new_dag_state])\n\n            response = self.render_template(\n                'airflow/confirm.html',\n                message=(\"Here's the list of task instances you are about to mark as failed\"),\n                details=details)\n\n            return response\n\n    def _mark_dagrun_state_as_success(self, dag_id, execution_date, confirmed, origin):\n        if not execution_date:\n            flash('Invalid execution date', 'error')\n            return redirect(origin)\n\n        execution_date = pendulum.parse(execution_date)\n        dag = dagbag.get_dag(dag_id)\n\n        if not dag:\n            flash('Cannot find DAG: {}'.format(dag_id), 'error')\n            return redirect(origin)\n\n        new_dag_state = set_dag_run_state_to_success(dag, execution_date,\n                                                     commit=confirmed)\n\n        if confirmed:\n            flash('Marked success on {} task instances'.format(len(new_dag_state)))\n            return redirect(origin)\n\n        else:\n            details = '\\n'.join([str(t) for t in new_dag_state])\n\n            response = self.render_template(\n                'airflow/confirm.html',\n                message=(\"Here's the list of task instances you are about to mark as success\"),\n                details=details)\n\n            return response\n\n    @expose('/dagrun_failed', methods=['POST'])\n    @has_dag_access(can_dag_edit=True)\n    @has_access\n    @action_logging\n    def dagrun_failed(self):\n        dag_id = request.form.get('dag_id')\n        execution_date = request.form.get('execution_date')\n        confirmed = request.form.get('confirmed') == 'true'\n        origin = request.form.get('origin')\n        return self._mark_dagrun_state_as_failed(dag_id, execution_date,\n                                                 confirmed, origin)\n\n    @expose('/dagrun_success', methods=['POST'])\n    @has_dag_access(can_dag_edit=True)\n    @has_access\n    @action_logging\n    def dagrun_success(self):\n        dag_id = request.form.get('dag_id')\n        execution_date = request.form.get('execution_date')\n        confirmed = request.form.get('confirmed') == 'true'\n        origin = request.form.get('origin')\n        return self._mark_dagrun_state_as_success(dag_id, execution_date,\n                                                  confirmed, origin)\n\n    def _mark_task_instance_state(self, dag_id, task_id, origin, execution_date,\n                                  confirmed, upstream, downstream,\n                                  future, past, state):\n        dag = dagbag.get_dag(dag_id)\n        task = dag.get_task(task_id)\n        task.dag = dag\n\n        execution_date = pendulum.parse(execution_date)\n\n        if not dag:\n            flash(\"Cannot find DAG: {}\".format(dag_id))\n            return redirect(origin)\n\n        if not task:\n            flash(\"Cannot find task {} in DAG {}\".format(task_id, dag.dag_id))\n            return redirect(origin)\n\n        from airflow.api.common.experimental.mark_tasks import set_state\n\n        if confirmed:\n            altered = set_state(tasks=[task], execution_date=execution_date,\n                                upstream=upstream, downstream=downstream,\n                                future=future, past=past, state=state,\n                                commit=True)\n\n            flash(\"Marked {} on {} task instances\".format(state, len(altered)))\n            return redirect(origin)\n\n        to_be_altered = set_state(tasks=[task], execution_date=execution_date,\n                                  upstream=upstream, downstream=downstream,\n                                  future=future, past=past, state=state,\n                                  commit=False)\n\n        details = \"\\n\".join([str(t) for t in to_be_altered])\n\n        response = self.render_template(\n            \"airflow/confirm.html\",\n            message=(\"Here's the list of task instances you are about to mark as {}:\".format(state)),\n            details=details)\n\n        return response\n\n    @expose('/failed', methods=['POST'])\n    @has_dag_access(can_dag_edit=True)\n    @has_access\n    @action_logging\n    def failed(self):\n        dag_id = request.form.get('dag_id')\n        task_id = request.form.get('task_id')\n        origin = request.form.get('origin')\n        execution_date = request.form.get('execution_date')\n\n        confirmed = request.form.get('confirmed') == \"true\"\n        upstream = request.form.get('failed_upstream') == \"true\"\n        downstream = request.form.get('failed_downstream') == \"true\"\n        future = request.form.get('failed_future') == \"true\"\n        past = request.form.get('failed_past') == \"true\"\n\n        return self._mark_task_instance_state(dag_id, task_id, origin, execution_date,\n                                              confirmed, upstream, downstream,\n                                              future, past, State.FAILED)\n\n    @expose('/success', methods=['POST'])\n    @has_dag_access(can_dag_edit=True)\n    @has_access\n    @action_logging\n    def success(self):\n        dag_id = request.form.get('dag_id')\n        task_id = request.form.get('task_id')\n        origin = request.form.get('origin')\n        execution_date = request.form.get('execution_date')\n\n        confirmed = request.form.get('confirmed') == \"true\"\n        upstream = request.form.get('success_upstream') == \"true\"\n        downstream = request.form.get('success_downstream') == \"true\"\n        future = request.form.get('success_future') == \"true\"\n        past = request.form.get('success_past') == \"true\"\n\n        return self._mark_task_instance_state(dag_id, task_id, origin, execution_date,\n                                              confirmed, upstream, downstream,\n                                              future, past, State.SUCCESS)\n\n    @expose('/tree')\n    @has_dag_access(can_dag_read=True)\n    @has_access\n    @gzipped\n    @action_logging\n    def tree(self):\n        default_dag_run = conf.getint('webserver', 'default_dag_run_display_number')\n        dag_id = request.args.get('dag_id')\n        blur = conf.getboolean('webserver', 'demo_mode')\n        dag_model = DagModel.get_dagmodel(dag_id)\n        if not dag_model:\n            flash('DAG \"{0}\" seems to be missing in database.'.format(dag_id), \"error\")\n            return redirect(url_for('Airflow.index'))\n        dag = dag_model.get_dag()\n\n        if dag is None:\n            dag = dagbag.get_dag(dag_id)\n            if dag is None:\n                flash('DAG \"{0}\" seems to be missing from DagBag.'.format(dag_id), \"error\")\n                return redirect(url_for('Airflow.index'))\n\n        root = request.args.get('root')\n        if root:\n            dag = dag.sub_dag(\n                task_regex=root,\n                include_downstream=False,\n                include_upstream=True)\n\n        base_date = request.args.get('base_date')\n        num_runs = request.args.get('num_runs')\n        num_runs = int(num_runs) if num_runs else default_dag_run\n\n        if base_date:\n            base_date = timezone.parse(base_date)\n        else:\n            base_date = dag.latest_execution_date or timezone.utcnow()\n\n        with create_session() as session:\n            dag_runs = (\n                session.query(DagRun)\n                .filter(\n                    DagRun.dag_id == dag.dag_id,\n                    DagRun.execution_date <= base_date)\n                .order_by(DagRun.execution_date.desc())\n                .limit(num_runs)\n                .all()\n            )\n        dag_runs = {\n            dr.execution_date: alchemy_to_dict(dr) for dr in dag_runs}\n\n        dates = sorted(list(dag_runs.keys()))\n        max_date = max(dates) if dates else None\n        min_date = min(dates) if dates else None\n\n        tis = dag.get_task_instances(start_date=min_date, end_date=base_date)\n        task_instances = {}\n        for ti in tis:\n            tid = alchemy_to_dict(ti)\n            dr = dag_runs.get(ti.execution_date)\n            tid['external_trigger'] = dr['external_trigger'] if dr else False\n            task_instances[(ti.task_id, ti.execution_date)] = tid\n\n        expanded = []\n        # The default recursion traces every path so that tree view has full\n        # expand/collapse functionality. After 5,000 nodes we stop and fall\n        # back on a quick DFS search for performance. See PR #320.\n        node_count = [0]\n        node_limit = 5000 / max(1, len(dag.leaves))\n\n        def recurse_nodes(task, visited):\n            visited.add(task)\n            node_count[0] += 1\n\n            children = [\n                recurse_nodes(t, visited) for t in task.downstream_list\n                if node_count[0] < node_limit or t not in visited]\n\n            # D3 tree uses children vs _children to define what is\n            # expanded or not. The following block makes it such that\n            # repeated nodes are collapsed by default.\n            children_key = 'children'\n            if task.task_id not in expanded:\n                expanded.append(task.task_id)\n            elif children:\n                children_key = \"_children\"\n\n            def set_duration(tid):\n                if (isinstance(tid, dict) and tid.get(\"state\") == State.RUNNING and\n                        tid[\"start_date\"] is not None):\n                    d = timezone.utcnow() - pendulum.parse(tid[\"start_date\"])\n                    tid[\"duration\"] = d.total_seconds()\n                return tid\n\n            return {\n                'name': task.task_id,\n                'instances': [\n                    set_duration(task_instances.get((task.task_id, d))) or {\n                        'execution_date': d.isoformat(),\n                        'task_id': task.task_id\n                    }\n                    for d in dates],\n                children_key: children,\n                'num_dep': len(task.downstream_list),\n                'operator': task.task_type,\n                'retries': task.retries,\n                'owner': task.owner,\n                'start_date': task.start_date,\n                'end_date': task.end_date,\n                'depends_on_past': task.depends_on_past,\n                'ui_color': task.ui_color,\n                'extra_links': task.extra_links,\n            }\n\n        data = {\n            'name': '[DAG]',\n            'children': [recurse_nodes(t, set()) for t in dag.roots],\n            'instances': [\n                dag_runs.get(d) or {'execution_date': d.isoformat()}\n                for d in dates],\n        }\n\n        session.commit()\n\n        form = DateTimeWithNumRunsForm(data={'base_date': max_date,\n                                             'num_runs': num_runs})\n        external_logs = conf.get('elasticsearch', 'frontend')\n        return self.render_template(\n            'airflow/tree.html',\n            operators=sorted({op.__class__ for op in dag.tasks}, key=lambda x: x.__name__),\n            root=root,\n            form=form,\n            dag=dag, data=data, blur=blur, num_runs=num_runs,\n            show_external_logs=bool(external_logs))\n\n    @expose('/graph')\n    @has_dag_access(can_dag_read=True)\n    @has_access\n    @gzipped\n    @action_logging\n    @provide_session\n    def graph(self, session=None):\n        dag_id = request.args.get('dag_id')\n        blur = conf.getboolean('webserver', 'demo_mode')\n        dag = dagbag.get_dag(dag_id)\n        if dag_id not in dagbag.dags:\n            flash('DAG \"{0}\" seems to be missing.'.format(dag_id), \"error\")\n            return redirect(url_for('Airflow.index'))\n\n        root = request.args.get('root')\n        if root:\n            dag = dag.sub_dag(\n                task_regex=root,\n                include_upstream=True,\n                include_downstream=False)\n\n        arrange = request.args.get('arrange', dag.orientation)\n\n        nodes = []\n        edges = []\n        for task in dag.tasks:\n            nodes.append({\n                'id': task.task_id,\n                'value': {\n                    'label': task.task_id,\n                    'labelStyle': \"fill:{0};\".format(task.ui_fgcolor),\n                    'style': \"fill:{0};\".format(task.ui_color),\n                    'rx': 5,\n                    'ry': 5,\n                }\n            })\n\n        def get_downstream(task):\n            for t in task.downstream_list:\n                edge = {\n                    'source_id': task.task_id,\n                    'target_id': t.task_id,\n                }\n                if edge not in edges:\n                    edges.append(edge)\n                    get_downstream(t)\n\n        for t in dag.roots:\n            get_downstream(t)\n\n        dt_nr_dr_data = get_date_time_num_runs_dag_runs_form_data(request, session, dag)\n        dt_nr_dr_data['arrange'] = arrange\n        dttm = dt_nr_dr_data['dttm']\n\n        class GraphForm(DateTimeWithNumRunsWithDagRunsForm):\n            arrange = SelectField(\"Layout\", choices=(\n                ('LR', \"Left->Right\"),\n                ('RL', \"Right->Left\"),\n                ('TB', \"Top->Bottom\"),\n                ('BT', \"Bottom->Top\"),\n            ))\n\n        form = GraphForm(data=dt_nr_dr_data)\n        form.execution_date.choices = dt_nr_dr_data['dr_choices']\n\n        task_instances = {\n            ti.task_id: alchemy_to_dict(ti)\n            for ti in dag.get_task_instances(dttm, dttm)}\n        tasks = {\n            t.task_id: {\n                'dag_id': t.dag_id,\n                'task_type': t.task_type,\n                'extra_links': t.extra_links,\n            }\n            for t in dag.tasks}\n        if not tasks:\n            flash(\"No tasks found\", \"error\")\n        session.commit()\n        doc_md = markdown.markdown(dag.doc_md) \\\n            if hasattr(dag, 'doc_md') and dag.doc_md else ''\n\n        external_logs = conf.get('elasticsearch', 'frontend')\n        return self.render_template(\n            'airflow/graph.html',\n            dag=dag,\n            form=form,\n            width=request.args.get('width', \"100%\"),\n            height=request.args.get('height', \"800\"),\n            execution_date=dttm.isoformat(),\n            state_token=wwwutils.state_token(dt_nr_dr_data['dr_state']),\n            doc_md=doc_md,\n            arrange=arrange,\n            operators=sorted({op.__class__ for op in dag.tasks}, key=lambda x: x.__name__),\n            blur=blur,\n            root=root or '',\n            task_instances=task_instances,\n            tasks=tasks,\n            nodes=nodes,\n            edges=edges,\n            show_external_logs=bool(external_logs))\n\n    @expose('/duration')\n    @has_dag_access(can_dag_read=True)\n    @has_access\n    @action_logging\n    @provide_session\n    def duration(self, session=None):\n        default_dag_run = conf.getint('webserver', 'default_dag_run_display_number')\n        dag_id = request.args.get('dag_id')\n        dag = dagbag.get_dag(dag_id)\n        base_date = request.args.get('base_date')\n        num_runs = request.args.get('num_runs')\n        num_runs = int(num_runs) if num_runs else default_dag_run\n\n        if dag is None:\n            flash('DAG \"{0}\" seems to be missing.'.format(dag_id), \"error\")\n            return redirect(url_for('Airflow.index'))\n\n        if base_date:\n            base_date = pendulum.parse(base_date)\n        else:\n            base_date = dag.latest_execution_date or timezone.utcnow()\n\n        dates = dag.date_range(base_date, num=-abs(num_runs))\n        min_date = dates[0] if dates else timezone.utc_epoch()\n\n        root = request.args.get('root')\n        if root:\n            dag = dag.sub_dag(\n                task_regex=root,\n                include_upstream=True,\n                include_downstream=False)\n\n        chart_height = wwwutils.get_chart_height(dag)\n        chart = nvd3.lineChart(\n            name=\"lineChart\", x_is_date=True, height=chart_height, width=\"1200\")\n        cum_chart = nvd3.lineChart(\n            name=\"cumLineChart\", x_is_date=True, height=chart_height, width=\"1200\")\n\n        y = defaultdict(list)\n        x = defaultdict(list)\n        cum_y = defaultdict(list)\n\n        tis = dag.get_task_instances(start_date=min_date, end_date=base_date)\n        TF = TaskFail\n        ti_fails = (\n            session.query(TF)\n                   .filter(TF.dag_id == dag.dag_id,\n                           TF.execution_date >= min_date,\n                           TF.execution_date <= base_date,\n                           TF.task_id.in_([t.task_id for t in dag.tasks]))\n                   .all()  # noqa\n        )\n\n        fails_totals = defaultdict(int)\n        for tf in ti_fails:\n            dict_key = (tf.dag_id, tf.task_id, tf.execution_date)\n            if tf.duration:\n                fails_totals[dict_key] += tf.duration\n\n        for ti in tis:\n            if ti.duration:\n                dttm = wwwutils.epoch(ti.execution_date)\n                x[ti.task_id].append(dttm)\n                y[ti.task_id].append(float(ti.duration))\n                fails_dict_key = (ti.dag_id, ti.task_id, ti.execution_date)\n                fails_total = fails_totals[fails_dict_key]\n                cum_y[ti.task_id].append(float(ti.duration + fails_total))\n\n        # determine the most relevant time unit for the set of task instance\n        # durations for the DAG\n        y_unit = infer_time_unit([d for t in y.values() for d in t])\n        cum_y_unit = infer_time_unit([d for t in cum_y.values() for d in t])\n        # update the y Axis on both charts to have the correct time units\n        chart.create_y_axis('yAxis', format='.02f', custom_format=False,\n                            label='Duration ({})'.format(y_unit))\n        chart.axislist['yAxis']['axisLabelDistance'] = '40'\n        cum_chart.create_y_axis('yAxis', format='.02f', custom_format=False,\n                                label='Duration ({})'.format(cum_y_unit))\n        cum_chart.axislist['yAxis']['axisLabelDistance'] = '40'\n\n        for task in dag.tasks:\n            if x[task.task_id]:\n                chart.add_serie(name=task.task_id, x=x[task.task_id],\n                                y=scale_time_units(y[task.task_id], y_unit))\n                cum_chart.add_serie(name=task.task_id, x=x[task.task_id],\n                                    y=scale_time_units(cum_y[task.task_id],\n                                                       cum_y_unit))\n\n        dates = sorted(list({ti.execution_date for ti in tis}))\n        max_date = max([ti.execution_date for ti in tis]) if dates else None\n\n        session.commit()\n\n        form = DateTimeWithNumRunsForm(data={'base_date': max_date,\n                                             'num_runs': num_runs})\n        chart.buildcontent()\n        cum_chart.buildcontent()\n        s_index = cum_chart.htmlcontent.rfind('});')\n        cum_chart.htmlcontent = (cum_chart.htmlcontent[:s_index] +\n                                 \"$( document ).trigger('chartload')\" +\n                                 cum_chart.htmlcontent[s_index:])\n\n        return self.render_template(\n            'airflow/duration_chart.html',\n            dag=dag,\n            demo_mode=conf.getboolean('webserver', 'demo_mode'),\n            root=root,\n            form=form,\n            chart=chart.htmlcontent,\n            cum_chart=cum_chart.htmlcontent\n        )\n\n    @expose('/tries')\n    @has_dag_access(can_dag_read=True)\n    @has_access\n    @action_logging\n    @provide_session\n    def tries(self, session=None):\n        default_dag_run = conf.getint('webserver', 'default_dag_run_display_number')\n        dag_id = request.args.get('dag_id')\n        dag = dagbag.get_dag(dag_id)\n        base_date = request.args.get('base_date')\n        num_runs = request.args.get('num_runs')\n        num_runs = int(num_runs) if num_runs else default_dag_run\n\n        if base_date:\n            base_date = pendulum.parse(base_date)\n        else:\n            base_date = dag.latest_execution_date or timezone.utcnow()\n\n        dates = dag.date_range(base_date, num=-abs(num_runs))\n        min_date = dates[0] if dates else timezone.utc_epoch()\n\n        root = request.args.get('root')\n        if root:\n            dag = dag.sub_dag(\n                task_regex=root,\n                include_upstream=True,\n                include_downstream=False)\n\n        chart_height = wwwutils.get_chart_height(dag)\n        chart = nvd3.lineChart(\n            name=\"lineChart\", x_is_date=True, y_axis_format='d', height=chart_height,\n            width=\"1200\")\n\n        for task in dag.tasks:\n            y = []\n            x = []\n            for ti in task.get_task_instances(start_date=min_date, end_date=base_date):\n                dttm = wwwutils.epoch(ti.execution_date)\n                x.append(dttm)\n                y.append(ti.try_number)\n            if x:\n                chart.add_serie(name=task.task_id, x=x, y=y)\n\n        tis = dag.get_task_instances(start_date=min_date, end_date=base_date)\n        tries = sorted(list({ti.try_number for ti in tis}))\n        max_date = max([ti.execution_date for ti in tis]) if tries else None\n\n        session.commit()\n\n        form = DateTimeWithNumRunsForm(data={'base_date': max_date,\n                                             'num_runs': num_runs})\n\n        chart.buildcontent()\n\n        return self.render_template(\n            'airflow/chart.html',\n            dag=dag,\n            demo_mode=conf.getboolean('webserver', 'demo_mode'),\n            root=root,\n            form=form,\n            chart=chart.htmlcontent\n        )\n\n    @expose('/landing_times')\n    @has_dag_access(can_dag_read=True)\n    @has_access\n    @action_logging\n    @provide_session\n    def landing_times(self, session=None):\n        default_dag_run = conf.getint('webserver', 'default_dag_run_display_number')\n        dag_id = request.args.get('dag_id')\n        dag = dagbag.get_dag(dag_id)\n        base_date = request.args.get('base_date')\n        num_runs = request.args.get('num_runs')\n        num_runs = int(num_runs) if num_runs else default_dag_run\n\n        if base_date:\n            base_date = pendulum.parse(base_date)\n        else:\n            base_date = dag.latest_execution_date or timezone.utcnow()\n\n        dates = dag.date_range(base_date, num=-abs(num_runs))\n        min_date = dates[0] if dates else timezone.utc_epoch()\n\n        root = request.args.get('root')\n        if root:\n            dag = dag.sub_dag(\n                task_regex=root,\n                include_upstream=True,\n                include_downstream=False)\n\n        chart_height = wwwutils.get_chart_height(dag)\n        chart = nvd3.lineChart(\n            name=\"lineChart\", x_is_date=True, height=chart_height, width=\"1200\")\n        y = {}\n        x = {}\n        for task in dag.tasks:\n            y[task.task_id] = []\n            x[task.task_id] = []\n            for ti in task.get_task_instances(start_date=min_date, end_date=base_date):\n                ts = ti.execution_date\n                if dag.schedule_interval and dag.following_schedule(ts):\n                    ts = dag.following_schedule(ts)\n                if ti.end_date:\n                    dttm = wwwutils.epoch(ti.execution_date)\n                    secs = (ti.end_date - ts).total_seconds()\n                    x[ti.task_id].append(dttm)\n                    y[ti.task_id].append(secs)\n\n        # determine the most relevant time unit for the set of landing times\n        # for the DAG\n        y_unit = infer_time_unit([d for t in y.values() for d in t])\n        # update the y Axis to have the correct time units\n        chart.create_y_axis('yAxis', format='.02f', custom_format=False,\n                            label='Landing Time ({})'.format(y_unit))\n        chart.axislist['yAxis']['axisLabelDistance'] = '40'\n        for task in dag.tasks:\n            if x[task.task_id]:\n                chart.add_serie(name=task.task_id, x=x[task.task_id],\n                                y=scale_time_units(y[task.task_id], y_unit))\n\n        tis = dag.get_task_instances(start_date=min_date, end_date=base_date)\n        dates = sorted(list({ti.execution_date for ti in tis}))\n        max_date = max([ti.execution_date for ti in tis]) if dates else None\n\n        session.commit()\n\n        form = DateTimeWithNumRunsForm(data={'base_date': max_date,\n                                             'num_runs': num_runs})\n        chart.buildcontent()\n        return self.render_template(\n            'airflow/chart.html',\n            dag=dag,\n            chart=chart.htmlcontent,\n            height=str(chart_height + 100) + \"px\",\n            demo_mode=conf.getboolean('webserver', 'demo_mode'),\n            root=root,\n            form=form,\n        )\n\n    @expose('/paused', methods=['POST'])\n    @has_dag_access(can_dag_edit=True)\n    @has_access\n    @action_logging\n    def paused(self):\n        dag_id = request.args.get('dag_id')\n        is_paused = True if request.args.get('is_paused') == 'false' else False\n        models.DagModel.get_dagmodel(dag_id).set_is_paused(is_paused=is_paused)\n        return \"OK\"\n\n    @expose('/refresh', methods=['POST'])\n    @has_dag_access(can_dag_edit=True)\n    @has_access\n    @action_logging\n    @provide_session\n    def refresh(self, session=None):\n        DagModel = models.DagModel\n        dag_id = request.values.get('dag_id')\n        orm_dag = session.query(\n            DagModel).filter(DagModel.dag_id == dag_id).first()\n\n        if orm_dag:\n            orm_dag.last_expired = timezone.utcnow()\n            session.merge(orm_dag)\n        session.commit()\n\n        dag = dagbag.get_dag(dag_id)\n        # sync dag permission\n        appbuilder.sm.sync_perm_for_dag(dag_id, dag.access_control)\n\n        flash(\"DAG [{}] is now fresh as a daisy\".format(dag_id))\n        return redirect(request.referrer)\n\n    @expose('/refresh_all', methods=['POST'])\n    @has_access\n    @action_logging\n    def refresh_all(self):\n        dagbag.collect_dags(only_if_updated=False)\n        # sync permissions for all dags\n        for dag_id, dag in dagbag.dags.items():\n            appbuilder.sm.sync_perm_for_dag(dag_id, dag.access_control)\n        flash(\"All DAGs are now up to date\")\n        return redirect(url_for('Airflow.index'))\n\n    @expose('/gantt')\n    @has_dag_access(can_dag_read=True)\n    @has_access\n    @action_logging\n    @provide_session\n    def gantt(self, session=None):\n        dag_id = request.args.get('dag_id')\n        dag = dagbag.get_dag(dag_id)\n        demo_mode = conf.getboolean('webserver', 'demo_mode')\n\n        root = request.args.get('root')\n        if root:\n            dag = dag.sub_dag(\n                task_regex=root,\n                include_upstream=True,\n                include_downstream=False)\n\n        dt_nr_dr_data = get_date_time_num_runs_dag_runs_form_data(request, session, dag)\n        dttm = dt_nr_dr_data['dttm']\n\n        form = DateTimeWithNumRunsWithDagRunsForm(data=dt_nr_dr_data)\n        form.execution_date.choices = dt_nr_dr_data['dr_choices']\n\n        tis = [\n            ti for ti in dag.get_task_instances(dttm, dttm)\n            if ti.start_date and ti.state]\n        tis = sorted(tis, key=lambda ti: ti.start_date)\n        TF = TaskFail\n        ti_fails = list(itertools.chain(*[(\n            session\n            .query(TF)\n            .filter(TF.dag_id == ti.dag_id,\n                    TF.task_id == ti.task_id,\n                    TF.execution_date == ti.execution_date)\n            .all()\n        ) for ti in tis]))\n\n        # determine bars to show in the gantt chart\n        gantt_bar_items = []\n        for ti in tis:\n            end_date = ti.end_date or timezone.utcnow()\n            try_count = ti.try_number\n            if ti.state != State.RUNNING:\n                try_count = ti.try_number - 1\n            gantt_bar_items.append((ti.task_id, ti.start_date, end_date, ti.state, try_count))\n\n        tf_count = 0\n        try_count = 1\n        prev_task_id = \"\"\n        for tf in ti_fails:\n            end_date = tf.end_date or timezone.utcnow()\n            if tf_count != 0 and tf.task_id == prev_task_id:\n                try_count = try_count + 1\n            else:\n                try_count = 1\n            prev_task_id = tf.task_id\n            gantt_bar_items.append((tf.task_id, tf.start_date, end_date, State.FAILED, try_count))\n            tf_count = tf_count + 1\n\n        task_types = {}\n        extra_links = {}\n        for t in dag.tasks:\n            task_types[t.task_id] = t.task_type\n            extra_links[t.task_id] = t.extra_links\n\n        tasks = []\n        for gantt_bar_item in gantt_bar_items:\n            task_id = gantt_bar_item[0]\n            start_date = gantt_bar_item[1]\n            end_date = gantt_bar_item[2]\n            state = gantt_bar_item[3]\n            try_count = gantt_bar_item[4]\n            tasks.append({\n                'startDate': wwwutils.epoch(start_date),\n                'endDate': wwwutils.epoch(end_date),\n                'isoStart': start_date.isoformat()[:-4],\n                'isoEnd': end_date.isoformat()[:-4],\n                'taskName': task_id,\n                'taskType': task_types[ti.task_id],\n                'duration': (end_date - start_date).total_seconds(),\n                'status': state,\n                'executionDate': dttm.isoformat(),\n                'try_number': try_count,\n                'extraLinks': extra_links[ti.task_id],\n            })\n\n        states = {task['status']: task['status'] for task in tasks}\n\n        data = {\n            'taskNames': [ti.task_id for ti in tis],\n            'tasks': tasks,\n            'taskStatus': states,\n            'height': len(tis) * 25 + 25,\n        }\n\n        session.commit()\n\n        return self.render_template(\n            'airflow/gantt.html',\n            dag=dag,\n            execution_date=dttm.isoformat(),\n            form=form,\n            data=data,\n            base_date='',\n            demo_mode=demo_mode,\n            root=root,\n        )\n\n    @expose('/extra_links')\n    @has_dag_access(can_dag_read=True)\n    @has_access\n    @action_logging\n    def extra_links(self):\n        \"\"\"\n        A restful endpoint that returns external links for a given Operator\n\n        It queries the operator that sent the request for the links it wishes\n        to provide for a given external link name.\n\n        API: GET\n        Args: dag_id: The id of the dag containing the task in question\n              task_id: The id of the task in question\n              execution_date: The date of execution of the task\n              link_name: The name of the link reference to find the actual URL for\n\n        Returns:\n            200: {url: <url of link>, error: None} - returned when there was no problem\n                finding the URL\n            404: {url: None, error: <error message>} - returned when the operator does\n                not return a URL\n        \"\"\"\n        dag_id = request.args.get('dag_id')\n        task_id = request.args.get('task_id')\n        execution_date = request.args.get('execution_date')\n        link_name = request.args.get('link_name')\n        dttm = airflow.utils.timezone.parse(execution_date)\n        dag = dagbag.get_dag(dag_id)\n\n        if not dag or task_id not in dag.task_ids:\n            response = jsonify(\n                {'url': None,\n                 'error': \"can't find dag {dag} or task_id {task_id}\".format(\n                     dag=dag,\n                     task_id=task_id\n                 )}\n            )\n            response.status_code = 404\n            return response\n\n        task = dag.get_task(task_id)\n\n        try:\n            url = task.get_extra_links(dttm, link_name)\n        except ValueError as err:\n            response = jsonify({'url': None, 'error': str(err)})\n            response.status_code = 404\n            return response\n        if url:\n            response = jsonify({'error': None, 'url': url})\n            response.status_code = 200\n            return response\n        else:\n            response = jsonify(\n                {'url': None, 'error': 'No URL found for {dest}'.format(dest=link_name)})\n            response.status_code = 404\n            return response\n\n    @expose('/object/task_instances')\n    @has_dag_access(can_dag_read=True)\n    @has_access\n    @action_logging\n    @provide_session\n    def task_instances(self, session=None):\n        dag_id = request.args.get('dag_id')\n        dag = dagbag.get_dag(dag_id)\n\n        dttm = request.args.get('execution_date')\n        if dttm:\n            dttm = pendulum.parse(dttm)\n        else:\n            return \"Error: Invalid execution_date\"\n\n        task_instances = {\n            ti.task_id: alchemy_to_dict(ti)\n            for ti in dag.get_task_instances(dttm, dttm)}\n\n        return json.dumps(task_instances)\n\n\nclass VersionView(AirflowBaseView):\n    @expose('/version')\n    @has_access\n    def version(self):\n        try:\n            airflow_version = airflow.__version__\n        except Exception as e:\n            airflow_version = None\n            logging.error(e)\n\n        # Get the Git repo and git hash\n        git_version = None\n        try:\n            with open(os.path.join(*[settings.AIRFLOW_HOME,\n                                   'airflow', 'git_version'])) as f:\n                git_version = f.readline()\n        except Exception as e:\n            logging.error(e)\n\n        # Render information\n        title = \"Version Info\"\n        return self.render_template(\n            'airflow/version.html',\n            title=title,\n            airflow_version=airflow_version,\n            git_version=git_version)\n\n\nclass ConfigurationView(AirflowBaseView):\n    @expose('/configuration')\n    @has_access\n    def conf(self):\n        raw = request.args.get('raw') == \"true\"\n        title = \"Airflow Configuration\"\n        subtitle = AIRFLOW_CONFIG\n        # Don't show config when expose_config variable is False in airflow config\n        if conf.getboolean(\"webserver\", \"expose_config\"):\n            with open(AIRFLOW_CONFIG, 'r') as file:\n                config = file.read()\n            table = [(section, key, value, source)\n                     for section, parameters in conf.as_dict(True, True).items()\n                     for key, (value, source) in parameters.items()]\n        else:\n            config = (\n                \"# Your Airflow administrator chose not to expose the \"\n                \"configuration, most likely for security reasons.\")\n            table = None\n\n        if raw:\n            return Response(\n                response=config,\n                status=200,\n                mimetype=\"application/text\")\n        else:\n            code_html = Markup(highlight(\n                config,\n                lexers.IniLexer(),  # Lexer call\n                HtmlFormatter(noclasses=True))\n            )\n            return self.render_template(\n                'airflow/config.html',\n                pre_subtitle=settings.HEADER + \"  v\" + airflow.__version__,\n                code_html=code_html, title=title, subtitle=subtitle,\n                table=table)\n\n\n######################################################################################\n#                                    ModelViews\n######################################################################################\n\nclass DagFilter(BaseFilter):\n    def apply(self, query, func): # noqa\n        if appbuilder.sm.has_all_dags_access():\n            return query\n        filter_dag_ids = appbuilder.sm.get_accessible_dag_ids()\n        return query.filter(self.model.dag_id.in_(filter_dag_ids))\n\n\nclass AirflowModelView(ModelView):\n    list_widget = AirflowModelListWidget\n    page_size = PAGE_SIZE\n\n    CustomSQLAInterface = wwwutils.CustomSQLAInterface\n\n\nclass SlaMissModelView(AirflowModelView):\n    route_base = '/slamiss'\n\n    datamodel = AirflowModelView.CustomSQLAInterface(SlaMiss)\n\n    base_permissions = ['can_list']\n\n    list_columns = ['dag_id', 'task_id', 'execution_date', 'email_sent', 'timestamp']\n    add_columns = ['dag_id', 'task_id', 'execution_date', 'email_sent', 'timestamp']\n    edit_columns = ['dag_id', 'task_id', 'execution_date', 'email_sent', 'timestamp']\n    search_columns = ['dag_id', 'task_id', 'email_sent', 'timestamp', 'execution_date']\n    base_order = ('execution_date', 'desc')\n    base_filters = [['dag_id', DagFilter, lambda: []]]\n\n    formatters_columns = {\n        'task_id': wwwutils.task_instance_link,\n        'execution_date': wwwutils.datetime_f('execution_date'),\n        'timestamp': wwwutils.datetime_f('timestamp'),\n        'dag_id': wwwutils.dag_link,\n    }\n\n\nclass XComModelView(AirflowModelView):\n    route_base = '/xcom'\n\n    datamodel = AirflowModelView.CustomSQLAInterface(XCom)\n\n    base_permissions = ['can_add', 'can_list', 'can_edit', 'can_delete']\n\n    search_columns = ['key', 'value', 'timestamp', 'execution_date', 'task_id', 'dag_id']\n    list_columns = ['key', 'value', 'timestamp', 'execution_date', 'task_id', 'dag_id']\n    add_columns = ['key', 'value', 'execution_date', 'task_id', 'dag_id']\n    edit_columns = ['key', 'value', 'execution_date', 'task_id', 'dag_id']\n    base_order = ('execution_date', 'desc')\n\n    base_filters = [['dag_id', DagFilter, lambda: []]]\n\n    formatters_columns = {\n        'task_id': wwwutils.task_instance_link,\n        'execution_date': wwwutils.datetime_f('execution_date'),\n        'timestamp': wwwutils.datetime_f('timestamp'),\n        'dag_id': wwwutils.dag_link,\n    }\n\n    @action('muldelete', 'Delete', \"Are you sure you want to delete selected records?\",\n            single=False)\n    def action_muldelete(self, items):\n        self.datamodel.delete_all(items)\n        self.update_redirect()\n        return redirect(self.get_redirect())\n\n    def pre_add(self, item):\n        item.execution_date = timezone.make_aware(item.execution_date)\n        item.value = XCom.serialize_value(item.value)\n\n    def pre_update(self, item):\n        item.execution_date = timezone.make_aware(item.execution_date)\n        item.value = XCom.serialize_value(item.value)\n\n\nclass ConnectionModelView(AirflowModelView):\n    route_base = '/connection'\n\n    datamodel = AirflowModelView.CustomSQLAInterface(Connection)\n\n    base_permissions = ['can_add', 'can_list', 'can_edit', 'can_delete']\n\n    extra_fields = ['extra__jdbc__drv_path', 'extra__jdbc__drv_clsname',\n                    'extra__google_cloud_platform__project',\n                    'extra__google_cloud_platform__key_path',\n                    'extra__google_cloud_platform__keyfile_dict',\n                    'extra__google_cloud_platform__scope',\n                    'extra__google_cloud_platform__num_retries',\n                    'extra__grpc__auth_type',\n                    'extra__grpc__credential_pem_file',\n                    'extra__grpc__scopes']\n    list_columns = ['conn_id', 'conn_type', 'host', 'port', 'is_encrypted',\n                    'is_extra_encrypted']\n    add_columns = edit_columns = ['conn_id', 'conn_type', 'host', 'schema',\n                                  'login', 'password', 'port', 'extra'] + extra_fields\n    add_form = edit_form = ConnectionForm\n    add_template = 'airflow/conn_create.html'\n    edit_template = 'airflow/conn_edit.html'\n\n    base_order = ('conn_id', 'asc')\n\n    @action('muldelete', 'Delete', 'Are you sure you want to delete selected records?',\n            single=False)\n    @has_dag_access(can_dag_edit=True)\n    def action_muldelete(self, items):\n        self.datamodel.delete_all(items)\n        self.update_redirect()\n        return redirect(self.get_redirect())\n\n    def process_form(self, form, is_created):\n        formdata = form.data\n        if formdata['conn_type'] in ['jdbc', 'google_cloud_platform', 'grpc']:\n            extra = {\n                key: formdata[key]\n                for key in self.extra_fields if key in formdata}\n            form.extra.data = json.dumps(extra)\n\n    def prefill_form(self, form, pk):\n        try:\n            d = json.loads(form.data.get('extra', '{}'))\n        except Exception:\n            d = {}\n\n        if not hasattr(d, 'get'):\n            logging.warning('extra field for {} is not iterable'.format(\n                form.data.get('conn_id', '<unknown>')))\n            return\n\n        for field in self.extra_fields:\n            value = d.get(field, '')\n            if value:\n                field = getattr(form, field)\n                field.data = value\n\n\nclass PoolModelView(AirflowModelView):\n    route_base = '/pool'\n\n    datamodel = AirflowModelView.CustomSQLAInterface(models.Pool)\n\n    base_permissions = ['can_add', 'can_list', 'can_edit', 'can_delete']\n\n    list_columns = ['pool', 'slots', 'used_slots', 'queued_slots']\n    add_columns = ['pool', 'slots', 'description']\n    edit_columns = ['pool', 'slots', 'description']\n\n    base_order = ('pool', 'asc')\n\n    @action('muldelete', 'Delete', 'Are you sure you want to delete selected records?',\n            single=False)\n    def action_muldelete(self, items):\n        if any(item.pool == models.Pool.DEFAULT_POOL_NAME for item in items):\n            flash(\"default_pool cannot be deleted\", 'error')\n            self.update_redirect()\n            return redirect(self.get_redirect())\n        self.datamodel.delete_all(items)\n        self.update_redirect()\n        return redirect(self.get_redirect())\n\n    def pool_link(attr):\n        pool_id = attr.get('pool')\n        if pool_id is not None:\n            url = url_for('TaskInstanceModelView.list', _flt_3_pool=pool_id)\n            return Markup(\"<a href='{url}'>{pool_id}</a>\").format(url=url, pool_id=pool_id)\n        else:\n            return Markup('<span class=\"label label-danger\">Invalid</span>')\n\n    def fused_slots(attr):\n        pool_id = attr.get('pool')\n        used_slots = attr.get('used_slots')\n        if pool_id is not None and used_slots is not None:\n            url = url_for('TaskInstanceModelView.list', _flt_3_pool=pool_id, _flt_3_state='running')\n            return Markup(\"<a href='{url}'>{used_slots}</a>\").format(url=url, used_slots=used_slots)\n        else:\n            return Markup('<span class=\"label label-danger\">Invalid</span>')\n\n    def fqueued_slots(attr):\n        pool_id = attr.get('pool')\n        queued_slots = attr.get('queued_slots')\n        if pool_id is not None and queued_slots is not None:\n            url = url_for('TaskInstanceModelView.list', _flt_3_pool=pool_id, _flt_3_state='queued')\n            return Markup(\"<a href='{url}'>{queued_slots}</a>\").format(url=url, queued_slots=queued_slots)\n        else:\n            return Markup('<span class=\"label label-danger\">Invalid</span>')\n\n    formatters_columns = {\n        'pool': pool_link,\n        'used_slots': fused_slots,\n        'queued_slots': fqueued_slots\n    }\n\n    validators_columns = {\n        'pool': [validators.DataRequired()],\n        'slots': [validators.NumberRange(min=0)]\n    }\n\n\nclass VariableModelView(AirflowModelView):\n    route_base = '/variable'\n\n    list_template = 'airflow/variable_list.html'\n    edit_template = 'airflow/variable_edit.html'\n\n    datamodel = AirflowModelView.CustomSQLAInterface(models.Variable)\n\n    base_permissions = ['can_add', 'can_list', 'can_edit', 'can_delete', 'can_varimport']\n\n    list_columns = ['key', 'val', 'is_encrypted']\n    add_columns = ['key', 'val']\n    edit_columns = ['key', 'val']\n    search_columns = ['key', 'val']\n\n    base_order = ('key', 'asc')\n\n    def hidden_field_formatter(attr):\n        key = attr.get('key')\n        val = attr.get('val')\n        if wwwutils.should_hide_value_for_key(key):\n            return Markup('*' * 8)\n        if val:\n            return val\n        else:\n            return Markup('<span class=\"label label-danger\">Invalid</span>')\n\n    formatters_columns = {\n        'val': hidden_field_formatter,\n    }\n\n    validators_columns = {\n        'key': [validators.DataRequired()]\n    }\n\n    def prefill_form(self, form, id):\n        if wwwutils.should_hide_value_for_key(form.key.data):\n            form.val.data = '*' * 8\n\n    @action('muldelete', 'Delete', 'Are you sure you want to delete selected records?',\n            single=False)\n    def action_muldelete(self, items):\n        self.datamodel.delete_all(items)\n        self.update_redirect()\n        return redirect(self.get_redirect())\n\n    @action('varexport', 'Export', '', single=False)\n    def action_varexport(self, items):\n        var_dict = {}\n        d = json.JSONDecoder()\n        for var in items:\n            try:\n                val = d.decode(var.val)\n            except Exception:\n                val = var.val\n            var_dict[var.key] = val\n\n        response = make_response(json.dumps(var_dict, sort_keys=True, indent=4))\n        response.headers[\"Content-Disposition\"] = \"attachment; filename=variables.json\"\n        response.headers[\"Content-Type\"] = \"application/json; charset=utf-8\"\n        return response\n\n    @expose('/varimport', methods=[\"POST\"])\n    @has_access\n    @action_logging\n    def varimport(self):\n        try:\n            out = request.files['file'].read()\n            if isinstance(out, bytes):\n                d = json.loads(out.decode('utf-8'))\n            else:\n                d = json.loads(out)\n        except Exception:\n            self.update_redirect()\n            flash(\"Missing file or syntax error.\", 'error')\n            return redirect(self.get_redirect())\n        else:\n            suc_count = fail_count = 0\n            for k, v in d.items():\n                try:\n                    models.Variable.set(k, v, serialize_json=not isinstance(v, str))\n                except Exception as e:\n                    logging.info('Variable import failed: {}'.format(repr(e)))\n                    fail_count += 1\n                else:\n                    suc_count += 1\n            flash(\"{} variable(s) successfully updated.\".format(suc_count))\n            if fail_count:\n                flash(\"{} variable(s) failed to be updated.\".format(fail_count), 'error')\n            self.update_redirect()\n            return redirect(self.get_redirect())\n\n\nclass JobModelView(AirflowModelView):\n    route_base = '/job'\n\n    datamodel = AirflowModelView.CustomSQLAInterface(jobs.BaseJob)\n\n    base_permissions = ['can_list']\n\n    list_columns = ['id', 'dag_id', 'state', 'job_type', 'start_date',\n                    'end_date', 'latest_heartbeat',\n                    'executor_class', 'hostname', 'unixname']\n    search_columns = ['id', 'dag_id', 'state', 'job_type', 'start_date',\n                      'end_date', 'latest_heartbeat', 'executor_class',\n                      'hostname', 'unixname']\n\n    base_order = ('start_date', 'desc')\n\n    base_filters = [['dag_id', DagFilter, lambda: []]]\n\n    formatters_columns = {\n        'start_date': wwwutils.datetime_f('start_date'),\n        'end_date': wwwutils.datetime_f('end_date'),\n        'hostname': wwwutils.nobr_f('hostname'),\n        'state': wwwutils.state_f,\n        'latest_heartbeat': wwwutils.datetime_f('latest_heartbeat'),\n    }\n\n\nclass DagRunModelView(AirflowModelView):\n    route_base = '/dagrun'\n\n    datamodel = AirflowModelView.CustomSQLAInterface(models.DagRun)\n\n    base_permissions = ['can_list', 'can_add']\n\n    add_columns = ['state', 'dag_id', 'execution_date', 'run_id', 'external_trigger']\n    list_columns = ['state', 'dag_id', 'execution_date', 'run_id', 'external_trigger']\n    search_columns = ['state', 'dag_id', 'execution_date', 'run_id', 'external_trigger']\n\n    base_order = ('execution_date', 'desc')\n\n    base_filters = [['dag_id', DagFilter, lambda: []]]\n\n    add_form = edit_form = DagRunForm\n\n    formatters_columns = {\n        'execution_date': wwwutils.datetime_f('execution_date'),\n        'state': wwwutils.state_f,\n        'start_date': wwwutils.datetime_f('start_date'),\n        'dag_id': wwwutils.dag_link,\n        'run_id': wwwutils.dag_run_link,\n    }\n\n    @action('muldelete', \"Delete\", \"Are you sure you want to delete selected records?\",\n            single=False)\n    @has_dag_access(can_dag_edit=True)\n    @provide_session\n    def action_muldelete(self, items, session=None):\n        self.datamodel.delete_all(items)\n        self.update_redirect()\n        dirty_ids = []\n        for item in items:\n            dirty_ids.append(item.dag_id)\n        return redirect(self.get_redirect())\n\n    @action('set_running', \"Set state to 'running'\", '', single=False)\n    @provide_session\n    def action_set_running(self, drs, session=None):\n        try:\n            DR = models.DagRun\n            count = 0\n            dirty_ids = []\n            for dr in session.query(DR).filter(\n                    DR.id.in_([dagrun.id for dagrun in drs])).all():\n                dirty_ids.append(dr.dag_id)\n                count += 1\n                dr.start_date = timezone.utcnow()\n                dr.state = State.RUNNING\n            session.commit()\n            flash(\"{count} dag runs were set to running\".format(count=count))\n        except Exception as ex:\n            flash(str(ex), 'error')\n            flash('Failed to set state', 'error')\n        return redirect(self.get_default_url())\n\n    @action('set_failed', \"Set state to 'failed'\",\n            \"All running task instances would also be marked as failed, are you sure?\",\n            single=False)\n    @provide_session\n    def action_set_failed(self, drs, session=None):\n        try:\n            DR = models.DagRun\n            count = 0\n            dirty_ids = []\n            altered_tis = []\n            for dr in session.query(DR).filter(\n                    DR.id.in_([dagrun.id for dagrun in drs])).all():\n                dirty_ids.append(dr.dag_id)\n                count += 1\n                altered_tis += \\\n                    set_dag_run_state_to_failed(dagbag.get_dag(dr.dag_id),\n                                                dr.execution_date,\n                                                commit=True,\n                                                session=session)\n            altered_ti_count = len(altered_tis)\n            flash(\n                \"{count} dag runs and {altered_ti_count} task instances \"\n                \"were set to failed\".format(count=count, altered_ti_count=altered_ti_count))\n        except Exception:\n            flash('Failed to set state', 'error')\n        return redirect(self.get_default_url())\n\n    @action('set_success', \"Set state to 'success'\",\n            \"All task instances would also be marked as success, are you sure?\",\n            single=False)\n    @provide_session\n    def action_set_success(self, drs, session=None):\n        try:\n            DR = models.DagRun\n            count = 0\n            dirty_ids = []\n            altered_tis = []\n            for dr in session.query(DR).filter(\n                    DR.id.in_([dagrun.id for dagrun in drs])).all():\n                dirty_ids.append(dr.dag_id)\n                count += 1\n                altered_tis += \\\n                    set_dag_run_state_to_success(dagbag.get_dag(dr.dag_id),\n                                                 dr.execution_date,\n                                                 commit=True,\n                                                 session=session)\n            altered_ti_count = len(altered_tis)\n            flash(\n                \"{count} dag runs and {altered_ti_count} task instances \"\n                \"were set to success\".format(count=count, altered_ti_count=altered_ti_count))\n        except Exception:\n            flash('Failed to set state', 'error')\n        return redirect(self.get_default_url())\n\n\nclass LogModelView(AirflowModelView):\n    route_base = '/log'\n\n    datamodel = AirflowModelView.CustomSQLAInterface(Log)\n\n    base_permissions = ['can_list']\n\n    list_columns = ['id', 'dttm', 'dag_id', 'task_id', 'event', 'execution_date',\n                    'owner', 'extra']\n    search_columns = ['dag_id', 'task_id', 'event', 'execution_date', 'owner', 'extra']\n\n    base_order = ('dttm', 'desc')\n\n    base_filters = [['dag_id', DagFilter, lambda: []]]\n\n    formatters_columns = {\n        'dttm': wwwutils.datetime_f('dttm'),\n        'execution_date': wwwutils.datetime_f('execution_date'),\n        'dag_id': wwwutils.dag_link,\n    }\n\n\nclass TaskInstanceModelView(AirflowModelView):\n    route_base = '/taskinstance'\n\n    datamodel = AirflowModelView.CustomSQLAInterface(models.TaskInstance)\n\n    base_permissions = ['can_list']\n\n    page_size = PAGE_SIZE\n\n    list_columns = ['state', 'dag_id', 'task_id', 'execution_date', 'operator',\n                    'start_date', 'end_date', 'duration', 'job_id', 'hostname',\n                    'unixname', 'priority_weight', 'queue', 'queued_dttm', 'try_number',\n                    'pool', 'log_url']\n\n    search_columns = ['state', 'dag_id', 'task_id', 'execution_date', 'hostname',\n                      'queue', 'pool', 'operator', 'start_date', 'end_date']\n\n    base_order = ('job_id', 'asc')\n\n    base_filters = [['dag_id', DagFilter, lambda: []]]\n\n    def log_url_formatter(attr):\n        log_url = attr.get('log_url')\n        return Markup(\n            '<a href=\"{log_url}\">'\n            '    <span class=\"glyphicon glyphicon-book\" aria-hidden=\"true\">'\n            '</span></a>').format(log_url=log_url)\n\n    def duration_f(attr):\n        end_date = attr.get('end_date')\n        duration = attr.get('duration')\n        if end_date and duration:\n            return timedelta(seconds=duration)\n\n    formatters_columns = {\n        'log_url': log_url_formatter,\n        'task_id': wwwutils.task_instance_link,\n        'hostname': wwwutils.nobr_f('hostname'),\n        'state': wwwutils.state_f,\n        'execution_date': wwwutils.datetime_f('execution_date'),\n        'start_date': wwwutils.datetime_f('start_date'),\n        'end_date': wwwutils.datetime_f('end_date'),\n        'queued_dttm': wwwutils.datetime_f('queued_dttm'),\n        'dag_id': wwwutils.dag_link,\n        'duration': duration_f,\n    }\n\n    @provide_session\n    @action('clear', lazy_gettext('Clear'),\n            lazy_gettext('Are you sure you want to clear the state of the selected task'\n                         ' instance(s) and set their dagruns to the running state?'),\n            single=False)\n    def action_clear(self, tis, session=None):\n        try:\n            dag_to_tis = {}\n\n            for ti in tis:\n                dag = dagbag.get_dag(ti.dag_id)\n                tis = dag_to_tis.setdefault(dag, [])\n                tis.append(ti)\n\n            for dag, tis in dag_to_tis.items():\n                models.clear_task_instances(tis, session, dag=dag)\n\n            session.commit()\n            flash(\"{0} task instances have been cleared\".format(len(tis)))\n            self.update_redirect()\n            return redirect(self.get_redirect())\n\n        except Exception:\n            flash('Failed to clear task instances', 'error')\n\n    @provide_session\n    def set_task_instance_state(self, tis, target_state, session=None):\n        try:\n            count = len(tis)\n            for ti in tis:\n                ti.set_state(target_state, session)\n            session.commit()\n            flash(\"{count} task instances were set to '{target_state}'\".format(\n                count=count, target_state=target_state))\n        except Exception:\n            flash('Failed to set state', 'error')\n\n    @action('set_running', \"Set state to 'running'\", '', single=False)\n    @has_dag_access(can_dag_edit=True)\n    def action_set_running(self, tis):\n        self.set_task_instance_state(tis, State.RUNNING)\n        self.update_redirect()\n        return redirect(self.get_redirect())\n\n    @action('set_failed', \"Set state to 'failed'\", '', single=False)\n    @has_dag_access(can_dag_edit=True)\n    def action_set_failed(self, tis):\n        self.set_task_instance_state(tis, State.FAILED)\n        self.update_redirect()\n        return redirect(self.get_redirect())\n\n    @action('set_success', \"Set state to 'success'\", '', single=False)\n    @has_dag_access(can_dag_edit=True)\n    def action_set_success(self, tis):\n        self.set_task_instance_state(tis, State.SUCCESS)\n        self.update_redirect()\n        return redirect(self.get_redirect())\n\n    @action('set_retry', \"Set state to 'up_for_retry'\", '', single=False)\n    @has_dag_access(can_dag_edit=True)\n    def action_set_retry(self, tis):\n        self.set_task_instance_state(tis, State.UP_FOR_RETRY)\n        self.update_redirect()\n        return redirect(self.get_redirect())\n\n\nclass DagModelView(AirflowModelView):\n    route_base = '/dagmodel'\n\n    datamodel = AirflowModelView.CustomSQLAInterface(models.DagModel)\n\n    base_permissions = ['can_list', 'can_show']\n\n    list_columns = ['dag_id', 'is_paused', 'last_scheduler_run',\n                    'last_expired', 'scheduler_lock', 'fileloc', 'owners']\n\n    formatters_columns = {\n        'dag_id': wwwutils.dag_link\n    }\n\n    base_filters = [['dag_id', DagFilter, lambda: []]]\n\n    def get_query(self):\n        \"\"\"\n        Default filters for model\n        \"\"\"\n        return (\n            super().get_query()\n            .filter(or_(models.DagModel.is_active,\n                        models.DagModel.is_paused))\n            .filter(~models.DagModel.is_subdag)\n        )\n\n    def get_count_query(self):\n        \"\"\"\n        Default filters for model\n        \"\"\"\n        return (\n            super().get_count_query()\n            .filter(models.DagModel.is_active)\n            .filter(~models.DagModel.is_subdag)\n        )\n", "code_before": "# -*- coding: utf-8 -*-\n#\n# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \"License\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n#\n\nimport copy\nimport itertools\nimport json\nimport logging\nimport math\nimport os\nimport socket\nimport traceback\nfrom collections import defaultdict\nfrom datetime import timedelta\nfrom urllib.parse import quote\n\nimport lazy_object_proxy\nimport markdown\nimport pendulum\nimport sqlalchemy as sqla\nfrom flask import Markup, Response, flash, jsonify, make_response, redirect, render_template, request, url_for\nfrom flask_appbuilder import BaseView, ModelView, expose, has_access\nfrom flask_appbuilder.actions import action\nfrom flask_appbuilder.models.sqla.filters import BaseFilter\nfrom flask_babel import lazy_gettext\nfrom pygments import highlight, lexers\nfrom pygments.formatters import HtmlFormatter\nfrom sqlalchemy import and_, desc, or_, union_all\nfrom wtforms import SelectField, validators\n\nimport airflow\nfrom airflow import jobs, models, settings\nfrom airflow._vendor import nvd3\nfrom airflow.api.common.experimental.mark_tasks import (\n    set_dag_run_state_to_failed, set_dag_run_state_to_success,\n)\nfrom airflow.configuration import AIRFLOW_CONFIG, conf\nfrom airflow.models import Connection, DagModel, DagRun, Log, SlaMiss, TaskFail, XCom, errors\nfrom airflow.ti_deps.dep_context import SCHEDULER_QUEUED_DEPS, DepContext\nfrom airflow.utils import timezone\nfrom airflow.utils.dates import infer_time_unit, scale_time_units\nfrom airflow.utils.db import create_session, provide_session\nfrom airflow.utils.helpers import alchemy_to_dict, render_log_filename\nfrom airflow.utils.state import State\nfrom airflow.www import utils as wwwutils\nfrom airflow.www.app import app, appbuilder\nfrom airflow.www.decorators import action_logging, gzipped, has_dag_access\nfrom airflow.www.forms import (\n    ConnectionForm, DagRunForm, DateTimeForm, DateTimeWithNumRunsForm, DateTimeWithNumRunsWithDagRunsForm,\n)\nfrom airflow.www.widgets import AirflowModelListWidget\n\nPAGE_SIZE = conf.getint('webserver', 'page_size')\nif os.environ.get('SKIP_DAGS_PARSING') != 'True':\n    dagbag = models.DagBag(settings.DAGS_FOLDER)\nelse:\n    dagbag = models.DagBag(os.devnull, include_examples=False)\n\n\ndef get_date_time_num_runs_dag_runs_form_data(request, session, dag):\n    dttm = request.args.get('execution_date')\n    if dttm:\n        dttm = pendulum.parse(dttm)\n    else:\n        dttm = dag.latest_execution_date or timezone.utcnow()\n\n    base_date = request.args.get('base_date')\n    if base_date:\n        base_date = timezone.parse(base_date)\n    else:\n        # The DateTimeField widget truncates milliseconds and would loose\n        # the first dag run. Round to next second.\n        base_date = (dttm + timedelta(seconds=1)).replace(microsecond=0)\n\n    default_dag_run = conf.getint('webserver', 'default_dag_run_display_number')\n    num_runs = request.args.get('num_runs')\n    num_runs = int(num_runs) if num_runs else default_dag_run\n\n    DR = models.DagRun\n    drs = (\n        session.query(DR)\n        .filter(\n            DR.dag_id == dag.dag_id,\n            DR.execution_date <= base_date)\n        .order_by(desc(DR.execution_date))\n        .limit(num_runs)\n        .all()\n    )\n    dr_choices = []\n    dr_state = None\n    for dr in drs:\n        dr_choices.append((dr.execution_date.isoformat(), dr.run_id))\n        if dttm == dr.execution_date:\n            dr_state = dr.state\n\n    # Happens if base_date was changed and the selected dag run is not in result\n    if not dr_state and drs:\n        dr = drs[0]\n        dttm = dr.execution_date\n        dr_state = dr.state\n\n    return {\n        'dttm': dttm,\n        'base_date': base_date,\n        'num_runs': num_runs,\n        'execution_date': dttm.isoformat(),\n        'dr_choices': dr_choices,\n        'dr_state': dr_state,\n    }\n\n\n######################################################################################\n#                                    BaseViews\n######################################################################################\n\n@app.errorhandler(404)\ndef circles(error):\n    return render_template(\n        'airflow/circles.html', hostname=socket.getfqdn()), 404\n\n\n@app.errorhandler(500)\ndef show_traceback(error):\n    from airflow.utils import asciiart as ascii_\n    return render_template(\n        'airflow/traceback.html',\n        hostname=socket.getfqdn(),\n        nukular=ascii_.nukular,\n        info=traceback.format_exc()), 500\n\n\nclass AirflowBaseView(BaseView):\n    route_base = ''\n\n    # Make our macros available to our UI templates too.\n    extra_args = {\n        'macros': airflow.macros,\n    }\n\n    def render_template(self, *args, **kwargs):\n        return super().render_template(\n            *args,\n            # Cache this at most once per request, not for the lifetime of the view instance\n            scheduler_job=lazy_object_proxy.Proxy(jobs.SchedulerJob.most_recent_job),\n            **kwargs\n        )\n\n\nclass Airflow(AirflowBaseView):\n    @expose('/health')\n    def health(self):\n        \"\"\"\n        An endpoint helping check the health status of the Airflow instance,\n        including metadatabase and scheduler.\n        \"\"\"\n\n        payload = {\n            'metadatabase': {'status': 'unhealthy'}\n        }\n\n        latest_scheduler_heartbeat = None\n        scheduler_status = 'unhealthy'\n        payload['metadatabase'] = {'status': 'healthy'}\n        try:\n            scheduler_job = jobs.SchedulerJob.most_recent_job()\n\n            if scheduler_job:\n                latest_scheduler_heartbeat = scheduler_job.latest_heartbeat.isoformat()\n                if scheduler_job.is_alive():\n                    scheduler_status = 'healthy'\n        except Exception:\n            payload['metadatabase']['status'] = 'unhealthy'\n\n        payload['scheduler'] = {'status': scheduler_status,\n                                'latest_scheduler_heartbeat': latest_scheduler_heartbeat}\n\n        return wwwutils.json_response(payload)\n\n    @expose('/home')\n    @has_access\n    def index(self):\n        hide_paused_dags_by_default = conf.getboolean('webserver',\n                                                      'hide_paused_dags_by_default')\n        show_paused_arg = request.args.get('showPaused', 'None')\n\n        default_dag_run = conf.getint('webserver', 'default_dag_run_display_number')\n        num_runs = request.args.get('num_runs')\n        num_runs = int(num_runs) if num_runs else default_dag_run\n\n        def get_int_arg(value, default=0):\n            try:\n                return int(value)\n            except ValueError:\n                return default\n\n        arg_current_page = request.args.get('page', '0')\n        arg_search_query = request.args.get('search', None)\n\n        dags_per_page = PAGE_SIZE\n        current_page = get_int_arg(arg_current_page, default=0)\n\n        if show_paused_arg.strip().lower() == 'false':\n            hide_paused = True\n        elif show_paused_arg.strip().lower() == 'true':\n            hide_paused = False\n        else:\n            hide_paused = hide_paused_dags_by_default\n\n        start = current_page * dags_per_page\n        end = start + dags_per_page\n\n        # Get all the dag id the user could access\n        filter_dag_ids = appbuilder.sm.get_accessible_dag_ids()\n\n        with create_session() as session:\n            # read orm_dags from the db\n            dags_query = session.query(DagModel).filter(\n                ~DagModel.is_subdag, DagModel.is_active\n            )\n\n            # optionally filter out \"paused\" dags\n            if hide_paused:\n                dags_query = dags_query.filter(~DagModel.is_paused)\n\n            if arg_search_query:\n                dags_query = dags_query.filter(\n                    DagModel.dag_id.ilike('%' + arg_search_query + '%') |\n                    DagModel.owners.ilike('%' + arg_search_query + '%')\n                )\n\n            if 'all_dags' not in filter_dag_ids:\n                dags_query = dags_query.filter(DagModel.dag_id.in_(filter_dag_ids))\n\n            dags = dags_query.order_by(DagModel.dag_id).offset(start).limit(dags_per_page).all()\n\n            import_errors = session.query(errors.ImportError).all()\n\n        for ie in import_errors:\n            flash(\n                \"Broken DAG: [{ie.filename}] {ie.stacktrace}\".format(ie=ie),\n                \"dag_import_error\")\n\n        from airflow.plugins_manager import import_errors as plugin_import_errors\n        for filename, stacktrace in plugin_import_errors.items():\n            flash(\n                \"Broken plugin: [{filename}] {stacktrace}\".format(\n                    stacktrace=stacktrace,\n                    filename=filename),\n                \"error\")\n\n        num_of_all_dags = dags_query.count()\n        num_of_pages = int(math.ceil(num_of_all_dags / float(dags_per_page)))\n\n        auto_complete_data = set()\n        for row in dags_query.with_entities(DagModel.dag_id, DagModel.owners):\n            auto_complete_data.add(row.dag_id)\n            auto_complete_data.add(row.owners)\n\n        return self.render_template(\n            'airflow/dags.html',\n            dags=dags,\n            hide_paused=hide_paused,\n            current_page=current_page,\n            search_query=arg_search_query if arg_search_query else '',\n            page_size=dags_per_page,\n            num_of_pages=num_of_pages,\n            num_dag_from=min(start + 1, num_of_all_dags),\n            num_dag_to=min(end, num_of_all_dags),\n            num_of_all_dags=num_of_all_dags,\n            paging=wwwutils.generate_pages(current_page, num_of_pages,\n                                           search=arg_search_query,\n                                           showPaused=not hide_paused),\n            auto_complete_data=auto_complete_data,\n            num_runs=num_runs)\n\n    @expose('/dag_stats')\n    @has_access\n    @provide_session\n    def dag_stats(self, session=None):\n        dr = models.DagRun\n\n        filter_dag_ids = appbuilder.sm.get_accessible_dag_ids()\n\n        dag_state_stats = session.query(dr.dag_id, dr.state, sqla.func.count(dr.state))\\\n            .group_by(dr.dag_id, dr.state)\n\n        payload = {}\n        if filter_dag_ids:\n            if 'all_dags' not in filter_dag_ids:\n                dag_state_stats = dag_state_stats.filter(dr.dag_id.in_(filter_dag_ids))\n            data = {}\n            for dag_id, state, count in dag_state_stats:\n                if dag_id not in data:\n                    data[dag_id] = {}\n                data[dag_id][state] = count\n\n            if 'all_dags' in filter_dag_ids:\n                filter_dag_ids = [dag_id for dag_id, in session.query(models.DagModel.dag_id)]\n\n            for dag_id in filter_dag_ids:\n                payload[dag_id] = []\n                for state in State.dag_states:\n                    count = data.get(dag_id, {}).get(state, 0)\n                    payload[dag_id].append({\n                        'state': state,\n                        'count': count,\n                        'dag_id': dag_id,\n                        'color': State.color(state)\n                    })\n        return wwwutils.json_response(payload)\n\n    @expose('/task_stats')\n    @has_access\n    @provide_session\n    def task_stats(self, session=None):\n        TI = models.TaskInstance\n        DagRun = models.DagRun\n        Dag = models.DagModel\n\n        filter_dag_ids = appbuilder.sm.get_accessible_dag_ids()\n\n        payload = {}\n        if not filter_dag_ids:\n            return\n\n        LastDagRun = (\n            session.query(\n                DagRun.dag_id,\n                sqla.func.max(DagRun.execution_date).label('execution_date')\n            )\n            .join(Dag, Dag.dag_id == DagRun.dag_id)\n            .filter(DagRun.state != State.RUNNING, Dag.is_active)\n            .group_by(DagRun.dag_id)\n            .subquery('last_dag_run')\n        )\n        RunningDagRun = (\n            session.query(DagRun.dag_id, DagRun.execution_date)\n                   .join(Dag, Dag.dag_id == DagRun.dag_id)\n                   .filter(DagRun.state == State.RUNNING, Dag.is_active)\n                   .subquery('running_dag_run')\n        )\n\n        # Select all task_instances from active dag_runs.\n        # If no dag_run is active, return task instances from most recent dag_run.\n        LastTI = (\n            session.query(TI.dag_id.label('dag_id'), TI.state.label('state'))\n                   .join(LastDagRun,\n                         and_(LastDagRun.c.dag_id == TI.dag_id,\n                              LastDagRun.c.execution_date == TI.execution_date))\n        )\n        RunningTI = (\n            session.query(TI.dag_id.label('dag_id'), TI.state.label('state'))\n                   .join(RunningDagRun,\n                         and_(RunningDagRun.c.dag_id == TI.dag_id,\n                              RunningDagRun.c.execution_date == TI.execution_date))\n        )\n\n        UnionTI = union_all(LastTI, RunningTI).alias('union_ti')\n        qry = (\n            session.query(UnionTI.c.dag_id, UnionTI.c.state, sqla.func.count())\n                   .group_by(UnionTI.c.dag_id, UnionTI.c.state)\n        )\n\n        data = {}\n        for dag_id, state, count in qry:\n            if 'all_dags' in filter_dag_ids or dag_id in filter_dag_ids:\n                if dag_id not in data:\n                    data[dag_id] = {}\n                data[dag_id][state] = count\n        session.commit()\n\n        if 'all_dags' in filter_dag_ids:\n            filter_dag_ids = [dag_id for dag_id, in session.query(models.DagModel.dag_id)]\n        for dag_id in filter_dag_ids:\n            payload[dag_id] = []\n            for state in State.task_states:\n                count = data.get(dag_id, {}).get(state, 0)\n                payload[dag_id].append({\n                    'state': state,\n                    'count': count,\n                    'dag_id': dag_id,\n                    'color': State.color(state)\n                })\n        return wwwutils.json_response(payload)\n\n    @expose('/last_dagruns')\n    @has_access\n    @provide_session\n    def last_dagruns(self, session=None):\n        DagRun = models.DagRun\n\n        filter_dag_ids = appbuilder.sm.get_accessible_dag_ids()\n\n        if not filter_dag_ids:\n            return\n\n        dags_to_latest_runs = dict(session.query(\n            DagRun.dag_id, sqla.func.max(DagRun.execution_date).label('execution_date'))\n            .group_by(DagRun.dag_id).all())\n\n        payload = {}\n        for dag in dagbag.dags.values():\n            dag_accessible = 'all_dags' in filter_dag_ids or dag.dag_id in filter_dag_ids\n            if (dag_accessible and dag.dag_id in dags_to_latest_runs and\n                    dags_to_latest_runs[dag.dag_id]):\n                payload[dag.safe_dag_id] = {\n                    'dag_id': dag.dag_id,\n                    'last_run': dags_to_latest_runs[dag.dag_id].strftime(\"%Y-%m-%d %H:%M\")\n                }\n\n        return wwwutils.json_response(payload)\n\n    @expose('/code')\n    @has_dag_access(can_dag_read=True)\n    @has_access\n    @provide_session\n    def code(self, session=None):\n        dm = models.DagModel\n        dag_id = request.args.get('dag_id')\n        dag = session.query(dm).filter(dm.dag_id == dag_id).first()\n        try:\n            with wwwutils.open_maybe_zipped(dag.fileloc, 'r') as f:\n                code = f.read()\n            html_code = highlight(\n                code, lexers.PythonLexer(), HtmlFormatter(linenos=True))\n        except OSError as e:\n            html_code = str(e)\n\n        return self.render_template(\n            'airflow/dag_code.html', html_code=html_code, dag=dag, title=dag_id,\n            root=request.args.get('root'),\n            demo_mode=conf.getboolean('webserver', 'demo_mode'),\n            wrapped=conf.getboolean('webserver', 'default_wrap'))\n\n    @expose('/dag_details')\n    @has_dag_access(can_dag_read=True)\n    @has_access\n    @provide_session\n    def dag_details(self, session=None):\n        dag_id = request.args.get('dag_id')\n        dag_orm = DagModel.get_dagmodel(dag_id)\n        # FIXME: items needed for this view should move to the database\n        dag = dag_orm.get_dag()\n        title = \"DAG details\"\n        root = request.args.get('root', '')\n\n        TI = models.TaskInstance\n        states = (\n            session.query(TI.state, sqla.func.count(TI.dag_id))\n                   .filter(TI.dag_id == dag_id)\n                   .group_by(TI.state)\n                   .all()\n        )\n\n        active_runs = models.DagRun.find(\n            dag_id=dag_id,\n            state=State.RUNNING,\n            external_trigger=False\n        )\n\n        return self.render_template(\n            'airflow/dag_details.html',\n            dag=dag, title=title, root=root, states=states, State=State, active_runs=active_runs)\n\n    @expose('/rendered')\n    @has_dag_access(can_dag_read=True)\n    @has_access\n    @action_logging\n    def rendered(self):\n        dag_id = request.args.get('dag_id')\n        task_id = request.args.get('task_id')\n        execution_date = request.args.get('execution_date')\n        dttm = pendulum.parse(execution_date)\n        form = DateTimeForm(data={'execution_date': dttm})\n        root = request.args.get('root', '')\n        dag = dagbag.get_dag(dag_id)\n        task = copy.copy(dag.get_task(task_id))\n        ti = models.TaskInstance(task=task, execution_date=dttm)\n        try:\n            ti.render_templates()\n        except Exception as e:\n            flash(\"Error rendering template: \" + str(e), \"error\")\n        title = \"Rendered Template\"\n        html_dict = {}\n        for template_field in task.__class__.template_fields:\n            content = getattr(task, template_field)\n            if template_field in wwwutils.get_attr_renderer():\n                html_dict[template_field] = \\\n                    wwwutils.get_attr_renderer()[template_field](content)\n            else:\n                html_dict[template_field] = (\n                    \"<pre><code>\" + str(content) + \"</pre></code>\")\n\n        return self.render_template(\n            'airflow/ti_code.html',\n            html_dict=html_dict,\n            dag=dag,\n            task_id=task_id,\n            execution_date=execution_date,\n            form=form,\n            root=root,\n            title=title)\n\n    @expose('/get_logs_with_metadata')\n    @has_dag_access(can_dag_read=True)\n    @has_access\n    @action_logging\n    @provide_session\n    def get_logs_with_metadata(self, session=None):\n        dag_id = request.args.get('dag_id')\n        task_id = request.args.get('task_id')\n        execution_date = request.args.get('execution_date')\n        dttm = pendulum.parse(execution_date)\n        if request.args.get('try_number') is not None:\n            try_number = int(request.args.get('try_number'))\n        else:\n            try_number = None\n        metadata = request.args.get('metadata')\n        metadata = json.loads(metadata)\n        response_format = request.args.get('format', 'json')\n\n        # metadata may be null\n        if not metadata:\n            metadata = {}\n\n        # Convert string datetime into actual datetime\n        try:\n            execution_date = timezone.parse(execution_date)\n        except ValueError:\n            error_message = (\n                'Given execution date, {}, could not be identified '\n                'as a date. Example date format: 2015-11-16T14:34:15+00:00'.format(\n                    execution_date))\n            response = jsonify({'error': error_message})\n            response.status_code = 400\n\n            return response\n\n        logger = logging.getLogger('airflow.task')\n        task_log_reader = conf.get('core', 'task_log_reader')\n        handler = next((handler for handler in logger.handlers\n                        if handler.name == task_log_reader), None)\n\n        ti = session.query(models.TaskInstance).filter(\n            models.TaskInstance.dag_id == dag_id,\n            models.TaskInstance.task_id == task_id,\n            models.TaskInstance.execution_date == dttm).first()\n\n        def _get_logs_with_metadata(try_number, metadata):\n            if ti is None:\n                logs = [\"*** Task instance did not exist in the DB\\n\"]\n                metadata['end_of_log'] = True\n            else:\n                logs, metadatas = handler.read(ti, try_number, metadata=metadata)\n                metadata = metadatas[0]\n            return logs, metadata\n\n        try:\n            if ti is not None:\n                dag = dagbag.get_dag(dag_id)\n                ti.task = dag.get_task(ti.task_id)\n            if response_format == 'json':\n                logs, metadata = _get_logs_with_metadata(try_number, metadata)\n                message = logs[0] if try_number is not None else logs\n                return jsonify(message=message, metadata=metadata)\n\n            filename_template = conf.get('core', 'LOG_FILENAME_TEMPLATE')\n            attachment_filename = render_log_filename(\n                ti=ti,\n                try_number=\"all\" if try_number is None else try_number,\n                filename_template=filename_template)\n            metadata['download_logs'] = True\n\n            def _generate_log_stream(try_number, metadata):\n                if try_number is None and ti is not None:\n                    next_try = ti.next_try_number\n                    try_numbers = list(range(1, next_try))\n                else:\n                    try_numbers = [try_number]\n                for try_number in try_numbers:\n                    metadata.pop('end_of_log', None)\n                    metadata.pop('max_offset', None)\n                    metadata.pop('offset', None)\n                    while 'end_of_log' not in metadata or not metadata['end_of_log']:\n                        logs, metadata = _get_logs_with_metadata(try_number, metadata)\n                        yield \"\\n\".join(logs) + \"\\n\"\n            return Response(_generate_log_stream(try_number, metadata),\n                            mimetype=\"text/plain\",\n                            headers={\"Content-Disposition\": \"attachment; filename={}\".format(\n                                attachment_filename)})\n        except AttributeError as e:\n            error_message = [\"Task log handler {} does not support read logs.\\n{}\\n\"\n                             .format(task_log_reader, str(e))]\n            metadata['end_of_log'] = True\n            return jsonify(message=error_message, error=True, metadata=metadata)\n\n    @expose('/log')\n    @has_dag_access(can_dag_read=True)\n    @has_access\n    @action_logging\n    @provide_session\n    def log(self, session=None):\n        dag_id = request.args.get('dag_id')\n        task_id = request.args.get('task_id')\n        execution_date = request.args.get('execution_date')\n        dttm = pendulum.parse(execution_date)\n        form = DateTimeForm(data={'execution_date': dttm})\n        dag_model = DagModel.get_dagmodel(dag_id)\n\n        ti = session.query(models.TaskInstance).filter(\n            models.TaskInstance.dag_id == dag_id,\n            models.TaskInstance.task_id == task_id,\n            models.TaskInstance.execution_date == dttm).first()\n\n        num_logs = 0\n        if ti is not None:\n            num_logs = ti.next_try_number - 1\n            if ti.state == State.UP_FOR_RESCHEDULE:\n                # Tasks in reschedule state decremented the try number\n                num_logs += 1\n        logs = [''] * num_logs\n        root = request.args.get('root', '')\n        return self.render_template(\n            'airflow/ti_log.html',\n            logs=logs, dag=dag_model, title=\"Log by attempts\",\n            dag_id=dag_id, task_id=task_id,\n            execution_date=execution_date, form=form,\n            root=root, wrapped=conf.getboolean('webserver', 'default_wrap'))\n\n    @expose('/elasticsearch')\n    @has_dag_access(can_dag_read=True)\n    @has_access\n    @action_logging\n    @provide_session\n    def elasticsearch(self, session=None):\n        dag_id = request.args.get('dag_id')\n        task_id = request.args.get('task_id')\n        execution_date = request.args.get('execution_date')\n        try_number = request.args.get('try_number', 1)\n        elasticsearch_frontend = conf.get('elasticsearch', 'frontend')\n        log_id_template = conf.get('elasticsearch', 'log_id_template')\n        log_id = log_id_template.format(\n            dag_id=dag_id, task_id=task_id,\n            execution_date=execution_date, try_number=try_number)\n        url = 'https://' + elasticsearch_frontend.format(log_id=quote(log_id))\n        return redirect(url)\n\n    @expose('/task')\n    @has_dag_access(can_dag_read=True)\n    @has_access\n    @action_logging\n    def task(self):\n        TI = models.TaskInstance\n\n        dag_id = request.args.get('dag_id')\n        task_id = request.args.get('task_id')\n        # Carrying execution_date through, even though it's irrelevant for\n        # this context\n        execution_date = request.args.get('execution_date')\n        dttm = pendulum.parse(execution_date)\n        form = DateTimeForm(data={'execution_date': dttm})\n        root = request.args.get('root', '')\n        dag = dagbag.get_dag(dag_id)\n\n        if not dag or task_id not in dag.task_ids:\n            flash(\n                \"Task [{}.{}] doesn't seem to exist\"\n                \" at the moment\".format(dag_id, task_id),\n                \"error\")\n            return redirect(url_for('Airflow.index'))\n        task = copy.copy(dag.get_task(task_id))\n        task.resolve_template_files()\n        ti = TI(task=task, execution_date=dttm)\n        ti.refresh_from_db()\n\n        ti_attrs = []\n        for attr_name in dir(ti):\n            if not attr_name.startswith('_'):\n                attr = getattr(ti, attr_name)\n                if type(attr) != type(self.task):  # noqa\n                    ti_attrs.append((attr_name, str(attr)))\n\n        task_attrs = []\n        for attr_name in dir(task):\n            if not attr_name.startswith('_'):\n                attr = getattr(task, attr_name)\n                if type(attr) != type(self.task) and \\\n                        attr_name not in wwwutils.get_attr_renderer():  # noqa\n                    task_attrs.append((attr_name, str(attr)))\n\n        # Color coding the special attributes that are code\n        special_attrs_rendered = {}\n        for attr_name in wwwutils.get_attr_renderer():\n            if hasattr(task, attr_name):\n                source = getattr(task, attr_name)\n                special_attrs_rendered[attr_name] = \\\n                    wwwutils.get_attr_renderer()[attr_name](source)\n\n        no_failed_deps_result = [(\n            \"Unknown\",\n            \"All dependencies are met but the task instance is not running. In most \"\n            \"cases this just means that the task will probably be scheduled soon \"\n            \"unless:<br/>\\n- The scheduler is down or under heavy load<br/>\\n{}\\n\"\n            \"<br/>\\nIf this task instance does not start soon please contact your \"\n            \"Airflow administrator for assistance.\".format(\n                \"- This task instance already ran and had it's state changed manually \"\n                \"(e.g. cleared in the UI)<br/>\" if ti.state == State.NONE else \"\"))]\n\n        # Use the scheduler's context to figure out which dependencies are not met\n        dep_context = DepContext(SCHEDULER_QUEUED_DEPS)\n        failed_dep_reasons = [(dep.dep_name, dep.reason) for dep in\n                              ti.get_failed_dep_statuses(\n                                  dep_context=dep_context)]\n\n        title = \"Task Instance Details\"\n        return self.render_template(\n            'airflow/task.html',\n            task_attrs=task_attrs,\n            ti_attrs=ti_attrs,\n            failed_dep_reasons=failed_dep_reasons or no_failed_deps_result,\n            task_id=task_id,\n            execution_date=execution_date,\n            special_attrs_rendered=special_attrs_rendered,\n            form=form,\n            root=root,\n            dag=dag, title=title)\n\n    @expose('/xcom')\n    @has_dag_access(can_dag_read=True)\n    @has_access\n    @action_logging\n    @provide_session\n    def xcom(self, session=None):\n        dag_id = request.args.get('dag_id')\n        task_id = request.args.get('task_id')\n        # Carrying execution_date through, even though it's irrelevant for\n        # this context\n        execution_date = request.args.get('execution_date')\n        dttm = pendulum.parse(execution_date)\n        form = DateTimeForm(data={'execution_date': dttm})\n        root = request.args.get('root', '')\n        dm_db = models.DagModel\n        ti_db = models.TaskInstance\n        dag = session.query(dm_db).filter(dm_db.dag_id == dag_id).first()\n        ti = session.query(ti_db).filter(ti_db.dag_id == dag_id and ti_db.task_id == task_id).first()\n\n        if not ti:\n            flash(\n                \"Task [{}.{}] doesn't seem to exist\"\n                \" at the moment\".format(dag_id, task_id),\n                \"error\")\n            return redirect(url_for('Airflow.index'))\n\n        xcomlist = session.query(XCom).filter(\n            XCom.dag_id == dag_id, XCom.task_id == task_id,\n            XCom.execution_date == dttm).all()\n\n        attributes = []\n        for xcom in xcomlist:\n            if not xcom.key.startswith('_'):\n                attributes.append((xcom.key, xcom.value))\n\n        title = \"XCom\"\n        return self.render_template(\n            'airflow/xcom.html',\n            attributes=attributes,\n            task_id=task_id,\n            execution_date=execution_date,\n            form=form,\n            root=root,\n            dag=dag, title=title)\n\n    @expose('/run', methods=['POST'])\n    @has_dag_access(can_dag_edit=True)\n    @has_access\n    @action_logging\n    def run(self):\n        dag_id = request.form.get('dag_id')\n        task_id = request.form.get('task_id')\n        origin = request.form.get('origin')\n        dag = dagbag.get_dag(dag_id)\n        task = dag.get_task(task_id)\n\n        execution_date = request.form.get('execution_date')\n        execution_date = pendulum.parse(execution_date)\n        ignore_all_deps = request.form.get('ignore_all_deps') == \"true\"\n        ignore_task_deps = request.form.get('ignore_task_deps') == \"true\"\n        ignore_ti_state = request.form.get('ignore_ti_state') == \"true\"\n\n        from airflow.executors import get_default_executor\n        executor = get_default_executor()\n        valid_celery_config = False\n        valid_kubernetes_config = False\n\n        try:\n            from airflow.executors.celery_executor import CeleryExecutor\n            valid_celery_config = isinstance(executor, CeleryExecutor)\n        except ImportError:\n            pass\n\n        try:\n            from airflow.executors.kubernetes_executor import KubernetesExecutor\n            valid_kubernetes_config = isinstance(executor, KubernetesExecutor)\n        except ImportError:\n            pass\n\n        if not valid_celery_config and not valid_kubernetes_config:\n            flash(\"Only works with the Celery or Kubernetes executors, sorry\", \"error\")\n            return redirect(origin)\n\n        ti = models.TaskInstance(task=task, execution_date=execution_date)\n        ti.refresh_from_db()\n\n        # Make sure the task instance can be queued\n        dep_context = DepContext(\n            deps=SCHEDULER_QUEUED_DEPS,\n            ignore_all_deps=ignore_all_deps,\n            ignore_task_deps=ignore_task_deps,\n            ignore_ti_state=ignore_ti_state)\n        failed_deps = list(ti.get_failed_dep_statuses(dep_context=dep_context))\n        if failed_deps:\n            failed_deps_str = \", \".join(\n                [\"{}: {}\".format(dep.dep_name, dep.reason) for dep in failed_deps])\n            flash(\"Could not queue task instance for execution, dependencies not met: \"\n                  \"{}\".format(failed_deps_str),\n                  \"error\")\n            return redirect(origin)\n\n        executor.start()\n        executor.queue_task_instance(\n            ti,\n            ignore_all_deps=ignore_all_deps,\n            ignore_task_deps=ignore_task_deps,\n            ignore_ti_state=ignore_ti_state)\n        executor.heartbeat()\n        flash(\n            \"Sent {} to the message queue, \"\n            \"it should start any moment now.\".format(ti))\n        return redirect(origin)\n\n    @expose('/delete', methods=['POST'])\n    @has_dag_access(can_dag_edit=True)\n    @has_access\n    @action_logging\n    def delete(self):\n        from airflow.api.common.experimental import delete_dag\n        from airflow.exceptions import DagNotFound, DagFileExists\n\n        dag_id = request.values.get('dag_id')\n        origin = request.values.get('origin') or url_for('Airflow.index')\n\n        try:\n            delete_dag.delete_dag(dag_id)\n        except DagNotFound:\n            flash(\"DAG with id {} not found. Cannot delete\".format(dag_id), 'error')\n            return redirect(request.referrer)\n        except DagFileExists:\n            flash(\"Dag id {} is still in DagBag. \"\n                  \"Remove the DAG file first.\".format(dag_id),\n                  'error')\n            return redirect(request.referrer)\n\n        flash(\"Deleting DAG with id {}. May take a couple minutes to fully\"\n              \" disappear.\".format(dag_id))\n\n        # Upon success return to origin.\n        return redirect(origin)\n\n    @expose('/trigger', methods=['POST'])\n    @has_dag_access(can_dag_edit=True)\n    @has_access\n    @action_logging\n    @provide_session\n    def trigger(self, session=None):\n        dag_id = request.values.get('dag_id')\n        origin = request.values.get('origin') or url_for('Airflow.index')\n        dag = session.query(models.DagModel).filter(models.DagModel.dag_id == dag_id).first()\n        if not dag:\n            flash(\"Cannot find dag {}\".format(dag_id))\n            return redirect(origin)\n\n        execution_date = timezone.utcnow()\n        run_id = \"manual__{0}\".format(execution_date.isoformat())\n\n        dr = DagRun.find(dag_id=dag_id, run_id=run_id)\n        if dr:\n            flash(\"This run_id {} already exists\".format(run_id))\n            return redirect(origin)\n\n        run_conf = {}\n\n        dag.create_dagrun(\n            run_id=run_id,\n            execution_date=execution_date,\n            state=State.RUNNING,\n            conf=run_conf,\n            external_trigger=True\n        )\n\n        flash(\n            \"Triggered {}, \"\n            \"it should start any moment now.\".format(dag_id))\n        return redirect(origin)\n\n    def _clear_dag_tis(self, dag, start_date, end_date, origin,\n                       recursive=False, confirmed=False, only_failed=False):\n        if confirmed:\n            count = dag.clear(\n                start_date=start_date,\n                end_date=end_date,\n                include_subdags=recursive,\n                include_parentdag=recursive,\n                only_failed=only_failed,\n            )\n\n            flash(\"{0} task instances have been cleared\".format(count))\n            return redirect(origin)\n\n        tis = dag.clear(\n            start_date=start_date,\n            end_date=end_date,\n            include_subdags=recursive,\n            include_parentdag=recursive,\n            only_failed=only_failed,\n            dry_run=True,\n        )\n        if not tis:\n            flash(\"No task instances to clear\", 'error')\n            response = redirect(origin)\n        else:\n            details = \"\\n\".join([str(t) for t in tis])\n\n            response = self.render_template(\n                'airflow/confirm.html',\n                message=(\"Here's the list of task instances you are about \"\n                         \"to clear:\"),\n                details=details)\n\n        return response\n\n    @expose('/clear', methods=['POST'])\n    @has_dag_access(can_dag_edit=True)\n    @has_access\n    @action_logging\n    def clear(self):\n        dag_id = request.form.get('dag_id')\n        task_id = request.form.get('task_id')\n        origin = request.form.get('origin')\n        dag = dagbag.get_dag(dag_id)\n\n        execution_date = request.form.get('execution_date')\n        execution_date = pendulum.parse(execution_date)\n        confirmed = request.form.get('confirmed') == \"true\"\n        upstream = request.form.get('upstream') == \"true\"\n        downstream = request.form.get('downstream') == \"true\"\n        future = request.form.get('future') == \"true\"\n        past = request.form.get('past') == \"true\"\n        recursive = request.form.get('recursive') == \"true\"\n        only_failed = request.form.get('only_failed') == \"true\"\n\n        dag = dag.sub_dag(\n            task_regex=r\"^{0}$\".format(task_id),\n            include_downstream=downstream,\n            include_upstream=upstream)\n\n        end_date = execution_date if not future else None\n        start_date = execution_date if not past else None\n\n        return self._clear_dag_tis(dag, start_date, end_date, origin,\n                                   recursive=recursive, confirmed=confirmed, only_failed=only_failed)\n\n    @expose('/dagrun_clear', methods=['POST'])\n    @has_dag_access(can_dag_edit=True)\n    @has_access\n    @action_logging\n    def dagrun_clear(self):\n        dag_id = request.form.get('dag_id')\n        origin = request.form.get('origin')\n        execution_date = request.form.get('execution_date')\n        confirmed = request.form.get('confirmed') == \"true\"\n\n        dag = dagbag.get_dag(dag_id)\n        execution_date = pendulum.parse(execution_date)\n        start_date = execution_date\n        end_date = execution_date\n\n        return self._clear_dag_tis(dag, start_date, end_date, origin,\n                                   recursive=True, confirmed=confirmed)\n\n    @expose('/blocked')\n    @has_access\n    @provide_session\n    def blocked(self, session=None):\n        DR = models.DagRun\n        filter_dag_ids = appbuilder.sm.get_accessible_dag_ids()\n\n        payload = []\n        if filter_dag_ids:\n            dags = (\n                session.query(DR.dag_id, sqla.func.count(DR.id))\n                       .filter(DR.state == State.RUNNING)\n                       .group_by(DR.dag_id)\n\n            )\n            if 'all_dags' not in filter_dag_ids:\n                dags = dags.filter(DR.dag_id.in_(filter_dag_ids))\n            dags = dags.all()\n\n            for dag_id, active_dag_runs in dags:\n                max_active_runs = 0\n                if dag_id in dagbag.dags:\n                    max_active_runs = dagbag.dags[dag_id].max_active_runs\n                payload.append({\n                    'dag_id': dag_id,\n                    'active_dag_run': active_dag_runs,\n                    'max_active_runs': max_active_runs,\n                })\n        return wwwutils.json_response(payload)\n\n    def _mark_dagrun_state_as_failed(self, dag_id, execution_date, confirmed, origin):\n        if not execution_date:\n            flash('Invalid execution date', 'error')\n            return redirect(origin)\n\n        execution_date = pendulum.parse(execution_date)\n        dag = dagbag.get_dag(dag_id)\n\n        if not dag:\n            flash('Cannot find DAG: {}'.format(dag_id), 'error')\n            return redirect(origin)\n\n        new_dag_state = set_dag_run_state_to_failed(dag, execution_date, commit=confirmed)\n\n        if confirmed:\n            flash('Marked failed on {} task instances'.format(len(new_dag_state)))\n            return redirect(origin)\n\n        else:\n            details = '\\n'.join([str(t) for t in new_dag_state])\n\n            response = self.render_template(\n                'airflow/confirm.html',\n                message=(\"Here's the list of task instances you are about to mark as failed\"),\n                details=details)\n\n            return response\n\n    def _mark_dagrun_state_as_success(self, dag_id, execution_date, confirmed, origin):\n        if not execution_date:\n            flash('Invalid execution date', 'error')\n            return redirect(origin)\n\n        execution_date = pendulum.parse(execution_date)\n        dag = dagbag.get_dag(dag_id)\n\n        if not dag:\n            flash('Cannot find DAG: {}'.format(dag_id), 'error')\n            return redirect(origin)\n\n        new_dag_state = set_dag_run_state_to_success(dag, execution_date,\n                                                     commit=confirmed)\n\n        if confirmed:\n            flash('Marked success on {} task instances'.format(len(new_dag_state)))\n            return redirect(origin)\n\n        else:\n            details = '\\n'.join([str(t) for t in new_dag_state])\n\n            response = self.render_template(\n                'airflow/confirm.html',\n                message=(\"Here's the list of task instances you are about to mark as success\"),\n                details=details)\n\n            return response\n\n    @expose('/dagrun_failed', methods=['POST'])\n    @has_dag_access(can_dag_edit=True)\n    @has_access\n    @action_logging\n    def dagrun_failed(self):\n        dag_id = request.form.get('dag_id')\n        execution_date = request.form.get('execution_date')\n        confirmed = request.form.get('confirmed') == 'true'\n        origin = request.form.get('origin')\n        return self._mark_dagrun_state_as_failed(dag_id, execution_date,\n                                                 confirmed, origin)\n\n    @expose('/dagrun_success', methods=['POST'])\n    @has_dag_access(can_dag_edit=True)\n    @has_access\n    @action_logging\n    def dagrun_success(self):\n        dag_id = request.form.get('dag_id')\n        execution_date = request.form.get('execution_date')\n        confirmed = request.form.get('confirmed') == 'true'\n        origin = request.form.get('origin')\n        return self._mark_dagrun_state_as_success(dag_id, execution_date,\n                                                  confirmed, origin)\n\n    def _mark_task_instance_state(self, dag_id, task_id, origin, execution_date,\n                                  confirmed, upstream, downstream,\n                                  future, past, state):\n        dag = dagbag.get_dag(dag_id)\n        task = dag.get_task(task_id)\n        task.dag = dag\n\n        execution_date = pendulum.parse(execution_date)\n\n        if not dag:\n            flash(\"Cannot find DAG: {}\".format(dag_id))\n            return redirect(origin)\n\n        if not task:\n            flash(\"Cannot find task {} in DAG {}\".format(task_id, dag.dag_id))\n            return redirect(origin)\n\n        from airflow.api.common.experimental.mark_tasks import set_state\n\n        if confirmed:\n            altered = set_state(tasks=[task], execution_date=execution_date,\n                                upstream=upstream, downstream=downstream,\n                                future=future, past=past, state=state,\n                                commit=True)\n\n            flash(\"Marked {} on {} task instances\".format(state, len(altered)))\n            return redirect(origin)\n\n        to_be_altered = set_state(tasks=[task], execution_date=execution_date,\n                                  upstream=upstream, downstream=downstream,\n                                  future=future, past=past, state=state,\n                                  commit=False)\n\n        details = \"\\n\".join([str(t) for t in to_be_altered])\n\n        response = self.render_template(\n            \"airflow/confirm.html\",\n            message=(\"Here's the list of task instances you are about to mark as {}:\".format(state)),\n            details=details)\n\n        return response\n\n    @expose('/failed', methods=['POST'])\n    @has_dag_access(can_dag_edit=True)\n    @has_access\n    @action_logging\n    def failed(self):\n        dag_id = request.form.get('dag_id')\n        task_id = request.form.get('task_id')\n        origin = request.form.get('origin')\n        execution_date = request.form.get('execution_date')\n\n        confirmed = request.form.get('confirmed') == \"true\"\n        upstream = request.form.get('failed_upstream') == \"true\"\n        downstream = request.form.get('failed_downstream') == \"true\"\n        future = request.form.get('failed_future') == \"true\"\n        past = request.form.get('failed_past') == \"true\"\n\n        return self._mark_task_instance_state(dag_id, task_id, origin, execution_date,\n                                              confirmed, upstream, downstream,\n                                              future, past, State.FAILED)\n\n    @expose('/success', methods=['POST'])\n    @has_dag_access(can_dag_edit=True)\n    @has_access\n    @action_logging\n    def success(self):\n        dag_id = request.form.get('dag_id')\n        task_id = request.form.get('task_id')\n        origin = request.form.get('origin')\n        execution_date = request.form.get('execution_date')\n\n        confirmed = request.form.get('confirmed') == \"true\"\n        upstream = request.form.get('success_upstream') == \"true\"\n        downstream = request.form.get('success_downstream') == \"true\"\n        future = request.form.get('success_future') == \"true\"\n        past = request.form.get('success_past') == \"true\"\n\n        return self._mark_task_instance_state(dag_id, task_id, origin, execution_date,\n                                              confirmed, upstream, downstream,\n                                              future, past, State.SUCCESS)\n\n    @expose('/tree')\n    @has_dag_access(can_dag_read=True)\n    @has_access\n    @gzipped\n    @action_logging\n    def tree(self):\n        default_dag_run = conf.getint('webserver', 'default_dag_run_display_number')\n        dag_id = request.args.get('dag_id')\n        blur = conf.getboolean('webserver', 'demo_mode')\n        dag_model = DagModel.get_dagmodel(dag_id)\n        if not dag_model:\n            flash('DAG \"{0}\" seems to be missing in database.'.format(dag_id), \"error\")\n            return redirect(url_for('Airflow.index'))\n        dag = dag_model.get_dag()\n\n        if dag is None:\n            dag = dagbag.get_dag(dag_id)\n            if dag is None:\n                flash('DAG \"{0}\" seems to be missing from DagBag.'.format(dag_id), \"error\")\n                return redirect(url_for('Airflow.index'))\n\n        root = request.args.get('root')\n        if root:\n            dag = dag.sub_dag(\n                task_regex=root,\n                include_downstream=False,\n                include_upstream=True)\n\n        base_date = request.args.get('base_date')\n        num_runs = request.args.get('num_runs')\n        num_runs = int(num_runs) if num_runs else default_dag_run\n\n        if base_date:\n            base_date = timezone.parse(base_date)\n        else:\n            base_date = dag.latest_execution_date or timezone.utcnow()\n\n        with create_session() as session:\n            dag_runs = (\n                session.query(DagRun)\n                .filter(\n                    DagRun.dag_id == dag.dag_id,\n                    DagRun.execution_date <= base_date)\n                .order_by(DagRun.execution_date.desc())\n                .limit(num_runs)\n                .all()\n            )\n        dag_runs = {\n            dr.execution_date: alchemy_to_dict(dr) for dr in dag_runs}\n\n        dates = sorted(list(dag_runs.keys()))\n        max_date = max(dates) if dates else None\n        min_date = min(dates) if dates else None\n\n        tis = dag.get_task_instances(start_date=min_date, end_date=base_date)\n        task_instances = {}\n        for ti in tis:\n            tid = alchemy_to_dict(ti)\n            dr = dag_runs.get(ti.execution_date)\n            tid['external_trigger'] = dr['external_trigger'] if dr else False\n            task_instances[(ti.task_id, ti.execution_date)] = tid\n\n        expanded = []\n        # The default recursion traces every path so that tree view has full\n        # expand/collapse functionality. After 5,000 nodes we stop and fall\n        # back on a quick DFS search for performance. See PR #320.\n        node_count = [0]\n        node_limit = 5000 / max(1, len(dag.leaves))\n\n        def recurse_nodes(task, visited):\n            visited.add(task)\n            node_count[0] += 1\n\n            children = [\n                recurse_nodes(t, visited) for t in task.downstream_list\n                if node_count[0] < node_limit or t not in visited]\n\n            # D3 tree uses children vs _children to define what is\n            # expanded or not. The following block makes it such that\n            # repeated nodes are collapsed by default.\n            children_key = 'children'\n            if task.task_id not in expanded:\n                expanded.append(task.task_id)\n            elif children:\n                children_key = \"_children\"\n\n            def set_duration(tid):\n                if (isinstance(tid, dict) and tid.get(\"state\") == State.RUNNING and\n                        tid[\"start_date\"] is not None):\n                    d = timezone.utcnow() - pendulum.parse(tid[\"start_date\"])\n                    tid[\"duration\"] = d.total_seconds()\n                return tid\n\n            return {\n                'name': task.task_id,\n                'instances': [\n                    set_duration(task_instances.get((task.task_id, d))) or {\n                        'execution_date': d.isoformat(),\n                        'task_id': task.task_id\n                    }\n                    for d in dates],\n                children_key: children,\n                'num_dep': len(task.downstream_list),\n                'operator': task.task_type,\n                'retries': task.retries,\n                'owner': task.owner,\n                'start_date': task.start_date,\n                'end_date': task.end_date,\n                'depends_on_past': task.depends_on_past,\n                'ui_color': task.ui_color,\n                'extra_links': task.extra_links,\n            }\n\n        data = {\n            'name': '[DAG]',\n            'children': [recurse_nodes(t, set()) for t in dag.roots],\n            'instances': [\n                dag_runs.get(d) or {'execution_date': d.isoformat()}\n                for d in dates],\n        }\n\n        session.commit()\n\n        form = DateTimeWithNumRunsForm(data={'base_date': max_date,\n                                             'num_runs': num_runs})\n        external_logs = conf.get('elasticsearch', 'frontend')\n        return self.render_template(\n            'airflow/tree.html',\n            operators=sorted({op.__class__ for op in dag.tasks}, key=lambda x: x.__name__),\n            root=root,\n            form=form,\n            dag=dag, data=data, blur=blur, num_runs=num_runs,\n            show_external_logs=bool(external_logs))\n\n    @expose('/graph')\n    @has_dag_access(can_dag_read=True)\n    @has_access\n    @gzipped\n    @action_logging\n    @provide_session\n    def graph(self, session=None):\n        dag_id = request.args.get('dag_id')\n        blur = conf.getboolean('webserver', 'demo_mode')\n        dag = dagbag.get_dag(dag_id)\n        if dag_id not in dagbag.dags:\n            flash('DAG \"{0}\" seems to be missing.'.format(dag_id), \"error\")\n            return redirect(url_for('Airflow.index'))\n\n        root = request.args.get('root')\n        if root:\n            dag = dag.sub_dag(\n                task_regex=root,\n                include_upstream=True,\n                include_downstream=False)\n\n        arrange = request.args.get('arrange', dag.orientation)\n\n        nodes = []\n        edges = []\n        for task in dag.tasks:\n            nodes.append({\n                'id': task.task_id,\n                'value': {\n                    'label': task.task_id,\n                    'labelStyle': \"fill:{0};\".format(task.ui_fgcolor),\n                    'style': \"fill:{0};\".format(task.ui_color),\n                    'rx': 5,\n                    'ry': 5,\n                }\n            })\n\n        def get_downstream(task):\n            for t in task.downstream_list:\n                edge = {\n                    'source_id': task.task_id,\n                    'target_id': t.task_id,\n                }\n                if edge not in edges:\n                    edges.append(edge)\n                    get_downstream(t)\n\n        for t in dag.roots:\n            get_downstream(t)\n\n        dt_nr_dr_data = get_date_time_num_runs_dag_runs_form_data(request, session, dag)\n        dt_nr_dr_data['arrange'] = arrange\n        dttm = dt_nr_dr_data['dttm']\n\n        class GraphForm(DateTimeWithNumRunsWithDagRunsForm):\n            arrange = SelectField(\"Layout\", choices=(\n                ('LR', \"Left->Right\"),\n                ('RL', \"Right->Left\"),\n                ('TB', \"Top->Bottom\"),\n                ('BT', \"Bottom->Top\"),\n            ))\n\n        form = GraphForm(data=dt_nr_dr_data)\n        form.execution_date.choices = dt_nr_dr_data['dr_choices']\n\n        task_instances = {\n            ti.task_id: alchemy_to_dict(ti)\n            for ti in dag.get_task_instances(dttm, dttm)}\n        tasks = {\n            t.task_id: {\n                'dag_id': t.dag_id,\n                'task_type': t.task_type,\n                'extra_links': t.extra_links,\n            }\n            for t in dag.tasks}\n        if not tasks:\n            flash(\"No tasks found\", \"error\")\n        session.commit()\n        doc_md = markdown.markdown(dag.doc_md) \\\n            if hasattr(dag, 'doc_md') and dag.doc_md else ''\n\n        external_logs = conf.get('elasticsearch', 'frontend')\n        return self.render_template(\n            'airflow/graph.html',\n            dag=dag,\n            form=form,\n            width=request.args.get('width', \"100%\"),\n            height=request.args.get('height', \"800\"),\n            execution_date=dttm.isoformat(),\n            state_token=wwwutils.state_token(dt_nr_dr_data['dr_state']),\n            doc_md=doc_md,\n            arrange=arrange,\n            operators=sorted({op.__class__ for op in dag.tasks}, key=lambda x: x.__name__),\n            blur=blur,\n            root=root or '',\n            task_instances=task_instances,\n            tasks=tasks,\n            nodes=nodes,\n            edges=edges,\n            show_external_logs=bool(external_logs))\n\n    @expose('/duration')\n    @has_dag_access(can_dag_read=True)\n    @has_access\n    @action_logging\n    @provide_session\n    def duration(self, session=None):\n        default_dag_run = conf.getint('webserver', 'default_dag_run_display_number')\n        dag_id = request.args.get('dag_id')\n        dag = dagbag.get_dag(dag_id)\n        base_date = request.args.get('base_date')\n        num_runs = request.args.get('num_runs')\n        num_runs = int(num_runs) if num_runs else default_dag_run\n\n        if dag is None:\n            flash('DAG \"{0}\" seems to be missing.'.format(dag_id), \"error\")\n            return redirect(url_for('Airflow.index'))\n\n        if base_date:\n            base_date = pendulum.parse(base_date)\n        else:\n            base_date = dag.latest_execution_date or timezone.utcnow()\n\n        dates = dag.date_range(base_date, num=-abs(num_runs))\n        min_date = dates[0] if dates else timezone.utc_epoch()\n\n        root = request.args.get('root')\n        if root:\n            dag = dag.sub_dag(\n                task_regex=root,\n                include_upstream=True,\n                include_downstream=False)\n\n        chart_height = wwwutils.get_chart_height(dag)\n        chart = nvd3.lineChart(\n            name=\"lineChart\", x_is_date=True, height=chart_height, width=\"1200\")\n        cum_chart = nvd3.lineChart(\n            name=\"cumLineChart\", x_is_date=True, height=chart_height, width=\"1200\")\n\n        y = defaultdict(list)\n        x = defaultdict(list)\n        cum_y = defaultdict(list)\n\n        tis = dag.get_task_instances(start_date=min_date, end_date=base_date)\n        TF = TaskFail\n        ti_fails = (\n            session.query(TF)\n                   .filter(TF.dag_id == dag.dag_id,\n                           TF.execution_date >= min_date,\n                           TF.execution_date <= base_date,\n                           TF.task_id.in_([t.task_id for t in dag.tasks]))\n                   .all()  # noqa\n        )\n\n        fails_totals = defaultdict(int)\n        for tf in ti_fails:\n            dict_key = (tf.dag_id, tf.task_id, tf.execution_date)\n            if tf.duration:\n                fails_totals[dict_key] += tf.duration\n\n        for ti in tis:\n            if ti.duration:\n                dttm = wwwutils.epoch(ti.execution_date)\n                x[ti.task_id].append(dttm)\n                y[ti.task_id].append(float(ti.duration))\n                fails_dict_key = (ti.dag_id, ti.task_id, ti.execution_date)\n                fails_total = fails_totals[fails_dict_key]\n                cum_y[ti.task_id].append(float(ti.duration + fails_total))\n\n        # determine the most relevant time unit for the set of task instance\n        # durations for the DAG\n        y_unit = infer_time_unit([d for t in y.values() for d in t])\n        cum_y_unit = infer_time_unit([d for t in cum_y.values() for d in t])\n        # update the y Axis on both charts to have the correct time units\n        chart.create_y_axis('yAxis', format='.02f', custom_format=False,\n                            label='Duration ({})'.format(y_unit))\n        chart.axislist['yAxis']['axisLabelDistance'] = '40'\n        cum_chart.create_y_axis('yAxis', format='.02f', custom_format=False,\n                                label='Duration ({})'.format(cum_y_unit))\n        cum_chart.axislist['yAxis']['axisLabelDistance'] = '40'\n\n        for task in dag.tasks:\n            if x[task.task_id]:\n                chart.add_serie(name=task.task_id, x=x[task.task_id],\n                                y=scale_time_units(y[task.task_id], y_unit))\n                cum_chart.add_serie(name=task.task_id, x=x[task.task_id],\n                                    y=scale_time_units(cum_y[task.task_id],\n                                                       cum_y_unit))\n\n        dates = sorted(list({ti.execution_date for ti in tis}))\n        max_date = max([ti.execution_date for ti in tis]) if dates else None\n\n        session.commit()\n\n        form = DateTimeWithNumRunsForm(data={'base_date': max_date,\n                                             'num_runs': num_runs})\n        chart.buildcontent()\n        cum_chart.buildcontent()\n        s_index = cum_chart.htmlcontent.rfind('});')\n        cum_chart.htmlcontent = (cum_chart.htmlcontent[:s_index] +\n                                 \"$( document ).trigger('chartload')\" +\n                                 cum_chart.htmlcontent[s_index:])\n\n        return self.render_template(\n            'airflow/duration_chart.html',\n            dag=dag,\n            demo_mode=conf.getboolean('webserver', 'demo_mode'),\n            root=root,\n            form=form,\n            chart=chart.htmlcontent,\n            cum_chart=cum_chart.htmlcontent\n        )\n\n    @expose('/tries')\n    @has_dag_access(can_dag_read=True)\n    @has_access\n    @action_logging\n    @provide_session\n    def tries(self, session=None):\n        default_dag_run = conf.getint('webserver', 'default_dag_run_display_number')\n        dag_id = request.args.get('dag_id')\n        dag = dagbag.get_dag(dag_id)\n        base_date = request.args.get('base_date')\n        num_runs = request.args.get('num_runs')\n        num_runs = int(num_runs) if num_runs else default_dag_run\n\n        if base_date:\n            base_date = pendulum.parse(base_date)\n        else:\n            base_date = dag.latest_execution_date or timezone.utcnow()\n\n        dates = dag.date_range(base_date, num=-abs(num_runs))\n        min_date = dates[0] if dates else timezone.utc_epoch()\n\n        root = request.args.get('root')\n        if root:\n            dag = dag.sub_dag(\n                task_regex=root,\n                include_upstream=True,\n                include_downstream=False)\n\n        chart_height = wwwutils.get_chart_height(dag)\n        chart = nvd3.lineChart(\n            name=\"lineChart\", x_is_date=True, y_axis_format='d', height=chart_height,\n            width=\"1200\")\n\n        for task in dag.tasks:\n            y = []\n            x = []\n            for ti in task.get_task_instances(start_date=min_date, end_date=base_date):\n                dttm = wwwutils.epoch(ti.execution_date)\n                x.append(dttm)\n                y.append(ti.try_number)\n            if x:\n                chart.add_serie(name=task.task_id, x=x, y=y)\n\n        tis = dag.get_task_instances(start_date=min_date, end_date=base_date)\n        tries = sorted(list({ti.try_number for ti in tis}))\n        max_date = max([ti.execution_date for ti in tis]) if tries else None\n\n        session.commit()\n\n        form = DateTimeWithNumRunsForm(data={'base_date': max_date,\n                                             'num_runs': num_runs})\n\n        chart.buildcontent()\n\n        return self.render_template(\n            'airflow/chart.html',\n            dag=dag,\n            demo_mode=conf.getboolean('webserver', 'demo_mode'),\n            root=root,\n            form=form,\n            chart=chart.htmlcontent\n        )\n\n    @expose('/landing_times')\n    @has_dag_access(can_dag_read=True)\n    @has_access\n    @action_logging\n    @provide_session\n    def landing_times(self, session=None):\n        default_dag_run = conf.getint('webserver', 'default_dag_run_display_number')\n        dag_id = request.args.get('dag_id')\n        dag = dagbag.get_dag(dag_id)\n        base_date = request.args.get('base_date')\n        num_runs = request.args.get('num_runs')\n        num_runs = int(num_runs) if num_runs else default_dag_run\n\n        if base_date:\n            base_date = pendulum.parse(base_date)\n        else:\n            base_date = dag.latest_execution_date or timezone.utcnow()\n\n        dates = dag.date_range(base_date, num=-abs(num_runs))\n        min_date = dates[0] if dates else timezone.utc_epoch()\n\n        root = request.args.get('root')\n        if root:\n            dag = dag.sub_dag(\n                task_regex=root,\n                include_upstream=True,\n                include_downstream=False)\n\n        chart_height = wwwutils.get_chart_height(dag)\n        chart = nvd3.lineChart(\n            name=\"lineChart\", x_is_date=True, height=chart_height, width=\"1200\")\n        y = {}\n        x = {}\n        for task in dag.tasks:\n            y[task.task_id] = []\n            x[task.task_id] = []\n            for ti in task.get_task_instances(start_date=min_date, end_date=base_date):\n                ts = ti.execution_date\n                if dag.schedule_interval and dag.following_schedule(ts):\n                    ts = dag.following_schedule(ts)\n                if ti.end_date:\n                    dttm = wwwutils.epoch(ti.execution_date)\n                    secs = (ti.end_date - ts).total_seconds()\n                    x[ti.task_id].append(dttm)\n                    y[ti.task_id].append(secs)\n\n        # determine the most relevant time unit for the set of landing times\n        # for the DAG\n        y_unit = infer_time_unit([d for t in y.values() for d in t])\n        # update the y Axis to have the correct time units\n        chart.create_y_axis('yAxis', format='.02f', custom_format=False,\n                            label='Landing Time ({})'.format(y_unit))\n        chart.axislist['yAxis']['axisLabelDistance'] = '40'\n        for task in dag.tasks:\n            if x[task.task_id]:\n                chart.add_serie(name=task.task_id, x=x[task.task_id],\n                                y=scale_time_units(y[task.task_id], y_unit))\n\n        tis = dag.get_task_instances(start_date=min_date, end_date=base_date)\n        dates = sorted(list({ti.execution_date for ti in tis}))\n        max_date = max([ti.execution_date for ti in tis]) if dates else None\n\n        session.commit()\n\n        form = DateTimeWithNumRunsForm(data={'base_date': max_date,\n                                             'num_runs': num_runs})\n        chart.buildcontent()\n        return self.render_template(\n            'airflow/chart.html',\n            dag=dag,\n            chart=chart.htmlcontent,\n            height=str(chart_height + 100) + \"px\",\n            demo_mode=conf.getboolean('webserver', 'demo_mode'),\n            root=root,\n            form=form,\n        )\n\n    @expose('/paused', methods=['POST'])\n    @has_dag_access(can_dag_edit=True)\n    @has_access\n    @action_logging\n    def paused(self):\n        dag_id = request.args.get('dag_id')\n        is_paused = True if request.args.get('is_paused') == 'false' else False\n        models.DagModel.get_dagmodel(dag_id).set_is_paused(is_paused=is_paused)\n        return \"OK\"\n\n    @expose('/refresh', methods=['POST'])\n    @has_dag_access(can_dag_edit=True)\n    @has_access\n    @action_logging\n    @provide_session\n    def refresh(self, session=None):\n        DagModel = models.DagModel\n        dag_id = request.values.get('dag_id')\n        orm_dag = session.query(\n            DagModel).filter(DagModel.dag_id == dag_id).first()\n\n        if orm_dag:\n            orm_dag.last_expired = timezone.utcnow()\n            session.merge(orm_dag)\n        session.commit()\n\n        dag = dagbag.get_dag(dag_id)\n        # sync dag permission\n        appbuilder.sm.sync_perm_for_dag(dag_id, dag.access_control)\n\n        flash(\"DAG [{}] is now fresh as a daisy\".format(dag_id))\n        return redirect(request.referrer)\n\n    @expose('/refresh_all', methods=['POST'])\n    @has_access\n    @action_logging\n    def refresh_all(self):\n        dagbag.collect_dags(only_if_updated=False)\n        # sync permissions for all dags\n        for dag_id, dag in dagbag.dags.items():\n            appbuilder.sm.sync_perm_for_dag(dag_id, dag.access_control)\n        flash(\"All DAGs are now up to date\")\n        return redirect(url_for('Airflow.index'))\n\n    @expose('/gantt')\n    @has_dag_access(can_dag_read=True)\n    @has_access\n    @action_logging\n    @provide_session\n    def gantt(self, session=None):\n        dag_id = request.args.get('dag_id')\n        dag = dagbag.get_dag(dag_id)\n        demo_mode = conf.getboolean('webserver', 'demo_mode')\n\n        root = request.args.get('root')\n        if root:\n            dag = dag.sub_dag(\n                task_regex=root,\n                include_upstream=True,\n                include_downstream=False)\n\n        dt_nr_dr_data = get_date_time_num_runs_dag_runs_form_data(request, session, dag)\n        dttm = dt_nr_dr_data['dttm']\n\n        form = DateTimeWithNumRunsWithDagRunsForm(data=dt_nr_dr_data)\n        form.execution_date.choices = dt_nr_dr_data['dr_choices']\n\n        tis = [\n            ti for ti in dag.get_task_instances(dttm, dttm)\n            if ti.start_date and ti.state]\n        tis = sorted(tis, key=lambda ti: ti.start_date)\n        TF = TaskFail\n        ti_fails = list(itertools.chain(*[(\n            session\n            .query(TF)\n            .filter(TF.dag_id == ti.dag_id,\n                    TF.task_id == ti.task_id,\n                    TF.execution_date == ti.execution_date)\n            .all()\n        ) for ti in tis]))\n\n        # determine bars to show in the gantt chart\n        gantt_bar_items = []\n        for ti in tis:\n            end_date = ti.end_date or timezone.utcnow()\n            try_count = ti.try_number\n            if ti.state != State.RUNNING:\n                try_count = ti.try_number - 1\n            gantt_bar_items.append((ti.task_id, ti.start_date, end_date, ti.state, try_count))\n\n        tf_count = 0\n        try_count = 1\n        prev_task_id = \"\"\n        for tf in ti_fails:\n            end_date = tf.end_date or timezone.utcnow()\n            if tf_count != 0 and tf.task_id == prev_task_id:\n                try_count = try_count + 1\n            else:\n                try_count = 1\n            prev_task_id = tf.task_id\n            gantt_bar_items.append((tf.task_id, tf.start_date, end_date, State.FAILED, try_count))\n            tf_count = tf_count + 1\n\n        task_types = {}\n        extra_links = {}\n        for t in dag.tasks:\n            task_types[t.task_id] = t.task_type\n            extra_links[t.task_id] = t.extra_links\n\n        tasks = []\n        for gantt_bar_item in gantt_bar_items:\n            task_id = gantt_bar_item[0]\n            start_date = gantt_bar_item[1]\n            end_date = gantt_bar_item[2]\n            state = gantt_bar_item[3]\n            try_count = gantt_bar_item[4]\n            tasks.append({\n                'startDate': wwwutils.epoch(start_date),\n                'endDate': wwwutils.epoch(end_date),\n                'isoStart': start_date.isoformat()[:-4],\n                'isoEnd': end_date.isoformat()[:-4],\n                'taskName': task_id,\n                'taskType': task_types[ti.task_id],\n                'duration': (end_date - start_date).total_seconds(),\n                'status': state,\n                'executionDate': dttm.isoformat(),\n                'try_number': try_count,\n                'extraLinks': extra_links[ti.task_id],\n            })\n\n        states = {task['status']: task['status'] for task in tasks}\n\n        data = {\n            'taskNames': [ti.task_id for ti in tis],\n            'tasks': tasks,\n            'taskStatus': states,\n            'height': len(tis) * 25 + 25,\n        }\n\n        session.commit()\n\n        return self.render_template(\n            'airflow/gantt.html',\n            dag=dag,\n            execution_date=dttm.isoformat(),\n            form=form,\n            data=data,\n            base_date='',\n            demo_mode=demo_mode,\n            root=root,\n        )\n\n    @expose('/extra_links')\n    @has_dag_access(can_dag_read=True)\n    @has_access\n    @action_logging\n    def extra_links(self):\n        \"\"\"\n        A restful endpoint that returns external links for a given Operator\n\n        It queries the operator that sent the request for the links it wishes\n        to provide for a given external link name.\n\n        API: GET\n        Args: dag_id: The id of the dag containing the task in question\n              task_id: The id of the task in question\n              execution_date: The date of execution of the task\n              link_name: The name of the link reference to find the actual URL for\n\n        Returns:\n            200: {url: <url of link>, error: None} - returned when there was no problem\n                finding the URL\n            404: {url: None, error: <error message>} - returned when the operator does\n                not return a URL\n        \"\"\"\n        dag_id = request.args.get('dag_id')\n        task_id = request.args.get('task_id')\n        execution_date = request.args.get('execution_date')\n        link_name = request.args.get('link_name')\n        dttm = airflow.utils.timezone.parse(execution_date)\n        dag = dagbag.get_dag(dag_id)\n\n        if not dag or task_id not in dag.task_ids:\n            response = jsonify(\n                {'url': None,\n                 'error': \"can't find dag {dag} or task_id {task_id}\".format(\n                     dag=dag,\n                     task_id=task_id\n                 )}\n            )\n            response.status_code = 404\n            return response\n\n        task = dag.get_task(task_id)\n\n        try:\n            url = task.get_extra_links(dttm, link_name)\n        except ValueError as err:\n            response = jsonify({'url': None, 'error': str(err)})\n            response.status_code = 404\n            return response\n        if url:\n            response = jsonify({'error': None, 'url': url})\n            response.status_code = 200\n            return response\n        else:\n            response = jsonify(\n                {'url': None, 'error': 'No URL found for {dest}'.format(dest=link_name)})\n            response.status_code = 404\n            return response\n\n    @expose('/object/task_instances')\n    @has_dag_access(can_dag_read=True)\n    @has_access\n    @action_logging\n    @provide_session\n    def task_instances(self, session=None):\n        dag_id = request.args.get('dag_id')\n        dag = dagbag.get_dag(dag_id)\n\n        dttm = request.args.get('execution_date')\n        if dttm:\n            dttm = pendulum.parse(dttm)\n        else:\n            return \"Error: Invalid execution_date\"\n\n        task_instances = {\n            ti.task_id: alchemy_to_dict(ti)\n            for ti in dag.get_task_instances(dttm, dttm)}\n\n        return json.dumps(task_instances)\n\n\nclass VersionView(AirflowBaseView):\n    @expose('/version')\n    @has_access\n    def version(self):\n        try:\n            airflow_version = airflow.__version__\n        except Exception as e:\n            airflow_version = None\n            logging.error(e)\n\n        # Get the Git repo and git hash\n        git_version = None\n        try:\n            with open(os.path.join(*[settings.AIRFLOW_HOME,\n                                   'airflow', 'git_version'])) as f:\n                git_version = f.readline()\n        except Exception as e:\n            logging.error(e)\n\n        # Render information\n        title = \"Version Info\"\n        return self.render_template(\n            'airflow/version.html',\n            title=title,\n            airflow_version=airflow_version,\n            git_version=git_version)\n\n\nclass ConfigurationView(AirflowBaseView):\n    @expose('/configuration')\n    @has_access\n    def conf(self):\n        raw = request.args.get('raw') == \"true\"\n        title = \"Airflow Configuration\"\n        subtitle = AIRFLOW_CONFIG\n        # Don't show config when expose_config variable is False in airflow config\n        if conf.getboolean(\"webserver\", \"expose_config\"):\n            with open(AIRFLOW_CONFIG, 'r') as file:\n                config = file.read()\n            table = [(section, key, value, source)\n                     for section, parameters in conf.as_dict(True, True).items()\n                     for key, (value, source) in parameters.items()]\n        else:\n            config = (\n                \"# Your Airflow administrator chose not to expose the \"\n                \"configuration, most likely for security reasons.\")\n            table = None\n\n        if raw:\n            return Response(\n                response=config,\n                status=200,\n                mimetype=\"application/text\")\n        else:\n            code_html = Markup(highlight(\n                config,\n                lexers.IniLexer(),  # Lexer call\n                HtmlFormatter(noclasses=True))\n            )\n            return self.render_template(\n                'airflow/config.html',\n                pre_subtitle=settings.HEADER + \"  v\" + airflow.__version__,\n                code_html=code_html, title=title, subtitle=subtitle,\n                table=table)\n\n\n######################################################################################\n#                                    ModelViews\n######################################################################################\n\nclass DagFilter(BaseFilter):\n    def apply(self, query, func): # noqa\n        if appbuilder.sm.has_all_dags_access():\n            return query\n        filter_dag_ids = appbuilder.sm.get_accessible_dag_ids()\n        return query.filter(self.model.dag_id.in_(filter_dag_ids))\n\n\nclass AirflowModelView(ModelView):\n    list_widget = AirflowModelListWidget\n    page_size = PAGE_SIZE\n\n    CustomSQLAInterface = wwwutils.CustomSQLAInterface\n\n\nclass SlaMissModelView(AirflowModelView):\n    route_base = '/slamiss'\n\n    datamodel = AirflowModelView.CustomSQLAInterface(SlaMiss)\n\n    base_permissions = ['can_list']\n\n    list_columns = ['dag_id', 'task_id', 'execution_date', 'email_sent', 'timestamp']\n    add_columns = ['dag_id', 'task_id', 'execution_date', 'email_sent', 'timestamp']\n    edit_columns = ['dag_id', 'task_id', 'execution_date', 'email_sent', 'timestamp']\n    search_columns = ['dag_id', 'task_id', 'email_sent', 'timestamp', 'execution_date']\n    base_order = ('execution_date', 'desc')\n    base_filters = [['dag_id', DagFilter, lambda: []]]\n\n    formatters_columns = {\n        'task_id': wwwutils.task_instance_link,\n        'execution_date': wwwutils.datetime_f('execution_date'),\n        'timestamp': wwwutils.datetime_f('timestamp'),\n        'dag_id': wwwutils.dag_link,\n    }\n\n\nclass XComModelView(AirflowModelView):\n    route_base = '/xcom'\n\n    datamodel = AirflowModelView.CustomSQLAInterface(XCom)\n\n    base_permissions = ['can_add', 'can_list', 'can_edit', 'can_delete']\n\n    search_columns = ['key', 'value', 'timestamp', 'execution_date', 'task_id', 'dag_id']\n    list_columns = ['key', 'value', 'timestamp', 'execution_date', 'task_id', 'dag_id']\n    add_columns = ['key', 'value', 'execution_date', 'task_id', 'dag_id']\n    edit_columns = ['key', 'value', 'execution_date', 'task_id', 'dag_id']\n    base_order = ('execution_date', 'desc')\n\n    base_filters = [['dag_id', DagFilter, lambda: []]]\n\n    formatters_columns = {\n        'task_id': wwwutils.task_instance_link,\n        'execution_date': wwwutils.datetime_f('execution_date'),\n        'timestamp': wwwutils.datetime_f('timestamp'),\n        'dag_id': wwwutils.dag_link,\n    }\n\n    @action('muldelete', 'Delete', \"Are you sure you want to delete selected records?\",\n            single=False)\n    def action_muldelete(self, items):\n        self.datamodel.delete_all(items)\n        self.update_redirect()\n        return redirect(self.get_redirect())\n\n    def pre_add(self, item):\n        item.execution_date = timezone.make_aware(item.execution_date)\n        item.value = XCom.serialize_value(item.value)\n\n    def pre_update(self, item):\n        item.execution_date = timezone.make_aware(item.execution_date)\n        item.value = XCom.serialize_value(item.value)\n\n\nclass ConnectionModelView(AirflowModelView):\n    route_base = '/connection'\n\n    datamodel = AirflowModelView.CustomSQLAInterface(Connection)\n\n    base_permissions = ['can_add', 'can_list', 'can_edit', 'can_delete']\n\n    extra_fields = ['extra__jdbc__drv_path', 'extra__jdbc__drv_clsname',\n                    'extra__google_cloud_platform__project',\n                    'extra__google_cloud_platform__key_path',\n                    'extra__google_cloud_platform__keyfile_dict',\n                    'extra__google_cloud_platform__scope',\n                    'extra__google_cloud_platform__num_retries',\n                    'extra__grpc__auth_type',\n                    'extra__grpc__credential_pem_file',\n                    'extra__grpc__scopes']\n    list_columns = ['conn_id', 'conn_type', 'host', 'port', 'is_encrypted',\n                    'is_extra_encrypted']\n    add_columns = edit_columns = ['conn_id', 'conn_type', 'host', 'schema',\n                                  'login', 'password', 'port', 'extra'] + extra_fields\n    add_form = edit_form = ConnectionForm\n    add_template = 'airflow/conn_create.html'\n    edit_template = 'airflow/conn_edit.html'\n\n    base_order = ('conn_id', 'asc')\n\n    @action('muldelete', 'Delete', 'Are you sure you want to delete selected records?',\n            single=False)\n    @has_dag_access(can_dag_edit=True)\n    def action_muldelete(self, items):\n        self.datamodel.delete_all(items)\n        self.update_redirect()\n        return redirect(self.get_redirect())\n\n    def process_form(self, form, is_created):\n        formdata = form.data\n        if formdata['conn_type'] in ['jdbc', 'google_cloud_platform', 'grpc']:\n            extra = {\n                key: formdata[key]\n                for key in self.extra_fields if key in formdata}\n            form.extra.data = json.dumps(extra)\n\n    def prefill_form(self, form, pk):\n        try:\n            d = json.loads(form.data.get('extra', '{}'))\n        except Exception:\n            d = {}\n\n        if not hasattr(d, 'get'):\n            logging.warning('extra field for {} is not iterable'.format(\n                form.data.get('conn_id', '<unknown>')))\n            return\n\n        for field in self.extra_fields:\n            value = d.get(field, '')\n            if value:\n                field = getattr(form, field)\n                field.data = value\n\n\nclass PoolModelView(AirflowModelView):\n    route_base = '/pool'\n\n    datamodel = AirflowModelView.CustomSQLAInterface(models.Pool)\n\n    base_permissions = ['can_add', 'can_list', 'can_edit', 'can_delete']\n\n    list_columns = ['pool', 'slots', 'used_slots', 'queued_slots']\n    add_columns = ['pool', 'slots', 'description']\n    edit_columns = ['pool', 'slots', 'description']\n\n    base_order = ('pool', 'asc')\n\n    @action('muldelete', 'Delete', 'Are you sure you want to delete selected records?',\n            single=False)\n    def action_muldelete(self, items):\n        if any(item.pool == models.Pool.DEFAULT_POOL_NAME for item in items):\n            flash(\"default_pool cannot be deleted\", 'error')\n            self.update_redirect()\n            return redirect(self.get_redirect())\n        self.datamodel.delete_all(items)\n        self.update_redirect()\n        return redirect(self.get_redirect())\n\n    def pool_link(attr):\n        pool_id = attr.get('pool')\n        if pool_id is not None:\n            url = url_for('TaskInstanceModelView.list', _flt_3_pool=pool_id)\n            return Markup(\"<a href='{url}'>{pool_id}</a>\").format(url=url, pool_id=pool_id)\n        else:\n            return Markup('<span class=\"label label-danger\">Invalid</span>')\n\n    def fused_slots(attr):\n        pool_id = attr.get('pool')\n        used_slots = attr.get('used_slots')\n        if pool_id is not None and used_slots is not None:\n            url = url_for('TaskInstanceModelView.list', _flt_3_pool=pool_id, _flt_3_state='running')\n            return Markup(\"<a href='{url}'>{used_slots}</a>\").format(url=url, used_slots=used_slots)\n        else:\n            return Markup('<span class=\"label label-danger\">Invalid</span>')\n\n    def fqueued_slots(attr):\n        pool_id = attr.get('pool')\n        queued_slots = attr.get('queued_slots')\n        if pool_id is not None and queued_slots is not None:\n            url = url_for('TaskInstanceModelView.list', _flt_3_pool=pool_id, _flt_3_state='queued')\n            return Markup(\"<a href='{url}'>{queued_slots}</a>\").format(url=url, queued_slots=queued_slots)\n        else:\n            return Markup('<span class=\"label label-danger\">Invalid</span>')\n\n    formatters_columns = {\n        'pool': pool_link,\n        'used_slots': fused_slots,\n        'queued_slots': fqueued_slots\n    }\n\n    validators_columns = {\n        'pool': [validators.DataRequired()],\n        'slots': [validators.NumberRange(min=0)]\n    }\n\n\nclass VariableModelView(AirflowModelView):\n    route_base = '/variable'\n\n    list_template = 'airflow/variable_list.html'\n    edit_template = 'airflow/variable_edit.html'\n\n    datamodel = AirflowModelView.CustomSQLAInterface(models.Variable)\n\n    base_permissions = ['can_add', 'can_list', 'can_edit', 'can_delete', 'can_varimport']\n\n    list_columns = ['key', 'val', 'is_encrypted']\n    add_columns = ['key', 'val']\n    edit_columns = ['key', 'val']\n    search_columns = ['key', 'val']\n\n    base_order = ('key', 'asc')\n\n    def hidden_field_formatter(attr):\n        key = attr.get('key')\n        val = attr.get('val')\n        if wwwutils.should_hide_value_for_key(key):\n            return Markup('*' * 8)\n        if val:\n            return val\n        else:\n            return Markup('<span class=\"label label-danger\">Invalid</span>')\n\n    formatters_columns = {\n        'val': hidden_field_formatter,\n    }\n\n    validators_columns = {\n        'key': [validators.DataRequired()]\n    }\n\n    def prefill_form(self, form, id):\n        if wwwutils.should_hide_value_for_key(form.key.data):\n            form.val.data = '*' * 8\n\n    @action('muldelete', 'Delete', 'Are you sure you want to delete selected records?',\n            single=False)\n    def action_muldelete(self, items):\n        self.datamodel.delete_all(items)\n        self.update_redirect()\n        return redirect(self.get_redirect())\n\n    @action('varexport', 'Export', '', single=False)\n    def action_varexport(self, items):\n        var_dict = {}\n        d = json.JSONDecoder()\n        for var in items:\n            try:\n                val = d.decode(var.val)\n            except Exception:\n                val = var.val\n            var_dict[var.key] = val\n\n        response = make_response(json.dumps(var_dict, sort_keys=True, indent=4))\n        response.headers[\"Content-Disposition\"] = \"attachment; filename=variables.json\"\n        response.headers[\"Content-Type\"] = \"application/json; charset=utf-8\"\n        return response\n\n    @expose('/varimport', methods=[\"POST\"])\n    @has_access\n    @action_logging\n    def varimport(self):\n        try:\n            out = request.files['file'].read()\n            if isinstance(out, bytes):\n                d = json.loads(out.decode('utf-8'))\n            else:\n                d = json.loads(out)\n        except Exception:\n            self.update_redirect()\n            flash(\"Missing file or syntax error.\", 'error')\n            return redirect(self.get_redirect())\n        else:\n            suc_count = fail_count = 0\n            for k, v in d.items():\n                try:\n                    models.Variable.set(k, v, serialize_json=not isinstance(v, str))\n                except Exception as e:\n                    logging.info('Variable import failed: {}'.format(repr(e)))\n                    fail_count += 1\n                else:\n                    suc_count += 1\n            flash(\"{} variable(s) successfully updated.\".format(suc_count))\n            if fail_count:\n                flash(\"{} variable(s) failed to be updated.\".format(fail_count), 'error')\n            self.update_redirect()\n            return redirect(self.get_redirect())\n\n\nclass JobModelView(AirflowModelView):\n    route_base = '/job'\n\n    datamodel = AirflowModelView.CustomSQLAInterface(jobs.BaseJob)\n\n    base_permissions = ['can_list']\n\n    list_columns = ['id', 'dag_id', 'state', 'job_type', 'start_date',\n                    'end_date', 'latest_heartbeat',\n                    'executor_class', 'hostname', 'unixname']\n    search_columns = ['id', 'dag_id', 'state', 'job_type', 'start_date',\n                      'end_date', 'latest_heartbeat', 'executor_class',\n                      'hostname', 'unixname']\n\n    base_order = ('start_date', 'desc')\n\n    base_filters = [['dag_id', DagFilter, lambda: []]]\n\n    formatters_columns = {\n        'start_date': wwwutils.datetime_f('start_date'),\n        'end_date': wwwutils.datetime_f('end_date'),\n        'hostname': wwwutils.nobr_f('hostname'),\n        'state': wwwutils.state_f,\n        'latest_heartbeat': wwwutils.datetime_f('latest_heartbeat'),\n    }\n\n\nclass DagRunModelView(AirflowModelView):\n    route_base = '/dagrun'\n\n    datamodel = AirflowModelView.CustomSQLAInterface(models.DagRun)\n\n    base_permissions = ['can_list', 'can_add']\n\n    add_columns = ['state', 'dag_id', 'execution_date', 'run_id', 'external_trigger']\n    list_columns = ['state', 'dag_id', 'execution_date', 'run_id', 'external_trigger']\n    search_columns = ['state', 'dag_id', 'execution_date', 'run_id', 'external_trigger']\n\n    base_order = ('execution_date', 'desc')\n\n    base_filters = [['dag_id', DagFilter, lambda: []]]\n\n    add_form = edit_form = DagRunForm\n\n    formatters_columns = {\n        'execution_date': wwwutils.datetime_f('execution_date'),\n        'state': wwwutils.state_f,\n        'start_date': wwwutils.datetime_f('start_date'),\n        'dag_id': wwwutils.dag_link,\n        'run_id': wwwutils.dag_run_link,\n    }\n\n    @action('muldelete', \"Delete\", \"Are you sure you want to delete selected records?\",\n            single=False)\n    @has_dag_access(can_dag_edit=True)\n    @provide_session\n    def action_muldelete(self, items, session=None):\n        self.datamodel.delete_all(items)\n        self.update_redirect()\n        dirty_ids = []\n        for item in items:\n            dirty_ids.append(item.dag_id)\n        return redirect(self.get_redirect())\n\n    @action('set_running', \"Set state to 'running'\", '', single=False)\n    @provide_session\n    def action_set_running(self, drs, session=None):\n        try:\n            DR = models.DagRun\n            count = 0\n            dirty_ids = []\n            for dr in session.query(DR).filter(\n                    DR.id.in_([dagrun.id for dagrun in drs])).all():\n                dirty_ids.append(dr.dag_id)\n                count += 1\n                dr.start_date = timezone.utcnow()\n                dr.state = State.RUNNING\n            session.commit()\n            flash(\"{count} dag runs were set to running\".format(count=count))\n        except Exception as ex:\n            flash(str(ex), 'error')\n            flash('Failed to set state', 'error')\n        return redirect(self.get_default_url())\n\n    @action('set_failed', \"Set state to 'failed'\",\n            \"All running task instances would also be marked as failed, are you sure?\",\n            single=False)\n    @provide_session\n    def action_set_failed(self, drs, session=None):\n        try:\n            DR = models.DagRun\n            count = 0\n            dirty_ids = []\n            altered_tis = []\n            for dr in session.query(DR).filter(\n                    DR.id.in_([dagrun.id for dagrun in drs])).all():\n                dirty_ids.append(dr.dag_id)\n                count += 1\n                altered_tis += \\\n                    set_dag_run_state_to_failed(dagbag.get_dag(dr.dag_id),\n                                                dr.execution_date,\n                                                commit=True,\n                                                session=session)\n            altered_ti_count = len(altered_tis)\n            flash(\n                \"{count} dag runs and {altered_ti_count} task instances \"\n                \"were set to failed\".format(count=count, altered_ti_count=altered_ti_count))\n        except Exception:\n            flash('Failed to set state', 'error')\n        return redirect(self.get_default_url())\n\n    @action('set_success', \"Set state to 'success'\",\n            \"All task instances would also be marked as success, are you sure?\",\n            single=False)\n    @provide_session\n    def action_set_success(self, drs, session=None):\n        try:\n            DR = models.DagRun\n            count = 0\n            dirty_ids = []\n            altered_tis = []\n            for dr in session.query(DR).filter(\n                    DR.id.in_([dagrun.id for dagrun in drs])).all():\n                dirty_ids.append(dr.dag_id)\n                count += 1\n                altered_tis += \\\n                    set_dag_run_state_to_success(dagbag.get_dag(dr.dag_id),\n                                                 dr.execution_date,\n                                                 commit=True,\n                                                 session=session)\n            altered_ti_count = len(altered_tis)\n            flash(\n                \"{count} dag runs and {altered_ti_count} task instances \"\n                \"were set to success\".format(count=count, altered_ti_count=altered_ti_count))\n        except Exception:\n            flash('Failed to set state', 'error')\n        return redirect(self.get_default_url())\n\n\nclass LogModelView(AirflowModelView):\n    route_base = '/log'\n\n    datamodel = AirflowModelView.CustomSQLAInterface(Log)\n\n    base_permissions = ['can_list']\n\n    list_columns = ['id', 'dttm', 'dag_id', 'task_id', 'event', 'execution_date',\n                    'owner', 'extra']\n    search_columns = ['dag_id', 'task_id', 'event', 'execution_date', 'owner', 'extra']\n\n    base_order = ('dttm', 'desc')\n\n    base_filters = [['dag_id', DagFilter, lambda: []]]\n\n    formatters_columns = {\n        'dttm': wwwutils.datetime_f('dttm'),\n        'execution_date': wwwutils.datetime_f('execution_date'),\n        'dag_id': wwwutils.dag_link,\n    }\n\n\nclass TaskInstanceModelView(AirflowModelView):\n    route_base = '/taskinstance'\n\n    datamodel = AirflowModelView.CustomSQLAInterface(models.TaskInstance)\n\n    base_permissions = ['can_list']\n\n    page_size = PAGE_SIZE\n\n    list_columns = ['state', 'dag_id', 'task_id', 'execution_date', 'operator',\n                    'start_date', 'end_date', 'duration', 'job_id', 'hostname',\n                    'unixname', 'priority_weight', 'queue', 'queued_dttm', 'try_number',\n                    'pool', 'log_url']\n\n    search_columns = ['state', 'dag_id', 'task_id', 'execution_date', 'hostname',\n                      'queue', 'pool', 'operator', 'start_date', 'end_date']\n\n    base_order = ('job_id', 'asc')\n\n    base_filters = [['dag_id', DagFilter, lambda: []]]\n\n    def log_url_formatter(attr):\n        log_url = attr.get('log_url')\n        return Markup(\n            '<a href=\"{log_url}\">'\n            '    <span class=\"glyphicon glyphicon-book\" aria-hidden=\"true\">'\n            '</span></a>').format(log_url=log_url)\n\n    def duration_f(attr):\n        end_date = attr.get('end_date')\n        duration = attr.get('duration')\n        if end_date and duration:\n            return timedelta(seconds=duration)\n\n    formatters_columns = {\n        'log_url': log_url_formatter,\n        'task_id': wwwutils.task_instance_link,\n        'hostname': wwwutils.nobr_f('hostname'),\n        'state': wwwutils.state_f,\n        'execution_date': wwwutils.datetime_f('execution_date'),\n        'start_date': wwwutils.datetime_f('start_date'),\n        'end_date': wwwutils.datetime_f('end_date'),\n        'queued_dttm': wwwutils.datetime_f('queued_dttm'),\n        'dag_id': wwwutils.dag_link,\n        'duration': duration_f,\n    }\n\n    @provide_session\n    @action('clear', lazy_gettext('Clear'),\n            lazy_gettext('Are you sure you want to clear the state of the selected task'\n                         ' instance(s) and set their dagruns to the running state?'),\n            single=False)\n    def action_clear(self, tis, session=None):\n        try:\n            dag_to_tis = {}\n\n            for ti in tis:\n                dag = dagbag.get_dag(ti.dag_id)\n                tis = dag_to_tis.setdefault(dag, [])\n                tis.append(ti)\n\n            for dag, tis in dag_to_tis.items():\n                models.clear_task_instances(tis, session, dag=dag)\n\n            session.commit()\n            flash(\"{0} task instances have been cleared\".format(len(tis)))\n            self.update_redirect()\n            return redirect(self.get_redirect())\n\n        except Exception:\n            flash('Failed to clear task instances', 'error')\n\n    @provide_session\n    def set_task_instance_state(self, tis, target_state, session=None):\n        try:\n            count = len(tis)\n            for ti in tis:\n                ti.set_state(target_state, session)\n            session.commit()\n            flash(\"{count} task instances were set to '{target_state}'\".format(\n                count=count, target_state=target_state))\n        except Exception:\n            flash('Failed to set state', 'error')\n\n    @action('set_running', \"Set state to 'running'\", '', single=False)\n    @has_dag_access(can_dag_edit=True)\n    def action_set_running(self, tis):\n        self.set_task_instance_state(tis, State.RUNNING)\n        self.update_redirect()\n        return redirect(self.get_redirect())\n\n    @action('set_failed', \"Set state to 'failed'\", '', single=False)\n    @has_dag_access(can_dag_edit=True)\n    def action_set_failed(self, tis):\n        self.set_task_instance_state(tis, State.FAILED)\n        self.update_redirect()\n        return redirect(self.get_redirect())\n\n    @action('set_success', \"Set state to 'success'\", '', single=False)\n    @has_dag_access(can_dag_edit=True)\n    def action_set_success(self, tis):\n        self.set_task_instance_state(tis, State.SUCCESS)\n        self.update_redirect()\n        return redirect(self.get_redirect())\n\n    @action('set_retry', \"Set state to 'up_for_retry'\", '', single=False)\n    @has_dag_access(can_dag_edit=True)\n    def action_set_retry(self, tis):\n        self.set_task_instance_state(tis, State.UP_FOR_RETRY)\n        self.update_redirect()\n        return redirect(self.get_redirect())\n\n\nclass DagModelView(AirflowModelView):\n    route_base = '/dagmodel'\n\n    datamodel = AirflowModelView.CustomSQLAInterface(models.DagModel)\n\n    base_permissions = ['can_list', 'can_show', 'can_edit']\n\n    list_columns = ['dag_id', 'is_paused', 'last_scheduler_run',\n                    'last_expired', 'scheduler_lock', 'fileloc', 'owners']\n\n    formatters_columns = {\n        'dag_id': wwwutils.dag_link\n    }\n\n    base_filters = [['dag_id', DagFilter, lambda: []]]\n\n    def get_query(self):\n        \"\"\"\n        Default filters for model\n        \"\"\"\n        return (\n            super().get_query()\n            .filter(or_(models.DagModel.is_active,\n                        models.DagModel.is_paused))\n            .filter(~models.DagModel.is_subdag)\n        )\n\n    def get_count_query(self):\n        \"\"\"\n        Default filters for model\n        \"\"\"\n        return (\n            super().get_count_query()\n            .filter(models.DagModel.is_active)\n            .filter(~models.DagModel.is_subdag)\n        )\n", "patch": "@@ -2555,7 +2555,7 @@ class DagModelView(AirflowModelView):\n \n     datamodel = AirflowModelView.CustomSQLAInterface(models.DagModel)\n \n-    base_permissions = ['can_list', 'can_show', 'can_edit']\n+    base_permissions = ['can_list', 'can_show']\n \n     list_columns = ['dag_id', 'is_paused', 'last_scheduler_run',\n                     'last_expired', 'scheduler_lock', 'fileloc', 'owners']", "file_path": "files/2019_10\\21", "file_language": "py", "file_name": "airflow/www/views.py", "outdated_file_modify": 1, "outdated_file_before": 0, "outdated_file_after": 0, "llm_check": 0, "static_check": 0, "static": {"rats": [false, []], "semgrep": [false, []]}, "target": 0, "function_before": [{"function": "def get_date_time_num_runs_dag_runs_form_data(request, session, dag):\n    dttm = request.args.get('execution_date')\n    if dttm:\n        dttm = pendulum.parse(dttm)\n    else:\n        dttm = dag.latest_execution_date or timezone.utcnow()\n\n    base_date = request.args.get('base_date')\n    if base_date:\n        base_date = timezone.parse(base_date)\n    else:\n        # The DateTimeField widget truncates milliseconds and would loose\n        # the first dag run. Round to next second.\n        base_date = (dttm + timedelta(seconds=1)).replace(microsecond=0)\n\n    default_dag_run = conf.getint('webserver', 'default_dag_run_display_number')\n    num_runs = request.args.get('num_runs')\n    num_runs = int(num_runs) if num_runs else default_dag_run\n\n    DR = models.DagRun\n    drs = (\n        session.query(DR)\n        .filter(\n            DR.dag_id == dag.dag_id,\n            DR.execution_date <= base_date)\n        .order_by(desc(DR.execution_date))\n        .limit(num_runs)\n        .all()\n    )\n    dr_choices = []\n    dr_state = None\n    for dr in drs:\n        dr_choices.append((dr.execution_date.isoformat(), dr.run_id))\n        if dttm == dr.execution_date:\n            dr_state = dr.state\n\n    # Happens if base_date was changed and the selected dag run is not in result\n    if not dr_state and drs:\n        dr = drs[0]\n        dttm = dr.execution_date\n        dr_state = dr.state\n\n    return {\n        'dttm': dttm,\n        'base_date': base_date,\n        'num_runs': num_runs,\n        'execution_date': dttm.isoformat(),\n        'dr_choices': dr_choices,\n        'dr_state': dr_state,\n    }", "target": 0}, {"function": "class AirflowBaseView(BaseView):\n    route_base = ''\n\n    # Make our macros available to our UI templates too.\n    extra_args = {\n        'macros': airflow.macros,\n    }\n\n    def render_template(self, *args, **kwargs):\n        return super().render_template(\n            *args,\n            # Cache this at most once per request, not for the lifetime of the view instance\n            scheduler_job=lazy_object_proxy.Proxy(jobs.SchedulerJob.most_recent_job),\n            **kwargs\n        )", "target": 0}, {"function": "class Airflow(AirflowBaseView):\n    @expose('/health')\n    def health(self):\n        \"\"\"\n        An endpoint helping check the health status of the Airflow instance,\n        including metadatabase and scheduler.\n        \"\"\"\n\n        payload = {\n            'metadatabase': {'status': 'unhealthy'}\n        }\n\n        latest_scheduler_heartbeat = None\n        scheduler_status = 'unhealthy'\n        payload['metadatabase'] = {'status': 'healthy'}\n        try:\n            scheduler_job = jobs.SchedulerJob.most_recent_job()\n\n            if scheduler_job:\n                latest_scheduler_heartbeat = scheduler_job.latest_heartbeat.isoformat()\n                if scheduler_job.is_alive():\n                    scheduler_status = 'healthy'\n        except Exception:\n            payload['metadatabase']['status'] = 'unhealthy'\n\n        payload['scheduler'] = {'status': scheduler_status,\n                                'latest_scheduler_heartbeat': latest_scheduler_heartbeat}\n\n        return wwwutils.json_response(payload)\n\n    @expose('/home')\n    @has_access\n    def index(self):\n        hide_paused_dags_by_default = conf.getboolean('webserver',\n                                                      'hide_paused_dags_by_default')\n        show_paused_arg = request.args.get('showPaused', 'None')\n\n        default_dag_run = conf.getint('webserver', 'default_dag_run_display_number')\n        num_runs = request.args.get('num_runs')\n        num_runs = int(num_runs) if num_runs else default_dag_run\n\n        def get_int_arg(value, default=0):\n            try:\n                return int(value)\n            except ValueError:\n                return default\n\n        arg_current_page = request.args.get('page', '0')\n        arg_search_query = request.args.get('search', None)\n\n        dags_per_page = PAGE_SIZE\n        current_page = get_int_arg(arg_current_page, default=0)\n\n        if show_paused_arg.strip().lower() == 'false':\n            hide_paused = True\n        elif show_paused_arg.strip().lower() == 'true':\n            hide_paused = False\n        else:\n            hide_paused = hide_paused_dags_by_default\n\n        start = current_page * dags_per_page\n        end = start + dags_per_page\n\n        # Get all the dag id the user could access\n        filter_dag_ids = appbuilder.sm.get_accessible_dag_ids()\n\n        with create_session() as session:\n            # read orm_dags from the db\n            dags_query = session.query(DagModel).filter(\n                ~DagModel.is_subdag, DagModel.is_active\n            )\n\n            # optionally filter out \"paused\" dags\n            if hide_paused:\n                dags_query = dags_query.filter(~DagModel.is_paused)\n\n            if arg_search_query:\n                dags_query = dags_query.filter(\n                    DagModel.dag_id.ilike('%' + arg_search_query + '%') |\n                    DagModel.owners.ilike('%' + arg_search_query + '%')\n                )\n\n            if 'all_dags' not in filter_dag_ids:\n                dags_query = dags_query.filter(DagModel.dag_id.in_(filter_dag_ids))\n\n            dags = dags_query.order_by(DagModel.dag_id).offset(start).limit(dags_per_page).all()\n\n            import_errors = session.query(errors.ImportError).all()\n\n        for ie in import_errors:\n            flash(\n                \"Broken DAG: [{ie.filename}] {ie.stacktrace}\".format(ie=ie),\n                \"dag_import_error\")\n\n        from airflow.plugins_manager import import_errors as plugin_import_errors\n        for filename, stacktrace in plugin_import_errors.items():\n            flash(\n                \"Broken plugin: [{filename}] {stacktrace}\".format(\n                    stacktrace=stacktrace,\n                    filename=filename),\n                \"error\")\n\n        num_of_all_dags = dags_query.count()\n        num_of_pages = int(math.ceil(num_of_all_dags / float(dags_per_page)))\n\n        auto_complete_data = set()\n        for row in dags_query.with_entities(DagModel.dag_id, DagModel.owners):\n            auto_complete_data.add(row.dag_id)\n            auto_complete_data.add(row.owners)\n\n        return self.render_template(\n            'airflow/dags.html',\n            dags=dags,\n            hide_paused=hide_paused,\n            current_page=current_page,\n            search_query=arg_search_query if arg_search_query else '',\n            page_size=dags_per_page,\n            num_of_pages=num_of_pages,\n            num_dag_from=min(start + 1, num_of_all_dags),\n            num_dag_to=min(end, num_of_all_dags),\n            num_of_all_dags=num_of_all_dags,\n            paging=wwwutils.generate_pages(current_page, num_of_pages,\n                                           search=arg_search_query,\n                                           showPaused=not hide_paused),\n            auto_complete_data=auto_complete_data,\n            num_runs=num_runs)\n\n    @expose('/dag_stats')\n    @has_access\n    @provide_session\n    def dag_stats(self, session=None):\n        dr = models.DagRun\n\n        filter_dag_ids = appbuilder.sm.get_accessible_dag_ids()\n\n        dag_state_stats = session.query(dr.dag_id, dr.state, sqla.func.count(dr.state))\\\n            .group_by(dr.dag_id, dr.state)\n\n        payload = {}\n        if filter_dag_ids:\n            if 'all_dags' not in filter_dag_ids:\n                dag_state_stats = dag_state_stats.filter(dr.dag_id.in_(filter_dag_ids))\n            data = {}\n            for dag_id, state, count in dag_state_stats:\n                if dag_id not in data:\n                    data[dag_id] = {}\n                data[dag_id][state] = count\n\n            if 'all_dags' in filter_dag_ids:\n                filter_dag_ids = [dag_id for dag_id, in session.query(models.DagModel.dag_id)]\n\n            for dag_id in filter_dag_ids:\n                payload[dag_id] = []\n                for state in State.dag_states:\n                    count = data.get(dag_id, {}).get(state, 0)\n                    payload[dag_id].append({\n                        'state': state,\n                        'count': count,\n                        'dag_id': dag_id,\n                        'color': State.color(state)\n                    })\n        return wwwutils.json_response(payload)\n\n    @expose('/task_stats')\n    @has_access\n    @provide_session\n    def task_stats(self, session=None):\n        TI = models.TaskInstance\n        DagRun = models.DagRun\n        Dag = models.DagModel\n\n        filter_dag_ids = appbuilder.sm.get_accessible_dag_ids()\n\n        payload = {}\n        if not filter_dag_ids:\n            return\n\n        LastDagRun = (\n            session.query(\n                DagRun.dag_id,\n                sqla.func.max(DagRun.execution_date).label('execution_date')\n            )\n            .join(Dag, Dag.dag_id == DagRun.dag_id)\n            .filter(DagRun.state != State.RUNNING, Dag.is_active)\n            .group_by(DagRun.dag_id)\n            .subquery('last_dag_run')\n        )\n        RunningDagRun = (\n            session.query(DagRun.dag_id, DagRun.execution_date)\n                   .join(Dag, Dag.dag_id == DagRun.dag_id)\n                   .filter(DagRun.state == State.RUNNING, Dag.is_active)\n                   .subquery('running_dag_run')\n        )\n\n        # Select all task_instances from active dag_runs.\n        # If no dag_run is active, return task instances from most recent dag_run.\n        LastTI = (\n            session.query(TI.dag_id.label('dag_id'), TI.state.label('state'))\n                   .join(LastDagRun,\n                         and_(LastDagRun.c.dag_id == TI.dag_id,\n                              LastDagRun.c.execution_date == TI.execution_date))\n        )\n        RunningTI = (\n            session.query(TI.dag_id.label('dag_id'), TI.state.label('state'))\n                   .join(RunningDagRun,\n                         and_(RunningDagRun.c.dag_id == TI.dag_id,\n                              RunningDagRun.c.execution_date == TI.execution_date))\n        )\n\n        UnionTI = union_all(LastTI, RunningTI).alias('union_ti')\n        qry = (\n            session.query(UnionTI.c.dag_id, UnionTI.c.state, sqla.func.count())\n                   .group_by(UnionTI.c.dag_id, UnionTI.c.state)\n        )\n\n        data = {}\n        for dag_id, state, count in qry:\n            if 'all_dags' in filter_dag_ids or dag_id in filter_dag_ids:\n                if dag_id not in data:\n                    data[dag_id] = {}\n                data[dag_id][state] = count\n        session.commit()\n\n        if 'all_dags' in filter_dag_ids:\n            filter_dag_ids = [dag_id for dag_id, in session.query(models.DagModel.dag_id)]\n        for dag_id in filter_dag_ids:\n            payload[dag_id] = []\n            for state in State.task_states:\n                count = data.get(dag_id, {}).get(state, 0)\n                payload[dag_id].append({\n                    'state': state,\n                    'count': count,\n                    'dag_id': dag_id,\n                    'color': State.color(state)\n                })\n        return wwwutils.json_response(payload)\n\n    @expose('/last_dagruns')\n    @has_access\n    @provide_session\n    def last_dagruns(self, session=None):\n        DagRun = models.DagRun\n\n        filter_dag_ids = appbuilder.sm.get_accessible_dag_ids()\n\n        if not filter_dag_ids:\n            return\n\n        dags_to_latest_runs = dict(session.query(\n            DagRun.dag_id, sqla.func.max(DagRun.execution_date).label('execution_date'))\n            .group_by(DagRun.dag_id).all())\n\n        payload = {}\n        for dag in dagbag.dags.values():\n            dag_accessible = 'all_dags' in filter_dag_ids or dag.dag_id in filter_dag_ids\n            if (dag_accessible and dag.dag_id in dags_to_latest_runs and\n                    dags_to_latest_runs[dag.dag_id]):\n                payload[dag.safe_dag_id] = {\n                    'dag_id': dag.dag_id,\n                    'last_run': dags_to_latest_runs[dag.dag_id].strftime(\"%Y-%m-%d %H:%M\")\n                }\n\n        return wwwutils.json_response(payload)\n\n    @expose('/code')\n    @has_dag_access(can_dag_read=True)\n    @has_access\n    @provide_session\n    def code(self, session=None):\n        dm = models.DagModel\n        dag_id = request.args.get('dag_id')\n        dag = session.query(dm).filter(dm.dag_id == dag_id).first()\n        try:\n            with wwwutils.open_maybe_zipped(dag.fileloc, 'r') as f:\n                code = f.read()\n            html_code = highlight(\n                code, lexers.PythonLexer(), HtmlFormatter(linenos=True))\n        except OSError as e:\n            html_code = str(e)\n\n        return self.render_template(\n            'airflow/dag_code.html', html_code=html_code, dag=dag, title=dag_id,\n            root=request.args.get('root'),\n            demo_mode=conf.getboolean('webserver', 'demo_mode'),\n            wrapped=conf.getboolean('webserver', 'default_wrap'))\n\n    @expose('/dag_details')\n    @has_dag_access(can_dag_read=True)\n    @has_access\n    @provide_session\n    def dag_details(self, session=None):\n        dag_id = request.args.get('dag_id')\n        dag_orm = DagModel.get_dagmodel(dag_id)\n        # FIXME: items needed for this view should move to the database\n        dag = dag_orm.get_dag()\n        title = \"DAG details\"\n        root = request.args.get('root', '')\n\n        TI = models.TaskInstance\n        states = (\n            session.query(TI.state, sqla.func.count(TI.dag_id))\n                   .filter(TI.dag_id == dag_id)\n                   .group_by(TI.state)\n                   .all()\n        )\n\n        active_runs = models.DagRun.find(\n            dag_id=dag_id,\n            state=State.RUNNING,\n            external_trigger=False\n        )\n\n        return self.render_template(\n            'airflow/dag_details.html',\n            dag=dag, title=title, root=root, states=states, State=State, active_runs=active_runs)\n\n    @expose('/rendered')\n    @has_dag_access(can_dag_read=True)\n    @has_access\n    @action_logging\n    def rendered(self):\n        dag_id = request.args.get('dag_id')\n        task_id = request.args.get('task_id')\n        execution_date = request.args.get('execution_date')\n        dttm = pendulum.parse(execution_date)\n        form = DateTimeForm(data={'execution_date': dttm})\n        root = request.args.get('root', '')\n        dag = dagbag.get_dag(dag_id)\n        task = copy.copy(dag.get_task(task_id))\n        ti = models.TaskInstance(task=task, execution_date=dttm)\n        try:\n            ti.render_templates()\n        except Exception as e:\n            flash(\"Error rendering template: \" + str(e), \"error\")\n        title = \"Rendered Template\"\n        html_dict = {}\n        for template_field in task.__class__.template_fields:\n            content = getattr(task, template_field)\n            if template_field in wwwutils.get_attr_renderer():\n                html_dict[template_field] = \\\n                    wwwutils.get_attr_renderer()[template_field](content)\n            else:\n                html_dict[template_field] = (\n                    \"<pre><code>\" + str(content) + \"</pre></code>\")\n\n        return self.render_template(\n            'airflow/ti_code.html',\n            html_dict=html_dict,\n            dag=dag,\n            task_id=task_id,\n            execution_date=execution_date,\n            form=form,\n            root=root,\n            title=title)\n\n    @expose('/get_logs_with_metadata')\n    @has_dag_access(can_dag_read=True)\n    @has_access\n    @action_logging\n    @provide_session\n    def get_logs_with_metadata(self, session=None):\n        dag_id = request.args.get('dag_id')\n        task_id = request.args.get('task_id')\n        execution_date = request.args.get('execution_date')\n        dttm = pendulum.parse(execution_date)\n        if request.args.get('try_number') is not None:\n            try_number = int(request.args.get('try_number'))\n        else:\n            try_number = None\n        metadata = request.args.get('metadata')\n        metadata = json.loads(metadata)\n        response_format = request.args.get('format', 'json')\n\n        # metadata may be null\n        if not metadata:\n            metadata = {}\n\n        # Convert string datetime into actual datetime\n        try:\n            execution_date = timezone.parse(execution_date)\n        except ValueError:\n            error_message = (\n                'Given execution date, {}, could not be identified '\n                'as a date. Example date format: 2015-11-16T14:34:15+00:00'.format(\n                    execution_date))\n            response = jsonify({'error': error_message})\n            response.status_code = 400\n\n            return response\n\n        logger = logging.getLogger('airflow.task')\n        task_log_reader = conf.get('core', 'task_log_reader')\n        handler = next((handler for handler in logger.handlers\n                        if handler.name == task_log_reader), None)\n\n        ti = session.query(models.TaskInstance).filter(\n            models.TaskInstance.dag_id == dag_id,\n            models.TaskInstance.task_id == task_id,\n            models.TaskInstance.execution_date == dttm).first()\n\n        def _get_logs_with_metadata(try_number, metadata):\n            if ti is None:\n                logs = [\"*** Task instance did not exist in the DB\\n\"]\n                metadata['end_of_log'] = True\n            else:\n                logs, metadatas = handler.read(ti, try_number, metadata=metadata)\n                metadata = metadatas[0]\n            return logs, metadata\n\n        try:\n            if ti is not None:\n                dag = dagbag.get_dag(dag_id)\n                ti.task = dag.get_task(ti.task_id)\n            if response_format == 'json':\n                logs, metadata = _get_logs_with_metadata(try_number, metadata)\n                message = logs[0] if try_number is not None else logs\n                return jsonify(message=message, metadata=metadata)\n\n            filename_template = conf.get('core', 'LOG_FILENAME_TEMPLATE')\n            attachment_filename = render_log_filename(\n                ti=ti,\n                try_number=\"all\" if try_number is None else try_number,\n                filename_template=filename_template)\n            metadata['download_logs'] = True\n\n            def _generate_log_stream(try_number, metadata):\n                if try_number is None and ti is not None:\n                    next_try = ti.next_try_number\n                    try_numbers = list(range(1, next_try))\n                else:\n                    try_numbers = [try_number]\n                for try_number in try_numbers:\n                    metadata.pop('end_of_log', None)\n                    metadata.pop('max_offset', None)\n                    metadata.pop('offset', None)\n                    while 'end_of_log' not in metadata or not metadata['end_of_log']:\n                        logs, metadata = _get_logs_with_metadata(try_number, metadata)\n                        yield \"\\n\".join(logs) + \"\\n\"\n            return Response(_generate_log_stream(try_number, metadata),\n                            mimetype=\"text/plain\",\n                            headers={\"Content-Disposition\": \"attachment; filename={}\".format(\n                                attachment_filename)})\n        except AttributeError as e:\n            error_message = [\"Task log handler {} does not support read logs.\\n{}\\n\"\n                             .format(task_log_reader, str(e))]\n            metadata['end_of_log'] = True\n            return jsonify(message=error_message, error=True, metadata=metadata)\n\n    @expose('/log')\n    @has_dag_access(can_dag_read=True)\n    @has_access\n    @action_logging\n    @provide_session\n    def log(self, session=None):\n        dag_id = request.args.get('dag_id')\n        task_id = request.args.get('task_id')\n        execution_date = request.args.get('execution_date')\n        dttm = pendulum.parse(execution_date)\n        form = DateTimeForm(data={'execution_date': dttm})\n        dag_model = DagModel.get_dagmodel(dag_id)\n\n        ti = session.query(models.TaskInstance).filter(\n            models.TaskInstance.dag_id == dag_id,\n            models.TaskInstance.task_id == task_id,\n            models.TaskInstance.execution_date == dttm).first()\n\n        num_logs = 0\n        if ti is not None:\n            num_logs = ti.next_try_number - 1\n            if ti.state == State.UP_FOR_RESCHEDULE:\n                # Tasks in reschedule state decremented the try number\n                num_logs += 1\n        logs = [''] * num_logs\n        root = request.args.get('root', '')\n        return self.render_template(\n            'airflow/ti_log.html',\n            logs=logs, dag=dag_model, title=\"Log by attempts\",\n            dag_id=dag_id, task_id=task_id,\n            execution_date=execution_date, form=form,\n            root=root, wrapped=conf.getboolean('webserver', 'default_wrap'))\n\n    @expose('/elasticsearch')\n    @has_dag_access(can_dag_read=True)\n    @has_access\n    @action_logging\n    @provide_session\n    def elasticsearch(self, session=None):\n        dag_id = request.args.get('dag_id')\n        task_id = request.args.get('task_id')\n        execution_date = request.args.get('execution_date')\n        try_number = request.args.get('try_number', 1)\n        elasticsearch_frontend = conf.get('elasticsearch', 'frontend')\n        log_id_template = conf.get('elasticsearch', 'log_id_template')\n        log_id = log_id_template.format(\n            dag_id=dag_id, task_id=task_id,\n            execution_date=execution_date, try_number=try_number)\n        url = 'https://' + elasticsearch_frontend.format(log_id=quote(log_id))\n        return redirect(url)\n\n    @expose('/task')\n    @has_dag_access(can_dag_read=True)\n    @has_access\n    @action_logging\n    def task(self):\n        TI = models.TaskInstance\n\n        dag_id = request.args.get('dag_id')\n        task_id = request.args.get('task_id')\n        # Carrying execution_date through, even though it's irrelevant for\n        # this context\n        execution_date = request.args.get('execution_date')\n        dttm = pendulum.parse(execution_date)\n        form = DateTimeForm(data={'execution_date': dttm})\n        root = request.args.get('root', '')\n        dag = dagbag.get_dag(dag_id)\n\n        if not dag or task_id not in dag.task_ids:\n            flash(\n                \"Task [{}.{}] doesn't seem to exist\"\n                \" at the moment\".format(dag_id, task_id),\n                \"error\")\n            return redirect(url_for('Airflow.index'))\n        task = copy.copy(dag.get_task(task_id))\n        task.resolve_template_files()\n        ti = TI(task=task, execution_date=dttm)\n        ti.refresh_from_db()\n\n        ti_attrs = []\n        for attr_name in dir(ti):\n            if not attr_name.startswith('_'):\n                attr = getattr(ti, attr_name)\n                if type(attr) != type(self.task):  # noqa\n                    ti_attrs.append((attr_name, str(attr)))\n\n        task_attrs = []\n        for attr_name in dir(task):\n            if not attr_name.startswith('_'):\n                attr = getattr(task, attr_name)\n                if type(attr) != type(self.task) and \\\n                        attr_name not in wwwutils.get_attr_renderer():  # noqa\n                    task_attrs.append((attr_name, str(attr)))\n\n        # Color coding the special attributes that are code\n        special_attrs_rendered = {}\n        for attr_name in wwwutils.get_attr_renderer():\n            if hasattr(task, attr_name):\n                source = getattr(task, attr_name)\n                special_attrs_rendered[attr_name] = \\\n                    wwwutils.get_attr_renderer()[attr_name](source)\n\n        no_failed_deps_result = [(\n            \"Unknown\",\n            \"All dependencies are met but the task instance is not running. In most \"\n            \"cases this just means that the task will probably be scheduled soon \"\n            \"unless:<br/>\\n- The scheduler is down or under heavy load<br/>\\n{}\\n\"\n            \"<br/>\\nIf this task instance does not start soon please contact your \"\n            \"Airflow administrator for assistance.\".format(\n                \"- This task instance already ran and had it's state changed manually \"\n                \"(e.g. cleared in the UI)<br/>\" if ti.state == State.NONE else \"\"))]\n\n        # Use the scheduler's context to figure out which dependencies are not met\n        dep_context = DepContext(SCHEDULER_QUEUED_DEPS)\n        failed_dep_reasons = [(dep.dep_name, dep.reason) for dep in\n                              ti.get_failed_dep_statuses(\n                                  dep_context=dep_context)]\n\n        title = \"Task Instance Details\"\n        return self.render_template(\n            'airflow/task.html',\n            task_attrs=task_attrs,\n            ti_attrs=ti_attrs,\n            failed_dep_reasons=failed_dep_reasons or no_failed_deps_result,\n            task_id=task_id,\n            execution_date=execution_date,\n            special_attrs_rendered=special_attrs_rendered,\n            form=form,\n            root=root,\n            dag=dag, title=title)\n\n    @expose('/xcom')\n    @has_dag_access(can_dag_read=True)\n    @has_access\n    @action_logging\n    @provide_session\n    def xcom(self, session=None):\n        dag_id = request.args.get('dag_id')\n        task_id = request.args.get('task_id')\n        # Carrying execution_date through, even though it's irrelevant for\n        # this context\n        execution_date = request.args.get('execution_date')\n        dttm = pendulum.parse(execution_date)\n        form = DateTimeForm(data={'execution_date': dttm})\n        root = request.args.get('root', '')\n        dm_db = models.DagModel\n        ti_db = models.TaskInstance\n        dag = session.query(dm_db).filter(dm_db.dag_id == dag_id).first()\n        ti = session.query(ti_db).filter(ti_db.dag_id == dag_id and ti_db.task_id == task_id).first()\n\n        if not ti:\n            flash(\n                \"Task [{}.{}] doesn't seem to exist\"\n                \" at the moment\".format(dag_id, task_id),\n                \"error\")\n            return redirect(url_for('Airflow.index'))\n\n        xcomlist = session.query(XCom).filter(\n            XCom.dag_id == dag_id, XCom.task_id == task_id,\n            XCom.execution_date == dttm).all()\n\n        attributes = []\n        for xcom in xcomlist:\n            if not xcom.key.startswith('_'):\n                attributes.append((xcom.key, xcom.value))\n\n        title = \"XCom\"\n        return self.render_template(\n            'airflow/xcom.html',\n            attributes=attributes,\n            task_id=task_id,\n            execution_date=execution_date,\n            form=form,\n            root=root,\n            dag=dag, title=title)\n\n    @expose('/run', methods=['POST'])\n    @has_dag_access(can_dag_edit=True)\n    @has_access\n    @action_logging\n    def run(self):\n        dag_id = request.form.get('dag_id')\n        task_id = request.form.get('task_id')\n        origin = request.form.get('origin')\n        dag = dagbag.get_dag(dag_id)\n        task = dag.get_task(task_id)\n\n        execution_date = request.form.get('execution_date')\n        execution_date = pendulum.parse(execution_date)\n        ignore_all_deps = request.form.get('ignore_all_deps') == \"true\"\n        ignore_task_deps = request.form.get('ignore_task_deps') == \"true\"\n        ignore_ti_state = request.form.get('ignore_ti_state') == \"true\"\n\n        from airflow.executors import get_default_executor\n        executor = get_default_executor()\n        valid_celery_config = False\n        valid_kubernetes_config = False\n\n        try:\n            from airflow.executors.celery_executor import CeleryExecutor\n            valid_celery_config = isinstance(executor, CeleryExecutor)\n        except ImportError:\n            pass\n\n        try:\n            from airflow.executors.kubernetes_executor import KubernetesExecutor\n            valid_kubernetes_config = isinstance(executor, KubernetesExecutor)\n        except ImportError:\n            pass\n\n        if not valid_celery_config and not valid_kubernetes_config:\n            flash(\"Only works with the Celery or Kubernetes executors, sorry\", \"error\")\n            return redirect(origin)\n\n        ti = models.TaskInstance(task=task, execution_date=execution_date)\n        ti.refresh_from_db()\n\n        # Make sure the task instance can be queued\n        dep_context = DepContext(\n            deps=SCHEDULER_QUEUED_DEPS,\n            ignore_all_deps=ignore_all_deps,\n            ignore_task_deps=ignore_task_deps,\n            ignore_ti_state=ignore_ti_state)\n        failed_deps = list(ti.get_failed_dep_statuses(dep_context=dep_context))\n        if failed_deps:\n            failed_deps_str = \", \".join(\n                [\"{}: {}\".format(dep.dep_name, dep.reason) for dep in failed_deps])\n            flash(\"Could not queue task instance for execution, dependencies not met: \"\n                  \"{}\".format(failed_deps_str),\n                  \"error\")\n            return redirect(origin)\n\n        executor.start()\n        executor.queue_task_instance(\n            ti,\n            ignore_all_deps=ignore_all_deps,\n            ignore_task_deps=ignore_task_deps,\n            ignore_ti_state=ignore_ti_state)\n        executor.heartbeat()\n        flash(\n            \"Sent {} to the message queue, \"\n            \"it should start any moment now.\".format(ti))\n        return redirect(origin)\n\n    @expose('/delete', methods=['POST'])\n    @has_dag_access(can_dag_edit=True)\n    @has_access\n    @action_logging\n    def delete(self):\n        from airflow.api.common.experimental import delete_dag\n        from airflow.exceptions import DagNotFound, DagFileExists\n\n        dag_id = request.values.get('dag_id')\n        origin = request.values.get('origin') or url_for('Airflow.index')\n\n        try:\n            delete_dag.delete_dag(dag_id)\n        except DagNotFound:\n            flash(\"DAG with id {} not found. Cannot delete\".format(dag_id), 'error')\n            return redirect(request.referrer)\n        except DagFileExists:\n            flash(\"Dag id {} is still in DagBag. \"\n                  \"Remove the DAG file first.\".format(dag_id),\n                  'error')\n            return redirect(request.referrer)\n\n        flash(\"Deleting DAG with id {}. May take a couple minutes to fully\"\n              \" disappear.\".format(dag_id))\n\n        # Upon success return to origin.\n        return redirect(origin)\n\n    @expose('/trigger', methods=['POST'])\n    @has_dag_access(can_dag_edit=True)\n    @has_access\n    @action_logging\n    @provide_session\n    def trigger(self, session=None):\n        dag_id = request.values.get('dag_id')\n        origin = request.values.get('origin') or url_for('Airflow.index')\n        dag = session.query(models.DagModel).filter(models.DagModel.dag_id == dag_id).first()\n        if not dag:\n            flash(\"Cannot find dag {}\".format(dag_id))\n            return redirect(origin)\n\n        execution_date = timezone.utcnow()\n        run_id = \"manual__{0}\".format(execution_date.isoformat())\n\n        dr = DagRun.find(dag_id=dag_id, run_id=run_id)\n        if dr:\n            flash(\"This run_id {} already exists\".format(run_id))\n            return redirect(origin)\n\n        run_conf = {}\n\n        dag.create_dagrun(\n            run_id=run_id,\n            execution_date=execution_date,\n            state=State.RUNNING,\n            conf=run_conf,\n            external_trigger=True\n        )\n\n        flash(\n            \"Triggered {}, \"\n            \"it should start any moment now.\".format(dag_id))\n        return redirect(origin)\n\n    def _clear_dag_tis(self, dag, start_date, end_date, origin,\n                       recursive=False, confirmed=False, only_failed=False):\n        if confirmed:\n            count = dag.clear(\n                start_date=start_date,\n                end_date=end_date,\n                include_subdags=recursive,\n                include_parentdag=recursive,\n                only_failed=only_failed,\n            )\n\n            flash(\"{0} task instances have been cleared\".format(count))\n            return redirect(origin)\n\n        tis = dag.clear(\n            start_date=start_date,\n            end_date=end_date,\n            include_subdags=recursive,\n            include_parentdag=recursive,\n            only_failed=only_failed,\n            dry_run=True,\n        )\n        if not tis:\n            flash(\"No task instances to clear\", 'error')\n            response = redirect(origin)\n        else:\n            details = \"\\n\".join([str(t) for t in tis])\n\n            response = self.render_template(\n                'airflow/confirm.html',\n                message=(\"Here's the list of task instances you are about \"\n                         \"to clear:\"),\n                details=details)\n\n        return response\n\n    @expose('/clear', methods=['POST'])\n    @has_dag_access(can_dag_edit=True)\n    @has_access\n    @action_logging\n    def clear(self):\n        dag_id = request.form.get('dag_id')\n        task_id = request.form.get('task_id')\n        origin = request.form.get('origin')\n        dag = dagbag.get_dag(dag_id)\n\n        execution_date = request.form.get('execution_date')\n        execution_date = pendulum.parse(execution_date)\n        confirmed = request.form.get('confirmed') == \"true\"\n        upstream = request.form.get('upstream') == \"true\"\n        downstream = request.form.get('downstream') == \"true\"\n        future = request.form.get('future') == \"true\"\n        past = request.form.get('past') == \"true\"\n        recursive = request.form.get('recursive') == \"true\"\n        only_failed = request.form.get('only_failed') == \"true\"\n\n        dag = dag.sub_dag(\n            task_regex=r\"^{0}$\".format(task_id),\n            include_downstream=downstream,\n            include_upstream=upstream)\n\n        end_date = execution_date if not future else None\n        start_date = execution_date if not past else None\n\n        return self._clear_dag_tis(dag, start_date, end_date, origin,\n                                   recursive=recursive, confirmed=confirmed, only_failed=only_failed)\n\n    @expose('/dagrun_clear', methods=['POST'])\n    @has_dag_access(can_dag_edit=True)\n    @has_access\n    @action_logging\n    def dagrun_clear(self):\n        dag_id = request.form.get('dag_id')\n        origin = request.form.get('origin')\n        execution_date = request.form.get('execution_date')\n        confirmed = request.form.get('confirmed') == \"true\"\n\n        dag = dagbag.get_dag(dag_id)\n        execution_date = pendulum.parse(execution_date)\n        start_date = execution_date\n        end_date = execution_date\n\n        return self._clear_dag_tis(dag, start_date, end_date, origin,\n                                   recursive=True, confirmed=confirmed)\n\n    @expose('/blocked')\n    @has_access\n    @provide_session\n    def blocked(self, session=None):\n        DR = models.DagRun\n        filter_dag_ids = appbuilder.sm.get_accessible_dag_ids()\n\n        payload = []\n        if filter_dag_ids:\n            dags = (\n                session.query(DR.dag_id, sqla.func.count(DR.id))\n                       .filter(DR.state == State.RUNNING)\n                       .group_by(DR.dag_id)\n\n            )\n            if 'all_dags' not in filter_dag_ids:\n                dags = dags.filter(DR.dag_id.in_(filter_dag_ids))\n            dags = dags.all()\n\n            for dag_id, active_dag_runs in dags:\n                max_active_runs = 0\n                if dag_id in dagbag.dags:\n                    max_active_runs = dagbag.dags[dag_id].max_active_runs\n                payload.append({\n                    'dag_id': dag_id,\n                    'active_dag_run': active_dag_runs,\n                    'max_active_runs': max_active_runs,\n                })\n        return wwwutils.json_response(payload)\n\n    def _mark_dagrun_state_as_failed(self, dag_id, execution_date, confirmed, origin):\n        if not execution_date:\n            flash('Invalid execution date', 'error')\n            return redirect(origin)\n\n        execution_date = pendulum.parse(execution_date)\n        dag = dagbag.get_dag(dag_id)\n\n        if not dag:\n            flash('Cannot find DAG: {}'.format(dag_id), 'error')\n            return redirect(origin)\n\n        new_dag_state = set_dag_run_state_to_failed(dag, execution_date, commit=confirmed)\n\n        if confirmed:\n            flash('Marked failed on {} task instances'.format(len(new_dag_state)))\n            return redirect(origin)\n\n        else:\n            details = '\\n'.join([str(t) for t in new_dag_state])\n\n            response = self.render_template(\n                'airflow/confirm.html',\n                message=(\"Here's the list of task instances you are about to mark as failed\"),\n                details=details)\n\n            return response\n\n    def _mark_dagrun_state_as_success(self, dag_id, execution_date, confirmed, origin):\n        if not execution_date:\n            flash('Invalid execution date', 'error')\n            return redirect(origin)\n\n        execution_date = pendulum.parse(execution_date)\n        dag = dagbag.get_dag(dag_id)\n\n        if not dag:\n            flash('Cannot find DAG: {}'.format(dag_id), 'error')\n            return redirect(origin)\n\n        new_dag_state = set_dag_run_state_to_success(dag, execution_date,\n                                                     commit=confirmed)\n\n        if confirmed:\n            flash('Marked success on {} task instances'.format(len(new_dag_state)))\n            return redirect(origin)\n\n        else:\n            details = '\\n'.join([str(t) for t in new_dag_state])\n\n            response = self.render_template(\n                'airflow/confirm.html',\n                message=(\"Here's the list of task instances you are about to mark as success\"),\n                details=details)\n\n            return response\n\n    @expose('/dagrun_failed', methods=['POST'])\n    @has_dag_access(can_dag_edit=True)\n    @has_access\n    @action_logging\n    def dagrun_failed(self):\n        dag_id = request.form.get('dag_id')\n        execution_date = request.form.get('execution_date')\n        confirmed = request.form.get('confirmed') == 'true'\n        origin = request.form.get('origin')\n        return self._mark_dagrun_state_as_failed(dag_id, execution_date,\n                                                 confirmed, origin)\n\n    @expose('/dagrun_success', methods=['POST'])\n    @has_dag_access(can_dag_edit=True)\n    @has_access\n    @action_logging\n    def dagrun_success(self):\n        dag_id = request.form.get('dag_id')\n        execution_date = request.form.get('execution_date')\n        confirmed = request.form.get('confirmed') == 'true'\n        origin = request.form.get('origin')\n        return self._mark_dagrun_state_as_success(dag_id, execution_date,\n                                                  confirmed, origin)\n\n    def _mark_task_instance_state(self, dag_id, task_id, origin, execution_date,\n                                  confirmed, upstream, downstream,\n                                  future, past, state):\n        dag = dagbag.get_dag(dag_id)\n        task = dag.get_task(task_id)\n        task.dag = dag\n\n        execution_date = pendulum.parse(execution_date)\n\n        if not dag:\n            flash(\"Cannot find DAG: {}\".format(dag_id))\n            return redirect(origin)\n\n        if not task:\n            flash(\"Cannot find task {} in DAG {}\".format(task_id, dag.dag_id))\n            return redirect(origin)\n\n        from airflow.api.common.experimental.mark_tasks import set_state\n\n        if confirmed:\n            altered = set_state(tasks=[task], execution_date=execution_date,\n                                upstream=upstream, downstream=downstream,\n                                future=future, past=past, state=state,\n                                commit=True)\n\n            flash(\"Marked {} on {} task instances\".format(state, len(altered)))\n            return redirect(origin)\n\n        to_be_altered = set_state(tasks=[task], execution_date=execution_date,\n                                  upstream=upstream, downstream=downstream,\n                                  future=future, past=past, state=state,\n                                  commit=False)\n\n        details = \"\\n\".join([str(t) for t in to_be_altered])\n\n        response = self.render_template(\n            \"airflow/confirm.html\",\n            message=(\"Here's the list of task instances you are about to mark as {}:\".format(state)),\n            details=details)\n\n        return response\n\n    @expose('/failed', methods=['POST'])\n    @has_dag_access(can_dag_edit=True)\n    @has_access\n    @action_logging\n    def failed(self):\n        dag_id = request.form.get('dag_id')\n        task_id = request.form.get('task_id')\n        origin = request.form.get('origin')\n        execution_date = request.form.get('execution_date')\n\n        confirmed = request.form.get('confirmed') == \"true\"\n        upstream = request.form.get('failed_upstream') == \"true\"\n        downstream = request.form.get('failed_downstream') == \"true\"\n        future = request.form.get('failed_future') == \"true\"\n        past = request.form.get('failed_past') == \"true\"\n\n        return self._mark_task_instance_state(dag_id, task_id, origin, execution_date,\n                                              confirmed, upstream, downstream,\n                                              future, past, State.FAILED)\n\n    @expose('/success', methods=['POST'])\n    @has_dag_access(can_dag_edit=True)\n    @has_access\n    @action_logging\n    def success(self):\n        dag_id = request.form.get('dag_id')\n        task_id = request.form.get('task_id')\n        origin = request.form.get('origin')\n        execution_date = request.form.get('execution_date')\n\n        confirmed = request.form.get('confirmed') == \"true\"\n        upstream = request.form.get('success_upstream') == \"true\"\n        downstream = request.form.get('success_downstream') == \"true\"\n        future = request.form.get('success_future') == \"true\"\n        past = request.form.get('success_past') == \"true\"\n\n        return self._mark_task_instance_state(dag_id, task_id, origin, execution_date,\n                                              confirmed, upstream, downstream,\n                                              future, past, State.SUCCESS)\n\n    @expose('/tree')\n    @has_dag_access(can_dag_read=True)\n    @has_access\n    @gzipped\n    @action_logging\n    def tree(self):\n        default_dag_run = conf.getint('webserver', 'default_dag_run_display_number')\n        dag_id = request.args.get('dag_id')\n        blur = conf.getboolean('webserver', 'demo_mode')\n        dag_model = DagModel.get_dagmodel(dag_id)\n        if not dag_model:\n            flash('DAG \"{0}\" seems to be missing in database.'.format(dag_id), \"error\")\n            return redirect(url_for('Airflow.index'))\n        dag = dag_model.get_dag()\n\n        if dag is None:\n            dag = dagbag.get_dag(dag_id)\n            if dag is None:\n                flash('DAG \"{0}\" seems to be missing from DagBag.'.format(dag_id), \"error\")\n                return redirect(url_for('Airflow.index'))\n\n        root = request.args.get('root')\n        if root:\n            dag = dag.sub_dag(\n                task_regex=root,\n                include_downstream=False,\n                include_upstream=True)\n\n        base_date = request.args.get('base_date')\n        num_runs = request.args.get('num_runs')\n        num_runs = int(num_runs) if num_runs else default_dag_run\n\n        if base_date:\n            base_date = timezone.parse(base_date)\n        else:\n            base_date = dag.latest_execution_date or timezone.utcnow()\n\n        with create_session() as session:\n            dag_runs = (\n                session.query(DagRun)\n                .filter(\n                    DagRun.dag_id == dag.dag_id,\n                    DagRun.execution_date <= base_date)\n                .order_by(DagRun.execution_date.desc())\n                .limit(num_runs)\n                .all()\n            )\n        dag_runs = {\n            dr.execution_date: alchemy_to_dict(dr) for dr in dag_runs}\n\n        dates = sorted(list(dag_runs.keys()))\n        max_date = max(dates) if dates else None\n        min_date = min(dates) if dates else None\n\n        tis = dag.get_task_instances(start_date=min_date, end_date=base_date)\n        task_instances = {}\n        for ti in tis:\n            tid = alchemy_to_dict(ti)\n            dr = dag_runs.get(ti.execution_date)\n            tid['external_trigger'] = dr['external_trigger'] if dr else False\n            task_instances[(ti.task_id, ti.execution_date)] = tid\n\n        expanded = []\n        # The default recursion traces every path so that tree view has full\n        # expand/collapse functionality. After 5,000 nodes we stop and fall\n        # back on a quick DFS search for performance. See PR #320.\n        node_count = [0]\n        node_limit = 5000 / max(1, len(dag.leaves))\n\n        def recurse_nodes(task, visited):\n            visited.add(task)\n            node_count[0] += 1\n\n            children = [\n                recurse_nodes(t, visited) for t in task.downstream_list\n                if node_count[0] < node_limit or t not in visited]\n\n            # D3 tree uses children vs _children to define what is\n            # expanded or not. The following block makes it such that\n            # repeated nodes are collapsed by default.\n            children_key = 'children'\n            if task.task_id not in expanded:\n                expanded.append(task.task_id)\n            elif children:\n                children_key = \"_children\"\n\n            def set_duration(tid):\n                if (isinstance(tid, dict) and tid.get(\"state\") == State.RUNNING and\n                        tid[\"start_date\"] is not None):\n                    d = timezone.utcnow() - pendulum.parse(tid[\"start_date\"])\n                    tid[\"duration\"] = d.total_seconds()\n                return tid\n\n            return {\n                'name': task.task_id,\n                'instances': [\n                    set_duration(task_instances.get((task.task_id, d))) or {\n                        'execution_date': d.isoformat(),\n                        'task_id': task.task_id\n                    }\n                    for d in dates],\n                children_key: children,\n                'num_dep': len(task.downstream_list),\n                'operator': task.task_type,\n                'retries': task.retries,\n                'owner': task.owner,\n                'start_date': task.start_date,\n                'end_date': task.end_date,\n                'depends_on_past': task.depends_on_past,\n                'ui_color': task.ui_color,\n                'extra_links': task.extra_links,\n            }\n\n        data = {\n            'name': '[DAG]',\n            'children': [recurse_nodes(t, set()) for t in dag.roots],\n            'instances': [\n                dag_runs.get(d) or {'execution_date': d.isoformat()}\n                for d in dates],\n        }\n\n        session.commit()\n\n        form = DateTimeWithNumRunsForm(data={'base_date': max_date,\n                                             'num_runs': num_runs})\n        external_logs = conf.get('elasticsearch', 'frontend')\n        return self.render_template(\n            'airflow/tree.html',\n            operators=sorted({op.__class__ for op in dag.tasks}, key=lambda x: x.__name__),\n            root=root,\n            form=form,\n            dag=dag, data=data, blur=blur, num_runs=num_runs,\n            show_external_logs=bool(external_logs))\n\n    @expose('/graph')\n    @has_dag_access(can_dag_read=True)\n    @has_access\n    @gzipped\n    @action_logging\n    @provide_session\n    def graph(self, session=None):\n        dag_id = request.args.get('dag_id')\n        blur = conf.getboolean('webserver', 'demo_mode')\n        dag = dagbag.get_dag(dag_id)\n        if dag_id not in dagbag.dags:\n            flash('DAG \"{0}\" seems to be missing.'.format(dag_id), \"error\")\n            return redirect(url_for('Airflow.index'))\n\n        root = request.args.get('root')\n        if root:\n            dag = dag.sub_dag(\n                task_regex=root,\n                include_upstream=True,\n                include_downstream=False)\n\n        arrange = request.args.get('arrange', dag.orientation)\n\n        nodes = []\n        edges = []\n        for task in dag.tasks:\n            nodes.append({\n                'id': task.task_id,\n                'value': {\n                    'label': task.task_id,\n                    'labelStyle': \"fill:{0};\".format(task.ui_fgcolor),\n                    'style': \"fill:{0};\".format(task.ui_color),\n                    'rx': 5,\n                    'ry': 5,\n                }\n            })\n\n        def get_downstream(task):\n            for t in task.downstream_list:\n                edge = {\n                    'source_id': task.task_id,\n                    'target_id': t.task_id,\n                }\n                if edge not in edges:\n                    edges.append(edge)\n                    get_downstream(t)\n\n        for t in dag.roots:\n            get_downstream(t)\n\n        dt_nr_dr_data = get_date_time_num_runs_dag_runs_form_data(request, session, dag)\n        dt_nr_dr_data['arrange'] = arrange\n        dttm = dt_nr_dr_data['dttm']\n\n        class GraphForm(DateTimeWithNumRunsWithDagRunsForm):\n            arrange = SelectField(\"Layout\", choices=(\n                ('LR', \"Left->Right\"),\n                ('RL', \"Right->Left\"),\n                ('TB', \"Top->Bottom\"),\n                ('BT', \"Bottom->Top\"),\n            ))\n\n        form = GraphForm(data=dt_nr_dr_data)\n        form.execution_date.choices = dt_nr_dr_data['dr_choices']\n\n        task_instances = {\n            ti.task_id: alchemy_to_dict(ti)\n            for ti in dag.get_task_instances(dttm, dttm)}\n        tasks = {\n            t.task_id: {\n                'dag_id': t.dag_id,\n                'task_type': t.task_type,\n                'extra_links': t.extra_links,\n            }\n            for t in dag.tasks}\n        if not tasks:\n            flash(\"No tasks found\", \"error\")\n        session.commit()\n        doc_md = markdown.markdown(dag.doc_md) \\\n            if hasattr(dag, 'doc_md') and dag.doc_md else ''\n\n        external_logs = conf.get('elasticsearch', 'frontend')\n        return self.render_template(\n            'airflow/graph.html',\n            dag=dag,\n            form=form,\n            width=request.args.get('width', \"100%\"),\n            height=request.args.get('height', \"800\"),\n            execution_date=dttm.isoformat(),\n            state_token=wwwutils.state_token(dt_nr_dr_data['dr_state']),\n            doc_md=doc_md,\n            arrange=arrange,\n            operators=sorted({op.__class__ for op in dag.tasks}, key=lambda x: x.__name__),\n            blur=blur,\n            root=root or '',\n            task_instances=task_instances,\n            tasks=tasks,\n            nodes=nodes,\n            edges=edges,\n            show_external_logs=bool(external_logs))\n\n    @expose('/duration')\n    @has_dag_access(can_dag_read=True)\n    @has_access\n    @action_logging\n    @provide_session\n    def duration(self, session=None):\n        default_dag_run = conf.getint('webserver', 'default_dag_run_display_number')\n        dag_id = request.args.get('dag_id')\n        dag = dagbag.get_dag(dag_id)\n        base_date = request.args.get('base_date')\n        num_runs = request.args.get('num_runs')\n        num_runs = int(num_runs) if num_runs else default_dag_run\n\n        if dag is None:\n            flash('DAG \"{0}\" seems to be missing.'.format(dag_id), \"error\")\n            return redirect(url_for('Airflow.index'))\n\n        if base_date:\n            base_date = pendulum.parse(base_date)\n        else:\n            base_date = dag.latest_execution_date or timezone.utcnow()\n\n        dates = dag.date_range(base_date, num=-abs(num_runs))\n        min_date = dates[0] if dates else timezone.utc_epoch()\n\n        root = request.args.get('root')\n        if root:\n            dag = dag.sub_dag(\n                task_regex=root,\n                include_upstream=True,\n                include_downstream=False)\n\n        chart_height = wwwutils.get_chart_height(dag)\n        chart = nvd3.lineChart(\n            name=\"lineChart\", x_is_date=True, height=chart_height, width=\"1200\")\n        cum_chart = nvd3.lineChart(\n            name=\"cumLineChart\", x_is_date=True, height=chart_height, width=\"1200\")\n\n        y = defaultdict(list)\n        x = defaultdict(list)\n        cum_y = defaultdict(list)\n\n        tis = dag.get_task_instances(start_date=min_date, end_date=base_date)\n        TF = TaskFail\n        ti_fails = (\n            session.query(TF)\n                   .filter(TF.dag_id == dag.dag_id,\n                           TF.execution_date >= min_date,\n                           TF.execution_date <= base_date,\n                           TF.task_id.in_([t.task_id for t in dag.tasks]))\n                   .all()  # noqa\n        )\n\n        fails_totals = defaultdict(int)\n        for tf in ti_fails:\n            dict_key = (tf.dag_id, tf.task_id, tf.execution_date)\n            if tf.duration:\n                fails_totals[dict_key] += tf.duration\n\n        for ti in tis:\n            if ti.duration:\n                dttm = wwwutils.epoch(ti.execution_date)\n                x[ti.task_id].append(dttm)\n                y[ti.task_id].append(float(ti.duration))\n                fails_dict_key = (ti.dag_id, ti.task_id, ti.execution_date)\n                fails_total = fails_totals[fails_dict_key]\n                cum_y[ti.task_id].append(float(ti.duration + fails_total))\n\n        # determine the most relevant time unit for the set of task instance\n        # durations for the DAG\n        y_unit = infer_time_unit([d for t in y.values() for d in t])\n        cum_y_unit = infer_time_unit([d for t in cum_y.values() for d in t])\n        # update the y Axis on both charts to have the correct time units\n        chart.create_y_axis('yAxis', format='.02f', custom_format=False,\n                            label='Duration ({})'.format(y_unit))\n        chart.axislist['yAxis']['axisLabelDistance'] = '40'\n        cum_chart.create_y_axis('yAxis', format='.02f', custom_format=False,\n                                label='Duration ({})'.format(cum_y_unit))\n        cum_chart.axislist['yAxis']['axisLabelDistance'] = '40'\n\n        for task in dag.tasks:\n            if x[task.task_id]:\n                chart.add_serie(name=task.task_id, x=x[task.task_id],\n                                y=scale_time_units(y[task.task_id], y_unit))\n                cum_chart.add_serie(name=task.task_id, x=x[task.task_id],\n                                    y=scale_time_units(cum_y[task.task_id],\n                                                       cum_y_unit))\n\n        dates = sorted(list({ti.execution_date for ti in tis}))\n        max_date = max([ti.execution_date for ti in tis]) if dates else None\n\n        session.commit()\n\n        form = DateTimeWithNumRunsForm(data={'base_date': max_date,\n                                             'num_runs': num_runs})\n        chart.buildcontent()\n        cum_chart.buildcontent()\n        s_index = cum_chart.htmlcontent.rfind('});')\n        cum_chart.htmlcontent = (cum_chart.htmlcontent[:s_index] +\n                                 \"$( document ).trigger('chartload')\" +\n                                 cum_chart.htmlcontent[s_index:])\n\n        return self.render_template(\n            'airflow/duration_chart.html',\n            dag=dag,\n            demo_mode=conf.getboolean('webserver', 'demo_mode'),\n            root=root,\n            form=form,\n            chart=chart.htmlcontent,\n            cum_chart=cum_chart.htmlcontent\n        )\n\n    @expose('/tries')\n    @has_dag_access(can_dag_read=True)\n    @has_access\n    @action_logging\n    @provide_session\n    def tries(self, session=None):\n        default_dag_run = conf.getint('webserver', 'default_dag_run_display_number')\n        dag_id = request.args.get('dag_id')\n        dag = dagbag.get_dag(dag_id)\n        base_date = request.args.get('base_date')\n        num_runs = request.args.get('num_runs')\n        num_runs = int(num_runs) if num_runs else default_dag_run\n\n        if base_date:\n            base_date = pendulum.parse(base_date)\n        else:\n            base_date = dag.latest_execution_date or timezone.utcnow()\n\n        dates = dag.date_range(base_date, num=-abs(num_runs))\n        min_date = dates[0] if dates else timezone.utc_epoch()\n\n        root = request.args.get('root')\n        if root:\n            dag = dag.sub_dag(\n                task_regex=root,\n                include_upstream=True,\n                include_downstream=False)\n\n        chart_height = wwwutils.get_chart_height(dag)\n        chart = nvd3.lineChart(\n            name=\"lineChart\", x_is_date=True, y_axis_format='d', height=chart_height,\n            width=\"1200\")\n\n        for task in dag.tasks:\n            y = []\n            x = []\n            for ti in task.get_task_instances(start_date=min_date, end_date=base_date):\n                dttm = wwwutils.epoch(ti.execution_date)\n                x.append(dttm)\n                y.append(ti.try_number)\n            if x:\n                chart.add_serie(name=task.task_id, x=x, y=y)\n\n        tis = dag.get_task_instances(start_date=min_date, end_date=base_date)\n        tries = sorted(list({ti.try_number for ti in tis}))\n        max_date = max([ti.execution_date for ti in tis]) if tries else None\n\n        session.commit()\n\n        form = DateTimeWithNumRunsForm(data={'base_date': max_date,\n                                             'num_runs': num_runs})\n\n        chart.buildcontent()\n\n        return self.render_template(\n            'airflow/chart.html',\n            dag=dag,\n            demo_mode=conf.getboolean('webserver', 'demo_mode'),\n            root=root,\n            form=form,\n            chart=chart.htmlcontent\n        )\n\n    @expose('/landing_times')\n    @has_dag_access(can_dag_read=True)\n    @has_access\n    @action_logging\n    @provide_session\n    def landing_times(self, session=None):\n        default_dag_run = conf.getint('webserver', 'default_dag_run_display_number')\n        dag_id = request.args.get('dag_id')\n        dag = dagbag.get_dag(dag_id)\n        base_date = request.args.get('base_date')\n        num_runs = request.args.get('num_runs')\n        num_runs = int(num_runs) if num_runs else default_dag_run\n\n        if base_date:\n            base_date = pendulum.parse(base_date)\n        else:\n            base_date = dag.latest_execution_date or timezone.utcnow()\n\n        dates = dag.date_range(base_date, num=-abs(num_runs))\n        min_date = dates[0] if dates else timezone.utc_epoch()\n\n        root = request.args.get('root')\n        if root:\n            dag = dag.sub_dag(\n                task_regex=root,\n                include_upstream=True,\n                include_downstream=False)\n\n        chart_height = wwwutils.get_chart_height(dag)\n        chart = nvd3.lineChart(\n            name=\"lineChart\", x_is_date=True, height=chart_height, width=\"1200\")\n        y = {}\n        x = {}\n        for task in dag.tasks:\n            y[task.task_id] = []\n            x[task.task_id] = []\n            for ti in task.get_task_instances(start_date=min_date, end_date=base_date):\n                ts = ti.execution_date\n                if dag.schedule_interval and dag.following_schedule(ts):\n                    ts = dag.following_schedule(ts)\n                if ti.end_date:\n                    dttm = wwwutils.epoch(ti.execution_date)\n                    secs = (ti.end_date - ts).total_seconds()\n                    x[ti.task_id].append(dttm)\n                    y[ti.task_id].append(secs)\n\n        # determine the most relevant time unit for the set of landing times\n        # for the DAG\n        y_unit = infer_time_unit([d for t in y.values() for d in t])\n        # update the y Axis to have the correct time units\n        chart.create_y_axis('yAxis', format='.02f', custom_format=False,\n                            label='Landing Time ({})'.format(y_unit))\n        chart.axislist['yAxis']['axisLabelDistance'] = '40'\n        for task in dag.tasks:\n            if x[task.task_id]:\n                chart.add_serie(name=task.task_id, x=x[task.task_id],\n                                y=scale_time_units(y[task.task_id], y_unit))\n\n        tis = dag.get_task_instances(start_date=min_date, end_date=base_date)\n        dates = sorted(list({ti.execution_date for ti in tis}))\n        max_date = max([ti.execution_date for ti in tis]) if dates else None\n\n        session.commit()\n\n        form = DateTimeWithNumRunsForm(data={'base_date': max_date,\n                                             'num_runs': num_runs})\n        chart.buildcontent()\n        return self.render_template(\n            'airflow/chart.html',\n            dag=dag,\n            chart=chart.htmlcontent,\n            height=str(chart_height + 100) + \"px\",\n            demo_mode=conf.getboolean('webserver', 'demo_mode'),\n            root=root,\n            form=form,\n        )\n\n    @expose('/paused', methods=['POST'])\n    @has_dag_access(can_dag_edit=True)\n    @has_access\n    @action_logging\n    def paused(self):\n        dag_id = request.args.get('dag_id')\n        is_paused = True if request.args.get('is_paused') == 'false' else False\n        models.DagModel.get_dagmodel(dag_id).set_is_paused(is_paused=is_paused)\n        return \"OK\"\n\n    @expose('/refresh', methods=['POST'])\n    @has_dag_access(can_dag_edit=True)\n    @has_access\n    @action_logging\n    @provide_session\n    def refresh(self, session=None):\n        DagModel = models.DagModel\n        dag_id = request.values.get('dag_id')\n        orm_dag = session.query(\n            DagModel).filter(DagModel.dag_id == dag_id).first()\n\n        if orm_dag:\n            orm_dag.last_expired = timezone.utcnow()\n            session.merge(orm_dag)\n        session.commit()\n\n        dag = dagbag.get_dag(dag_id)\n        # sync dag permission\n        appbuilder.sm.sync_perm_for_dag(dag_id, dag.access_control)\n\n        flash(\"DAG [{}] is now fresh as a daisy\".format(dag_id))\n        return redirect(request.referrer)\n\n    @expose('/refresh_all', methods=['POST'])\n    @has_access\n    @action_logging\n    def refresh_all(self):\n        dagbag.collect_dags(only_if_updated=False)\n        # sync permissions for all dags\n        for dag_id, dag in dagbag.dags.items():\n            appbuilder.sm.sync_perm_for_dag(dag_id, dag.access_control)\n        flash(\"All DAGs are now up to date\")\n        return redirect(url_for('Airflow.index'))\n\n    @expose('/gantt')\n    @has_dag_access(can_dag_read=True)\n    @has_access\n    @action_logging\n    @provide_session\n    def gantt(self, session=None):\n        dag_id = request.args.get('dag_id')\n        dag = dagbag.get_dag(dag_id)\n        demo_mode = conf.getboolean('webserver', 'demo_mode')\n\n        root = request.args.get('root')\n        if root:\n            dag = dag.sub_dag(\n                task_regex=root,\n                include_upstream=True,\n                include_downstream=False)\n\n        dt_nr_dr_data = get_date_time_num_runs_dag_runs_form_data(request, session, dag)\n        dttm = dt_nr_dr_data['dttm']\n\n        form = DateTimeWithNumRunsWithDagRunsForm(data=dt_nr_dr_data)\n        form.execution_date.choices = dt_nr_dr_data['dr_choices']\n\n        tis = [\n            ti for ti in dag.get_task_instances(dttm, dttm)\n            if ti.start_date and ti.state]\n        tis = sorted(tis, key=lambda ti: ti.start_date)\n        TF = TaskFail\n        ti_fails = list(itertools.chain(*[(\n            session\n            .query(TF)\n            .filter(TF.dag_id == ti.dag_id,\n                    TF.task_id == ti.task_id,\n                    TF.execution_date == ti.execution_date)\n            .all()\n        ) for ti in tis]))\n\n        # determine bars to show in the gantt chart\n        gantt_bar_items = []\n        for ti in tis:\n            end_date = ti.end_date or timezone.utcnow()\n            try_count = ti.try_number\n            if ti.state != State.RUNNING:\n                try_count = ti.try_number - 1\n            gantt_bar_items.append((ti.task_id, ti.start_date, end_date, ti.state, try_count))\n\n        tf_count = 0\n        try_count = 1\n        prev_task_id = \"\"\n        for tf in ti_fails:\n            end_date = tf.end_date or timezone.utcnow()\n            if tf_count != 0 and tf.task_id == prev_task_id:\n                try_count = try_count + 1\n            else:\n                try_count = 1\n            prev_task_id = tf.task_id\n            gantt_bar_items.append((tf.task_id, tf.start_date, end_date, State.FAILED, try_count))\n            tf_count = tf_count + 1\n\n        task_types = {}\n        extra_links = {}\n        for t in dag.tasks:\n            task_types[t.task_id] = t.task_type\n            extra_links[t.task_id] = t.extra_links\n\n        tasks = []\n        for gantt_bar_item in gantt_bar_items:\n            task_id = gantt_bar_item[0]\n            start_date = gantt_bar_item[1]\n            end_date = gantt_bar_item[2]\n            state = gantt_bar_item[3]\n            try_count = gantt_bar_item[4]\n            tasks.append({\n                'startDate': wwwutils.epoch(start_date),\n                'endDate': wwwutils.epoch(end_date),\n                'isoStart': start_date.isoformat()[:-4],\n                'isoEnd': end_date.isoformat()[:-4],\n                'taskName': task_id,\n                'taskType': task_types[ti.task_id],\n                'duration': (end_date - start_date).total_seconds(),\n                'status': state,\n                'executionDate': dttm.isoformat(),\n                'try_number': try_count,\n                'extraLinks': extra_links[ti.task_id],\n            })\n\n        states = {task['status']: task['status'] for task in tasks}\n\n        data = {\n            'taskNames': [ti.task_id for ti in tis],\n            'tasks': tasks,\n            'taskStatus': states,\n            'height': len(tis) * 25 + 25,\n        }\n\n        session.commit()\n\n        return self.render_template(\n            'airflow/gantt.html',\n            dag=dag,\n            execution_date=dttm.isoformat(),\n            form=form,\n            data=data,\n            base_date='',\n            demo_mode=demo_mode,\n            root=root,\n        )\n\n    @expose('/extra_links')\n    @has_dag_access(can_dag_read=True)\n    @has_access\n    @action_logging\n    def extra_links(self):\n        \"\"\"\n        A restful endpoint that returns external links for a given Operator\n\n        It queries the operator that sent the request for the links it wishes\n        to provide for a given external link name.\n\n        API: GET\n        Args: dag_id: The id of the dag containing the task in question\n              task_id: The id of the task in question\n              execution_date: The date of execution of the task\n              link_name: The name of the link reference to find the actual URL for\n\n        Returns:\n            200: {url: <url of link>, error: None} - returned when there was no problem\n                finding the URL\n            404: {url: None, error: <error message>} - returned when the operator does\n                not return a URL\n        \"\"\"\n        dag_id = request.args.get('dag_id')\n        task_id = request.args.get('task_id')\n        execution_date = request.args.get('execution_date')\n        link_name = request.args.get('link_name')\n        dttm = airflow.utils.timezone.parse(execution_date)\n        dag = dagbag.get_dag(dag_id)\n\n        if not dag or task_id not in dag.task_ids:\n            response = jsonify(\n                {'url': None,\n                 'error': \"can't find dag {dag} or task_id {task_id}\".format(\n                     dag=dag,\n                     task_id=task_id\n                 )}\n            )\n            response.status_code = 404\n            return response\n\n        task = dag.get_task(task_id)\n\n        try:\n            url = task.get_extra_links(dttm, link_name)\n        except ValueError as err:\n            response = jsonify({'url': None, 'error': str(err)})\n            response.status_code = 404\n            return response\n        if url:\n            response = jsonify({'error': None, 'url': url})\n            response.status_code = 200\n            return response\n        else:\n            response = jsonify(\n                {'url': None, 'error': 'No URL found for {dest}'.format(dest=link_name)})\n            response.status_code = 404\n            return response\n\n    @expose('/object/task_instances')\n    @has_dag_access(can_dag_read=True)\n    @has_access\n    @action_logging\n    @provide_session\n    def task_instances(self, session=None):\n        dag_id = request.args.get('dag_id')\n        dag = dagbag.get_dag(dag_id)\n\n        dttm = request.args.get('execution_date')\n        if dttm:\n            dttm = pendulum.parse(dttm)\n        else:\n            return \"Error: Invalid execution_date\"\n\n        task_instances = {\n            ti.task_id: alchemy_to_dict(ti)\n            for ti in dag.get_task_instances(dttm, dttm)}\n\n        return json.dumps(task_instances)", "target": 0}, {"function": "class VersionView(AirflowBaseView):\n    @expose('/version')\n    @has_access\n    def version(self):\n        try:\n            airflow_version = airflow.__version__\n        except Exception as e:\n            airflow_version = None\n            logging.error(e)\n\n        # Get the Git repo and git hash\n        git_version = None\n        try:\n            with open(os.path.join(*[settings.AIRFLOW_HOME,\n                                   'airflow', 'git_version'])) as f:\n                git_version = f.readline()\n        except Exception as e:\n            logging.error(e)\n\n        # Render information\n        title = \"Version Info\"\n        return self.render_template(\n            'airflow/version.html',\n            title=title,\n            airflow_version=airflow_version,\n            git_version=git_version)", "target": 0}, {"function": "class ConfigurationView(AirflowBaseView):\n    @expose('/configuration')\n    @has_access\n    def conf(self):\n        raw = request.args.get('raw') == \"true\"\n        title = \"Airflow Configuration\"\n        subtitle = AIRFLOW_CONFIG\n        # Don't show config when expose_config variable is False in airflow config\n        if conf.getboolean(\"webserver\", \"expose_config\"):\n            with open(AIRFLOW_CONFIG, 'r') as file:\n                config = file.read()\n            table = [(section, key, value, source)\n                     for section, parameters in conf.as_dict(True, True).items()\n                     for key, (value, source) in parameters.items()]\n        else:\n            config = (\n                \"# Your Airflow administrator chose not to expose the \"\n                \"configuration, most likely for security reasons.\")\n            table = None\n\n        if raw:\n            return Response(\n                response=config,\n                status=200,\n                mimetype=\"application/text\")\n        else:\n            code_html = Markup(highlight(\n                config,\n                lexers.IniLexer(),  # Lexer call\n                HtmlFormatter(noclasses=True))\n            )\n            return self.render_template(\n                'airflow/config.html',\n                pre_subtitle=settings.HEADER + \"  v\" + airflow.__version__,\n                code_html=code_html, title=title, subtitle=subtitle,\n                table=table)", "target": 0}, {"function": "class DagFilter(BaseFilter):\n    def apply(self, query, func): # noqa\n        if appbuilder.sm.has_all_dags_access():\n            return query\n        filter_dag_ids = appbuilder.sm.get_accessible_dag_ids()\n        return query.filter(self.model.dag_id.in_(filter_dag_ids))", "target": 0}, {"function": "class AirflowModelView(ModelView):\n    list_widget = AirflowModelListWidget\n    page_size = PAGE_SIZE\n\n    CustomSQLAInterface = wwwutils.CustomSQLAInterface", "target": 0}, {"function": "class SlaMissModelView(AirflowModelView):\n    route_base = '/slamiss'\n\n    datamodel = AirflowModelView.CustomSQLAInterface(SlaMiss)\n\n    base_permissions = ['can_list']\n\n    list_columns = ['dag_id', 'task_id', 'execution_date', 'email_sent', 'timestamp']\n    add_columns = ['dag_id', 'task_id', 'execution_date', 'email_sent', 'timestamp']\n    edit_columns = ['dag_id', 'task_id', 'execution_date', 'email_sent', 'timestamp']\n    search_columns = ['dag_id', 'task_id', 'email_sent', 'timestamp', 'execution_date']\n    base_order = ('execution_date', 'desc')\n    base_filters = [['dag_id', DagFilter, lambda: []]]\n\n    formatters_columns = {\n        'task_id': wwwutils.task_instance_link,\n        'execution_date': wwwutils.datetime_f('execution_date'),\n        'timestamp': wwwutils.datetime_f('timestamp'),\n        'dag_id': wwwutils.dag_link,\n    }", "target": 0}, {"function": "class XComModelView(AirflowModelView):\n    route_base = '/xcom'\n\n    datamodel = AirflowModelView.CustomSQLAInterface(XCom)\n\n    base_permissions = ['can_add', 'can_list', 'can_edit', 'can_delete']\n\n    search_columns = ['key', 'value', 'timestamp', 'execution_date', 'task_id', 'dag_id']\n    list_columns = ['key', 'value', 'timestamp', 'execution_date', 'task_id', 'dag_id']\n    add_columns = ['key', 'value', 'execution_date', 'task_id', 'dag_id']\n    edit_columns = ['key', 'value', 'execution_date', 'task_id', 'dag_id']\n    base_order = ('execution_date', 'desc')\n\n    base_filters = [['dag_id', DagFilter, lambda: []]]\n\n    formatters_columns = {\n        'task_id': wwwutils.task_instance_link,\n        'execution_date': wwwutils.datetime_f('execution_date'),\n        'timestamp': wwwutils.datetime_f('timestamp'),\n        'dag_id': wwwutils.dag_link,\n    }\n\n    @action('muldelete', 'Delete', \"Are you sure you want to delete selected records?\",\n            single=False)\n    def action_muldelete(self, items):\n        self.datamodel.delete_all(items)\n        self.update_redirect()\n        return redirect(self.get_redirect())\n\n    def pre_add(self, item):\n        item.execution_date = timezone.make_aware(item.execution_date)\n        item.value = XCom.serialize_value(item.value)\n\n    def pre_update(self, item):\n        item.execution_date = timezone.make_aware(item.execution_date)\n        item.value = XCom.serialize_value(item.value)", "target": 0}, {"function": "class ConnectionModelView(AirflowModelView):\n    route_base = '/connection'\n\n    datamodel = AirflowModelView.CustomSQLAInterface(Connection)\n\n    base_permissions = ['can_add', 'can_list', 'can_edit', 'can_delete']\n\n    extra_fields = ['extra__jdbc__drv_path', 'extra__jdbc__drv_clsname',\n                    'extra__google_cloud_platform__project',\n                    'extra__google_cloud_platform__key_path',\n                    'extra__google_cloud_platform__keyfile_dict',\n                    'extra__google_cloud_platform__scope',\n                    'extra__google_cloud_platform__num_retries',\n                    'extra__grpc__auth_type',\n                    'extra__grpc__credential_pem_file',\n                    'extra__grpc__scopes']\n    list_columns = ['conn_id', 'conn_type', 'host', 'port', 'is_encrypted',\n                    'is_extra_encrypted']\n    add_columns = edit_columns = ['conn_id', 'conn_type', 'host', 'schema',\n                                  'login', 'password', 'port', 'extra'] + extra_fields\n    add_form = edit_form = ConnectionForm\n    add_template = 'airflow/conn_create.html'\n    edit_template = 'airflow/conn_edit.html'\n\n    base_order = ('conn_id', 'asc')\n\n    @action('muldelete', 'Delete', 'Are you sure you want to delete selected records?',\n            single=False)\n    @has_dag_access(can_dag_edit=True)\n    def action_muldelete(self, items):\n        self.datamodel.delete_all(items)\n        self.update_redirect()\n        return redirect(self.get_redirect())\n\n    def process_form(self, form, is_created):\n        formdata = form.data\n        if formdata['conn_type'] in ['jdbc', 'google_cloud_platform', 'grpc']:\n            extra = {\n                key: formdata[key]\n                for key in self.extra_fields if key in formdata}\n            form.extra.data = json.dumps(extra)\n\n    def prefill_form(self, form, pk):\n        try:\n            d = json.loads(form.data.get('extra', '{}'))\n        except Exception:\n            d = {}\n\n        if not hasattr(d, 'get'):\n            logging.warning('extra field for {} is not iterable'.format(\n                form.data.get('conn_id', '<unknown>')))\n            return\n\n        for field in self.extra_fields:\n            value = d.get(field, '')\n            if value:\n                field = getattr(form, field)\n                field.data = value", "target": 0}, {"function": "class PoolModelView(AirflowModelView):\n    route_base = '/pool'\n\n    datamodel = AirflowModelView.CustomSQLAInterface(models.Pool)\n\n    base_permissions = ['can_add', 'can_list', 'can_edit', 'can_delete']\n\n    list_columns = ['pool', 'slots', 'used_slots', 'queued_slots']\n    add_columns = ['pool', 'slots', 'description']\n    edit_columns = ['pool', 'slots', 'description']\n\n    base_order = ('pool', 'asc')\n\n    @action('muldelete', 'Delete', 'Are you sure you want to delete selected records?',\n            single=False)\n    def action_muldelete(self, items):\n        if any(item.pool == models.Pool.DEFAULT_POOL_NAME for item in items):\n            flash(\"default_pool cannot be deleted\", 'error')\n            self.update_redirect()\n            return redirect(self.get_redirect())\n        self.datamodel.delete_all(items)\n        self.update_redirect()\n        return redirect(self.get_redirect())\n\n    def pool_link(attr):\n        pool_id = attr.get('pool')\n        if pool_id is not None:\n            url = url_for('TaskInstanceModelView.list', _flt_3_pool=pool_id)\n            return Markup(\"<a href='{url}'>{pool_id}</a>\").format(url=url, pool_id=pool_id)\n        else:\n            return Markup('<span class=\"label label-danger\">Invalid</span>')\n\n    def fused_slots(attr):\n        pool_id = attr.get('pool')\n        used_slots = attr.get('used_slots')\n        if pool_id is not None and used_slots is not None:\n            url = url_for('TaskInstanceModelView.list', _flt_3_pool=pool_id, _flt_3_state='running')\n            return Markup(\"<a href='{url}'>{used_slots}</a>\").format(url=url, used_slots=used_slots)\n        else:\n            return Markup('<span class=\"label label-danger\">Invalid</span>')\n\n    def fqueued_slots(attr):\n        pool_id = attr.get('pool')\n        queued_slots = attr.get('queued_slots')\n        if pool_id is not None and queued_slots is not None:\n            url = url_for('TaskInstanceModelView.list', _flt_3_pool=pool_id, _flt_3_state='queued')\n            return Markup(\"<a href='{url}'>{queued_slots}</a>\").format(url=url, queued_slots=queued_slots)\n        else:\n            return Markup('<span class=\"label label-danger\">Invalid</span>')\n\n    formatters_columns = {\n        'pool': pool_link,\n        'used_slots': fused_slots,\n        'queued_slots': fqueued_slots\n    }\n\n    validators_columns = {\n        'pool': [validators.DataRequired()],\n        'slots': [validators.NumberRange(min=0)]\n    }", "target": 0}, {"function": "class VariableModelView(AirflowModelView):\n    route_base = '/variable'\n\n    list_template = 'airflow/variable_list.html'\n    edit_template = 'airflow/variable_edit.html'\n\n    datamodel = AirflowModelView.CustomSQLAInterface(models.Variable)\n\n    base_permissions = ['can_add', 'can_list', 'can_edit', 'can_delete', 'can_varimport']\n\n    list_columns = ['key', 'val', 'is_encrypted']\n    add_columns = ['key', 'val']\n    edit_columns = ['key', 'val']\n    search_columns = ['key', 'val']\n\n    base_order = ('key', 'asc')\n\n    def hidden_field_formatter(attr):\n        key = attr.get('key')\n        val = attr.get('val')\n        if wwwutils.should_hide_value_for_key(key):\n            return Markup('*' * 8)\n        if val:\n            return val\n        else:\n            return Markup('<span class=\"label label-danger\">Invalid</span>')\n\n    formatters_columns = {\n        'val': hidden_field_formatter,\n    }\n\n    validators_columns = {\n        'key': [validators.DataRequired()]\n    }\n\n    def prefill_form(self, form, id):\n        if wwwutils.should_hide_value_for_key(form.key.data):\n            form.val.data = '*' * 8\n\n    @action('muldelete', 'Delete', 'Are you sure you want to delete selected records?',\n            single=False)\n    def action_muldelete(self, items):\n        self.datamodel.delete_all(items)\n        self.update_redirect()\n        return redirect(self.get_redirect())\n\n    @action('varexport', 'Export', '', single=False)\n    def action_varexport(self, items):\n        var_dict = {}\n        d = json.JSONDecoder()\n        for var in items:\n            try:\n                val = d.decode(var.val)\n            except Exception:\n                val = var.val\n            var_dict[var.key] = val\n\n        response = make_response(json.dumps(var_dict, sort_keys=True, indent=4))\n        response.headers[\"Content-Disposition\"] = \"attachment; filename=variables.json\"\n        response.headers[\"Content-Type\"] = \"application/json; charset=utf-8\"\n        return response\n\n    @expose('/varimport', methods=[\"POST\"])\n    @has_access\n    @action_logging\n    def varimport(self):\n        try:\n            out = request.files['file'].read()\n            if isinstance(out, bytes):\n                d = json.loads(out.decode('utf-8'))\n            else:\n                d = json.loads(out)\n        except Exception:\n            self.update_redirect()\n            flash(\"Missing file or syntax error.\", 'error')\n            return redirect(self.get_redirect())\n        else:\n            suc_count = fail_count = 0\n            for k, v in d.items():\n                try:\n                    models.Variable.set(k, v, serialize_json=not isinstance(v, str))\n                except Exception as e:\n                    logging.info('Variable import failed: {}'.format(repr(e)))\n                    fail_count += 1\n                else:\n                    suc_count += 1\n            flash(\"{} variable(s) successfully updated.\".format(suc_count))\n            if fail_count:\n                flash(\"{} variable(s) failed to be updated.\".format(fail_count), 'error')\n            self.update_redirect()\n            return redirect(self.get_redirect())", "target": 0}, {"function": "class JobModelView(AirflowModelView):\n    route_base = '/job'\n\n    datamodel = AirflowModelView.CustomSQLAInterface(jobs.BaseJob)\n\n    base_permissions = ['can_list']\n\n    list_columns = ['id', 'dag_id', 'state', 'job_type', 'start_date',\n                    'end_date', 'latest_heartbeat',\n                    'executor_class', 'hostname', 'unixname']\n    search_columns = ['id', 'dag_id', 'state', 'job_type', 'start_date',\n                      'end_date', 'latest_heartbeat', 'executor_class',\n                      'hostname', 'unixname']\n\n    base_order = ('start_date', 'desc')\n\n    base_filters = [['dag_id', DagFilter, lambda: []]]\n\n    formatters_columns = {\n        'start_date': wwwutils.datetime_f('start_date'),\n        'end_date': wwwutils.datetime_f('end_date'),\n        'hostname': wwwutils.nobr_f('hostname'),\n        'state': wwwutils.state_f,\n        'latest_heartbeat': wwwutils.datetime_f('latest_heartbeat'),\n    }", "target": 0}, {"function": "class DagRunModelView(AirflowModelView):\n    route_base = '/dagrun'\n\n    datamodel = AirflowModelView.CustomSQLAInterface(models.DagRun)\n\n    base_permissions = ['can_list', 'can_add']\n\n    add_columns = ['state', 'dag_id', 'execution_date', 'run_id', 'external_trigger']\n    list_columns = ['state', 'dag_id', 'execution_date', 'run_id', 'external_trigger']\n    search_columns = ['state', 'dag_id', 'execution_date', 'run_id', 'external_trigger']\n\n    base_order = ('execution_date', 'desc')\n\n    base_filters = [['dag_id', DagFilter, lambda: []]]\n\n    add_form = edit_form = DagRunForm\n\n    formatters_columns = {\n        'execution_date': wwwutils.datetime_f('execution_date'),\n        'state': wwwutils.state_f,\n        'start_date': wwwutils.datetime_f('start_date'),\n        'dag_id': wwwutils.dag_link,\n        'run_id': wwwutils.dag_run_link,\n    }\n\n    @action('muldelete', \"Delete\", \"Are you sure you want to delete selected records?\",\n            single=False)\n    @has_dag_access(can_dag_edit=True)\n    @provide_session\n    def action_muldelete(self, items, session=None):\n        self.datamodel.delete_all(items)\n        self.update_redirect()\n        dirty_ids = []\n        for item in items:\n            dirty_ids.append(item.dag_id)\n        return redirect(self.get_redirect())\n\n    @action('set_running', \"Set state to 'running'\", '', single=False)\n    @provide_session\n    def action_set_running(self, drs, session=None):\n        try:\n            DR = models.DagRun\n            count = 0\n            dirty_ids = []\n            for dr in session.query(DR).filter(\n                    DR.id.in_([dagrun.id for dagrun in drs])).all():\n                dirty_ids.append(dr.dag_id)\n                count += 1\n                dr.start_date = timezone.utcnow()\n                dr.state = State.RUNNING\n            session.commit()\n            flash(\"{count} dag runs were set to running\".format(count=count))\n        except Exception as ex:\n            flash(str(ex), 'error')\n            flash('Failed to set state', 'error')\n        return redirect(self.get_default_url())\n\n    @action('set_failed', \"Set state to 'failed'\",\n            \"All running task instances would also be marked as failed, are you sure?\",\n            single=False)\n    @provide_session\n    def action_set_failed(self, drs, session=None):\n        try:\n            DR = models.DagRun\n            count = 0\n            dirty_ids = []\n            altered_tis = []\n            for dr in session.query(DR).filter(\n                    DR.id.in_([dagrun.id for dagrun in drs])).all():\n                dirty_ids.append(dr.dag_id)\n                count += 1\n                altered_tis += \\\n                    set_dag_run_state_to_failed(dagbag.get_dag(dr.dag_id),\n                                                dr.execution_date,\n                                                commit=True,\n                                                session=session)\n            altered_ti_count = len(altered_tis)\n            flash(\n                \"{count} dag runs and {altered_ti_count} task instances \"\n                \"were set to failed\".format(count=count, altered_ti_count=altered_ti_count))\n        except Exception:\n            flash('Failed to set state', 'error')\n        return redirect(self.get_default_url())\n\n    @action('set_success', \"Set state to 'success'\",\n            \"All task instances would also be marked as success, are you sure?\",\n            single=False)\n    @provide_session\n    def action_set_success(self, drs, session=None):\n        try:\n            DR = models.DagRun\n            count = 0\n            dirty_ids = []\n            altered_tis = []\n            for dr in session.query(DR).filter(\n                    DR.id.in_([dagrun.id for dagrun in drs])).all():\n                dirty_ids.append(dr.dag_id)\n                count += 1\n                altered_tis += \\\n                    set_dag_run_state_to_success(dagbag.get_dag(dr.dag_id),\n                                                 dr.execution_date,\n                                                 commit=True,\n                                                 session=session)\n            altered_ti_count = len(altered_tis)\n            flash(\n                \"{count} dag runs and {altered_ti_count} task instances \"\n                \"were set to success\".format(count=count, altered_ti_count=altered_ti_count))\n        except Exception:\n            flash('Failed to set state', 'error')\n        return redirect(self.get_default_url())", "target": 0}, {"function": "class LogModelView(AirflowModelView):\n    route_base = '/log'\n\n    datamodel = AirflowModelView.CustomSQLAInterface(Log)\n\n    base_permissions = ['can_list']\n\n    list_columns = ['id', 'dttm', 'dag_id', 'task_id', 'event', 'execution_date',\n                    'owner', 'extra']\n    search_columns = ['dag_id', 'task_id', 'event', 'execution_date', 'owner', 'extra']\n\n    base_order = ('dttm', 'desc')\n\n    base_filters = [['dag_id', DagFilter, lambda: []]]\n\n    formatters_columns = {\n        'dttm': wwwutils.datetime_f('dttm'),\n        'execution_date': wwwutils.datetime_f('execution_date'),\n        'dag_id': wwwutils.dag_link,\n    }", "target": 0}, {"function": "class TaskInstanceModelView(AirflowModelView):\n    route_base = '/taskinstance'\n\n    datamodel = AirflowModelView.CustomSQLAInterface(models.TaskInstance)\n\n    base_permissions = ['can_list']\n\n    page_size = PAGE_SIZE\n\n    list_columns = ['state', 'dag_id', 'task_id', 'execution_date', 'operator',\n                    'start_date', 'end_date', 'duration', 'job_id', 'hostname',\n                    'unixname', 'priority_weight', 'queue', 'queued_dttm', 'try_number',\n                    'pool', 'log_url']\n\n    search_columns = ['state', 'dag_id', 'task_id', 'execution_date', 'hostname',\n                      'queue', 'pool', 'operator', 'start_date', 'end_date']\n\n    base_order = ('job_id', 'asc')\n\n    base_filters = [['dag_id', DagFilter, lambda: []]]\n\n    def log_url_formatter(attr):\n        log_url = attr.get('log_url')\n        return Markup(\n            '<a href=\"{log_url}\">'\n            '    <span class=\"glyphicon glyphicon-book\" aria-hidden=\"true\">'\n            '</span></a>').format(log_url=log_url)\n\n    def duration_f(attr):\n        end_date = attr.get('end_date')\n        duration = attr.get('duration')\n        if end_date and duration:\n            return timedelta(seconds=duration)\n\n    formatters_columns = {\n        'log_url': log_url_formatter,\n        'task_id': wwwutils.task_instance_link,\n        'hostname': wwwutils.nobr_f('hostname'),\n        'state': wwwutils.state_f,\n        'execution_date': wwwutils.datetime_f('execution_date'),\n        'start_date': wwwutils.datetime_f('start_date'),\n        'end_date': wwwutils.datetime_f('end_date'),\n        'queued_dttm': wwwutils.datetime_f('queued_dttm'),\n        'dag_id': wwwutils.dag_link,\n        'duration': duration_f,\n    }\n\n    @provide_session\n    @action('clear', lazy_gettext('Clear'),\n            lazy_gettext('Are you sure you want to clear the state of the selected task'\n                         ' instance(s) and set their dagruns to the running state?'),\n            single=False)\n    def action_clear(self, tis, session=None):\n        try:\n            dag_to_tis = {}\n\n            for ti in tis:\n                dag = dagbag.get_dag(ti.dag_id)\n                tis = dag_to_tis.setdefault(dag, [])\n                tis.append(ti)\n\n            for dag, tis in dag_to_tis.items():\n                models.clear_task_instances(tis, session, dag=dag)\n\n            session.commit()\n            flash(\"{0} task instances have been cleared\".format(len(tis)))\n            self.update_redirect()\n            return redirect(self.get_redirect())\n\n        except Exception:\n            flash('Failed to clear task instances', 'error')\n\n    @provide_session\n    def set_task_instance_state(self, tis, target_state, session=None):\n        try:\n            count = len(tis)\n            for ti in tis:\n                ti.set_state(target_state, session)\n            session.commit()\n            flash(\"{count} task instances were set to '{target_state}'\".format(\n                count=count, target_state=target_state))\n        except Exception:\n            flash('Failed to set state', 'error')\n\n    @action('set_running', \"Set state to 'running'\", '', single=False)\n    @has_dag_access(can_dag_edit=True)\n    def action_set_running(self, tis):\n        self.set_task_instance_state(tis, State.RUNNING)\n        self.update_redirect()\n        return redirect(self.get_redirect())\n\n    @action('set_failed', \"Set state to 'failed'\", '', single=False)\n    @has_dag_access(can_dag_edit=True)\n    def action_set_failed(self, tis):\n        self.set_task_instance_state(tis, State.FAILED)\n        self.update_redirect()\n        return redirect(self.get_redirect())\n\n    @action('set_success', \"Set state to 'success'\", '', single=False)\n    @has_dag_access(can_dag_edit=True)\n    def action_set_success(self, tis):\n        self.set_task_instance_state(tis, State.SUCCESS)\n        self.update_redirect()\n        return redirect(self.get_redirect())\n\n    @action('set_retry', \"Set state to 'up_for_retry'\", '', single=False)\n    @has_dag_access(can_dag_edit=True)\n    def action_set_retry(self, tis):\n        self.set_task_instance_state(tis, State.UP_FOR_RETRY)\n        self.update_redirect()\n        return redirect(self.get_redirect())", "target": 0}, {"function": "class DagModelView(AirflowModelView):\n    route_base = '/dagmodel'\n\n    datamodel = AirflowModelView.CustomSQLAInterface(models.DagModel)\n\n    base_permissions = ['can_list', 'can_show', 'can_edit']\n\n    list_columns = ['dag_id', 'is_paused', 'last_scheduler_run',\n                    'last_expired', 'scheduler_lock', 'fileloc', 'owners']\n\n    formatters_columns = {\n        'dag_id': wwwutils.dag_link\n    }\n\n    base_filters = [['dag_id', DagFilter, lambda: []]]\n\n    def get_query(self):\n        \"\"\"\n        Default filters for model\n        \"\"\"\n        return (\n            super().get_query()\n            .filter(or_(models.DagModel.is_active,\n                        models.DagModel.is_paused))\n            .filter(~models.DagModel.is_subdag)\n        )\n\n    def get_count_query(self):\n        \"\"\"\n        Default filters for model\n        \"\"\"\n        return (\n            super().get_count_query()\n            .filter(models.DagModel.is_active)\n            .filter(~models.DagModel.is_subdag)\n        )", "target": 0}], "function_after": [{"function": "def get_date_time_num_runs_dag_runs_form_data(request, session, dag):\n    dttm = request.args.get('execution_date')\n    if dttm:\n        dttm = pendulum.parse(dttm)\n    else:\n        dttm = dag.latest_execution_date or timezone.utcnow()\n\n    base_date = request.args.get('base_date')\n    if base_date:\n        base_date = timezone.parse(base_date)\n    else:\n        # The DateTimeField widget truncates milliseconds and would loose\n        # the first dag run. Round to next second.\n        base_date = (dttm + timedelta(seconds=1)).replace(microsecond=0)\n\n    default_dag_run = conf.getint('webserver', 'default_dag_run_display_number')\n    num_runs = request.args.get('num_runs')\n    num_runs = int(num_runs) if num_runs else default_dag_run\n\n    DR = models.DagRun\n    drs = (\n        session.query(DR)\n        .filter(\n            DR.dag_id == dag.dag_id,\n            DR.execution_date <= base_date)\n        .order_by(desc(DR.execution_date))\n        .limit(num_runs)\n        .all()\n    )\n    dr_choices = []\n    dr_state = None\n    for dr in drs:\n        dr_choices.append((dr.execution_date.isoformat(), dr.run_id))\n        if dttm == dr.execution_date:\n            dr_state = dr.state\n\n    # Happens if base_date was changed and the selected dag run is not in result\n    if not dr_state and drs:\n        dr = drs[0]\n        dttm = dr.execution_date\n        dr_state = dr.state\n\n    return {\n        'dttm': dttm,\n        'base_date': base_date,\n        'num_runs': num_runs,\n        'execution_date': dttm.isoformat(),\n        'dr_choices': dr_choices,\n        'dr_state': dr_state,\n    }", "target": 0}, {"function": "class AirflowBaseView(BaseView):\n    route_base = ''\n\n    # Make our macros available to our UI templates too.\n    extra_args = {\n        'macros': airflow.macros,\n    }\n\n    def render_template(self, *args, **kwargs):\n        return super().render_template(\n            *args,\n            # Cache this at most once per request, not for the lifetime of the view instance\n            scheduler_job=lazy_object_proxy.Proxy(jobs.SchedulerJob.most_recent_job),\n            **kwargs\n        )", "target": 0}, {"function": "class Airflow(AirflowBaseView):\n    @expose('/health')\n    def health(self):\n        \"\"\"\n        An endpoint helping check the health status of the Airflow instance,\n        including metadatabase and scheduler.\n        \"\"\"\n\n        payload = {\n            'metadatabase': {'status': 'unhealthy'}\n        }\n\n        latest_scheduler_heartbeat = None\n        scheduler_status = 'unhealthy'\n        payload['metadatabase'] = {'status': 'healthy'}\n        try:\n            scheduler_job = jobs.SchedulerJob.most_recent_job()\n\n            if scheduler_job:\n                latest_scheduler_heartbeat = scheduler_job.latest_heartbeat.isoformat()\n                if scheduler_job.is_alive():\n                    scheduler_status = 'healthy'\n        except Exception:\n            payload['metadatabase']['status'] = 'unhealthy'\n\n        payload['scheduler'] = {'status': scheduler_status,\n                                'latest_scheduler_heartbeat': latest_scheduler_heartbeat}\n\n        return wwwutils.json_response(payload)\n\n    @expose('/home')\n    @has_access\n    def index(self):\n        hide_paused_dags_by_default = conf.getboolean('webserver',\n                                                      'hide_paused_dags_by_default')\n        show_paused_arg = request.args.get('showPaused', 'None')\n\n        default_dag_run = conf.getint('webserver', 'default_dag_run_display_number')\n        num_runs = request.args.get('num_runs')\n        num_runs = int(num_runs) if num_runs else default_dag_run\n\n        def get_int_arg(value, default=0):\n            try:\n                return int(value)\n            except ValueError:\n                return default\n\n        arg_current_page = request.args.get('page', '0')\n        arg_search_query = request.args.get('search', None)\n\n        dags_per_page = PAGE_SIZE\n        current_page = get_int_arg(arg_current_page, default=0)\n\n        if show_paused_arg.strip().lower() == 'false':\n            hide_paused = True\n        elif show_paused_arg.strip().lower() == 'true':\n            hide_paused = False\n        else:\n            hide_paused = hide_paused_dags_by_default\n\n        start = current_page * dags_per_page\n        end = start + dags_per_page\n\n        # Get all the dag id the user could access\n        filter_dag_ids = appbuilder.sm.get_accessible_dag_ids()\n\n        with create_session() as session:\n            # read orm_dags from the db\n            dags_query = session.query(DagModel).filter(\n                ~DagModel.is_subdag, DagModel.is_active\n            )\n\n            # optionally filter out \"paused\" dags\n            if hide_paused:\n                dags_query = dags_query.filter(~DagModel.is_paused)\n\n            if arg_search_query:\n                dags_query = dags_query.filter(\n                    DagModel.dag_id.ilike('%' + arg_search_query + '%') |\n                    DagModel.owners.ilike('%' + arg_search_query + '%')\n                )\n\n            if 'all_dags' not in filter_dag_ids:\n                dags_query = dags_query.filter(DagModel.dag_id.in_(filter_dag_ids))\n\n            dags = dags_query.order_by(DagModel.dag_id).offset(start).limit(dags_per_page).all()\n\n            import_errors = session.query(errors.ImportError).all()\n\n        for ie in import_errors:\n            flash(\n                \"Broken DAG: [{ie.filename}] {ie.stacktrace}\".format(ie=ie),\n                \"dag_import_error\")\n\n        from airflow.plugins_manager import import_errors as plugin_import_errors\n        for filename, stacktrace in plugin_import_errors.items():\n            flash(\n                \"Broken plugin: [{filename}] {stacktrace}\".format(\n                    stacktrace=stacktrace,\n                    filename=filename),\n                \"error\")\n\n        num_of_all_dags = dags_query.count()\n        num_of_pages = int(math.ceil(num_of_all_dags / float(dags_per_page)))\n\n        auto_complete_data = set()\n        for row in dags_query.with_entities(DagModel.dag_id, DagModel.owners):\n            auto_complete_data.add(row.dag_id)\n            auto_complete_data.add(row.owners)\n\n        return self.render_template(\n            'airflow/dags.html',\n            dags=dags,\n            hide_paused=hide_paused,\n            current_page=current_page,\n            search_query=arg_search_query if arg_search_query else '',\n            page_size=dags_per_page,\n            num_of_pages=num_of_pages,\n            num_dag_from=min(start + 1, num_of_all_dags),\n            num_dag_to=min(end, num_of_all_dags),\n            num_of_all_dags=num_of_all_dags,\n            paging=wwwutils.generate_pages(current_page, num_of_pages,\n                                           search=arg_search_query,\n                                           showPaused=not hide_paused),\n            auto_complete_data=auto_complete_data,\n            num_runs=num_runs)\n\n    @expose('/dag_stats')\n    @has_access\n    @provide_session\n    def dag_stats(self, session=None):\n        dr = models.DagRun\n\n        filter_dag_ids = appbuilder.sm.get_accessible_dag_ids()\n\n        dag_state_stats = session.query(dr.dag_id, dr.state, sqla.func.count(dr.state))\\\n            .group_by(dr.dag_id, dr.state)\n\n        payload = {}\n        if filter_dag_ids:\n            if 'all_dags' not in filter_dag_ids:\n                dag_state_stats = dag_state_stats.filter(dr.dag_id.in_(filter_dag_ids))\n            data = {}\n            for dag_id, state, count in dag_state_stats:\n                if dag_id not in data:\n                    data[dag_id] = {}\n                data[dag_id][state] = count\n\n            if 'all_dags' in filter_dag_ids:\n                filter_dag_ids = [dag_id for dag_id, in session.query(models.DagModel.dag_id)]\n\n            for dag_id in filter_dag_ids:\n                payload[dag_id] = []\n                for state in State.dag_states:\n                    count = data.get(dag_id, {}).get(state, 0)\n                    payload[dag_id].append({\n                        'state': state,\n                        'count': count,\n                        'dag_id': dag_id,\n                        'color': State.color(state)\n                    })\n        return wwwutils.json_response(payload)\n\n    @expose('/task_stats')\n    @has_access\n    @provide_session\n    def task_stats(self, session=None):\n        TI = models.TaskInstance\n        DagRun = models.DagRun\n        Dag = models.DagModel\n\n        filter_dag_ids = appbuilder.sm.get_accessible_dag_ids()\n\n        payload = {}\n        if not filter_dag_ids:\n            return\n\n        LastDagRun = (\n            session.query(\n                DagRun.dag_id,\n                sqla.func.max(DagRun.execution_date).label('execution_date')\n            )\n            .join(Dag, Dag.dag_id == DagRun.dag_id)\n            .filter(DagRun.state != State.RUNNING, Dag.is_active)\n            .group_by(DagRun.dag_id)\n            .subquery('last_dag_run')\n        )\n        RunningDagRun = (\n            session.query(DagRun.dag_id, DagRun.execution_date)\n                   .join(Dag, Dag.dag_id == DagRun.dag_id)\n                   .filter(DagRun.state == State.RUNNING, Dag.is_active)\n                   .subquery('running_dag_run')\n        )\n\n        # Select all task_instances from active dag_runs.\n        # If no dag_run is active, return task instances from most recent dag_run.\n        LastTI = (\n            session.query(TI.dag_id.label('dag_id'), TI.state.label('state'))\n                   .join(LastDagRun,\n                         and_(LastDagRun.c.dag_id == TI.dag_id,\n                              LastDagRun.c.execution_date == TI.execution_date))\n        )\n        RunningTI = (\n            session.query(TI.dag_id.label('dag_id'), TI.state.label('state'))\n                   .join(RunningDagRun,\n                         and_(RunningDagRun.c.dag_id == TI.dag_id,\n                              RunningDagRun.c.execution_date == TI.execution_date))\n        )\n\n        UnionTI = union_all(LastTI, RunningTI).alias('union_ti')\n        qry = (\n            session.query(UnionTI.c.dag_id, UnionTI.c.state, sqla.func.count())\n                   .group_by(UnionTI.c.dag_id, UnionTI.c.state)\n        )\n\n        data = {}\n        for dag_id, state, count in qry:\n            if 'all_dags' in filter_dag_ids or dag_id in filter_dag_ids:\n                if dag_id not in data:\n                    data[dag_id] = {}\n                data[dag_id][state] = count\n        session.commit()\n\n        if 'all_dags' in filter_dag_ids:\n            filter_dag_ids = [dag_id for dag_id, in session.query(models.DagModel.dag_id)]\n        for dag_id in filter_dag_ids:\n            payload[dag_id] = []\n            for state in State.task_states:\n                count = data.get(dag_id, {}).get(state, 0)\n                payload[dag_id].append({\n                    'state': state,\n                    'count': count,\n                    'dag_id': dag_id,\n                    'color': State.color(state)\n                })\n        return wwwutils.json_response(payload)\n\n    @expose('/last_dagruns')\n    @has_access\n    @provide_session\n    def last_dagruns(self, session=None):\n        DagRun = models.DagRun\n\n        filter_dag_ids = appbuilder.sm.get_accessible_dag_ids()\n\n        if not filter_dag_ids:\n            return\n\n        dags_to_latest_runs = dict(session.query(\n            DagRun.dag_id, sqla.func.max(DagRun.execution_date).label('execution_date'))\n            .group_by(DagRun.dag_id).all())\n\n        payload = {}\n        for dag in dagbag.dags.values():\n            dag_accessible = 'all_dags' in filter_dag_ids or dag.dag_id in filter_dag_ids\n            if (dag_accessible and dag.dag_id in dags_to_latest_runs and\n                    dags_to_latest_runs[dag.dag_id]):\n                payload[dag.safe_dag_id] = {\n                    'dag_id': dag.dag_id,\n                    'last_run': dags_to_latest_runs[dag.dag_id].strftime(\"%Y-%m-%d %H:%M\")\n                }\n\n        return wwwutils.json_response(payload)\n\n    @expose('/code')\n    @has_dag_access(can_dag_read=True)\n    @has_access\n    @provide_session\n    def code(self, session=None):\n        dm = models.DagModel\n        dag_id = request.args.get('dag_id')\n        dag = session.query(dm).filter(dm.dag_id == dag_id).first()\n        try:\n            with wwwutils.open_maybe_zipped(dag.fileloc, 'r') as f:\n                code = f.read()\n            html_code = highlight(\n                code, lexers.PythonLexer(), HtmlFormatter(linenos=True))\n        except OSError as e:\n            html_code = str(e)\n\n        return self.render_template(\n            'airflow/dag_code.html', html_code=html_code, dag=dag, title=dag_id,\n            root=request.args.get('root'),\n            demo_mode=conf.getboolean('webserver', 'demo_mode'),\n            wrapped=conf.getboolean('webserver', 'default_wrap'))\n\n    @expose('/dag_details')\n    @has_dag_access(can_dag_read=True)\n    @has_access\n    @provide_session\n    def dag_details(self, session=None):\n        dag_id = request.args.get('dag_id')\n        dag_orm = DagModel.get_dagmodel(dag_id)\n        # FIXME: items needed for this view should move to the database\n        dag = dag_orm.get_dag()\n        title = \"DAG details\"\n        root = request.args.get('root', '')\n\n        TI = models.TaskInstance\n        states = (\n            session.query(TI.state, sqla.func.count(TI.dag_id))\n                   .filter(TI.dag_id == dag_id)\n                   .group_by(TI.state)\n                   .all()\n        )\n\n        active_runs = models.DagRun.find(\n            dag_id=dag_id,\n            state=State.RUNNING,\n            external_trigger=False\n        )\n\n        return self.render_template(\n            'airflow/dag_details.html',\n            dag=dag, title=title, root=root, states=states, State=State, active_runs=active_runs)\n\n    @expose('/rendered')\n    @has_dag_access(can_dag_read=True)\n    @has_access\n    @action_logging\n    def rendered(self):\n        dag_id = request.args.get('dag_id')\n        task_id = request.args.get('task_id')\n        execution_date = request.args.get('execution_date')\n        dttm = pendulum.parse(execution_date)\n        form = DateTimeForm(data={'execution_date': dttm})\n        root = request.args.get('root', '')\n        dag = dagbag.get_dag(dag_id)\n        task = copy.copy(dag.get_task(task_id))\n        ti = models.TaskInstance(task=task, execution_date=dttm)\n        try:\n            ti.render_templates()\n        except Exception as e:\n            flash(\"Error rendering template: \" + str(e), \"error\")\n        title = \"Rendered Template\"\n        html_dict = {}\n        for template_field in task.__class__.template_fields:\n            content = getattr(task, template_field)\n            if template_field in wwwutils.get_attr_renderer():\n                html_dict[template_field] = \\\n                    wwwutils.get_attr_renderer()[template_field](content)\n            else:\n                html_dict[template_field] = (\n                    \"<pre><code>\" + str(content) + \"</pre></code>\")\n\n        return self.render_template(\n            'airflow/ti_code.html',\n            html_dict=html_dict,\n            dag=dag,\n            task_id=task_id,\n            execution_date=execution_date,\n            form=form,\n            root=root,\n            title=title)\n\n    @expose('/get_logs_with_metadata')\n    @has_dag_access(can_dag_read=True)\n    @has_access\n    @action_logging\n    @provide_session\n    def get_logs_with_metadata(self, session=None):\n        dag_id = request.args.get('dag_id')\n        task_id = request.args.get('task_id')\n        execution_date = request.args.get('execution_date')\n        dttm = pendulum.parse(execution_date)\n        if request.args.get('try_number') is not None:\n            try_number = int(request.args.get('try_number'))\n        else:\n            try_number = None\n        metadata = request.args.get('metadata')\n        metadata = json.loads(metadata)\n        response_format = request.args.get('format', 'json')\n\n        # metadata may be null\n        if not metadata:\n            metadata = {}\n\n        # Convert string datetime into actual datetime\n        try:\n            execution_date = timezone.parse(execution_date)\n        except ValueError:\n            error_message = (\n                'Given execution date, {}, could not be identified '\n                'as a date. Example date format: 2015-11-16T14:34:15+00:00'.format(\n                    execution_date))\n            response = jsonify({'error': error_message})\n            response.status_code = 400\n\n            return response\n\n        logger = logging.getLogger('airflow.task')\n        task_log_reader = conf.get('core', 'task_log_reader')\n        handler = next((handler for handler in logger.handlers\n                        if handler.name == task_log_reader), None)\n\n        ti = session.query(models.TaskInstance).filter(\n            models.TaskInstance.dag_id == dag_id,\n            models.TaskInstance.task_id == task_id,\n            models.TaskInstance.execution_date == dttm).first()\n\n        def _get_logs_with_metadata(try_number, metadata):\n            if ti is None:\n                logs = [\"*** Task instance did not exist in the DB\\n\"]\n                metadata['end_of_log'] = True\n            else:\n                logs, metadatas = handler.read(ti, try_number, metadata=metadata)\n                metadata = metadatas[0]\n            return logs, metadata\n\n        try:\n            if ti is not None:\n                dag = dagbag.get_dag(dag_id)\n                ti.task = dag.get_task(ti.task_id)\n            if response_format == 'json':\n                logs, metadata = _get_logs_with_metadata(try_number, metadata)\n                message = logs[0] if try_number is not None else logs\n                return jsonify(message=message, metadata=metadata)\n\n            filename_template = conf.get('core', 'LOG_FILENAME_TEMPLATE')\n            attachment_filename = render_log_filename(\n                ti=ti,\n                try_number=\"all\" if try_number is None else try_number,\n                filename_template=filename_template)\n            metadata['download_logs'] = True\n\n            def _generate_log_stream(try_number, metadata):\n                if try_number is None and ti is not None:\n                    next_try = ti.next_try_number\n                    try_numbers = list(range(1, next_try))\n                else:\n                    try_numbers = [try_number]\n                for try_number in try_numbers:\n                    metadata.pop('end_of_log', None)\n                    metadata.pop('max_offset', None)\n                    metadata.pop('offset', None)\n                    while 'end_of_log' not in metadata or not metadata['end_of_log']:\n                        logs, metadata = _get_logs_with_metadata(try_number, metadata)\n                        yield \"\\n\".join(logs) + \"\\n\"\n            return Response(_generate_log_stream(try_number, metadata),\n                            mimetype=\"text/plain\",\n                            headers={\"Content-Disposition\": \"attachment; filename={}\".format(\n                                attachment_filename)})\n        except AttributeError as e:\n            error_message = [\"Task log handler {} does not support read logs.\\n{}\\n\"\n                             .format(task_log_reader, str(e))]\n            metadata['end_of_log'] = True\n            return jsonify(message=error_message, error=True, metadata=metadata)\n\n    @expose('/log')\n    @has_dag_access(can_dag_read=True)\n    @has_access\n    @action_logging\n    @provide_session\n    def log(self, session=None):\n        dag_id = request.args.get('dag_id')\n        task_id = request.args.get('task_id')\n        execution_date = request.args.get('execution_date')\n        dttm = pendulum.parse(execution_date)\n        form = DateTimeForm(data={'execution_date': dttm})\n        dag_model = DagModel.get_dagmodel(dag_id)\n\n        ti = session.query(models.TaskInstance).filter(\n            models.TaskInstance.dag_id == dag_id,\n            models.TaskInstance.task_id == task_id,\n            models.TaskInstance.execution_date == dttm).first()\n\n        num_logs = 0\n        if ti is not None:\n            num_logs = ti.next_try_number - 1\n            if ti.state == State.UP_FOR_RESCHEDULE:\n                # Tasks in reschedule state decremented the try number\n                num_logs += 1\n        logs = [''] * num_logs\n        root = request.args.get('root', '')\n        return self.render_template(\n            'airflow/ti_log.html',\n            logs=logs, dag=dag_model, title=\"Log by attempts\",\n            dag_id=dag_id, task_id=task_id,\n            execution_date=execution_date, form=form,\n            root=root, wrapped=conf.getboolean('webserver', 'default_wrap'))\n\n    @expose('/elasticsearch')\n    @has_dag_access(can_dag_read=True)\n    @has_access\n    @action_logging\n    @provide_session\n    def elasticsearch(self, session=None):\n        dag_id = request.args.get('dag_id')\n        task_id = request.args.get('task_id')\n        execution_date = request.args.get('execution_date')\n        try_number = request.args.get('try_number', 1)\n        elasticsearch_frontend = conf.get('elasticsearch', 'frontend')\n        log_id_template = conf.get('elasticsearch', 'log_id_template')\n        log_id = log_id_template.format(\n            dag_id=dag_id, task_id=task_id,\n            execution_date=execution_date, try_number=try_number)\n        url = 'https://' + elasticsearch_frontend.format(log_id=quote(log_id))\n        return redirect(url)\n\n    @expose('/task')\n    @has_dag_access(can_dag_read=True)\n    @has_access\n    @action_logging\n    def task(self):\n        TI = models.TaskInstance\n\n        dag_id = request.args.get('dag_id')\n        task_id = request.args.get('task_id')\n        # Carrying execution_date through, even though it's irrelevant for\n        # this context\n        execution_date = request.args.get('execution_date')\n        dttm = pendulum.parse(execution_date)\n        form = DateTimeForm(data={'execution_date': dttm})\n        root = request.args.get('root', '')\n        dag = dagbag.get_dag(dag_id)\n\n        if not dag or task_id not in dag.task_ids:\n            flash(\n                \"Task [{}.{}] doesn't seem to exist\"\n                \" at the moment\".format(dag_id, task_id),\n                \"error\")\n            return redirect(url_for('Airflow.index'))\n        task = copy.copy(dag.get_task(task_id))\n        task.resolve_template_files()\n        ti = TI(task=task, execution_date=dttm)\n        ti.refresh_from_db()\n\n        ti_attrs = []\n        for attr_name in dir(ti):\n            if not attr_name.startswith('_'):\n                attr = getattr(ti, attr_name)\n                if type(attr) != type(self.task):  # noqa\n                    ti_attrs.append((attr_name, str(attr)))\n\n        task_attrs = []\n        for attr_name in dir(task):\n            if not attr_name.startswith('_'):\n                attr = getattr(task, attr_name)\n                if type(attr) != type(self.task) and \\\n                        attr_name not in wwwutils.get_attr_renderer():  # noqa\n                    task_attrs.append((attr_name, str(attr)))\n\n        # Color coding the special attributes that are code\n        special_attrs_rendered = {}\n        for attr_name in wwwutils.get_attr_renderer():\n            if hasattr(task, attr_name):\n                source = getattr(task, attr_name)\n                special_attrs_rendered[attr_name] = \\\n                    wwwutils.get_attr_renderer()[attr_name](source)\n\n        no_failed_deps_result = [(\n            \"Unknown\",\n            \"All dependencies are met but the task instance is not running. In most \"\n            \"cases this just means that the task will probably be scheduled soon \"\n            \"unless:<br/>\\n- The scheduler is down or under heavy load<br/>\\n{}\\n\"\n            \"<br/>\\nIf this task instance does not start soon please contact your \"\n            \"Airflow administrator for assistance.\".format(\n                \"- This task instance already ran and had it's state changed manually \"\n                \"(e.g. cleared in the UI)<br/>\" if ti.state == State.NONE else \"\"))]\n\n        # Use the scheduler's context to figure out which dependencies are not met\n        dep_context = DepContext(SCHEDULER_QUEUED_DEPS)\n        failed_dep_reasons = [(dep.dep_name, dep.reason) for dep in\n                              ti.get_failed_dep_statuses(\n                                  dep_context=dep_context)]\n\n        title = \"Task Instance Details\"\n        return self.render_template(\n            'airflow/task.html',\n            task_attrs=task_attrs,\n            ti_attrs=ti_attrs,\n            failed_dep_reasons=failed_dep_reasons or no_failed_deps_result,\n            task_id=task_id,\n            execution_date=execution_date,\n            special_attrs_rendered=special_attrs_rendered,\n            form=form,\n            root=root,\n            dag=dag, title=title)\n\n    @expose('/xcom')\n    @has_dag_access(can_dag_read=True)\n    @has_access\n    @action_logging\n    @provide_session\n    def xcom(self, session=None):\n        dag_id = request.args.get('dag_id')\n        task_id = request.args.get('task_id')\n        # Carrying execution_date through, even though it's irrelevant for\n        # this context\n        execution_date = request.args.get('execution_date')\n        dttm = pendulum.parse(execution_date)\n        form = DateTimeForm(data={'execution_date': dttm})\n        root = request.args.get('root', '')\n        dm_db = models.DagModel\n        ti_db = models.TaskInstance\n        dag = session.query(dm_db).filter(dm_db.dag_id == dag_id).first()\n        ti = session.query(ti_db).filter(ti_db.dag_id == dag_id and ti_db.task_id == task_id).first()\n\n        if not ti:\n            flash(\n                \"Task [{}.{}] doesn't seem to exist\"\n                \" at the moment\".format(dag_id, task_id),\n                \"error\")\n            return redirect(url_for('Airflow.index'))\n\n        xcomlist = session.query(XCom).filter(\n            XCom.dag_id == dag_id, XCom.task_id == task_id,\n            XCom.execution_date == dttm).all()\n\n        attributes = []\n        for xcom in xcomlist:\n            if not xcom.key.startswith('_'):\n                attributes.append((xcom.key, xcom.value))\n\n        title = \"XCom\"\n        return self.render_template(\n            'airflow/xcom.html',\n            attributes=attributes,\n            task_id=task_id,\n            execution_date=execution_date,\n            form=form,\n            root=root,\n            dag=dag, title=title)\n\n    @expose('/run', methods=['POST'])\n    @has_dag_access(can_dag_edit=True)\n    @has_access\n    @action_logging\n    def run(self):\n        dag_id = request.form.get('dag_id')\n        task_id = request.form.get('task_id')\n        origin = request.form.get('origin')\n        dag = dagbag.get_dag(dag_id)\n        task = dag.get_task(task_id)\n\n        execution_date = request.form.get('execution_date')\n        execution_date = pendulum.parse(execution_date)\n        ignore_all_deps = request.form.get('ignore_all_deps') == \"true\"\n        ignore_task_deps = request.form.get('ignore_task_deps') == \"true\"\n        ignore_ti_state = request.form.get('ignore_ti_state') == \"true\"\n\n        from airflow.executors import get_default_executor\n        executor = get_default_executor()\n        valid_celery_config = False\n        valid_kubernetes_config = False\n\n        try:\n            from airflow.executors.celery_executor import CeleryExecutor\n            valid_celery_config = isinstance(executor, CeleryExecutor)\n        except ImportError:\n            pass\n\n        try:\n            from airflow.executors.kubernetes_executor import KubernetesExecutor\n            valid_kubernetes_config = isinstance(executor, KubernetesExecutor)\n        except ImportError:\n            pass\n\n        if not valid_celery_config and not valid_kubernetes_config:\n            flash(\"Only works with the Celery or Kubernetes executors, sorry\", \"error\")\n            return redirect(origin)\n\n        ti = models.TaskInstance(task=task, execution_date=execution_date)\n        ti.refresh_from_db()\n\n        # Make sure the task instance can be queued\n        dep_context = DepContext(\n            deps=SCHEDULER_QUEUED_DEPS,\n            ignore_all_deps=ignore_all_deps,\n            ignore_task_deps=ignore_task_deps,\n            ignore_ti_state=ignore_ti_state)\n        failed_deps = list(ti.get_failed_dep_statuses(dep_context=dep_context))\n        if failed_deps:\n            failed_deps_str = \", \".join(\n                [\"{}: {}\".format(dep.dep_name, dep.reason) for dep in failed_deps])\n            flash(\"Could not queue task instance for execution, dependencies not met: \"\n                  \"{}\".format(failed_deps_str),\n                  \"error\")\n            return redirect(origin)\n\n        executor.start()\n        executor.queue_task_instance(\n            ti,\n            ignore_all_deps=ignore_all_deps,\n            ignore_task_deps=ignore_task_deps,\n            ignore_ti_state=ignore_ti_state)\n        executor.heartbeat()\n        flash(\n            \"Sent {} to the message queue, \"\n            \"it should start any moment now.\".format(ti))\n        return redirect(origin)\n\n    @expose('/delete', methods=['POST'])\n    @has_dag_access(can_dag_edit=True)\n    @has_access\n    @action_logging\n    def delete(self):\n        from airflow.api.common.experimental import delete_dag\n        from airflow.exceptions import DagNotFound, DagFileExists\n\n        dag_id = request.values.get('dag_id')\n        origin = request.values.get('origin') or url_for('Airflow.index')\n\n        try:\n            delete_dag.delete_dag(dag_id)\n        except DagNotFound:\n            flash(\"DAG with id {} not found. Cannot delete\".format(dag_id), 'error')\n            return redirect(request.referrer)\n        except DagFileExists:\n            flash(\"Dag id {} is still in DagBag. \"\n                  \"Remove the DAG file first.\".format(dag_id),\n                  'error')\n            return redirect(request.referrer)\n\n        flash(\"Deleting DAG with id {}. May take a couple minutes to fully\"\n              \" disappear.\".format(dag_id))\n\n        # Upon success return to origin.\n        return redirect(origin)\n\n    @expose('/trigger', methods=['POST'])\n    @has_dag_access(can_dag_edit=True)\n    @has_access\n    @action_logging\n    @provide_session\n    def trigger(self, session=None):\n        dag_id = request.values.get('dag_id')\n        origin = request.values.get('origin') or url_for('Airflow.index')\n        dag = session.query(models.DagModel).filter(models.DagModel.dag_id == dag_id).first()\n        if not dag:\n            flash(\"Cannot find dag {}\".format(dag_id))\n            return redirect(origin)\n\n        execution_date = timezone.utcnow()\n        run_id = \"manual__{0}\".format(execution_date.isoformat())\n\n        dr = DagRun.find(dag_id=dag_id, run_id=run_id)\n        if dr:\n            flash(\"This run_id {} already exists\".format(run_id))\n            return redirect(origin)\n\n        run_conf = {}\n\n        dag.create_dagrun(\n            run_id=run_id,\n            execution_date=execution_date,\n            state=State.RUNNING,\n            conf=run_conf,\n            external_trigger=True\n        )\n\n        flash(\n            \"Triggered {}, \"\n            \"it should start any moment now.\".format(dag_id))\n        return redirect(origin)\n\n    def _clear_dag_tis(self, dag, start_date, end_date, origin,\n                       recursive=False, confirmed=False, only_failed=False):\n        if confirmed:\n            count = dag.clear(\n                start_date=start_date,\n                end_date=end_date,\n                include_subdags=recursive,\n                include_parentdag=recursive,\n                only_failed=only_failed,\n            )\n\n            flash(\"{0} task instances have been cleared\".format(count))\n            return redirect(origin)\n\n        tis = dag.clear(\n            start_date=start_date,\n            end_date=end_date,\n            include_subdags=recursive,\n            include_parentdag=recursive,\n            only_failed=only_failed,\n            dry_run=True,\n        )\n        if not tis:\n            flash(\"No task instances to clear\", 'error')\n            response = redirect(origin)\n        else:\n            details = \"\\n\".join([str(t) for t in tis])\n\n            response = self.render_template(\n                'airflow/confirm.html',\n                message=(\"Here's the list of task instances you are about \"\n                         \"to clear:\"),\n                details=details)\n\n        return response\n\n    @expose('/clear', methods=['POST'])\n    @has_dag_access(can_dag_edit=True)\n    @has_access\n    @action_logging\n    def clear(self):\n        dag_id = request.form.get('dag_id')\n        task_id = request.form.get('task_id')\n        origin = request.form.get('origin')\n        dag = dagbag.get_dag(dag_id)\n\n        execution_date = request.form.get('execution_date')\n        execution_date = pendulum.parse(execution_date)\n        confirmed = request.form.get('confirmed') == \"true\"\n        upstream = request.form.get('upstream') == \"true\"\n        downstream = request.form.get('downstream') == \"true\"\n        future = request.form.get('future') == \"true\"\n        past = request.form.get('past') == \"true\"\n        recursive = request.form.get('recursive') == \"true\"\n        only_failed = request.form.get('only_failed') == \"true\"\n\n        dag = dag.sub_dag(\n            task_regex=r\"^{0}$\".format(task_id),\n            include_downstream=downstream,\n            include_upstream=upstream)\n\n        end_date = execution_date if not future else None\n        start_date = execution_date if not past else None\n\n        return self._clear_dag_tis(dag, start_date, end_date, origin,\n                                   recursive=recursive, confirmed=confirmed, only_failed=only_failed)\n\n    @expose('/dagrun_clear', methods=['POST'])\n    @has_dag_access(can_dag_edit=True)\n    @has_access\n    @action_logging\n    def dagrun_clear(self):\n        dag_id = request.form.get('dag_id')\n        origin = request.form.get('origin')\n        execution_date = request.form.get('execution_date')\n        confirmed = request.form.get('confirmed') == \"true\"\n\n        dag = dagbag.get_dag(dag_id)\n        execution_date = pendulum.parse(execution_date)\n        start_date = execution_date\n        end_date = execution_date\n\n        return self._clear_dag_tis(dag, start_date, end_date, origin,\n                                   recursive=True, confirmed=confirmed)\n\n    @expose('/blocked')\n    @has_access\n    @provide_session\n    def blocked(self, session=None):\n        DR = models.DagRun\n        filter_dag_ids = appbuilder.sm.get_accessible_dag_ids()\n\n        payload = []\n        if filter_dag_ids:\n            dags = (\n                session.query(DR.dag_id, sqla.func.count(DR.id))\n                       .filter(DR.state == State.RUNNING)\n                       .group_by(DR.dag_id)\n\n            )\n            if 'all_dags' not in filter_dag_ids:\n                dags = dags.filter(DR.dag_id.in_(filter_dag_ids))\n            dags = dags.all()\n\n            for dag_id, active_dag_runs in dags:\n                max_active_runs = 0\n                if dag_id in dagbag.dags:\n                    max_active_runs = dagbag.dags[dag_id].max_active_runs\n                payload.append({\n                    'dag_id': dag_id,\n                    'active_dag_run': active_dag_runs,\n                    'max_active_runs': max_active_runs,\n                })\n        return wwwutils.json_response(payload)\n\n    def _mark_dagrun_state_as_failed(self, dag_id, execution_date, confirmed, origin):\n        if not execution_date:\n            flash('Invalid execution date', 'error')\n            return redirect(origin)\n\n        execution_date = pendulum.parse(execution_date)\n        dag = dagbag.get_dag(dag_id)\n\n        if not dag:\n            flash('Cannot find DAG: {}'.format(dag_id), 'error')\n            return redirect(origin)\n\n        new_dag_state = set_dag_run_state_to_failed(dag, execution_date, commit=confirmed)\n\n        if confirmed:\n            flash('Marked failed on {} task instances'.format(len(new_dag_state)))\n            return redirect(origin)\n\n        else:\n            details = '\\n'.join([str(t) for t in new_dag_state])\n\n            response = self.render_template(\n                'airflow/confirm.html',\n                message=(\"Here's the list of task instances you are about to mark as failed\"),\n                details=details)\n\n            return response\n\n    def _mark_dagrun_state_as_success(self, dag_id, execution_date, confirmed, origin):\n        if not execution_date:\n            flash('Invalid execution date', 'error')\n            return redirect(origin)\n\n        execution_date = pendulum.parse(execution_date)\n        dag = dagbag.get_dag(dag_id)\n\n        if not dag:\n            flash('Cannot find DAG: {}'.format(dag_id), 'error')\n            return redirect(origin)\n\n        new_dag_state = set_dag_run_state_to_success(dag, execution_date,\n                                                     commit=confirmed)\n\n        if confirmed:\n            flash('Marked success on {} task instances'.format(len(new_dag_state)))\n            return redirect(origin)\n\n        else:\n            details = '\\n'.join([str(t) for t in new_dag_state])\n\n            response = self.render_template(\n                'airflow/confirm.html',\n                message=(\"Here's the list of task instances you are about to mark as success\"),\n                details=details)\n\n            return response\n\n    @expose('/dagrun_failed', methods=['POST'])\n    @has_dag_access(can_dag_edit=True)\n    @has_access\n    @action_logging\n    def dagrun_failed(self):\n        dag_id = request.form.get('dag_id')\n        execution_date = request.form.get('execution_date')\n        confirmed = request.form.get('confirmed') == 'true'\n        origin = request.form.get('origin')\n        return self._mark_dagrun_state_as_failed(dag_id, execution_date,\n                                                 confirmed, origin)\n\n    @expose('/dagrun_success', methods=['POST'])\n    @has_dag_access(can_dag_edit=True)\n    @has_access\n    @action_logging\n    def dagrun_success(self):\n        dag_id = request.form.get('dag_id')\n        execution_date = request.form.get('execution_date')\n        confirmed = request.form.get('confirmed') == 'true'\n        origin = request.form.get('origin')\n        return self._mark_dagrun_state_as_success(dag_id, execution_date,\n                                                  confirmed, origin)\n\n    def _mark_task_instance_state(self, dag_id, task_id, origin, execution_date,\n                                  confirmed, upstream, downstream,\n                                  future, past, state):\n        dag = dagbag.get_dag(dag_id)\n        task = dag.get_task(task_id)\n        task.dag = dag\n\n        execution_date = pendulum.parse(execution_date)\n\n        if not dag:\n            flash(\"Cannot find DAG: {}\".format(dag_id))\n            return redirect(origin)\n\n        if not task:\n            flash(\"Cannot find task {} in DAG {}\".format(task_id, dag.dag_id))\n            return redirect(origin)\n\n        from airflow.api.common.experimental.mark_tasks import set_state\n\n        if confirmed:\n            altered = set_state(tasks=[task], execution_date=execution_date,\n                                upstream=upstream, downstream=downstream,\n                                future=future, past=past, state=state,\n                                commit=True)\n\n            flash(\"Marked {} on {} task instances\".format(state, len(altered)))\n            return redirect(origin)\n\n        to_be_altered = set_state(tasks=[task], execution_date=execution_date,\n                                  upstream=upstream, downstream=downstream,\n                                  future=future, past=past, state=state,\n                                  commit=False)\n\n        details = \"\\n\".join([str(t) for t in to_be_altered])\n\n        response = self.render_template(\n            \"airflow/confirm.html\",\n            message=(\"Here's the list of task instances you are about to mark as {}:\".format(state)),\n            details=details)\n\n        return response\n\n    @expose('/failed', methods=['POST'])\n    @has_dag_access(can_dag_edit=True)\n    @has_access\n    @action_logging\n    def failed(self):\n        dag_id = request.form.get('dag_id')\n        task_id = request.form.get('task_id')\n        origin = request.form.get('origin')\n        execution_date = request.form.get('execution_date')\n\n        confirmed = request.form.get('confirmed') == \"true\"\n        upstream = request.form.get('failed_upstream') == \"true\"\n        downstream = request.form.get('failed_downstream') == \"true\"\n        future = request.form.get('failed_future') == \"true\"\n        past = request.form.get('failed_past') == \"true\"\n\n        return self._mark_task_instance_state(dag_id, task_id, origin, execution_date,\n                                              confirmed, upstream, downstream,\n                                              future, past, State.FAILED)\n\n    @expose('/success', methods=['POST'])\n    @has_dag_access(can_dag_edit=True)\n    @has_access\n    @action_logging\n    def success(self):\n        dag_id = request.form.get('dag_id')\n        task_id = request.form.get('task_id')\n        origin = request.form.get('origin')\n        execution_date = request.form.get('execution_date')\n\n        confirmed = request.form.get('confirmed') == \"true\"\n        upstream = request.form.get('success_upstream') == \"true\"\n        downstream = request.form.get('success_downstream') == \"true\"\n        future = request.form.get('success_future') == \"true\"\n        past = request.form.get('success_past') == \"true\"\n\n        return self._mark_task_instance_state(dag_id, task_id, origin, execution_date,\n                                              confirmed, upstream, downstream,\n                                              future, past, State.SUCCESS)\n\n    @expose('/tree')\n    @has_dag_access(can_dag_read=True)\n    @has_access\n    @gzipped\n    @action_logging\n    def tree(self):\n        default_dag_run = conf.getint('webserver', 'default_dag_run_display_number')\n        dag_id = request.args.get('dag_id')\n        blur = conf.getboolean('webserver', 'demo_mode')\n        dag_model = DagModel.get_dagmodel(dag_id)\n        if not dag_model:\n            flash('DAG \"{0}\" seems to be missing in database.'.format(dag_id), \"error\")\n            return redirect(url_for('Airflow.index'))\n        dag = dag_model.get_dag()\n\n        if dag is None:\n            dag = dagbag.get_dag(dag_id)\n            if dag is None:\n                flash('DAG \"{0}\" seems to be missing from DagBag.'.format(dag_id), \"error\")\n                return redirect(url_for('Airflow.index'))\n\n        root = request.args.get('root')\n        if root:\n            dag = dag.sub_dag(\n                task_regex=root,\n                include_downstream=False,\n                include_upstream=True)\n\n        base_date = request.args.get('base_date')\n        num_runs = request.args.get('num_runs')\n        num_runs = int(num_runs) if num_runs else default_dag_run\n\n        if base_date:\n            base_date = timezone.parse(base_date)\n        else:\n            base_date = dag.latest_execution_date or timezone.utcnow()\n\n        with create_session() as session:\n            dag_runs = (\n                session.query(DagRun)\n                .filter(\n                    DagRun.dag_id == dag.dag_id,\n                    DagRun.execution_date <= base_date)\n                .order_by(DagRun.execution_date.desc())\n                .limit(num_runs)\n                .all()\n            )\n        dag_runs = {\n            dr.execution_date: alchemy_to_dict(dr) for dr in dag_runs}\n\n        dates = sorted(list(dag_runs.keys()))\n        max_date = max(dates) if dates else None\n        min_date = min(dates) if dates else None\n\n        tis = dag.get_task_instances(start_date=min_date, end_date=base_date)\n        task_instances = {}\n        for ti in tis:\n            tid = alchemy_to_dict(ti)\n            dr = dag_runs.get(ti.execution_date)\n            tid['external_trigger'] = dr['external_trigger'] if dr else False\n            task_instances[(ti.task_id, ti.execution_date)] = tid\n\n        expanded = []\n        # The default recursion traces every path so that tree view has full\n        # expand/collapse functionality. After 5,000 nodes we stop and fall\n        # back on a quick DFS search for performance. See PR #320.\n        node_count = [0]\n        node_limit = 5000 / max(1, len(dag.leaves))\n\n        def recurse_nodes(task, visited):\n            visited.add(task)\n            node_count[0] += 1\n\n            children = [\n                recurse_nodes(t, visited) for t in task.downstream_list\n                if node_count[0] < node_limit or t not in visited]\n\n            # D3 tree uses children vs _children to define what is\n            # expanded or not. The following block makes it such that\n            # repeated nodes are collapsed by default.\n            children_key = 'children'\n            if task.task_id not in expanded:\n                expanded.append(task.task_id)\n            elif children:\n                children_key = \"_children\"\n\n            def set_duration(tid):\n                if (isinstance(tid, dict) and tid.get(\"state\") == State.RUNNING and\n                        tid[\"start_date\"] is not None):\n                    d = timezone.utcnow() - pendulum.parse(tid[\"start_date\"])\n                    tid[\"duration\"] = d.total_seconds()\n                return tid\n\n            return {\n                'name': task.task_id,\n                'instances': [\n                    set_duration(task_instances.get((task.task_id, d))) or {\n                        'execution_date': d.isoformat(),\n                        'task_id': task.task_id\n                    }\n                    for d in dates],\n                children_key: children,\n                'num_dep': len(task.downstream_list),\n                'operator': task.task_type,\n                'retries': task.retries,\n                'owner': task.owner,\n                'start_date': task.start_date,\n                'end_date': task.end_date,\n                'depends_on_past': task.depends_on_past,\n                'ui_color': task.ui_color,\n                'extra_links': task.extra_links,\n            }\n\n        data = {\n            'name': '[DAG]',\n            'children': [recurse_nodes(t, set()) for t in dag.roots],\n            'instances': [\n                dag_runs.get(d) or {'execution_date': d.isoformat()}\n                for d in dates],\n        }\n\n        session.commit()\n\n        form = DateTimeWithNumRunsForm(data={'base_date': max_date,\n                                             'num_runs': num_runs})\n        external_logs = conf.get('elasticsearch', 'frontend')\n        return self.render_template(\n            'airflow/tree.html',\n            operators=sorted({op.__class__ for op in dag.tasks}, key=lambda x: x.__name__),\n            root=root,\n            form=form,\n            dag=dag, data=data, blur=blur, num_runs=num_runs,\n            show_external_logs=bool(external_logs))\n\n    @expose('/graph')\n    @has_dag_access(can_dag_read=True)\n    @has_access\n    @gzipped\n    @action_logging\n    @provide_session\n    def graph(self, session=None):\n        dag_id = request.args.get('dag_id')\n        blur = conf.getboolean('webserver', 'demo_mode')\n        dag = dagbag.get_dag(dag_id)\n        if dag_id not in dagbag.dags:\n            flash('DAG \"{0}\" seems to be missing.'.format(dag_id), \"error\")\n            return redirect(url_for('Airflow.index'))\n\n        root = request.args.get('root')\n        if root:\n            dag = dag.sub_dag(\n                task_regex=root,\n                include_upstream=True,\n                include_downstream=False)\n\n        arrange = request.args.get('arrange', dag.orientation)\n\n        nodes = []\n        edges = []\n        for task in dag.tasks:\n            nodes.append({\n                'id': task.task_id,\n                'value': {\n                    'label': task.task_id,\n                    'labelStyle': \"fill:{0};\".format(task.ui_fgcolor),\n                    'style': \"fill:{0};\".format(task.ui_color),\n                    'rx': 5,\n                    'ry': 5,\n                }\n            })\n\n        def get_downstream(task):\n            for t in task.downstream_list:\n                edge = {\n                    'source_id': task.task_id,\n                    'target_id': t.task_id,\n                }\n                if edge not in edges:\n                    edges.append(edge)\n                    get_downstream(t)\n\n        for t in dag.roots:\n            get_downstream(t)\n\n        dt_nr_dr_data = get_date_time_num_runs_dag_runs_form_data(request, session, dag)\n        dt_nr_dr_data['arrange'] = arrange\n        dttm = dt_nr_dr_data['dttm']\n\n        class GraphForm(DateTimeWithNumRunsWithDagRunsForm):\n            arrange = SelectField(\"Layout\", choices=(\n                ('LR', \"Left->Right\"),\n                ('RL', \"Right->Left\"),\n                ('TB', \"Top->Bottom\"),\n                ('BT', \"Bottom->Top\"),\n            ))\n\n        form = GraphForm(data=dt_nr_dr_data)\n        form.execution_date.choices = dt_nr_dr_data['dr_choices']\n\n        task_instances = {\n            ti.task_id: alchemy_to_dict(ti)\n            for ti in dag.get_task_instances(dttm, dttm)}\n        tasks = {\n            t.task_id: {\n                'dag_id': t.dag_id,\n                'task_type': t.task_type,\n                'extra_links': t.extra_links,\n            }\n            for t in dag.tasks}\n        if not tasks:\n            flash(\"No tasks found\", \"error\")\n        session.commit()\n        doc_md = markdown.markdown(dag.doc_md) \\\n            if hasattr(dag, 'doc_md') and dag.doc_md else ''\n\n        external_logs = conf.get('elasticsearch', 'frontend')\n        return self.render_template(\n            'airflow/graph.html',\n            dag=dag,\n            form=form,\n            width=request.args.get('width', \"100%\"),\n            height=request.args.get('height', \"800\"),\n            execution_date=dttm.isoformat(),\n            state_token=wwwutils.state_token(dt_nr_dr_data['dr_state']),\n            doc_md=doc_md,\n            arrange=arrange,\n            operators=sorted({op.__class__ for op in dag.tasks}, key=lambda x: x.__name__),\n            blur=blur,\n            root=root or '',\n            task_instances=task_instances,\n            tasks=tasks,\n            nodes=nodes,\n            edges=edges,\n            show_external_logs=bool(external_logs))\n\n    @expose('/duration')\n    @has_dag_access(can_dag_read=True)\n    @has_access\n    @action_logging\n    @provide_session\n    def duration(self, session=None):\n        default_dag_run = conf.getint('webserver', 'default_dag_run_display_number')\n        dag_id = request.args.get('dag_id')\n        dag = dagbag.get_dag(dag_id)\n        base_date = request.args.get('base_date')\n        num_runs = request.args.get('num_runs')\n        num_runs = int(num_runs) if num_runs else default_dag_run\n\n        if dag is None:\n            flash('DAG \"{0}\" seems to be missing.'.format(dag_id), \"error\")\n            return redirect(url_for('Airflow.index'))\n\n        if base_date:\n            base_date = pendulum.parse(base_date)\n        else:\n            base_date = dag.latest_execution_date or timezone.utcnow()\n\n        dates = dag.date_range(base_date, num=-abs(num_runs))\n        min_date = dates[0] if dates else timezone.utc_epoch()\n\n        root = request.args.get('root')\n        if root:\n            dag = dag.sub_dag(\n                task_regex=root,\n                include_upstream=True,\n                include_downstream=False)\n\n        chart_height = wwwutils.get_chart_height(dag)\n        chart = nvd3.lineChart(\n            name=\"lineChart\", x_is_date=True, height=chart_height, width=\"1200\")\n        cum_chart = nvd3.lineChart(\n            name=\"cumLineChart\", x_is_date=True, height=chart_height, width=\"1200\")\n\n        y = defaultdict(list)\n        x = defaultdict(list)\n        cum_y = defaultdict(list)\n\n        tis = dag.get_task_instances(start_date=min_date, end_date=base_date)\n        TF = TaskFail\n        ti_fails = (\n            session.query(TF)\n                   .filter(TF.dag_id == dag.dag_id,\n                           TF.execution_date >= min_date,\n                           TF.execution_date <= base_date,\n                           TF.task_id.in_([t.task_id for t in dag.tasks]))\n                   .all()  # noqa\n        )\n\n        fails_totals = defaultdict(int)\n        for tf in ti_fails:\n            dict_key = (tf.dag_id, tf.task_id, tf.execution_date)\n            if tf.duration:\n                fails_totals[dict_key] += tf.duration\n\n        for ti in tis:\n            if ti.duration:\n                dttm = wwwutils.epoch(ti.execution_date)\n                x[ti.task_id].append(dttm)\n                y[ti.task_id].append(float(ti.duration))\n                fails_dict_key = (ti.dag_id, ti.task_id, ti.execution_date)\n                fails_total = fails_totals[fails_dict_key]\n                cum_y[ti.task_id].append(float(ti.duration + fails_total))\n\n        # determine the most relevant time unit for the set of task instance\n        # durations for the DAG\n        y_unit = infer_time_unit([d for t in y.values() for d in t])\n        cum_y_unit = infer_time_unit([d for t in cum_y.values() for d in t])\n        # update the y Axis on both charts to have the correct time units\n        chart.create_y_axis('yAxis', format='.02f', custom_format=False,\n                            label='Duration ({})'.format(y_unit))\n        chart.axislist['yAxis']['axisLabelDistance'] = '40'\n        cum_chart.create_y_axis('yAxis', format='.02f', custom_format=False,\n                                label='Duration ({})'.format(cum_y_unit))\n        cum_chart.axislist['yAxis']['axisLabelDistance'] = '40'\n\n        for task in dag.tasks:\n            if x[task.task_id]:\n                chart.add_serie(name=task.task_id, x=x[task.task_id],\n                                y=scale_time_units(y[task.task_id], y_unit))\n                cum_chart.add_serie(name=task.task_id, x=x[task.task_id],\n                                    y=scale_time_units(cum_y[task.task_id],\n                                                       cum_y_unit))\n\n        dates = sorted(list({ti.execution_date for ti in tis}))\n        max_date = max([ti.execution_date for ti in tis]) if dates else None\n\n        session.commit()\n\n        form = DateTimeWithNumRunsForm(data={'base_date': max_date,\n                                             'num_runs': num_runs})\n        chart.buildcontent()\n        cum_chart.buildcontent()\n        s_index = cum_chart.htmlcontent.rfind('});')\n        cum_chart.htmlcontent = (cum_chart.htmlcontent[:s_index] +\n                                 \"$( document ).trigger('chartload')\" +\n                                 cum_chart.htmlcontent[s_index:])\n\n        return self.render_template(\n            'airflow/duration_chart.html',\n            dag=dag,\n            demo_mode=conf.getboolean('webserver', 'demo_mode'),\n            root=root,\n            form=form,\n            chart=chart.htmlcontent,\n            cum_chart=cum_chart.htmlcontent\n        )\n\n    @expose('/tries')\n    @has_dag_access(can_dag_read=True)\n    @has_access\n    @action_logging\n    @provide_session\n    def tries(self, session=None):\n        default_dag_run = conf.getint('webserver', 'default_dag_run_display_number')\n        dag_id = request.args.get('dag_id')\n        dag = dagbag.get_dag(dag_id)\n        base_date = request.args.get('base_date')\n        num_runs = request.args.get('num_runs')\n        num_runs = int(num_runs) if num_runs else default_dag_run\n\n        if base_date:\n            base_date = pendulum.parse(base_date)\n        else:\n            base_date = dag.latest_execution_date or timezone.utcnow()\n\n        dates = dag.date_range(base_date, num=-abs(num_runs))\n        min_date = dates[0] if dates else timezone.utc_epoch()\n\n        root = request.args.get('root')\n        if root:\n            dag = dag.sub_dag(\n                task_regex=root,\n                include_upstream=True,\n                include_downstream=False)\n\n        chart_height = wwwutils.get_chart_height(dag)\n        chart = nvd3.lineChart(\n            name=\"lineChart\", x_is_date=True, y_axis_format='d', height=chart_height,\n            width=\"1200\")\n\n        for task in dag.tasks:\n            y = []\n            x = []\n            for ti in task.get_task_instances(start_date=min_date, end_date=base_date):\n                dttm = wwwutils.epoch(ti.execution_date)\n                x.append(dttm)\n                y.append(ti.try_number)\n            if x:\n                chart.add_serie(name=task.task_id, x=x, y=y)\n\n        tis = dag.get_task_instances(start_date=min_date, end_date=base_date)\n        tries = sorted(list({ti.try_number for ti in tis}))\n        max_date = max([ti.execution_date for ti in tis]) if tries else None\n\n        session.commit()\n\n        form = DateTimeWithNumRunsForm(data={'base_date': max_date,\n                                             'num_runs': num_runs})\n\n        chart.buildcontent()\n\n        return self.render_template(\n            'airflow/chart.html',\n            dag=dag,\n            demo_mode=conf.getboolean('webserver', 'demo_mode'),\n            root=root,\n            form=form,\n            chart=chart.htmlcontent\n        )\n\n    @expose('/landing_times')\n    @has_dag_access(can_dag_read=True)\n    @has_access\n    @action_logging\n    @provide_session\n    def landing_times(self, session=None):\n        default_dag_run = conf.getint('webserver', 'default_dag_run_display_number')\n        dag_id = request.args.get('dag_id')\n        dag = dagbag.get_dag(dag_id)\n        base_date = request.args.get('base_date')\n        num_runs = request.args.get('num_runs')\n        num_runs = int(num_runs) if num_runs else default_dag_run\n\n        if base_date:\n            base_date = pendulum.parse(base_date)\n        else:\n            base_date = dag.latest_execution_date or timezone.utcnow()\n\n        dates = dag.date_range(base_date, num=-abs(num_runs))\n        min_date = dates[0] if dates else timezone.utc_epoch()\n\n        root = request.args.get('root')\n        if root:\n            dag = dag.sub_dag(\n                task_regex=root,\n                include_upstream=True,\n                include_downstream=False)\n\n        chart_height = wwwutils.get_chart_height(dag)\n        chart = nvd3.lineChart(\n            name=\"lineChart\", x_is_date=True, height=chart_height, width=\"1200\")\n        y = {}\n        x = {}\n        for task in dag.tasks:\n            y[task.task_id] = []\n            x[task.task_id] = []\n            for ti in task.get_task_instances(start_date=min_date, end_date=base_date):\n                ts = ti.execution_date\n                if dag.schedule_interval and dag.following_schedule(ts):\n                    ts = dag.following_schedule(ts)\n                if ti.end_date:\n                    dttm = wwwutils.epoch(ti.execution_date)\n                    secs = (ti.end_date - ts).total_seconds()\n                    x[ti.task_id].append(dttm)\n                    y[ti.task_id].append(secs)\n\n        # determine the most relevant time unit for the set of landing times\n        # for the DAG\n        y_unit = infer_time_unit([d for t in y.values() for d in t])\n        # update the y Axis to have the correct time units\n        chart.create_y_axis('yAxis', format='.02f', custom_format=False,\n                            label='Landing Time ({})'.format(y_unit))\n        chart.axislist['yAxis']['axisLabelDistance'] = '40'\n        for task in dag.tasks:\n            if x[task.task_id]:\n                chart.add_serie(name=task.task_id, x=x[task.task_id],\n                                y=scale_time_units(y[task.task_id], y_unit))\n\n        tis = dag.get_task_instances(start_date=min_date, end_date=base_date)\n        dates = sorted(list({ti.execution_date for ti in tis}))\n        max_date = max([ti.execution_date for ti in tis]) if dates else None\n\n        session.commit()\n\n        form = DateTimeWithNumRunsForm(data={'base_date': max_date,\n                                             'num_runs': num_runs})\n        chart.buildcontent()\n        return self.render_template(\n            'airflow/chart.html',\n            dag=dag,\n            chart=chart.htmlcontent,\n            height=str(chart_height + 100) + \"px\",\n            demo_mode=conf.getboolean('webserver', 'demo_mode'),\n            root=root,\n            form=form,\n        )\n\n    @expose('/paused', methods=['POST'])\n    @has_dag_access(can_dag_edit=True)\n    @has_access\n    @action_logging\n    def paused(self):\n        dag_id = request.args.get('dag_id')\n        is_paused = True if request.args.get('is_paused') == 'false' else False\n        models.DagModel.get_dagmodel(dag_id).set_is_paused(is_paused=is_paused)\n        return \"OK\"\n\n    @expose('/refresh', methods=['POST'])\n    @has_dag_access(can_dag_edit=True)\n    @has_access\n    @action_logging\n    @provide_session\n    def refresh(self, session=None):\n        DagModel = models.DagModel\n        dag_id = request.values.get('dag_id')\n        orm_dag = session.query(\n            DagModel).filter(DagModel.dag_id == dag_id).first()\n\n        if orm_dag:\n            orm_dag.last_expired = timezone.utcnow()\n            session.merge(orm_dag)\n        session.commit()\n\n        dag = dagbag.get_dag(dag_id)\n        # sync dag permission\n        appbuilder.sm.sync_perm_for_dag(dag_id, dag.access_control)\n\n        flash(\"DAG [{}] is now fresh as a daisy\".format(dag_id))\n        return redirect(request.referrer)\n\n    @expose('/refresh_all', methods=['POST'])\n    @has_access\n    @action_logging\n    def refresh_all(self):\n        dagbag.collect_dags(only_if_updated=False)\n        # sync permissions for all dags\n        for dag_id, dag in dagbag.dags.items():\n            appbuilder.sm.sync_perm_for_dag(dag_id, dag.access_control)\n        flash(\"All DAGs are now up to date\")\n        return redirect(url_for('Airflow.index'))\n\n    @expose('/gantt')\n    @has_dag_access(can_dag_read=True)\n    @has_access\n    @action_logging\n    @provide_session\n    def gantt(self, session=None):\n        dag_id = request.args.get('dag_id')\n        dag = dagbag.get_dag(dag_id)\n        demo_mode = conf.getboolean('webserver', 'demo_mode')\n\n        root = request.args.get('root')\n        if root:\n            dag = dag.sub_dag(\n                task_regex=root,\n                include_upstream=True,\n                include_downstream=False)\n\n        dt_nr_dr_data = get_date_time_num_runs_dag_runs_form_data(request, session, dag)\n        dttm = dt_nr_dr_data['dttm']\n\n        form = DateTimeWithNumRunsWithDagRunsForm(data=dt_nr_dr_data)\n        form.execution_date.choices = dt_nr_dr_data['dr_choices']\n\n        tis = [\n            ti for ti in dag.get_task_instances(dttm, dttm)\n            if ti.start_date and ti.state]\n        tis = sorted(tis, key=lambda ti: ti.start_date)\n        TF = TaskFail\n        ti_fails = list(itertools.chain(*[(\n            session\n            .query(TF)\n            .filter(TF.dag_id == ti.dag_id,\n                    TF.task_id == ti.task_id,\n                    TF.execution_date == ti.execution_date)\n            .all()\n        ) for ti in tis]))\n\n        # determine bars to show in the gantt chart\n        gantt_bar_items = []\n        for ti in tis:\n            end_date = ti.end_date or timezone.utcnow()\n            try_count = ti.try_number\n            if ti.state != State.RUNNING:\n                try_count = ti.try_number - 1\n            gantt_bar_items.append((ti.task_id, ti.start_date, end_date, ti.state, try_count))\n\n        tf_count = 0\n        try_count = 1\n        prev_task_id = \"\"\n        for tf in ti_fails:\n            end_date = tf.end_date or timezone.utcnow()\n            if tf_count != 0 and tf.task_id == prev_task_id:\n                try_count = try_count + 1\n            else:\n                try_count = 1\n            prev_task_id = tf.task_id\n            gantt_bar_items.append((tf.task_id, tf.start_date, end_date, State.FAILED, try_count))\n            tf_count = tf_count + 1\n\n        task_types = {}\n        extra_links = {}\n        for t in dag.tasks:\n            task_types[t.task_id] = t.task_type\n            extra_links[t.task_id] = t.extra_links\n\n        tasks = []\n        for gantt_bar_item in gantt_bar_items:\n            task_id = gantt_bar_item[0]\n            start_date = gantt_bar_item[1]\n            end_date = gantt_bar_item[2]\n            state = gantt_bar_item[3]\n            try_count = gantt_bar_item[4]\n            tasks.append({\n                'startDate': wwwutils.epoch(start_date),\n                'endDate': wwwutils.epoch(end_date),\n                'isoStart': start_date.isoformat()[:-4],\n                'isoEnd': end_date.isoformat()[:-4],\n                'taskName': task_id,\n                'taskType': task_types[ti.task_id],\n                'duration': (end_date - start_date).total_seconds(),\n                'status': state,\n                'executionDate': dttm.isoformat(),\n                'try_number': try_count,\n                'extraLinks': extra_links[ti.task_id],\n            })\n\n        states = {task['status']: task['status'] for task in tasks}\n\n        data = {\n            'taskNames': [ti.task_id for ti in tis],\n            'tasks': tasks,\n            'taskStatus': states,\n            'height': len(tis) * 25 + 25,\n        }\n\n        session.commit()\n\n        return self.render_template(\n            'airflow/gantt.html',\n            dag=dag,\n            execution_date=dttm.isoformat(),\n            form=form,\n            data=data,\n            base_date='',\n            demo_mode=demo_mode,\n            root=root,\n        )\n\n    @expose('/extra_links')\n    @has_dag_access(can_dag_read=True)\n    @has_access\n    @action_logging\n    def extra_links(self):\n        \"\"\"\n        A restful endpoint that returns external links for a given Operator\n\n        It queries the operator that sent the request for the links it wishes\n        to provide for a given external link name.\n\n        API: GET\n        Args: dag_id: The id of the dag containing the task in question\n              task_id: The id of the task in question\n              execution_date: The date of execution of the task\n              link_name: The name of the link reference to find the actual URL for\n\n        Returns:\n            200: {url: <url of link>, error: None} - returned when there was no problem\n                finding the URL\n            404: {url: None, error: <error message>} - returned when the operator does\n                not return a URL\n        \"\"\"\n        dag_id = request.args.get('dag_id')\n        task_id = request.args.get('task_id')\n        execution_date = request.args.get('execution_date')\n        link_name = request.args.get('link_name')\n        dttm = airflow.utils.timezone.parse(execution_date)\n        dag = dagbag.get_dag(dag_id)\n\n        if not dag or task_id not in dag.task_ids:\n            response = jsonify(\n                {'url': None,\n                 'error': \"can't find dag {dag} or task_id {task_id}\".format(\n                     dag=dag,\n                     task_id=task_id\n                 )}\n            )\n            response.status_code = 404\n            return response\n\n        task = dag.get_task(task_id)\n\n        try:\n            url = task.get_extra_links(dttm, link_name)\n        except ValueError as err:\n            response = jsonify({'url': None, 'error': str(err)})\n            response.status_code = 404\n            return response\n        if url:\n            response = jsonify({'error': None, 'url': url})\n            response.status_code = 200\n            return response\n        else:\n            response = jsonify(\n                {'url': None, 'error': 'No URL found for {dest}'.format(dest=link_name)})\n            response.status_code = 404\n            return response\n\n    @expose('/object/task_instances')\n    @has_dag_access(can_dag_read=True)\n    @has_access\n    @action_logging\n    @provide_session\n    def task_instances(self, session=None):\n        dag_id = request.args.get('dag_id')\n        dag = dagbag.get_dag(dag_id)\n\n        dttm = request.args.get('execution_date')\n        if dttm:\n            dttm = pendulum.parse(dttm)\n        else:\n            return \"Error: Invalid execution_date\"\n\n        task_instances = {\n            ti.task_id: alchemy_to_dict(ti)\n            for ti in dag.get_task_instances(dttm, dttm)}\n\n        return json.dumps(task_instances)", "target": 0}, {"function": "class VersionView(AirflowBaseView):\n    @expose('/version')\n    @has_access\n    def version(self):\n        try:\n            airflow_version = airflow.__version__\n        except Exception as e:\n            airflow_version = None\n            logging.error(e)\n\n        # Get the Git repo and git hash\n        git_version = None\n        try:\n            with open(os.path.join(*[settings.AIRFLOW_HOME,\n                                   'airflow', 'git_version'])) as f:\n                git_version = f.readline()\n        except Exception as e:\n            logging.error(e)\n\n        # Render information\n        title = \"Version Info\"\n        return self.render_template(\n            'airflow/version.html',\n            title=title,\n            airflow_version=airflow_version,\n            git_version=git_version)", "target": 0}, {"function": "class ConfigurationView(AirflowBaseView):\n    @expose('/configuration')\n    @has_access\n    def conf(self):\n        raw = request.args.get('raw') == \"true\"\n        title = \"Airflow Configuration\"\n        subtitle = AIRFLOW_CONFIG\n        # Don't show config when expose_config variable is False in airflow config\n        if conf.getboolean(\"webserver\", \"expose_config\"):\n            with open(AIRFLOW_CONFIG, 'r') as file:\n                config = file.read()\n            table = [(section, key, value, source)\n                     for section, parameters in conf.as_dict(True, True).items()\n                     for key, (value, source) in parameters.items()]\n        else:\n            config = (\n                \"# Your Airflow administrator chose not to expose the \"\n                \"configuration, most likely for security reasons.\")\n            table = None\n\n        if raw:\n            return Response(\n                response=config,\n                status=200,\n                mimetype=\"application/text\")\n        else:\n            code_html = Markup(highlight(\n                config,\n                lexers.IniLexer(),  # Lexer call\n                HtmlFormatter(noclasses=True))\n            )\n            return self.render_template(\n                'airflow/config.html',\n                pre_subtitle=settings.HEADER + \"  v\" + airflow.__version__,\n                code_html=code_html, title=title, subtitle=subtitle,\n                table=table)", "target": 0}, {"function": "class DagFilter(BaseFilter):\n    def apply(self, query, func): # noqa\n        if appbuilder.sm.has_all_dags_access():\n            return query\n        filter_dag_ids = appbuilder.sm.get_accessible_dag_ids()\n        return query.filter(self.model.dag_id.in_(filter_dag_ids))", "target": 0}, {"function": "class AirflowModelView(ModelView):\n    list_widget = AirflowModelListWidget\n    page_size = PAGE_SIZE\n\n    CustomSQLAInterface = wwwutils.CustomSQLAInterface", "target": 0}, {"function": "class SlaMissModelView(AirflowModelView):\n    route_base = '/slamiss'\n\n    datamodel = AirflowModelView.CustomSQLAInterface(SlaMiss)\n\n    base_permissions = ['can_list']\n\n    list_columns = ['dag_id', 'task_id', 'execution_date', 'email_sent', 'timestamp']\n    add_columns = ['dag_id', 'task_id', 'execution_date', 'email_sent', 'timestamp']\n    edit_columns = ['dag_id', 'task_id', 'execution_date', 'email_sent', 'timestamp']\n    search_columns = ['dag_id', 'task_id', 'email_sent', 'timestamp', 'execution_date']\n    base_order = ('execution_date', 'desc')\n    base_filters = [['dag_id', DagFilter, lambda: []]]\n\n    formatters_columns = {\n        'task_id': wwwutils.task_instance_link,\n        'execution_date': wwwutils.datetime_f('execution_date'),\n        'timestamp': wwwutils.datetime_f('timestamp'),\n        'dag_id': wwwutils.dag_link,\n    }", "target": 0}, {"function": "class XComModelView(AirflowModelView):\n    route_base = '/xcom'\n\n    datamodel = AirflowModelView.CustomSQLAInterface(XCom)\n\n    base_permissions = ['can_add', 'can_list', 'can_edit', 'can_delete']\n\n    search_columns = ['key', 'value', 'timestamp', 'execution_date', 'task_id', 'dag_id']\n    list_columns = ['key', 'value', 'timestamp', 'execution_date', 'task_id', 'dag_id']\n    add_columns = ['key', 'value', 'execution_date', 'task_id', 'dag_id']\n    edit_columns = ['key', 'value', 'execution_date', 'task_id', 'dag_id']\n    base_order = ('execution_date', 'desc')\n\n    base_filters = [['dag_id', DagFilter, lambda: []]]\n\n    formatters_columns = {\n        'task_id': wwwutils.task_instance_link,\n        'execution_date': wwwutils.datetime_f('execution_date'),\n        'timestamp': wwwutils.datetime_f('timestamp'),\n        'dag_id': wwwutils.dag_link,\n    }\n\n    @action('muldelete', 'Delete', \"Are you sure you want to delete selected records?\",\n            single=False)\n    def action_muldelete(self, items):\n        self.datamodel.delete_all(items)\n        self.update_redirect()\n        return redirect(self.get_redirect())\n\n    def pre_add(self, item):\n        item.execution_date = timezone.make_aware(item.execution_date)\n        item.value = XCom.serialize_value(item.value)\n\n    def pre_update(self, item):\n        item.execution_date = timezone.make_aware(item.execution_date)\n        item.value = XCom.serialize_value(item.value)", "target": 0}, {"function": "class ConnectionModelView(AirflowModelView):\n    route_base = '/connection'\n\n    datamodel = AirflowModelView.CustomSQLAInterface(Connection)\n\n    base_permissions = ['can_add', 'can_list', 'can_edit', 'can_delete']\n\n    extra_fields = ['extra__jdbc__drv_path', 'extra__jdbc__drv_clsname',\n                    'extra__google_cloud_platform__project',\n                    'extra__google_cloud_platform__key_path',\n                    'extra__google_cloud_platform__keyfile_dict',\n                    'extra__google_cloud_platform__scope',\n                    'extra__google_cloud_platform__num_retries',\n                    'extra__grpc__auth_type',\n                    'extra__grpc__credential_pem_file',\n                    'extra__grpc__scopes']\n    list_columns = ['conn_id', 'conn_type', 'host', 'port', 'is_encrypted',\n                    'is_extra_encrypted']\n    add_columns = edit_columns = ['conn_id', 'conn_type', 'host', 'schema',\n                                  'login', 'password', 'port', 'extra'] + extra_fields\n    add_form = edit_form = ConnectionForm\n    add_template = 'airflow/conn_create.html'\n    edit_template = 'airflow/conn_edit.html'\n\n    base_order = ('conn_id', 'asc')\n\n    @action('muldelete', 'Delete', 'Are you sure you want to delete selected records?',\n            single=False)\n    @has_dag_access(can_dag_edit=True)\n    def action_muldelete(self, items):\n        self.datamodel.delete_all(items)\n        self.update_redirect()\n        return redirect(self.get_redirect())\n\n    def process_form(self, form, is_created):\n        formdata = form.data\n        if formdata['conn_type'] in ['jdbc', 'google_cloud_platform', 'grpc']:\n            extra = {\n                key: formdata[key]\n                for key in self.extra_fields if key in formdata}\n            form.extra.data = json.dumps(extra)\n\n    def prefill_form(self, form, pk):\n        try:\n            d = json.loads(form.data.get('extra', '{}'))\n        except Exception:\n            d = {}\n\n        if not hasattr(d, 'get'):\n            logging.warning('extra field for {} is not iterable'.format(\n                form.data.get('conn_id', '<unknown>')))\n            return\n\n        for field in self.extra_fields:\n            value = d.get(field, '')\n            if value:\n                field = getattr(form, field)\n                field.data = value", "target": 0}, {"function": "class PoolModelView(AirflowModelView):\n    route_base = '/pool'\n\n    datamodel = AirflowModelView.CustomSQLAInterface(models.Pool)\n\n    base_permissions = ['can_add', 'can_list', 'can_edit', 'can_delete']\n\n    list_columns = ['pool', 'slots', 'used_slots', 'queued_slots']\n    add_columns = ['pool', 'slots', 'description']\n    edit_columns = ['pool', 'slots', 'description']\n\n    base_order = ('pool', 'asc')\n\n    @action('muldelete', 'Delete', 'Are you sure you want to delete selected records?',\n            single=False)\n    def action_muldelete(self, items):\n        if any(item.pool == models.Pool.DEFAULT_POOL_NAME for item in items):\n            flash(\"default_pool cannot be deleted\", 'error')\n            self.update_redirect()\n            return redirect(self.get_redirect())\n        self.datamodel.delete_all(items)\n        self.update_redirect()\n        return redirect(self.get_redirect())\n\n    def pool_link(attr):\n        pool_id = attr.get('pool')\n        if pool_id is not None:\n            url = url_for('TaskInstanceModelView.list', _flt_3_pool=pool_id)\n            return Markup(\"<a href='{url}'>{pool_id}</a>\").format(url=url, pool_id=pool_id)\n        else:\n            return Markup('<span class=\"label label-danger\">Invalid</span>')\n\n    def fused_slots(attr):\n        pool_id = attr.get('pool')\n        used_slots = attr.get('used_slots')\n        if pool_id is not None and used_slots is not None:\n            url = url_for('TaskInstanceModelView.list', _flt_3_pool=pool_id, _flt_3_state='running')\n            return Markup(\"<a href='{url}'>{used_slots}</a>\").format(url=url, used_slots=used_slots)\n        else:\n            return Markup('<span class=\"label label-danger\">Invalid</span>')\n\n    def fqueued_slots(attr):\n        pool_id = attr.get('pool')\n        queued_slots = attr.get('queued_slots')\n        if pool_id is not None and queued_slots is not None:\n            url = url_for('TaskInstanceModelView.list', _flt_3_pool=pool_id, _flt_3_state='queued')\n            return Markup(\"<a href='{url}'>{queued_slots}</a>\").format(url=url, queued_slots=queued_slots)\n        else:\n            return Markup('<span class=\"label label-danger\">Invalid</span>')\n\n    formatters_columns = {\n        'pool': pool_link,\n        'used_slots': fused_slots,\n        'queued_slots': fqueued_slots\n    }\n\n    validators_columns = {\n        'pool': [validators.DataRequired()],\n        'slots': [validators.NumberRange(min=0)]\n    }", "target": 0}, {"function": "class VariableModelView(AirflowModelView):\n    route_base = '/variable'\n\n    list_template = 'airflow/variable_list.html'\n    edit_template = 'airflow/variable_edit.html'\n\n    datamodel = AirflowModelView.CustomSQLAInterface(models.Variable)\n\n    base_permissions = ['can_add', 'can_list', 'can_edit', 'can_delete', 'can_varimport']\n\n    list_columns = ['key', 'val', 'is_encrypted']\n    add_columns = ['key', 'val']\n    edit_columns = ['key', 'val']\n    search_columns = ['key', 'val']\n\n    base_order = ('key', 'asc')\n\n    def hidden_field_formatter(attr):\n        key = attr.get('key')\n        val = attr.get('val')\n        if wwwutils.should_hide_value_for_key(key):\n            return Markup('*' * 8)\n        if val:\n            return val\n        else:\n            return Markup('<span class=\"label label-danger\">Invalid</span>')\n\n    formatters_columns = {\n        'val': hidden_field_formatter,\n    }\n\n    validators_columns = {\n        'key': [validators.DataRequired()]\n    }\n\n    def prefill_form(self, form, id):\n        if wwwutils.should_hide_value_for_key(form.key.data):\n            form.val.data = '*' * 8\n\n    @action('muldelete', 'Delete', 'Are you sure you want to delete selected records?',\n            single=False)\n    def action_muldelete(self, items):\n        self.datamodel.delete_all(items)\n        self.update_redirect()\n        return redirect(self.get_redirect())\n\n    @action('varexport', 'Export', '', single=False)\n    def action_varexport(self, items):\n        var_dict = {}\n        d = json.JSONDecoder()\n        for var in items:\n            try:\n                val = d.decode(var.val)\n            except Exception:\n                val = var.val\n            var_dict[var.key] = val\n\n        response = make_response(json.dumps(var_dict, sort_keys=True, indent=4))\n        response.headers[\"Content-Disposition\"] = \"attachment; filename=variables.json\"\n        response.headers[\"Content-Type\"] = \"application/json; charset=utf-8\"\n        return response\n\n    @expose('/varimport', methods=[\"POST\"])\n    @has_access\n    @action_logging\n    def varimport(self):\n        try:\n            out = request.files['file'].read()\n            if isinstance(out, bytes):\n                d = json.loads(out.decode('utf-8'))\n            else:\n                d = json.loads(out)\n        except Exception:\n            self.update_redirect()\n            flash(\"Missing file or syntax error.\", 'error')\n            return redirect(self.get_redirect())\n        else:\n            suc_count = fail_count = 0\n            for k, v in d.items():\n                try:\n                    models.Variable.set(k, v, serialize_json=not isinstance(v, str))\n                except Exception as e:\n                    logging.info('Variable import failed: {}'.format(repr(e)))\n                    fail_count += 1\n                else:\n                    suc_count += 1\n            flash(\"{} variable(s) successfully updated.\".format(suc_count))\n            if fail_count:\n                flash(\"{} variable(s) failed to be updated.\".format(fail_count), 'error')\n            self.update_redirect()\n            return redirect(self.get_redirect())", "target": 0}, {"function": "class JobModelView(AirflowModelView):\n    route_base = '/job'\n\n    datamodel = AirflowModelView.CustomSQLAInterface(jobs.BaseJob)\n\n    base_permissions = ['can_list']\n\n    list_columns = ['id', 'dag_id', 'state', 'job_type', 'start_date',\n                    'end_date', 'latest_heartbeat',\n                    'executor_class', 'hostname', 'unixname']\n    search_columns = ['id', 'dag_id', 'state', 'job_type', 'start_date',\n                      'end_date', 'latest_heartbeat', 'executor_class',\n                      'hostname', 'unixname']\n\n    base_order = ('start_date', 'desc')\n\n    base_filters = [['dag_id', DagFilter, lambda: []]]\n\n    formatters_columns = {\n        'start_date': wwwutils.datetime_f('start_date'),\n        'end_date': wwwutils.datetime_f('end_date'),\n        'hostname': wwwutils.nobr_f('hostname'),\n        'state': wwwutils.state_f,\n        'latest_heartbeat': wwwutils.datetime_f('latest_heartbeat'),\n    }", "target": 0}, {"function": "class DagRunModelView(AirflowModelView):\n    route_base = '/dagrun'\n\n    datamodel = AirflowModelView.CustomSQLAInterface(models.DagRun)\n\n    base_permissions = ['can_list', 'can_add']\n\n    add_columns = ['state', 'dag_id', 'execution_date', 'run_id', 'external_trigger']\n    list_columns = ['state', 'dag_id', 'execution_date', 'run_id', 'external_trigger']\n    search_columns = ['state', 'dag_id', 'execution_date', 'run_id', 'external_trigger']\n\n    base_order = ('execution_date', 'desc')\n\n    base_filters = [['dag_id', DagFilter, lambda: []]]\n\n    add_form = edit_form = DagRunForm\n\n    formatters_columns = {\n        'execution_date': wwwutils.datetime_f('execution_date'),\n        'state': wwwutils.state_f,\n        'start_date': wwwutils.datetime_f('start_date'),\n        'dag_id': wwwutils.dag_link,\n        'run_id': wwwutils.dag_run_link,\n    }\n\n    @action('muldelete', \"Delete\", \"Are you sure you want to delete selected records?\",\n            single=False)\n    @has_dag_access(can_dag_edit=True)\n    @provide_session\n    def action_muldelete(self, items, session=None):\n        self.datamodel.delete_all(items)\n        self.update_redirect()\n        dirty_ids = []\n        for item in items:\n            dirty_ids.append(item.dag_id)\n        return redirect(self.get_redirect())\n\n    @action('set_running', \"Set state to 'running'\", '', single=False)\n    @provide_session\n    def action_set_running(self, drs, session=None):\n        try:\n            DR = models.DagRun\n            count = 0\n            dirty_ids = []\n            for dr in session.query(DR).filter(\n                    DR.id.in_([dagrun.id for dagrun in drs])).all():\n                dirty_ids.append(dr.dag_id)\n                count += 1\n                dr.start_date = timezone.utcnow()\n                dr.state = State.RUNNING\n            session.commit()\n            flash(\"{count} dag runs were set to running\".format(count=count))\n        except Exception as ex:\n            flash(str(ex), 'error')\n            flash('Failed to set state', 'error')\n        return redirect(self.get_default_url())\n\n    @action('set_failed', \"Set state to 'failed'\",\n            \"All running task instances would also be marked as failed, are you sure?\",\n            single=False)\n    @provide_session\n    def action_set_failed(self, drs, session=None):\n        try:\n            DR = models.DagRun\n            count = 0\n            dirty_ids = []\n            altered_tis = []\n            for dr in session.query(DR).filter(\n                    DR.id.in_([dagrun.id for dagrun in drs])).all():\n                dirty_ids.append(dr.dag_id)\n                count += 1\n                altered_tis += \\\n                    set_dag_run_state_to_failed(dagbag.get_dag(dr.dag_id),\n                                                dr.execution_date,\n                                                commit=True,\n                                                session=session)\n            altered_ti_count = len(altered_tis)\n            flash(\n                \"{count} dag runs and {altered_ti_count} task instances \"\n                \"were set to failed\".format(count=count, altered_ti_count=altered_ti_count))\n        except Exception:\n            flash('Failed to set state', 'error')\n        return redirect(self.get_default_url())\n\n    @action('set_success', \"Set state to 'success'\",\n            \"All task instances would also be marked as success, are you sure?\",\n            single=False)\n    @provide_session\n    def action_set_success(self, drs, session=None):\n        try:\n            DR = models.DagRun\n            count = 0\n            dirty_ids = []\n            altered_tis = []\n            for dr in session.query(DR).filter(\n                    DR.id.in_([dagrun.id for dagrun in drs])).all():\n                dirty_ids.append(dr.dag_id)\n                count += 1\n                altered_tis += \\\n                    set_dag_run_state_to_success(dagbag.get_dag(dr.dag_id),\n                                                 dr.execution_date,\n                                                 commit=True,\n                                                 session=session)\n            altered_ti_count = len(altered_tis)\n            flash(\n                \"{count} dag runs and {altered_ti_count} task instances \"\n                \"were set to success\".format(count=count, altered_ti_count=altered_ti_count))\n        except Exception:\n            flash('Failed to set state', 'error')\n        return redirect(self.get_default_url())", "target": 0}, {"function": "class LogModelView(AirflowModelView):\n    route_base = '/log'\n\n    datamodel = AirflowModelView.CustomSQLAInterface(Log)\n\n    base_permissions = ['can_list']\n\n    list_columns = ['id', 'dttm', 'dag_id', 'task_id', 'event', 'execution_date',\n                    'owner', 'extra']\n    search_columns = ['dag_id', 'task_id', 'event', 'execution_date', 'owner', 'extra']\n\n    base_order = ('dttm', 'desc')\n\n    base_filters = [['dag_id', DagFilter, lambda: []]]\n\n    formatters_columns = {\n        'dttm': wwwutils.datetime_f('dttm'),\n        'execution_date': wwwutils.datetime_f('execution_date'),\n        'dag_id': wwwutils.dag_link,\n    }", "target": 0}, {"function": "class TaskInstanceModelView(AirflowModelView):\n    route_base = '/taskinstance'\n\n    datamodel = AirflowModelView.CustomSQLAInterface(models.TaskInstance)\n\n    base_permissions = ['can_list']\n\n    page_size = PAGE_SIZE\n\n    list_columns = ['state', 'dag_id', 'task_id', 'execution_date', 'operator',\n                    'start_date', 'end_date', 'duration', 'job_id', 'hostname',\n                    'unixname', 'priority_weight', 'queue', 'queued_dttm', 'try_number',\n                    'pool', 'log_url']\n\n    search_columns = ['state', 'dag_id', 'task_id', 'execution_date', 'hostname',\n                      'queue', 'pool', 'operator', 'start_date', 'end_date']\n\n    base_order = ('job_id', 'asc')\n\n    base_filters = [['dag_id', DagFilter, lambda: []]]\n\n    def log_url_formatter(attr):\n        log_url = attr.get('log_url')\n        return Markup(\n            '<a href=\"{log_url}\">'\n            '    <span class=\"glyphicon glyphicon-book\" aria-hidden=\"true\">'\n            '</span></a>').format(log_url=log_url)\n\n    def duration_f(attr):\n        end_date = attr.get('end_date')\n        duration = attr.get('duration')\n        if end_date and duration:\n            return timedelta(seconds=duration)\n\n    formatters_columns = {\n        'log_url': log_url_formatter,\n        'task_id': wwwutils.task_instance_link,\n        'hostname': wwwutils.nobr_f('hostname'),\n        'state': wwwutils.state_f,\n        'execution_date': wwwutils.datetime_f('execution_date'),\n        'start_date': wwwutils.datetime_f('start_date'),\n        'end_date': wwwutils.datetime_f('end_date'),\n        'queued_dttm': wwwutils.datetime_f('queued_dttm'),\n        'dag_id': wwwutils.dag_link,\n        'duration': duration_f,\n    }\n\n    @provide_session\n    @action('clear', lazy_gettext('Clear'),\n            lazy_gettext('Are you sure you want to clear the state of the selected task'\n                         ' instance(s) and set their dagruns to the running state?'),\n            single=False)\n    def action_clear(self, tis, session=None):\n        try:\n            dag_to_tis = {}\n\n            for ti in tis:\n                dag = dagbag.get_dag(ti.dag_id)\n                tis = dag_to_tis.setdefault(dag, [])\n                tis.append(ti)\n\n            for dag, tis in dag_to_tis.items():\n                models.clear_task_instances(tis, session, dag=dag)\n\n            session.commit()\n            flash(\"{0} task instances have been cleared\".format(len(tis)))\n            self.update_redirect()\n            return redirect(self.get_redirect())\n\n        except Exception:\n            flash('Failed to clear task instances', 'error')\n\n    @provide_session\n    def set_task_instance_state(self, tis, target_state, session=None):\n        try:\n            count = len(tis)\n            for ti in tis:\n                ti.set_state(target_state, session)\n            session.commit()\n            flash(\"{count} task instances were set to '{target_state}'\".format(\n                count=count, target_state=target_state))\n        except Exception:\n            flash('Failed to set state', 'error')\n\n    @action('set_running', \"Set state to 'running'\", '', single=False)\n    @has_dag_access(can_dag_edit=True)\n    def action_set_running(self, tis):\n        self.set_task_instance_state(tis, State.RUNNING)\n        self.update_redirect()\n        return redirect(self.get_redirect())\n\n    @action('set_failed', \"Set state to 'failed'\", '', single=False)\n    @has_dag_access(can_dag_edit=True)\n    def action_set_failed(self, tis):\n        self.set_task_instance_state(tis, State.FAILED)\n        self.update_redirect()\n        return redirect(self.get_redirect())\n\n    @action('set_success', \"Set state to 'success'\", '', single=False)\n    @has_dag_access(can_dag_edit=True)\n    def action_set_success(self, tis):\n        self.set_task_instance_state(tis, State.SUCCESS)\n        self.update_redirect()\n        return redirect(self.get_redirect())\n\n    @action('set_retry', \"Set state to 'up_for_retry'\", '', single=False)\n    @has_dag_access(can_dag_edit=True)\n    def action_set_retry(self, tis):\n        self.set_task_instance_state(tis, State.UP_FOR_RETRY)\n        self.update_redirect()\n        return redirect(self.get_redirect())", "target": 0}, {"function": "class DagModelView(AirflowModelView):\n    route_base = '/dagmodel'\n\n    datamodel = AirflowModelView.CustomSQLAInterface(models.DagModel)\n\n    base_permissions = ['can_list', 'can_show']\n\n    list_columns = ['dag_id', 'is_paused', 'last_scheduler_run',\n                    'last_expired', 'scheduler_lock', 'fileloc', 'owners']\n\n    formatters_columns = {\n        'dag_id': wwwutils.dag_link\n    }\n\n    base_filters = [['dag_id', DagFilter, lambda: []]]\n\n    def get_query(self):\n        \"\"\"\n        Default filters for model\n        \"\"\"\n        return (\n            super().get_query()\n            .filter(or_(models.DagModel.is_active,\n                        models.DagModel.is_paused))\n            .filter(~models.DagModel.is_subdag)\n        )\n\n    def get_count_query(self):\n        \"\"\"\n        Default filters for model\n        \"\"\"\n        return (\n            super().get_count_query()\n            .filter(models.DagModel.is_active)\n            .filter(~models.DagModel.is_subdag)\n        )", "target": 0}]}, {"raw_url": "https://github.com/apache/airflow/raw/c082065f3be07e1c5f39bb86e2b4a06413238631/tests%2Fwww%2Ftest_views.py", "code": "# -*- coding: utf-8 -*-\n#\n# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \"License\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n\nimport copy\nimport io\nimport json\nimport logging.config\nimport os\nimport shutil\nimport sys\nimport tempfile\nimport unittest\nimport urllib\nfrom datetime import timedelta\nfrom unittest import mock\nfrom urllib.parse import quote_plus\n\nimport jinja2\nfrom flask import Markup, url_for\nfrom parameterized import parameterized\nfrom werkzeug.test import Client\nfrom werkzeug.wrappers import BaseResponse\n\nfrom airflow import models, settings\nfrom airflow.config_templates.airflow_local_settings import DEFAULT_LOGGING_CONFIG\nfrom airflow.configuration import conf\nfrom airflow.jobs import BaseJob\nfrom airflow.models import DAG, BaseOperator, Connection, DagRun, TaskInstance\nfrom airflow.models.baseoperator import BaseOperatorLink\nfrom airflow.operators.dummy_operator import DummyOperator\nfrom airflow.settings import Session\nfrom airflow.utils import dates, timezone\nfrom airflow.utils.db import create_session\nfrom airflow.utils.state import State\nfrom airflow.utils.timezone import datetime\nfrom airflow.www import app as application\nfrom tests.test_utils.config import conf_vars\n\n\nclass TestBase(unittest.TestCase):\n    @classmethod\n    def setUpClass(cls):\n        cls.app, cls.appbuilder = application.create_app(session=Session, testing=True)\n        cls.app.config['WTF_CSRF_ENABLED'] = False\n        cls.app.jinja_env.undefined = jinja2.StrictUndefined\n        settings.configure_orm()\n        cls.session = Session\n\n    def setUp(self):\n        self.client = self.app.test_client()\n        self.login()\n\n    def login(self):\n        role_admin = self.appbuilder.sm.find_role('Admin')\n        tester = self.appbuilder.sm.find_user(username='test')\n        if not tester:\n            self.appbuilder.sm.add_user(\n                username='test',\n                first_name='test',\n                last_name='test',\n                email='test@fab.org',\n                role=role_admin,\n                password='test')\n        return self.client.post('/login/', data=dict(\n            username='test',\n            password='test'\n        ), follow_redirects=True)\n\n    def logout(self):\n        return self.client.get('/logout/')\n\n    @classmethod\n    def clear_table(cls, model):\n        with create_session() as session:\n            session.query(model).delete()\n\n    def check_content_in_response(self, text, resp, resp_code=200):\n        resp_html = resp.data.decode('utf-8')\n        self.assertEqual(resp_code, resp.status_code)\n        if isinstance(text, list):\n            for kw in text:\n                self.assertIn(kw, resp_html)\n        else:\n            self.assertIn(text, resp_html)\n\n    def check_content_not_in_response(self, text, resp, resp_code=200):\n        resp_html = resp.data.decode('utf-8')\n        self.assertEqual(resp_code, resp.status_code)\n        if isinstance(text, list):\n            for kw in text:\n                self.assertNotIn(kw, resp_html)\n        else:\n            self.assertNotIn(text, resp_html)\n\n    def percent_encode(self, obj):\n        return urllib.parse.quote_plus(str(obj))\n\n\nclass TestConnectionModelView(TestBase):\n    def setUp(self):\n        super().setUp()\n        self.connection = {\n            'conn_id': 'test_conn',\n            'conn_type': 'http',\n            'host': 'localhost',\n            'port': 8080,\n            'username': 'root',\n            'password': 'admin'\n        }\n\n    def tearDown(self):\n        self.clear_table(Connection)\n        super().tearDown()\n\n    def test_create_connection(self):\n        resp = self.client.post('/connection/add',\n                                data=self.connection,\n                                follow_redirects=True)\n        self.check_content_in_response('Added Row', resp)\n\n\nclass TestVariableModelView(TestBase):\n    def setUp(self):\n        super().setUp()\n        self.variable = {\n            'key': 'test_key',\n            'val': 'text_val',\n            'is_encrypted': True\n        }\n\n    def tearDown(self):\n        self.clear_table(models.Variable)\n        super().tearDown()\n\n    def test_can_handle_error_on_decrypt(self):\n\n        # create valid variable\n        resp = self.client.post('/variable/add',\n                                data=self.variable,\n                                follow_redirects=True)\n\n        # update the variable with a wrong value, given that is encrypted\n        Var = models.Variable\n        (self.session.query(Var)\n            .filter(Var.key == self.variable['key'])\n            .update({\n                'val': 'failed_value_not_encrypted'\n            }, synchronize_session=False))\n        self.session.commit()\n\n        # retrieve Variables page, should not fail and contain the Invalid\n        # label for the variable\n        resp = self.client.get('/variable/list', follow_redirects=True)\n        self.check_content_in_response(\n            '<span class=\"label label-danger\">Invalid</span>', resp)\n\n    def test_xss_prevention(self):\n        xss = \"/variable/list/<img%20src=''%20onerror='alert(1);'>\"\n\n        resp = self.client.get(\n            xss,\n            follow_redirects=True,\n        )\n        self.assertEqual(resp.status_code, 404)\n        self.assertNotIn(\"<img src='' onerror='alert(1);'>\",\n                         resp.data.decode(\"utf-8\"))\n\n    def test_import_variables_no_file(self):\n        resp = self.client.post('/variable/varimport',\n                                follow_redirects=True)\n        self.check_content_in_response('Missing file or syntax error.', resp)\n\n    def test_import_variables_failed(self):\n        content = '{\"str_key\": \"str_value\"}'\n\n        with mock.patch('airflow.models.Variable.set') as set_mock:\n            set_mock.side_effect = UnicodeEncodeError\n            self.assertEqual(self.session.query(models.Variable).count(), 0)\n\n            try:\n                # python 3+\n                bytes_content = io.BytesIO(bytes(content, encoding='utf-8'))\n            except TypeError:\n                # python 2.7\n                bytes_content = io.BytesIO(bytes(content))\n\n            resp = self.client.post('/variable/varimport',\n                                    data={'file': (bytes_content, 'test.json')},\n                                    follow_redirects=True)\n            self.check_content_in_response('1 variable(s) failed to be updated.', resp)\n\n    def test_import_variables_success(self):\n        self.assertEqual(self.session.query(models.Variable).count(), 0)\n\n        content = ('{\"str_key\": \"str_value\", \"int_key\": 60,'\n                   '\"list_key\": [1, 2], \"dict_key\": {\"k_a\": 2, \"k_b\": 3}}')\n        try:\n            # python 3+\n            bytes_content = io.BytesIO(bytes(content, encoding='utf-8'))\n        except TypeError:\n            # python 2.7\n            bytes_content = io.BytesIO(bytes(content))\n\n        resp = self.client.post('/variable/varimport',\n                                data={'file': (bytes_content, 'test.json')},\n                                follow_redirects=True)\n        self.check_content_in_response('4 variable(s) successfully updated.', resp)\n\n\nclass TestPoolModelView(TestBase):\n    def setUp(self):\n        super().setUp()\n        self.pool = {\n            'pool': 'test-pool',\n            'slots': 777,\n            'description': 'test-pool-description',\n        }\n\n    def tearDown(self):\n        self.clear_table(models.Pool)\n        super().tearDown()\n\n    def test_create_pool_with_same_name(self):\n        # create test pool\n        resp = self.client.post('/pool/add',\n                                data=self.pool,\n                                follow_redirects=True)\n        self.check_content_in_response('Added Row', resp)\n\n        # create pool with the same name\n        resp = self.client.post('/pool/add',\n                                data=self.pool,\n                                follow_redirects=True)\n        self.check_content_in_response('Already exists.', resp)\n\n    def test_create_pool_with_empty_name(self):\n\n        self.pool['pool'] = ''\n        resp = self.client.post('/pool/add',\n                                data=self.pool,\n                                follow_redirects=True)\n        self.check_content_in_response('This field is required.', resp)\n\n    def test_odd_name(self):\n        self.pool['pool'] = 'test-pool<script></script>'\n        self.session.add(models.Pool(**self.pool))\n        self.session.commit()\n        resp = self.client.get('/pool/list/')\n        self.check_content_in_response('test-pool&lt;script&gt;', resp)\n        self.check_content_not_in_response('test-pool<script>', resp)\n\n    def test_list(self):\n        self.pool['pool'] = 'test-pool'\n        self.session.add(models.Pool(**self.pool))\n        self.session.commit()\n        resp = self.client.get('/pool/list/')\n        # We should see this link\n        with self.app.test_request_context():\n            url = url_for('TaskInstanceModelView.list', _flt_3_pool='test-pool', _flt_3_state='running')\n            used_tag = Markup(\"<a href='{url}'>{slots}</a>\").format(url=url, slots=0)\n\n            url = url_for('TaskInstanceModelView.list', _flt_3_pool='test-pool', _flt_3_state='queued')\n            queued_tag = Markup(\"<a href='{url}'>{slots}</a>\").format(url=url, slots=0)\n        self.check_content_in_response(used_tag, resp)\n        self.check_content_in_response(queued_tag, resp)\n\n\nclass TestMountPoint(unittest.TestCase):\n    @classmethod\n    def setUpClass(cls):\n        application.app = None\n        application.appbuilder = None\n        conf.set(\"webserver\", \"base_url\", \"http://localhost/test\")\n        app = application.cached_app(config={'WTF_CSRF_ENABLED': False}, session=Session, testing=True)\n        cls.client = Client(app, BaseResponse)\n\n    @classmethod\n    def tearDownClass(cls):\n        application.app = None\n        application.appbuilder = None\n\n    def test_mount(self):\n        # Test an endpoint that doesn't need auth!\n        resp = self.client.get('/test/health')\n        self.assertEqual(resp.status_code, 200)\n        self.assertIn(b\"healthy\", resp.data)\n\n    def test_not_found(self):\n        resp = self.client.get('/', follow_redirects=True)\n        self.assertEqual(resp.status_code, 404)\n\n    def test_index(self):\n        resp = self.client.get('/test/')\n        self.assertEqual(resp.status_code, 302)\n        self.assertEqual(resp.headers['Location'], 'http://localhost/test/home')\n\n\nclass TestAirflowBaseViews(TestBase):\n    EXAMPLE_DAG_DEFAULT_DATE = dates.days_ago(2)\n    run_id = \"test_{}\".format(models.DagRun.id_for_date(EXAMPLE_DAG_DEFAULT_DATE))\n\n    @classmethod\n    def setUpClass(cls):\n        super().setUpClass()\n        dagbag = models.DagBag(include_examples=True)\n        for dag in dagbag.dags.values():\n            dag.sync_to_db()\n\n    def setUp(self):\n        super().setUp()\n        self.logout()\n        self.login()\n        self.cleanup_dagruns()\n        self.prepare_dagruns()\n\n    def cleanup_dagruns(self):\n        DR = models.DagRun\n        dag_ids = ['example_bash_operator',\n                   'example_subdag_operator',\n                   'example_xcom']\n        (self.session\n             .query(DR)\n             .filter(DR.dag_id.in_(dag_ids))\n             .filter(DR.run_id == self.run_id)\n             .delete(synchronize_session='fetch'))\n        self.session.commit()\n\n    def prepare_dagruns(self):\n        dagbag = models.DagBag(include_examples=True)\n        self.bash_dag = dagbag.dags['example_bash_operator']\n        self.sub_dag = dagbag.dags['example_subdag_operator']\n        self.xcom_dag = dagbag.dags['example_xcom']\n\n        self.bash_dagrun = self.bash_dag.create_dagrun(\n            run_id=self.run_id,\n            execution_date=self.EXAMPLE_DAG_DEFAULT_DATE,\n            start_date=timezone.utcnow(),\n            state=State.RUNNING)\n\n        self.sub_dagrun = self.sub_dag.create_dagrun(\n            run_id=self.run_id,\n            execution_date=self.EXAMPLE_DAG_DEFAULT_DATE,\n            start_date=timezone.utcnow(),\n            state=State.RUNNING)\n\n        self.xcom_dagrun = self.xcom_dag.create_dagrun(\n            run_id=self.run_id,\n            execution_date=self.EXAMPLE_DAG_DEFAULT_DATE,\n            start_date=timezone.utcnow(),\n            state=State.RUNNING)\n\n    def test_index(self):\n        resp = self.client.get('/', follow_redirects=True)\n        self.check_content_in_response('DAGs', resp)\n\n    def test_health(self):\n\n        # case-1: healthy scheduler status\n        last_scheduler_heartbeat_for_testing_1 = timezone.utcnow()\n        self.session.add(BaseJob(job_type='SchedulerJob',\n                                 state='running',\n                                 latest_heartbeat=last_scheduler_heartbeat_for_testing_1))\n        self.session.commit()\n\n        resp_json = json.loads(self.client.get('health', follow_redirects=True).data.decode('utf-8'))\n\n        self.assertEqual('healthy', resp_json['metadatabase']['status'])\n        self.assertEqual('healthy', resp_json['scheduler']['status'])\n        self.assertEqual(last_scheduler_heartbeat_for_testing_1.isoformat(),\n                         resp_json['scheduler']['latest_scheduler_heartbeat'])\n\n        self.session.query(BaseJob).\\\n            filter(BaseJob.job_type == 'SchedulerJob',\n                   BaseJob.state == 'running',\n                   BaseJob.latest_heartbeat == last_scheduler_heartbeat_for_testing_1).\\\n            delete()\n        self.session.commit()\n\n        # case-2: unhealthy scheduler status - scenario 1 (SchedulerJob is running too slowly)\n        last_scheduler_heartbeat_for_testing_2 = timezone.utcnow() - timedelta(minutes=1)\n        (self.session\n             .query(BaseJob)\n             .filter(BaseJob.job_type == 'SchedulerJob')\n             .update({'latest_heartbeat': last_scheduler_heartbeat_for_testing_2 - timedelta(seconds=1)}))\n        self.session.add(BaseJob(job_type='SchedulerJob',\n                                 state='running',\n                                 latest_heartbeat=last_scheduler_heartbeat_for_testing_2))\n        self.session.commit()\n\n        resp_json = json.loads(self.client.get('health', follow_redirects=True).data.decode('utf-8'))\n\n        self.assertEqual('healthy', resp_json['metadatabase']['status'])\n        self.assertEqual('unhealthy', resp_json['scheduler']['status'])\n        self.assertEqual(last_scheduler_heartbeat_for_testing_2.isoformat(),\n                         resp_json['scheduler']['latest_scheduler_heartbeat'])\n\n        self.session.query(BaseJob).\\\n            filter(BaseJob.job_type == 'SchedulerJob',\n                   BaseJob.state == 'running',\n                   BaseJob.latest_heartbeat == last_scheduler_heartbeat_for_testing_2).\\\n            delete()\n        self.session.commit()\n\n        # case-3: unhealthy scheduler status - scenario 2 (no running SchedulerJob)\n        self.session.query(BaseJob).\\\n            filter(BaseJob.job_type == 'SchedulerJob',\n                   BaseJob.state == 'running').\\\n            delete()\n        self.session.commit()\n\n        resp_json = json.loads(self.client.get('health', follow_redirects=True).data.decode('utf-8'))\n\n        self.assertEqual('healthy', resp_json['metadatabase']['status'])\n        self.assertEqual('unhealthy', resp_json['scheduler']['status'])\n        self.assertIsNone(None, resp_json['scheduler']['latest_scheduler_heartbeat'])\n\n    def test_home(self):\n        resp = self.client.get('home', follow_redirects=True)\n        self.check_content_in_response('DAGs', resp)\n\n    def test_task(self):\n        url = ('task?task_id=runme_0&dag_id=example_bash_operator&execution_date={}'\n               .format(self.percent_encode(self.EXAMPLE_DAG_DEFAULT_DATE)))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('Task Instance Details', resp)\n\n    def test_xcom(self):\n        url = ('xcom?task_id=runme_0&dag_id=example_bash_operator&execution_date={}'\n               .format(self.percent_encode(self.EXAMPLE_DAG_DEFAULT_DATE)))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('XCom', resp)\n\n    def test_rendered(self):\n        url = ('rendered?task_id=runme_0&dag_id=example_bash_operator&execution_date={}'\n               .format(self.percent_encode(self.EXAMPLE_DAG_DEFAULT_DATE)))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('Rendered Template', resp)\n\n    def test_blocked(self):\n        url = 'blocked'\n        resp = self.client.get(url, follow_redirects=True)\n        self.assertEqual(200, resp.status_code)\n\n    def test_dag_stats(self):\n        resp = self.client.get('dag_stats', follow_redirects=True)\n        self.assertEqual(resp.status_code, 200)\n\n    def test_task_stats(self):\n        resp = self.client.get('task_stats', follow_redirects=True)\n        self.assertEqual(resp.status_code, 200)\n\n    def test_dag_details(self):\n        url = 'dag_details?dag_id=example_bash_operator'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('DAG details', resp)\n\n    def test_dag_details_subdag(self):\n        url = 'dag_details?dag_id=example_subdag_operator.section-1'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('DAG details', resp)\n\n    def test_graph(self):\n        url = 'graph?dag_id=example_bash_operator'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('runme_1', resp)\n\n    def test_last_dagruns(self):\n        resp = self.client.get('last_dagruns', follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n\n    def test_tree(self):\n        url = 'tree?dag_id=example_bash_operator'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('runme_1', resp)\n\n    def test_tree_subdag(self):\n        url = 'tree?dag_id=example_subdag_operator.section-1'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('section-1-task-1', resp)\n\n    def test_duration(self):\n        url = 'duration?days=30&dag_id=example_bash_operator'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n\n    def test_duration_missing(self):\n        url = 'duration?days=30&dag_id=missing_dag'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('seems to be missing', resp)\n\n    def test_tries(self):\n        url = 'tries?days=30&dag_id=example_bash_operator'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n\n    def test_landing_times(self):\n        url = 'landing_times?days=30&dag_id=example_bash_operator'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n\n    def test_gantt(self):\n        url = 'gantt?dag_id=example_bash_operator'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n\n    def test_code(self):\n        url = 'code?dag_id=example_bash_operator'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n\n    def test_paused(self):\n        url = 'paused?dag_id=example_bash_operator&is_paused=false'\n        resp = self.client.post(url, follow_redirects=True)\n        self.check_content_in_response('OK', resp)\n\n    def test_failed(self):\n        form = dict(\n            task_id=\"run_this_last\",\n            dag_id=\"example_bash_operator\",\n            execution_date=self.EXAMPLE_DAG_DEFAULT_DATE,\n            upstream=\"false\",\n            downstream=\"false\",\n            future=\"false\",\n            past=\"false\",\n        )\n        resp = self.client.post(\"failed\", data=form)\n        self.check_content_in_response('Wait a minute', resp)\n\n    def test_success(self):\n        form = dict(\n            task_id=\"run_this_last\",\n            dag_id=\"example_bash_operator\",\n            execution_date=self.EXAMPLE_DAG_DEFAULT_DATE,\n            upstream=\"false\",\n            downstream=\"false\",\n            future=\"false\",\n            past=\"false\",\n        )\n        resp = self.client.post('success', data=form)\n        self.check_content_in_response('Wait a minute', resp)\n\n    def test_clear(self):\n        form = dict(\n            task_id=\"runme_1\",\n            dag_id=\"example_bash_operator\",\n            execution_date=self.EXAMPLE_DAG_DEFAULT_DATE,\n            upstream=\"false\",\n            downstream=\"false\",\n            future=\"false\",\n            past=\"false\",\n            only_failed=\"false\",\n        )\n        resp = self.client.post(\"clear\", data=form)\n        self.check_content_in_response(['example_bash_operator', 'Wait a minute'], resp)\n\n    def test_run(self):\n        form = dict(\n            task_id=\"runme_0\",\n            dag_id=\"example_bash_operator\",\n            ignore_all_deps=\"false\",\n            ignore_ti_state=\"true\",\n            execution_date=self.EXAMPLE_DAG_DEFAULT_DATE,\n        )\n        resp = self.client.post('run', data=form)\n        self.check_content_in_response('', resp, resp_code=302)\n\n    def test_refresh(self):\n        resp = self.client.post('refresh?dag_id=example_bash_operator')\n        self.check_content_in_response('', resp, resp_code=302)\n\n    def test_refresh_all(self):\n        resp = self.client.post(\"/refresh_all\",\n                                follow_redirects=True)\n        self.check_content_in_response('', resp, resp_code=200)\n\n    def test_delete_dag_button_normal(self):\n        resp = self.client.get('/', follow_redirects=True)\n        self.check_content_in_response('/delete?dag_id=example_bash_operator', resp)\n        self.check_content_in_response(\"return confirmDeleteDag(this, 'example_bash_operator')\", resp)\n\n    def test_delete_dag_button_for_dag_on_scheduler_only(self):\n        # Test for JIRA AIRFLOW-3233 (PR 4069):\n        # The delete-dag URL should be generated correctly for DAGs\n        # that exist on the scheduler (DB) but not the webserver DagBag\n\n        test_dag_id = \"non_existent_dag\"\n\n        DM = models.DagModel\n        self.session.query(DM).filter(DM.dag_id == 'example_bash_operator').update({'dag_id': test_dag_id})\n        self.session.commit()\n\n        resp = self.client.get('/', follow_redirects=True)\n        self.check_content_in_response('/delete?dag_id={}'.format(test_dag_id), resp)\n        self.check_content_in_response(\"return confirmDeleteDag(this, '{}')\".format(test_dag_id), resp)\n\n        self.session.query(DM).filter(DM.dag_id == test_dag_id).update({'dag_id': 'example_bash_operator'})\n        self.session.commit()\n\n\nclass TestConfigurationView(TestBase):\n    def test_configuration_do_not_expose_config(self):\n        self.logout()\n        self.login()\n        with conf_vars({('webserver', 'expose_config'): 'False'}):\n            resp = self.client.get('configuration', follow_redirects=True)\n        self.check_content_in_response(\n            ['Airflow Configuration', '# Your Airflow administrator chose not to expose the configuration, '\n                                      'most likely for security reasons.'], resp)\n\n    def test_configuration_expose_config(self):\n        self.logout()\n        self.login()\n        with conf_vars({('webserver', 'expose_config'): 'True'}):\n            resp = self.client.get('configuration', follow_redirects=True)\n        self.check_content_in_response(\n            ['Airflow Configuration', 'Running Configuration'], resp)\n\n\nclass TestLogView(TestBase):\n    DAG_ID = 'dag_for_testing_log_view'\n    TASK_ID = 'task_for_testing_log_view'\n    DEFAULT_DATE = timezone.datetime(2017, 9, 1)\n    ENDPOINT = 'log?dag_id={dag_id}&task_id={task_id}&' \\\n               'execution_date={execution_date}'.format(dag_id=DAG_ID,\n                                                        task_id=TASK_ID,\n                                                        execution_date=DEFAULT_DATE)\n\n    def setUp(self):\n        # Make sure that the configure_logging is not cached\n        self.old_modules = dict(sys.modules)\n\n        # Create a custom logging configuration\n        logging_config = copy.deepcopy(DEFAULT_LOGGING_CONFIG)\n        current_dir = os.path.dirname(os.path.abspath(__file__))\n        logging_config['handlers']['task']['base_log_folder'] = os.path.normpath(\n            os.path.join(current_dir, 'test_logs'))\n\n        logging_config['handlers']['task']['filename_template'] = \\\n            '{{ ti.dag_id }}/{{ ti.task_id }}/' \\\n            '{{ ts | replace(\":\", \".\") }}/{{ try_number }}.log'\n\n        # Write the custom logging configuration to a file\n        self.settings_folder = tempfile.mkdtemp()\n        settings_file = os.path.join(self.settings_folder, \"airflow_local_settings.py\")\n        new_logging_file = \"LOGGING_CONFIG = {}\".format(logging_config)\n        with open(settings_file, 'w') as handle:\n            handle.writelines(new_logging_file)\n        sys.path.append(self.settings_folder)\n        conf.set('core', 'logging_config_class', 'airflow_local_settings.LOGGING_CONFIG')\n\n        self.app, self.appbuilder = application.create_app(session=Session, testing=True)\n        self.app.config['WTF_CSRF_ENABLED'] = False\n        self.client = self.app.test_client()\n        settings.configure_orm()\n        self.login()\n\n        from airflow.www.views import dagbag\n        dag = DAG(self.DAG_ID, start_date=self.DEFAULT_DATE)\n        dag.sync_to_db()\n        task = DummyOperator(task_id=self.TASK_ID, dag=dag)\n        dagbag.bag_dag(dag, parent_dag=dag, root_dag=dag)\n        with create_session() as session:\n            self.ti = TaskInstance(task=task, execution_date=self.DEFAULT_DATE)\n            self.ti.try_number = 1\n            session.merge(self.ti)\n\n    def tearDown(self):\n        logging.config.dictConfig(DEFAULT_LOGGING_CONFIG)\n        self.clear_table(TaskInstance)\n\n        # Remove any new modules imported during the test run. This lets us\n        # import the same source files for more than one test.\n        for m in [m for m in sys.modules if m not in self.old_modules]:\n            del sys.modules[m]\n\n        sys.path.remove(self.settings_folder)\n        shutil.rmtree(self.settings_folder)\n        conf.set('core', 'logging_config_class', '')\n\n        self.logout()\n        super().tearDown()\n\n    @parameterized.expand([\n        [State.NONE, 0, 0],\n        [State.UP_FOR_RETRY, 2, 2],\n        [State.UP_FOR_RESCHEDULE, 0, 1],\n        [State.UP_FOR_RESCHEDULE, 1, 2],\n        [State.RUNNING, 1, 1],\n        [State.SUCCESS, 1, 1],\n        [State.FAILED, 3, 3],\n    ])\n    def test_get_file_task_log(self, state, try_number, expected_num_logs_visible):\n        with create_session() as session:\n            self.ti.state = state\n            self.ti.try_number = try_number\n            session.merge(self.ti)\n\n        response = self.client.get(\n            TestLogView.ENDPOINT, data=dict(\n                username='test',\n                password='test'), follow_redirects=True)\n        self.assertEqual(response.status_code, 200)\n        self.assertIn('Log by attempts', response.data.decode('utf-8'))\n        for num in range(1, expected_num_logs_visible + 1):\n            self.assertIn('try-{}'.format(num), response.data.decode('utf-8'))\n        self.assertNotIn('try-0', response.data.decode('utf-8'))\n        self.assertNotIn('try-{}'.format(expected_num_logs_visible + 1), response.data.decode('utf-8'))\n\n    def test_get_logs_with_metadata_as_download_file(self):\n        url_template = \"get_logs_with_metadata?dag_id={}&\" \\\n                       \"task_id={}&execution_date={}&\" \\\n                       \"try_number={}&metadata={}&format=file\"\n        try_number = 1\n        url = url_template.format(self.DAG_ID,\n                                  self.TASK_ID,\n                                  quote_plus(self.DEFAULT_DATE.isoformat()),\n                                  try_number,\n                                  json.dumps({}))\n        response = self.client.get(url)\n        expected_filename = '{}/{}/{}/{}.log'.format(self.DAG_ID,\n                                                     self.TASK_ID,\n                                                     self.DEFAULT_DATE.isoformat(),\n                                                     try_number)\n\n        content_disposition = response.headers.get('Content-Disposition')\n        self.assertTrue(content_disposition.startswith('attachment'))\n        self.assertTrue(expected_filename in content_disposition)\n        self.assertEqual(200, response.status_code)\n        self.assertIn('Log for testing.', response.data.decode('utf-8'))\n\n    def test_get_logs_with_metadata_as_download_large_file(self):\n        with mock.patch(\"airflow.utils.log.file_task_handler.FileTaskHandler.read\") as read_mock:\n            first_return = (['1st line'], [{}])\n            second_return = (['2nd line'], [{'end_of_log': False}])\n            third_return = (['3rd line'], [{'end_of_log': True}])\n            fourth_return = (['should never be read'], [{'end_of_log': True}])\n            read_mock.side_effect = [first_return, second_return, third_return, fourth_return]\n            url_template = \"get_logs_with_metadata?dag_id={}&\" \\\n                           \"task_id={}&execution_date={}&\" \\\n                           \"try_number={}&metadata={}&format=file\"\n            try_number = 1\n            url = url_template.format(self.DAG_ID,\n                                      self.TASK_ID,\n                                      quote_plus(self.DEFAULT_DATE.isoformat()),\n                                      try_number,\n                                      json.dumps({}))\n            response = self.client.get(url)\n\n            self.assertIn('1st line', response.data.decode('utf-8'))\n            self.assertIn('2nd line', response.data.decode('utf-8'))\n            self.assertIn('3rd line', response.data.decode('utf-8'))\n            self.assertNotIn('should never be read', response.data.decode('utf-8'))\n\n    def test_get_logs_with_metadata(self):\n        url_template = \"get_logs_with_metadata?dag_id={}&\" \\\n                       \"task_id={}&execution_date={}&\" \\\n                       \"try_number={}&metadata={}\"\n        response = \\\n            self.client.get(url_template.format(self.DAG_ID,\n                                                self.TASK_ID,\n                                                quote_plus(self.DEFAULT_DATE.isoformat()),\n                                                1,\n                                                json.dumps({})), data=dict(\n                                                    username='test',\n                                                    password='test'),\n                            follow_redirects=True)\n\n        self.assertIn('\"message\":', response.data.decode('utf-8'))\n        self.assertIn('\"metadata\":', response.data.decode('utf-8'))\n        self.assertIn('Log for testing.', response.data.decode('utf-8'))\n        self.assertEqual(200, response.status_code)\n\n    def test_get_logs_with_null_metadata(self):\n        url_template = \"get_logs_with_metadata?dag_id={}&\" \\\n                       \"task_id={}&execution_date={}&\" \\\n                       \"try_number={}&metadata=null\"\n        response = \\\n            self.client.get(url_template.format(self.DAG_ID,\n                                                self.TASK_ID,\n                                                quote_plus(self.DEFAULT_DATE.isoformat()),\n                                                1), data=dict(\n                                                    username='test',\n                                                    password='test'),\n                            follow_redirects=True)\n\n        self.assertIn('\"message\":', response.data.decode('utf-8'))\n        self.assertIn('\"metadata\":', response.data.decode('utf-8'))\n        self.assertIn('Log for testing.', response.data.decode('utf-8'))\n        self.assertEqual(200, response.status_code)\n\n\nclass TestVersionView(TestBase):\n    def test_version(self):\n        resp = self.client.get('version', data=dict(\n            username='test',\n            password='test'\n        ), follow_redirects=True)\n        self.check_content_in_response('Version Info', resp)\n\n\nclass ViewWithDateTimeAndNumRunsAndDagRunsFormTester:\n    DAG_ID = 'dag_for_testing_dt_nr_dr_form'\n    DEFAULT_DATE = datetime(2017, 9, 1)\n    RUNS_DATA = [\n        ('dag_run_for_testing_dt_nr_dr_form_4', datetime(2018, 4, 4)),\n        ('dag_run_for_testing_dt_nr_dr_form_3', datetime(2018, 3, 3)),\n        ('dag_run_for_testing_dt_nr_dr_form_2', datetime(2018, 2, 2)),\n        ('dag_run_for_testing_dt_nr_dr_form_1', datetime(2018, 1, 1)),\n    ]\n\n    def __init__(self, test, endpoint):\n        self.test = test\n        self.endpoint = endpoint\n\n    def setUp(self):\n        from airflow.www.views import dagbag\n        from airflow.utils.state import State\n        dag = DAG(self.DAG_ID, start_date=self.DEFAULT_DATE)\n        dagbag.bag_dag(dag, parent_dag=dag, root_dag=dag)\n        self.runs = []\n        for rd in self.RUNS_DATA:\n            run = dag.create_dagrun(\n                run_id=rd[0],\n                execution_date=rd[1],\n                state=State.SUCCESS,\n                external_trigger=True\n            )\n            self.runs.append(run)\n\n    def tearDown(self):\n        self.test.session.query(DagRun).filter(\n            DagRun.dag_id == self.DAG_ID).delete()\n        self.test.session.commit()\n        self.test.session.close()\n\n    def assertBaseDateAndNumRuns(self, base_date, num_runs, data):\n        self.test.assertNotIn('name=\"base_date\" value=\"{}\"'.format(base_date), data)\n        self.test.assertNotIn('<option selected=\"\" value=\"{}\">{}</option>'.format(\n            num_runs, num_runs), data)\n\n    def assertRunIsNotInDropdown(self, run, data):\n        self.test.assertNotIn(run.execution_date.isoformat(), data)\n        self.test.assertNotIn(run.run_id, data)\n\n    def assertRunIsInDropdownNotSelected(self, run, data):\n        self.test.assertIn('<option value=\"{}\">{}</option>'.format(\n            run.execution_date.isoformat(), run.run_id), data)\n\n    def assertRunIsSelected(self, run, data):\n        self.test.assertIn('<option selected value=\"{}\">{}</option>'.format(\n            run.execution_date.isoformat(), run.run_id), data)\n\n    def test_with_default_parameters(self):\n        \"\"\"\n        Tests view with no URL parameter.\n        Should show all dag runs in the drop down.\n        Should select the latest dag run.\n        Should set base date to current date (not asserted)\n        \"\"\"\n        response = self.test.client.get(\n            self.endpoint, data=dict(\n                username='test',\n                password='test'), follow_redirects=True)\n        self.test.assertEqual(response.status_code, 200)\n        data = response.data.decode('utf-8')\n        self.test.assertIn('Base date:', data)\n        self.test.assertIn('Number of runs:', data)\n        self.assertRunIsSelected(self.runs[0], data)\n        self.assertRunIsInDropdownNotSelected(self.runs[1], data)\n        self.assertRunIsInDropdownNotSelected(self.runs[2], data)\n        self.assertRunIsInDropdownNotSelected(self.runs[3], data)\n\n    def test_with_execution_date_parameter_only(self):\n        \"\"\"\n        Tests view with execution_date URL parameter.\n        Scenario: click link from dag runs view.\n        Should only show dag runs older than execution_date in the drop down.\n        Should select the particular dag run.\n        Should set base date to execution date.\n        \"\"\"\n        response = self.test.client.get(\n            self.endpoint + '&execution_date={}'.format(\n                self.runs[1].execution_date.isoformat()),\n            data=dict(\n                username='test',\n                password='test'\n            ), follow_redirects=True\n        )\n        self.test.assertEqual(response.status_code, 200)\n        data = response.data.decode('utf-8')\n        self.assertBaseDateAndNumRuns(\n            self.runs[1].execution_date,\n            conf.getint('webserver', 'default_dag_run_display_number'),\n            data)\n        self.assertRunIsNotInDropdown(self.runs[0], data)\n        self.assertRunIsSelected(self.runs[1], data)\n        self.assertRunIsInDropdownNotSelected(self.runs[2], data)\n        self.assertRunIsInDropdownNotSelected(self.runs[3], data)\n\n    def test_with_base_date_and_num_runs_parmeters_only(self):\n        \"\"\"\n        Tests view with base_date and num_runs URL parameters.\n        Should only show dag runs older than base_date in the drop down,\n        limited to num_runs.\n        Should select the latest dag run.\n        Should set base date and num runs to submitted values.\n        \"\"\"\n        response = self.test.client.get(\n            self.endpoint + '&base_date={}&num_runs=2'.format(\n                self.runs[1].execution_date.isoformat()),\n            data=dict(\n                username='test',\n                password='test'\n            ), follow_redirects=True\n        )\n        self.test.assertEqual(response.status_code, 200)\n        data = response.data.decode('utf-8')\n        self.assertBaseDateAndNumRuns(self.runs[1].execution_date, 2, data)\n        self.assertRunIsNotInDropdown(self.runs[0], data)\n        self.assertRunIsSelected(self.runs[1], data)\n        self.assertRunIsInDropdownNotSelected(self.runs[2], data)\n        self.assertRunIsNotInDropdown(self.runs[3], data)\n\n    def test_with_base_date_and_num_runs_and_execution_date_outside(self):\n        \"\"\"\n        Tests view with base_date and num_runs and execution-date URL parameters.\n        Scenario: change the base date and num runs and press \"Go\",\n        the selected execution date is outside the new range.\n        Should only show dag runs older than base_date in the drop down.\n        Should select the latest dag run within the range.\n        Should set base date and num runs to submitted values.\n        \"\"\"\n        response = self.test.client.get(\n            self.endpoint + '&base_date={}&num_runs=42&execution_date={}'.format(\n                self.runs[1].execution_date.isoformat(),\n                self.runs[0].execution_date.isoformat()),\n            data=dict(\n                username='test',\n                password='test'\n            ), follow_redirects=True\n        )\n        self.test.assertEqual(response.status_code, 200)\n        data = response.data.decode('utf-8')\n        self.assertBaseDateAndNumRuns(self.runs[1].execution_date, 42, data)\n        self.assertRunIsNotInDropdown(self.runs[0], data)\n        self.assertRunIsSelected(self.runs[1], data)\n        self.assertRunIsInDropdownNotSelected(self.runs[2], data)\n        self.assertRunIsInDropdownNotSelected(self.runs[3], data)\n\n    def test_with_base_date_and_num_runs_and_execution_date_within(self):\n        \"\"\"\n        Tests view with base_date and num_runs and execution-date URL parameters.\n        Scenario: change the base date and num runs and press \"Go\",\n        the selected execution date is within the new range.\n        Should only show dag runs older than base_date in the drop down.\n        Should select the dag run with the execution date.\n        Should set base date and num runs to submitted values.\n        \"\"\"\n        response = self.test.client.get(\n            self.endpoint + '&base_date={}&num_runs=5&execution_date={}'.format(\n                self.runs[2].execution_date.isoformat(),\n                self.runs[3].execution_date.isoformat()),\n            data=dict(\n                username='test',\n                password='test'\n            ), follow_redirects=True\n        )\n        self.test.assertEqual(response.status_code, 200)\n        data = response.data.decode('utf-8')\n        self.assertBaseDateAndNumRuns(self.runs[2].execution_date, 5, data)\n        self.assertRunIsNotInDropdown(self.runs[0], data)\n        self.assertRunIsNotInDropdown(self.runs[1], data)\n        self.assertRunIsInDropdownNotSelected(self.runs[2], data)\n        self.assertRunIsSelected(self.runs[3], data)\n\n\nclass TestGraphView(TestBase):\n    GRAPH_ENDPOINT = '/graph?dag_id={dag_id}'.format(\n        dag_id=ViewWithDateTimeAndNumRunsAndDagRunsFormTester.DAG_ID\n    )\n\n    @classmethod\n    def setUpClass(cls):\n        super().setUpClass()\n\n    def setUp(self):\n        super().setUp()\n        self.tester = ViewWithDateTimeAndNumRunsAndDagRunsFormTester(\n            self, self.GRAPH_ENDPOINT)\n        self.tester.setUp()\n\n    def tearDown(self):\n        self.tester.tearDown()\n        super().tearDown()\n\n    @classmethod\n    def tearDownClass(cls):\n        super().tearDownClass()\n\n    def test_dt_nr_dr_form_default_parameters(self):\n        self.tester.test_with_default_parameters()\n\n    def test_dt_nr_dr_form_with_execution_date_parameter_only(self):\n        self.tester.test_with_execution_date_parameter_only()\n\n    def test_dt_nr_dr_form_with_base_date_and_num_runs_parmeters_only(self):\n        self.tester.test_with_base_date_and_num_runs_parmeters_only()\n\n    def test_dt_nr_dr_form_with_base_date_and_num_runs_and_execution_date_outside(self):\n        self.tester.test_with_base_date_and_num_runs_and_execution_date_outside()\n\n    def test_dt_nr_dr_form_with_base_date_and_num_runs_and_execution_date_within(self):\n        self.tester.test_with_base_date_and_num_runs_and_execution_date_within()\n\n\nclass TestGanttView(TestBase):\n    GANTT_ENDPOINT = '/gantt?dag_id={dag_id}'.format(\n        dag_id=ViewWithDateTimeAndNumRunsAndDagRunsFormTester.DAG_ID\n    )\n\n    @classmethod\n    def setUpClass(cls):\n        super().setUpClass()\n\n    def setUp(self):\n        super().setUp()\n        self.tester = ViewWithDateTimeAndNumRunsAndDagRunsFormTester(\n            self, self.GANTT_ENDPOINT)\n        self.tester.setUp()\n\n    def tearDown(self):\n        self.tester.tearDown()\n        super().tearDown()\n\n    @classmethod\n    def tearDownClass(cls):\n        super().tearDownClass()\n\n    def test_dt_nr_dr_form_default_parameters(self):\n        self.tester.test_with_default_parameters()\n\n    def test_dt_nr_dr_form_with_execution_date_parameter_only(self):\n        self.tester.test_with_execution_date_parameter_only()\n\n    def test_dt_nr_dr_form_with_base_date_and_num_runs_parmeters_only(self):\n        self.tester.test_with_base_date_and_num_runs_parmeters_only()\n\n    def test_dt_nr_dr_form_with_base_date_and_num_runs_and_execution_date_outside(self):\n        self.tester.test_with_base_date_and_num_runs_and_execution_date_outside()\n\n    def test_dt_nr_dr_form_with_base_date_and_num_runs_and_execution_date_within(self):\n        self.tester.test_with_base_date_and_num_runs_and_execution_date_within()\n\n\nclass TestDagACLView(TestBase):\n    \"\"\"\n    Test Airflow DAG acl\n    \"\"\"\n    default_date = timezone.datetime(2018, 6, 1)\n    run_id = \"test_{}\".format(models.DagRun.id_for_date(default_date))\n\n    @classmethod\n    def setUpClass(cls):\n        super().setUpClass()\n        dagbag = models.DagBag(include_examples=True)\n        for dag in dagbag.dags.values():\n            dag.sync_to_db()\n\n    def cleanup_dagruns(self):\n        DR = models.DagRun\n        dag_ids = ['example_bash_operator',\n                   'example_subdag_operator']\n        (self.session\n             .query(DR)\n             .filter(DR.dag_id.in_(dag_ids))\n             .filter(DR.run_id == self.run_id)\n             .delete(synchronize_session='fetch'))\n        self.session.commit()\n\n    def prepare_dagruns(self):\n        dagbag = models.DagBag(include_examples=True)\n        self.bash_dag = dagbag.dags['example_bash_operator']\n        self.sub_dag = dagbag.dags['example_subdag_operator']\n\n        self.bash_dagrun = self.bash_dag.create_dagrun(\n            run_id=self.run_id,\n            execution_date=self.default_date,\n            start_date=timezone.utcnow(),\n            state=State.RUNNING)\n\n        self.sub_dagrun = self.sub_dag.create_dagrun(\n            run_id=self.run_id,\n            execution_date=self.default_date,\n            start_date=timezone.utcnow(),\n            state=State.RUNNING)\n\n    def setUp(self):\n        super().setUp()\n        self.cleanup_dagruns()\n        self.prepare_dagruns()\n        self.logout()\n        self.appbuilder.sm.sync_roles()\n        self.add_permission_for_role()\n\n    def login(self, username=None, password=None):\n        role_admin = self.appbuilder.sm.find_role('Admin')\n        tester = self.appbuilder.sm.find_user(username='test')\n        if not tester:\n            self.appbuilder.sm.add_user(\n                username='test',\n                first_name='test',\n                last_name='test',\n                email='test@fab.org',\n                role=role_admin,\n                password='test')\n\n        role_user = self.appbuilder.sm.find_role('User')\n        test_user = self.appbuilder.sm.find_user(username='test_user')\n        if not test_user:\n            self.appbuilder.sm.add_user(\n                username='test_user',\n                first_name='test_user',\n                last_name='test_user',\n                email='test_user@fab.org',\n                role=role_user,\n                password='test_user')\n\n        role_viewer = self.appbuilder.sm.find_role('Viewer')\n        test_viewer = self.appbuilder.sm.find_user(username='test_viewer')\n        if not test_viewer:\n            self.appbuilder.sm.add_user(\n                username='test_viewer',\n                first_name='test_viewer',\n                last_name='test_viewer',\n                email='test_viewer@fab.org',\n                role=role_viewer,\n                password='test_viewer')\n\n        dag_acl_role = self.appbuilder.sm.add_role('dag_acl_tester')\n        dag_tester = self.appbuilder.sm.find_user(username='dag_tester')\n        if not dag_tester:\n            self.appbuilder.sm.add_user(\n                username='dag_tester',\n                first_name='dag_test',\n                last_name='dag_test',\n                email='dag_test@fab.org',\n                role=dag_acl_role,\n                password='dag_test')\n\n        # create an user without permission\n        dag_no_role = self.appbuilder.sm.add_role('dag_acl_faker')\n        dag_faker = self.appbuilder.sm.find_user(username='dag_faker')\n        if not dag_faker:\n            self.appbuilder.sm.add_user(\n                username='dag_faker',\n                first_name='dag_faker',\n                last_name='dag_faker',\n                email='dag_fake@fab.org',\n                role=dag_no_role,\n                password='dag_faker')\n\n        # create an user with only read permission\n        dag_read_only_role = self.appbuilder.sm.add_role('dag_acl_read_only')\n        dag_read_only = self.appbuilder.sm.find_user(username='dag_read_only')\n        if not dag_read_only:\n            self.appbuilder.sm.add_user(\n                username='dag_read_only',\n                first_name='dag_read_only',\n                last_name='dag_read_only',\n                email='dag_read_only@fab.org',\n                role=dag_read_only_role,\n                password='dag_read_only')\n\n        # create an user that has all dag access\n        all_dag_role = self.appbuilder.sm.add_role('all_dag_role')\n        all_dag_tester = self.appbuilder.sm.find_user(username='all_dag_user')\n        if not all_dag_tester:\n            self.appbuilder.sm.add_user(\n                username='all_dag_user',\n                first_name='all_dag_user',\n                last_name='all_dag_user',\n                email='all_dag_user@fab.org',\n                role=all_dag_role,\n                password='all_dag_user')\n\n        user = username if username else 'dag_tester'\n        passwd = password if password else 'dag_test'\n\n        return self.client.post('/login/', data=dict(\n            username=user,\n            password=passwd\n        ))\n\n    def logout(self):\n        return self.client.get('/logout/')\n\n    def add_permission_for_role(self):\n        self.logout()\n        self.login(username='test',\n                   password='test')\n        perm_on_dag = self.appbuilder.sm.\\\n            find_permission_view_menu('can_dag_edit', 'example_bash_operator')\n        dag_tester_role = self.appbuilder.sm.find_role('dag_acl_tester')\n        self.appbuilder.sm.add_permission_role(dag_tester_role, perm_on_dag)\n\n        perm_on_all_dag = self.appbuilder.sm.\\\n            find_permission_view_menu('can_dag_edit', 'all_dags')\n        all_dag_role = self.appbuilder.sm.find_role('all_dag_role')\n        self.appbuilder.sm.add_permission_role(all_dag_role, perm_on_all_dag)\n\n        role_user = self.appbuilder.sm.find_role('User')\n        self.appbuilder.sm.add_permission_role(role_user, perm_on_all_dag)\n\n        read_only_perm_on_dag = self.appbuilder.sm.\\\n            find_permission_view_menu('can_dag_read', 'example_bash_operator')\n        dag_read_only_role = self.appbuilder.sm.find_role('dag_acl_read_only')\n        self.appbuilder.sm.add_permission_role(dag_read_only_role, read_only_perm_on_dag)\n\n    def test_permission_exist(self):\n        self.logout()\n        self.login(username='test',\n                   password='test')\n        test_view_menu = self.appbuilder.sm.find_view_menu('example_bash_operator')\n        perms_views = self.appbuilder.sm.find_permissions_view_menu(test_view_menu)\n        self.assertEqual(len(perms_views), 2)\n        # each dag view will create one write, and one read permission\n        self.assertTrue(str(perms_views[0]).startswith('can dag'))\n        self.assertTrue(str(perms_views[1]).startswith('can dag'))\n\n    def test_role_permission_associate(self):\n        self.logout()\n        self.login(username='test',\n                   password='test')\n        test_role = self.appbuilder.sm.find_role('dag_acl_tester')\n        perms = {str(perm) for perm in test_role.permissions}\n        self.assertIn('can dag edit on example_bash_operator', perms)\n        self.assertNotIn('can dag read on example_bash_operator', perms)\n\n    def test_index_success(self):\n        self.logout()\n        self.login()\n        resp = self.client.get('/', follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n\n    def test_index_failure(self):\n        self.logout()\n        self.login()\n        resp = self.client.get('/', follow_redirects=True)\n        # The user can only access/view example_bash_operator dag.\n        self.check_content_not_in_response('example_subdag_operator', resp)\n\n    def test_index_for_all_dag_user(self):\n        self.logout()\n        self.login(username='all_dag_user',\n                   password='all_dag_user')\n        resp = self.client.get('/', follow_redirects=True)\n        # The all dag user can access/view all dags.\n        self.check_content_in_response('example_subdag_operator', resp)\n        self.check_content_in_response('example_bash_operator', resp)\n\n    def test_dag_stats_success(self):\n        self.logout()\n        self.login()\n        resp = self.client.get('dag_stats', follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n\n    def test_dag_stats_failure(self):\n        self.logout()\n        self.login()\n        resp = self.client.get('dag_stats', follow_redirects=True)\n        self.check_content_not_in_response('example_subdag_operator', resp)\n\n    def test_dag_stats_success_for_all_dag_user(self):\n        self.logout()\n        self.login(username='all_dag_user',\n                   password='all_dag_user')\n        resp = self.client.get('dag_stats', follow_redirects=True)\n        self.check_content_in_response('example_subdag_operator', resp)\n        self.check_content_in_response('example_bash_operator', resp)\n\n    def test_task_stats_success(self):\n        self.logout()\n        self.login()\n        resp = self.client.get('task_stats', follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n\n    def test_task_stats_failure(self):\n        self.logout()\n        self.login()\n        resp = self.client.get('task_stats', follow_redirects=True)\n        self.check_content_not_in_response('example_subdag_operator', resp)\n\n    def test_task_stats_success_for_all_dag_user(self):\n        self.logout()\n        self.login(username='all_dag_user',\n                   password='all_dag_user')\n        resp = self.client.get('task_stats', follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n        self.check_content_in_response('example_subdag_operator', resp)\n\n    def test_code_success(self):\n        self.logout()\n        self.login()\n        url = 'code?dag_id=example_bash_operator'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n\n    def test_code_failure(self):\n        self.logout()\n        self.login(username='dag_faker',\n                   password='dag_faker')\n        url = 'code?dag_id=example_bash_operator'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_not_in_response('example_bash_operator', resp)\n\n    def test_code_success_for_all_dag_user(self):\n        self.logout()\n        self.login(username='all_dag_user',\n                   password='all_dag_user')\n        url = 'code?dag_id=example_bash_operator'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n\n        url = 'code?dag_id=example_subdag_operator'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('example_subdag_operator', resp)\n\n    def test_dag_details_success(self):\n        self.logout()\n        self.login()\n        url = 'dag_details?dag_id=example_bash_operator'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('DAG details', resp)\n\n    def test_dag_details_failure(self):\n        self.logout()\n        self.login(username='dag_faker',\n                   password='dag_faker')\n        url = 'dag_details?dag_id=example_bash_operator'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_not_in_response('DAG details', resp)\n\n    def test_dag_details_success_for_all_dag_user(self):\n        self.logout()\n        self.login(username='all_dag_user',\n                   password='all_dag_user')\n        url = 'dag_details?dag_id=example_bash_operator'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n\n        url = 'dag_details?dag_id=example_subdag_operator'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('example_subdag_operator', resp)\n\n    def test_rendered_success(self):\n        self.logout()\n        self.login()\n        url = ('rendered?task_id=runme_0&dag_id=example_bash_operator&execution_date={}'\n               .format(self.percent_encode(self.default_date)))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('Rendered Template', resp)\n\n    def test_rendered_failure(self):\n        self.logout()\n        self.login(username='dag_faker',\n                   password='dag_faker')\n        url = ('rendered?task_id=runme_0&dag_id=example_bash_operator&execution_date={}'\n               .format(self.percent_encode(self.default_date)))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_not_in_response('Rendered Template', resp)\n\n    def test_rendered_success_for_all_dag_user(self):\n        self.logout()\n        self.login(username='all_dag_user',\n                   password='all_dag_user')\n        url = ('rendered?task_id=runme_0&dag_id=example_bash_operator&execution_date={}'\n               .format(self.percent_encode(self.default_date)))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('Rendered Template', resp)\n\n    def test_task_success(self):\n        self.logout()\n        self.login()\n        url = ('task?task_id=runme_0&dag_id=example_bash_operator&execution_date={}'\n               .format(self.percent_encode(self.default_date)))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('Task Instance Details', resp)\n\n    def test_task_failure(self):\n        self.logout()\n        self.login(username='dag_faker',\n                   password='dag_faker')\n        url = ('task?task_id=runme_0&dag_id=example_bash_operator&execution_date={}'\n               .format(self.percent_encode(self.default_date)))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_not_in_response('Task Instance Details', resp)\n\n    def test_task_success_for_all_dag_user(self):\n        self.logout()\n        self.login(username='all_dag_user',\n                   password='all_dag_user')\n        url = ('task?task_id=runme_0&dag_id=example_bash_operator&execution_date={}'\n               .format(self.percent_encode(self.default_date)))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('Task Instance Details', resp)\n\n    def test_xcom_success(self):\n        self.logout()\n        self.login()\n        url = ('xcom?task_id=runme_0&dag_id=example_bash_operator&execution_date={}'\n               .format(self.percent_encode(self.default_date)))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('XCom', resp)\n\n    def test_xcom_failure(self):\n        self.logout()\n        self.login(username='dag_faker',\n                   password='dag_faker')\n        url = ('xcom?task_id=runme_0&dag_id=example_bash_operator&execution_date={}'\n               .format(self.percent_encode(self.default_date)))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_not_in_response('XCom', resp)\n\n    def test_xcom_success_for_all_dag_user(self):\n        self.logout()\n        self.login(username='all_dag_user',\n                   password='all_dag_user')\n        url = ('xcom?task_id=runme_0&dag_id=example_bash_operator&execution_date={}'\n               .format(self.percent_encode(self.default_date)))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('XCom', resp)\n\n    def test_run_success(self):\n        self.logout()\n        self.login()\n        form = dict(\n            task_id=\"runme_0\",\n            dag_id=\"example_bash_operator\",\n            ignore_all_deps=\"false\",\n            ignore_ti_state=\"true\",\n            execution_date=self.default_date,\n        )\n        resp = self.client.post('run', data=form)\n        self.check_content_in_response('', resp, resp_code=302)\n\n    def test_run_success_for_all_dag_user(self):\n        self.logout()\n        self.login(username='all_dag_user',\n                   password='all_dag_user')\n        form = dict(\n            task_id=\"runme_0\",\n            dag_id=\"example_bash_operator\",\n            ignore_all_deps=\"false\",\n            ignore_ti_state=\"true\",\n            execution_date=self.default_date\n        )\n        resp = self.client.post('run', data=form)\n        self.check_content_in_response('', resp, resp_code=302)\n\n    def test_blocked_success(self):\n        url = 'blocked'\n        self.logout()\n        self.login()\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n\n    def test_blocked_success_for_all_dag_user(self):\n        url = 'blocked'\n        self.logout()\n        self.login(username='all_dag_user',\n                   password='all_dag_user')\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n        self.check_content_in_response('example_subdag_operator', resp)\n\n    def test_failed_success(self):\n        self.logout()\n        self.login()\n        form = dict(\n            task_id=\"run_this_last\",\n            dag_id=\"example_bash_operator\",\n            execution_date=self.default_date,\n            upstream=\"false\",\n            downstream=\"false\",\n            future=\"false\",\n            past=\"false\",\n        )\n        resp = self.client.post('failed', data=form)\n        self.check_content_in_response('Redirecting', resp, 302)\n\n    def test_duration_success(self):\n        url = 'duration?days=30&dag_id=example_bash_operator'\n        self.logout()\n        self.login()\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n\n    def test_duration_failure(self):\n        url = 'duration?days=30&dag_id=example_bash_operator'\n        self.logout()\n        # login as an user without permissions\n        self.login(username='dag_faker',\n                   password='dag_faker')\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_not_in_response('example_bash_operator', resp)\n\n    def test_tries_success(self):\n        url = 'tries?days=30&dag_id=example_bash_operator'\n        self.logout()\n        self.login()\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n\n    def test_tries_failure(self):\n        url = 'tries?days=30&dag_id=example_bash_operator'\n        self.logout()\n        # login as an user without permissions\n        self.login(username='dag_faker',\n                   password='dag_faker')\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_not_in_response('example_bash_operator', resp)\n\n    def test_landing_times_success(self):\n        url = 'landing_times?days=30&dag_id=example_bash_operator'\n        self.logout()\n        self.login()\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n\n    def test_landing_times_failure(self):\n        url = 'landing_times?days=30&dag_id=example_bash_operator'\n        self.logout()\n        self.login(username='dag_faker',\n                   password='dag_faker')\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_not_in_response('example_bash_operator', resp)\n\n    def test_paused_success(self):\n        # post request failure won't test\n        url = 'paused?dag_id=example_bash_operator&is_paused=false'\n        self.logout()\n        self.login()\n        resp = self.client.post(url, follow_redirects=True)\n        self.check_content_in_response('OK', resp)\n\n    def test_refresh_success(self):\n        self.logout()\n        self.login()\n        resp = self.client.post('refresh?dag_id=example_bash_operator')\n        self.check_content_in_response('', resp, resp_code=302)\n\n    def test_gantt_success(self):\n        url = 'gantt?dag_id=example_bash_operator'\n        self.logout()\n        self.login()\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n\n    def test_gantt_failure(self):\n        url = 'gantt?dag_id=example_bash_operator'\n        self.logout()\n        self.login(username='dag_faker',\n                   password='dag_faker')\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_not_in_response('example_bash_operator', resp)\n\n    def test_success_fail_for_read_only_role(self):\n        # succcess endpoint need can_dag_edit, which read only role can not access\n        self.logout()\n        self.login(username='dag_read_only',\n                   password='dag_read_only')\n\n        form = dict(\n            task_id=\"run_this_last\",\n            dag_id=\"example_bash_operator\",\n            execution_date=self.default_date,\n            upstream=\"false\",\n            downstream=\"false\",\n            future=\"false\",\n            past=\"false\",\n        )\n        resp = self.client.post('success', data=form)\n        self.check_content_not_in_response('Wait a minute', resp, resp_code=302)\n\n    def test_tree_success_for_read_only_role(self):\n        # tree view only allows can_dag_read, which read only role could access\n        self.logout()\n        self.login(username='dag_read_only',\n                   password='dag_read_only')\n\n        url = 'tree?dag_id=example_bash_operator'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('runme_1', resp)\n\n    def test_log_success(self):\n        self.logout()\n        self.login()\n        url = ('log?task_id=runme_0&dag_id=example_bash_operator&execution_date={}'\n               .format(self.percent_encode(self.default_date)))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('Log by attempts', resp)\n        url = ('get_logs_with_metadata?task_id=runme_0&dag_id=example_bash_operator&'\n               'execution_date={}&try_number=1&metadata=null'\n               .format(self.percent_encode(self.default_date)))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('\"message\":', resp)\n        self.check_content_in_response('\"metadata\":', resp)\n\n    def test_log_failure(self):\n        self.logout()\n        self.login(username='dag_faker',\n                   password='dag_faker')\n        url = ('log?task_id=runme_0&dag_id=example_bash_operator&execution_date={}'\n               .format(self.percent_encode(self.default_date)))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_not_in_response('Log by attempts', resp)\n        url = ('get_logs_with_metadata?task_id=runme_0&dag_id=example_bash_operator&'\n               'execution_date={}&try_number=1&metadata=null'\n               .format(self.percent_encode(self.default_date)))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_not_in_response('\"message\":', resp)\n        self.check_content_not_in_response('\"metadata\":', resp)\n\n    def test_log_success_for_user(self):\n        self.logout()\n        self.login(username='test_user',\n                   password='test_user')\n        url = ('log?task_id=runme_0&dag_id=example_bash_operator&execution_date={}'\n               .format(self.percent_encode(self.default_date)))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('Log by attempts', resp)\n        url = ('get_logs_with_metadata?task_id=runme_0&dag_id=example_bash_operator&'\n               'execution_date={}&try_number=1&metadata=null'\n               .format(self.percent_encode(self.default_date)))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('\"message\":', resp)\n        self.check_content_in_response('\"metadata\":', resp)\n\n    def test_tree_view_for_viewer(self):\n        self.logout()\n        self.login(username='test_viewer',\n                   password='test_viewer')\n        url = 'tree?dag_id=example_bash_operator'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('runme_1', resp)\n\n    def test_refresh_failure_for_viewer(self):\n        # viewer role can't refresh\n        self.logout()\n        self.login(username='test_viewer',\n                   password='test_viewer')\n        resp = self.client.post('refresh?dag_id=example_bash_operator')\n        self.check_content_in_response('Redirecting', resp, resp_code=302)\n\n\nclass TestTaskInstanceView(TestBase):\n    TI_ENDPOINT = '/taskinstance/list/?_flt_0_execution_date={}'\n\n    def test_start_date_filter(self):\n        resp = self.client.get(self.TI_ENDPOINT.format(\n            self.percent_encode('2018-10-09 22:44:31')))\n        # We aren't checking the logic of the date filter itself (that is built\n        # in to FAB) but simply that our UTC conversion was run - i.e. it\n        # doesn't blow up!\n        self.check_content_in_response('List Task Instance', resp)\n\n\nclass TestTriggerDag(TestBase):\n\n    def setUp(self):\n        super().setUp()\n        self.session = Session()\n        models.DagBag().get_dag(\"example_bash_operator\").sync_to_db(session=self.session)\n\n    def test_trigger_dag_button_normal_exist(self):\n        resp = self.client.get('/', follow_redirects=True)\n        self.assertIn('/trigger?dag_id=example_bash_operator', resp.data.decode('utf-8'))\n        self.assertIn(\"return confirmDeleteDag(this, 'example_bash_operator')\", resp.data.decode('utf-8'))\n\n    @unittest.skipIf('mysql' in conf.get('core', 'sql_alchemy_conn'),\n                     \"flaky when run on mysql\")\n    def test_trigger_dag_button(self):\n\n        test_dag_id = \"example_bash_operator\"\n\n        DR = models.DagRun\n        self.session.query(DR).delete()\n        self.session.commit()\n\n        self.client.post('trigger?dag_id={}'.format(test_dag_id))\n\n        run = self.session.query(DR).filter(DR.dag_id == test_dag_id).first()\n        self.assertIsNotNone(run)\n        self.assertIn(\"manual__\", run.run_id)\n\n\nclass TestExtraLinks(TestBase):\n    def setUp(self):\n        super().setUp()\n        self.ENDPOINT = \"extra_links\"\n        self.DEFAULT_DATE = datetime(2017, 1, 1)\n\n        class RaiseErrorLink(BaseOperatorLink):\n            name = 'raise_error'\n\n            def get_link(self, operator, dttm):\n                raise ValueError('This is an error')\n\n        class NoResponseLink(BaseOperatorLink):\n            name = 'no_response'\n\n            def get_link(self, operator, dttm):\n                return None\n\n        class FooBarLink(BaseOperatorLink):\n            name = 'foo-bar'\n\n            def get_link(self, operator, dttm):\n                return 'http://www.example.com/{0}/{1}/{2}'.format(\n                    operator.task_id, 'foo-bar', dttm)\n\n        class AirflowLink(BaseOperatorLink):\n            name = 'airflow'\n\n            def get_link(self, operator, dttm):\n                return 'https://airflow.apache.org'\n\n        class DummyTestOperator(BaseOperator):\n\n            operator_extra_links = (\n                RaiseErrorLink(),\n                NoResponseLink(),\n                FooBarLink(),\n                AirflowLink(),\n            )\n\n        self.dag = DAG('dag', start_date=self.DEFAULT_DATE)\n        self.task = DummyTestOperator(task_id=\"some_dummy_task\", dag=self.dag)\n\n    def tearDown(self):\n        super().tearDown()\n\n    @mock.patch('airflow.www.views.dagbag.get_dag')\n    def test_extra_links_works(self, get_dag_function):\n        get_dag_function.return_value = self.dag\n\n        response = self.client.get(\n            \"{0}?dag_id={1}&task_id={2}&execution_date={3}&link_name=foo-bar\"\n            .format(self.ENDPOINT, self.dag.dag_id, self.task.task_id, self.DEFAULT_DATE),\n            follow_redirects=True)\n\n        self.assertEqual(response.status_code, 200)\n        response_str = response.data\n        if isinstance(response.data, bytes):\n            response_str = response_str.decode()\n        self.assertEqual(json.loads(response_str), {\n            'url': ('http://www.example.com/some_dummy_task/'\n                    'foo-bar/2017-01-01T00:00:00+00:00'),\n            'error': None\n        })\n\n    @mock.patch('airflow.www.views.dagbag.get_dag')\n    def test_global_extra_links_works(self, get_dag_function):\n        get_dag_function.return_value = self.dag\n\n        response = self.client.get(\n            \"{0}?dag_id={1}&task_id={2}&execution_date={3}&link_name=github\"\n            .format(self.ENDPOINT, self.dag.dag_id, self.task.task_id, self.DEFAULT_DATE),\n            follow_redirects=True)\n\n        self.assertEqual(response.status_code, 200)\n        response_str = response.data\n        if isinstance(response.data, bytes):\n            response_str = response_str.decode()\n        self.assertEqual(json.loads(response_str), {\n            'url': 'https://github.com/apache/airflow',\n            'error': None\n        })\n\n    @mock.patch('airflow.www.views.dagbag.get_dag')\n    def test_operator_extra_link_override_global_extra_link(self, get_dag_function):\n        get_dag_function.return_value = self.dag\n\n        response = self.client.get(\n            \"{0}?dag_id={1}&task_id={2}&execution_date={3}&link_name=airflow\".format(\n                self.ENDPOINT, self.dag.dag_id, self.task.task_id, self.DEFAULT_DATE),\n            follow_redirects=True)\n\n        self.assertEqual(response.status_code, 200)\n        response_str = response.data\n        if isinstance(response.data, bytes):\n            response_str = response_str.decode()\n        self.assertEqual(json.loads(response_str), {\n            'url': 'https://airflow.apache.org',\n            'error': None\n        })\n\n    @mock.patch('airflow.www.views.dagbag.get_dag')\n    def test_extra_links_error_raised(self, get_dag_function):\n        get_dag_function.return_value = self.dag\n\n        response = self.client.get(\n            \"{0}?dag_id={1}&task_id={2}&execution_date={3}&link_name=raise_error\"\n            .format(self.ENDPOINT, self.dag.dag_id, self.task.task_id, self.DEFAULT_DATE),\n            follow_redirects=True)\n\n        self.assertEqual(404, response.status_code)\n        response_str = response.data\n        if isinstance(response.data, bytes):\n            response_str = response_str.decode()\n        self.assertEqual(json.loads(response_str), {\n            'url': None,\n            'error': 'This is an error'})\n\n    @mock.patch('airflow.www.views.dagbag.get_dag')\n    def test_extra_links_no_response(self, get_dag_function):\n        get_dag_function.return_value = self.dag\n\n        response = self.client.get(\n            \"{0}?dag_id={1}&task_id={2}&execution_date={3}&link_name=no_response\"\n            .format(self.ENDPOINT, self.dag.dag_id, self.task.task_id, self.DEFAULT_DATE),\n            follow_redirects=True)\n\n        self.assertEqual(response.status_code, 404)\n        response_str = response.data\n        if isinstance(response.data, bytes):\n            response_str = response_str.decode()\n        self.assertEqual(json.loads(response_str), {\n            'url': None,\n            'error': 'No URL found for no_response'})\n\n\nclass TestDagRunModelView(TestBase):\n    @classmethod\n    def setUpClass(cls):\n        super().setUpClass()\n        models.DagBag().get_dag(\"example_bash_operator\").sync_to_db(session=cls.session)\n        cls.clear_table(models.DagRun)\n\n    def tearDown(self):\n        self.clear_table(models.DagRun)\n\n    def test_create_dagrun(self):\n        data = {\n            \"state\": \"running\",\n            \"dag_id\": \"example_bash_operator\",\n            \"execution_date\": \"2018-07-06 05:04:03\",\n            \"run_id\": \"manual_abc\",\n        }\n        resp = self.client.post('/dagrun/add',\n                                data=data,\n                                follow_redirects=True)\n        self.check_content_in_response('Added Row', resp)\n\n        dr = self.session.query(models.DagRun).one()\n\n        self.assertEqual(dr.execution_date, timezone.convert_to_utc(datetime(2018, 7, 6, 5, 4, 3)))\n\n\nclass TestDecorators(TestBase):\n    EXAMPLE_DAG_DEFAULT_DATE = dates.days_ago(2)\n    run_id = \"test_{}\".format(models.DagRun.id_for_date(EXAMPLE_DAG_DEFAULT_DATE))\n\n    @classmethod\n    def setUpClass(cls):\n        super().setUpClass()\n        dagbag = models.DagBag(include_examples=True)\n        for dag in dagbag.dags.values():\n            dag.sync_to_db()\n\n    def setUp(self):\n        super().setUp()\n        self.logout()\n        self.login()\n        self.cleanup_dagruns()\n        self.prepare_dagruns()\n\n    def cleanup_dagruns(self):\n        DR = models.DagRun\n        dag_ids = ['example_bash_operator',\n                   'example_subdag_operator',\n                   'example_xcom']\n        (self.session\n             .query(DR)\n             .filter(DR.dag_id.in_(dag_ids))\n             .filter(DR.run_id == self.run_id)\n             .delete(synchronize_session='fetch'))\n        self.session.commit()\n\n    def prepare_dagruns(self):\n        dagbag = models.DagBag(include_examples=True)\n        self.bash_dag = dagbag.dags['example_bash_operator']\n        self.sub_dag = dagbag.dags['example_subdag_operator']\n        self.xcom_dag = dagbag.dags['example_xcom']\n\n        self.bash_dagrun = self.bash_dag.create_dagrun(\n            run_id=self.run_id,\n            execution_date=self.EXAMPLE_DAG_DEFAULT_DATE,\n            start_date=timezone.utcnow(),\n            state=State.RUNNING)\n\n        self.sub_dagrun = self.sub_dag.create_dagrun(\n            run_id=self.run_id,\n            execution_date=self.EXAMPLE_DAG_DEFAULT_DATE,\n            start_date=timezone.utcnow(),\n            state=State.RUNNING)\n\n        self.xcom_dagrun = self.xcom_dag.create_dagrun(\n            run_id=self.run_id,\n            execution_date=self.EXAMPLE_DAG_DEFAULT_DATE,\n            start_date=timezone.utcnow(),\n            state=State.RUNNING)\n\n    def check_last_log(self, dag_id, event, execution_date=None):\n        from airflow.models import Log\n        qry = self.session.query(Log.dag_id, Log.task_id, Log.event, Log.execution_date,\n                                 Log.owner, Log.extra)\n        qry = qry.filter(Log.dag_id == dag_id, Log.event == event)\n        if execution_date:\n            qry = qry.filter(Log.execution_date == execution_date)\n        logs = qry.order_by(Log.dttm.desc()).limit(5).all()\n        self.assertGreaterEqual(len(logs), 1)\n        self.assertTrue(logs[0].extra)\n\n    def test_action_logging_get(self):\n        url = 'graph?dag_id=example_bash_operator&execution_date={}'.format(\n            self.percent_encode(self.EXAMPLE_DAG_DEFAULT_DATE))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('runme_1', resp)\n\n        # In mysql backend, this commit() is needed to write down the logs\n        self.session.commit()\n        self.check_last_log(\"example_bash_operator\", event=\"graph\",\n                            execution_date=self.EXAMPLE_DAG_DEFAULT_DATE)\n\n    def test_action_logging_post(self):\n        form = dict(\n            task_id=\"runme_1\",\n            dag_id=\"example_bash_operator\",\n            execution_date=self.EXAMPLE_DAG_DEFAULT_DATE,\n            upstream=\"false\",\n            downstream=\"false\",\n            future=\"false\",\n            past=\"false\",\n            only_failed=\"false\",\n        )\n        resp = self.client.post(\"clear\", data=form)\n        self.check_content_in_response(['example_bash_operator', 'Wait a minute'], resp)\n        # In mysql backend, this commit() is needed to write down the logs\n        self.session.commit()\n        self.check_last_log(\"example_bash_operator\", event=\"clear\",\n                            execution_date=self.EXAMPLE_DAG_DEFAULT_DATE)\n\n\nif __name__ == '__main__':\n    unittest.main()\n", "code_before": "# -*- coding: utf-8 -*-\n#\n# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \"License\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n\nimport copy\nimport io\nimport json\nimport logging.config\nimport os\nimport shutil\nimport sys\nimport tempfile\nimport unittest\nimport urllib\nfrom datetime import timedelta\nfrom unittest import mock\nfrom urllib.parse import quote_plus\n\nimport jinja2\nfrom flask import Markup, url_for\nfrom parameterized import parameterized\nfrom werkzeug.test import Client\nfrom werkzeug.wrappers import BaseResponse\n\nfrom airflow import models, settings\nfrom airflow.config_templates.airflow_local_settings import DEFAULT_LOGGING_CONFIG\nfrom airflow.configuration import conf\nfrom airflow.jobs import BaseJob\nfrom airflow.models import DAG, BaseOperator, Connection, DagRun, TaskInstance\nfrom airflow.models.baseoperator import BaseOperatorLink\nfrom airflow.operators.dummy_operator import DummyOperator\nfrom airflow.settings import Session\nfrom airflow.utils import dates, timezone\nfrom airflow.utils.db import create_session\nfrom airflow.utils.state import State\nfrom airflow.utils.timezone import datetime\nfrom airflow.www import app as application\nfrom tests.test_utils.config import conf_vars\n\n\nclass TestBase(unittest.TestCase):\n    @classmethod\n    def setUpClass(cls):\n        cls.app, cls.appbuilder = application.create_app(session=Session, testing=True)\n        cls.app.config['WTF_CSRF_ENABLED'] = False\n        cls.app.jinja_env.undefined = jinja2.StrictUndefined\n        settings.configure_orm()\n        cls.session = Session\n\n    def setUp(self):\n        self.client = self.app.test_client()\n        self.login()\n\n    def login(self):\n        role_admin = self.appbuilder.sm.find_role('Admin')\n        tester = self.appbuilder.sm.find_user(username='test')\n        if not tester:\n            self.appbuilder.sm.add_user(\n                username='test',\n                first_name='test',\n                last_name='test',\n                email='test@fab.org',\n                role=role_admin,\n                password='test')\n        return self.client.post('/login/', data=dict(\n            username='test',\n            password='test'\n        ), follow_redirects=True)\n\n    def logout(self):\n        return self.client.get('/logout/')\n\n    @classmethod\n    def clear_table(cls, model):\n        with create_session() as session:\n            session.query(model).delete()\n\n    def check_content_in_response(self, text, resp, resp_code=200):\n        resp_html = resp.data.decode('utf-8')\n        self.assertEqual(resp_code, resp.status_code)\n        if isinstance(text, list):\n            for kw in text:\n                self.assertIn(kw, resp_html)\n        else:\n            self.assertIn(text, resp_html)\n\n    def check_content_not_in_response(self, text, resp, resp_code=200):\n        resp_html = resp.data.decode('utf-8')\n        self.assertEqual(resp_code, resp.status_code)\n        if isinstance(text, list):\n            for kw in text:\n                self.assertNotIn(kw, resp_html)\n        else:\n            self.assertNotIn(text, resp_html)\n\n    def percent_encode(self, obj):\n        return urllib.parse.quote_plus(str(obj))\n\n\nclass TestConnectionModelView(TestBase):\n    def setUp(self):\n        super().setUp()\n        self.connection = {\n            'conn_id': 'test_conn',\n            'conn_type': 'http',\n            'host': 'localhost',\n            'port': 8080,\n            'username': 'root',\n            'password': 'admin'\n        }\n\n    def tearDown(self):\n        self.clear_table(Connection)\n        super().tearDown()\n\n    def test_create_connection(self):\n        resp = self.client.post('/connection/add',\n                                data=self.connection,\n                                follow_redirects=True)\n        self.check_content_in_response('Added Row', resp)\n\n\nclass TestVariableModelView(TestBase):\n    def setUp(self):\n        super().setUp()\n        self.variable = {\n            'key': 'test_key',\n            'val': 'text_val',\n            'is_encrypted': True\n        }\n\n    def tearDown(self):\n        self.clear_table(models.Variable)\n        super().tearDown()\n\n    def test_can_handle_error_on_decrypt(self):\n\n        # create valid variable\n        resp = self.client.post('/variable/add',\n                                data=self.variable,\n                                follow_redirects=True)\n\n        # update the variable with a wrong value, given that is encrypted\n        Var = models.Variable\n        (self.session.query(Var)\n            .filter(Var.key == self.variable['key'])\n            .update({\n                'val': 'failed_value_not_encrypted'\n            }, synchronize_session=False))\n        self.session.commit()\n\n        # retrieve Variables page, should not fail and contain the Invalid\n        # label for the variable\n        resp = self.client.get('/variable/list', follow_redirects=True)\n        self.check_content_in_response(\n            '<span class=\"label label-danger\">Invalid</span>', resp)\n\n    def test_xss_prevention(self):\n        xss = \"/variable/list/<img%20src=''%20onerror='alert(1);'>\"\n\n        resp = self.client.get(\n            xss,\n            follow_redirects=True,\n        )\n        self.assertEqual(resp.status_code, 404)\n        self.assertNotIn(\"<img src='' onerror='alert(1);'>\",\n                         resp.data.decode(\"utf-8\"))\n\n    def test_import_variables_no_file(self):\n        resp = self.client.post('/variable/varimport',\n                                follow_redirects=True)\n        self.check_content_in_response('Missing file or syntax error.', resp)\n\n    def test_import_variables_failed(self):\n        content = '{\"str_key\": \"str_value\"}'\n\n        with mock.patch('airflow.models.Variable.set') as set_mock:\n            set_mock.side_effect = UnicodeEncodeError\n            self.assertEqual(self.session.query(models.Variable).count(), 0)\n\n            try:\n                # python 3+\n                bytes_content = io.BytesIO(bytes(content, encoding='utf-8'))\n            except TypeError:\n                # python 2.7\n                bytes_content = io.BytesIO(bytes(content))\n\n            resp = self.client.post('/variable/varimport',\n                                    data={'file': (bytes_content, 'test.json')},\n                                    follow_redirects=True)\n            self.check_content_in_response('1 variable(s) failed to be updated.', resp)\n\n    def test_import_variables_success(self):\n        self.assertEqual(self.session.query(models.Variable).count(), 0)\n\n        content = ('{\"str_key\": \"str_value\", \"int_key\": 60,'\n                   '\"list_key\": [1, 2], \"dict_key\": {\"k_a\": 2, \"k_b\": 3}}')\n        try:\n            # python 3+\n            bytes_content = io.BytesIO(bytes(content, encoding='utf-8'))\n        except TypeError:\n            # python 2.7\n            bytes_content = io.BytesIO(bytes(content))\n\n        resp = self.client.post('/variable/varimport',\n                                data={'file': (bytes_content, 'test.json')},\n                                follow_redirects=True)\n        self.check_content_in_response('4 variable(s) successfully updated.', resp)\n\n\nclass TestPoolModelView(TestBase):\n    def setUp(self):\n        super().setUp()\n        self.pool = {\n            'pool': 'test-pool',\n            'slots': 777,\n            'description': 'test-pool-description',\n        }\n\n    def tearDown(self):\n        self.clear_table(models.Pool)\n        super().tearDown()\n\n    def test_create_pool_with_same_name(self):\n        # create test pool\n        resp = self.client.post('/pool/add',\n                                data=self.pool,\n                                follow_redirects=True)\n        self.check_content_in_response('Added Row', resp)\n\n        # create pool with the same name\n        resp = self.client.post('/pool/add',\n                                data=self.pool,\n                                follow_redirects=True)\n        self.check_content_in_response('Already exists.', resp)\n\n    def test_create_pool_with_empty_name(self):\n\n        self.pool['pool'] = ''\n        resp = self.client.post('/pool/add',\n                                data=self.pool,\n                                follow_redirects=True)\n        self.check_content_in_response('This field is required.', resp)\n\n    def test_odd_name(self):\n        self.pool['pool'] = 'test-pool<script></script>'\n        self.session.add(models.Pool(**self.pool))\n        self.session.commit()\n        resp = self.client.get('/pool/list/')\n        self.check_content_in_response('test-pool&lt;script&gt;', resp)\n        self.check_content_not_in_response('test-pool<script>', resp)\n\n    def test_list(self):\n        self.pool['pool'] = 'test-pool'\n        self.session.add(models.Pool(**self.pool))\n        self.session.commit()\n        resp = self.client.get('/pool/list/')\n        # We should see this link\n        with self.app.test_request_context():\n            url = url_for('TaskInstanceModelView.list', _flt_3_pool='test-pool', _flt_3_state='running')\n            used_tag = Markup(\"<a href='{url}'>{slots}</a>\").format(url=url, slots=0)\n\n            url = url_for('TaskInstanceModelView.list', _flt_3_pool='test-pool', _flt_3_state='queued')\n            queued_tag = Markup(\"<a href='{url}'>{slots}</a>\").format(url=url, slots=0)\n        self.check_content_in_response(used_tag, resp)\n        self.check_content_in_response(queued_tag, resp)\n\n\nclass TestMountPoint(unittest.TestCase):\n    @classmethod\n    def setUpClass(cls):\n        application.app = None\n        application.appbuilder = None\n        conf.set(\"webserver\", \"base_url\", \"http://localhost/test\")\n        app = application.cached_app(config={'WTF_CSRF_ENABLED': False}, session=Session, testing=True)\n        cls.client = Client(app, BaseResponse)\n\n    @classmethod\n    def tearDownClass(cls):\n        application.app = None\n        application.appbuilder = None\n\n    def test_mount(self):\n        # Test an endpoint that doesn't need auth!\n        resp = self.client.get('/test/health')\n        self.assertEqual(resp.status_code, 200)\n        self.assertIn(b\"healthy\", resp.data)\n\n    def test_not_found(self):\n        resp = self.client.get('/', follow_redirects=True)\n        self.assertEqual(resp.status_code, 404)\n\n    def test_index(self):\n        resp = self.client.get('/test/')\n        self.assertEqual(resp.status_code, 302)\n        self.assertEqual(resp.headers['Location'], 'http://localhost/test/home')\n\n\nclass TestAirflowBaseViews(TestBase):\n    EXAMPLE_DAG_DEFAULT_DATE = dates.days_ago(2)\n    run_id = \"test_{}\".format(models.DagRun.id_for_date(EXAMPLE_DAG_DEFAULT_DATE))\n\n    @classmethod\n    def setUpClass(cls):\n        super().setUpClass()\n        dagbag = models.DagBag(include_examples=True)\n        for dag in dagbag.dags.values():\n            dag.sync_to_db()\n\n    def setUp(self):\n        super().setUp()\n        self.logout()\n        self.login()\n        self.cleanup_dagruns()\n        self.prepare_dagruns()\n\n    def cleanup_dagruns(self):\n        DR = models.DagRun\n        dag_ids = ['example_bash_operator',\n                   'example_subdag_operator',\n                   'example_xcom']\n        (self.session\n             .query(DR)\n             .filter(DR.dag_id.in_(dag_ids))\n             .filter(DR.run_id == self.run_id)\n             .delete(synchronize_session='fetch'))\n        self.session.commit()\n\n    def prepare_dagruns(self):\n        dagbag = models.DagBag(include_examples=True)\n        self.bash_dag = dagbag.dags['example_bash_operator']\n        self.sub_dag = dagbag.dags['example_subdag_operator']\n        self.xcom_dag = dagbag.dags['example_xcom']\n\n        self.bash_dagrun = self.bash_dag.create_dagrun(\n            run_id=self.run_id,\n            execution_date=self.EXAMPLE_DAG_DEFAULT_DATE,\n            start_date=timezone.utcnow(),\n            state=State.RUNNING)\n\n        self.sub_dagrun = self.sub_dag.create_dagrun(\n            run_id=self.run_id,\n            execution_date=self.EXAMPLE_DAG_DEFAULT_DATE,\n            start_date=timezone.utcnow(),\n            state=State.RUNNING)\n\n        self.xcom_dagrun = self.xcom_dag.create_dagrun(\n            run_id=self.run_id,\n            execution_date=self.EXAMPLE_DAG_DEFAULT_DATE,\n            start_date=timezone.utcnow(),\n            state=State.RUNNING)\n\n    def test_index(self):\n        resp = self.client.get('/', follow_redirects=True)\n        self.check_content_in_response('DAGs', resp)\n\n    def test_health(self):\n\n        # case-1: healthy scheduler status\n        last_scheduler_heartbeat_for_testing_1 = timezone.utcnow()\n        self.session.add(BaseJob(job_type='SchedulerJob',\n                                 state='running',\n                                 latest_heartbeat=last_scheduler_heartbeat_for_testing_1))\n        self.session.commit()\n\n        resp_json = json.loads(self.client.get('health', follow_redirects=True).data.decode('utf-8'))\n\n        self.assertEqual('healthy', resp_json['metadatabase']['status'])\n        self.assertEqual('healthy', resp_json['scheduler']['status'])\n        self.assertEqual(last_scheduler_heartbeat_for_testing_1.isoformat(),\n                         resp_json['scheduler']['latest_scheduler_heartbeat'])\n\n        self.session.query(BaseJob).\\\n            filter(BaseJob.job_type == 'SchedulerJob',\n                   BaseJob.state == 'running',\n                   BaseJob.latest_heartbeat == last_scheduler_heartbeat_for_testing_1).\\\n            delete()\n        self.session.commit()\n\n        # case-2: unhealthy scheduler status - scenario 1 (SchedulerJob is running too slowly)\n        last_scheduler_heartbeat_for_testing_2 = timezone.utcnow() - timedelta(minutes=1)\n        (self.session\n             .query(BaseJob)\n             .filter(BaseJob.job_type == 'SchedulerJob')\n             .update({'latest_heartbeat': last_scheduler_heartbeat_for_testing_2 - timedelta(seconds=1)}))\n        self.session.add(BaseJob(job_type='SchedulerJob',\n                                 state='running',\n                                 latest_heartbeat=last_scheduler_heartbeat_for_testing_2))\n        self.session.commit()\n\n        resp_json = json.loads(self.client.get('health', follow_redirects=True).data.decode('utf-8'))\n\n        self.assertEqual('healthy', resp_json['metadatabase']['status'])\n        self.assertEqual('unhealthy', resp_json['scheduler']['status'])\n        self.assertEqual(last_scheduler_heartbeat_for_testing_2.isoformat(),\n                         resp_json['scheduler']['latest_scheduler_heartbeat'])\n\n        self.session.query(BaseJob).\\\n            filter(BaseJob.job_type == 'SchedulerJob',\n                   BaseJob.state == 'running',\n                   BaseJob.latest_heartbeat == last_scheduler_heartbeat_for_testing_2).\\\n            delete()\n        self.session.commit()\n\n        # case-3: unhealthy scheduler status - scenario 2 (no running SchedulerJob)\n        self.session.query(BaseJob).\\\n            filter(BaseJob.job_type == 'SchedulerJob',\n                   BaseJob.state == 'running').\\\n            delete()\n        self.session.commit()\n\n        resp_json = json.loads(self.client.get('health', follow_redirects=True).data.decode('utf-8'))\n\n        self.assertEqual('healthy', resp_json['metadatabase']['status'])\n        self.assertEqual('unhealthy', resp_json['scheduler']['status'])\n        self.assertIsNone(None, resp_json['scheduler']['latest_scheduler_heartbeat'])\n\n    def test_home(self):\n        resp = self.client.get('home', follow_redirects=True)\n        self.check_content_in_response('DAGs', resp)\n\n    def test_task(self):\n        url = ('task?task_id=runme_0&dag_id=example_bash_operator&execution_date={}'\n               .format(self.percent_encode(self.EXAMPLE_DAG_DEFAULT_DATE)))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('Task Instance Details', resp)\n\n    def test_xcom(self):\n        url = ('xcom?task_id=runme_0&dag_id=example_bash_operator&execution_date={}'\n               .format(self.percent_encode(self.EXAMPLE_DAG_DEFAULT_DATE)))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('XCom', resp)\n\n    def test_edit_dagrun_page(self):\n        resp = self.client.get('dagmodel/edit/example_bash_operator', follow_redirects=False)\n        self.assertEqual(resp.status_code, 200)\n\n    def test_edit_dagrun_url(self):\n        with self.app.test_request_context():\n            url = url_for('DagModelView.edit', pk='example_bash_operator')\n            self.assertEqual(url, '/dagmodel/edit/example_bash_operator')\n\n    def test_rendered(self):\n        url = ('rendered?task_id=runme_0&dag_id=example_bash_operator&execution_date={}'\n               .format(self.percent_encode(self.EXAMPLE_DAG_DEFAULT_DATE)))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('Rendered Template', resp)\n\n    def test_blocked(self):\n        url = 'blocked'\n        resp = self.client.get(url, follow_redirects=True)\n        self.assertEqual(200, resp.status_code)\n\n    def test_dag_stats(self):\n        resp = self.client.get('dag_stats', follow_redirects=True)\n        self.assertEqual(resp.status_code, 200)\n\n    def test_task_stats(self):\n        resp = self.client.get('task_stats', follow_redirects=True)\n        self.assertEqual(resp.status_code, 200)\n\n    def test_dag_details(self):\n        url = 'dag_details?dag_id=example_bash_operator'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('DAG details', resp)\n\n    def test_dag_details_subdag(self):\n        url = 'dag_details?dag_id=example_subdag_operator.section-1'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('DAG details', resp)\n\n    def test_graph(self):\n        url = 'graph?dag_id=example_bash_operator'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('runme_1', resp)\n\n    def test_last_dagruns(self):\n        resp = self.client.get('last_dagruns', follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n\n    def test_tree(self):\n        url = 'tree?dag_id=example_bash_operator'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('runme_1', resp)\n\n    def test_tree_subdag(self):\n        url = 'tree?dag_id=example_subdag_operator.section-1'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('section-1-task-1', resp)\n\n    def test_duration(self):\n        url = 'duration?days=30&dag_id=example_bash_operator'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n\n    def test_duration_missing(self):\n        url = 'duration?days=30&dag_id=missing_dag'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('seems to be missing', resp)\n\n    def test_tries(self):\n        url = 'tries?days=30&dag_id=example_bash_operator'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n\n    def test_landing_times(self):\n        url = 'landing_times?days=30&dag_id=example_bash_operator'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n\n    def test_gantt(self):\n        url = 'gantt?dag_id=example_bash_operator'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n\n    def test_code(self):\n        url = 'code?dag_id=example_bash_operator'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n\n    def test_paused(self):\n        url = 'paused?dag_id=example_bash_operator&is_paused=false'\n        resp = self.client.post(url, follow_redirects=True)\n        self.check_content_in_response('OK', resp)\n\n    def test_failed(self):\n        form = dict(\n            task_id=\"run_this_last\",\n            dag_id=\"example_bash_operator\",\n            execution_date=self.EXAMPLE_DAG_DEFAULT_DATE,\n            upstream=\"false\",\n            downstream=\"false\",\n            future=\"false\",\n            past=\"false\",\n        )\n        resp = self.client.post(\"failed\", data=form)\n        self.check_content_in_response('Wait a minute', resp)\n\n    def test_success(self):\n        form = dict(\n            task_id=\"run_this_last\",\n            dag_id=\"example_bash_operator\",\n            execution_date=self.EXAMPLE_DAG_DEFAULT_DATE,\n            upstream=\"false\",\n            downstream=\"false\",\n            future=\"false\",\n            past=\"false\",\n        )\n        resp = self.client.post('success', data=form)\n        self.check_content_in_response('Wait a minute', resp)\n\n    def test_clear(self):\n        form = dict(\n            task_id=\"runme_1\",\n            dag_id=\"example_bash_operator\",\n            execution_date=self.EXAMPLE_DAG_DEFAULT_DATE,\n            upstream=\"false\",\n            downstream=\"false\",\n            future=\"false\",\n            past=\"false\",\n            only_failed=\"false\",\n        )\n        resp = self.client.post(\"clear\", data=form)\n        self.check_content_in_response(['example_bash_operator', 'Wait a minute'], resp)\n\n    def test_run(self):\n        form = dict(\n            task_id=\"runme_0\",\n            dag_id=\"example_bash_operator\",\n            ignore_all_deps=\"false\",\n            ignore_ti_state=\"true\",\n            execution_date=self.EXAMPLE_DAG_DEFAULT_DATE,\n        )\n        resp = self.client.post('run', data=form)\n        self.check_content_in_response('', resp, resp_code=302)\n\n    def test_refresh(self):\n        resp = self.client.post('refresh?dag_id=example_bash_operator')\n        self.check_content_in_response('', resp, resp_code=302)\n\n    def test_refresh_all(self):\n        resp = self.client.post(\"/refresh_all\",\n                                follow_redirects=True)\n        self.check_content_in_response('', resp, resp_code=200)\n\n    def test_delete_dag_button_normal(self):\n        resp = self.client.get('/', follow_redirects=True)\n        self.check_content_in_response('/delete?dag_id=example_bash_operator', resp)\n        self.check_content_in_response(\"return confirmDeleteDag(this, 'example_bash_operator')\", resp)\n\n    def test_delete_dag_button_for_dag_on_scheduler_only(self):\n        # Test for JIRA AIRFLOW-3233 (PR 4069):\n        # The delete-dag URL should be generated correctly for DAGs\n        # that exist on the scheduler (DB) but not the webserver DagBag\n\n        test_dag_id = \"non_existent_dag\"\n\n        DM = models.DagModel\n        self.session.query(DM).filter(DM.dag_id == 'example_bash_operator').update({'dag_id': test_dag_id})\n        self.session.commit()\n\n        resp = self.client.get('/', follow_redirects=True)\n        self.check_content_in_response('/delete?dag_id={}'.format(test_dag_id), resp)\n        self.check_content_in_response(\"return confirmDeleteDag(this, '{}')\".format(test_dag_id), resp)\n\n        self.session.query(DM).filter(DM.dag_id == test_dag_id).update({'dag_id': 'example_bash_operator'})\n        self.session.commit()\n\n\nclass TestConfigurationView(TestBase):\n    def test_configuration_do_not_expose_config(self):\n        self.logout()\n        self.login()\n        with conf_vars({('webserver', 'expose_config'): 'False'}):\n            resp = self.client.get('configuration', follow_redirects=True)\n        self.check_content_in_response(\n            ['Airflow Configuration', '# Your Airflow administrator chose not to expose the configuration, '\n                                      'most likely for security reasons.'], resp)\n\n    def test_configuration_expose_config(self):\n        self.logout()\n        self.login()\n        with conf_vars({('webserver', 'expose_config'): 'True'}):\n            resp = self.client.get('configuration', follow_redirects=True)\n        self.check_content_in_response(\n            ['Airflow Configuration', 'Running Configuration'], resp)\n\n\nclass TestLogView(TestBase):\n    DAG_ID = 'dag_for_testing_log_view'\n    TASK_ID = 'task_for_testing_log_view'\n    DEFAULT_DATE = timezone.datetime(2017, 9, 1)\n    ENDPOINT = 'log?dag_id={dag_id}&task_id={task_id}&' \\\n               'execution_date={execution_date}'.format(dag_id=DAG_ID,\n                                                        task_id=TASK_ID,\n                                                        execution_date=DEFAULT_DATE)\n\n    def setUp(self):\n        # Make sure that the configure_logging is not cached\n        self.old_modules = dict(sys.modules)\n\n        # Create a custom logging configuration\n        logging_config = copy.deepcopy(DEFAULT_LOGGING_CONFIG)\n        current_dir = os.path.dirname(os.path.abspath(__file__))\n        logging_config['handlers']['task']['base_log_folder'] = os.path.normpath(\n            os.path.join(current_dir, 'test_logs'))\n\n        logging_config['handlers']['task']['filename_template'] = \\\n            '{{ ti.dag_id }}/{{ ti.task_id }}/' \\\n            '{{ ts | replace(\":\", \".\") }}/{{ try_number }}.log'\n\n        # Write the custom logging configuration to a file\n        self.settings_folder = tempfile.mkdtemp()\n        settings_file = os.path.join(self.settings_folder, \"airflow_local_settings.py\")\n        new_logging_file = \"LOGGING_CONFIG = {}\".format(logging_config)\n        with open(settings_file, 'w') as handle:\n            handle.writelines(new_logging_file)\n        sys.path.append(self.settings_folder)\n        conf.set('core', 'logging_config_class', 'airflow_local_settings.LOGGING_CONFIG')\n\n        self.app, self.appbuilder = application.create_app(session=Session, testing=True)\n        self.app.config['WTF_CSRF_ENABLED'] = False\n        self.client = self.app.test_client()\n        settings.configure_orm()\n        self.login()\n\n        from airflow.www.views import dagbag\n        dag = DAG(self.DAG_ID, start_date=self.DEFAULT_DATE)\n        dag.sync_to_db()\n        task = DummyOperator(task_id=self.TASK_ID, dag=dag)\n        dagbag.bag_dag(dag, parent_dag=dag, root_dag=dag)\n        with create_session() as session:\n            self.ti = TaskInstance(task=task, execution_date=self.DEFAULT_DATE)\n            self.ti.try_number = 1\n            session.merge(self.ti)\n\n    def tearDown(self):\n        logging.config.dictConfig(DEFAULT_LOGGING_CONFIG)\n        self.clear_table(TaskInstance)\n\n        # Remove any new modules imported during the test run. This lets us\n        # import the same source files for more than one test.\n        for m in [m for m in sys.modules if m not in self.old_modules]:\n            del sys.modules[m]\n\n        sys.path.remove(self.settings_folder)\n        shutil.rmtree(self.settings_folder)\n        conf.set('core', 'logging_config_class', '')\n\n        self.logout()\n        super().tearDown()\n\n    @parameterized.expand([\n        [State.NONE, 0, 0],\n        [State.UP_FOR_RETRY, 2, 2],\n        [State.UP_FOR_RESCHEDULE, 0, 1],\n        [State.UP_FOR_RESCHEDULE, 1, 2],\n        [State.RUNNING, 1, 1],\n        [State.SUCCESS, 1, 1],\n        [State.FAILED, 3, 3],\n    ])\n    def test_get_file_task_log(self, state, try_number, expected_num_logs_visible):\n        with create_session() as session:\n            self.ti.state = state\n            self.ti.try_number = try_number\n            session.merge(self.ti)\n\n        response = self.client.get(\n            TestLogView.ENDPOINT, data=dict(\n                username='test',\n                password='test'), follow_redirects=True)\n        self.assertEqual(response.status_code, 200)\n        self.assertIn('Log by attempts', response.data.decode('utf-8'))\n        for num in range(1, expected_num_logs_visible + 1):\n            self.assertIn('try-{}'.format(num), response.data.decode('utf-8'))\n        self.assertNotIn('try-0', response.data.decode('utf-8'))\n        self.assertNotIn('try-{}'.format(expected_num_logs_visible + 1), response.data.decode('utf-8'))\n\n    def test_get_logs_with_metadata_as_download_file(self):\n        url_template = \"get_logs_with_metadata?dag_id={}&\" \\\n                       \"task_id={}&execution_date={}&\" \\\n                       \"try_number={}&metadata={}&format=file\"\n        try_number = 1\n        url = url_template.format(self.DAG_ID,\n                                  self.TASK_ID,\n                                  quote_plus(self.DEFAULT_DATE.isoformat()),\n                                  try_number,\n                                  json.dumps({}))\n        response = self.client.get(url)\n        expected_filename = '{}/{}/{}/{}.log'.format(self.DAG_ID,\n                                                     self.TASK_ID,\n                                                     self.DEFAULT_DATE.isoformat(),\n                                                     try_number)\n\n        content_disposition = response.headers.get('Content-Disposition')\n        self.assertTrue(content_disposition.startswith('attachment'))\n        self.assertTrue(expected_filename in content_disposition)\n        self.assertEqual(200, response.status_code)\n        self.assertIn('Log for testing.', response.data.decode('utf-8'))\n\n    def test_get_logs_with_metadata_as_download_large_file(self):\n        with mock.patch(\"airflow.utils.log.file_task_handler.FileTaskHandler.read\") as read_mock:\n            first_return = (['1st line'], [{}])\n            second_return = (['2nd line'], [{'end_of_log': False}])\n            third_return = (['3rd line'], [{'end_of_log': True}])\n            fourth_return = (['should never be read'], [{'end_of_log': True}])\n            read_mock.side_effect = [first_return, second_return, third_return, fourth_return]\n            url_template = \"get_logs_with_metadata?dag_id={}&\" \\\n                           \"task_id={}&execution_date={}&\" \\\n                           \"try_number={}&metadata={}&format=file\"\n            try_number = 1\n            url = url_template.format(self.DAG_ID,\n                                      self.TASK_ID,\n                                      quote_plus(self.DEFAULT_DATE.isoformat()),\n                                      try_number,\n                                      json.dumps({}))\n            response = self.client.get(url)\n\n            self.assertIn('1st line', response.data.decode('utf-8'))\n            self.assertIn('2nd line', response.data.decode('utf-8'))\n            self.assertIn('3rd line', response.data.decode('utf-8'))\n            self.assertNotIn('should never be read', response.data.decode('utf-8'))\n\n    def test_get_logs_with_metadata(self):\n        url_template = \"get_logs_with_metadata?dag_id={}&\" \\\n                       \"task_id={}&execution_date={}&\" \\\n                       \"try_number={}&metadata={}\"\n        response = \\\n            self.client.get(url_template.format(self.DAG_ID,\n                                                self.TASK_ID,\n                                                quote_plus(self.DEFAULT_DATE.isoformat()),\n                                                1,\n                                                json.dumps({})), data=dict(\n                                                    username='test',\n                                                    password='test'),\n                            follow_redirects=True)\n\n        self.assertIn('\"message\":', response.data.decode('utf-8'))\n        self.assertIn('\"metadata\":', response.data.decode('utf-8'))\n        self.assertIn('Log for testing.', response.data.decode('utf-8'))\n        self.assertEqual(200, response.status_code)\n\n    def test_get_logs_with_null_metadata(self):\n        url_template = \"get_logs_with_metadata?dag_id={}&\" \\\n                       \"task_id={}&execution_date={}&\" \\\n                       \"try_number={}&metadata=null\"\n        response = \\\n            self.client.get(url_template.format(self.DAG_ID,\n                                                self.TASK_ID,\n                                                quote_plus(self.DEFAULT_DATE.isoformat()),\n                                                1), data=dict(\n                                                    username='test',\n                                                    password='test'),\n                            follow_redirects=True)\n\n        self.assertIn('\"message\":', response.data.decode('utf-8'))\n        self.assertIn('\"metadata\":', response.data.decode('utf-8'))\n        self.assertIn('Log for testing.', response.data.decode('utf-8'))\n        self.assertEqual(200, response.status_code)\n\n\nclass TestVersionView(TestBase):\n    def test_version(self):\n        resp = self.client.get('version', data=dict(\n            username='test',\n            password='test'\n        ), follow_redirects=True)\n        self.check_content_in_response('Version Info', resp)\n\n\nclass ViewWithDateTimeAndNumRunsAndDagRunsFormTester:\n    DAG_ID = 'dag_for_testing_dt_nr_dr_form'\n    DEFAULT_DATE = datetime(2017, 9, 1)\n    RUNS_DATA = [\n        ('dag_run_for_testing_dt_nr_dr_form_4', datetime(2018, 4, 4)),\n        ('dag_run_for_testing_dt_nr_dr_form_3', datetime(2018, 3, 3)),\n        ('dag_run_for_testing_dt_nr_dr_form_2', datetime(2018, 2, 2)),\n        ('dag_run_for_testing_dt_nr_dr_form_1', datetime(2018, 1, 1)),\n    ]\n\n    def __init__(self, test, endpoint):\n        self.test = test\n        self.endpoint = endpoint\n\n    def setUp(self):\n        from airflow.www.views import dagbag\n        from airflow.utils.state import State\n        dag = DAG(self.DAG_ID, start_date=self.DEFAULT_DATE)\n        dagbag.bag_dag(dag, parent_dag=dag, root_dag=dag)\n        self.runs = []\n        for rd in self.RUNS_DATA:\n            run = dag.create_dagrun(\n                run_id=rd[0],\n                execution_date=rd[1],\n                state=State.SUCCESS,\n                external_trigger=True\n            )\n            self.runs.append(run)\n\n    def tearDown(self):\n        self.test.session.query(DagRun).filter(\n            DagRun.dag_id == self.DAG_ID).delete()\n        self.test.session.commit()\n        self.test.session.close()\n\n    def assertBaseDateAndNumRuns(self, base_date, num_runs, data):\n        self.test.assertNotIn('name=\"base_date\" value=\"{}\"'.format(base_date), data)\n        self.test.assertNotIn('<option selected=\"\" value=\"{}\">{}</option>'.format(\n            num_runs, num_runs), data)\n\n    def assertRunIsNotInDropdown(self, run, data):\n        self.test.assertNotIn(run.execution_date.isoformat(), data)\n        self.test.assertNotIn(run.run_id, data)\n\n    def assertRunIsInDropdownNotSelected(self, run, data):\n        self.test.assertIn('<option value=\"{}\">{}</option>'.format(\n            run.execution_date.isoformat(), run.run_id), data)\n\n    def assertRunIsSelected(self, run, data):\n        self.test.assertIn('<option selected value=\"{}\">{}</option>'.format(\n            run.execution_date.isoformat(), run.run_id), data)\n\n    def test_with_default_parameters(self):\n        \"\"\"\n        Tests view with no URL parameter.\n        Should show all dag runs in the drop down.\n        Should select the latest dag run.\n        Should set base date to current date (not asserted)\n        \"\"\"\n        response = self.test.client.get(\n            self.endpoint, data=dict(\n                username='test',\n                password='test'), follow_redirects=True)\n        self.test.assertEqual(response.status_code, 200)\n        data = response.data.decode('utf-8')\n        self.test.assertIn('Base date:', data)\n        self.test.assertIn('Number of runs:', data)\n        self.assertRunIsSelected(self.runs[0], data)\n        self.assertRunIsInDropdownNotSelected(self.runs[1], data)\n        self.assertRunIsInDropdownNotSelected(self.runs[2], data)\n        self.assertRunIsInDropdownNotSelected(self.runs[3], data)\n\n    def test_with_execution_date_parameter_only(self):\n        \"\"\"\n        Tests view with execution_date URL parameter.\n        Scenario: click link from dag runs view.\n        Should only show dag runs older than execution_date in the drop down.\n        Should select the particular dag run.\n        Should set base date to execution date.\n        \"\"\"\n        response = self.test.client.get(\n            self.endpoint + '&execution_date={}'.format(\n                self.runs[1].execution_date.isoformat()),\n            data=dict(\n                username='test',\n                password='test'\n            ), follow_redirects=True\n        )\n        self.test.assertEqual(response.status_code, 200)\n        data = response.data.decode('utf-8')\n        self.assertBaseDateAndNumRuns(\n            self.runs[1].execution_date,\n            conf.getint('webserver', 'default_dag_run_display_number'),\n            data)\n        self.assertRunIsNotInDropdown(self.runs[0], data)\n        self.assertRunIsSelected(self.runs[1], data)\n        self.assertRunIsInDropdownNotSelected(self.runs[2], data)\n        self.assertRunIsInDropdownNotSelected(self.runs[3], data)\n\n    def test_with_base_date_and_num_runs_parmeters_only(self):\n        \"\"\"\n        Tests view with base_date and num_runs URL parameters.\n        Should only show dag runs older than base_date in the drop down,\n        limited to num_runs.\n        Should select the latest dag run.\n        Should set base date and num runs to submitted values.\n        \"\"\"\n        response = self.test.client.get(\n            self.endpoint + '&base_date={}&num_runs=2'.format(\n                self.runs[1].execution_date.isoformat()),\n            data=dict(\n                username='test',\n                password='test'\n            ), follow_redirects=True\n        )\n        self.test.assertEqual(response.status_code, 200)\n        data = response.data.decode('utf-8')\n        self.assertBaseDateAndNumRuns(self.runs[1].execution_date, 2, data)\n        self.assertRunIsNotInDropdown(self.runs[0], data)\n        self.assertRunIsSelected(self.runs[1], data)\n        self.assertRunIsInDropdownNotSelected(self.runs[2], data)\n        self.assertRunIsNotInDropdown(self.runs[3], data)\n\n    def test_with_base_date_and_num_runs_and_execution_date_outside(self):\n        \"\"\"\n        Tests view with base_date and num_runs and execution-date URL parameters.\n        Scenario: change the base date and num runs and press \"Go\",\n        the selected execution date is outside the new range.\n        Should only show dag runs older than base_date in the drop down.\n        Should select the latest dag run within the range.\n        Should set base date and num runs to submitted values.\n        \"\"\"\n        response = self.test.client.get(\n            self.endpoint + '&base_date={}&num_runs=42&execution_date={}'.format(\n                self.runs[1].execution_date.isoformat(),\n                self.runs[0].execution_date.isoformat()),\n            data=dict(\n                username='test',\n                password='test'\n            ), follow_redirects=True\n        )\n        self.test.assertEqual(response.status_code, 200)\n        data = response.data.decode('utf-8')\n        self.assertBaseDateAndNumRuns(self.runs[1].execution_date, 42, data)\n        self.assertRunIsNotInDropdown(self.runs[0], data)\n        self.assertRunIsSelected(self.runs[1], data)\n        self.assertRunIsInDropdownNotSelected(self.runs[2], data)\n        self.assertRunIsInDropdownNotSelected(self.runs[3], data)\n\n    def test_with_base_date_and_num_runs_and_execution_date_within(self):\n        \"\"\"\n        Tests view with base_date and num_runs and execution-date URL parameters.\n        Scenario: change the base date and num runs and press \"Go\",\n        the selected execution date is within the new range.\n        Should only show dag runs older than base_date in the drop down.\n        Should select the dag run with the execution date.\n        Should set base date and num runs to submitted values.\n        \"\"\"\n        response = self.test.client.get(\n            self.endpoint + '&base_date={}&num_runs=5&execution_date={}'.format(\n                self.runs[2].execution_date.isoformat(),\n                self.runs[3].execution_date.isoformat()),\n            data=dict(\n                username='test',\n                password='test'\n            ), follow_redirects=True\n        )\n        self.test.assertEqual(response.status_code, 200)\n        data = response.data.decode('utf-8')\n        self.assertBaseDateAndNumRuns(self.runs[2].execution_date, 5, data)\n        self.assertRunIsNotInDropdown(self.runs[0], data)\n        self.assertRunIsNotInDropdown(self.runs[1], data)\n        self.assertRunIsInDropdownNotSelected(self.runs[2], data)\n        self.assertRunIsSelected(self.runs[3], data)\n\n\nclass TestGraphView(TestBase):\n    GRAPH_ENDPOINT = '/graph?dag_id={dag_id}'.format(\n        dag_id=ViewWithDateTimeAndNumRunsAndDagRunsFormTester.DAG_ID\n    )\n\n    @classmethod\n    def setUpClass(cls):\n        super().setUpClass()\n\n    def setUp(self):\n        super().setUp()\n        self.tester = ViewWithDateTimeAndNumRunsAndDagRunsFormTester(\n            self, self.GRAPH_ENDPOINT)\n        self.tester.setUp()\n\n    def tearDown(self):\n        self.tester.tearDown()\n        super().tearDown()\n\n    @classmethod\n    def tearDownClass(cls):\n        super().tearDownClass()\n\n    def test_dt_nr_dr_form_default_parameters(self):\n        self.tester.test_with_default_parameters()\n\n    def test_dt_nr_dr_form_with_execution_date_parameter_only(self):\n        self.tester.test_with_execution_date_parameter_only()\n\n    def test_dt_nr_dr_form_with_base_date_and_num_runs_parmeters_only(self):\n        self.tester.test_with_base_date_and_num_runs_parmeters_only()\n\n    def test_dt_nr_dr_form_with_base_date_and_num_runs_and_execution_date_outside(self):\n        self.tester.test_with_base_date_and_num_runs_and_execution_date_outside()\n\n    def test_dt_nr_dr_form_with_base_date_and_num_runs_and_execution_date_within(self):\n        self.tester.test_with_base_date_and_num_runs_and_execution_date_within()\n\n\nclass TestGanttView(TestBase):\n    GANTT_ENDPOINT = '/gantt?dag_id={dag_id}'.format(\n        dag_id=ViewWithDateTimeAndNumRunsAndDagRunsFormTester.DAG_ID\n    )\n\n    @classmethod\n    def setUpClass(cls):\n        super().setUpClass()\n\n    def setUp(self):\n        super().setUp()\n        self.tester = ViewWithDateTimeAndNumRunsAndDagRunsFormTester(\n            self, self.GANTT_ENDPOINT)\n        self.tester.setUp()\n\n    def tearDown(self):\n        self.tester.tearDown()\n        super().tearDown()\n\n    @classmethod\n    def tearDownClass(cls):\n        super().tearDownClass()\n\n    def test_dt_nr_dr_form_default_parameters(self):\n        self.tester.test_with_default_parameters()\n\n    def test_dt_nr_dr_form_with_execution_date_parameter_only(self):\n        self.tester.test_with_execution_date_parameter_only()\n\n    def test_dt_nr_dr_form_with_base_date_and_num_runs_parmeters_only(self):\n        self.tester.test_with_base_date_and_num_runs_parmeters_only()\n\n    def test_dt_nr_dr_form_with_base_date_and_num_runs_and_execution_date_outside(self):\n        self.tester.test_with_base_date_and_num_runs_and_execution_date_outside()\n\n    def test_dt_nr_dr_form_with_base_date_and_num_runs_and_execution_date_within(self):\n        self.tester.test_with_base_date_and_num_runs_and_execution_date_within()\n\n\nclass TestDagACLView(TestBase):\n    \"\"\"\n    Test Airflow DAG acl\n    \"\"\"\n    default_date = timezone.datetime(2018, 6, 1)\n    run_id = \"test_{}\".format(models.DagRun.id_for_date(default_date))\n\n    @classmethod\n    def setUpClass(cls):\n        super().setUpClass()\n        dagbag = models.DagBag(include_examples=True)\n        for dag in dagbag.dags.values():\n            dag.sync_to_db()\n\n    def cleanup_dagruns(self):\n        DR = models.DagRun\n        dag_ids = ['example_bash_operator',\n                   'example_subdag_operator']\n        (self.session\n             .query(DR)\n             .filter(DR.dag_id.in_(dag_ids))\n             .filter(DR.run_id == self.run_id)\n             .delete(synchronize_session='fetch'))\n        self.session.commit()\n\n    def prepare_dagruns(self):\n        dagbag = models.DagBag(include_examples=True)\n        self.bash_dag = dagbag.dags['example_bash_operator']\n        self.sub_dag = dagbag.dags['example_subdag_operator']\n\n        self.bash_dagrun = self.bash_dag.create_dagrun(\n            run_id=self.run_id,\n            execution_date=self.default_date,\n            start_date=timezone.utcnow(),\n            state=State.RUNNING)\n\n        self.sub_dagrun = self.sub_dag.create_dagrun(\n            run_id=self.run_id,\n            execution_date=self.default_date,\n            start_date=timezone.utcnow(),\n            state=State.RUNNING)\n\n    def setUp(self):\n        super().setUp()\n        self.cleanup_dagruns()\n        self.prepare_dagruns()\n        self.logout()\n        self.appbuilder.sm.sync_roles()\n        self.add_permission_for_role()\n\n    def login(self, username=None, password=None):\n        role_admin = self.appbuilder.sm.find_role('Admin')\n        tester = self.appbuilder.sm.find_user(username='test')\n        if not tester:\n            self.appbuilder.sm.add_user(\n                username='test',\n                first_name='test',\n                last_name='test',\n                email='test@fab.org',\n                role=role_admin,\n                password='test')\n\n        role_user = self.appbuilder.sm.find_role('User')\n        test_user = self.appbuilder.sm.find_user(username='test_user')\n        if not test_user:\n            self.appbuilder.sm.add_user(\n                username='test_user',\n                first_name='test_user',\n                last_name='test_user',\n                email='test_user@fab.org',\n                role=role_user,\n                password='test_user')\n\n        role_viewer = self.appbuilder.sm.find_role('Viewer')\n        test_viewer = self.appbuilder.sm.find_user(username='test_viewer')\n        if not test_viewer:\n            self.appbuilder.sm.add_user(\n                username='test_viewer',\n                first_name='test_viewer',\n                last_name='test_viewer',\n                email='test_viewer@fab.org',\n                role=role_viewer,\n                password='test_viewer')\n\n        dag_acl_role = self.appbuilder.sm.add_role('dag_acl_tester')\n        dag_tester = self.appbuilder.sm.find_user(username='dag_tester')\n        if not dag_tester:\n            self.appbuilder.sm.add_user(\n                username='dag_tester',\n                first_name='dag_test',\n                last_name='dag_test',\n                email='dag_test@fab.org',\n                role=dag_acl_role,\n                password='dag_test')\n\n        # create an user without permission\n        dag_no_role = self.appbuilder.sm.add_role('dag_acl_faker')\n        dag_faker = self.appbuilder.sm.find_user(username='dag_faker')\n        if not dag_faker:\n            self.appbuilder.sm.add_user(\n                username='dag_faker',\n                first_name='dag_faker',\n                last_name='dag_faker',\n                email='dag_fake@fab.org',\n                role=dag_no_role,\n                password='dag_faker')\n\n        # create an user with only read permission\n        dag_read_only_role = self.appbuilder.sm.add_role('dag_acl_read_only')\n        dag_read_only = self.appbuilder.sm.find_user(username='dag_read_only')\n        if not dag_read_only:\n            self.appbuilder.sm.add_user(\n                username='dag_read_only',\n                first_name='dag_read_only',\n                last_name='dag_read_only',\n                email='dag_read_only@fab.org',\n                role=dag_read_only_role,\n                password='dag_read_only')\n\n        # create an user that has all dag access\n        all_dag_role = self.appbuilder.sm.add_role('all_dag_role')\n        all_dag_tester = self.appbuilder.sm.find_user(username='all_dag_user')\n        if not all_dag_tester:\n            self.appbuilder.sm.add_user(\n                username='all_dag_user',\n                first_name='all_dag_user',\n                last_name='all_dag_user',\n                email='all_dag_user@fab.org',\n                role=all_dag_role,\n                password='all_dag_user')\n\n        user = username if username else 'dag_tester'\n        passwd = password if password else 'dag_test'\n\n        return self.client.post('/login/', data=dict(\n            username=user,\n            password=passwd\n        ))\n\n    def logout(self):\n        return self.client.get('/logout/')\n\n    def add_permission_for_role(self):\n        self.logout()\n        self.login(username='test',\n                   password='test')\n        perm_on_dag = self.appbuilder.sm.\\\n            find_permission_view_menu('can_dag_edit', 'example_bash_operator')\n        dag_tester_role = self.appbuilder.sm.find_role('dag_acl_tester')\n        self.appbuilder.sm.add_permission_role(dag_tester_role, perm_on_dag)\n\n        perm_on_all_dag = self.appbuilder.sm.\\\n            find_permission_view_menu('can_dag_edit', 'all_dags')\n        all_dag_role = self.appbuilder.sm.find_role('all_dag_role')\n        self.appbuilder.sm.add_permission_role(all_dag_role, perm_on_all_dag)\n\n        role_user = self.appbuilder.sm.find_role('User')\n        self.appbuilder.sm.add_permission_role(role_user, perm_on_all_dag)\n\n        read_only_perm_on_dag = self.appbuilder.sm.\\\n            find_permission_view_menu('can_dag_read', 'example_bash_operator')\n        dag_read_only_role = self.appbuilder.sm.find_role('dag_acl_read_only')\n        self.appbuilder.sm.add_permission_role(dag_read_only_role, read_only_perm_on_dag)\n\n    def test_permission_exist(self):\n        self.logout()\n        self.login(username='test',\n                   password='test')\n        test_view_menu = self.appbuilder.sm.find_view_menu('example_bash_operator')\n        perms_views = self.appbuilder.sm.find_permissions_view_menu(test_view_menu)\n        self.assertEqual(len(perms_views), 2)\n        # each dag view will create one write, and one read permission\n        self.assertTrue(str(perms_views[0]).startswith('can dag'))\n        self.assertTrue(str(perms_views[1]).startswith('can dag'))\n\n    def test_role_permission_associate(self):\n        self.logout()\n        self.login(username='test',\n                   password='test')\n        test_role = self.appbuilder.sm.find_role('dag_acl_tester')\n        perms = {str(perm) for perm in test_role.permissions}\n        self.assertIn('can dag edit on example_bash_operator', perms)\n        self.assertNotIn('can dag read on example_bash_operator', perms)\n\n    def test_index_success(self):\n        self.logout()\n        self.login()\n        resp = self.client.get('/', follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n\n    def test_index_failure(self):\n        self.logout()\n        self.login()\n        resp = self.client.get('/', follow_redirects=True)\n        # The user can only access/view example_bash_operator dag.\n        self.check_content_not_in_response('example_subdag_operator', resp)\n\n    def test_index_for_all_dag_user(self):\n        self.logout()\n        self.login(username='all_dag_user',\n                   password='all_dag_user')\n        resp = self.client.get('/', follow_redirects=True)\n        # The all dag user can access/view all dags.\n        self.check_content_in_response('example_subdag_operator', resp)\n        self.check_content_in_response('example_bash_operator', resp)\n\n    def test_dag_stats_success(self):\n        self.logout()\n        self.login()\n        resp = self.client.get('dag_stats', follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n\n    def test_dag_stats_failure(self):\n        self.logout()\n        self.login()\n        resp = self.client.get('dag_stats', follow_redirects=True)\n        self.check_content_not_in_response('example_subdag_operator', resp)\n\n    def test_dag_stats_success_for_all_dag_user(self):\n        self.logout()\n        self.login(username='all_dag_user',\n                   password='all_dag_user')\n        resp = self.client.get('dag_stats', follow_redirects=True)\n        self.check_content_in_response('example_subdag_operator', resp)\n        self.check_content_in_response('example_bash_operator', resp)\n\n    def test_task_stats_success(self):\n        self.logout()\n        self.login()\n        resp = self.client.get('task_stats', follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n\n    def test_task_stats_failure(self):\n        self.logout()\n        self.login()\n        resp = self.client.get('task_stats', follow_redirects=True)\n        self.check_content_not_in_response('example_subdag_operator', resp)\n\n    def test_task_stats_success_for_all_dag_user(self):\n        self.logout()\n        self.login(username='all_dag_user',\n                   password='all_dag_user')\n        resp = self.client.get('task_stats', follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n        self.check_content_in_response('example_subdag_operator', resp)\n\n    def test_code_success(self):\n        self.logout()\n        self.login()\n        url = 'code?dag_id=example_bash_operator'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n\n    def test_code_failure(self):\n        self.logout()\n        self.login(username='dag_faker',\n                   password='dag_faker')\n        url = 'code?dag_id=example_bash_operator'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_not_in_response('example_bash_operator', resp)\n\n    def test_code_success_for_all_dag_user(self):\n        self.logout()\n        self.login(username='all_dag_user',\n                   password='all_dag_user')\n        url = 'code?dag_id=example_bash_operator'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n\n        url = 'code?dag_id=example_subdag_operator'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('example_subdag_operator', resp)\n\n    def test_dag_details_success(self):\n        self.logout()\n        self.login()\n        url = 'dag_details?dag_id=example_bash_operator'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('DAG details', resp)\n\n    def test_dag_details_failure(self):\n        self.logout()\n        self.login(username='dag_faker',\n                   password='dag_faker')\n        url = 'dag_details?dag_id=example_bash_operator'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_not_in_response('DAG details', resp)\n\n    def test_dag_details_success_for_all_dag_user(self):\n        self.logout()\n        self.login(username='all_dag_user',\n                   password='all_dag_user')\n        url = 'dag_details?dag_id=example_bash_operator'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n\n        url = 'dag_details?dag_id=example_subdag_operator'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('example_subdag_operator', resp)\n\n    def test_rendered_success(self):\n        self.logout()\n        self.login()\n        url = ('rendered?task_id=runme_0&dag_id=example_bash_operator&execution_date={}'\n               .format(self.percent_encode(self.default_date)))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('Rendered Template', resp)\n\n    def test_rendered_failure(self):\n        self.logout()\n        self.login(username='dag_faker',\n                   password='dag_faker')\n        url = ('rendered?task_id=runme_0&dag_id=example_bash_operator&execution_date={}'\n               .format(self.percent_encode(self.default_date)))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_not_in_response('Rendered Template', resp)\n\n    def test_rendered_success_for_all_dag_user(self):\n        self.logout()\n        self.login(username='all_dag_user',\n                   password='all_dag_user')\n        url = ('rendered?task_id=runme_0&dag_id=example_bash_operator&execution_date={}'\n               .format(self.percent_encode(self.default_date)))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('Rendered Template', resp)\n\n    def test_task_success(self):\n        self.logout()\n        self.login()\n        url = ('task?task_id=runme_0&dag_id=example_bash_operator&execution_date={}'\n               .format(self.percent_encode(self.default_date)))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('Task Instance Details', resp)\n\n    def test_task_failure(self):\n        self.logout()\n        self.login(username='dag_faker',\n                   password='dag_faker')\n        url = ('task?task_id=runme_0&dag_id=example_bash_operator&execution_date={}'\n               .format(self.percent_encode(self.default_date)))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_not_in_response('Task Instance Details', resp)\n\n    def test_task_success_for_all_dag_user(self):\n        self.logout()\n        self.login(username='all_dag_user',\n                   password='all_dag_user')\n        url = ('task?task_id=runme_0&dag_id=example_bash_operator&execution_date={}'\n               .format(self.percent_encode(self.default_date)))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('Task Instance Details', resp)\n\n    def test_xcom_success(self):\n        self.logout()\n        self.login()\n        url = ('xcom?task_id=runme_0&dag_id=example_bash_operator&execution_date={}'\n               .format(self.percent_encode(self.default_date)))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('XCom', resp)\n\n    def test_xcom_failure(self):\n        self.logout()\n        self.login(username='dag_faker',\n                   password='dag_faker')\n        url = ('xcom?task_id=runme_0&dag_id=example_bash_operator&execution_date={}'\n               .format(self.percent_encode(self.default_date)))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_not_in_response('XCom', resp)\n\n    def test_xcom_success_for_all_dag_user(self):\n        self.logout()\n        self.login(username='all_dag_user',\n                   password='all_dag_user')\n        url = ('xcom?task_id=runme_0&dag_id=example_bash_operator&execution_date={}'\n               .format(self.percent_encode(self.default_date)))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('XCom', resp)\n\n    def test_run_success(self):\n        self.logout()\n        self.login()\n        form = dict(\n            task_id=\"runme_0\",\n            dag_id=\"example_bash_operator\",\n            ignore_all_deps=\"false\",\n            ignore_ti_state=\"true\",\n            execution_date=self.default_date,\n        )\n        resp = self.client.post('run', data=form)\n        self.check_content_in_response('', resp, resp_code=302)\n\n    def test_run_success_for_all_dag_user(self):\n        self.logout()\n        self.login(username='all_dag_user',\n                   password='all_dag_user')\n        form = dict(\n            task_id=\"runme_0\",\n            dag_id=\"example_bash_operator\",\n            ignore_all_deps=\"false\",\n            ignore_ti_state=\"true\",\n            execution_date=self.default_date\n        )\n        resp = self.client.post('run', data=form)\n        self.check_content_in_response('', resp, resp_code=302)\n\n    def test_blocked_success(self):\n        url = 'blocked'\n        self.logout()\n        self.login()\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n\n    def test_blocked_success_for_all_dag_user(self):\n        url = 'blocked'\n        self.logout()\n        self.login(username='all_dag_user',\n                   password='all_dag_user')\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n        self.check_content_in_response('example_subdag_operator', resp)\n\n    def test_failed_success(self):\n        self.logout()\n        self.login()\n        form = dict(\n            task_id=\"run_this_last\",\n            dag_id=\"example_bash_operator\",\n            execution_date=self.default_date,\n            upstream=\"false\",\n            downstream=\"false\",\n            future=\"false\",\n            past=\"false\",\n        )\n        resp = self.client.post('failed', data=form)\n        self.check_content_in_response('Redirecting', resp, 302)\n\n    def test_duration_success(self):\n        url = 'duration?days=30&dag_id=example_bash_operator'\n        self.logout()\n        self.login()\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n\n    def test_duration_failure(self):\n        url = 'duration?days=30&dag_id=example_bash_operator'\n        self.logout()\n        # login as an user without permissions\n        self.login(username='dag_faker',\n                   password='dag_faker')\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_not_in_response('example_bash_operator', resp)\n\n    def test_tries_success(self):\n        url = 'tries?days=30&dag_id=example_bash_operator'\n        self.logout()\n        self.login()\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n\n    def test_tries_failure(self):\n        url = 'tries?days=30&dag_id=example_bash_operator'\n        self.logout()\n        # login as an user without permissions\n        self.login(username='dag_faker',\n                   password='dag_faker')\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_not_in_response('example_bash_operator', resp)\n\n    def test_landing_times_success(self):\n        url = 'landing_times?days=30&dag_id=example_bash_operator'\n        self.logout()\n        self.login()\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n\n    def test_landing_times_failure(self):\n        url = 'landing_times?days=30&dag_id=example_bash_operator'\n        self.logout()\n        self.login(username='dag_faker',\n                   password='dag_faker')\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_not_in_response('example_bash_operator', resp)\n\n    def test_paused_success(self):\n        # post request failure won't test\n        url = 'paused?dag_id=example_bash_operator&is_paused=false'\n        self.logout()\n        self.login()\n        resp = self.client.post(url, follow_redirects=True)\n        self.check_content_in_response('OK', resp)\n\n    def test_refresh_success(self):\n        self.logout()\n        self.login()\n        resp = self.client.post('refresh?dag_id=example_bash_operator')\n        self.check_content_in_response('', resp, resp_code=302)\n\n    def test_gantt_success(self):\n        url = 'gantt?dag_id=example_bash_operator'\n        self.logout()\n        self.login()\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n\n    def test_gantt_failure(self):\n        url = 'gantt?dag_id=example_bash_operator'\n        self.logout()\n        self.login(username='dag_faker',\n                   password='dag_faker')\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_not_in_response('example_bash_operator', resp)\n\n    def test_success_fail_for_read_only_role(self):\n        # succcess endpoint need can_dag_edit, which read only role can not access\n        self.logout()\n        self.login(username='dag_read_only',\n                   password='dag_read_only')\n\n        form = dict(\n            task_id=\"run_this_last\",\n            dag_id=\"example_bash_operator\",\n            execution_date=self.default_date,\n            upstream=\"false\",\n            downstream=\"false\",\n            future=\"false\",\n            past=\"false\",\n        )\n        resp = self.client.post('success', data=form)\n        self.check_content_not_in_response('Wait a minute', resp, resp_code=302)\n\n    def test_tree_success_for_read_only_role(self):\n        # tree view only allows can_dag_read, which read only role could access\n        self.logout()\n        self.login(username='dag_read_only',\n                   password='dag_read_only')\n\n        url = 'tree?dag_id=example_bash_operator'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('runme_1', resp)\n\n    def test_log_success(self):\n        self.logout()\n        self.login()\n        url = ('log?task_id=runme_0&dag_id=example_bash_operator&execution_date={}'\n               .format(self.percent_encode(self.default_date)))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('Log by attempts', resp)\n        url = ('get_logs_with_metadata?task_id=runme_0&dag_id=example_bash_operator&'\n               'execution_date={}&try_number=1&metadata=null'\n               .format(self.percent_encode(self.default_date)))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('\"message\":', resp)\n        self.check_content_in_response('\"metadata\":', resp)\n\n    def test_log_failure(self):\n        self.logout()\n        self.login(username='dag_faker',\n                   password='dag_faker')\n        url = ('log?task_id=runme_0&dag_id=example_bash_operator&execution_date={}'\n               .format(self.percent_encode(self.default_date)))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_not_in_response('Log by attempts', resp)\n        url = ('get_logs_with_metadata?task_id=runme_0&dag_id=example_bash_operator&'\n               'execution_date={}&try_number=1&metadata=null'\n               .format(self.percent_encode(self.default_date)))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_not_in_response('\"message\":', resp)\n        self.check_content_not_in_response('\"metadata\":', resp)\n\n    def test_log_success_for_user(self):\n        self.logout()\n        self.login(username='test_user',\n                   password='test_user')\n        url = ('log?task_id=runme_0&dag_id=example_bash_operator&execution_date={}'\n               .format(self.percent_encode(self.default_date)))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('Log by attempts', resp)\n        url = ('get_logs_with_metadata?task_id=runme_0&dag_id=example_bash_operator&'\n               'execution_date={}&try_number=1&metadata=null'\n               .format(self.percent_encode(self.default_date)))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('\"message\":', resp)\n        self.check_content_in_response('\"metadata\":', resp)\n\n    def test_tree_view_for_viewer(self):\n        self.logout()\n        self.login(username='test_viewer',\n                   password='test_viewer')\n        url = 'tree?dag_id=example_bash_operator'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('runme_1', resp)\n\n    def test_refresh_failure_for_viewer(self):\n        # viewer role can't refresh\n        self.logout()\n        self.login(username='test_viewer',\n                   password='test_viewer')\n        resp = self.client.post('refresh?dag_id=example_bash_operator')\n        self.check_content_in_response('Redirecting', resp, resp_code=302)\n\n\nclass TestTaskInstanceView(TestBase):\n    TI_ENDPOINT = '/taskinstance/list/?_flt_0_execution_date={}'\n\n    def test_start_date_filter(self):\n        resp = self.client.get(self.TI_ENDPOINT.format(\n            self.percent_encode('2018-10-09 22:44:31')))\n        # We aren't checking the logic of the date filter itself (that is built\n        # in to FAB) but simply that our UTC conversion was run - i.e. it\n        # doesn't blow up!\n        self.check_content_in_response('List Task Instance', resp)\n\n\nclass TestTriggerDag(TestBase):\n\n    def setUp(self):\n        super().setUp()\n        self.session = Session()\n        models.DagBag().get_dag(\"example_bash_operator\").sync_to_db(session=self.session)\n\n    def test_trigger_dag_button_normal_exist(self):\n        resp = self.client.get('/', follow_redirects=True)\n        self.assertIn('/trigger?dag_id=example_bash_operator', resp.data.decode('utf-8'))\n        self.assertIn(\"return confirmDeleteDag(this, 'example_bash_operator')\", resp.data.decode('utf-8'))\n\n    @unittest.skipIf('mysql' in conf.get('core', 'sql_alchemy_conn'),\n                     \"flaky when run on mysql\")\n    def test_trigger_dag_button(self):\n\n        test_dag_id = \"example_bash_operator\"\n\n        DR = models.DagRun\n        self.session.query(DR).delete()\n        self.session.commit()\n\n        self.client.post('trigger?dag_id={}'.format(test_dag_id))\n\n        run = self.session.query(DR).filter(DR.dag_id == test_dag_id).first()\n        self.assertIsNotNone(run)\n        self.assertIn(\"manual__\", run.run_id)\n\n\nclass TestExtraLinks(TestBase):\n    def setUp(self):\n        super().setUp()\n        self.ENDPOINT = \"extra_links\"\n        self.DEFAULT_DATE = datetime(2017, 1, 1)\n\n        class RaiseErrorLink(BaseOperatorLink):\n            name = 'raise_error'\n\n            def get_link(self, operator, dttm):\n                raise ValueError('This is an error')\n\n        class NoResponseLink(BaseOperatorLink):\n            name = 'no_response'\n\n            def get_link(self, operator, dttm):\n                return None\n\n        class FooBarLink(BaseOperatorLink):\n            name = 'foo-bar'\n\n            def get_link(self, operator, dttm):\n                return 'http://www.example.com/{0}/{1}/{2}'.format(\n                    operator.task_id, 'foo-bar', dttm)\n\n        class AirflowLink(BaseOperatorLink):\n            name = 'airflow'\n\n            def get_link(self, operator, dttm):\n                return 'https://airflow.apache.org'\n\n        class DummyTestOperator(BaseOperator):\n\n            operator_extra_links = (\n                RaiseErrorLink(),\n                NoResponseLink(),\n                FooBarLink(),\n                AirflowLink(),\n            )\n\n        self.dag = DAG('dag', start_date=self.DEFAULT_DATE)\n        self.task = DummyTestOperator(task_id=\"some_dummy_task\", dag=self.dag)\n\n    def tearDown(self):\n        super().tearDown()\n\n    @mock.patch('airflow.www.views.dagbag.get_dag')\n    def test_extra_links_works(self, get_dag_function):\n        get_dag_function.return_value = self.dag\n\n        response = self.client.get(\n            \"{0}?dag_id={1}&task_id={2}&execution_date={3}&link_name=foo-bar\"\n            .format(self.ENDPOINT, self.dag.dag_id, self.task.task_id, self.DEFAULT_DATE),\n            follow_redirects=True)\n\n        self.assertEqual(response.status_code, 200)\n        response_str = response.data\n        if isinstance(response.data, bytes):\n            response_str = response_str.decode()\n        self.assertEqual(json.loads(response_str), {\n            'url': ('http://www.example.com/some_dummy_task/'\n                    'foo-bar/2017-01-01T00:00:00+00:00'),\n            'error': None\n        })\n\n    @mock.patch('airflow.www.views.dagbag.get_dag')\n    def test_global_extra_links_works(self, get_dag_function):\n        get_dag_function.return_value = self.dag\n\n        response = self.client.get(\n            \"{0}?dag_id={1}&task_id={2}&execution_date={3}&link_name=github\"\n            .format(self.ENDPOINT, self.dag.dag_id, self.task.task_id, self.DEFAULT_DATE),\n            follow_redirects=True)\n\n        self.assertEqual(response.status_code, 200)\n        response_str = response.data\n        if isinstance(response.data, bytes):\n            response_str = response_str.decode()\n        self.assertEqual(json.loads(response_str), {\n            'url': 'https://github.com/apache/airflow',\n            'error': None\n        })\n\n    @mock.patch('airflow.www.views.dagbag.get_dag')\n    def test_operator_extra_link_override_global_extra_link(self, get_dag_function):\n        get_dag_function.return_value = self.dag\n\n        response = self.client.get(\n            \"{0}?dag_id={1}&task_id={2}&execution_date={3}&link_name=airflow\".format(\n                self.ENDPOINT, self.dag.dag_id, self.task.task_id, self.DEFAULT_DATE),\n            follow_redirects=True)\n\n        self.assertEqual(response.status_code, 200)\n        response_str = response.data\n        if isinstance(response.data, bytes):\n            response_str = response_str.decode()\n        self.assertEqual(json.loads(response_str), {\n            'url': 'https://airflow.apache.org',\n            'error': None\n        })\n\n    @mock.patch('airflow.www.views.dagbag.get_dag')\n    def test_extra_links_error_raised(self, get_dag_function):\n        get_dag_function.return_value = self.dag\n\n        response = self.client.get(\n            \"{0}?dag_id={1}&task_id={2}&execution_date={3}&link_name=raise_error\"\n            .format(self.ENDPOINT, self.dag.dag_id, self.task.task_id, self.DEFAULT_DATE),\n            follow_redirects=True)\n\n        self.assertEqual(404, response.status_code)\n        response_str = response.data\n        if isinstance(response.data, bytes):\n            response_str = response_str.decode()\n        self.assertEqual(json.loads(response_str), {\n            'url': None,\n            'error': 'This is an error'})\n\n    @mock.patch('airflow.www.views.dagbag.get_dag')\n    def test_extra_links_no_response(self, get_dag_function):\n        get_dag_function.return_value = self.dag\n\n        response = self.client.get(\n            \"{0}?dag_id={1}&task_id={2}&execution_date={3}&link_name=no_response\"\n            .format(self.ENDPOINT, self.dag.dag_id, self.task.task_id, self.DEFAULT_DATE),\n            follow_redirects=True)\n\n        self.assertEqual(response.status_code, 404)\n        response_str = response.data\n        if isinstance(response.data, bytes):\n            response_str = response_str.decode()\n        self.assertEqual(json.loads(response_str), {\n            'url': None,\n            'error': 'No URL found for no_response'})\n\n\nclass TestDagRunModelView(TestBase):\n    @classmethod\n    def setUpClass(cls):\n        super().setUpClass()\n        models.DagBag().get_dag(\"example_bash_operator\").sync_to_db(session=cls.session)\n        cls.clear_table(models.DagRun)\n\n    def tearDown(self):\n        self.clear_table(models.DagRun)\n\n    def test_create_dagrun(self):\n        data = {\n            \"state\": \"running\",\n            \"dag_id\": \"example_bash_operator\",\n            \"execution_date\": \"2018-07-06 05:04:03\",\n            \"run_id\": \"manual_abc\",\n        }\n        resp = self.client.post('/dagrun/add',\n                                data=data,\n                                follow_redirects=True)\n        self.check_content_in_response('Added Row', resp)\n\n        dr = self.session.query(models.DagRun).one()\n\n        self.assertEqual(dr.execution_date, timezone.convert_to_utc(datetime(2018, 7, 6, 5, 4, 3)))\n\n\nclass TestDecorators(TestBase):\n    EXAMPLE_DAG_DEFAULT_DATE = dates.days_ago(2)\n    run_id = \"test_{}\".format(models.DagRun.id_for_date(EXAMPLE_DAG_DEFAULT_DATE))\n\n    @classmethod\n    def setUpClass(cls):\n        super().setUpClass()\n        dagbag = models.DagBag(include_examples=True)\n        for dag in dagbag.dags.values():\n            dag.sync_to_db()\n\n    def setUp(self):\n        super().setUp()\n        self.logout()\n        self.login()\n        self.cleanup_dagruns()\n        self.prepare_dagruns()\n\n    def cleanup_dagruns(self):\n        DR = models.DagRun\n        dag_ids = ['example_bash_operator',\n                   'example_subdag_operator',\n                   'example_xcom']\n        (self.session\n             .query(DR)\n             .filter(DR.dag_id.in_(dag_ids))\n             .filter(DR.run_id == self.run_id)\n             .delete(synchronize_session='fetch'))\n        self.session.commit()\n\n    def prepare_dagruns(self):\n        dagbag = models.DagBag(include_examples=True)\n        self.bash_dag = dagbag.dags['example_bash_operator']\n        self.sub_dag = dagbag.dags['example_subdag_operator']\n        self.xcom_dag = dagbag.dags['example_xcom']\n\n        self.bash_dagrun = self.bash_dag.create_dagrun(\n            run_id=self.run_id,\n            execution_date=self.EXAMPLE_DAG_DEFAULT_DATE,\n            start_date=timezone.utcnow(),\n            state=State.RUNNING)\n\n        self.sub_dagrun = self.sub_dag.create_dagrun(\n            run_id=self.run_id,\n            execution_date=self.EXAMPLE_DAG_DEFAULT_DATE,\n            start_date=timezone.utcnow(),\n            state=State.RUNNING)\n\n        self.xcom_dagrun = self.xcom_dag.create_dagrun(\n            run_id=self.run_id,\n            execution_date=self.EXAMPLE_DAG_DEFAULT_DATE,\n            start_date=timezone.utcnow(),\n            state=State.RUNNING)\n\n    def check_last_log(self, dag_id, event, execution_date=None):\n        from airflow.models import Log\n        qry = self.session.query(Log.dag_id, Log.task_id, Log.event, Log.execution_date,\n                                 Log.owner, Log.extra)\n        qry = qry.filter(Log.dag_id == dag_id, Log.event == event)\n        if execution_date:\n            qry = qry.filter(Log.execution_date == execution_date)\n        logs = qry.order_by(Log.dttm.desc()).limit(5).all()\n        self.assertGreaterEqual(len(logs), 1)\n        self.assertTrue(logs[0].extra)\n\n    def test_action_logging_get(self):\n        url = 'graph?dag_id=example_bash_operator&execution_date={}'.format(\n            self.percent_encode(self.EXAMPLE_DAG_DEFAULT_DATE))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('runme_1', resp)\n\n        # In mysql backend, this commit() is needed to write down the logs\n        self.session.commit()\n        self.check_last_log(\"example_bash_operator\", event=\"graph\",\n                            execution_date=self.EXAMPLE_DAG_DEFAULT_DATE)\n\n    def test_action_logging_post(self):\n        form = dict(\n            task_id=\"runme_1\",\n            dag_id=\"example_bash_operator\",\n            execution_date=self.EXAMPLE_DAG_DEFAULT_DATE,\n            upstream=\"false\",\n            downstream=\"false\",\n            future=\"false\",\n            past=\"false\",\n            only_failed=\"false\",\n        )\n        resp = self.client.post(\"clear\", data=form)\n        self.check_content_in_response(['example_bash_operator', 'Wait a minute'], resp)\n        # In mysql backend, this commit() is needed to write down the logs\n        self.session.commit()\n        self.check_last_log(\"example_bash_operator\", event=\"clear\",\n                            execution_date=self.EXAMPLE_DAG_DEFAULT_DATE)\n\n\nif __name__ == '__main__':\n    unittest.main()\n", "patch": "@@ -446,15 +446,6 @@ def test_xcom(self):\n         resp = self.client.get(url, follow_redirects=True)\n         self.check_content_in_response('XCom', resp)\n \n-    def test_edit_dagrun_page(self):\n-        resp = self.client.get('dagmodel/edit/example_bash_operator', follow_redirects=False)\n-        self.assertEqual(resp.status_code, 200)\n-\n-    def test_edit_dagrun_url(self):\n-        with self.app.test_request_context():\n-            url = url_for('DagModelView.edit', pk='example_bash_operator')\n-            self.assertEqual(url, '/dagmodel/edit/example_bash_operator')\n-\n     def test_rendered(self):\n         url = ('rendered?task_id=runme_0&dag_id=example_bash_operator&execution_date={}'\n                .format(self.percent_encode(self.EXAMPLE_DAG_DEFAULT_DATE)))", "file_path": "files/2019_10\\22", "file_language": "py", "file_name": "tests/www/test_views.py", "outdated_file_modify": 0, "outdated_file_before": 0, "outdated_file_after": 0, "llm_check": 0, "static_check": 0, "static": {"rats": [false, []], "semgrep": [false, []]}, "target": 0, "function_before": [{"function": "class TestBase(unittest.TestCase):\n    @classmethod\n    def setUpClass(cls):\n        cls.app, cls.appbuilder = application.create_app(session=Session, testing=True)\n        cls.app.config['WTF_CSRF_ENABLED'] = False\n        cls.app.jinja_env.undefined = jinja2.StrictUndefined\n        settings.configure_orm()\n        cls.session = Session\n\n    def setUp(self):\n        self.client = self.app.test_client()\n        self.login()\n\n    def login(self):\n        role_admin = self.appbuilder.sm.find_role('Admin')\n        tester = self.appbuilder.sm.find_user(username='test')\n        if not tester:\n            self.appbuilder.sm.add_user(\n                username='test',\n                first_name='test',\n                last_name='test',\n                email='test@fab.org',\n                role=role_admin,\n                password='test')\n        return self.client.post('/login/', data=dict(\n            username='test',\n            password='test'\n        ), follow_redirects=True)\n\n    def logout(self):\n        return self.client.get('/logout/')\n\n    @classmethod\n    def clear_table(cls, model):\n        with create_session() as session:\n            session.query(model).delete()\n\n    def check_content_in_response(self, text, resp, resp_code=200):\n        resp_html = resp.data.decode('utf-8')\n        self.assertEqual(resp_code, resp.status_code)\n        if isinstance(text, list):\n            for kw in text:\n                self.assertIn(kw, resp_html)\n        else:\n            self.assertIn(text, resp_html)\n\n    def check_content_not_in_response(self, text, resp, resp_code=200):\n        resp_html = resp.data.decode('utf-8')\n        self.assertEqual(resp_code, resp.status_code)\n        if isinstance(text, list):\n            for kw in text:\n                self.assertNotIn(kw, resp_html)\n        else:\n            self.assertNotIn(text, resp_html)\n\n    def percent_encode(self, obj):\n        return urllib.parse.quote_plus(str(obj))", "target": 0}, {"function": "class TestConnectionModelView(TestBase):\n    def setUp(self):\n        super().setUp()\n        self.connection = {\n            'conn_id': 'test_conn',\n            'conn_type': 'http',\n            'host': 'localhost',\n            'port': 8080,\n            'username': 'root',\n            'password': 'admin'\n        }\n\n    def tearDown(self):\n        self.clear_table(Connection)\n        super().tearDown()\n\n    def test_create_connection(self):\n        resp = self.client.post('/connection/add',\n                                data=self.connection,\n                                follow_redirects=True)\n        self.check_content_in_response('Added Row', resp)", "target": 0}, {"function": "class TestVariableModelView(TestBase):\n    def setUp(self):\n        super().setUp()\n        self.variable = {\n            'key': 'test_key',\n            'val': 'text_val',\n            'is_encrypted': True\n        }\n\n    def tearDown(self):\n        self.clear_table(models.Variable)\n        super().tearDown()\n\n    def test_can_handle_error_on_decrypt(self):\n\n        # create valid variable\n        resp = self.client.post('/variable/add',\n                                data=self.variable,\n                                follow_redirects=True)\n\n        # update the variable with a wrong value, given that is encrypted\n        Var = models.Variable\n        (self.session.query(Var)\n            .filter(Var.key == self.variable['key'])\n            .update({\n                'val': 'failed_value_not_encrypted'\n            }, synchronize_session=False))\n        self.session.commit()\n\n        # retrieve Variables page, should not fail and contain the Invalid\n        # label for the variable\n        resp = self.client.get('/variable/list', follow_redirects=True)\n        self.check_content_in_response(\n            '<span class=\"label label-danger\">Invalid</span>', resp)\n\n    def test_xss_prevention(self):\n        xss = \"/variable/list/<img%20src=''%20onerror='alert(1);'>\"\n\n        resp = self.client.get(\n            xss,\n            follow_redirects=True,\n        )\n        self.assertEqual(resp.status_code, 404)\n        self.assertNotIn(\"<img src='' onerror='alert(1);'>\",\n                         resp.data.decode(\"utf-8\"))\n\n    def test_import_variables_no_file(self):\n        resp = self.client.post('/variable/varimport',\n                                follow_redirects=True)\n        self.check_content_in_response('Missing file or syntax error.', resp)\n\n    def test_import_variables_failed(self):\n        content = '{\"str_key\": \"str_value\"}'\n\n        with mock.patch('airflow.models.Variable.set') as set_mock:\n            set_mock.side_effect = UnicodeEncodeError\n            self.assertEqual(self.session.query(models.Variable).count(), 0)\n\n            try:\n                # python 3+\n                bytes_content = io.BytesIO(bytes(content, encoding='utf-8'))\n            except TypeError:\n                # python 2.7\n                bytes_content = io.BytesIO(bytes(content))\n\n            resp = self.client.post('/variable/varimport',\n                                    data={'file': (bytes_content, 'test.json')},\n                                    follow_redirects=True)\n            self.check_content_in_response('1 variable(s) failed to be updated.', resp)\n\n    def test_import_variables_success(self):\n        self.assertEqual(self.session.query(models.Variable).count(), 0)\n\n        content = ('{\"str_key\": \"str_value\", \"int_key\": 60,'\n                   '\"list_key\": [1, 2], \"dict_key\": {\"k_a\": 2, \"k_b\": 3}}')\n        try:\n            # python 3+\n            bytes_content = io.BytesIO(bytes(content, encoding='utf-8'))\n        except TypeError:\n            # python 2.7\n            bytes_content = io.BytesIO(bytes(content))\n\n        resp = self.client.post('/variable/varimport',\n                                data={'file': (bytes_content, 'test.json')},\n                                follow_redirects=True)\n        self.check_content_in_response('4 variable(s) successfully updated.', resp)", "target": 0}, {"function": "class TestPoolModelView(TestBase):\n    def setUp(self):\n        super().setUp()\n        self.pool = {\n            'pool': 'test-pool',\n            'slots': 777,\n            'description': 'test-pool-description',\n        }\n\n    def tearDown(self):\n        self.clear_table(models.Pool)\n        super().tearDown()\n\n    def test_create_pool_with_same_name(self):\n        # create test pool\n        resp = self.client.post('/pool/add',\n                                data=self.pool,\n                                follow_redirects=True)\n        self.check_content_in_response('Added Row', resp)\n\n        # create pool with the same name\n        resp = self.client.post('/pool/add',\n                                data=self.pool,\n                                follow_redirects=True)\n        self.check_content_in_response('Already exists.', resp)\n\n    def test_create_pool_with_empty_name(self):\n\n        self.pool['pool'] = ''\n        resp = self.client.post('/pool/add',\n                                data=self.pool,\n                                follow_redirects=True)\n        self.check_content_in_response('This field is required.', resp)\n\n    def test_odd_name(self):\n        self.pool['pool'] = 'test-pool<script></script>'\n        self.session.add(models.Pool(**self.pool))\n        self.session.commit()\n        resp = self.client.get('/pool/list/')\n        self.check_content_in_response('test-pool&lt;script&gt;', resp)\n        self.check_content_not_in_response('test-pool<script>', resp)\n\n    def test_list(self):\n        self.pool['pool'] = 'test-pool'\n        self.session.add(models.Pool(**self.pool))\n        self.session.commit()\n        resp = self.client.get('/pool/list/')\n        # We should see this link\n        with self.app.test_request_context():\n            url = url_for('TaskInstanceModelView.list', _flt_3_pool='test-pool', _flt_3_state='running')\n            used_tag = Markup(\"<a href='{url}'>{slots}</a>\").format(url=url, slots=0)\n\n            url = url_for('TaskInstanceModelView.list', _flt_3_pool='test-pool', _flt_3_state='queued')\n            queued_tag = Markup(\"<a href='{url}'>{slots}</a>\").format(url=url, slots=0)\n        self.check_content_in_response(used_tag, resp)\n        self.check_content_in_response(queued_tag, resp)", "target": 0}, {"function": "class TestMountPoint(unittest.TestCase):\n    @classmethod\n    def setUpClass(cls):\n        application.app = None\n        application.appbuilder = None\n        conf.set(\"webserver\", \"base_url\", \"http://localhost/test\")\n        app = application.cached_app(config={'WTF_CSRF_ENABLED': False}, session=Session, testing=True)\n        cls.client = Client(app, BaseResponse)\n\n    @classmethod\n    def tearDownClass(cls):\n        application.app = None\n        application.appbuilder = None\n\n    def test_mount(self):\n        # Test an endpoint that doesn't need auth!\n        resp = self.client.get('/test/health')\n        self.assertEqual(resp.status_code, 200)\n        self.assertIn(b\"healthy\", resp.data)\n\n    def test_not_found(self):\n        resp = self.client.get('/', follow_redirects=True)\n        self.assertEqual(resp.status_code, 404)\n\n    def test_index(self):\n        resp = self.client.get('/test/')\n        self.assertEqual(resp.status_code, 302)\n        self.assertEqual(resp.headers['Location'], 'http://localhost/test/home')", "target": 0}, {"function": "class TestAirflowBaseViews(TestBase):\n    EXAMPLE_DAG_DEFAULT_DATE = dates.days_ago(2)\n    run_id = \"test_{}\".format(models.DagRun.id_for_date(EXAMPLE_DAG_DEFAULT_DATE))\n\n    @classmethod\n    def setUpClass(cls):\n        super().setUpClass()\n        dagbag = models.DagBag(include_examples=True)\n        for dag in dagbag.dags.values():\n            dag.sync_to_db()\n\n    def setUp(self):\n        super().setUp()\n        self.logout()\n        self.login()\n        self.cleanup_dagruns()\n        self.prepare_dagruns()\n\n    def cleanup_dagruns(self):\n        DR = models.DagRun\n        dag_ids = ['example_bash_operator',\n                   'example_subdag_operator',\n                   'example_xcom']\n        (self.session\n             .query(DR)\n             .filter(DR.dag_id.in_(dag_ids))\n             .filter(DR.run_id == self.run_id)\n             .delete(synchronize_session='fetch'))\n        self.session.commit()\n\n    def prepare_dagruns(self):\n        dagbag = models.DagBag(include_examples=True)\n        self.bash_dag = dagbag.dags['example_bash_operator']\n        self.sub_dag = dagbag.dags['example_subdag_operator']\n        self.xcom_dag = dagbag.dags['example_xcom']\n\n        self.bash_dagrun = self.bash_dag.create_dagrun(\n            run_id=self.run_id,\n            execution_date=self.EXAMPLE_DAG_DEFAULT_DATE,\n            start_date=timezone.utcnow(),\n            state=State.RUNNING)\n\n        self.sub_dagrun = self.sub_dag.create_dagrun(\n            run_id=self.run_id,\n            execution_date=self.EXAMPLE_DAG_DEFAULT_DATE,\n            start_date=timezone.utcnow(),\n            state=State.RUNNING)\n\n        self.xcom_dagrun = self.xcom_dag.create_dagrun(\n            run_id=self.run_id,\n            execution_date=self.EXAMPLE_DAG_DEFAULT_DATE,\n            start_date=timezone.utcnow(),\n            state=State.RUNNING)\n\n    def test_index(self):\n        resp = self.client.get('/', follow_redirects=True)\n        self.check_content_in_response('DAGs', resp)\n\n    def test_health(self):\n\n        # case-1: healthy scheduler status\n        last_scheduler_heartbeat_for_testing_1 = timezone.utcnow()\n        self.session.add(BaseJob(job_type='SchedulerJob',\n                                 state='running',\n                                 latest_heartbeat=last_scheduler_heartbeat_for_testing_1))\n        self.session.commit()\n\n        resp_json = json.loads(self.client.get('health', follow_redirects=True).data.decode('utf-8'))\n\n        self.assertEqual('healthy', resp_json['metadatabase']['status'])\n        self.assertEqual('healthy', resp_json['scheduler']['status'])\n        self.assertEqual(last_scheduler_heartbeat_for_testing_1.isoformat(),\n                         resp_json['scheduler']['latest_scheduler_heartbeat'])\n\n        self.session.query(BaseJob).\\\n            filter(BaseJob.job_type == 'SchedulerJob',\n                   BaseJob.state == 'running',\n                   BaseJob.latest_heartbeat == last_scheduler_heartbeat_for_testing_1).\\\n            delete()\n        self.session.commit()\n\n        # case-2: unhealthy scheduler status - scenario 1 (SchedulerJob is running too slowly)\n        last_scheduler_heartbeat_for_testing_2 = timezone.utcnow() - timedelta(minutes=1)\n        (self.session\n             .query(BaseJob)\n             .filter(BaseJob.job_type == 'SchedulerJob')\n             .update({'latest_heartbeat': last_scheduler_heartbeat_for_testing_2 - timedelta(seconds=1)}))\n        self.session.add(BaseJob(job_type='SchedulerJob',\n                                 state='running',\n                                 latest_heartbeat=last_scheduler_heartbeat_for_testing_2))\n        self.session.commit()\n\n        resp_json = json.loads(self.client.get('health', follow_redirects=True).data.decode('utf-8'))\n\n        self.assertEqual('healthy', resp_json['metadatabase']['status'])\n        self.assertEqual('unhealthy', resp_json['scheduler']['status'])\n        self.assertEqual(last_scheduler_heartbeat_for_testing_2.isoformat(),\n                         resp_json['scheduler']['latest_scheduler_heartbeat'])\n\n        self.session.query(BaseJob).\\\n            filter(BaseJob.job_type == 'SchedulerJob',\n                   BaseJob.state == 'running',\n                   BaseJob.latest_heartbeat == last_scheduler_heartbeat_for_testing_2).\\\n            delete()\n        self.session.commit()\n\n        # case-3: unhealthy scheduler status - scenario 2 (no running SchedulerJob)\n        self.session.query(BaseJob).\\\n            filter(BaseJob.job_type == 'SchedulerJob',\n                   BaseJob.state == 'running').\\\n            delete()\n        self.session.commit()\n\n        resp_json = json.loads(self.client.get('health', follow_redirects=True).data.decode('utf-8'))\n\n        self.assertEqual('healthy', resp_json['metadatabase']['status'])\n        self.assertEqual('unhealthy', resp_json['scheduler']['status'])\n        self.assertIsNone(None, resp_json['scheduler']['latest_scheduler_heartbeat'])\n\n    def test_home(self):\n        resp = self.client.get('home', follow_redirects=True)\n        self.check_content_in_response('DAGs', resp)\n\n    def test_task(self):\n        url = ('task?task_id=runme_0&dag_id=example_bash_operator&execution_date={}'\n               .format(self.percent_encode(self.EXAMPLE_DAG_DEFAULT_DATE)))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('Task Instance Details', resp)\n\n    def test_xcom(self):\n        url = ('xcom?task_id=runme_0&dag_id=example_bash_operator&execution_date={}'\n               .format(self.percent_encode(self.EXAMPLE_DAG_DEFAULT_DATE)))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('XCom', resp)\n\n    def test_edit_dagrun_page(self):\n        resp = self.client.get('dagmodel/edit/example_bash_operator', follow_redirects=False)\n        self.assertEqual(resp.status_code, 200)\n\n    def test_edit_dagrun_url(self):\n        with self.app.test_request_context():\n            url = url_for('DagModelView.edit', pk='example_bash_operator')\n            self.assertEqual(url, '/dagmodel/edit/example_bash_operator')\n\n    def test_rendered(self):\n        url = ('rendered?task_id=runme_0&dag_id=example_bash_operator&execution_date={}'\n               .format(self.percent_encode(self.EXAMPLE_DAG_DEFAULT_DATE)))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('Rendered Template', resp)\n\n    def test_blocked(self):\n        url = 'blocked'\n        resp = self.client.get(url, follow_redirects=True)\n        self.assertEqual(200, resp.status_code)\n\n    def test_dag_stats(self):\n        resp = self.client.get('dag_stats', follow_redirects=True)\n        self.assertEqual(resp.status_code, 200)\n\n    def test_task_stats(self):\n        resp = self.client.get('task_stats', follow_redirects=True)\n        self.assertEqual(resp.status_code, 200)\n\n    def test_dag_details(self):\n        url = 'dag_details?dag_id=example_bash_operator'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('DAG details', resp)\n\n    def test_dag_details_subdag(self):\n        url = 'dag_details?dag_id=example_subdag_operator.section-1'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('DAG details', resp)\n\n    def test_graph(self):\n        url = 'graph?dag_id=example_bash_operator'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('runme_1', resp)\n\n    def test_last_dagruns(self):\n        resp = self.client.get('last_dagruns', follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n\n    def test_tree(self):\n        url = 'tree?dag_id=example_bash_operator'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('runme_1', resp)\n\n    def test_tree_subdag(self):\n        url = 'tree?dag_id=example_subdag_operator.section-1'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('section-1-task-1', resp)\n\n    def test_duration(self):\n        url = 'duration?days=30&dag_id=example_bash_operator'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n\n    def test_duration_missing(self):\n        url = 'duration?days=30&dag_id=missing_dag'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('seems to be missing', resp)\n\n    def test_tries(self):\n        url = 'tries?days=30&dag_id=example_bash_operator'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n\n    def test_landing_times(self):\n        url = 'landing_times?days=30&dag_id=example_bash_operator'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n\n    def test_gantt(self):\n        url = 'gantt?dag_id=example_bash_operator'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n\n    def test_code(self):\n        url = 'code?dag_id=example_bash_operator'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n\n    def test_paused(self):\n        url = 'paused?dag_id=example_bash_operator&is_paused=false'\n        resp = self.client.post(url, follow_redirects=True)\n        self.check_content_in_response('OK', resp)\n\n    def test_failed(self):\n        form = dict(\n            task_id=\"run_this_last\",\n            dag_id=\"example_bash_operator\",\n            execution_date=self.EXAMPLE_DAG_DEFAULT_DATE,\n            upstream=\"false\",\n            downstream=\"false\",\n            future=\"false\",\n            past=\"false\",\n        )\n        resp = self.client.post(\"failed\", data=form)\n        self.check_content_in_response('Wait a minute', resp)\n\n    def test_success(self):\n        form = dict(\n            task_id=\"run_this_last\",\n            dag_id=\"example_bash_operator\",\n            execution_date=self.EXAMPLE_DAG_DEFAULT_DATE,\n            upstream=\"false\",\n            downstream=\"false\",\n            future=\"false\",\n            past=\"false\",\n        )\n        resp = self.client.post('success', data=form)\n        self.check_content_in_response('Wait a minute', resp)\n\n    def test_clear(self):\n        form = dict(\n            task_id=\"runme_1\",\n            dag_id=\"example_bash_operator\",\n            execution_date=self.EXAMPLE_DAG_DEFAULT_DATE,\n            upstream=\"false\",\n            downstream=\"false\",\n            future=\"false\",\n            past=\"false\",\n            only_failed=\"false\",\n        )\n        resp = self.client.post(\"clear\", data=form)\n        self.check_content_in_response(['example_bash_operator', 'Wait a minute'], resp)\n\n    def test_run(self):\n        form = dict(\n            task_id=\"runme_0\",\n            dag_id=\"example_bash_operator\",\n            ignore_all_deps=\"false\",\n            ignore_ti_state=\"true\",\n            execution_date=self.EXAMPLE_DAG_DEFAULT_DATE,\n        )\n        resp = self.client.post('run', data=form)\n        self.check_content_in_response('', resp, resp_code=302)\n\n    def test_refresh(self):\n        resp = self.client.post('refresh?dag_id=example_bash_operator')\n        self.check_content_in_response('', resp, resp_code=302)\n\n    def test_refresh_all(self):\n        resp = self.client.post(\"/refresh_all\",\n                                follow_redirects=True)\n        self.check_content_in_response('', resp, resp_code=200)\n\n    def test_delete_dag_button_normal(self):\n        resp = self.client.get('/', follow_redirects=True)\n        self.check_content_in_response('/delete?dag_id=example_bash_operator', resp)\n        self.check_content_in_response(\"return confirmDeleteDag(this, 'example_bash_operator')\", resp)\n\n    def test_delete_dag_button_for_dag_on_scheduler_only(self):\n        # Test for JIRA AIRFLOW-3233 (PR 4069):\n        # The delete-dag URL should be generated correctly for DAGs\n        # that exist on the scheduler (DB) but not the webserver DagBag\n\n        test_dag_id = \"non_existent_dag\"\n\n        DM = models.DagModel\n        self.session.query(DM).filter(DM.dag_id == 'example_bash_operator').update({'dag_id': test_dag_id})\n        self.session.commit()\n\n        resp = self.client.get('/', follow_redirects=True)\n        self.check_content_in_response('/delete?dag_id={}'.format(test_dag_id), resp)\n        self.check_content_in_response(\"return confirmDeleteDag(this, '{}')\".format(test_dag_id), resp)\n\n        self.session.query(DM).filter(DM.dag_id == test_dag_id).update({'dag_id': 'example_bash_operator'})\n        self.session.commit()", "target": 0}, {"function": "class TestConfigurationView(TestBase):\n    def test_configuration_do_not_expose_config(self):\n        self.logout()\n        self.login()\n        with conf_vars({('webserver', 'expose_config'): 'False'}):\n            resp = self.client.get('configuration', follow_redirects=True)\n        self.check_content_in_response(\n            ['Airflow Configuration', '# Your Airflow administrator chose not to expose the configuration, '\n                                      'most likely for security reasons.'], resp)\n\n    def test_configuration_expose_config(self):\n        self.logout()\n        self.login()\n        with conf_vars({('webserver', 'expose_config'): 'True'}):\n            resp = self.client.get('configuration', follow_redirects=True)\n        self.check_content_in_response(\n            ['Airflow Configuration', 'Running Configuration'], resp)", "target": 0}, {"function": "class TestLogView(TestBase):\n    DAG_ID = 'dag_for_testing_log_view'\n    TASK_ID = 'task_for_testing_log_view'\n    DEFAULT_DATE = timezone.datetime(2017, 9, 1)\n    ENDPOINT = 'log?dag_id={dag_id}&task_id={task_id}&' \\\n               'execution_date={execution_date}'.format(dag_id=DAG_ID,\n                                                        task_id=TASK_ID,\n                                                        execution_date=DEFAULT_DATE)\n\n    def setUp(self):\n        # Make sure that the configure_logging is not cached\n        self.old_modules = dict(sys.modules)\n\n        # Create a custom logging configuration\n        logging_config = copy.deepcopy(DEFAULT_LOGGING_CONFIG)\n        current_dir = os.path.dirname(os.path.abspath(__file__))\n        logging_config['handlers']['task']['base_log_folder'] = os.path.normpath(\n            os.path.join(current_dir, 'test_logs'))\n\n        logging_config['handlers']['task']['filename_template'] = \\\n            '{{ ti.dag_id }}/{{ ti.task_id }}/' \\\n            '{{ ts | replace(\":\", \".\") }}/{{ try_number }}.log'\n\n        # Write the custom logging configuration to a file\n        self.settings_folder = tempfile.mkdtemp()\n        settings_file = os.path.join(self.settings_folder, \"airflow_local_settings.py\")\n        new_logging_file = \"LOGGING_CONFIG = {}\".format(logging_config)\n        with open(settings_file, 'w') as handle:\n            handle.writelines(new_logging_file)\n        sys.path.append(self.settings_folder)\n        conf.set('core', 'logging_config_class', 'airflow_local_settings.LOGGING_CONFIG')\n\n        self.app, self.appbuilder = application.create_app(session=Session, testing=True)\n        self.app.config['WTF_CSRF_ENABLED'] = False\n        self.client = self.app.test_client()\n        settings.configure_orm()\n        self.login()\n\n        from airflow.www.views import dagbag\n        dag = DAG(self.DAG_ID, start_date=self.DEFAULT_DATE)\n        dag.sync_to_db()\n        task = DummyOperator(task_id=self.TASK_ID, dag=dag)\n        dagbag.bag_dag(dag, parent_dag=dag, root_dag=dag)\n        with create_session() as session:\n            self.ti = TaskInstance(task=task, execution_date=self.DEFAULT_DATE)\n            self.ti.try_number = 1\n            session.merge(self.ti)\n\n    def tearDown(self):\n        logging.config.dictConfig(DEFAULT_LOGGING_CONFIG)\n        self.clear_table(TaskInstance)\n\n        # Remove any new modules imported during the test run. This lets us\n        # import the same source files for more than one test.\n        for m in [m for m in sys.modules if m not in self.old_modules]:\n            del sys.modules[m]\n\n        sys.path.remove(self.settings_folder)\n        shutil.rmtree(self.settings_folder)\n        conf.set('core', 'logging_config_class', '')\n\n        self.logout()\n        super().tearDown()\n\n    @parameterized.expand([\n        [State.NONE, 0, 0],\n        [State.UP_FOR_RETRY, 2, 2],\n        [State.UP_FOR_RESCHEDULE, 0, 1],\n        [State.UP_FOR_RESCHEDULE, 1, 2],\n        [State.RUNNING, 1, 1],\n        [State.SUCCESS, 1, 1],\n        [State.FAILED, 3, 3],\n    ])\n    def test_get_file_task_log(self, state, try_number, expected_num_logs_visible):\n        with create_session() as session:\n            self.ti.state = state\n            self.ti.try_number = try_number\n            session.merge(self.ti)\n\n        response = self.client.get(\n            TestLogView.ENDPOINT, data=dict(\n                username='test',\n                password='test'), follow_redirects=True)\n        self.assertEqual(response.status_code, 200)\n        self.assertIn('Log by attempts', response.data.decode('utf-8'))\n        for num in range(1, expected_num_logs_visible + 1):\n            self.assertIn('try-{}'.format(num), response.data.decode('utf-8'))\n        self.assertNotIn('try-0', response.data.decode('utf-8'))\n        self.assertNotIn('try-{}'.format(expected_num_logs_visible + 1), response.data.decode('utf-8'))\n\n    def test_get_logs_with_metadata_as_download_file(self):\n        url_template = \"get_logs_with_metadata?dag_id={}&\" \\\n                       \"task_id={}&execution_date={}&\" \\\n                       \"try_number={}&metadata={}&format=file\"\n        try_number = 1\n        url = url_template.format(self.DAG_ID,\n                                  self.TASK_ID,\n                                  quote_plus(self.DEFAULT_DATE.isoformat()),\n                                  try_number,\n                                  json.dumps({}))\n        response = self.client.get(url)\n        expected_filename = '{}/{}/{}/{}.log'.format(self.DAG_ID,\n                                                     self.TASK_ID,\n                                                     self.DEFAULT_DATE.isoformat(),\n                                                     try_number)\n\n        content_disposition = response.headers.get('Content-Disposition')\n        self.assertTrue(content_disposition.startswith('attachment'))\n        self.assertTrue(expected_filename in content_disposition)\n        self.assertEqual(200, response.status_code)\n        self.assertIn('Log for testing.', response.data.decode('utf-8'))\n\n    def test_get_logs_with_metadata_as_download_large_file(self):\n        with mock.patch(\"airflow.utils.log.file_task_handler.FileTaskHandler.read\") as read_mock:\n            first_return = (['1st line'], [{}])\n            second_return = (['2nd line'], [{'end_of_log': False}])\n            third_return = (['3rd line'], [{'end_of_log': True}])\n            fourth_return = (['should never be read'], [{'end_of_log': True}])\n            read_mock.side_effect = [first_return, second_return, third_return, fourth_return]\n            url_template = \"get_logs_with_metadata?dag_id={}&\" \\\n                           \"task_id={}&execution_date={}&\" \\\n                           \"try_number={}&metadata={}&format=file\"\n            try_number = 1\n            url = url_template.format(self.DAG_ID,\n                                      self.TASK_ID,\n                                      quote_plus(self.DEFAULT_DATE.isoformat()),\n                                      try_number,\n                                      json.dumps({}))\n            response = self.client.get(url)\n\n            self.assertIn('1st line', response.data.decode('utf-8'))\n            self.assertIn('2nd line', response.data.decode('utf-8'))\n            self.assertIn('3rd line', response.data.decode('utf-8'))\n            self.assertNotIn('should never be read', response.data.decode('utf-8'))\n\n    def test_get_logs_with_metadata(self):\n        url_template = \"get_logs_with_metadata?dag_id={}&\" \\\n                       \"task_id={}&execution_date={}&\" \\\n                       \"try_number={}&metadata={}\"\n        response = \\\n            self.client.get(url_template.format(self.DAG_ID,\n                                                self.TASK_ID,\n                                                quote_plus(self.DEFAULT_DATE.isoformat()),\n                                                1,\n                                                json.dumps({})), data=dict(\n                                                    username='test',\n                                                    password='test'),\n                            follow_redirects=True)\n\n        self.assertIn('\"message\":', response.data.decode('utf-8'))\n        self.assertIn('\"metadata\":', response.data.decode('utf-8'))\n        self.assertIn('Log for testing.', response.data.decode('utf-8'))\n        self.assertEqual(200, response.status_code)\n\n    def test_get_logs_with_null_metadata(self):\n        url_template = \"get_logs_with_metadata?dag_id={}&\" \\\n                       \"task_id={}&execution_date={}&\" \\\n                       \"try_number={}&metadata=null\"\n        response = \\\n            self.client.get(url_template.format(self.DAG_ID,\n                                                self.TASK_ID,\n                                                quote_plus(self.DEFAULT_DATE.isoformat()),\n                                                1), data=dict(\n                                                    username='test',\n                                                    password='test'),\n                            follow_redirects=True)\n\n        self.assertIn('\"message\":', response.data.decode('utf-8'))\n        self.assertIn('\"metadata\":', response.data.decode('utf-8'))\n        self.assertIn('Log for testing.', response.data.decode('utf-8'))\n        self.assertEqual(200, response.status_code)", "target": 0}, {"function": "class TestVersionView(TestBase):\n    def test_version(self):\n        resp = self.client.get('version', data=dict(\n            username='test',\n            password='test'\n        ), follow_redirects=True)\n        self.check_content_in_response('Version Info', resp)", "target": 0}, {"function": "class ViewWithDateTimeAndNumRunsAndDagRunsFormTester:\n    DAG_ID = 'dag_for_testing_dt_nr_dr_form'\n    DEFAULT_DATE = datetime(2017, 9, 1)\n    RUNS_DATA = [\n        ('dag_run_for_testing_dt_nr_dr_form_4', datetime(2018, 4, 4)),\n        ('dag_run_for_testing_dt_nr_dr_form_3', datetime(2018, 3, 3)),\n        ('dag_run_for_testing_dt_nr_dr_form_2', datetime(2018, 2, 2)),\n        ('dag_run_for_testing_dt_nr_dr_form_1', datetime(2018, 1, 1)),\n    ]\n\n    def __init__(self, test, endpoint):\n        self.test = test\n        self.endpoint = endpoint\n\n    def setUp(self):\n        from airflow.www.views import dagbag\n        from airflow.utils.state import State\n        dag = DAG(self.DAG_ID, start_date=self.DEFAULT_DATE)\n        dagbag.bag_dag(dag, parent_dag=dag, root_dag=dag)\n        self.runs = []\n        for rd in self.RUNS_DATA:\n            run = dag.create_dagrun(\n                run_id=rd[0],\n                execution_date=rd[1],\n                state=State.SUCCESS,\n                external_trigger=True\n            )\n            self.runs.append(run)\n\n    def tearDown(self):\n        self.test.session.query(DagRun).filter(\n            DagRun.dag_id == self.DAG_ID).delete()\n        self.test.session.commit()\n        self.test.session.close()\n\n    def assertBaseDateAndNumRuns(self, base_date, num_runs, data):\n        self.test.assertNotIn('name=\"base_date\" value=\"{}\"'.format(base_date), data)\n        self.test.assertNotIn('<option selected=\"\" value=\"{}\">{}</option>'.format(\n            num_runs, num_runs), data)\n\n    def assertRunIsNotInDropdown(self, run, data):\n        self.test.assertNotIn(run.execution_date.isoformat(), data)\n        self.test.assertNotIn(run.run_id, data)\n\n    def assertRunIsInDropdownNotSelected(self, run, data):\n        self.test.assertIn('<option value=\"{}\">{}</option>'.format(\n            run.execution_date.isoformat(), run.run_id), data)\n\n    def assertRunIsSelected(self, run, data):\n        self.test.assertIn('<option selected value=\"{}\">{}</option>'.format(\n            run.execution_date.isoformat(), run.run_id), data)\n\n    def test_with_default_parameters(self):\n        \"\"\"\n        Tests view with no URL parameter.\n        Should show all dag runs in the drop down.\n        Should select the latest dag run.\n        Should set base date to current date (not asserted)\n        \"\"\"\n        response = self.test.client.get(\n            self.endpoint, data=dict(\n                username='test',\n                password='test'), follow_redirects=True)\n        self.test.assertEqual(response.status_code, 200)\n        data = response.data.decode('utf-8')\n        self.test.assertIn('Base date:', data)\n        self.test.assertIn('Number of runs:', data)\n        self.assertRunIsSelected(self.runs[0], data)\n        self.assertRunIsInDropdownNotSelected(self.runs[1], data)\n        self.assertRunIsInDropdownNotSelected(self.runs[2], data)\n        self.assertRunIsInDropdownNotSelected(self.runs[3], data)\n\n    def test_with_execution_date_parameter_only(self):\n        \"\"\"\n        Tests view with execution_date URL parameter.\n        Scenario: click link from dag runs view.\n        Should only show dag runs older than execution_date in the drop down.\n        Should select the particular dag run.\n        Should set base date to execution date.\n        \"\"\"\n        response = self.test.client.get(\n            self.endpoint + '&execution_date={}'.format(\n                self.runs[1].execution_date.isoformat()),\n            data=dict(\n                username='test',\n                password='test'\n            ), follow_redirects=True\n        )\n        self.test.assertEqual(response.status_code, 200)\n        data = response.data.decode('utf-8')\n        self.assertBaseDateAndNumRuns(\n            self.runs[1].execution_date,\n            conf.getint('webserver', 'default_dag_run_display_number'),\n            data)\n        self.assertRunIsNotInDropdown(self.runs[0], data)\n        self.assertRunIsSelected(self.runs[1], data)\n        self.assertRunIsInDropdownNotSelected(self.runs[2], data)\n        self.assertRunIsInDropdownNotSelected(self.runs[3], data)\n\n    def test_with_base_date_and_num_runs_parmeters_only(self):\n        \"\"\"\n        Tests view with base_date and num_runs URL parameters.\n        Should only show dag runs older than base_date in the drop down,\n        limited to num_runs.\n        Should select the latest dag run.\n        Should set base date and num runs to submitted values.\n        \"\"\"\n        response = self.test.client.get(\n            self.endpoint + '&base_date={}&num_runs=2'.format(\n                self.runs[1].execution_date.isoformat()),\n            data=dict(\n                username='test',\n                password='test'\n            ), follow_redirects=True\n        )\n        self.test.assertEqual(response.status_code, 200)\n        data = response.data.decode('utf-8')\n        self.assertBaseDateAndNumRuns(self.runs[1].execution_date, 2, data)\n        self.assertRunIsNotInDropdown(self.runs[0], data)\n        self.assertRunIsSelected(self.runs[1], data)\n        self.assertRunIsInDropdownNotSelected(self.runs[2], data)\n        self.assertRunIsNotInDropdown(self.runs[3], data)\n\n    def test_with_base_date_and_num_runs_and_execution_date_outside(self):\n        \"\"\"\n        Tests view with base_date and num_runs and execution-date URL parameters.\n        Scenario: change the base date and num runs and press \"Go\",\n        the selected execution date is outside the new range.\n        Should only show dag runs older than base_date in the drop down.\n        Should select the latest dag run within the range.\n        Should set base date and num runs to submitted values.\n        \"\"\"\n        response = self.test.client.get(\n            self.endpoint + '&base_date={}&num_runs=42&execution_date={}'.format(\n                self.runs[1].execution_date.isoformat(),\n                self.runs[0].execution_date.isoformat()),\n            data=dict(\n                username='test',\n                password='test'\n            ), follow_redirects=True\n        )\n        self.test.assertEqual(response.status_code, 200)\n        data = response.data.decode('utf-8')\n        self.assertBaseDateAndNumRuns(self.runs[1].execution_date, 42, data)\n        self.assertRunIsNotInDropdown(self.runs[0], data)\n        self.assertRunIsSelected(self.runs[1], data)\n        self.assertRunIsInDropdownNotSelected(self.runs[2], data)\n        self.assertRunIsInDropdownNotSelected(self.runs[3], data)\n\n    def test_with_base_date_and_num_runs_and_execution_date_within(self):\n        \"\"\"\n        Tests view with base_date and num_runs and execution-date URL parameters.\n        Scenario: change the base date and num runs and press \"Go\",\n        the selected execution date is within the new range.\n        Should only show dag runs older than base_date in the drop down.\n        Should select the dag run with the execution date.\n        Should set base date and num runs to submitted values.\n        \"\"\"\n        response = self.test.client.get(\n            self.endpoint + '&base_date={}&num_runs=5&execution_date={}'.format(\n                self.runs[2].execution_date.isoformat(),\n                self.runs[3].execution_date.isoformat()),\n            data=dict(\n                username='test',\n                password='test'\n            ), follow_redirects=True\n        )\n        self.test.assertEqual(response.status_code, 200)\n        data = response.data.decode('utf-8')\n        self.assertBaseDateAndNumRuns(self.runs[2].execution_date, 5, data)\n        self.assertRunIsNotInDropdown(self.runs[0], data)\n        self.assertRunIsNotInDropdown(self.runs[1], data)\n        self.assertRunIsInDropdownNotSelected(self.runs[2], data)\n        self.assertRunIsSelected(self.runs[3], data)", "target": 0}, {"function": "class TestGraphView(TestBase):\n    GRAPH_ENDPOINT = '/graph?dag_id={dag_id}'.format(\n        dag_id=ViewWithDateTimeAndNumRunsAndDagRunsFormTester.DAG_ID\n    )\n\n    @classmethod\n    def setUpClass(cls):\n        super().setUpClass()\n\n    def setUp(self):\n        super().setUp()\n        self.tester = ViewWithDateTimeAndNumRunsAndDagRunsFormTester(\n            self, self.GRAPH_ENDPOINT)\n        self.tester.setUp()\n\n    def tearDown(self):\n        self.tester.tearDown()\n        super().tearDown()\n\n    @classmethod\n    def tearDownClass(cls):\n        super().tearDownClass()\n\n    def test_dt_nr_dr_form_default_parameters(self):\n        self.tester.test_with_default_parameters()\n\n    def test_dt_nr_dr_form_with_execution_date_parameter_only(self):\n        self.tester.test_with_execution_date_parameter_only()\n\n    def test_dt_nr_dr_form_with_base_date_and_num_runs_parmeters_only(self):\n        self.tester.test_with_base_date_and_num_runs_parmeters_only()\n\n    def test_dt_nr_dr_form_with_base_date_and_num_runs_and_execution_date_outside(self):\n        self.tester.test_with_base_date_and_num_runs_and_execution_date_outside()\n\n    def test_dt_nr_dr_form_with_base_date_and_num_runs_and_execution_date_within(self):\n        self.tester.test_with_base_date_and_num_runs_and_execution_date_within()", "target": 0}, {"function": "class TestGanttView(TestBase):\n    GANTT_ENDPOINT = '/gantt?dag_id={dag_id}'.format(\n        dag_id=ViewWithDateTimeAndNumRunsAndDagRunsFormTester.DAG_ID\n    )\n\n    @classmethod\n    def setUpClass(cls):\n        super().setUpClass()\n\n    def setUp(self):\n        super().setUp()\n        self.tester = ViewWithDateTimeAndNumRunsAndDagRunsFormTester(\n            self, self.GANTT_ENDPOINT)\n        self.tester.setUp()\n\n    def tearDown(self):\n        self.tester.tearDown()\n        super().tearDown()\n\n    @classmethod\n    def tearDownClass(cls):\n        super().tearDownClass()\n\n    def test_dt_nr_dr_form_default_parameters(self):\n        self.tester.test_with_default_parameters()\n\n    def test_dt_nr_dr_form_with_execution_date_parameter_only(self):\n        self.tester.test_with_execution_date_parameter_only()\n\n    def test_dt_nr_dr_form_with_base_date_and_num_runs_parmeters_only(self):\n        self.tester.test_with_base_date_and_num_runs_parmeters_only()\n\n    def test_dt_nr_dr_form_with_base_date_and_num_runs_and_execution_date_outside(self):\n        self.tester.test_with_base_date_and_num_runs_and_execution_date_outside()\n\n    def test_dt_nr_dr_form_with_base_date_and_num_runs_and_execution_date_within(self):\n        self.tester.test_with_base_date_and_num_runs_and_execution_date_within()", "target": 0}, {"function": "class TestDagACLView(TestBase):\n    \"\"\"\n    Test Airflow DAG acl\n    \"\"\"\n    default_date = timezone.datetime(2018, 6, 1)\n    run_id = \"test_{}\".format(models.DagRun.id_for_date(default_date))\n\n    @classmethod\n    def setUpClass(cls):\n        super().setUpClass()\n        dagbag = models.DagBag(include_examples=True)\n        for dag in dagbag.dags.values():\n            dag.sync_to_db()\n\n    def cleanup_dagruns(self):\n        DR = models.DagRun\n        dag_ids = ['example_bash_operator',\n                   'example_subdag_operator']\n        (self.session\n             .query(DR)\n             .filter(DR.dag_id.in_(dag_ids))\n             .filter(DR.run_id == self.run_id)\n             .delete(synchronize_session='fetch'))\n        self.session.commit()\n\n    def prepare_dagruns(self):\n        dagbag = models.DagBag(include_examples=True)\n        self.bash_dag = dagbag.dags['example_bash_operator']\n        self.sub_dag = dagbag.dags['example_subdag_operator']\n\n        self.bash_dagrun = self.bash_dag.create_dagrun(\n            run_id=self.run_id,\n            execution_date=self.default_date,\n            start_date=timezone.utcnow(),\n            state=State.RUNNING)\n\n        self.sub_dagrun = self.sub_dag.create_dagrun(\n            run_id=self.run_id,\n            execution_date=self.default_date,\n            start_date=timezone.utcnow(),\n            state=State.RUNNING)\n\n    def setUp(self):\n        super().setUp()\n        self.cleanup_dagruns()\n        self.prepare_dagruns()\n        self.logout()\n        self.appbuilder.sm.sync_roles()\n        self.add_permission_for_role()\n\n    def login(self, username=None, password=None):\n        role_admin = self.appbuilder.sm.find_role('Admin')\n        tester = self.appbuilder.sm.find_user(username='test')\n        if not tester:\n            self.appbuilder.sm.add_user(\n                username='test',\n                first_name='test',\n                last_name='test',\n                email='test@fab.org',\n                role=role_admin,\n                password='test')\n\n        role_user = self.appbuilder.sm.find_role('User')\n        test_user = self.appbuilder.sm.find_user(username='test_user')\n        if not test_user:\n            self.appbuilder.sm.add_user(\n                username='test_user',\n                first_name='test_user',\n                last_name='test_user',\n                email='test_user@fab.org',\n                role=role_user,\n                password='test_user')\n\n        role_viewer = self.appbuilder.sm.find_role('Viewer')\n        test_viewer = self.appbuilder.sm.find_user(username='test_viewer')\n        if not test_viewer:\n            self.appbuilder.sm.add_user(\n                username='test_viewer',\n                first_name='test_viewer',\n                last_name='test_viewer',\n                email='test_viewer@fab.org',\n                role=role_viewer,\n                password='test_viewer')\n\n        dag_acl_role = self.appbuilder.sm.add_role('dag_acl_tester')\n        dag_tester = self.appbuilder.sm.find_user(username='dag_tester')\n        if not dag_tester:\n            self.appbuilder.sm.add_user(\n                username='dag_tester',\n                first_name='dag_test',\n                last_name='dag_test',\n                email='dag_test@fab.org',\n                role=dag_acl_role,\n                password='dag_test')\n\n        # create an user without permission\n        dag_no_role = self.appbuilder.sm.add_role('dag_acl_faker')\n        dag_faker = self.appbuilder.sm.find_user(username='dag_faker')\n        if not dag_faker:\n            self.appbuilder.sm.add_user(\n                username='dag_faker',\n                first_name='dag_faker',\n                last_name='dag_faker',\n                email='dag_fake@fab.org',\n                role=dag_no_role,\n                password='dag_faker')\n\n        # create an user with only read permission\n        dag_read_only_role = self.appbuilder.sm.add_role('dag_acl_read_only')\n        dag_read_only = self.appbuilder.sm.find_user(username='dag_read_only')\n        if not dag_read_only:\n            self.appbuilder.sm.add_user(\n                username='dag_read_only',\n                first_name='dag_read_only',\n                last_name='dag_read_only',\n                email='dag_read_only@fab.org',\n                role=dag_read_only_role,\n                password='dag_read_only')\n\n        # create an user that has all dag access\n        all_dag_role = self.appbuilder.sm.add_role('all_dag_role')\n        all_dag_tester = self.appbuilder.sm.find_user(username='all_dag_user')\n        if not all_dag_tester:\n            self.appbuilder.sm.add_user(\n                username='all_dag_user',\n                first_name='all_dag_user',\n                last_name='all_dag_user',\n                email='all_dag_user@fab.org',\n                role=all_dag_role,\n                password='all_dag_user')\n\n        user = username if username else 'dag_tester'\n        passwd = password if password else 'dag_test'\n\n        return self.client.post('/login/', data=dict(\n            username=user,\n            password=passwd\n        ))\n\n    def logout(self):\n        return self.client.get('/logout/')\n\n    def add_permission_for_role(self):\n        self.logout()\n        self.login(username='test',\n                   password='test')\n        perm_on_dag = self.appbuilder.sm.\\\n            find_permission_view_menu('can_dag_edit', 'example_bash_operator')\n        dag_tester_role = self.appbuilder.sm.find_role('dag_acl_tester')\n        self.appbuilder.sm.add_permission_role(dag_tester_role, perm_on_dag)\n\n        perm_on_all_dag = self.appbuilder.sm.\\\n            find_permission_view_menu('can_dag_edit', 'all_dags')\n        all_dag_role = self.appbuilder.sm.find_role('all_dag_role')\n        self.appbuilder.sm.add_permission_role(all_dag_role, perm_on_all_dag)\n\n        role_user = self.appbuilder.sm.find_role('User')\n        self.appbuilder.sm.add_permission_role(role_user, perm_on_all_dag)\n\n        read_only_perm_on_dag = self.appbuilder.sm.\\\n            find_permission_view_menu('can_dag_read', 'example_bash_operator')\n        dag_read_only_role = self.appbuilder.sm.find_role('dag_acl_read_only')\n        self.appbuilder.sm.add_permission_role(dag_read_only_role, read_only_perm_on_dag)\n\n    def test_permission_exist(self):\n        self.logout()\n        self.login(username='test',\n                   password='test')\n        test_view_menu = self.appbuilder.sm.find_view_menu('example_bash_operator')\n        perms_views = self.appbuilder.sm.find_permissions_view_menu(test_view_menu)\n        self.assertEqual(len(perms_views), 2)\n        # each dag view will create one write, and one read permission\n        self.assertTrue(str(perms_views[0]).startswith('can dag'))\n        self.assertTrue(str(perms_views[1]).startswith('can dag'))\n\n    def test_role_permission_associate(self):\n        self.logout()\n        self.login(username='test',\n                   password='test')\n        test_role = self.appbuilder.sm.find_role('dag_acl_tester')\n        perms = {str(perm) for perm in test_role.permissions}\n        self.assertIn('can dag edit on example_bash_operator', perms)\n        self.assertNotIn('can dag read on example_bash_operator', perms)\n\n    def test_index_success(self):\n        self.logout()\n        self.login()\n        resp = self.client.get('/', follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n\n    def test_index_failure(self):\n        self.logout()\n        self.login()\n        resp = self.client.get('/', follow_redirects=True)\n        # The user can only access/view example_bash_operator dag.\n        self.check_content_not_in_response('example_subdag_operator', resp)\n\n    def test_index_for_all_dag_user(self):\n        self.logout()\n        self.login(username='all_dag_user',\n                   password='all_dag_user')\n        resp = self.client.get('/', follow_redirects=True)\n        # The all dag user can access/view all dags.\n        self.check_content_in_response('example_subdag_operator', resp)\n        self.check_content_in_response('example_bash_operator', resp)\n\n    def test_dag_stats_success(self):\n        self.logout()\n        self.login()\n        resp = self.client.get('dag_stats', follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n\n    def test_dag_stats_failure(self):\n        self.logout()\n        self.login()\n        resp = self.client.get('dag_stats', follow_redirects=True)\n        self.check_content_not_in_response('example_subdag_operator', resp)\n\n    def test_dag_stats_success_for_all_dag_user(self):\n        self.logout()\n        self.login(username='all_dag_user',\n                   password='all_dag_user')\n        resp = self.client.get('dag_stats', follow_redirects=True)\n        self.check_content_in_response('example_subdag_operator', resp)\n        self.check_content_in_response('example_bash_operator', resp)\n\n    def test_task_stats_success(self):\n        self.logout()\n        self.login()\n        resp = self.client.get('task_stats', follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n\n    def test_task_stats_failure(self):\n        self.logout()\n        self.login()\n        resp = self.client.get('task_stats', follow_redirects=True)\n        self.check_content_not_in_response('example_subdag_operator', resp)\n\n    def test_task_stats_success_for_all_dag_user(self):\n        self.logout()\n        self.login(username='all_dag_user',\n                   password='all_dag_user')\n        resp = self.client.get('task_stats', follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n        self.check_content_in_response('example_subdag_operator', resp)\n\n    def test_code_success(self):\n        self.logout()\n        self.login()\n        url = 'code?dag_id=example_bash_operator'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n\n    def test_code_failure(self):\n        self.logout()\n        self.login(username='dag_faker',\n                   password='dag_faker')\n        url = 'code?dag_id=example_bash_operator'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_not_in_response('example_bash_operator', resp)\n\n    def test_code_success_for_all_dag_user(self):\n        self.logout()\n        self.login(username='all_dag_user',\n                   password='all_dag_user')\n        url = 'code?dag_id=example_bash_operator'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n\n        url = 'code?dag_id=example_subdag_operator'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('example_subdag_operator', resp)\n\n    def test_dag_details_success(self):\n        self.logout()\n        self.login()\n        url = 'dag_details?dag_id=example_bash_operator'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('DAG details', resp)\n\n    def test_dag_details_failure(self):\n        self.logout()\n        self.login(username='dag_faker',\n                   password='dag_faker')\n        url = 'dag_details?dag_id=example_bash_operator'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_not_in_response('DAG details', resp)\n\n    def test_dag_details_success_for_all_dag_user(self):\n        self.logout()\n        self.login(username='all_dag_user',\n                   password='all_dag_user')\n        url = 'dag_details?dag_id=example_bash_operator'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n\n        url = 'dag_details?dag_id=example_subdag_operator'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('example_subdag_operator', resp)\n\n    def test_rendered_success(self):\n        self.logout()\n        self.login()\n        url = ('rendered?task_id=runme_0&dag_id=example_bash_operator&execution_date={}'\n               .format(self.percent_encode(self.default_date)))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('Rendered Template', resp)\n\n    def test_rendered_failure(self):\n        self.logout()\n        self.login(username='dag_faker',\n                   password='dag_faker')\n        url = ('rendered?task_id=runme_0&dag_id=example_bash_operator&execution_date={}'\n               .format(self.percent_encode(self.default_date)))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_not_in_response('Rendered Template', resp)\n\n    def test_rendered_success_for_all_dag_user(self):\n        self.logout()\n        self.login(username='all_dag_user',\n                   password='all_dag_user')\n        url = ('rendered?task_id=runme_0&dag_id=example_bash_operator&execution_date={}'\n               .format(self.percent_encode(self.default_date)))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('Rendered Template', resp)\n\n    def test_task_success(self):\n        self.logout()\n        self.login()\n        url = ('task?task_id=runme_0&dag_id=example_bash_operator&execution_date={}'\n               .format(self.percent_encode(self.default_date)))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('Task Instance Details', resp)\n\n    def test_task_failure(self):\n        self.logout()\n        self.login(username='dag_faker',\n                   password='dag_faker')\n        url = ('task?task_id=runme_0&dag_id=example_bash_operator&execution_date={}'\n               .format(self.percent_encode(self.default_date)))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_not_in_response('Task Instance Details', resp)\n\n    def test_task_success_for_all_dag_user(self):\n        self.logout()\n        self.login(username='all_dag_user',\n                   password='all_dag_user')\n        url = ('task?task_id=runme_0&dag_id=example_bash_operator&execution_date={}'\n               .format(self.percent_encode(self.default_date)))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('Task Instance Details', resp)\n\n    def test_xcom_success(self):\n        self.logout()\n        self.login()\n        url = ('xcom?task_id=runme_0&dag_id=example_bash_operator&execution_date={}'\n               .format(self.percent_encode(self.default_date)))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('XCom', resp)\n\n    def test_xcom_failure(self):\n        self.logout()\n        self.login(username='dag_faker',\n                   password='dag_faker')\n        url = ('xcom?task_id=runme_0&dag_id=example_bash_operator&execution_date={}'\n               .format(self.percent_encode(self.default_date)))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_not_in_response('XCom', resp)\n\n    def test_xcom_success_for_all_dag_user(self):\n        self.logout()\n        self.login(username='all_dag_user',\n                   password='all_dag_user')\n        url = ('xcom?task_id=runme_0&dag_id=example_bash_operator&execution_date={}'\n               .format(self.percent_encode(self.default_date)))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('XCom', resp)\n\n    def test_run_success(self):\n        self.logout()\n        self.login()\n        form = dict(\n            task_id=\"runme_0\",\n            dag_id=\"example_bash_operator\",\n            ignore_all_deps=\"false\",\n            ignore_ti_state=\"true\",\n            execution_date=self.default_date,\n        )\n        resp = self.client.post('run', data=form)\n        self.check_content_in_response('', resp, resp_code=302)\n\n    def test_run_success_for_all_dag_user(self):\n        self.logout()\n        self.login(username='all_dag_user',\n                   password='all_dag_user')\n        form = dict(\n            task_id=\"runme_0\",\n            dag_id=\"example_bash_operator\",\n            ignore_all_deps=\"false\",\n            ignore_ti_state=\"true\",\n            execution_date=self.default_date\n        )\n        resp = self.client.post('run', data=form)\n        self.check_content_in_response('', resp, resp_code=302)\n\n    def test_blocked_success(self):\n        url = 'blocked'\n        self.logout()\n        self.login()\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n\n    def test_blocked_success_for_all_dag_user(self):\n        url = 'blocked'\n        self.logout()\n        self.login(username='all_dag_user',\n                   password='all_dag_user')\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n        self.check_content_in_response('example_subdag_operator', resp)\n\n    def test_failed_success(self):\n        self.logout()\n        self.login()\n        form = dict(\n            task_id=\"run_this_last\",\n            dag_id=\"example_bash_operator\",\n            execution_date=self.default_date,\n            upstream=\"false\",\n            downstream=\"false\",\n            future=\"false\",\n            past=\"false\",\n        )\n        resp = self.client.post('failed', data=form)\n        self.check_content_in_response('Redirecting', resp, 302)\n\n    def test_duration_success(self):\n        url = 'duration?days=30&dag_id=example_bash_operator'\n        self.logout()\n        self.login()\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n\n    def test_duration_failure(self):\n        url = 'duration?days=30&dag_id=example_bash_operator'\n        self.logout()\n        # login as an user without permissions\n        self.login(username='dag_faker',\n                   password='dag_faker')\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_not_in_response('example_bash_operator', resp)\n\n    def test_tries_success(self):\n        url = 'tries?days=30&dag_id=example_bash_operator'\n        self.logout()\n        self.login()\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n\n    def test_tries_failure(self):\n        url = 'tries?days=30&dag_id=example_bash_operator'\n        self.logout()\n        # login as an user without permissions\n        self.login(username='dag_faker',\n                   password='dag_faker')\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_not_in_response('example_bash_operator', resp)\n\n    def test_landing_times_success(self):\n        url = 'landing_times?days=30&dag_id=example_bash_operator'\n        self.logout()\n        self.login()\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n\n    def test_landing_times_failure(self):\n        url = 'landing_times?days=30&dag_id=example_bash_operator'\n        self.logout()\n        self.login(username='dag_faker',\n                   password='dag_faker')\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_not_in_response('example_bash_operator', resp)\n\n    def test_paused_success(self):\n        # post request failure won't test\n        url = 'paused?dag_id=example_bash_operator&is_paused=false'\n        self.logout()\n        self.login()\n        resp = self.client.post(url, follow_redirects=True)\n        self.check_content_in_response('OK', resp)\n\n    def test_refresh_success(self):\n        self.logout()\n        self.login()\n        resp = self.client.post('refresh?dag_id=example_bash_operator')\n        self.check_content_in_response('', resp, resp_code=302)\n\n    def test_gantt_success(self):\n        url = 'gantt?dag_id=example_bash_operator'\n        self.logout()\n        self.login()\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n\n    def test_gantt_failure(self):\n        url = 'gantt?dag_id=example_bash_operator'\n        self.logout()\n        self.login(username='dag_faker',\n                   password='dag_faker')\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_not_in_response('example_bash_operator', resp)\n\n    def test_success_fail_for_read_only_role(self):\n        # succcess endpoint need can_dag_edit, which read only role can not access\n        self.logout()\n        self.login(username='dag_read_only',\n                   password='dag_read_only')\n\n        form = dict(\n            task_id=\"run_this_last\",\n            dag_id=\"example_bash_operator\",\n            execution_date=self.default_date,\n            upstream=\"false\",\n            downstream=\"false\",\n            future=\"false\",\n            past=\"false\",\n        )\n        resp = self.client.post('success', data=form)\n        self.check_content_not_in_response('Wait a minute', resp, resp_code=302)\n\n    def test_tree_success_for_read_only_role(self):\n        # tree view only allows can_dag_read, which read only role could access\n        self.logout()\n        self.login(username='dag_read_only',\n                   password='dag_read_only')\n\n        url = 'tree?dag_id=example_bash_operator'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('runme_1', resp)\n\n    def test_log_success(self):\n        self.logout()\n        self.login()\n        url = ('log?task_id=runme_0&dag_id=example_bash_operator&execution_date={}'\n               .format(self.percent_encode(self.default_date)))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('Log by attempts', resp)\n        url = ('get_logs_with_metadata?task_id=runme_0&dag_id=example_bash_operator&'\n               'execution_date={}&try_number=1&metadata=null'\n               .format(self.percent_encode(self.default_date)))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('\"message\":', resp)\n        self.check_content_in_response('\"metadata\":', resp)\n\n    def test_log_failure(self):\n        self.logout()\n        self.login(username='dag_faker',\n                   password='dag_faker')\n        url = ('log?task_id=runme_0&dag_id=example_bash_operator&execution_date={}'\n               .format(self.percent_encode(self.default_date)))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_not_in_response('Log by attempts', resp)\n        url = ('get_logs_with_metadata?task_id=runme_0&dag_id=example_bash_operator&'\n               'execution_date={}&try_number=1&metadata=null'\n               .format(self.percent_encode(self.default_date)))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_not_in_response('\"message\":', resp)\n        self.check_content_not_in_response('\"metadata\":', resp)\n\n    def test_log_success_for_user(self):\n        self.logout()\n        self.login(username='test_user',\n                   password='test_user')\n        url = ('log?task_id=runme_0&dag_id=example_bash_operator&execution_date={}'\n               .format(self.percent_encode(self.default_date)))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('Log by attempts', resp)\n        url = ('get_logs_with_metadata?task_id=runme_0&dag_id=example_bash_operator&'\n               'execution_date={}&try_number=1&metadata=null'\n               .format(self.percent_encode(self.default_date)))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('\"message\":', resp)\n        self.check_content_in_response('\"metadata\":', resp)\n\n    def test_tree_view_for_viewer(self):\n        self.logout()\n        self.login(username='test_viewer',\n                   password='test_viewer')\n        url = 'tree?dag_id=example_bash_operator'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('runme_1', resp)\n\n    def test_refresh_failure_for_viewer(self):\n        # viewer role can't refresh\n        self.logout()\n        self.login(username='test_viewer',\n                   password='test_viewer')\n        resp = self.client.post('refresh?dag_id=example_bash_operator')\n        self.check_content_in_response('Redirecting', resp, resp_code=302)", "target": 0}, {"function": "class TestTaskInstanceView(TestBase):\n    TI_ENDPOINT = '/taskinstance/list/?_flt_0_execution_date={}'\n\n    def test_start_date_filter(self):\n        resp = self.client.get(self.TI_ENDPOINT.format(\n            self.percent_encode('2018-10-09 22:44:31')))\n        # We aren't checking the logic of the date filter itself (that is built\n        # in to FAB) but simply that our UTC conversion was run - i.e. it\n        # doesn't blow up!\n        self.check_content_in_response('List Task Instance', resp)", "target": 0}, {"function": "class TestTriggerDag(TestBase):\n\n    def setUp(self):\n        super().setUp()\n        self.session = Session()\n        models.DagBag().get_dag(\"example_bash_operator\").sync_to_db(session=self.session)\n\n    def test_trigger_dag_button_normal_exist(self):\n        resp = self.client.get('/', follow_redirects=True)\n        self.assertIn('/trigger?dag_id=example_bash_operator', resp.data.decode('utf-8'))\n        self.assertIn(\"return confirmDeleteDag(this, 'example_bash_operator')\", resp.data.decode('utf-8'))\n\n    @unittest.skipIf('mysql' in conf.get('core', 'sql_alchemy_conn'),\n                     \"flaky when run on mysql\")\n    def test_trigger_dag_button(self):\n\n        test_dag_id = \"example_bash_operator\"\n\n        DR = models.DagRun\n        self.session.query(DR).delete()\n        self.session.commit()\n\n        self.client.post('trigger?dag_id={}'.format(test_dag_id))\n\n        run = self.session.query(DR).filter(DR.dag_id == test_dag_id).first()\n        self.assertIsNotNone(run)\n        self.assertIn(\"manual__\", run.run_id)", "target": 0}, {"function": "class TestExtraLinks(TestBase):\n    def setUp(self):\n        super().setUp()\n        self.ENDPOINT = \"extra_links\"\n        self.DEFAULT_DATE = datetime(2017, 1, 1)\n\n        class RaiseErrorLink(BaseOperatorLink):\n            name = 'raise_error'\n\n            def get_link(self, operator, dttm):\n                raise ValueError('This is an error')\n\n        class NoResponseLink(BaseOperatorLink):\n            name = 'no_response'\n\n            def get_link(self, operator, dttm):\n                return None\n\n        class FooBarLink(BaseOperatorLink):\n            name = 'foo-bar'\n\n            def get_link(self, operator, dttm):\n                return 'http://www.example.com/{0}/{1}/{2}'.format(\n                    operator.task_id, 'foo-bar', dttm)\n\n        class AirflowLink(BaseOperatorLink):\n            name = 'airflow'\n\n            def get_link(self, operator, dttm):\n                return 'https://airflow.apache.org'\n\n        class DummyTestOperator(BaseOperator):\n\n            operator_extra_links = (\n                RaiseErrorLink(),\n                NoResponseLink(),\n                FooBarLink(),\n                AirflowLink(),\n            )\n\n        self.dag = DAG('dag', start_date=self.DEFAULT_DATE)\n        self.task = DummyTestOperator(task_id=\"some_dummy_task\", dag=self.dag)\n\n    def tearDown(self):\n        super().tearDown()\n\n    @mock.patch('airflow.www.views.dagbag.get_dag')\n    def test_extra_links_works(self, get_dag_function):\n        get_dag_function.return_value = self.dag\n\n        response = self.client.get(\n            \"{0}?dag_id={1}&task_id={2}&execution_date={3}&link_name=foo-bar\"\n            .format(self.ENDPOINT, self.dag.dag_id, self.task.task_id, self.DEFAULT_DATE),\n            follow_redirects=True)\n\n        self.assertEqual(response.status_code, 200)\n        response_str = response.data\n        if isinstance(response.data, bytes):\n            response_str = response_str.decode()\n        self.assertEqual(json.loads(response_str), {\n            'url': ('http://www.example.com/some_dummy_task/'\n                    'foo-bar/2017-01-01T00:00:00+00:00'),\n            'error': None\n        })\n\n    @mock.patch('airflow.www.views.dagbag.get_dag')\n    def test_global_extra_links_works(self, get_dag_function):\n        get_dag_function.return_value = self.dag\n\n        response = self.client.get(\n            \"{0}?dag_id={1}&task_id={2}&execution_date={3}&link_name=github\"\n            .format(self.ENDPOINT, self.dag.dag_id, self.task.task_id, self.DEFAULT_DATE),\n            follow_redirects=True)\n\n        self.assertEqual(response.status_code, 200)\n        response_str = response.data\n        if isinstance(response.data, bytes):\n            response_str = response_str.decode()\n        self.assertEqual(json.loads(response_str), {\n            'url': 'https://github.com/apache/airflow',\n            'error': None\n        })\n\n    @mock.patch('airflow.www.views.dagbag.get_dag')\n    def test_operator_extra_link_override_global_extra_link(self, get_dag_function):\n        get_dag_function.return_value = self.dag\n\n        response = self.client.get(\n            \"{0}?dag_id={1}&task_id={2}&execution_date={3}&link_name=airflow\".format(\n                self.ENDPOINT, self.dag.dag_id, self.task.task_id, self.DEFAULT_DATE),\n            follow_redirects=True)\n\n        self.assertEqual(response.status_code, 200)\n        response_str = response.data\n        if isinstance(response.data, bytes):\n            response_str = response_str.decode()\n        self.assertEqual(json.loads(response_str), {\n            'url': 'https://airflow.apache.org',\n            'error': None\n        })\n\n    @mock.patch('airflow.www.views.dagbag.get_dag')\n    def test_extra_links_error_raised(self, get_dag_function):\n        get_dag_function.return_value = self.dag\n\n        response = self.client.get(\n            \"{0}?dag_id={1}&task_id={2}&execution_date={3}&link_name=raise_error\"\n            .format(self.ENDPOINT, self.dag.dag_id, self.task.task_id, self.DEFAULT_DATE),\n            follow_redirects=True)\n\n        self.assertEqual(404, response.status_code)\n        response_str = response.data\n        if isinstance(response.data, bytes):\n            response_str = response_str.decode()\n        self.assertEqual(json.loads(response_str), {\n            'url': None,\n            'error': 'This is an error'})\n\n    @mock.patch('airflow.www.views.dagbag.get_dag')\n    def test_extra_links_no_response(self, get_dag_function):\n        get_dag_function.return_value = self.dag\n\n        response = self.client.get(\n            \"{0}?dag_id={1}&task_id={2}&execution_date={3}&link_name=no_response\"\n            .format(self.ENDPOINT, self.dag.dag_id, self.task.task_id, self.DEFAULT_DATE),\n            follow_redirects=True)\n\n        self.assertEqual(response.status_code, 404)\n        response_str = response.data\n        if isinstance(response.data, bytes):\n            response_str = response_str.decode()\n        self.assertEqual(json.loads(response_str), {\n            'url': None,\n            'error': 'No URL found for no_response'})", "target": 0}, {"function": "class TestDagRunModelView(TestBase):\n    @classmethod\n    def setUpClass(cls):\n        super().setUpClass()\n        models.DagBag().get_dag(\"example_bash_operator\").sync_to_db(session=cls.session)\n        cls.clear_table(models.DagRun)\n\n    def tearDown(self):\n        self.clear_table(models.DagRun)\n\n    def test_create_dagrun(self):\n        data = {\n            \"state\": \"running\",\n            \"dag_id\": \"example_bash_operator\",\n            \"execution_date\": \"2018-07-06 05:04:03\",\n            \"run_id\": \"manual_abc\",\n        }\n        resp = self.client.post('/dagrun/add',\n                                data=data,\n                                follow_redirects=True)\n        self.check_content_in_response('Added Row', resp)\n\n        dr = self.session.query(models.DagRun).one()\n\n        self.assertEqual(dr.execution_date, timezone.convert_to_utc(datetime(2018, 7, 6, 5, 4, 3)))", "target": 0}, {"function": "class TestDecorators(TestBase):\n    EXAMPLE_DAG_DEFAULT_DATE = dates.days_ago(2)\n    run_id = \"test_{}\".format(models.DagRun.id_for_date(EXAMPLE_DAG_DEFAULT_DATE))\n\n    @classmethod\n    def setUpClass(cls):\n        super().setUpClass()\n        dagbag = models.DagBag(include_examples=True)\n        for dag in dagbag.dags.values():\n            dag.sync_to_db()\n\n    def setUp(self):\n        super().setUp()\n        self.logout()\n        self.login()\n        self.cleanup_dagruns()\n        self.prepare_dagruns()\n\n    def cleanup_dagruns(self):\n        DR = models.DagRun\n        dag_ids = ['example_bash_operator',\n                   'example_subdag_operator',\n                   'example_xcom']\n        (self.session\n             .query(DR)\n             .filter(DR.dag_id.in_(dag_ids))\n             .filter(DR.run_id == self.run_id)\n             .delete(synchronize_session='fetch'))\n        self.session.commit()\n\n    def prepare_dagruns(self):\n        dagbag = models.DagBag(include_examples=True)\n        self.bash_dag = dagbag.dags['example_bash_operator']\n        self.sub_dag = dagbag.dags['example_subdag_operator']\n        self.xcom_dag = dagbag.dags['example_xcom']\n\n        self.bash_dagrun = self.bash_dag.create_dagrun(\n            run_id=self.run_id,\n            execution_date=self.EXAMPLE_DAG_DEFAULT_DATE,\n            start_date=timezone.utcnow(),\n            state=State.RUNNING)\n\n        self.sub_dagrun = self.sub_dag.create_dagrun(\n            run_id=self.run_id,\n            execution_date=self.EXAMPLE_DAG_DEFAULT_DATE,\n            start_date=timezone.utcnow(),\n            state=State.RUNNING)\n\n        self.xcom_dagrun = self.xcom_dag.create_dagrun(\n            run_id=self.run_id,\n            execution_date=self.EXAMPLE_DAG_DEFAULT_DATE,\n            start_date=timezone.utcnow(),\n            state=State.RUNNING)\n\n    def check_last_log(self, dag_id, event, execution_date=None):\n        from airflow.models import Log\n        qry = self.session.query(Log.dag_id, Log.task_id, Log.event, Log.execution_date,\n                                 Log.owner, Log.extra)\n        qry = qry.filter(Log.dag_id == dag_id, Log.event == event)\n        if execution_date:\n            qry = qry.filter(Log.execution_date == execution_date)\n        logs = qry.order_by(Log.dttm.desc()).limit(5).all()\n        self.assertGreaterEqual(len(logs), 1)\n        self.assertTrue(logs[0].extra)\n\n    def test_action_logging_get(self):\n        url = 'graph?dag_id=example_bash_operator&execution_date={}'.format(\n            self.percent_encode(self.EXAMPLE_DAG_DEFAULT_DATE))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('runme_1', resp)\n\n        # In mysql backend, this commit() is needed to write down the logs\n        self.session.commit()\n        self.check_last_log(\"example_bash_operator\", event=\"graph\",\n                            execution_date=self.EXAMPLE_DAG_DEFAULT_DATE)\n\n    def test_action_logging_post(self):\n        form = dict(\n            task_id=\"runme_1\",\n            dag_id=\"example_bash_operator\",\n            execution_date=self.EXAMPLE_DAG_DEFAULT_DATE,\n            upstream=\"false\",\n            downstream=\"false\",\n            future=\"false\",\n            past=\"false\",\n            only_failed=\"false\",\n        )\n        resp = self.client.post(\"clear\", data=form)\n        self.check_content_in_response(['example_bash_operator', 'Wait a minute'], resp)\n        # In mysql backend, this commit() is needed to write down the logs\n        self.session.commit()\n        self.check_last_log(\"example_bash_operator\", event=\"clear\",\n                            execution_date=self.EXAMPLE_DAG_DEFAULT_DATE)", "target": 0}], "function_after": [{"function": "class TestBase(unittest.TestCase):\n    @classmethod\n    def setUpClass(cls):\n        cls.app, cls.appbuilder = application.create_app(session=Session, testing=True)\n        cls.app.config['WTF_CSRF_ENABLED'] = False\n        cls.app.jinja_env.undefined = jinja2.StrictUndefined\n        settings.configure_orm()\n        cls.session = Session\n\n    def setUp(self):\n        self.client = self.app.test_client()\n        self.login()\n\n    def login(self):\n        role_admin = self.appbuilder.sm.find_role('Admin')\n        tester = self.appbuilder.sm.find_user(username='test')\n        if not tester:\n            self.appbuilder.sm.add_user(\n                username='test',\n                first_name='test',\n                last_name='test',\n                email='test@fab.org',\n                role=role_admin,\n                password='test')\n        return self.client.post('/login/', data=dict(\n            username='test',\n            password='test'\n        ), follow_redirects=True)\n\n    def logout(self):\n        return self.client.get('/logout/')\n\n    @classmethod\n    def clear_table(cls, model):\n        with create_session() as session:\n            session.query(model).delete()\n\n    def check_content_in_response(self, text, resp, resp_code=200):\n        resp_html = resp.data.decode('utf-8')\n        self.assertEqual(resp_code, resp.status_code)\n        if isinstance(text, list):\n            for kw in text:\n                self.assertIn(kw, resp_html)\n        else:\n            self.assertIn(text, resp_html)\n\n    def check_content_not_in_response(self, text, resp, resp_code=200):\n        resp_html = resp.data.decode('utf-8')\n        self.assertEqual(resp_code, resp.status_code)\n        if isinstance(text, list):\n            for kw in text:\n                self.assertNotIn(kw, resp_html)\n        else:\n            self.assertNotIn(text, resp_html)\n\n    def percent_encode(self, obj):\n        return urllib.parse.quote_plus(str(obj))", "target": 0}, {"function": "class TestConnectionModelView(TestBase):\n    def setUp(self):\n        super().setUp()\n        self.connection = {\n            'conn_id': 'test_conn',\n            'conn_type': 'http',\n            'host': 'localhost',\n            'port': 8080,\n            'username': 'root',\n            'password': 'admin'\n        }\n\n    def tearDown(self):\n        self.clear_table(Connection)\n        super().tearDown()\n\n    def test_create_connection(self):\n        resp = self.client.post('/connection/add',\n                                data=self.connection,\n                                follow_redirects=True)\n        self.check_content_in_response('Added Row', resp)", "target": 0}, {"function": "class TestVariableModelView(TestBase):\n    def setUp(self):\n        super().setUp()\n        self.variable = {\n            'key': 'test_key',\n            'val': 'text_val',\n            'is_encrypted': True\n        }\n\n    def tearDown(self):\n        self.clear_table(models.Variable)\n        super().tearDown()\n\n    def test_can_handle_error_on_decrypt(self):\n\n        # create valid variable\n        resp = self.client.post('/variable/add',\n                                data=self.variable,\n                                follow_redirects=True)\n\n        # update the variable with a wrong value, given that is encrypted\n        Var = models.Variable\n        (self.session.query(Var)\n            .filter(Var.key == self.variable['key'])\n            .update({\n                'val': 'failed_value_not_encrypted'\n            }, synchronize_session=False))\n        self.session.commit()\n\n        # retrieve Variables page, should not fail and contain the Invalid\n        # label for the variable\n        resp = self.client.get('/variable/list', follow_redirects=True)\n        self.check_content_in_response(\n            '<span class=\"label label-danger\">Invalid</span>', resp)\n\n    def test_xss_prevention(self):\n        xss = \"/variable/list/<img%20src=''%20onerror='alert(1);'>\"\n\n        resp = self.client.get(\n            xss,\n            follow_redirects=True,\n        )\n        self.assertEqual(resp.status_code, 404)\n        self.assertNotIn(\"<img src='' onerror='alert(1);'>\",\n                         resp.data.decode(\"utf-8\"))\n\n    def test_import_variables_no_file(self):\n        resp = self.client.post('/variable/varimport',\n                                follow_redirects=True)\n        self.check_content_in_response('Missing file or syntax error.', resp)\n\n    def test_import_variables_failed(self):\n        content = '{\"str_key\": \"str_value\"}'\n\n        with mock.patch('airflow.models.Variable.set') as set_mock:\n            set_mock.side_effect = UnicodeEncodeError\n            self.assertEqual(self.session.query(models.Variable).count(), 0)\n\n            try:\n                # python 3+\n                bytes_content = io.BytesIO(bytes(content, encoding='utf-8'))\n            except TypeError:\n                # python 2.7\n                bytes_content = io.BytesIO(bytes(content))\n\n            resp = self.client.post('/variable/varimport',\n                                    data={'file': (bytes_content, 'test.json')},\n                                    follow_redirects=True)\n            self.check_content_in_response('1 variable(s) failed to be updated.', resp)\n\n    def test_import_variables_success(self):\n        self.assertEqual(self.session.query(models.Variable).count(), 0)\n\n        content = ('{\"str_key\": \"str_value\", \"int_key\": 60,'\n                   '\"list_key\": [1, 2], \"dict_key\": {\"k_a\": 2, \"k_b\": 3}}')\n        try:\n            # python 3+\n            bytes_content = io.BytesIO(bytes(content, encoding='utf-8'))\n        except TypeError:\n            # python 2.7\n            bytes_content = io.BytesIO(bytes(content))\n\n        resp = self.client.post('/variable/varimport',\n                                data={'file': (bytes_content, 'test.json')},\n                                follow_redirects=True)\n        self.check_content_in_response('4 variable(s) successfully updated.', resp)", "target": 0}, {"function": "class TestPoolModelView(TestBase):\n    def setUp(self):\n        super().setUp()\n        self.pool = {\n            'pool': 'test-pool',\n            'slots': 777,\n            'description': 'test-pool-description',\n        }\n\n    def tearDown(self):\n        self.clear_table(models.Pool)\n        super().tearDown()\n\n    def test_create_pool_with_same_name(self):\n        # create test pool\n        resp = self.client.post('/pool/add',\n                                data=self.pool,\n                                follow_redirects=True)\n        self.check_content_in_response('Added Row', resp)\n\n        # create pool with the same name\n        resp = self.client.post('/pool/add',\n                                data=self.pool,\n                                follow_redirects=True)\n        self.check_content_in_response('Already exists.', resp)\n\n    def test_create_pool_with_empty_name(self):\n\n        self.pool['pool'] = ''\n        resp = self.client.post('/pool/add',\n                                data=self.pool,\n                                follow_redirects=True)\n        self.check_content_in_response('This field is required.', resp)\n\n    def test_odd_name(self):\n        self.pool['pool'] = 'test-pool<script></script>'\n        self.session.add(models.Pool(**self.pool))\n        self.session.commit()\n        resp = self.client.get('/pool/list/')\n        self.check_content_in_response('test-pool&lt;script&gt;', resp)\n        self.check_content_not_in_response('test-pool<script>', resp)\n\n    def test_list(self):\n        self.pool['pool'] = 'test-pool'\n        self.session.add(models.Pool(**self.pool))\n        self.session.commit()\n        resp = self.client.get('/pool/list/')\n        # We should see this link\n        with self.app.test_request_context():\n            url = url_for('TaskInstanceModelView.list', _flt_3_pool='test-pool', _flt_3_state='running')\n            used_tag = Markup(\"<a href='{url}'>{slots}</a>\").format(url=url, slots=0)\n\n            url = url_for('TaskInstanceModelView.list', _flt_3_pool='test-pool', _flt_3_state='queued')\n            queued_tag = Markup(\"<a href='{url}'>{slots}</a>\").format(url=url, slots=0)\n        self.check_content_in_response(used_tag, resp)\n        self.check_content_in_response(queued_tag, resp)", "target": 0}, {"function": "class TestMountPoint(unittest.TestCase):\n    @classmethod\n    def setUpClass(cls):\n        application.app = None\n        application.appbuilder = None\n        conf.set(\"webserver\", \"base_url\", \"http://localhost/test\")\n        app = application.cached_app(config={'WTF_CSRF_ENABLED': False}, session=Session, testing=True)\n        cls.client = Client(app, BaseResponse)\n\n    @classmethod\n    def tearDownClass(cls):\n        application.app = None\n        application.appbuilder = None\n\n    def test_mount(self):\n        # Test an endpoint that doesn't need auth!\n        resp = self.client.get('/test/health')\n        self.assertEqual(resp.status_code, 200)\n        self.assertIn(b\"healthy\", resp.data)\n\n    def test_not_found(self):\n        resp = self.client.get('/', follow_redirects=True)\n        self.assertEqual(resp.status_code, 404)\n\n    def test_index(self):\n        resp = self.client.get('/test/')\n        self.assertEqual(resp.status_code, 302)\n        self.assertEqual(resp.headers['Location'], 'http://localhost/test/home')", "target": 0}, {"function": "class TestAirflowBaseViews(TestBase):\n    EXAMPLE_DAG_DEFAULT_DATE = dates.days_ago(2)\n    run_id = \"test_{}\".format(models.DagRun.id_for_date(EXAMPLE_DAG_DEFAULT_DATE))\n\n    @classmethod\n    def setUpClass(cls):\n        super().setUpClass()\n        dagbag = models.DagBag(include_examples=True)\n        for dag in dagbag.dags.values():\n            dag.sync_to_db()\n\n    def setUp(self):\n        super().setUp()\n        self.logout()\n        self.login()\n        self.cleanup_dagruns()\n        self.prepare_dagruns()\n\n    def cleanup_dagruns(self):\n        DR = models.DagRun\n        dag_ids = ['example_bash_operator',\n                   'example_subdag_operator',\n                   'example_xcom']\n        (self.session\n             .query(DR)\n             .filter(DR.dag_id.in_(dag_ids))\n             .filter(DR.run_id == self.run_id)\n             .delete(synchronize_session='fetch'))\n        self.session.commit()\n\n    def prepare_dagruns(self):\n        dagbag = models.DagBag(include_examples=True)\n        self.bash_dag = dagbag.dags['example_bash_operator']\n        self.sub_dag = dagbag.dags['example_subdag_operator']\n        self.xcom_dag = dagbag.dags['example_xcom']\n\n        self.bash_dagrun = self.bash_dag.create_dagrun(\n            run_id=self.run_id,\n            execution_date=self.EXAMPLE_DAG_DEFAULT_DATE,\n            start_date=timezone.utcnow(),\n            state=State.RUNNING)\n\n        self.sub_dagrun = self.sub_dag.create_dagrun(\n            run_id=self.run_id,\n            execution_date=self.EXAMPLE_DAG_DEFAULT_DATE,\n            start_date=timezone.utcnow(),\n            state=State.RUNNING)\n\n        self.xcom_dagrun = self.xcom_dag.create_dagrun(\n            run_id=self.run_id,\n            execution_date=self.EXAMPLE_DAG_DEFAULT_DATE,\n            start_date=timezone.utcnow(),\n            state=State.RUNNING)\n\n    def test_index(self):\n        resp = self.client.get('/', follow_redirects=True)\n        self.check_content_in_response('DAGs', resp)\n\n    def test_health(self):\n\n        # case-1: healthy scheduler status\n        last_scheduler_heartbeat_for_testing_1 = timezone.utcnow()\n        self.session.add(BaseJob(job_type='SchedulerJob',\n                                 state='running',\n                                 latest_heartbeat=last_scheduler_heartbeat_for_testing_1))\n        self.session.commit()\n\n        resp_json = json.loads(self.client.get('health', follow_redirects=True).data.decode('utf-8'))\n\n        self.assertEqual('healthy', resp_json['metadatabase']['status'])\n        self.assertEqual('healthy', resp_json['scheduler']['status'])\n        self.assertEqual(last_scheduler_heartbeat_for_testing_1.isoformat(),\n                         resp_json['scheduler']['latest_scheduler_heartbeat'])\n\n        self.session.query(BaseJob).\\\n            filter(BaseJob.job_type == 'SchedulerJob',\n                   BaseJob.state == 'running',\n                   BaseJob.latest_heartbeat == last_scheduler_heartbeat_for_testing_1).\\\n            delete()\n        self.session.commit()\n\n        # case-2: unhealthy scheduler status - scenario 1 (SchedulerJob is running too slowly)\n        last_scheduler_heartbeat_for_testing_2 = timezone.utcnow() - timedelta(minutes=1)\n        (self.session\n             .query(BaseJob)\n             .filter(BaseJob.job_type == 'SchedulerJob')\n             .update({'latest_heartbeat': last_scheduler_heartbeat_for_testing_2 - timedelta(seconds=1)}))\n        self.session.add(BaseJob(job_type='SchedulerJob',\n                                 state='running',\n                                 latest_heartbeat=last_scheduler_heartbeat_for_testing_2))\n        self.session.commit()\n\n        resp_json = json.loads(self.client.get('health', follow_redirects=True).data.decode('utf-8'))\n\n        self.assertEqual('healthy', resp_json['metadatabase']['status'])\n        self.assertEqual('unhealthy', resp_json['scheduler']['status'])\n        self.assertEqual(last_scheduler_heartbeat_for_testing_2.isoformat(),\n                         resp_json['scheduler']['latest_scheduler_heartbeat'])\n\n        self.session.query(BaseJob).\\\n            filter(BaseJob.job_type == 'SchedulerJob',\n                   BaseJob.state == 'running',\n                   BaseJob.latest_heartbeat == last_scheduler_heartbeat_for_testing_2).\\\n            delete()\n        self.session.commit()\n\n        # case-3: unhealthy scheduler status - scenario 2 (no running SchedulerJob)\n        self.session.query(BaseJob).\\\n            filter(BaseJob.job_type == 'SchedulerJob',\n                   BaseJob.state == 'running').\\\n            delete()\n        self.session.commit()\n\n        resp_json = json.loads(self.client.get('health', follow_redirects=True).data.decode('utf-8'))\n\n        self.assertEqual('healthy', resp_json['metadatabase']['status'])\n        self.assertEqual('unhealthy', resp_json['scheduler']['status'])\n        self.assertIsNone(None, resp_json['scheduler']['latest_scheduler_heartbeat'])\n\n    def test_home(self):\n        resp = self.client.get('home', follow_redirects=True)\n        self.check_content_in_response('DAGs', resp)\n\n    def test_task(self):\n        url = ('task?task_id=runme_0&dag_id=example_bash_operator&execution_date={}'\n               .format(self.percent_encode(self.EXAMPLE_DAG_DEFAULT_DATE)))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('Task Instance Details', resp)\n\n    def test_xcom(self):\n        url = ('xcom?task_id=runme_0&dag_id=example_bash_operator&execution_date={}'\n               .format(self.percent_encode(self.EXAMPLE_DAG_DEFAULT_DATE)))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('XCom', resp)\n\n    def test_rendered(self):\n        url = ('rendered?task_id=runme_0&dag_id=example_bash_operator&execution_date={}'\n               .format(self.percent_encode(self.EXAMPLE_DAG_DEFAULT_DATE)))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('Rendered Template', resp)\n\n    def test_blocked(self):\n        url = 'blocked'\n        resp = self.client.get(url, follow_redirects=True)\n        self.assertEqual(200, resp.status_code)\n\n    def test_dag_stats(self):\n        resp = self.client.get('dag_stats', follow_redirects=True)\n        self.assertEqual(resp.status_code, 200)\n\n    def test_task_stats(self):\n        resp = self.client.get('task_stats', follow_redirects=True)\n        self.assertEqual(resp.status_code, 200)\n\n    def test_dag_details(self):\n        url = 'dag_details?dag_id=example_bash_operator'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('DAG details', resp)\n\n    def test_dag_details_subdag(self):\n        url = 'dag_details?dag_id=example_subdag_operator.section-1'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('DAG details', resp)\n\n    def test_graph(self):\n        url = 'graph?dag_id=example_bash_operator'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('runme_1', resp)\n\n    def test_last_dagruns(self):\n        resp = self.client.get('last_dagruns', follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n\n    def test_tree(self):\n        url = 'tree?dag_id=example_bash_operator'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('runme_1', resp)\n\n    def test_tree_subdag(self):\n        url = 'tree?dag_id=example_subdag_operator.section-1'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('section-1-task-1', resp)\n\n    def test_duration(self):\n        url = 'duration?days=30&dag_id=example_bash_operator'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n\n    def test_duration_missing(self):\n        url = 'duration?days=30&dag_id=missing_dag'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('seems to be missing', resp)\n\n    def test_tries(self):\n        url = 'tries?days=30&dag_id=example_bash_operator'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n\n    def test_landing_times(self):\n        url = 'landing_times?days=30&dag_id=example_bash_operator'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n\n    def test_gantt(self):\n        url = 'gantt?dag_id=example_bash_operator'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n\n    def test_code(self):\n        url = 'code?dag_id=example_bash_operator'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n\n    def test_paused(self):\n        url = 'paused?dag_id=example_bash_operator&is_paused=false'\n        resp = self.client.post(url, follow_redirects=True)\n        self.check_content_in_response('OK', resp)\n\n    def test_failed(self):\n        form = dict(\n            task_id=\"run_this_last\",\n            dag_id=\"example_bash_operator\",\n            execution_date=self.EXAMPLE_DAG_DEFAULT_DATE,\n            upstream=\"false\",\n            downstream=\"false\",\n            future=\"false\",\n            past=\"false\",\n        )\n        resp = self.client.post(\"failed\", data=form)\n        self.check_content_in_response('Wait a minute', resp)\n\n    def test_success(self):\n        form = dict(\n            task_id=\"run_this_last\",\n            dag_id=\"example_bash_operator\",\n            execution_date=self.EXAMPLE_DAG_DEFAULT_DATE,\n            upstream=\"false\",\n            downstream=\"false\",\n            future=\"false\",\n            past=\"false\",\n        )\n        resp = self.client.post('success', data=form)\n        self.check_content_in_response('Wait a minute', resp)\n\n    def test_clear(self):\n        form = dict(\n            task_id=\"runme_1\",\n            dag_id=\"example_bash_operator\",\n            execution_date=self.EXAMPLE_DAG_DEFAULT_DATE,\n            upstream=\"false\",\n            downstream=\"false\",\n            future=\"false\",\n            past=\"false\",\n            only_failed=\"false\",\n        )\n        resp = self.client.post(\"clear\", data=form)\n        self.check_content_in_response(['example_bash_operator', 'Wait a minute'], resp)\n\n    def test_run(self):\n        form = dict(\n            task_id=\"runme_0\",\n            dag_id=\"example_bash_operator\",\n            ignore_all_deps=\"false\",\n            ignore_ti_state=\"true\",\n            execution_date=self.EXAMPLE_DAG_DEFAULT_DATE,\n        )\n        resp = self.client.post('run', data=form)\n        self.check_content_in_response('', resp, resp_code=302)\n\n    def test_refresh(self):\n        resp = self.client.post('refresh?dag_id=example_bash_operator')\n        self.check_content_in_response('', resp, resp_code=302)\n\n    def test_refresh_all(self):\n        resp = self.client.post(\"/refresh_all\",\n                                follow_redirects=True)\n        self.check_content_in_response('', resp, resp_code=200)\n\n    def test_delete_dag_button_normal(self):\n        resp = self.client.get('/', follow_redirects=True)\n        self.check_content_in_response('/delete?dag_id=example_bash_operator', resp)\n        self.check_content_in_response(\"return confirmDeleteDag(this, 'example_bash_operator')\", resp)\n\n    def test_delete_dag_button_for_dag_on_scheduler_only(self):\n        # Test for JIRA AIRFLOW-3233 (PR 4069):\n        # The delete-dag URL should be generated correctly for DAGs\n        # that exist on the scheduler (DB) but not the webserver DagBag\n\n        test_dag_id = \"non_existent_dag\"\n\n        DM = models.DagModel\n        self.session.query(DM).filter(DM.dag_id == 'example_bash_operator').update({'dag_id': test_dag_id})\n        self.session.commit()\n\n        resp = self.client.get('/', follow_redirects=True)\n        self.check_content_in_response('/delete?dag_id={}'.format(test_dag_id), resp)\n        self.check_content_in_response(\"return confirmDeleteDag(this, '{}')\".format(test_dag_id), resp)\n\n        self.session.query(DM).filter(DM.dag_id == test_dag_id).update({'dag_id': 'example_bash_operator'})\n        self.session.commit()", "target": 0}, {"function": "class TestConfigurationView(TestBase):\n    def test_configuration_do_not_expose_config(self):\n        self.logout()\n        self.login()\n        with conf_vars({('webserver', 'expose_config'): 'False'}):\n            resp = self.client.get('configuration', follow_redirects=True)\n        self.check_content_in_response(\n            ['Airflow Configuration', '# Your Airflow administrator chose not to expose the configuration, '\n                                      'most likely for security reasons.'], resp)\n\n    def test_configuration_expose_config(self):\n        self.logout()\n        self.login()\n        with conf_vars({('webserver', 'expose_config'): 'True'}):\n            resp = self.client.get('configuration', follow_redirects=True)\n        self.check_content_in_response(\n            ['Airflow Configuration', 'Running Configuration'], resp)", "target": 0}, {"function": "class TestLogView(TestBase):\n    DAG_ID = 'dag_for_testing_log_view'\n    TASK_ID = 'task_for_testing_log_view'\n    DEFAULT_DATE = timezone.datetime(2017, 9, 1)\n    ENDPOINT = 'log?dag_id={dag_id}&task_id={task_id}&' \\\n               'execution_date={execution_date}'.format(dag_id=DAG_ID,\n                                                        task_id=TASK_ID,\n                                                        execution_date=DEFAULT_DATE)\n\n    def setUp(self):\n        # Make sure that the configure_logging is not cached\n        self.old_modules = dict(sys.modules)\n\n        # Create a custom logging configuration\n        logging_config = copy.deepcopy(DEFAULT_LOGGING_CONFIG)\n        current_dir = os.path.dirname(os.path.abspath(__file__))\n        logging_config['handlers']['task']['base_log_folder'] = os.path.normpath(\n            os.path.join(current_dir, 'test_logs'))\n\n        logging_config['handlers']['task']['filename_template'] = \\\n            '{{ ti.dag_id }}/{{ ti.task_id }}/' \\\n            '{{ ts | replace(\":\", \".\") }}/{{ try_number }}.log'\n\n        # Write the custom logging configuration to a file\n        self.settings_folder = tempfile.mkdtemp()\n        settings_file = os.path.join(self.settings_folder, \"airflow_local_settings.py\")\n        new_logging_file = \"LOGGING_CONFIG = {}\".format(logging_config)\n        with open(settings_file, 'w') as handle:\n            handle.writelines(new_logging_file)\n        sys.path.append(self.settings_folder)\n        conf.set('core', 'logging_config_class', 'airflow_local_settings.LOGGING_CONFIG')\n\n        self.app, self.appbuilder = application.create_app(session=Session, testing=True)\n        self.app.config['WTF_CSRF_ENABLED'] = False\n        self.client = self.app.test_client()\n        settings.configure_orm()\n        self.login()\n\n        from airflow.www.views import dagbag\n        dag = DAG(self.DAG_ID, start_date=self.DEFAULT_DATE)\n        dag.sync_to_db()\n        task = DummyOperator(task_id=self.TASK_ID, dag=dag)\n        dagbag.bag_dag(dag, parent_dag=dag, root_dag=dag)\n        with create_session() as session:\n            self.ti = TaskInstance(task=task, execution_date=self.DEFAULT_DATE)\n            self.ti.try_number = 1\n            session.merge(self.ti)\n\n    def tearDown(self):\n        logging.config.dictConfig(DEFAULT_LOGGING_CONFIG)\n        self.clear_table(TaskInstance)\n\n        # Remove any new modules imported during the test run. This lets us\n        # import the same source files for more than one test.\n        for m in [m for m in sys.modules if m not in self.old_modules]:\n            del sys.modules[m]\n\n        sys.path.remove(self.settings_folder)\n        shutil.rmtree(self.settings_folder)\n        conf.set('core', 'logging_config_class', '')\n\n        self.logout()\n        super().tearDown()\n\n    @parameterized.expand([\n        [State.NONE, 0, 0],\n        [State.UP_FOR_RETRY, 2, 2],\n        [State.UP_FOR_RESCHEDULE, 0, 1],\n        [State.UP_FOR_RESCHEDULE, 1, 2],\n        [State.RUNNING, 1, 1],\n        [State.SUCCESS, 1, 1],\n        [State.FAILED, 3, 3],\n    ])\n    def test_get_file_task_log(self, state, try_number, expected_num_logs_visible):\n        with create_session() as session:\n            self.ti.state = state\n            self.ti.try_number = try_number\n            session.merge(self.ti)\n\n        response = self.client.get(\n            TestLogView.ENDPOINT, data=dict(\n                username='test',\n                password='test'), follow_redirects=True)\n        self.assertEqual(response.status_code, 200)\n        self.assertIn('Log by attempts', response.data.decode('utf-8'))\n        for num in range(1, expected_num_logs_visible + 1):\n            self.assertIn('try-{}'.format(num), response.data.decode('utf-8'))\n        self.assertNotIn('try-0', response.data.decode('utf-8'))\n        self.assertNotIn('try-{}'.format(expected_num_logs_visible + 1), response.data.decode('utf-8'))\n\n    def test_get_logs_with_metadata_as_download_file(self):\n        url_template = \"get_logs_with_metadata?dag_id={}&\" \\\n                       \"task_id={}&execution_date={}&\" \\\n                       \"try_number={}&metadata={}&format=file\"\n        try_number = 1\n        url = url_template.format(self.DAG_ID,\n                                  self.TASK_ID,\n                                  quote_plus(self.DEFAULT_DATE.isoformat()),\n                                  try_number,\n                                  json.dumps({}))\n        response = self.client.get(url)\n        expected_filename = '{}/{}/{}/{}.log'.format(self.DAG_ID,\n                                                     self.TASK_ID,\n                                                     self.DEFAULT_DATE.isoformat(),\n                                                     try_number)\n\n        content_disposition = response.headers.get('Content-Disposition')\n        self.assertTrue(content_disposition.startswith('attachment'))\n        self.assertTrue(expected_filename in content_disposition)\n        self.assertEqual(200, response.status_code)\n        self.assertIn('Log for testing.', response.data.decode('utf-8'))\n\n    def test_get_logs_with_metadata_as_download_large_file(self):\n        with mock.patch(\"airflow.utils.log.file_task_handler.FileTaskHandler.read\") as read_mock:\n            first_return = (['1st line'], [{}])\n            second_return = (['2nd line'], [{'end_of_log': False}])\n            third_return = (['3rd line'], [{'end_of_log': True}])\n            fourth_return = (['should never be read'], [{'end_of_log': True}])\n            read_mock.side_effect = [first_return, second_return, third_return, fourth_return]\n            url_template = \"get_logs_with_metadata?dag_id={}&\" \\\n                           \"task_id={}&execution_date={}&\" \\\n                           \"try_number={}&metadata={}&format=file\"\n            try_number = 1\n            url = url_template.format(self.DAG_ID,\n                                      self.TASK_ID,\n                                      quote_plus(self.DEFAULT_DATE.isoformat()),\n                                      try_number,\n                                      json.dumps({}))\n            response = self.client.get(url)\n\n            self.assertIn('1st line', response.data.decode('utf-8'))\n            self.assertIn('2nd line', response.data.decode('utf-8'))\n            self.assertIn('3rd line', response.data.decode('utf-8'))\n            self.assertNotIn('should never be read', response.data.decode('utf-8'))\n\n    def test_get_logs_with_metadata(self):\n        url_template = \"get_logs_with_metadata?dag_id={}&\" \\\n                       \"task_id={}&execution_date={}&\" \\\n                       \"try_number={}&metadata={}\"\n        response = \\\n            self.client.get(url_template.format(self.DAG_ID,\n                                                self.TASK_ID,\n                                                quote_plus(self.DEFAULT_DATE.isoformat()),\n                                                1,\n                                                json.dumps({})), data=dict(\n                                                    username='test',\n                                                    password='test'),\n                            follow_redirects=True)\n\n        self.assertIn('\"message\":', response.data.decode('utf-8'))\n        self.assertIn('\"metadata\":', response.data.decode('utf-8'))\n        self.assertIn('Log for testing.', response.data.decode('utf-8'))\n        self.assertEqual(200, response.status_code)\n\n    def test_get_logs_with_null_metadata(self):\n        url_template = \"get_logs_with_metadata?dag_id={}&\" \\\n                       \"task_id={}&execution_date={}&\" \\\n                       \"try_number={}&metadata=null\"\n        response = \\\n            self.client.get(url_template.format(self.DAG_ID,\n                                                self.TASK_ID,\n                                                quote_plus(self.DEFAULT_DATE.isoformat()),\n                                                1), data=dict(\n                                                    username='test',\n                                                    password='test'),\n                            follow_redirects=True)\n\n        self.assertIn('\"message\":', response.data.decode('utf-8'))\n        self.assertIn('\"metadata\":', response.data.decode('utf-8'))\n        self.assertIn('Log for testing.', response.data.decode('utf-8'))\n        self.assertEqual(200, response.status_code)", "target": 0}, {"function": "class TestVersionView(TestBase):\n    def test_version(self):\n        resp = self.client.get('version', data=dict(\n            username='test',\n            password='test'\n        ), follow_redirects=True)\n        self.check_content_in_response('Version Info', resp)", "target": 0}, {"function": "class ViewWithDateTimeAndNumRunsAndDagRunsFormTester:\n    DAG_ID = 'dag_for_testing_dt_nr_dr_form'\n    DEFAULT_DATE = datetime(2017, 9, 1)\n    RUNS_DATA = [\n        ('dag_run_for_testing_dt_nr_dr_form_4', datetime(2018, 4, 4)),\n        ('dag_run_for_testing_dt_nr_dr_form_3', datetime(2018, 3, 3)),\n        ('dag_run_for_testing_dt_nr_dr_form_2', datetime(2018, 2, 2)),\n        ('dag_run_for_testing_dt_nr_dr_form_1', datetime(2018, 1, 1)),\n    ]\n\n    def __init__(self, test, endpoint):\n        self.test = test\n        self.endpoint = endpoint\n\n    def setUp(self):\n        from airflow.www.views import dagbag\n        from airflow.utils.state import State\n        dag = DAG(self.DAG_ID, start_date=self.DEFAULT_DATE)\n        dagbag.bag_dag(dag, parent_dag=dag, root_dag=dag)\n        self.runs = []\n        for rd in self.RUNS_DATA:\n            run = dag.create_dagrun(\n                run_id=rd[0],\n                execution_date=rd[1],\n                state=State.SUCCESS,\n                external_trigger=True\n            )\n            self.runs.append(run)\n\n    def tearDown(self):\n        self.test.session.query(DagRun).filter(\n            DagRun.dag_id == self.DAG_ID).delete()\n        self.test.session.commit()\n        self.test.session.close()\n\n    def assertBaseDateAndNumRuns(self, base_date, num_runs, data):\n        self.test.assertNotIn('name=\"base_date\" value=\"{}\"'.format(base_date), data)\n        self.test.assertNotIn('<option selected=\"\" value=\"{}\">{}</option>'.format(\n            num_runs, num_runs), data)\n\n    def assertRunIsNotInDropdown(self, run, data):\n        self.test.assertNotIn(run.execution_date.isoformat(), data)\n        self.test.assertNotIn(run.run_id, data)\n\n    def assertRunIsInDropdownNotSelected(self, run, data):\n        self.test.assertIn('<option value=\"{}\">{}</option>'.format(\n            run.execution_date.isoformat(), run.run_id), data)\n\n    def assertRunIsSelected(self, run, data):\n        self.test.assertIn('<option selected value=\"{}\">{}</option>'.format(\n            run.execution_date.isoformat(), run.run_id), data)\n\n    def test_with_default_parameters(self):\n        \"\"\"\n        Tests view with no URL parameter.\n        Should show all dag runs in the drop down.\n        Should select the latest dag run.\n        Should set base date to current date (not asserted)\n        \"\"\"\n        response = self.test.client.get(\n            self.endpoint, data=dict(\n                username='test',\n                password='test'), follow_redirects=True)\n        self.test.assertEqual(response.status_code, 200)\n        data = response.data.decode('utf-8')\n        self.test.assertIn('Base date:', data)\n        self.test.assertIn('Number of runs:', data)\n        self.assertRunIsSelected(self.runs[0], data)\n        self.assertRunIsInDropdownNotSelected(self.runs[1], data)\n        self.assertRunIsInDropdownNotSelected(self.runs[2], data)\n        self.assertRunIsInDropdownNotSelected(self.runs[3], data)\n\n    def test_with_execution_date_parameter_only(self):\n        \"\"\"\n        Tests view with execution_date URL parameter.\n        Scenario: click link from dag runs view.\n        Should only show dag runs older than execution_date in the drop down.\n        Should select the particular dag run.\n        Should set base date to execution date.\n        \"\"\"\n        response = self.test.client.get(\n            self.endpoint + '&execution_date={}'.format(\n                self.runs[1].execution_date.isoformat()),\n            data=dict(\n                username='test',\n                password='test'\n            ), follow_redirects=True\n        )\n        self.test.assertEqual(response.status_code, 200)\n        data = response.data.decode('utf-8')\n        self.assertBaseDateAndNumRuns(\n            self.runs[1].execution_date,\n            conf.getint('webserver', 'default_dag_run_display_number'),\n            data)\n        self.assertRunIsNotInDropdown(self.runs[0], data)\n        self.assertRunIsSelected(self.runs[1], data)\n        self.assertRunIsInDropdownNotSelected(self.runs[2], data)\n        self.assertRunIsInDropdownNotSelected(self.runs[3], data)\n\n    def test_with_base_date_and_num_runs_parmeters_only(self):\n        \"\"\"\n        Tests view with base_date and num_runs URL parameters.\n        Should only show dag runs older than base_date in the drop down,\n        limited to num_runs.\n        Should select the latest dag run.\n        Should set base date and num runs to submitted values.\n        \"\"\"\n        response = self.test.client.get(\n            self.endpoint + '&base_date={}&num_runs=2'.format(\n                self.runs[1].execution_date.isoformat()),\n            data=dict(\n                username='test',\n                password='test'\n            ), follow_redirects=True\n        )\n        self.test.assertEqual(response.status_code, 200)\n        data = response.data.decode('utf-8')\n        self.assertBaseDateAndNumRuns(self.runs[1].execution_date, 2, data)\n        self.assertRunIsNotInDropdown(self.runs[0], data)\n        self.assertRunIsSelected(self.runs[1], data)\n        self.assertRunIsInDropdownNotSelected(self.runs[2], data)\n        self.assertRunIsNotInDropdown(self.runs[3], data)\n\n    def test_with_base_date_and_num_runs_and_execution_date_outside(self):\n        \"\"\"\n        Tests view with base_date and num_runs and execution-date URL parameters.\n        Scenario: change the base date and num runs and press \"Go\",\n        the selected execution date is outside the new range.\n        Should only show dag runs older than base_date in the drop down.\n        Should select the latest dag run within the range.\n        Should set base date and num runs to submitted values.\n        \"\"\"\n        response = self.test.client.get(\n            self.endpoint + '&base_date={}&num_runs=42&execution_date={}'.format(\n                self.runs[1].execution_date.isoformat(),\n                self.runs[0].execution_date.isoformat()),\n            data=dict(\n                username='test',\n                password='test'\n            ), follow_redirects=True\n        )\n        self.test.assertEqual(response.status_code, 200)\n        data = response.data.decode('utf-8')\n        self.assertBaseDateAndNumRuns(self.runs[1].execution_date, 42, data)\n        self.assertRunIsNotInDropdown(self.runs[0], data)\n        self.assertRunIsSelected(self.runs[1], data)\n        self.assertRunIsInDropdownNotSelected(self.runs[2], data)\n        self.assertRunIsInDropdownNotSelected(self.runs[3], data)\n\n    def test_with_base_date_and_num_runs_and_execution_date_within(self):\n        \"\"\"\n        Tests view with base_date and num_runs and execution-date URL parameters.\n        Scenario: change the base date and num runs and press \"Go\",\n        the selected execution date is within the new range.\n        Should only show dag runs older than base_date in the drop down.\n        Should select the dag run with the execution date.\n        Should set base date and num runs to submitted values.\n        \"\"\"\n        response = self.test.client.get(\n            self.endpoint + '&base_date={}&num_runs=5&execution_date={}'.format(\n                self.runs[2].execution_date.isoformat(),\n                self.runs[3].execution_date.isoformat()),\n            data=dict(\n                username='test',\n                password='test'\n            ), follow_redirects=True\n        )\n        self.test.assertEqual(response.status_code, 200)\n        data = response.data.decode('utf-8')\n        self.assertBaseDateAndNumRuns(self.runs[2].execution_date, 5, data)\n        self.assertRunIsNotInDropdown(self.runs[0], data)\n        self.assertRunIsNotInDropdown(self.runs[1], data)\n        self.assertRunIsInDropdownNotSelected(self.runs[2], data)\n        self.assertRunIsSelected(self.runs[3], data)", "target": 0}, {"function": "class TestGraphView(TestBase):\n    GRAPH_ENDPOINT = '/graph?dag_id={dag_id}'.format(\n        dag_id=ViewWithDateTimeAndNumRunsAndDagRunsFormTester.DAG_ID\n    )\n\n    @classmethod\n    def setUpClass(cls):\n        super().setUpClass()\n\n    def setUp(self):\n        super().setUp()\n        self.tester = ViewWithDateTimeAndNumRunsAndDagRunsFormTester(\n            self, self.GRAPH_ENDPOINT)\n        self.tester.setUp()\n\n    def tearDown(self):\n        self.tester.tearDown()\n        super().tearDown()\n\n    @classmethod\n    def tearDownClass(cls):\n        super().tearDownClass()\n\n    def test_dt_nr_dr_form_default_parameters(self):\n        self.tester.test_with_default_parameters()\n\n    def test_dt_nr_dr_form_with_execution_date_parameter_only(self):\n        self.tester.test_with_execution_date_parameter_only()\n\n    def test_dt_nr_dr_form_with_base_date_and_num_runs_parmeters_only(self):\n        self.tester.test_with_base_date_and_num_runs_parmeters_only()\n\n    def test_dt_nr_dr_form_with_base_date_and_num_runs_and_execution_date_outside(self):\n        self.tester.test_with_base_date_and_num_runs_and_execution_date_outside()\n\n    def test_dt_nr_dr_form_with_base_date_and_num_runs_and_execution_date_within(self):\n        self.tester.test_with_base_date_and_num_runs_and_execution_date_within()", "target": 0}, {"function": "class TestGanttView(TestBase):\n    GANTT_ENDPOINT = '/gantt?dag_id={dag_id}'.format(\n        dag_id=ViewWithDateTimeAndNumRunsAndDagRunsFormTester.DAG_ID\n    )\n\n    @classmethod\n    def setUpClass(cls):\n        super().setUpClass()\n\n    def setUp(self):\n        super().setUp()\n        self.tester = ViewWithDateTimeAndNumRunsAndDagRunsFormTester(\n            self, self.GANTT_ENDPOINT)\n        self.tester.setUp()\n\n    def tearDown(self):\n        self.tester.tearDown()\n        super().tearDown()\n\n    @classmethod\n    def tearDownClass(cls):\n        super().tearDownClass()\n\n    def test_dt_nr_dr_form_default_parameters(self):\n        self.tester.test_with_default_parameters()\n\n    def test_dt_nr_dr_form_with_execution_date_parameter_only(self):\n        self.tester.test_with_execution_date_parameter_only()\n\n    def test_dt_nr_dr_form_with_base_date_and_num_runs_parmeters_only(self):\n        self.tester.test_with_base_date_and_num_runs_parmeters_only()\n\n    def test_dt_nr_dr_form_with_base_date_and_num_runs_and_execution_date_outside(self):\n        self.tester.test_with_base_date_and_num_runs_and_execution_date_outside()\n\n    def test_dt_nr_dr_form_with_base_date_and_num_runs_and_execution_date_within(self):\n        self.tester.test_with_base_date_and_num_runs_and_execution_date_within()", "target": 0}, {"function": "class TestDagACLView(TestBase):\n    \"\"\"\n    Test Airflow DAG acl\n    \"\"\"\n    default_date = timezone.datetime(2018, 6, 1)\n    run_id = \"test_{}\".format(models.DagRun.id_for_date(default_date))\n\n    @classmethod\n    def setUpClass(cls):\n        super().setUpClass()\n        dagbag = models.DagBag(include_examples=True)\n        for dag in dagbag.dags.values():\n            dag.sync_to_db()\n\n    def cleanup_dagruns(self):\n        DR = models.DagRun\n        dag_ids = ['example_bash_operator',\n                   'example_subdag_operator']\n        (self.session\n             .query(DR)\n             .filter(DR.dag_id.in_(dag_ids))\n             .filter(DR.run_id == self.run_id)\n             .delete(synchronize_session='fetch'))\n        self.session.commit()\n\n    def prepare_dagruns(self):\n        dagbag = models.DagBag(include_examples=True)\n        self.bash_dag = dagbag.dags['example_bash_operator']\n        self.sub_dag = dagbag.dags['example_subdag_operator']\n\n        self.bash_dagrun = self.bash_dag.create_dagrun(\n            run_id=self.run_id,\n            execution_date=self.default_date,\n            start_date=timezone.utcnow(),\n            state=State.RUNNING)\n\n        self.sub_dagrun = self.sub_dag.create_dagrun(\n            run_id=self.run_id,\n            execution_date=self.default_date,\n            start_date=timezone.utcnow(),\n            state=State.RUNNING)\n\n    def setUp(self):\n        super().setUp()\n        self.cleanup_dagruns()\n        self.prepare_dagruns()\n        self.logout()\n        self.appbuilder.sm.sync_roles()\n        self.add_permission_for_role()\n\n    def login(self, username=None, password=None):\n        role_admin = self.appbuilder.sm.find_role('Admin')\n        tester = self.appbuilder.sm.find_user(username='test')\n        if not tester:\n            self.appbuilder.sm.add_user(\n                username='test',\n                first_name='test',\n                last_name='test',\n                email='test@fab.org',\n                role=role_admin,\n                password='test')\n\n        role_user = self.appbuilder.sm.find_role('User')\n        test_user = self.appbuilder.sm.find_user(username='test_user')\n        if not test_user:\n            self.appbuilder.sm.add_user(\n                username='test_user',\n                first_name='test_user',\n                last_name='test_user',\n                email='test_user@fab.org',\n                role=role_user,\n                password='test_user')\n\n        role_viewer = self.appbuilder.sm.find_role('Viewer')\n        test_viewer = self.appbuilder.sm.find_user(username='test_viewer')\n        if not test_viewer:\n            self.appbuilder.sm.add_user(\n                username='test_viewer',\n                first_name='test_viewer',\n                last_name='test_viewer',\n                email='test_viewer@fab.org',\n                role=role_viewer,\n                password='test_viewer')\n\n        dag_acl_role = self.appbuilder.sm.add_role('dag_acl_tester')\n        dag_tester = self.appbuilder.sm.find_user(username='dag_tester')\n        if not dag_tester:\n            self.appbuilder.sm.add_user(\n                username='dag_tester',\n                first_name='dag_test',\n                last_name='dag_test',\n                email='dag_test@fab.org',\n                role=dag_acl_role,\n                password='dag_test')\n\n        # create an user without permission\n        dag_no_role = self.appbuilder.sm.add_role('dag_acl_faker')\n        dag_faker = self.appbuilder.sm.find_user(username='dag_faker')\n        if not dag_faker:\n            self.appbuilder.sm.add_user(\n                username='dag_faker',\n                first_name='dag_faker',\n                last_name='dag_faker',\n                email='dag_fake@fab.org',\n                role=dag_no_role,\n                password='dag_faker')\n\n        # create an user with only read permission\n        dag_read_only_role = self.appbuilder.sm.add_role('dag_acl_read_only')\n        dag_read_only = self.appbuilder.sm.find_user(username='dag_read_only')\n        if not dag_read_only:\n            self.appbuilder.sm.add_user(\n                username='dag_read_only',\n                first_name='dag_read_only',\n                last_name='dag_read_only',\n                email='dag_read_only@fab.org',\n                role=dag_read_only_role,\n                password='dag_read_only')\n\n        # create an user that has all dag access\n        all_dag_role = self.appbuilder.sm.add_role('all_dag_role')\n        all_dag_tester = self.appbuilder.sm.find_user(username='all_dag_user')\n        if not all_dag_tester:\n            self.appbuilder.sm.add_user(\n                username='all_dag_user',\n                first_name='all_dag_user',\n                last_name='all_dag_user',\n                email='all_dag_user@fab.org',\n                role=all_dag_role,\n                password='all_dag_user')\n\n        user = username if username else 'dag_tester'\n        passwd = password if password else 'dag_test'\n\n        return self.client.post('/login/', data=dict(\n            username=user,\n            password=passwd\n        ))\n\n    def logout(self):\n        return self.client.get('/logout/')\n\n    def add_permission_for_role(self):\n        self.logout()\n        self.login(username='test',\n                   password='test')\n        perm_on_dag = self.appbuilder.sm.\\\n            find_permission_view_menu('can_dag_edit', 'example_bash_operator')\n        dag_tester_role = self.appbuilder.sm.find_role('dag_acl_tester')\n        self.appbuilder.sm.add_permission_role(dag_tester_role, perm_on_dag)\n\n        perm_on_all_dag = self.appbuilder.sm.\\\n            find_permission_view_menu('can_dag_edit', 'all_dags')\n        all_dag_role = self.appbuilder.sm.find_role('all_dag_role')\n        self.appbuilder.sm.add_permission_role(all_dag_role, perm_on_all_dag)\n\n        role_user = self.appbuilder.sm.find_role('User')\n        self.appbuilder.sm.add_permission_role(role_user, perm_on_all_dag)\n\n        read_only_perm_on_dag = self.appbuilder.sm.\\\n            find_permission_view_menu('can_dag_read', 'example_bash_operator')\n        dag_read_only_role = self.appbuilder.sm.find_role('dag_acl_read_only')\n        self.appbuilder.sm.add_permission_role(dag_read_only_role, read_only_perm_on_dag)\n\n    def test_permission_exist(self):\n        self.logout()\n        self.login(username='test',\n                   password='test')\n        test_view_menu = self.appbuilder.sm.find_view_menu('example_bash_operator')\n        perms_views = self.appbuilder.sm.find_permissions_view_menu(test_view_menu)\n        self.assertEqual(len(perms_views), 2)\n        # each dag view will create one write, and one read permission\n        self.assertTrue(str(perms_views[0]).startswith('can dag'))\n        self.assertTrue(str(perms_views[1]).startswith('can dag'))\n\n    def test_role_permission_associate(self):\n        self.logout()\n        self.login(username='test',\n                   password='test')\n        test_role = self.appbuilder.sm.find_role('dag_acl_tester')\n        perms = {str(perm) for perm in test_role.permissions}\n        self.assertIn('can dag edit on example_bash_operator', perms)\n        self.assertNotIn('can dag read on example_bash_operator', perms)\n\n    def test_index_success(self):\n        self.logout()\n        self.login()\n        resp = self.client.get('/', follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n\n    def test_index_failure(self):\n        self.logout()\n        self.login()\n        resp = self.client.get('/', follow_redirects=True)\n        # The user can only access/view example_bash_operator dag.\n        self.check_content_not_in_response('example_subdag_operator', resp)\n\n    def test_index_for_all_dag_user(self):\n        self.logout()\n        self.login(username='all_dag_user',\n                   password='all_dag_user')\n        resp = self.client.get('/', follow_redirects=True)\n        # The all dag user can access/view all dags.\n        self.check_content_in_response('example_subdag_operator', resp)\n        self.check_content_in_response('example_bash_operator', resp)\n\n    def test_dag_stats_success(self):\n        self.logout()\n        self.login()\n        resp = self.client.get('dag_stats', follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n\n    def test_dag_stats_failure(self):\n        self.logout()\n        self.login()\n        resp = self.client.get('dag_stats', follow_redirects=True)\n        self.check_content_not_in_response('example_subdag_operator', resp)\n\n    def test_dag_stats_success_for_all_dag_user(self):\n        self.logout()\n        self.login(username='all_dag_user',\n                   password='all_dag_user')\n        resp = self.client.get('dag_stats', follow_redirects=True)\n        self.check_content_in_response('example_subdag_operator', resp)\n        self.check_content_in_response('example_bash_operator', resp)\n\n    def test_task_stats_success(self):\n        self.logout()\n        self.login()\n        resp = self.client.get('task_stats', follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n\n    def test_task_stats_failure(self):\n        self.logout()\n        self.login()\n        resp = self.client.get('task_stats', follow_redirects=True)\n        self.check_content_not_in_response('example_subdag_operator', resp)\n\n    def test_task_stats_success_for_all_dag_user(self):\n        self.logout()\n        self.login(username='all_dag_user',\n                   password='all_dag_user')\n        resp = self.client.get('task_stats', follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n        self.check_content_in_response('example_subdag_operator', resp)\n\n    def test_code_success(self):\n        self.logout()\n        self.login()\n        url = 'code?dag_id=example_bash_operator'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n\n    def test_code_failure(self):\n        self.logout()\n        self.login(username='dag_faker',\n                   password='dag_faker')\n        url = 'code?dag_id=example_bash_operator'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_not_in_response('example_bash_operator', resp)\n\n    def test_code_success_for_all_dag_user(self):\n        self.logout()\n        self.login(username='all_dag_user',\n                   password='all_dag_user')\n        url = 'code?dag_id=example_bash_operator'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n\n        url = 'code?dag_id=example_subdag_operator'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('example_subdag_operator', resp)\n\n    def test_dag_details_success(self):\n        self.logout()\n        self.login()\n        url = 'dag_details?dag_id=example_bash_operator'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('DAG details', resp)\n\n    def test_dag_details_failure(self):\n        self.logout()\n        self.login(username='dag_faker',\n                   password='dag_faker')\n        url = 'dag_details?dag_id=example_bash_operator'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_not_in_response('DAG details', resp)\n\n    def test_dag_details_success_for_all_dag_user(self):\n        self.logout()\n        self.login(username='all_dag_user',\n                   password='all_dag_user')\n        url = 'dag_details?dag_id=example_bash_operator'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n\n        url = 'dag_details?dag_id=example_subdag_operator'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('example_subdag_operator', resp)\n\n    def test_rendered_success(self):\n        self.logout()\n        self.login()\n        url = ('rendered?task_id=runme_0&dag_id=example_bash_operator&execution_date={}'\n               .format(self.percent_encode(self.default_date)))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('Rendered Template', resp)\n\n    def test_rendered_failure(self):\n        self.logout()\n        self.login(username='dag_faker',\n                   password='dag_faker')\n        url = ('rendered?task_id=runme_0&dag_id=example_bash_operator&execution_date={}'\n               .format(self.percent_encode(self.default_date)))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_not_in_response('Rendered Template', resp)\n\n    def test_rendered_success_for_all_dag_user(self):\n        self.logout()\n        self.login(username='all_dag_user',\n                   password='all_dag_user')\n        url = ('rendered?task_id=runme_0&dag_id=example_bash_operator&execution_date={}'\n               .format(self.percent_encode(self.default_date)))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('Rendered Template', resp)\n\n    def test_task_success(self):\n        self.logout()\n        self.login()\n        url = ('task?task_id=runme_0&dag_id=example_bash_operator&execution_date={}'\n               .format(self.percent_encode(self.default_date)))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('Task Instance Details', resp)\n\n    def test_task_failure(self):\n        self.logout()\n        self.login(username='dag_faker',\n                   password='dag_faker')\n        url = ('task?task_id=runme_0&dag_id=example_bash_operator&execution_date={}'\n               .format(self.percent_encode(self.default_date)))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_not_in_response('Task Instance Details', resp)\n\n    def test_task_success_for_all_dag_user(self):\n        self.logout()\n        self.login(username='all_dag_user',\n                   password='all_dag_user')\n        url = ('task?task_id=runme_0&dag_id=example_bash_operator&execution_date={}'\n               .format(self.percent_encode(self.default_date)))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('Task Instance Details', resp)\n\n    def test_xcom_success(self):\n        self.logout()\n        self.login()\n        url = ('xcom?task_id=runme_0&dag_id=example_bash_operator&execution_date={}'\n               .format(self.percent_encode(self.default_date)))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('XCom', resp)\n\n    def test_xcom_failure(self):\n        self.logout()\n        self.login(username='dag_faker',\n                   password='dag_faker')\n        url = ('xcom?task_id=runme_0&dag_id=example_bash_operator&execution_date={}'\n               .format(self.percent_encode(self.default_date)))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_not_in_response('XCom', resp)\n\n    def test_xcom_success_for_all_dag_user(self):\n        self.logout()\n        self.login(username='all_dag_user',\n                   password='all_dag_user')\n        url = ('xcom?task_id=runme_0&dag_id=example_bash_operator&execution_date={}'\n               .format(self.percent_encode(self.default_date)))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('XCom', resp)\n\n    def test_run_success(self):\n        self.logout()\n        self.login()\n        form = dict(\n            task_id=\"runme_0\",\n            dag_id=\"example_bash_operator\",\n            ignore_all_deps=\"false\",\n            ignore_ti_state=\"true\",\n            execution_date=self.default_date,\n        )\n        resp = self.client.post('run', data=form)\n        self.check_content_in_response('', resp, resp_code=302)\n\n    def test_run_success_for_all_dag_user(self):\n        self.logout()\n        self.login(username='all_dag_user',\n                   password='all_dag_user')\n        form = dict(\n            task_id=\"runme_0\",\n            dag_id=\"example_bash_operator\",\n            ignore_all_deps=\"false\",\n            ignore_ti_state=\"true\",\n            execution_date=self.default_date\n        )\n        resp = self.client.post('run', data=form)\n        self.check_content_in_response('', resp, resp_code=302)\n\n    def test_blocked_success(self):\n        url = 'blocked'\n        self.logout()\n        self.login()\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n\n    def test_blocked_success_for_all_dag_user(self):\n        url = 'blocked'\n        self.logout()\n        self.login(username='all_dag_user',\n                   password='all_dag_user')\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n        self.check_content_in_response('example_subdag_operator', resp)\n\n    def test_failed_success(self):\n        self.logout()\n        self.login()\n        form = dict(\n            task_id=\"run_this_last\",\n            dag_id=\"example_bash_operator\",\n            execution_date=self.default_date,\n            upstream=\"false\",\n            downstream=\"false\",\n            future=\"false\",\n            past=\"false\",\n        )\n        resp = self.client.post('failed', data=form)\n        self.check_content_in_response('Redirecting', resp, 302)\n\n    def test_duration_success(self):\n        url = 'duration?days=30&dag_id=example_bash_operator'\n        self.logout()\n        self.login()\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n\n    def test_duration_failure(self):\n        url = 'duration?days=30&dag_id=example_bash_operator'\n        self.logout()\n        # login as an user without permissions\n        self.login(username='dag_faker',\n                   password='dag_faker')\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_not_in_response('example_bash_operator', resp)\n\n    def test_tries_success(self):\n        url = 'tries?days=30&dag_id=example_bash_operator'\n        self.logout()\n        self.login()\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n\n    def test_tries_failure(self):\n        url = 'tries?days=30&dag_id=example_bash_operator'\n        self.logout()\n        # login as an user without permissions\n        self.login(username='dag_faker',\n                   password='dag_faker')\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_not_in_response('example_bash_operator', resp)\n\n    def test_landing_times_success(self):\n        url = 'landing_times?days=30&dag_id=example_bash_operator'\n        self.logout()\n        self.login()\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n\n    def test_landing_times_failure(self):\n        url = 'landing_times?days=30&dag_id=example_bash_operator'\n        self.logout()\n        self.login(username='dag_faker',\n                   password='dag_faker')\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_not_in_response('example_bash_operator', resp)\n\n    def test_paused_success(self):\n        # post request failure won't test\n        url = 'paused?dag_id=example_bash_operator&is_paused=false'\n        self.logout()\n        self.login()\n        resp = self.client.post(url, follow_redirects=True)\n        self.check_content_in_response('OK', resp)\n\n    def test_refresh_success(self):\n        self.logout()\n        self.login()\n        resp = self.client.post('refresh?dag_id=example_bash_operator')\n        self.check_content_in_response('', resp, resp_code=302)\n\n    def test_gantt_success(self):\n        url = 'gantt?dag_id=example_bash_operator'\n        self.logout()\n        self.login()\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('example_bash_operator', resp)\n\n    def test_gantt_failure(self):\n        url = 'gantt?dag_id=example_bash_operator'\n        self.logout()\n        self.login(username='dag_faker',\n                   password='dag_faker')\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_not_in_response('example_bash_operator', resp)\n\n    def test_success_fail_for_read_only_role(self):\n        # succcess endpoint need can_dag_edit, which read only role can not access\n        self.logout()\n        self.login(username='dag_read_only',\n                   password='dag_read_only')\n\n        form = dict(\n            task_id=\"run_this_last\",\n            dag_id=\"example_bash_operator\",\n            execution_date=self.default_date,\n            upstream=\"false\",\n            downstream=\"false\",\n            future=\"false\",\n            past=\"false\",\n        )\n        resp = self.client.post('success', data=form)\n        self.check_content_not_in_response('Wait a minute', resp, resp_code=302)\n\n    def test_tree_success_for_read_only_role(self):\n        # tree view only allows can_dag_read, which read only role could access\n        self.logout()\n        self.login(username='dag_read_only',\n                   password='dag_read_only')\n\n        url = 'tree?dag_id=example_bash_operator'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('runme_1', resp)\n\n    def test_log_success(self):\n        self.logout()\n        self.login()\n        url = ('log?task_id=runme_0&dag_id=example_bash_operator&execution_date={}'\n               .format(self.percent_encode(self.default_date)))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('Log by attempts', resp)\n        url = ('get_logs_with_metadata?task_id=runme_0&dag_id=example_bash_operator&'\n               'execution_date={}&try_number=1&metadata=null'\n               .format(self.percent_encode(self.default_date)))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('\"message\":', resp)\n        self.check_content_in_response('\"metadata\":', resp)\n\n    def test_log_failure(self):\n        self.logout()\n        self.login(username='dag_faker',\n                   password='dag_faker')\n        url = ('log?task_id=runme_0&dag_id=example_bash_operator&execution_date={}'\n               .format(self.percent_encode(self.default_date)))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_not_in_response('Log by attempts', resp)\n        url = ('get_logs_with_metadata?task_id=runme_0&dag_id=example_bash_operator&'\n               'execution_date={}&try_number=1&metadata=null'\n               .format(self.percent_encode(self.default_date)))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_not_in_response('\"message\":', resp)\n        self.check_content_not_in_response('\"metadata\":', resp)\n\n    def test_log_success_for_user(self):\n        self.logout()\n        self.login(username='test_user',\n                   password='test_user')\n        url = ('log?task_id=runme_0&dag_id=example_bash_operator&execution_date={}'\n               .format(self.percent_encode(self.default_date)))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('Log by attempts', resp)\n        url = ('get_logs_with_metadata?task_id=runme_0&dag_id=example_bash_operator&'\n               'execution_date={}&try_number=1&metadata=null'\n               .format(self.percent_encode(self.default_date)))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('\"message\":', resp)\n        self.check_content_in_response('\"metadata\":', resp)\n\n    def test_tree_view_for_viewer(self):\n        self.logout()\n        self.login(username='test_viewer',\n                   password='test_viewer')\n        url = 'tree?dag_id=example_bash_operator'\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('runme_1', resp)\n\n    def test_refresh_failure_for_viewer(self):\n        # viewer role can't refresh\n        self.logout()\n        self.login(username='test_viewer',\n                   password='test_viewer')\n        resp = self.client.post('refresh?dag_id=example_bash_operator')\n        self.check_content_in_response('Redirecting', resp, resp_code=302)", "target": 0}, {"function": "class TestTaskInstanceView(TestBase):\n    TI_ENDPOINT = '/taskinstance/list/?_flt_0_execution_date={}'\n\n    def test_start_date_filter(self):\n        resp = self.client.get(self.TI_ENDPOINT.format(\n            self.percent_encode('2018-10-09 22:44:31')))\n        # We aren't checking the logic of the date filter itself (that is built\n        # in to FAB) but simply that our UTC conversion was run - i.e. it\n        # doesn't blow up!\n        self.check_content_in_response('List Task Instance', resp)", "target": 0}, {"function": "class TestTriggerDag(TestBase):\n\n    def setUp(self):\n        super().setUp()\n        self.session = Session()\n        models.DagBag().get_dag(\"example_bash_operator\").sync_to_db(session=self.session)\n\n    def test_trigger_dag_button_normal_exist(self):\n        resp = self.client.get('/', follow_redirects=True)\n        self.assertIn('/trigger?dag_id=example_bash_operator', resp.data.decode('utf-8'))\n        self.assertIn(\"return confirmDeleteDag(this, 'example_bash_operator')\", resp.data.decode('utf-8'))\n\n    @unittest.skipIf('mysql' in conf.get('core', 'sql_alchemy_conn'),\n                     \"flaky when run on mysql\")\n    def test_trigger_dag_button(self):\n\n        test_dag_id = \"example_bash_operator\"\n\n        DR = models.DagRun\n        self.session.query(DR).delete()\n        self.session.commit()\n\n        self.client.post('trigger?dag_id={}'.format(test_dag_id))\n\n        run = self.session.query(DR).filter(DR.dag_id == test_dag_id).first()\n        self.assertIsNotNone(run)\n        self.assertIn(\"manual__\", run.run_id)", "target": 0}, {"function": "class TestExtraLinks(TestBase):\n    def setUp(self):\n        super().setUp()\n        self.ENDPOINT = \"extra_links\"\n        self.DEFAULT_DATE = datetime(2017, 1, 1)\n\n        class RaiseErrorLink(BaseOperatorLink):\n            name = 'raise_error'\n\n            def get_link(self, operator, dttm):\n                raise ValueError('This is an error')\n\n        class NoResponseLink(BaseOperatorLink):\n            name = 'no_response'\n\n            def get_link(self, operator, dttm):\n                return None\n\n        class FooBarLink(BaseOperatorLink):\n            name = 'foo-bar'\n\n            def get_link(self, operator, dttm):\n                return 'http://www.example.com/{0}/{1}/{2}'.format(\n                    operator.task_id, 'foo-bar', dttm)\n\n        class AirflowLink(BaseOperatorLink):\n            name = 'airflow'\n\n            def get_link(self, operator, dttm):\n                return 'https://airflow.apache.org'\n\n        class DummyTestOperator(BaseOperator):\n\n            operator_extra_links = (\n                RaiseErrorLink(),\n                NoResponseLink(),\n                FooBarLink(),\n                AirflowLink(),\n            )\n\n        self.dag = DAG('dag', start_date=self.DEFAULT_DATE)\n        self.task = DummyTestOperator(task_id=\"some_dummy_task\", dag=self.dag)\n\n    def tearDown(self):\n        super().tearDown()\n\n    @mock.patch('airflow.www.views.dagbag.get_dag')\n    def test_extra_links_works(self, get_dag_function):\n        get_dag_function.return_value = self.dag\n\n        response = self.client.get(\n            \"{0}?dag_id={1}&task_id={2}&execution_date={3}&link_name=foo-bar\"\n            .format(self.ENDPOINT, self.dag.dag_id, self.task.task_id, self.DEFAULT_DATE),\n            follow_redirects=True)\n\n        self.assertEqual(response.status_code, 200)\n        response_str = response.data\n        if isinstance(response.data, bytes):\n            response_str = response_str.decode()\n        self.assertEqual(json.loads(response_str), {\n            'url': ('http://www.example.com/some_dummy_task/'\n                    'foo-bar/2017-01-01T00:00:00+00:00'),\n            'error': None\n        })\n\n    @mock.patch('airflow.www.views.dagbag.get_dag')\n    def test_global_extra_links_works(self, get_dag_function):\n        get_dag_function.return_value = self.dag\n\n        response = self.client.get(\n            \"{0}?dag_id={1}&task_id={2}&execution_date={3}&link_name=github\"\n            .format(self.ENDPOINT, self.dag.dag_id, self.task.task_id, self.DEFAULT_DATE),\n            follow_redirects=True)\n\n        self.assertEqual(response.status_code, 200)\n        response_str = response.data\n        if isinstance(response.data, bytes):\n            response_str = response_str.decode()\n        self.assertEqual(json.loads(response_str), {\n            'url': 'https://github.com/apache/airflow',\n            'error': None\n        })\n\n    @mock.patch('airflow.www.views.dagbag.get_dag')\n    def test_operator_extra_link_override_global_extra_link(self, get_dag_function):\n        get_dag_function.return_value = self.dag\n\n        response = self.client.get(\n            \"{0}?dag_id={1}&task_id={2}&execution_date={3}&link_name=airflow\".format(\n                self.ENDPOINT, self.dag.dag_id, self.task.task_id, self.DEFAULT_DATE),\n            follow_redirects=True)\n\n        self.assertEqual(response.status_code, 200)\n        response_str = response.data\n        if isinstance(response.data, bytes):\n            response_str = response_str.decode()\n        self.assertEqual(json.loads(response_str), {\n            'url': 'https://airflow.apache.org',\n            'error': None\n        })\n\n    @mock.patch('airflow.www.views.dagbag.get_dag')\n    def test_extra_links_error_raised(self, get_dag_function):\n        get_dag_function.return_value = self.dag\n\n        response = self.client.get(\n            \"{0}?dag_id={1}&task_id={2}&execution_date={3}&link_name=raise_error\"\n            .format(self.ENDPOINT, self.dag.dag_id, self.task.task_id, self.DEFAULT_DATE),\n            follow_redirects=True)\n\n        self.assertEqual(404, response.status_code)\n        response_str = response.data\n        if isinstance(response.data, bytes):\n            response_str = response_str.decode()\n        self.assertEqual(json.loads(response_str), {\n            'url': None,\n            'error': 'This is an error'})\n\n    @mock.patch('airflow.www.views.dagbag.get_dag')\n    def test_extra_links_no_response(self, get_dag_function):\n        get_dag_function.return_value = self.dag\n\n        response = self.client.get(\n            \"{0}?dag_id={1}&task_id={2}&execution_date={3}&link_name=no_response\"\n            .format(self.ENDPOINT, self.dag.dag_id, self.task.task_id, self.DEFAULT_DATE),\n            follow_redirects=True)\n\n        self.assertEqual(response.status_code, 404)\n        response_str = response.data\n        if isinstance(response.data, bytes):\n            response_str = response_str.decode()\n        self.assertEqual(json.loads(response_str), {\n            'url': None,\n            'error': 'No URL found for no_response'})", "target": 0}, {"function": "class TestDagRunModelView(TestBase):\n    @classmethod\n    def setUpClass(cls):\n        super().setUpClass()\n        models.DagBag().get_dag(\"example_bash_operator\").sync_to_db(session=cls.session)\n        cls.clear_table(models.DagRun)\n\n    def tearDown(self):\n        self.clear_table(models.DagRun)\n\n    def test_create_dagrun(self):\n        data = {\n            \"state\": \"running\",\n            \"dag_id\": \"example_bash_operator\",\n            \"execution_date\": \"2018-07-06 05:04:03\",\n            \"run_id\": \"manual_abc\",\n        }\n        resp = self.client.post('/dagrun/add',\n                                data=data,\n                                follow_redirects=True)\n        self.check_content_in_response('Added Row', resp)\n\n        dr = self.session.query(models.DagRun).one()\n\n        self.assertEqual(dr.execution_date, timezone.convert_to_utc(datetime(2018, 7, 6, 5, 4, 3)))", "target": 0}, {"function": "class TestDecorators(TestBase):\n    EXAMPLE_DAG_DEFAULT_DATE = dates.days_ago(2)\n    run_id = \"test_{}\".format(models.DagRun.id_for_date(EXAMPLE_DAG_DEFAULT_DATE))\n\n    @classmethod\n    def setUpClass(cls):\n        super().setUpClass()\n        dagbag = models.DagBag(include_examples=True)\n        for dag in dagbag.dags.values():\n            dag.sync_to_db()\n\n    def setUp(self):\n        super().setUp()\n        self.logout()\n        self.login()\n        self.cleanup_dagruns()\n        self.prepare_dagruns()\n\n    def cleanup_dagruns(self):\n        DR = models.DagRun\n        dag_ids = ['example_bash_operator',\n                   'example_subdag_operator',\n                   'example_xcom']\n        (self.session\n             .query(DR)\n             .filter(DR.dag_id.in_(dag_ids))\n             .filter(DR.run_id == self.run_id)\n             .delete(synchronize_session='fetch'))\n        self.session.commit()\n\n    def prepare_dagruns(self):\n        dagbag = models.DagBag(include_examples=True)\n        self.bash_dag = dagbag.dags['example_bash_operator']\n        self.sub_dag = dagbag.dags['example_subdag_operator']\n        self.xcom_dag = dagbag.dags['example_xcom']\n\n        self.bash_dagrun = self.bash_dag.create_dagrun(\n            run_id=self.run_id,\n            execution_date=self.EXAMPLE_DAG_DEFAULT_DATE,\n            start_date=timezone.utcnow(),\n            state=State.RUNNING)\n\n        self.sub_dagrun = self.sub_dag.create_dagrun(\n            run_id=self.run_id,\n            execution_date=self.EXAMPLE_DAG_DEFAULT_DATE,\n            start_date=timezone.utcnow(),\n            state=State.RUNNING)\n\n        self.xcom_dagrun = self.xcom_dag.create_dagrun(\n            run_id=self.run_id,\n            execution_date=self.EXAMPLE_DAG_DEFAULT_DATE,\n            start_date=timezone.utcnow(),\n            state=State.RUNNING)\n\n    def check_last_log(self, dag_id, event, execution_date=None):\n        from airflow.models import Log\n        qry = self.session.query(Log.dag_id, Log.task_id, Log.event, Log.execution_date,\n                                 Log.owner, Log.extra)\n        qry = qry.filter(Log.dag_id == dag_id, Log.event == event)\n        if execution_date:\n            qry = qry.filter(Log.execution_date == execution_date)\n        logs = qry.order_by(Log.dttm.desc()).limit(5).all()\n        self.assertGreaterEqual(len(logs), 1)\n        self.assertTrue(logs[0].extra)\n\n    def test_action_logging_get(self):\n        url = 'graph?dag_id=example_bash_operator&execution_date={}'.format(\n            self.percent_encode(self.EXAMPLE_DAG_DEFAULT_DATE))\n        resp = self.client.get(url, follow_redirects=True)\n        self.check_content_in_response('runme_1', resp)\n\n        # In mysql backend, this commit() is needed to write down the logs\n        self.session.commit()\n        self.check_last_log(\"example_bash_operator\", event=\"graph\",\n                            execution_date=self.EXAMPLE_DAG_DEFAULT_DATE)\n\n    def test_action_logging_post(self):\n        form = dict(\n            task_id=\"runme_1\",\n            dag_id=\"example_bash_operator\",\n            execution_date=self.EXAMPLE_DAG_DEFAULT_DATE,\n            upstream=\"false\",\n            downstream=\"false\",\n            future=\"false\",\n            past=\"false\",\n            only_failed=\"false\",\n        )\n        resp = self.client.post(\"clear\", data=form)\n        self.check_content_in_response(['example_bash_operator', 'Wait a minute'], resp)\n        # In mysql backend, this commit() is needed to write down the logs\n        self.session.commit()\n        self.check_last_log(\"example_bash_operator\", event=\"clear\",\n                            execution_date=self.EXAMPLE_DAG_DEFAULT_DATE)", "target": 0}]}], "outdated": 0, "cwe_descripiton": "", "cwe_consequence": "", "cwe_method": "", "cwe_solution": ""}
