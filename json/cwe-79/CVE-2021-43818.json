{"index": 6943, "cve_id": "CVE-2021-43818", "cwe_id": ["CWE-79", "CWE-74"], "cve_language": "Python", "cve_description": "lxml is a library for processing XML and HTML in the Python language. Prior to version 4.6.5, the HTML Cleaner in lxml.html lets certain crafted script content pass through, as well as script content in SVG files embedded using data URIs. Users that employ the HTML cleaner in a security relevant context should upgrade to lxml 4.6.5 to receive a patch. There are no known workarounds available.", "cvss": "7.1", "publish_date": "December 13, 2021", "AV": "NETWORK", "AC": "NETWORK", "PR": "NONE", "UI": "REQUIRED", "S": "CHANGED", "C": "LOW", "I": "LOW", "A": "LOW", "commit_id": "12fa9669007180a7bb87d990c375cf91ca5b664a", "commit_message": "Cleaner: Prevent \"@import\" from re-occurring in the CSS after replacements, e.g. \"@@importimport\".\n\nReported as GHSL-2021-1037", "commit_date": "2021-11-11T12:19:30Z", "project": "lxml/lxml", "url": "https://api.github.com/repos/lxml/lxml/commits/12fa9669007180a7bb87d990c375cf91ca5b664a", "html_url": "https://github.com/lxml/lxml/commit/12fa9669007180a7bb87d990c375cf91ca5b664a", "windows_before": [{"commit_id": "982f8d5612925010a12a70748a077af846def6be", "commit_date": "Fri Nov 5 10:34:03 2021 +0100", "commit_message": "Change version in master branch to 4.7.0a0.", "files_name": ["src/lxml/__init__.py"]}, {"commit_id": "fc58250d1e0316bee26f80e1bbaeb0bc9df3fffc", "commit_date": "Fri Nov 5 10:33:34 2021 +0100", "commit_message": "Explicitly set ACLOCAL_PATH in wheel build script now that we use a non-release version of libxml2 (and the build fails without it).", "files_name": ["tools/manylinux/build-wheels.sh"]}, {"commit_id": "7b941e58ab088a25a8e0a7f6e13e4e5b9dd93c37", "commit_date": "Wed Nov 3 09:50:09 2021 +0100", "commit_message": "Switch to latest libxml2 2.9.12+ (unreleased) that has fixes for traversing lxml's fake root trees.", "files_name": [".github/workflows/wheels.yml", "CHANGES.txt", "Makefile", "buildlibxml.py"]}, {"commit_id": "7efe24307b77fb66771544c5c9730064629d468c", "commit_date": "Tue Nov 2 21:25:22 2021 +0100", "commit_message": "Merge branch 'lxml-4.6'", "files_name": ["24a459910130afc8a16bdecdde35ca9d5aa47f1d - Tue Nov 2 20:28:49 2021 +0100 : Fix PyPy3 as wheel matrix targets.", ".github/workflows/wheels.yml"]}, {"commit_id": "b232e1987408e76fb6450f1a476dbab0377c92e8", "commit_date": "Tue Nov 2 19:57:23 2021 +0100", "commit_message": "Add PyPy3 7.3.3. as wheel matrix targets.", "files_name": [".github/workflows/wheels.yml"]}, {"commit_id": "667f4b47995e0d4cc9b8c20ead1709810c9965d0", "commit_date": "Tue Nov 2 16:50:11 2021 +0100", "commit_message": "Switch bach to macOS 10.14 as wheel deployment target, since 10.9 fails to build cleanly.", "files_name": [".github/workflows/wheels.yml"]}, {"commit_id": "03c3f10f517c72a233241dcfafb8d3429d3e44c8", "commit_date": "Tue Nov 2 16:10:07 2021 +0100", "commit_message": "Skip manylinux2010 builds since they serve no purpose. manylinux1 and manylinux_2_24 should be enough.", "files_name": [".github/workflows/wheels.yml"]}, {"commit_id": "9f801230ac89a640742a9cc5695eda3c184aab0d", "commit_date": "Tue Nov 2 16:07:55 2021 +0100", "commit_message": "Use older macOS 10.9 as wheel deployment target, instead of the more recent 10.14.", "files_name": [".github/workflows/wheels.yml"]}, {"commit_id": "ad43340bd405f963049fa6682dbdc9a4e5462a82", "commit_date": "Tue Nov 2 15:59:23 2021 +0100", "commit_message": "Merge branch 'lxml-4.6'", "files_name": ["b8c0f6f7e0e0a6e34a6c3d57fe8415894bb1dd75 - Tue Nov 2 15:59:12 2021 +0100 : Do not upload plain Linux wheels, only many/musllinux.", ".github/workflows/wheels.yml"]}, {"commit_id": "ae377082fea8520fb1a3a76746c44424d2c1fa0c", "commit_date": "Tue Nov 2 15:19:22 2021 +0100", "commit_message": "Correct the wheel destination path from which they are uploaded.", "files_name": [".github/workflows/wheels.yml"]}, {"commit_id": "96ad726a877d66a94147016ca3d4cd8caec1e93b", "commit_date": "Tue Nov 2 13:55:58 2021 +0100", "commit_message": "Merge branch 'lxml-4.6'", "files_name": ["bbee1e900d46bb7044dedf67455f29433aa385ac - Tue Nov 2 13:36:48 2021 +0100 : Fix download URLs for wheels build on Github Actions.", "download_artefacts.py"]}, {"commit_id": "fd32c6188e27a636624f6082b7ac5cf5c1d10b48", "commit_date": "Mon Nov 1 11:29:23 2021 +0100", "commit_message": "Add wheel building workflow for Github Actions.", "files_name": [".github/workflows/wheels.yml", "Makefile", "setup.py", "tools/manylinux/build-wheels.sh"]}, {"commit_id": "75fbd5077de1852b6b43e1ddc70f86cefc42e08b", "commit_date": "Tue Nov 2 10:48:45 2021 +0000", "commit_message": "Fix arch variable referencing error for Py<3.5 (GH-331)", "files_name": ["buildlibxml.py"]}, {"commit_id": "c71f859e736d4e8261553b842c1e964f0b18d20c", "commit_date": "Tue Nov 2 13:36:48 2021 +0100", "commit_message": "Fix download URLs for wheels build on Github Actions.", "files_name": ["download_artefacts.py"]}, {"commit_id": "54b4074b5935f4743299a2a73cfa877618a0a220", "commit_date": "Mon Nov 1 11:29:23 2021 +0100", "commit_message": "Add wheel building workflow for Github Actions.", "files_name": [".github/workflows/wheels.yml", "Makefile", "setup.py", "tools/manylinux/build-wheels.sh"]}, {"commit_id": "f8924b87ea6db10d4b6c2a6c78aa0e72ca72f578", "commit_date": "Tue Nov 2 10:48:45 2021 +0000", "commit_message": "Fix arch variable referencing error for Py<3.5 (GH-331)", "files_name": ["buildlibxml.py"]}, {"commit_id": "4ea0648b7e67e7cb701cf45e1c02a732e6cf8265", "commit_date": "Fri Oct 22 16:57:50 2021 +0300", "commit_message": "Add package metadata marker for Python 3.10 support (GH-330)", "files_name": ["setup.py", "tox.ini"]}, {"commit_id": "8b72a74464f9d5c9a1d8453fe4ab296f7539f431", "commit_date": "Sun Oct 17 18:33:03 2021 +0100", "commit_message": "Add win-arm64 build support (GH-326)", "files_name": ["buildlibxml.py"]}, {"commit_id": "557f431642b8338de34b6907b480f96ff8a2313d", "commit_date": "Sun Oct 17 19:29:05 2021 +0200", "commit_message": "GitHub Actions: \"3.10\" instead of 3.10-dev, pin rnc2rng to keep py2.7 compat (GH-328)", "files_name": [".github/workflows/ci.yml", ".travis.yml"]}, {"commit_id": "3f77f6f04f7e0c086625c2ab674dfcfb709c0448", "commit_date": "Sun Oct 17 19:27:47 2021 +0200", "commit_message": "Updates FAQ.txt with a detail regarding XPath (GH-329)", "files_name": ["doc/FAQ.txt"]}, {"commit_id": "9d2be1fabd7a1a5157762e0f19bcfb30c84d399a", "commit_date": "Fri Oct 15 12:07:08 2021 +0200", "commit_message": "Update some dead links to their archive.org mirror (GH-327)", "files_name": ["doc/FAQ.txt"]}, {"commit_id": "4d123498d48aa1936cf1502d856b11224da3bd49", "commit_date": "Fri Oct 15 05:40:59 2021 -0400", "commit_message": "Add a manylinux 'musllinux' variant for building wheels (GH-325)", "files_name": ["Makefile"]}, {"commit_id": "22cbfe0d63ab150f22cd23f3783ced396578aaf6", "commit_date": "Mon Nov 1 10:47:49 2021 +0100", "commit_message": "Update release date for 4.6.4.", "files_name": ["CHANGES.txt", "doc/main.txt"]}, {"commit_id": "2d586e565e300cda26c6fce73bdf8a14c8096031", "commit_date": "Fri Oct 22 16:57:50 2021 +0300", "commit_message": "Add package metadata marker for Python 3.10 support (GH-330)", "files_name": ["setup.py", "tox.ini"]}, {"commit_id": "5d7d69d7de25f7d0f5079965e6ab8cfdba672ed1", "commit_date": "Sun Oct 17 18:33:03 2021 +0100", "commit_message": "Add win-arm64 build support (GH-326)", "files_name": ["buildlibxml.py"]}, {"commit_id": "02cdbb301b1b1c0eecea267cb2af9ece5987bfd4", "commit_date": "Sun Oct 17 19:29:05 2021 +0200", "commit_message": "GitHub Actions: \"3.10\" instead of 3.10-dev, pin rnc2rng to keep py2.7 compat (GH-328)", "files_name": [".github/workflows/ci.yml", ".travis.yml"]}, {"commit_id": "ec7d871dc32dbc14874d9eeacf1b709b1df0628d", "commit_date": "Sun Oct 17 19:27:47 2021 +0200", "commit_message": "Updates FAQ.txt with a detail regarding XPath (GH-329)", "files_name": ["doc/FAQ.txt"]}, {"commit_id": "f0f6905a14c1f09c3c38efc8c66856e05aff1b0c", "commit_date": "Fri Oct 15 12:07:08 2021 +0200", "commit_message": "Update some dead links to their archive.org mirror (GH-327)", "files_name": ["doc/FAQ.txt"]}, {"commit_id": "39eaef1fcb7974fd7d2f2165d8be436ead6ad98f", "commit_date": "Fri Oct 15 05:40:59 2021 -0400", "commit_message": "Add a manylinux 'musllinux' variant for building wheels (GH-325)", "files_name": ["Makefile"]}, {"commit_id": "d663158fcb2c1f5495d5ad97b64e69ed205c616c", "commit_date": "Fri Oct 15 11:28:26 2021 +0200", "commit_message": "Merge branch 'lxml-4.6'", "files_name": ["e5aa4547d009aef3393dea13662f8952c0cc6bbb - Fri Oct 15 11:25:41 2021 +0200 : CI: Test against fixed dependency versions in Py2 since many libraries have removed Py3 support by now.", "tools/ci-run.sh"]}, {"commit_id": "288b16cc285c8e8233f6fa8fd6fcd6ed77fec7cf", "commit_date": "Fri Oct 15 11:07:34 2021 +0200", "commit_message": "Update changelog.", "files_name": ["CHANGES.txt"]}, {"commit_id": "eb0e6469d112a2a240509d4f07a9abe0f5ccda3e", "commit_date": "Fri Oct 15 11:04:56 2021 +0200", "commit_message": "Add Python 3.10 to build matrix.", "files_name": [".travis.yml", "appveyor.yml"]}, {"commit_id": "bc84830de8cbd675cae1aa4f753a9fc887a7c268", "commit_date": "Fri Oct 15 11:02:48 2021 +0200", "commit_message": "Prepare release of 4.6.4.", "files_name": ["CHANGES.txt", "doc/main.txt", "src/lxml/__init__.py"]}, {"commit_id": "dfb02bdc527cdb173320b3e181421b42682eba27", "commit_date": "Fri Oct 15 10:52:54 2021 +0200", "commit_message": "Correct sentence in performance comparison docs.", "files_name": ["doc/performance.txt"]}, {"commit_id": "b23c93a9ffb93a84a720a9115e9a4562711fa453", "commit_date": "Fri Oct 15 11:25:41 2021 +0200", "commit_message": "CI: Test against fixed dependency versions in Py2 since many libraries have removed Py3 support by now.", "files_name": ["tools/ci-run.sh"]}, {"commit_id": "015420ddd0161f032014fde3f23dd7a8634f78b6", "commit_date": "Fri Oct 15 11:04:56 2021 +0200", "commit_message": "Add Python 3.10 to build matrix.", "files_name": [".travis.yml", "appveyor.yml"]}, {"commit_id": "5e268f937ac8e6c96c9b60f95e2c9d0c09c0e836", "commit_date": "Fri Oct 15 11:02:48 2021 +0200", "commit_message": "Prepare release of 4.6.4.", "files_name": ["CHANGES.txt", "doc/main.txt", "src/lxml/__init__.py"]}, {"commit_id": "38d3477e8c270f56f5f37a7b4f46ac928a93e330", "commit_date": "Sat Aug 7 11:48:02 2021 +0200", "commit_message": "Remove outdated mention of Pyrex.", "files_name": ["doc/capi.txt"]}, {"commit_id": "3d2141da72148d065a1f2ab91589a7aa998c4074", "commit_date": "Sun Jul 25 12:06:40 2021 +0200", "commit_message": "Add note on crypto currency donations (and why we don't take them).", "files_name": ["README.rst"]}, {"commit_id": "5c8edfa39b0e31490a581740aaff44656ec72348", "commit_date": "Sat Aug 14 12:28:33 2021 +0300", "commit_message": "Add link to Github for PyPi (GH-320)", "files_name": [".gitignore", "setup.py"]}, {"commit_id": "0c9a2198e4855ca1274c2bd5b2e6a9dbba9f8288", "commit_date": "Thu Aug 12 16:58:41 2021 +0200", "commit_message": "Implement a dedicated int/float parser for XML (schema) values in lxml.objectify. This disables support for \"_\" in numbers, which are allowed by Python but not by XMLSchema. We keep a few additional literals, such as \"+NaN\", simply because they shouldn't hurt.", "files_name": ["src/lxml/objectify.pyx", "src/lxml/tests/test_objectify.py"]}, {"commit_id": "e23a807e816373e9eae9d45b5cecdd85ed2fa76a", "commit_date": "Thu Aug 12 08:01:57 2021 +0200", "commit_message": "Use Cython's autowrapping feature for cdef functions to keep internal utility functions out of the objectify module dict.", "files_name": ["src/lxml/objectify.pyx"]}, {"commit_id": "d866aad6313e9a042d5cb8654a891616607c0532", "commit_date": "Sat Aug 7 11:48:02 2021 +0200", "commit_message": "Remove outdated mention of Pyrex.", "files_name": ["doc/capi.txt"]}, {"commit_id": "36bca0b36548e1391f38bdb937593b3f9ce3056b", "commit_date": "Sun Jul 25 12:06:40 2021 +0200", "commit_message": "Add note on crypto currency donations (and why we don't take them).", "files_name": ["README.rst"]}, {"commit_id": "9f89e0f5f7aa97388a38183270aad512f09b0672", "commit_date": "Sun Jul 18 15:58:25 2021 +0200", "commit_message": "Update changelog.", "files_name": ["CHANGES.txt"]}, {"commit_id": "8244dfde2260cbed606852a5e046a53ebb84caa9", "commit_date": "Thu Jul 29 14:25:34 2021 +0200", "commit_message": "_tofilelikeC14N: Always close output buffer (GH-322)", "files_name": ["src/lxml/serializer.pxi"]}, {"commit_id": "02a49b1d6ad177c948652f8b4d72aa0e2b386b89", "commit_date": "Sun Jul 18 11:51:54 2021 +0200", "commit_message": "Rewrite Unicode chunk parsing by directly encoding to UTF-8. Previously, we required Py_UNICODE strings, which is inefficient since most strings in Py3 use the PEP-393 memory layout.", "files_name": ["src/lxml/parser.pxi", "src/lxml/tests/test_elementtree.py"]}, {"commit_id": "b626841385ca65f4f260cef38b5ea32f0dcbe3b1", "commit_date": "Sat Jul 17 02:22:31 2021 +0200", "commit_message": "Try to get the wheel upload working in CI.", "files_name": [".github/workflows/ci.yml"]}, {"commit_id": "566effd518cf6a465cb00c9238c8d9ffe9272d95", "commit_date": "Sat Jul 17 02:08:23 2021 +0200", "commit_message": "Try to get the wheel upload working in CI.", "files_name": [".github/workflows/ci.yml"]}, {"commit_id": "7f03ec206f16574f392574d1622a55f33189242f", "commit_date": "Sat Jul 17 01:05:55 2021 +0200", "commit_message": "Fix wheel build CFLAGS in CI.", "files_name": ["tools/ci-run.sh"]}, {"commit_id": "5b8f5277fdca04b50b906af9ca1851e7f9191163", "commit_date": "Sat Jul 17 01:03:33 2021 +0200", "commit_message": "User older, compatible coverage version in CI.", "files_name": ["tools/ci-run.sh"]}, {"commit_id": "549175ece534bc96d08f0570452f733df2c993ff", "commit_date": "Sat Jul 17 00:59:06 2021 +0200", "commit_message": "Fix CI wheel build target.", "files_name": ["tools/ci-run.sh"]}, {"commit_id": "3706ce50e4006e7ad4d3065d6f18228ca59a20d7", "commit_date": "Sat Jul 17 00:44:35 2021 +0200", "commit_message": "Use -flto for wheel builds.", "files_name": ["tools/ci-run.sh"]}, {"commit_id": "18d9ffebc0ed14dbdef7e2bb073a7dcf2b9d62eb", "commit_date": "Sat Jul 17 00:28:21 2021 +0200", "commit_message": "Improve CFLAGS in CI builds to get better C compiler warnings and better wheels.", "files_name": ["tools/ci-run.sh"]}, {"commit_id": "f26d6be6385034e9ccfcb8ced5764dec8369326a", "commit_date": "Sat Jul 17 00:21:56 2021 +0200", "commit_message": "Fix CI uploads and ccache key.", "files_name": [".github/workflows/ci.yml"]}, {"commit_id": "88778d57b6e12d7d36ca9e5b03b20597ae9928ae", "commit_date": "Sat Jul 17 00:09:20 2021 +0200", "commit_message": "Use ccache in CI builds.", "files_name": ["tools/ci-run.sh"]}, {"commit_id": "aedeafb69356081fc9245d5e8613c5c660c37e79", "commit_date": "Sat Jul 17 00:05:45 2021 +0200", "commit_message": "Disallow CI failures in Py3.10. Seems to work now.", "files_name": []}], "windows_after": [{"commit_id": "f2330237440df7e8f39c3ad1b1aa8852be3b27c0", "commit_date": "Thu Nov 11 13:21:08 2021 +0100", "commit_message": "Cleaner: Remove SVG image data URLs since they can embed script content.", "files_name": ["src/lxml/html/clean.py", "src/lxml/html/tests/test_clean.py"]}, {"commit_id": "7837d13c450eaf48dd9b05c60e3c245b3c7ffe9b", "commit_date": "Fri Nov 19 13:11:59 2021 +0100", "commit_message": "Define LIBXML_STATIC and LIBXSLT_STATIC when linking statically against libxml2/libxslt. This is needed on Windows but shouldn't get in the way otherwise.", "files_name": ["setupinfo.py"]}, {"commit_id": "8a9579c32782f3d59b73bcf3e7d2fb3b52b80956", "commit_date": "Fri Nov 19 17:28:48 2021 +0100", "commit_message": "Make sure the namespace mapping stack in C14NWriterTarget contains only Unicode strings, not bytes.", "files_name": ["src/lxml/etree.pyx", "src/lxml/serializer.pxi"]}, {"commit_id": "fefdcc06c4704aefddd44ef2d02748db8dd9e7e7", "commit_date": "Sun Nov 21 21:04:21 2021 +0100", "commit_message": "Add test for Python3 regression in C14N2 serialization (GH-332)", "files_name": ["src/lxml/tests/test_etree.py"]}, {"commit_id": "c8b6f714576ddfc5c16d3b6e885753f52e2992b1", "commit_date": "Sun Nov 21 20:14:22 2021 +0100", "commit_message": "Download Windows libraries from new \"lxml/libxml2-win-binaries\" repo.", "files_name": ["buildlibxml.py"]}, {"commit_id": "e6c925f8c61bc62a572dc4ff945569ee59b2128a", "commit_date": "Sun Nov 21 22:10:01 2021 +0100", "commit_message": "Include header files of zlib+libiconv in static wheel builds.", "files_name": ["CHANGES.txt", "setup.py"]}, {"commit_id": "9e8633538985907dca0604bb28010dd7a72366ab", "commit_date": "Sun Nov 21 22:21:18 2021 +0100", "commit_message": "Update changelog.", "files_name": ["CHANGES.txt"]}, {"commit_id": "d3b9676f7fe6aaf388577c9a4c446bbe2f92c307", "commit_date": "Sun Nov 21 22:34:38 2021 +0100", "commit_message": "Use newer VS image in appveyor to enable Py3.9/10 support.", "files_name": ["appveyor.yml"]}, {"commit_id": "ac6b00dd7e60f2fc85baf28799596b0e005e9627", "commit_date": "Mon Nov 29 09:15:30 2021 +0100", "commit_message": "Use the non-depcrecated TextTestResult instead of _TextTestResult (GH-333)", "files_name": ["test.py"]}, {"commit_id": "97bf85d31c0338314b7545c1303508ded9d51379", "commit_date": "Fri Dec 10 10:40:28 2021 +0100", "commit_message": "Add macOS-M1 as wheel build platform.", "files_name": [".github/workflows/wheels.yml"]}, {"commit_id": "cc1028fda607eb264c94d6535f2639138a8297c7", "commit_date": "Fri Dec 10 10:51:58 2021 +0100", "commit_message": "Install automake and libtool in macOS build to be able to install the latest non-release libxml2.", "files_name": [".github/workflows/wheels.yml"]}, {"commit_id": "fd0d4713f258f77e57d289415001d5b9ce04ce53", "commit_date": "Fri Dec 10 10:51:58 2021 +0100", "commit_message": "Install automake and libtool in macOS build to be able to install the latest non-release libxml2.", "files_name": [".github/workflows/wheels.yml"]}, {"commit_id": "cd4bec9cb62b3134b09494bd0ba6b6bc11d184df", "commit_date": "Fri Dec 10 10:40:28 2021 +0100", "commit_message": "Add macOS-M1 as wheel build platform.", "files_name": [".github/workflows/wheels.yml"]}, {"commit_id": "d083b8d7f4121aed6e2e99a06fbb85d41ad9e550", "commit_date": "Fri Dec 10 21:00:29 2021 +0100", "commit_message": "Exclude a test when using the macOS system libraries because it fails with libxml2 2.9.4.", "files_name": ["src/lxml/tests/common_imports.py", "src/lxml/tests/test_htmlparser.py", "src/lxml/tests/test_unicode.py"]}, {"commit_id": "d85c6de992886dd13f6b7acb8e549674d313f6f8", "commit_date": "Fri Dec 10 21:00:29 2021 +0100", "commit_message": "Exclude a test when using the macOS system libraries because it fails with libxml2 2.9.4.", "files_name": ["src/lxml/tests/common_imports.py", "src/lxml/tests/test_htmlparser.py", "src/lxml/tests/test_unicode.py"]}, {"commit_id": "4b220b5ee6f53312418004d830d37cef4fbc1681", "commit_date": "Mon Nov 29 09:15:30 2021 +0100", "commit_message": "Use the non-depcrecated TextTestResult instead of _TextTestResult (GH-333)", "files_name": ["test.py"]}, {"commit_id": "add0d3d85eebc1ce7357352910c04e0e8a82f138", "commit_date": "Fri Dec 10 21:16:03 2021 +0100", "commit_message": "Fix condition in test decorator.", "files_name": ["src/lxml/tests/common_imports.py"]}, {"commit_id": "54d2985a36184a4b36017a6000fa4d11411f7292", "commit_date": "Fri Dec 10 21:16:03 2021 +0100", "commit_message": "Fix condition in test decorator.", "files_name": ["src/lxml/tests/common_imports.py"]}, {"commit_id": "69a747356655158fdf9abaecea5feafb3bd6b5f5", "commit_date": "Sat Dec 11 12:19:21 2021 +0100", "commit_message": "Cleaner: cover some more cases where scripts could sneak through in specially crafted style content.", "files_name": ["src/lxml/html/clean.py", "src/lxml/html/tests/test_clean.py"]}, {"commit_id": "b7ea6871bd751b588868cf85b7784211f2c12fe7", "commit_date": "Sat Dec 11 12:19:44 2021 +0100", "commit_message": "Update changelog.", "files_name": ["CHANGES.txt"]}, {"commit_id": "a3eacbc0dcf1de1c822ec29fb7d090a4b1712a9c", "commit_date": "Sun Dec 12 15:10:58 2021 +0100", "commit_message": "Prepare release of 4.6.5.", "files_name": ["CHANGES.txt", "doc/main.txt", "src/lxml/__init__.py"]}, {"commit_id": "99f6eb5495d5fe742958669ca3661524c037e177", "commit_date": "Sun Dec 12 15:14:42 2021 +0100", "commit_message": "Merge branch 'lxml-4.6'", "files_name": ["a9611ba80bc5196c1dd07a0b1964fcb603695d63 - Sun Dec 12 15:23:49 2021 +0100 : Fix a test in Py2.", "src/lxml/html/tests/test_clean.py"]}, {"commit_id": "68607a1e62979b3441b8957bbace508d2fcee0c5", "commit_date": "Sun Dec 12 15:30:20 2021 +0100", "commit_message": "Merge branch 'lxml-4.6'", "files_name": ["5c4f6a23d5758ec66cfe22b082a40c2e08df4658 - Sun Dec 12 22:37:23 2021 +0100 : Prepare release of lxml 4.7.0.", "CHANGES.txt", "doc/main.txt", "src/lxml/__init__.py"]}, {"commit_id": "bef75f90ce7d3f9b46e86496b9ee9a59c540495a", "commit_date": "Sun Dec 12 22:41:12 2021 +0100", "commit_message": "Fix some doc links.", "files_name": ["doc/main.txt"]}, {"commit_id": "4848bfc1628ad6f917b2d06e311a110c2f496660", "commit_date": "Mon Dec 13 09:33:41 2021 +0100", "commit_message": "Make sure the apidocs are generated from the freshly built modules.", "files_name": ["Makefile"]}, {"commit_id": "891f273b7b5d691b377b972d0f8659bad9ac7144", "commit_date": "Mon Dec 13 13:20:25 2021 +0100", "commit_message": "Do not overwrite the wildcard includes for the \"lxml.includes\" package when adding installed header files.", "files_name": ["setup.py"]}, {"commit_id": "393443595416bafc14e345331969274e85726e7a", "commit_date": "Mon Dec 13 13:21:29 2021 +0100", "commit_message": "Prepare release of lxml 4.7.1.", "files_name": ["CHANGES.txt", "doc/main.txt", "src/lxml/__init__.py"]}, {"commit_id": "016be649e5d01c1b029e0701b83d9d0c368ddf6f", "commit_date": "Mon Dec 13 13:29:22 2021 +0100", "commit_message": "Remove useless macOS-M1 build target since there are currently no GHA build servers for it.", "files_name": [".github/workflows/wheels.yml"]}, {"commit_id": "f0a575a5b5d9860be5b481950194f443ba7b9eac", "commit_date": "Mon Dec 13 13:49:36 2021 +0100", "commit_message": "Add a test to get at least minimal coverage for the lxml.html.builder module.", "files_name": ["src/lxml/tests/test_builder.py"]}, {"commit_id": "745ac2685ca05c67afbf2a1dde24e4d48bd86dcd", "commit_date": "Mon Dec 13 14:27:54 2021 +0100", "commit_message": "Move zlib.h and friends into a subdirectory \"extlibs\" in lxml/includes/ to separate them from lxml-version.h etc. These files are copied by setuptools as package data from an external install directory and thus need to be in a separate package to prevent conflicting with the content of the normal lxml.includes package.", "files_name": [".gitignore", "setup.py"]}, {"commit_id": "4fce7ff777126ec5fd011d4f8da04efc62d2b0de", "commit_date": "Mon Dec 13 21:55:58 2021 +0100", "commit_message": "Update changelog to add the (single) CVE ID for the two HTML Cleaner security issues.", "files_name": ["CHANGES.txt"]}, {"commit_id": "9133c26da758b7cc0a837b2359a8297222eebfc9", "commit_date": "Mon Dec 13 21:56:05 2021 +0100", "commit_message": "Merge branch 'lxml-4.6'", "files_name": ["2b9e0477f37c739498396131ca10211091002e4b - Mon Dec 13 23:23:47 2021 +0100 : Update several links in the docs.", "doc/FAQ.txt", "doc/build.txt", "doc/lxml-source-howto.txt", "doc/main.txt", "doc/mkhtml.py", "doc/mklatex.py"]}, {"commit_id": "88a3e0a2903176dc14e37410b0c1422839c9b406", "commit_date": "Sat Dec 25 15:06:04 2021 +0100", "commit_message": "Remove link to PDF documentation as it's currently unavailable.", "files_name": ["doc/main.txt"]}, {"commit_id": "17c30e84fa7ebd5fb14da8f5884507d80902797f", "commit_date": "Sun Jan 2 12:18:57 2022 +0100", "commit_message": "Make regex more efficient.", "files_name": ["buildlibxml.py"]}, {"commit_id": "4eff06df2f25e07e7b46954bd2bd02920b470cf9", "commit_date": "Sun Jan 2 19:54:11 2022 +0800", "commit_message": "Fix typos (GH-334)", "files_name": ["doc/FAQ.txt", "src/lxml/html/diff.py"]}, {"commit_id": "ec3ac3733efe0a067fdc2bf937a98dc6b3e965d9", "commit_date": "Thu Jan 13 09:52:38 2022 +0100", "commit_message": "Added note to documentation about XSLT bug (GH-335)", "files_name": ["doc/xpathxslt.txt"]}, {"commit_id": "d56997b270c120893fbcfb777e170bf61691f262", "commit_date": "Thu Jan 13 15:17:53 2022 +0100", "commit_message": "Add a visible warning to the build output when detecting libxml2 2.9.11 or 2.9.12.", "files_name": ["setupinfo.py"]}, {"commit_id": "5a5c7fb01d15af58def4bab2ba7b15c937042835", "commit_date": "Thu Jan 13 15:28:42 2022 +0100", "commit_message": "Update the build and dependency docs a little. Also add a warning about libxml2 2.9.11/12.", "files_name": ["doc/FAQ.txt", "doc/build.txt"]}, {"commit_id": "55f281565a455dcf77731d38ddd86284c3ca3e28", "commit_date": "Thu Jan 20 18:56:56 2022 +0800", "commit_message": "setupinfo.py: check the return value of subprocesses (GH-336)", "files_name": ["setupinfo.py"]}, {"commit_id": "ac829d561c0bf71fb8cc704305ffc18bd26c6abb", "commit_date": "Fri Jan 21 17:56:44 2022 +0100", "commit_message": "Make it clear that the HTML Cleaner is not meant for security sensitive environments.", "files_name": ["doc/lxmlhtml.txt"]}, {"commit_id": "1e3666018329cadf8e147607824614aebf7e2099", "commit_date": "Sat Feb 12 21:40:07 2022 +0100", "commit_message": "Allow Path-like objects for file arguments (GH-337)", "files_name": ["src/lxml/apihelpers.pxi", "src/lxml/dtd.pxi", "src/lxml/includes/etree_defs.h", "src/lxml/iterparse.pxi", "src/lxml/parser.pxi", "src/lxml/python.pxd", "src/lxml/serializer.pxi", "src/lxml/tests/common_imports.py", "src/lxml/tests/test_dtd.py", "src/lxml/tests/test_etree.py", "src/lxml/tests/test_xmlschema.py", "src/lxml/tests/test_xslt.py", "src/lxml/xmlschema.pxi"]}, {"commit_id": "f7bb07b5f68fede97754685dad076cd7b7442bac", "commit_date": "Sun Feb 13 19:40:39 2022 +0100", "commit_message": "Use expected XSD spellings for xsi:double infinity and NaN (GH-338)", "files_name": ["src/lxml/objectify.pyx", "src/lxml/tests/test_objectify.py"]}, {"commit_id": "ec2b2e5ae83bd7fae4f32dc6737dea64de58cc37", "commit_date": "Mon Feb 14 20:20:22 2022 +0100", "commit_message": "Allow QName as tag value in ElementMaker, not just strings.", "files_name": ["src/lxml/builder.pxd", "src/lxml/builder.py", "src/lxml/tests/test_builder.py"]}, {"commit_id": "62104691cc773d4b668951f5d2324ae1579792c0", "commit_date": "Mon Feb 14 20:43:32 2022 +0100", "commit_message": "Modernise some code in the ElementMaker implementation.", "files_name": ["src/lxml/builder.py"]}, {"commit_id": "c5a398bfa2660d07eca5881fa6cc60fe9413428c", "commit_date": "Mon Feb 14 20:44:42 2022 +0100", "commit_message": "Add an AArch64 wheel build for Py3.6.", "files_name": [".github/workflows/wheels.yml"]}, {"commit_id": "4cb54bcace727c2f4da464e2ecc04737ed855b72", "commit_date": "Tue Feb 15 23:53:56 2022 +0100", "commit_message": "Update changelog.", "files_name": ["CHANGES.txt"]}, {"commit_id": "e82c9153c4a7d505480b94c60b9a84d79d948efb", "commit_date": "Thu Feb 17 12:07:39 2022 +0100", "commit_message": "Prepare release of 4.8.0.", "files_name": ["CHANGES.txt", "doc/main.txt", "src/lxml/__init__.py"]}, {"commit_id": "064ff1f6298e96e292a398ccc1922aa05785fef0", "commit_date": "Thu Feb 17 15:10:24 2022 +0100", "commit_message": "Fix Py3.6 wheel build for AArch64.", "files_name": ["Makefile"]}, {"commit_id": "9660889bbbc0c961452590e261420d7b603c122d", "commit_date": "Fri Feb 18 11:42:40 2022 +0100", "commit_message": "Parse libxml2 error constants from libxml2-api.xml instead of the HTML sources to avoid having to generate the documentation. Also avoid actually writing the output files if there are no changes, to avoid useless rebuilds.", "files_name": ["update-error-constants.py"]}, {"commit_id": "182e0c92f7fd32701f85cad532f29c2e559757b5", "commit_date": "Fri Feb 18 12:12:48 2022 +0100", "commit_message": "Add CI test jobs for Python 3.11. (GH-339)", "files_name": [".github/workflows/ci.yml"]}, {"commit_id": "9bec8d63c3e9ccd93d99bc53762786aa98c71c2d", "commit_date": "Fri Feb 18 12:00:46 2022 +0100", "commit_message": "Clean up some docstrings.", "files_name": ["src/lxml/xmlerror.pxi"]}, {"commit_id": "1fa1800401ca56a7657c0e55a19a71059ec97820", "commit_date": "Fri Feb 18 12:02:44 2022 +0100", "commit_message": "Update outdated comment.", "files_name": []}], "parents": [{"commit_id_before": "24a459910130afc8a16bdecdde35ca9d5aa47f1d", "url_before": "https://api.github.com/repos/lxml/lxml/commits/24a459910130afc8a16bdecdde35ca9d5aa47f1d", "html_url_before": "https://github.com/lxml/lxml/commit/24a459910130afc8a16bdecdde35ca9d5aa47f1d"}], "details": [{"raw_url": "https://github.com/lxml/lxml/raw/12fa9669007180a7bb87d990c375cf91ca5b664a/src%2Flxml%2Fhtml%2Fclean.py", "code": "# cython: language_level=3str\n\n\"\"\"A cleanup tool for HTML.\n\nRemoves unwanted tags and content.  See the `Cleaner` class for\ndetails.\n\"\"\"\n\nfrom __future__ import absolute_import\n\nimport copy\nimport re\nimport sys\ntry:\n    from urlparse import urlsplit\n    from urllib import unquote_plus\nexcept ImportError:\n    # Python 3\n    from urllib.parse import urlsplit, unquote_plus\nfrom lxml import etree\nfrom lxml.html import defs\nfrom lxml.html import fromstring, XHTML_NAMESPACE\nfrom lxml.html import xhtml_to_html, _transform_result\n\ntry:\n    unichr\nexcept NameError:\n    # Python 3\n    unichr = chr\ntry:\n    unicode\nexcept NameError:\n    # Python 3\n    unicode = str\ntry:\n    basestring\nexcept NameError:\n    basestring = (str, bytes)\n\n\n__all__ = ['clean_html', 'clean', 'Cleaner', 'autolink', 'autolink_html',\n           'word_break', 'word_break_html']\n\n# Look at http://code.sixapart.com/trac/livejournal/browser/trunk/cgi-bin/cleanhtml.pl\n#   Particularly the CSS cleaning; most of the tag cleaning is integrated now\n# I have multiple kinds of schemes searched; but should schemes be\n#   whitelisted instead?\n# max height?\n# remove images?  Also in CSS?  background attribute?\n# Some way to whitelist object, iframe, etc (e.g., if you want to\n#   allow *just* embedded YouTube movies)\n# Log what was deleted and why?\n# style=\"behavior: ...\" might be bad in IE?\n# Should we have something for just <meta http-equiv>?  That's the worst of the\n#   metas.\n# UTF-7 detections?  Example:\n#     <HEAD><META HTTP-EQUIV=\"CONTENT-TYPE\" CONTENT=\"text/html; charset=UTF-7\"> </HEAD>+ADw-SCRIPT+AD4-alert('XSS');+ADw-/SCRIPT+AD4-\n#   you don't always have to have the charset set, if the page has no charset\n#   and there's UTF7-like code in it.\n# Look at these tests: http://htmlpurifier.org/live/smoketests/xssAttacks.php\n\n\n# This is an IE-specific construct you can have in a stylesheet to\n# run some Javascript:\n_replace_css_javascript = re.compile(\n    r'expression\\s*\\(.*?\\)', re.S|re.I).sub\n\n# Do I have to worry about @\\nimport?\n_replace_css_import = re.compile(\n    r'@\\s*import', re.I).sub\n\n_looks_like_tag_content = re.compile(\n    r'</?[a-zA-Z]+|\\son[a-zA-Z]+\\s*=',\n    *((re.ASCII,) if sys.version_info[0] >= 3 else ())).search\n\n# All kinds of schemes besides just javascript: that can cause\n# execution:\n_is_image_dataurl = re.compile(\n    r'^data:image/.+;base64', re.I).search\n_is_possibly_malicious_scheme = re.compile(\n    r'(?:javascript|jscript|livescript|vbscript|data|about|mocha):',\n    re.I).search\ndef _is_javascript_scheme(s):\n    if _is_image_dataurl(s):\n        return None\n    return _is_possibly_malicious_scheme(s)\n\n_substitute_whitespace = re.compile(r'[\\s\\x00-\\x08\\x0B\\x0C\\x0E-\\x19]+').sub\n# FIXME: should data: be blocked?\n\n# FIXME: check against: http://msdn2.microsoft.com/en-us/library/ms537512.aspx\n_conditional_comment_re = re.compile(\n    r'\\[if[\\s\\n\\r]+.*?][\\s\\n\\r]*>', re.I|re.S)\n\n_find_styled_elements = etree.XPath(\n    \"descendant-or-self::*[@style]\")\n\n_find_external_links = etree.XPath(\n    (\"descendant-or-self::a  [normalize-space(@href) and substring(normalize-space(@href),1,1) != '#'] |\"\n     \"descendant-or-self::x:a[normalize-space(@href) and substring(normalize-space(@href),1,1) != '#']\"),\n    namespaces={'x':XHTML_NAMESPACE})\n\n\nclass Cleaner(object):\n    \"\"\"\n    Instances cleans the document of each of the possible offending\n    elements.  The cleaning is controlled by attributes; you can\n    override attributes in a subclass, or set them in the constructor.\n\n    ``scripts``:\n        Removes any ``<script>`` tags.\n\n    ``javascript``:\n        Removes any Javascript, like an ``onclick`` attribute. Also removes stylesheets\n        as they could contain Javascript.\n\n    ``comments``:\n        Removes any comments.\n\n    ``style``:\n        Removes any style tags.\n\n    ``inline_style``\n        Removes any style attributes.  Defaults to the value of the ``style`` option.\n\n    ``links``:\n        Removes any ``<link>`` tags\n\n    ``meta``:\n        Removes any ``<meta>`` tags\n\n    ``page_structure``:\n        Structural parts of a page: ``<head>``, ``<html>``, ``<title>``.\n\n    ``processing_instructions``:\n        Removes any processing instructions.\n\n    ``embedded``:\n        Removes any embedded objects (flash, iframes)\n\n    ``frames``:\n        Removes any frame-related tags\n\n    ``forms``:\n        Removes any form tags\n\n    ``annoying_tags``:\n        Tags that aren't *wrong*, but are annoying.  ``<blink>`` and ``<marquee>``\n\n    ``remove_tags``:\n        A list of tags to remove.  Only the tags will be removed,\n        their content will get pulled up into the parent tag.\n\n    ``kill_tags``:\n        A list of tags to kill.  Killing also removes the tag's content,\n        i.e. the whole subtree, not just the tag itself.\n\n    ``allow_tags``:\n        A list of tags to include (default include all).\n\n    ``remove_unknown_tags``:\n        Remove any tags that aren't standard parts of HTML.\n\n    ``safe_attrs_only``:\n        If true, only include 'safe' attributes (specifically the list\n        from the feedparser HTML sanitisation web site).\n\n    ``safe_attrs``:\n        A set of attribute names to override the default list of attributes\n        considered 'safe' (when safe_attrs_only=True).\n\n    ``add_nofollow``:\n        If true, then any <a> tags will have ``rel=\"nofollow\"`` added to them.\n\n    ``host_whitelist``:\n        A list or set of hosts that you can use for embedded content\n        (for content like ``<object>``, ``<link rel=\"stylesheet\">``, etc).\n        You can also implement/override the method\n        ``allow_embedded_url(el, url)`` or ``allow_element(el)`` to\n        implement more complex rules for what can be embedded.\n        Anything that passes this test will be shown, regardless of\n        the value of (for instance) ``embedded``.\n\n        Note that this parameter might not work as intended if you do not\n        make the links absolute before doing the cleaning.\n\n        Note that you may also need to set ``whitelist_tags``.\n\n    ``whitelist_tags``:\n        A set of tags that can be included with ``host_whitelist``.\n        The default is ``iframe`` and ``embed``; you may wish to\n        include other tags like ``script``, or you may want to\n        implement ``allow_embedded_url`` for more control.  Set to None to\n        include all tags.\n\n    This modifies the document *in place*.\n    \"\"\"\n\n    scripts = True\n    javascript = True\n    comments = True\n    style = False\n    inline_style = None\n    links = True\n    meta = True\n    page_structure = True\n    processing_instructions = True\n    embedded = True\n    frames = True\n    forms = True\n    annoying_tags = True\n    remove_tags = None\n    allow_tags = None\n    kill_tags = None\n    remove_unknown_tags = True\n    safe_attrs_only = True\n    safe_attrs = defs.safe_attrs\n    add_nofollow = False\n    host_whitelist = ()\n    whitelist_tags = {'iframe', 'embed'}\n\n    def __init__(self, **kw):\n        not_an_attribute = object()\n        for name, value in kw.items():\n            default = getattr(self, name, not_an_attribute)\n            if (default is not None and default is not True and default is not False\n                    and not isinstance(default, (frozenset, set, tuple, list))):\n                raise TypeError(\n                    \"Unknown parameter: %s=%r\" % (name, value))\n            setattr(self, name, value)\n        if self.inline_style is None and 'inline_style' not in kw:\n            self.inline_style = self.style\n\n        if kw.get(\"allow_tags\"):\n            if kw.get(\"remove_unknown_tags\"):\n                raise ValueError(\"It does not make sense to pass in both \"\n                                 \"allow_tags and remove_unknown_tags\")\n            self.remove_unknown_tags = False\n\n    # Used to lookup the primary URL for a given tag that is up for\n    # removal:\n    _tag_link_attrs = dict(\n        script='src',\n        link='href',\n        # From: http://java.sun.com/j2se/1.4.2/docs/guide/misc/applet.html\n        # From what I can tell, both attributes can contain a link:\n        applet=['code', 'object'],\n        iframe='src',\n        embed='src',\n        layer='src',\n        # FIXME: there doesn't really seem like a general way to figure out what\n        # links an <object> tag uses; links often go in <param> tags with values\n        # that we don't really know.  You'd have to have knowledge about specific\n        # kinds of plugins (probably keyed off classid), and match against those.\n        ##object=?,\n        # FIXME: not looking at the action currently, because it is more complex\n        # than than -- if you keep the form, you should keep the form controls.\n        ##form='action',\n        a='href',\n        )\n\n    def __call__(self, doc):\n        \"\"\"\n        Cleans the document.\n        \"\"\"\n        try:\n            getroot = doc.getroot\n        except AttributeError:\n            pass  # Element instance\n        else:\n            doc = getroot()  # ElementTree instance, instead of an element\n        # convert XHTML to HTML\n        xhtml_to_html(doc)\n        # Normalize a case that IE treats <image> like <img>, and that\n        # can confuse either this step or later steps.\n        for el in doc.iter('image'):\n            el.tag = 'img'\n        if not self.comments:\n            # Of course, if we were going to kill comments anyway, we don't\n            # need to worry about this\n            self.kill_conditional_comments(doc)\n\n        kill_tags = set(self.kill_tags or ())\n        remove_tags = set(self.remove_tags or ())\n        allow_tags = set(self.allow_tags or ())\n\n        if self.scripts:\n            kill_tags.add('script')\n        if self.safe_attrs_only:\n            safe_attrs = set(self.safe_attrs)\n            for el in doc.iter(etree.Element):\n                attrib = el.attrib\n                for aname in attrib.keys():\n                    if aname not in safe_attrs:\n                        del attrib[aname]\n        if self.javascript:\n            if not (self.safe_attrs_only and\n                    self.safe_attrs == defs.safe_attrs):\n                # safe_attrs handles events attributes itself\n                for el in doc.iter(etree.Element):\n                    attrib = el.attrib\n                    for aname in attrib.keys():\n                        if aname.startswith('on'):\n                            del attrib[aname]\n            doc.rewrite_links(self._remove_javascript_link,\n                              resolve_base_href=False)\n            # If we're deleting style then we don't have to remove JS links\n            # from styles, otherwise...\n            if not self.inline_style:\n                for el in _find_styled_elements(doc):\n                    old = el.get('style')\n                    new = _replace_css_javascript('', old)\n                    new = _replace_css_import('', new)\n                    if self._has_sneaky_javascript(new):\n                        # Something tricky is going on...\n                        del el.attrib['style']\n                    elif new != old:\n                        el.set('style', new)\n            if not self.style:\n                for el in list(doc.iter('style')):\n                    if el.get('type', '').lower().strip() == 'text/javascript':\n                        el.drop_tree()\n                        continue\n                    old = el.text or ''\n                    new = _replace_css_javascript('', old)\n                    # The imported CSS can do anything; we just can't allow:\n                    new = _replace_css_import('', new)\n                    if self._has_sneaky_javascript(new):\n                        # Something tricky is going on...\n                        el.text = '/* deleted */'\n                    elif new != old:\n                        el.text = new\n        if self.comments:\n            kill_tags.add(etree.Comment)\n        if self.processing_instructions:\n            kill_tags.add(etree.ProcessingInstruction)\n        if self.style:\n            kill_tags.add('style')\n        if self.inline_style:\n            etree.strip_attributes(doc, 'style')\n        if self.links:\n            kill_tags.add('link')\n        elif self.style or self.javascript:\n            # We must get rid of included stylesheets if Javascript is not\n            # allowed, as you can put Javascript in them\n            for el in list(doc.iter('link')):\n                if 'stylesheet' in el.get('rel', '').lower():\n                    # Note this kills alternate stylesheets as well\n                    if not self.allow_element(el):\n                        el.drop_tree()\n        if self.meta:\n            kill_tags.add('meta')\n        if self.page_structure:\n            remove_tags.update(('head', 'html', 'title'))\n        if self.embedded:\n            # FIXME: is <layer> really embedded?\n            # We should get rid of any <param> tags not inside <applet>;\n            # These are not really valid anyway.\n            for el in list(doc.iter('param')):\n                parent = el.getparent()\n                while parent is not None and parent.tag not in ('applet', 'object'):\n                    parent = parent.getparent()\n                if parent is None:\n                    el.drop_tree()\n            kill_tags.update(('applet',))\n            # The alternate contents that are in an iframe are a good fallback:\n            remove_tags.update(('iframe', 'embed', 'layer', 'object', 'param'))\n        if self.frames:\n            # FIXME: ideally we should look at the frame links, but\n            # generally frames don't mix properly with an HTML\n            # fragment anyway.\n            kill_tags.update(defs.frame_tags)\n        if self.forms:\n            remove_tags.add('form')\n            kill_tags.update(('button', 'input', 'select', 'textarea'))\n        if self.annoying_tags:\n            remove_tags.update(('blink', 'marquee'))\n\n        _remove = []\n        _kill = []\n        for el in doc.iter():\n            if el.tag in kill_tags:\n                if self.allow_element(el):\n                    continue\n                _kill.append(el)\n            elif el.tag in remove_tags:\n                if self.allow_element(el):\n                    continue\n                _remove.append(el)\n\n        if _remove and _remove[0] == doc:\n            # We have to drop the parent-most tag, which we can't\n            # do.  Instead we'll rewrite it:\n            el = _remove.pop(0)\n            el.tag = 'div'\n            el.attrib.clear()\n        elif _kill and _kill[0] == doc:\n            # We have to drop the parent-most element, which we can't\n            # do.  Instead we'll clear it:\n            el = _kill.pop(0)\n            if el.tag != 'html':\n                el.tag = 'div'\n            el.clear()\n\n        _kill.reverse() # start with innermost tags\n        for el in _kill:\n            el.drop_tree()\n        for el in _remove:\n            el.drop_tag()\n\n        if self.remove_unknown_tags:\n            if allow_tags:\n                raise ValueError(\n                    \"It does not make sense to pass in both allow_tags and remove_unknown_tags\")\n            allow_tags = set(defs.tags)\n        if allow_tags:\n            # make sure we do not remove comments/PIs if users want them (which is rare enough)\n            if not self.comments:\n                allow_tags.add(etree.Comment)\n            if not self.processing_instructions:\n                allow_tags.add(etree.ProcessingInstruction)\n\n            bad = []\n            for el in doc.iter():\n                if el.tag not in allow_tags:\n                    bad.append(el)\n            if bad:\n                if bad[0] is doc:\n                    el = bad.pop(0)\n                    el.tag = 'div'\n                    el.attrib.clear()\n                for el in bad:\n                    el.drop_tag()\n        if self.add_nofollow:\n            for el in _find_external_links(doc):\n                if not self.allow_follow(el):\n                    rel = el.get('rel')\n                    if rel:\n                        if ('nofollow' in rel\n                                and ' nofollow ' in (' %s ' % rel)):\n                            continue\n                        rel = '%s nofollow' % rel\n                    else:\n                        rel = 'nofollow'\n                    el.set('rel', rel)\n\n    def allow_follow(self, anchor):\n        \"\"\"\n        Override to suppress rel=\"nofollow\" on some anchors.\n        \"\"\"\n        return False\n\n    def allow_element(self, el):\n        \"\"\"\n        Decide whether an element is configured to be accepted or rejected.\n\n        :param el: an element.\n        :return: true to accept the element or false to reject/discard it.\n        \"\"\"\n        if el.tag not in self._tag_link_attrs:\n            return False\n        attr = self._tag_link_attrs[el.tag]\n        if isinstance(attr, (list, tuple)):\n            for one_attr in attr:\n                url = el.get(one_attr)\n                if not url:\n                    return False\n                if not self.allow_embedded_url(el, url):\n                    return False\n            return True\n        else:\n            url = el.get(attr)\n            if not url:\n                return False\n            return self.allow_embedded_url(el, url)\n\n    def allow_embedded_url(self, el, url):\n        \"\"\"\n        Decide whether a URL that was found in an element's attributes or text\n        if configured to be accepted or rejected.\n\n        :param el: an element.\n        :param url: a URL found on the element.\n        :return: true to accept the URL and false to reject it.\n        \"\"\"\n        if self.whitelist_tags is not None and el.tag not in self.whitelist_tags:\n            return False\n        scheme, netloc, path, query, fragment = urlsplit(url)\n        netloc = netloc.lower().split(':', 1)[0]\n        if scheme not in ('http', 'https'):\n            return False\n        if netloc in self.host_whitelist:\n            return True\n        return False\n\n    def kill_conditional_comments(self, doc):\n        \"\"\"\n        IE conditional comments basically embed HTML that the parser\n        doesn't normally see.  We can't allow anything like that, so\n        we'll kill any comments that could be conditional.\n        \"\"\"\n        has_conditional_comment = _conditional_comment_re.search\n        self._kill_elements(\n            doc, lambda el: has_conditional_comment(el.text),\n            etree.Comment)                \n\n    def _kill_elements(self, doc, condition, iterate=None):\n        bad = []\n        for el in doc.iter(iterate):\n            if condition(el):\n                bad.append(el)\n        for el in bad:\n            el.drop_tree()\n\n    def _remove_javascript_link(self, link):\n        # links like \"j a v a s c r i p t:\" might be interpreted in IE\n        new = _substitute_whitespace('', unquote_plus(link))\n        if _is_javascript_scheme(new):\n            # FIXME: should this be None to delete?\n            return ''\n        return link\n\n    _substitute_comments = re.compile(r'/\\*.*?\\*/', re.S).sub\n\n    def _has_sneaky_javascript(self, style):\n        \"\"\"\n        Depending on the browser, stuff like ``e x p r e s s i o n(...)``\n        can get interpreted, or ``expre/* stuff */ssion(...)``.  This\n        checks for attempt to do stuff like this.\n\n        Typically the response will be to kill the entire style; if you\n        have just a bit of Javascript in the style another rule will catch\n        that and remove only the Javascript from the style; this catches\n        more sneaky attempts.\n        \"\"\"\n        style = self._substitute_comments('', style)\n        style = style.replace('\\\\', '')\n        style = _substitute_whitespace('', style)\n        style = style.lower()\n        if 'javascript:' in style:\n            return True\n        if 'expression(' in style:\n            return True\n        if '@import' in style:\n            return True\n        if '</noscript' in style:\n            # e.g. '<noscript><style><a title=\"</noscript><img src=x onerror=alert(1)>\">'\n            return True\n        if _looks_like_tag_content(style):\n            # e.g. '<math><style><img src=x onerror=alert(1)></style></math>'\n            return True\n        return False\n\n    def clean_html(self, html):\n        result_type = type(html)\n        if isinstance(html, basestring):\n            doc = fromstring(html)\n        else:\n            doc = copy.deepcopy(html)\n        self(doc)\n        return _transform_result(result_type, doc)\n\nclean = Cleaner()\nclean_html = clean.clean_html\n\n############################################################\n## Autolinking\n############################################################\n\n_link_regexes = [\n    re.compile(r'(?P<body>https?://(?P<host>[a-z0-9._-]+)(?:/[/\\-_.,a-z0-9%&?;=~]*)?(?:\\([/\\-_.,a-z0-9%&?;=~]*\\))?)', re.I),\n    # This is conservative, but autolinking can be a bit conservative:\n    re.compile(r'mailto:(?P<body>[a-z0-9._-]+@(?P<host>[a-z0-9_.-]+[a-z]))', re.I),\n    ]\n\n_avoid_elements = ['textarea', 'pre', 'code', 'head', 'select', 'a']\n\n_avoid_hosts = [\n    re.compile(r'^localhost', re.I),\n    re.compile(r'\\bexample\\.(?:com|org|net)$', re.I),\n    re.compile(r'^127\\.0\\.0\\.1$'),\n    ]\n\n_avoid_classes = ['nolink']\n\ndef autolink(el, link_regexes=_link_regexes,\n             avoid_elements=_avoid_elements,\n             avoid_hosts=_avoid_hosts,\n             avoid_classes=_avoid_classes):\n    \"\"\"\n    Turn any URLs into links.\n\n    It will search for links identified by the given regular\n    expressions (by default mailto and http(s) links).\n\n    It won't link text in an element in avoid_elements, or an element\n    with a class in avoid_classes.  It won't link to anything with a\n    host that matches one of the regular expressions in avoid_hosts\n    (default localhost and 127.0.0.1).\n\n    If you pass in an element, the element's tail will not be\n    substituted, only the contents of the element.\n    \"\"\"\n    if el.tag in avoid_elements:\n        return\n    class_name = el.get('class')\n    if class_name:\n        class_name = class_name.split()\n        for match_class in avoid_classes:\n            if match_class in class_name:\n                return\n    for child in list(el):\n        autolink(child, link_regexes=link_regexes,\n                 avoid_elements=avoid_elements,\n                 avoid_hosts=avoid_hosts,\n                 avoid_classes=avoid_classes)\n        if child.tail:\n            text, tail_children = _link_text(\n                child.tail, link_regexes, avoid_hosts, factory=el.makeelement)\n            if tail_children:\n                child.tail = text\n                index = el.index(child)\n                el[index+1:index+1] = tail_children\n    if el.text:\n        text, pre_children = _link_text(\n            el.text, link_regexes, avoid_hosts, factory=el.makeelement)\n        if pre_children:\n            el.text = text\n            el[:0] = pre_children\n\ndef _link_text(text, link_regexes, avoid_hosts, factory):\n    leading_text = ''\n    links = []\n    last_pos = 0\n    while 1:\n        best_match, best_pos = None, None\n        for regex in link_regexes:\n            regex_pos = last_pos\n            while 1:\n                match = regex.search(text, pos=regex_pos)\n                if match is None:\n                    break\n                host = match.group('host')\n                for host_regex in avoid_hosts:\n                    if host_regex.search(host):\n                        regex_pos = match.end()\n                        break\n                else:\n                    break\n            if match is None:\n                continue\n            if best_pos is None or match.start() < best_pos:\n                best_match = match\n                best_pos = match.start()\n        if best_match is None:\n            # No more matches\n            if links:\n                assert not links[-1].tail\n                links[-1].tail = text\n            else:\n                assert not leading_text\n                leading_text = text\n            break\n        link = best_match.group(0)\n        end = best_match.end()\n        if link.endswith('.') or link.endswith(','):\n            # These punctuation marks shouldn't end a link\n            end -= 1\n            link = link[:-1]\n        prev_text = text[:best_match.start()]\n        if links:\n            assert not links[-1].tail\n            links[-1].tail = prev_text\n        else:\n            assert not leading_text\n            leading_text = prev_text\n        anchor = factory('a')\n        anchor.set('href', link)\n        body = best_match.group('body')\n        if not body:\n            body = link\n        if body.endswith('.') or body.endswith(','):\n            body = body[:-1]\n        anchor.text = body\n        links.append(anchor)\n        text = text[end:]\n    return leading_text, links\n                \ndef autolink_html(html, *args, **kw):\n    result_type = type(html)\n    if isinstance(html, basestring):\n        doc = fromstring(html)\n    else:\n        doc = copy.deepcopy(html)\n    autolink(doc, *args, **kw)\n    return _transform_result(result_type, doc)\n\nautolink_html.__doc__ = autolink.__doc__\n\n############################################################\n## Word wrapping\n############################################################\n\n_avoid_word_break_elements = ['pre', 'textarea', 'code']\n_avoid_word_break_classes = ['nobreak']\n\ndef word_break(el, max_width=40,\n               avoid_elements=_avoid_word_break_elements,\n               avoid_classes=_avoid_word_break_classes,\n               break_character=unichr(0x200b)):\n    \"\"\"\n    Breaks any long words found in the body of the text (not attributes).\n\n    Doesn't effect any of the tags in avoid_elements, by default\n    ``<textarea>`` and ``<pre>``\n\n    Breaks words by inserting &#8203;, which is a unicode character\n    for Zero Width Space character.  This generally takes up no space\n    in rendering, but does copy as a space, and in monospace contexts\n    usually takes up space.\n\n    See http://www.cs.tut.fi/~jkorpela/html/nobr.html for a discussion\n    \"\"\"\n    # Character suggestion of &#8203 comes from:\n    #   http://www.cs.tut.fi/~jkorpela/html/nobr.html\n    if el.tag in _avoid_word_break_elements:\n        return\n    class_name = el.get('class')\n    if class_name:\n        dont_break = False\n        class_name = class_name.split()\n        for avoid in avoid_classes:\n            if avoid in class_name:\n                dont_break = True\n                break\n        if dont_break:\n            return\n    if el.text:\n        el.text = _break_text(el.text, max_width, break_character)\n    for child in el:\n        word_break(child, max_width=max_width,\n                   avoid_elements=avoid_elements,\n                   avoid_classes=avoid_classes,\n                   break_character=break_character)\n        if child.tail:\n            child.tail = _break_text(child.tail, max_width, break_character)\n\ndef word_break_html(html, *args, **kw):\n    result_type = type(html)\n    doc = fromstring(html)\n    word_break(doc, *args, **kw)\n    return _transform_result(result_type, doc)\n\ndef _break_text(text, max_width, break_character):\n    words = text.split()\n    for word in words:\n        if len(word) > max_width:\n            replacement = _insert_break(word, max_width, break_character)\n            text = text.replace(word, replacement)\n    return text\n\n_break_prefer_re = re.compile(r'[^a-z]', re.I)\n\ndef _insert_break(word, width, break_character):\n    orig_word = word\n    result = ''\n    while len(word) > width:\n        start = word[:width]\n        breaks = list(_break_prefer_re.finditer(start))\n        if breaks:\n            last_break = breaks[-1]\n            # Only walk back up to 10 characters to find a nice break:\n            if last_break.end() > width-10:\n                # FIXME: should the break character be at the end of the\n                # chunk, or the beginning of the next chunk?\n                start = word[:last_break.end()]\n        result += start + break_character\n        word = word[len(start):]\n    result += word\n    return result\n    \n", "code_before": "# cython: language_level=3str\n\n\"\"\"A cleanup tool for HTML.\n\nRemoves unwanted tags and content.  See the `Cleaner` class for\ndetails.\n\"\"\"\n\nfrom __future__ import absolute_import\n\nimport copy\nimport re\nimport sys\ntry:\n    from urlparse import urlsplit\n    from urllib import unquote_plus\nexcept ImportError:\n    # Python 3\n    from urllib.parse import urlsplit, unquote_plus\nfrom lxml import etree\nfrom lxml.html import defs\nfrom lxml.html import fromstring, XHTML_NAMESPACE\nfrom lxml.html import xhtml_to_html, _transform_result\n\ntry:\n    unichr\nexcept NameError:\n    # Python 3\n    unichr = chr\ntry:\n    unicode\nexcept NameError:\n    # Python 3\n    unicode = str\ntry:\n    basestring\nexcept NameError:\n    basestring = (str, bytes)\n\n\n__all__ = ['clean_html', 'clean', 'Cleaner', 'autolink', 'autolink_html',\n           'word_break', 'word_break_html']\n\n# Look at http://code.sixapart.com/trac/livejournal/browser/trunk/cgi-bin/cleanhtml.pl\n#   Particularly the CSS cleaning; most of the tag cleaning is integrated now\n# I have multiple kinds of schemes searched; but should schemes be\n#   whitelisted instead?\n# max height?\n# remove images?  Also in CSS?  background attribute?\n# Some way to whitelist object, iframe, etc (e.g., if you want to\n#   allow *just* embedded YouTube movies)\n# Log what was deleted and why?\n# style=\"behavior: ...\" might be bad in IE?\n# Should we have something for just <meta http-equiv>?  That's the worst of the\n#   metas.\n# UTF-7 detections?  Example:\n#     <HEAD><META HTTP-EQUIV=\"CONTENT-TYPE\" CONTENT=\"text/html; charset=UTF-7\"> </HEAD>+ADw-SCRIPT+AD4-alert('XSS');+ADw-/SCRIPT+AD4-\n#   you don't always have to have the charset set, if the page has no charset\n#   and there's UTF7-like code in it.\n# Look at these tests: http://htmlpurifier.org/live/smoketests/xssAttacks.php\n\n\n# This is an IE-specific construct you can have in a stylesheet to\n# run some Javascript:\n_replace_css_javascript = re.compile(\n    r'expression\\s*\\(.*?\\)', re.S|re.I).sub\n\n# Do I have to worry about @\\nimport?\n_replace_css_import = re.compile(\n    r'@\\s*import', re.I).sub\n\n_looks_like_tag_content = re.compile(\n    r'</?[a-zA-Z]+|\\son[a-zA-Z]+\\s*=',\n    *((re.ASCII,) if sys.version_info[0] >= 3 else ())).search\n\n# All kinds of schemes besides just javascript: that can cause\n# execution:\n_is_image_dataurl = re.compile(\n    r'^data:image/.+;base64', re.I).search\n_is_possibly_malicious_scheme = re.compile(\n    r'(?:javascript|jscript|livescript|vbscript|data|about|mocha):',\n    re.I).search\ndef _is_javascript_scheme(s):\n    if _is_image_dataurl(s):\n        return None\n    return _is_possibly_malicious_scheme(s)\n\n_substitute_whitespace = re.compile(r'[\\s\\x00-\\x08\\x0B\\x0C\\x0E-\\x19]+').sub\n# FIXME: should data: be blocked?\n\n# FIXME: check against: http://msdn2.microsoft.com/en-us/library/ms537512.aspx\n_conditional_comment_re = re.compile(\n    r'\\[if[\\s\\n\\r]+.*?][\\s\\n\\r]*>', re.I|re.S)\n\n_find_styled_elements = etree.XPath(\n    \"descendant-or-self::*[@style]\")\n\n_find_external_links = etree.XPath(\n    (\"descendant-or-self::a  [normalize-space(@href) and substring(normalize-space(@href),1,1) != '#'] |\"\n     \"descendant-or-self::x:a[normalize-space(@href) and substring(normalize-space(@href),1,1) != '#']\"),\n    namespaces={'x':XHTML_NAMESPACE})\n\n\nclass Cleaner(object):\n    \"\"\"\n    Instances cleans the document of each of the possible offending\n    elements.  The cleaning is controlled by attributes; you can\n    override attributes in a subclass, or set them in the constructor.\n\n    ``scripts``:\n        Removes any ``<script>`` tags.\n\n    ``javascript``:\n        Removes any Javascript, like an ``onclick`` attribute. Also removes stylesheets\n        as they could contain Javascript.\n\n    ``comments``:\n        Removes any comments.\n\n    ``style``:\n        Removes any style tags.\n\n    ``inline_style``\n        Removes any style attributes.  Defaults to the value of the ``style`` option.\n\n    ``links``:\n        Removes any ``<link>`` tags\n\n    ``meta``:\n        Removes any ``<meta>`` tags\n\n    ``page_structure``:\n        Structural parts of a page: ``<head>``, ``<html>``, ``<title>``.\n\n    ``processing_instructions``:\n        Removes any processing instructions.\n\n    ``embedded``:\n        Removes any embedded objects (flash, iframes)\n\n    ``frames``:\n        Removes any frame-related tags\n\n    ``forms``:\n        Removes any form tags\n\n    ``annoying_tags``:\n        Tags that aren't *wrong*, but are annoying.  ``<blink>`` and ``<marquee>``\n\n    ``remove_tags``:\n        A list of tags to remove.  Only the tags will be removed,\n        their content will get pulled up into the parent tag.\n\n    ``kill_tags``:\n        A list of tags to kill.  Killing also removes the tag's content,\n        i.e. the whole subtree, not just the tag itself.\n\n    ``allow_tags``:\n        A list of tags to include (default include all).\n\n    ``remove_unknown_tags``:\n        Remove any tags that aren't standard parts of HTML.\n\n    ``safe_attrs_only``:\n        If true, only include 'safe' attributes (specifically the list\n        from the feedparser HTML sanitisation web site).\n\n    ``safe_attrs``:\n        A set of attribute names to override the default list of attributes\n        considered 'safe' (when safe_attrs_only=True).\n\n    ``add_nofollow``:\n        If true, then any <a> tags will have ``rel=\"nofollow\"`` added to them.\n\n    ``host_whitelist``:\n        A list or set of hosts that you can use for embedded content\n        (for content like ``<object>``, ``<link rel=\"stylesheet\">``, etc).\n        You can also implement/override the method\n        ``allow_embedded_url(el, url)`` or ``allow_element(el)`` to\n        implement more complex rules for what can be embedded.\n        Anything that passes this test will be shown, regardless of\n        the value of (for instance) ``embedded``.\n\n        Note that this parameter might not work as intended if you do not\n        make the links absolute before doing the cleaning.\n\n        Note that you may also need to set ``whitelist_tags``.\n\n    ``whitelist_tags``:\n        A set of tags that can be included with ``host_whitelist``.\n        The default is ``iframe`` and ``embed``; you may wish to\n        include other tags like ``script``, or you may want to\n        implement ``allow_embedded_url`` for more control.  Set to None to\n        include all tags.\n\n    This modifies the document *in place*.\n    \"\"\"\n\n    scripts = True\n    javascript = True\n    comments = True\n    style = False\n    inline_style = None\n    links = True\n    meta = True\n    page_structure = True\n    processing_instructions = True\n    embedded = True\n    frames = True\n    forms = True\n    annoying_tags = True\n    remove_tags = None\n    allow_tags = None\n    kill_tags = None\n    remove_unknown_tags = True\n    safe_attrs_only = True\n    safe_attrs = defs.safe_attrs\n    add_nofollow = False\n    host_whitelist = ()\n    whitelist_tags = {'iframe', 'embed'}\n\n    def __init__(self, **kw):\n        not_an_attribute = object()\n        for name, value in kw.items():\n            default = getattr(self, name, not_an_attribute)\n            if (default is not None and default is not True and default is not False\n                    and not isinstance(default, (frozenset, set, tuple, list))):\n                raise TypeError(\n                    \"Unknown parameter: %s=%r\" % (name, value))\n            setattr(self, name, value)\n        if self.inline_style is None and 'inline_style' not in kw:\n            self.inline_style = self.style\n\n        if kw.get(\"allow_tags\"):\n            if kw.get(\"remove_unknown_tags\"):\n                raise ValueError(\"It does not make sense to pass in both \"\n                                 \"allow_tags and remove_unknown_tags\")\n            self.remove_unknown_tags = False\n\n    # Used to lookup the primary URL for a given tag that is up for\n    # removal:\n    _tag_link_attrs = dict(\n        script='src',\n        link='href',\n        # From: http://java.sun.com/j2se/1.4.2/docs/guide/misc/applet.html\n        # From what I can tell, both attributes can contain a link:\n        applet=['code', 'object'],\n        iframe='src',\n        embed='src',\n        layer='src',\n        # FIXME: there doesn't really seem like a general way to figure out what\n        # links an <object> tag uses; links often go in <param> tags with values\n        # that we don't really know.  You'd have to have knowledge about specific\n        # kinds of plugins (probably keyed off classid), and match against those.\n        ##object=?,\n        # FIXME: not looking at the action currently, because it is more complex\n        # than than -- if you keep the form, you should keep the form controls.\n        ##form='action',\n        a='href',\n        )\n\n    def __call__(self, doc):\n        \"\"\"\n        Cleans the document.\n        \"\"\"\n        try:\n            getroot = doc.getroot\n        except AttributeError:\n            pass  # Element instance\n        else:\n            doc = getroot()  # ElementTree instance, instead of an element\n        # convert XHTML to HTML\n        xhtml_to_html(doc)\n        # Normalize a case that IE treats <image> like <img>, and that\n        # can confuse either this step or later steps.\n        for el in doc.iter('image'):\n            el.tag = 'img'\n        if not self.comments:\n            # Of course, if we were going to kill comments anyway, we don't\n            # need to worry about this\n            self.kill_conditional_comments(doc)\n\n        kill_tags = set(self.kill_tags or ())\n        remove_tags = set(self.remove_tags or ())\n        allow_tags = set(self.allow_tags or ())\n\n        if self.scripts:\n            kill_tags.add('script')\n        if self.safe_attrs_only:\n            safe_attrs = set(self.safe_attrs)\n            for el in doc.iter(etree.Element):\n                attrib = el.attrib\n                for aname in attrib.keys():\n                    if aname not in safe_attrs:\n                        del attrib[aname]\n        if self.javascript:\n            if not (self.safe_attrs_only and\n                    self.safe_attrs == defs.safe_attrs):\n                # safe_attrs handles events attributes itself\n                for el in doc.iter(etree.Element):\n                    attrib = el.attrib\n                    for aname in attrib.keys():\n                        if aname.startswith('on'):\n                            del attrib[aname]\n            doc.rewrite_links(self._remove_javascript_link,\n                              resolve_base_href=False)\n            # If we're deleting style then we don't have to remove JS links\n            # from styles, otherwise...\n            if not self.inline_style:\n                for el in _find_styled_elements(doc):\n                    old = el.get('style')\n                    new = _replace_css_javascript('', old)\n                    new = _replace_css_import('', new)\n                    if self._has_sneaky_javascript(new):\n                        # Something tricky is going on...\n                        del el.attrib['style']\n                    elif new != old:\n                        el.set('style', new)\n            if not self.style:\n                for el in list(doc.iter('style')):\n                    if el.get('type', '').lower().strip() == 'text/javascript':\n                        el.drop_tree()\n                        continue\n                    old = el.text or ''\n                    new = _replace_css_javascript('', old)\n                    # The imported CSS can do anything; we just can't allow:\n                    new = _replace_css_import('', new)\n                    if self._has_sneaky_javascript(new):\n                        # Something tricky is going on...\n                        el.text = '/* deleted */'\n                    elif new != old:\n                        el.text = new\n        if self.comments:\n            kill_tags.add(etree.Comment)\n        if self.processing_instructions:\n            kill_tags.add(etree.ProcessingInstruction)\n        if self.style:\n            kill_tags.add('style')\n        if self.inline_style:\n            etree.strip_attributes(doc, 'style')\n        if self.links:\n            kill_tags.add('link')\n        elif self.style or self.javascript:\n            # We must get rid of included stylesheets if Javascript is not\n            # allowed, as you can put Javascript in them\n            for el in list(doc.iter('link')):\n                if 'stylesheet' in el.get('rel', '').lower():\n                    # Note this kills alternate stylesheets as well\n                    if not self.allow_element(el):\n                        el.drop_tree()\n        if self.meta:\n            kill_tags.add('meta')\n        if self.page_structure:\n            remove_tags.update(('head', 'html', 'title'))\n        if self.embedded:\n            # FIXME: is <layer> really embedded?\n            # We should get rid of any <param> tags not inside <applet>;\n            # These are not really valid anyway.\n            for el in list(doc.iter('param')):\n                parent = el.getparent()\n                while parent is not None and parent.tag not in ('applet', 'object'):\n                    parent = parent.getparent()\n                if parent is None:\n                    el.drop_tree()\n            kill_tags.update(('applet',))\n            # The alternate contents that are in an iframe are a good fallback:\n            remove_tags.update(('iframe', 'embed', 'layer', 'object', 'param'))\n        if self.frames:\n            # FIXME: ideally we should look at the frame links, but\n            # generally frames don't mix properly with an HTML\n            # fragment anyway.\n            kill_tags.update(defs.frame_tags)\n        if self.forms:\n            remove_tags.add('form')\n            kill_tags.update(('button', 'input', 'select', 'textarea'))\n        if self.annoying_tags:\n            remove_tags.update(('blink', 'marquee'))\n\n        _remove = []\n        _kill = []\n        for el in doc.iter():\n            if el.tag in kill_tags:\n                if self.allow_element(el):\n                    continue\n                _kill.append(el)\n            elif el.tag in remove_tags:\n                if self.allow_element(el):\n                    continue\n                _remove.append(el)\n\n        if _remove and _remove[0] == doc:\n            # We have to drop the parent-most tag, which we can't\n            # do.  Instead we'll rewrite it:\n            el = _remove.pop(0)\n            el.tag = 'div'\n            el.attrib.clear()\n        elif _kill and _kill[0] == doc:\n            # We have to drop the parent-most element, which we can't\n            # do.  Instead we'll clear it:\n            el = _kill.pop(0)\n            if el.tag != 'html':\n                el.tag = 'div'\n            el.clear()\n\n        _kill.reverse() # start with innermost tags\n        for el in _kill:\n            el.drop_tree()\n        for el in _remove:\n            el.drop_tag()\n\n        if self.remove_unknown_tags:\n            if allow_tags:\n                raise ValueError(\n                    \"It does not make sense to pass in both allow_tags and remove_unknown_tags\")\n            allow_tags = set(defs.tags)\n        if allow_tags:\n            # make sure we do not remove comments/PIs if users want them (which is rare enough)\n            if not self.comments:\n                allow_tags.add(etree.Comment)\n            if not self.processing_instructions:\n                allow_tags.add(etree.ProcessingInstruction)\n\n            bad = []\n            for el in doc.iter():\n                if el.tag not in allow_tags:\n                    bad.append(el)\n            if bad:\n                if bad[0] is doc:\n                    el = bad.pop(0)\n                    el.tag = 'div'\n                    el.attrib.clear()\n                for el in bad:\n                    el.drop_tag()\n        if self.add_nofollow:\n            for el in _find_external_links(doc):\n                if not self.allow_follow(el):\n                    rel = el.get('rel')\n                    if rel:\n                        if ('nofollow' in rel\n                                and ' nofollow ' in (' %s ' % rel)):\n                            continue\n                        rel = '%s nofollow' % rel\n                    else:\n                        rel = 'nofollow'\n                    el.set('rel', rel)\n\n    def allow_follow(self, anchor):\n        \"\"\"\n        Override to suppress rel=\"nofollow\" on some anchors.\n        \"\"\"\n        return False\n\n    def allow_element(self, el):\n        \"\"\"\n        Decide whether an element is configured to be accepted or rejected.\n\n        :param el: an element.\n        :return: true to accept the element or false to reject/discard it.\n        \"\"\"\n        if el.tag not in self._tag_link_attrs:\n            return False\n        attr = self._tag_link_attrs[el.tag]\n        if isinstance(attr, (list, tuple)):\n            for one_attr in attr:\n                url = el.get(one_attr)\n                if not url:\n                    return False\n                if not self.allow_embedded_url(el, url):\n                    return False\n            return True\n        else:\n            url = el.get(attr)\n            if not url:\n                return False\n            return self.allow_embedded_url(el, url)\n\n    def allow_embedded_url(self, el, url):\n        \"\"\"\n        Decide whether a URL that was found in an element's attributes or text\n        if configured to be accepted or rejected.\n\n        :param el: an element.\n        :param url: a URL found on the element.\n        :return: true to accept the URL and false to reject it.\n        \"\"\"\n        if self.whitelist_tags is not None and el.tag not in self.whitelist_tags:\n            return False\n        scheme, netloc, path, query, fragment = urlsplit(url)\n        netloc = netloc.lower().split(':', 1)[0]\n        if scheme not in ('http', 'https'):\n            return False\n        if netloc in self.host_whitelist:\n            return True\n        return False\n\n    def kill_conditional_comments(self, doc):\n        \"\"\"\n        IE conditional comments basically embed HTML that the parser\n        doesn't normally see.  We can't allow anything like that, so\n        we'll kill any comments that could be conditional.\n        \"\"\"\n        has_conditional_comment = _conditional_comment_re.search\n        self._kill_elements(\n            doc, lambda el: has_conditional_comment(el.text),\n            etree.Comment)                \n\n    def _kill_elements(self, doc, condition, iterate=None):\n        bad = []\n        for el in doc.iter(iterate):\n            if condition(el):\n                bad.append(el)\n        for el in bad:\n            el.drop_tree()\n\n    def _remove_javascript_link(self, link):\n        # links like \"j a v a s c r i p t:\" might be interpreted in IE\n        new = _substitute_whitespace('', unquote_plus(link))\n        if _is_javascript_scheme(new):\n            # FIXME: should this be None to delete?\n            return ''\n        return link\n\n    _substitute_comments = re.compile(r'/\\*.*?\\*/', re.S).sub\n\n    def _has_sneaky_javascript(self, style):\n        \"\"\"\n        Depending on the browser, stuff like ``e x p r e s s i o n(...)``\n        can get interpreted, or ``expre/* stuff */ssion(...)``.  This\n        checks for attempt to do stuff like this.\n\n        Typically the response will be to kill the entire style; if you\n        have just a bit of Javascript in the style another rule will catch\n        that and remove only the Javascript from the style; this catches\n        more sneaky attempts.\n        \"\"\"\n        style = self._substitute_comments('', style)\n        style = style.replace('\\\\', '')\n        style = _substitute_whitespace('', style)\n        style = style.lower()\n        if 'javascript:' in style:\n            return True\n        if 'expression(' in style:\n            return True\n        if '</noscript' in style:\n            # e.g. '<noscript><style><a title=\"</noscript><img src=x onerror=alert(1)>\">'\n            return True\n        if _looks_like_tag_content(style):\n            # e.g. '<math><style><img src=x onerror=alert(1)></style></math>'\n            return True\n        return False\n\n    def clean_html(self, html):\n        result_type = type(html)\n        if isinstance(html, basestring):\n            doc = fromstring(html)\n        else:\n            doc = copy.deepcopy(html)\n        self(doc)\n        return _transform_result(result_type, doc)\n\nclean = Cleaner()\nclean_html = clean.clean_html\n\n############################################################\n## Autolinking\n############################################################\n\n_link_regexes = [\n    re.compile(r'(?P<body>https?://(?P<host>[a-z0-9._-]+)(?:/[/\\-_.,a-z0-9%&?;=~]*)?(?:\\([/\\-_.,a-z0-9%&?;=~]*\\))?)', re.I),\n    # This is conservative, but autolinking can be a bit conservative:\n    re.compile(r'mailto:(?P<body>[a-z0-9._-]+@(?P<host>[a-z0-9_.-]+[a-z]))', re.I),\n    ]\n\n_avoid_elements = ['textarea', 'pre', 'code', 'head', 'select', 'a']\n\n_avoid_hosts = [\n    re.compile(r'^localhost', re.I),\n    re.compile(r'\\bexample\\.(?:com|org|net)$', re.I),\n    re.compile(r'^127\\.0\\.0\\.1$'),\n    ]\n\n_avoid_classes = ['nolink']\n\ndef autolink(el, link_regexes=_link_regexes,\n             avoid_elements=_avoid_elements,\n             avoid_hosts=_avoid_hosts,\n             avoid_classes=_avoid_classes):\n    \"\"\"\n    Turn any URLs into links.\n\n    It will search for links identified by the given regular\n    expressions (by default mailto and http(s) links).\n\n    It won't link text in an element in avoid_elements, or an element\n    with a class in avoid_classes.  It won't link to anything with a\n    host that matches one of the regular expressions in avoid_hosts\n    (default localhost and 127.0.0.1).\n\n    If you pass in an element, the element's tail will not be\n    substituted, only the contents of the element.\n    \"\"\"\n    if el.tag in avoid_elements:\n        return\n    class_name = el.get('class')\n    if class_name:\n        class_name = class_name.split()\n        for match_class in avoid_classes:\n            if match_class in class_name:\n                return\n    for child in list(el):\n        autolink(child, link_regexes=link_regexes,\n                 avoid_elements=avoid_elements,\n                 avoid_hosts=avoid_hosts,\n                 avoid_classes=avoid_classes)\n        if child.tail:\n            text, tail_children = _link_text(\n                child.tail, link_regexes, avoid_hosts, factory=el.makeelement)\n            if tail_children:\n                child.tail = text\n                index = el.index(child)\n                el[index+1:index+1] = tail_children\n    if el.text:\n        text, pre_children = _link_text(\n            el.text, link_regexes, avoid_hosts, factory=el.makeelement)\n        if pre_children:\n            el.text = text\n            el[:0] = pre_children\n\ndef _link_text(text, link_regexes, avoid_hosts, factory):\n    leading_text = ''\n    links = []\n    last_pos = 0\n    while 1:\n        best_match, best_pos = None, None\n        for regex in link_regexes:\n            regex_pos = last_pos\n            while 1:\n                match = regex.search(text, pos=regex_pos)\n                if match is None:\n                    break\n                host = match.group('host')\n                for host_regex in avoid_hosts:\n                    if host_regex.search(host):\n                        regex_pos = match.end()\n                        break\n                else:\n                    break\n            if match is None:\n                continue\n            if best_pos is None or match.start() < best_pos:\n                best_match = match\n                best_pos = match.start()\n        if best_match is None:\n            # No more matches\n            if links:\n                assert not links[-1].tail\n                links[-1].tail = text\n            else:\n                assert not leading_text\n                leading_text = text\n            break\n        link = best_match.group(0)\n        end = best_match.end()\n        if link.endswith('.') or link.endswith(','):\n            # These punctuation marks shouldn't end a link\n            end -= 1\n            link = link[:-1]\n        prev_text = text[:best_match.start()]\n        if links:\n            assert not links[-1].tail\n            links[-1].tail = prev_text\n        else:\n            assert not leading_text\n            leading_text = prev_text\n        anchor = factory('a')\n        anchor.set('href', link)\n        body = best_match.group('body')\n        if not body:\n            body = link\n        if body.endswith('.') or body.endswith(','):\n            body = body[:-1]\n        anchor.text = body\n        links.append(anchor)\n        text = text[end:]\n    return leading_text, links\n                \ndef autolink_html(html, *args, **kw):\n    result_type = type(html)\n    if isinstance(html, basestring):\n        doc = fromstring(html)\n    else:\n        doc = copy.deepcopy(html)\n    autolink(doc, *args, **kw)\n    return _transform_result(result_type, doc)\n\nautolink_html.__doc__ = autolink.__doc__\n\n############################################################\n## Word wrapping\n############################################################\n\n_avoid_word_break_elements = ['pre', 'textarea', 'code']\n_avoid_word_break_classes = ['nobreak']\n\ndef word_break(el, max_width=40,\n               avoid_elements=_avoid_word_break_elements,\n               avoid_classes=_avoid_word_break_classes,\n               break_character=unichr(0x200b)):\n    \"\"\"\n    Breaks any long words found in the body of the text (not attributes).\n\n    Doesn't effect any of the tags in avoid_elements, by default\n    ``<textarea>`` and ``<pre>``\n\n    Breaks words by inserting &#8203;, which is a unicode character\n    for Zero Width Space character.  This generally takes up no space\n    in rendering, but does copy as a space, and in monospace contexts\n    usually takes up space.\n\n    See http://www.cs.tut.fi/~jkorpela/html/nobr.html for a discussion\n    \"\"\"\n    # Character suggestion of &#8203 comes from:\n    #   http://www.cs.tut.fi/~jkorpela/html/nobr.html\n    if el.tag in _avoid_word_break_elements:\n        return\n    class_name = el.get('class')\n    if class_name:\n        dont_break = False\n        class_name = class_name.split()\n        for avoid in avoid_classes:\n            if avoid in class_name:\n                dont_break = True\n                break\n        if dont_break:\n            return\n    if el.text:\n        el.text = _break_text(el.text, max_width, break_character)\n    for child in el:\n        word_break(child, max_width=max_width,\n                   avoid_elements=avoid_elements,\n                   avoid_classes=avoid_classes,\n                   break_character=break_character)\n        if child.tail:\n            child.tail = _break_text(child.tail, max_width, break_character)\n\ndef word_break_html(html, *args, **kw):\n    result_type = type(html)\n    doc = fromstring(html)\n    word_break(doc, *args, **kw)\n    return _transform_result(result_type, doc)\n\ndef _break_text(text, max_width, break_character):\n    words = text.split()\n    for word in words:\n        if len(word) > max_width:\n            replacement = _insert_break(word, max_width, break_character)\n            text = text.replace(word, replacement)\n    return text\n\n_break_prefer_re = re.compile(r'[^a-z]', re.I)\n\ndef _insert_break(word, width, break_character):\n    orig_word = word\n    result = ''\n    while len(word) > width:\n        start = word[:width]\n        breaks = list(_break_prefer_re.finditer(start))\n        if breaks:\n            last_break = breaks[-1]\n            # Only walk back up to 10 characters to find a nice break:\n            if last_break.end() > width-10:\n                # FIXME: should the break character be at the end of the\n                # chunk, or the beginning of the next chunk?\n                start = word[:last_break.end()]\n        result += start + break_character\n        word = word[len(start):]\n    result += word\n    return result\n    \n", "patch": "@@ -541,6 +541,8 @@ def _has_sneaky_javascript(self, style):\n             return True\n         if 'expression(' in style:\n             return True\n+        if '@import' in style:\n+            return True\n         if '</noscript' in style:\n             # e.g. '<noscript><style><a title=\"</noscript><img src=x onerror=alert(1)>\">'\n             return True", "file_path": "files/2021_12/404", "file_language": "py", "file_name": "src/lxml/html/clean.py", "outdated_file_modify": 1, "outdated_file_before": 0, "outdated_file_after": 1, "llm_check": 0, "static_check": 0, "static": {"rats": [false, []], "semgrep": [false, []]}, "target": 0, "function_before": [{"function": "def _is_javascript_scheme(s):\n    if _is_image_dataurl(s):\n        return None\n    return _is_possibly_malicious_scheme(s)", "target": 0}, {"function": "class Cleaner(object):\n    \"\"\"\n    Instances cleans the document of each of the possible offending\n    elements.  The cleaning is controlled by attributes; you can\n    override attributes in a subclass, or set them in the constructor.\n\n    ``scripts``:\n        Removes any ``<script>`` tags.\n\n    ``javascript``:\n        Removes any Javascript, like an ``onclick`` attribute. Also removes stylesheets\n        as they could contain Javascript.\n\n    ``comments``:\n        Removes any comments.\n\n    ``style``:\n        Removes any style tags.\n\n    ``inline_style``\n        Removes any style attributes.  Defaults to the value of the ``style`` option.\n\n    ``links``:\n        Removes any ``<link>`` tags\n\n    ``meta``:\n        Removes any ``<meta>`` tags\n\n    ``page_structure``:\n        Structural parts of a page: ``<head>``, ``<html>``, ``<title>``.\n\n    ``processing_instructions``:\n        Removes any processing instructions.\n\n    ``embedded``:\n        Removes any embedded objects (flash, iframes)\n\n    ``frames``:\n        Removes any frame-related tags\n\n    ``forms``:\n        Removes any form tags\n\n    ``annoying_tags``:\n        Tags that aren't *wrong*, but are annoying.  ``<blink>`` and ``<marquee>``\n\n    ``remove_tags``:\n        A list of tags to remove.  Only the tags will be removed,\n        their content will get pulled up into the parent tag.\n\n    ``kill_tags``:\n        A list of tags to kill.  Killing also removes the tag's content,\n        i.e. the whole subtree, not just the tag itself.\n\n    ``allow_tags``:\n        A list of tags to include (default include all).\n\n    ``remove_unknown_tags``:\n        Remove any tags that aren't standard parts of HTML.\n\n    ``safe_attrs_only``:\n        If true, only include 'safe' attributes (specifically the list\n        from the feedparser HTML sanitisation web site).\n\n    ``safe_attrs``:\n        A set of attribute names to override the default list of attributes\n        considered 'safe' (when safe_attrs_only=True).\n\n    ``add_nofollow``:\n        If true, then any <a> tags will have ``rel=\"nofollow\"`` added to them.\n\n    ``host_whitelist``:\n        A list or set of hosts that you can use for embedded content\n        (for content like ``<object>``, ``<link rel=\"stylesheet\">``, etc).\n        You can also implement/override the method\n        ``allow_embedded_url(el, url)`` or ``allow_element(el)`` to\n        implement more complex rules for what can be embedded.\n        Anything that passes this test will be shown, regardless of\n        the value of (for instance) ``embedded``.\n\n        Note that this parameter might not work as intended if you do not\n        make the links absolute before doing the cleaning.\n\n        Note that you may also need to set ``whitelist_tags``.\n\n    ``whitelist_tags``:\n        A set of tags that can be included with ``host_whitelist``.\n        The default is ``iframe`` and ``embed``; you may wish to\n        include other tags like ``script``, or you may want to\n        implement ``allow_embedded_url`` for more control.  Set to None to\n        include all tags.\n\n    This modifies the document *in place*.\n    \"\"\"\n\n    scripts = True\n    javascript = True\n    comments = True\n    style = False\n    inline_style = None\n    links = True\n    meta = True\n    page_structure = True\n    processing_instructions = True\n    embedded = True\n    frames = True\n    forms = True\n    annoying_tags = True\n    remove_tags = None\n    allow_tags = None\n    kill_tags = None\n    remove_unknown_tags = True\n    safe_attrs_only = True\n    safe_attrs = defs.safe_attrs\n    add_nofollow = False\n    host_whitelist = ()\n    whitelist_tags = {'iframe', 'embed'}\n\n    def __init__(self, **kw):\n        not_an_attribute = object()\n        for name, value in kw.items():\n            default = getattr(self, name, not_an_attribute)\n            if (default is not None and default is not True and default is not False\n                    and not isinstance(default, (frozenset, set, tuple, list))):\n                raise TypeError(\n                    \"Unknown parameter: %s=%r\" % (name, value))\n            setattr(self, name, value)\n        if self.inline_style is None and 'inline_style' not in kw:\n            self.inline_style = self.style\n\n        if kw.get(\"allow_tags\"):\n            if kw.get(\"remove_unknown_tags\"):\n                raise ValueError(\"It does not make sense to pass in both \"\n                                 \"allow_tags and remove_unknown_tags\")\n            self.remove_unknown_tags = False\n\n    # Used to lookup the primary URL for a given tag that is up for\n    # removal:\n    _tag_link_attrs = dict(\n        script='src',\n        link='href',\n        # From: http://java.sun.com/j2se/1.4.2/docs/guide/misc/applet.html\n        # From what I can tell, both attributes can contain a link:\n        applet=['code', 'object'],\n        iframe='src',\n        embed='src',\n        layer='src',\n        # FIXME: there doesn't really seem like a general way to figure out what\n        # links an <object> tag uses; links often go in <param> tags with values\n        # that we don't really know.  You'd have to have knowledge about specific\n        # kinds of plugins (probably keyed off classid), and match against those.\n        ##object=?,\n        # FIXME: not looking at the action currently, because it is more complex\n        # than than -- if you keep the form, you should keep the form controls.\n        ##form='action',\n        a='href',\n        )\n\n    def __call__(self, doc):\n        \"\"\"\n        Cleans the document.\n        \"\"\"\n        try:\n            getroot = doc.getroot\n        except AttributeError:\n            pass  # Element instance\n        else:\n            doc = getroot()  # ElementTree instance, instead of an element\n        # convert XHTML to HTML\n        xhtml_to_html(doc)\n        # Normalize a case that IE treats <image> like <img>, and that\n        # can confuse either this step or later steps.\n        for el in doc.iter('image'):\n            el.tag = 'img'\n        if not self.comments:\n            # Of course, if we were going to kill comments anyway, we don't\n            # need to worry about this\n            self.kill_conditional_comments(doc)\n\n        kill_tags = set(self.kill_tags or ())\n        remove_tags = set(self.remove_tags or ())\n        allow_tags = set(self.allow_tags or ())\n\n        if self.scripts:\n            kill_tags.add('script')\n        if self.safe_attrs_only:\n            safe_attrs = set(self.safe_attrs)\n            for el in doc.iter(etree.Element):\n                attrib = el.attrib\n                for aname in attrib.keys():\n                    if aname not in safe_attrs:\n                        del attrib[aname]\n        if self.javascript:\n            if not (self.safe_attrs_only and\n                    self.safe_attrs == defs.safe_attrs):\n                # safe_attrs handles events attributes itself\n                for el in doc.iter(etree.Element):\n                    attrib = el.attrib\n                    for aname in attrib.keys():\n                        if aname.startswith('on'):\n                            del attrib[aname]\n            doc.rewrite_links(self._remove_javascript_link,\n                              resolve_base_href=False)\n            # If we're deleting style then we don't have to remove JS links\n            # from styles, otherwise...\n            if not self.inline_style:\n                for el in _find_styled_elements(doc):\n                    old = el.get('style')\n                    new = _replace_css_javascript('', old)\n                    new = _replace_css_import('', new)\n                    if self._has_sneaky_javascript(new):\n                        # Something tricky is going on...\n                        del el.attrib['style']\n                    elif new != old:\n                        el.set('style', new)\n            if not self.style:\n                for el in list(doc.iter('style')):\n                    if el.get('type', '').lower().strip() == 'text/javascript':\n                        el.drop_tree()\n                        continue\n                    old = el.text or ''\n                    new = _replace_css_javascript('', old)\n                    # The imported CSS can do anything; we just can't allow:\n                    new = _replace_css_import('', new)\n                    if self._has_sneaky_javascript(new):\n                        # Something tricky is going on...\n                        el.text = '/* deleted */'\n                    elif new != old:\n                        el.text = new\n        if self.comments:\n            kill_tags.add(etree.Comment)\n        if self.processing_instructions:\n            kill_tags.add(etree.ProcessingInstruction)\n        if self.style:\n            kill_tags.add('style')\n        if self.inline_style:\n            etree.strip_attributes(doc, 'style')\n        if self.links:\n            kill_tags.add('link')\n        elif self.style or self.javascript:\n            # We must get rid of included stylesheets if Javascript is not\n            # allowed, as you can put Javascript in them\n            for el in list(doc.iter('link')):\n                if 'stylesheet' in el.get('rel', '').lower():\n                    # Note this kills alternate stylesheets as well\n                    if not self.allow_element(el):\n                        el.drop_tree()\n        if self.meta:\n            kill_tags.add('meta')\n        if self.page_structure:\n            remove_tags.update(('head', 'html', 'title'))\n        if self.embedded:\n            # FIXME: is <layer> really embedded?\n            # We should get rid of any <param> tags not inside <applet>;\n            # These are not really valid anyway.\n            for el in list(doc.iter('param')):\n                parent = el.getparent()\n                while parent is not None and parent.tag not in ('applet', 'object'):\n                    parent = parent.getparent()\n                if parent is None:\n                    el.drop_tree()\n            kill_tags.update(('applet',))\n            # The alternate contents that are in an iframe are a good fallback:\n            remove_tags.update(('iframe', 'embed', 'layer', 'object', 'param'))\n        if self.frames:\n            # FIXME: ideally we should look at the frame links, but\n            # generally frames don't mix properly with an HTML\n            # fragment anyway.\n            kill_tags.update(defs.frame_tags)\n        if self.forms:\n            remove_tags.add('form')\n            kill_tags.update(('button', 'input', 'select', 'textarea'))\n        if self.annoying_tags:\n            remove_tags.update(('blink', 'marquee'))\n\n        _remove = []\n        _kill = []\n        for el in doc.iter():\n            if el.tag in kill_tags:\n                if self.allow_element(el):\n                    continue\n                _kill.append(el)\n            elif el.tag in remove_tags:\n                if self.allow_element(el):\n                    continue\n                _remove.append(el)\n\n        if _remove and _remove[0] == doc:\n            # We have to drop the parent-most tag, which we can't\n            # do.  Instead we'll rewrite it:\n            el = _remove.pop(0)\n            el.tag = 'div'\n            el.attrib.clear()\n        elif _kill and _kill[0] == doc:\n            # We have to drop the parent-most element, which we can't\n            # do.  Instead we'll clear it:\n            el = _kill.pop(0)\n            if el.tag != 'html':\n                el.tag = 'div'\n            el.clear()\n\n        _kill.reverse() # start with innermost tags\n        for el in _kill:\n            el.drop_tree()\n        for el in _remove:\n            el.drop_tag()\n\n        if self.remove_unknown_tags:\n            if allow_tags:\n                raise ValueError(\n                    \"It does not make sense to pass in both allow_tags and remove_unknown_tags\")\n            allow_tags = set(defs.tags)\n        if allow_tags:\n            # make sure we do not remove comments/PIs if users want them (which is rare enough)\n            if not self.comments:\n                allow_tags.add(etree.Comment)\n            if not self.processing_instructions:\n                allow_tags.add(etree.ProcessingInstruction)\n\n            bad = []\n            for el in doc.iter():\n                if el.tag not in allow_tags:\n                    bad.append(el)\n            if bad:\n                if bad[0] is doc:\n                    el = bad.pop(0)\n                    el.tag = 'div'\n                    el.attrib.clear()\n                for el in bad:\n                    el.drop_tag()\n        if self.add_nofollow:\n            for el in _find_external_links(doc):\n                if not self.allow_follow(el):\n                    rel = el.get('rel')\n                    if rel:\n                        if ('nofollow' in rel\n                                and ' nofollow ' in (' %s ' % rel)):\n                            continue\n                        rel = '%s nofollow' % rel\n                    else:\n                        rel = 'nofollow'\n                    el.set('rel', rel)\n\n    def allow_follow(self, anchor):\n        \"\"\"\n        Override to suppress rel=\"nofollow\" on some anchors.\n        \"\"\"\n        return False\n\n    def allow_element(self, el):\n        \"\"\"\n        Decide whether an element is configured to be accepted or rejected.\n\n        :param el: an element.\n        :return: true to accept the element or false to reject/discard it.\n        \"\"\"\n        if el.tag not in self._tag_link_attrs:\n            return False\n        attr = self._tag_link_attrs[el.tag]\n        if isinstance(attr, (list, tuple)):\n            for one_attr in attr:\n                url = el.get(one_attr)\n                if not url:\n                    return False\n                if not self.allow_embedded_url(el, url):\n                    return False\n            return True\n        else:\n            url = el.get(attr)\n            if not url:\n                return False\n            return self.allow_embedded_url(el, url)\n\n    def allow_embedded_url(self, el, url):\n        \"\"\"\n        Decide whether a URL that was found in an element's attributes or text\n        if configured to be accepted or rejected.\n\n        :param el: an element.\n        :param url: a URL found on the element.\n        :return: true to accept the URL and false to reject it.\n        \"\"\"\n        if self.whitelist_tags is not None and el.tag not in self.whitelist_tags:\n            return False\n        scheme, netloc, path, query, fragment = urlsplit(url)\n        netloc = netloc.lower().split(':', 1)[0]\n        if scheme not in ('http', 'https'):\n            return False\n        if netloc in self.host_whitelist:\n            return True\n        return False\n\n    def kill_conditional_comments(self, doc):\n        \"\"\"\n        IE conditional comments basically embed HTML that the parser\n        doesn't normally see.  We can't allow anything like that, so\n        we'll kill any comments that could be conditional.\n        \"\"\"\n        has_conditional_comment = _conditional_comment_re.search\n        self._kill_elements(\n            doc, lambda el: has_conditional_comment(el.text),\n            etree.Comment)                \n\n    def _kill_elements(self, doc, condition, iterate=None):\n        bad = []\n        for el in doc.iter(iterate):\n            if condition(el):\n                bad.append(el)\n        for el in bad:\n            el.drop_tree()\n\n    def _remove_javascript_link(self, link):\n        # links like \"j a v a s c r i p t:\" might be interpreted in IE\n        new = _substitute_whitespace('', unquote_plus(link))\n        if _is_javascript_scheme(new):\n            # FIXME: should this be None to delete?\n            return ''\n        return link\n\n    _substitute_comments = re.compile(r'/\\*.*?\\*/', re.S).sub\n\n    def _has_sneaky_javascript(self, style):\n        \"\"\"\n        Depending on the browser, stuff like ``e x p r e s s i o n(...)``\n        can get interpreted, or ``expre/* stuff */ssion(...)``.  This\n        checks for attempt to do stuff like this.\n\n        Typically the response will be to kill the entire style; if you\n        have just a bit of Javascript in the style another rule will catch\n        that and remove only the Javascript from the style; this catches\n        more sneaky attempts.\n        \"\"\"\n        style = self._substitute_comments('', style)\n        style = style.replace('\\\\', '')\n        style = _substitute_whitespace('', style)\n        style = style.lower()\n        if 'javascript:' in style:\n            return True\n        if 'expression(' in style:\n            return True\n        if '</noscript' in style:\n            # e.g. '<noscript><style><a title=\"</noscript><img src=x onerror=alert(1)>\">'\n            return True\n        if _looks_like_tag_content(style):\n            # e.g. '<math><style><img src=x onerror=alert(1)></style></math>'\n            return True\n        return False\n\n    def clean_html(self, html):\n        result_type = type(html)\n        if isinstance(html, basestring):\n            doc = fromstring(html)\n        else:\n            doc = copy.deepcopy(html)\n        self(doc)\n        return _transform_result(result_type, doc)", "target": 0}, {"function": "def autolink(el, link_regexes=_link_regexes,\n             avoid_elements=_avoid_elements,\n             avoid_hosts=_avoid_hosts,\n             avoid_classes=_avoid_classes):\n    \"\"\"\n    Turn any URLs into links.\n\n    It will search for links identified by the given regular\n    expressions (by default mailto and http(s) links).\n\n    It won't link text in an element in avoid_elements, or an element\n    with a class in avoid_classes.  It won't link to anything with a\n    host that matches one of the regular expressions in avoid_hosts\n    (default localhost and 127.0.0.1).\n\n    If you pass in an element, the element's tail will not be\n    substituted, only the contents of the element.\n    \"\"\"\n    if el.tag in avoid_elements:\n        return\n    class_name = el.get('class')\n    if class_name:\n        class_name = class_name.split()\n        for match_class in avoid_classes:\n            if match_class in class_name:\n                return\n    for child in list(el):\n        autolink(child, link_regexes=link_regexes,\n                 avoid_elements=avoid_elements,\n                 avoid_hosts=avoid_hosts,\n                 avoid_classes=avoid_classes)\n        if child.tail:\n            text, tail_children = _link_text(\n                child.tail, link_regexes, avoid_hosts, factory=el.makeelement)\n            if tail_children:\n                child.tail = text\n                index = el.index(child)\n                el[index+1:index+1] = tail_children\n    if el.text:\n        text, pre_children = _link_text(\n            el.text, link_regexes, avoid_hosts, factory=el.makeelement)\n        if pre_children:\n            el.text = text\n            el[:0] = pre_children", "target": 0}, {"function": "def _link_text(text, link_regexes, avoid_hosts, factory):\n    leading_text = ''\n    links = []\n    last_pos = 0\n    while 1:\n        best_match, best_pos = None, None\n        for regex in link_regexes:\n            regex_pos = last_pos\n            while 1:\n                match = regex.search(text, pos=regex_pos)\n                if match is None:\n                    break\n                host = match.group('host')\n                for host_regex in avoid_hosts:\n                    if host_regex.search(host):\n                        regex_pos = match.end()\n                        break\n                else:\n                    break\n            if match is None:\n                continue\n            if best_pos is None or match.start() < best_pos:\n                best_match = match\n                best_pos = match.start()\n        if best_match is None:\n            # No more matches\n            if links:\n                assert not links[-1].tail\n                links[-1].tail = text\n            else:\n                assert not leading_text\n                leading_text = text\n            break\n        link = best_match.group(0)\n        end = best_match.end()\n        if link.endswith('.') or link.endswith(','):\n            # These punctuation marks shouldn't end a link\n            end -= 1\n            link = link[:-1]\n        prev_text = text[:best_match.start()]\n        if links:\n            assert not links[-1].tail\n            links[-1].tail = prev_text\n        else:\n            assert not leading_text\n            leading_text = prev_text\n        anchor = factory('a')\n        anchor.set('href', link)\n        body = best_match.group('body')\n        if not body:\n            body = link\n        if body.endswith('.') or body.endswith(','):\n            body = body[:-1]\n        anchor.text = body\n        links.append(anchor)\n        text = text[end:]\n    return leading_text, links", "target": 0}, {"function": "def autolink_html(html, *args, **kw):\n    result_type = type(html)\n    if isinstance(html, basestring):\n        doc = fromstring(html)\n    else:\n        doc = copy.deepcopy(html)\n    autolink(doc, *args, **kw)\n    return _transform_result(result_type, doc)", "target": 0}, {"function": "def word_break(el, max_width=40,\n               avoid_elements=_avoid_word_break_elements,\n               avoid_classes=_avoid_word_break_classes,\n               break_character=unichr(0x200b)):\n    \"\"\"\n    Breaks any long words found in the body of the text (not attributes).\n\n    Doesn't effect any of the tags in avoid_elements, by default\n    ``<textarea>`` and ``<pre>``\n\n    Breaks words by inserting &#8203;, which is a unicode character\n    for Zero Width Space character.  This generally takes up no space\n    in rendering, but does copy as a space, and in monospace contexts\n    usually takes up space.\n\n    See http://www.cs.tut.fi/~jkorpela/html/nobr.html for a discussion\n    \"\"\"\n    # Character suggestion of &#8203 comes from:\n    #   http://www.cs.tut.fi/~jkorpela/html/nobr.html\n    if el.tag in _avoid_word_break_elements:\n        return\n    class_name = el.get('class')\n    if class_name:\n        dont_break = False\n        class_name = class_name.split()\n        for avoid in avoid_classes:\n            if avoid in class_name:\n                dont_break = True\n                break\n        if dont_break:\n            return\n    if el.text:\n        el.text = _break_text(el.text, max_width, break_character)\n    for child in el:\n        word_break(child, max_width=max_width,\n                   avoid_elements=avoid_elements,\n                   avoid_classes=avoid_classes,\n                   break_character=break_character)\n        if child.tail:\n            child.tail = _break_text(child.tail, max_width, break_character)", "target": 0}, {"function": "def word_break_html(html, *args, **kw):\n    result_type = type(html)\n    doc = fromstring(html)\n    word_break(doc, *args, **kw)\n    return _transform_result(result_type, doc)", "target": 0}, {"function": "def _break_text(text, max_width, break_character):\n    words = text.split()\n    for word in words:\n        if len(word) > max_width:\n            replacement = _insert_break(word, max_width, break_character)\n            text = text.replace(word, replacement)\n    return text", "target": 0}, {"function": "def _insert_break(word, width, break_character):\n    orig_word = word\n    result = ''\n    while len(word) > width:\n        start = word[:width]\n        breaks = list(_break_prefer_re.finditer(start))\n        if breaks:\n            last_break = breaks[-1]\n            # Only walk back up to 10 characters to find a nice break:\n            if last_break.end() > width-10:\n                # FIXME: should the break character be at the end of the\n                # chunk, or the beginning of the next chunk?\n                start = word[:last_break.end()]\n        result += start + break_character\n        word = word[len(start):]\n    result += word\n    return result", "target": 0}], "function_after": [{"function": "def _is_javascript_scheme(s):\n    if _is_image_dataurl(s):\n        return None\n    return _is_possibly_malicious_scheme(s)", "target": 0}, {"function": "class Cleaner(object):\n    \"\"\"\n    Instances cleans the document of each of the possible offending\n    elements.  The cleaning is controlled by attributes; you can\n    override attributes in a subclass, or set them in the constructor.\n\n    ``scripts``:\n        Removes any ``<script>`` tags.\n\n    ``javascript``:\n        Removes any Javascript, like an ``onclick`` attribute. Also removes stylesheets\n        as they could contain Javascript.\n\n    ``comments``:\n        Removes any comments.\n\n    ``style``:\n        Removes any style tags.\n\n    ``inline_style``\n        Removes any style attributes.  Defaults to the value of the ``style`` option.\n\n    ``links``:\n        Removes any ``<link>`` tags\n\n    ``meta``:\n        Removes any ``<meta>`` tags\n\n    ``page_structure``:\n        Structural parts of a page: ``<head>``, ``<html>``, ``<title>``.\n\n    ``processing_instructions``:\n        Removes any processing instructions.\n\n    ``embedded``:\n        Removes any embedded objects (flash, iframes)\n\n    ``frames``:\n        Removes any frame-related tags\n\n    ``forms``:\n        Removes any form tags\n\n    ``annoying_tags``:\n        Tags that aren't *wrong*, but are annoying.  ``<blink>`` and ``<marquee>``\n\n    ``remove_tags``:\n        A list of tags to remove.  Only the tags will be removed,\n        their content will get pulled up into the parent tag.\n\n    ``kill_tags``:\n        A list of tags to kill.  Killing also removes the tag's content,\n        i.e. the whole subtree, not just the tag itself.\n\n    ``allow_tags``:\n        A list of tags to include (default include all).\n\n    ``remove_unknown_tags``:\n        Remove any tags that aren't standard parts of HTML.\n\n    ``safe_attrs_only``:\n        If true, only include 'safe' attributes (specifically the list\n        from the feedparser HTML sanitisation web site).\n\n    ``safe_attrs``:\n        A set of attribute names to override the default list of attributes\n        considered 'safe' (when safe_attrs_only=True).\n\n    ``add_nofollow``:\n        If true, then any <a> tags will have ``rel=\"nofollow\"`` added to them.\n\n    ``host_whitelist``:\n        A list or set of hosts that you can use for embedded content\n        (for content like ``<object>``, ``<link rel=\"stylesheet\">``, etc).\n        You can also implement/override the method\n        ``allow_embedded_url(el, url)`` or ``allow_element(el)`` to\n        implement more complex rules for what can be embedded.\n        Anything that passes this test will be shown, regardless of\n        the value of (for instance) ``embedded``.\n\n        Note that this parameter might not work as intended if you do not\n        make the links absolute before doing the cleaning.\n\n        Note that you may also need to set ``whitelist_tags``.\n\n    ``whitelist_tags``:\n        A set of tags that can be included with ``host_whitelist``.\n        The default is ``iframe`` and ``embed``; you may wish to\n        include other tags like ``script``, or you may want to\n        implement ``allow_embedded_url`` for more control.  Set to None to\n        include all tags.\n\n    This modifies the document *in place*.\n    \"\"\"\n\n    scripts = True\n    javascript = True\n    comments = True\n    style = False\n    inline_style = None\n    links = True\n    meta = True\n    page_structure = True\n    processing_instructions = True\n    embedded = True\n    frames = True\n    forms = True\n    annoying_tags = True\n    remove_tags = None\n    allow_tags = None\n    kill_tags = None\n    remove_unknown_tags = True\n    safe_attrs_only = True\n    safe_attrs = defs.safe_attrs\n    add_nofollow = False\n    host_whitelist = ()\n    whitelist_tags = {'iframe', 'embed'}\n\n    def __init__(self, **kw):\n        not_an_attribute = object()\n        for name, value in kw.items():\n            default = getattr(self, name, not_an_attribute)\n            if (default is not None and default is not True and default is not False\n                    and not isinstance(default, (frozenset, set, tuple, list))):\n                raise TypeError(\n                    \"Unknown parameter: %s=%r\" % (name, value))\n            setattr(self, name, value)\n        if self.inline_style is None and 'inline_style' not in kw:\n            self.inline_style = self.style\n\n        if kw.get(\"allow_tags\"):\n            if kw.get(\"remove_unknown_tags\"):\n                raise ValueError(\"It does not make sense to pass in both \"\n                                 \"allow_tags and remove_unknown_tags\")\n            self.remove_unknown_tags = False\n\n    # Used to lookup the primary URL for a given tag that is up for\n    # removal:\n    _tag_link_attrs = dict(\n        script='src',\n        link='href',\n        # From: http://java.sun.com/j2se/1.4.2/docs/guide/misc/applet.html\n        # From what I can tell, both attributes can contain a link:\n        applet=['code', 'object'],\n        iframe='src',\n        embed='src',\n        layer='src',\n        # FIXME: there doesn't really seem like a general way to figure out what\n        # links an <object> tag uses; links often go in <param> tags with values\n        # that we don't really know.  You'd have to have knowledge about specific\n        # kinds of plugins (probably keyed off classid), and match against those.\n        ##object=?,\n        # FIXME: not looking at the action currently, because it is more complex\n        # than than -- if you keep the form, you should keep the form controls.\n        ##form='action',\n        a='href',\n        )\n\n    def __call__(self, doc):\n        \"\"\"\n        Cleans the document.\n        \"\"\"\n        try:\n            getroot = doc.getroot\n        except AttributeError:\n            pass  # Element instance\n        else:\n            doc = getroot()  # ElementTree instance, instead of an element\n        # convert XHTML to HTML\n        xhtml_to_html(doc)\n        # Normalize a case that IE treats <image> like <img>, and that\n        # can confuse either this step or later steps.\n        for el in doc.iter('image'):\n            el.tag = 'img'\n        if not self.comments:\n            # Of course, if we were going to kill comments anyway, we don't\n            # need to worry about this\n            self.kill_conditional_comments(doc)\n\n        kill_tags = set(self.kill_tags or ())\n        remove_tags = set(self.remove_tags or ())\n        allow_tags = set(self.allow_tags or ())\n\n        if self.scripts:\n            kill_tags.add('script')\n        if self.safe_attrs_only:\n            safe_attrs = set(self.safe_attrs)\n            for el in doc.iter(etree.Element):\n                attrib = el.attrib\n                for aname in attrib.keys():\n                    if aname not in safe_attrs:\n                        del attrib[aname]\n        if self.javascript:\n            if not (self.safe_attrs_only and\n                    self.safe_attrs == defs.safe_attrs):\n                # safe_attrs handles events attributes itself\n                for el in doc.iter(etree.Element):\n                    attrib = el.attrib\n                    for aname in attrib.keys():\n                        if aname.startswith('on'):\n                            del attrib[aname]\n            doc.rewrite_links(self._remove_javascript_link,\n                              resolve_base_href=False)\n            # If we're deleting style then we don't have to remove JS links\n            # from styles, otherwise...\n            if not self.inline_style:\n                for el in _find_styled_elements(doc):\n                    old = el.get('style')\n                    new = _replace_css_javascript('', old)\n                    new = _replace_css_import('', new)\n                    if self._has_sneaky_javascript(new):\n                        # Something tricky is going on...\n                        del el.attrib['style']\n                    elif new != old:\n                        el.set('style', new)\n            if not self.style:\n                for el in list(doc.iter('style')):\n                    if el.get('type', '').lower().strip() == 'text/javascript':\n                        el.drop_tree()\n                        continue\n                    old = el.text or ''\n                    new = _replace_css_javascript('', old)\n                    # The imported CSS can do anything; we just can't allow:\n                    new = _replace_css_import('', new)\n                    if self._has_sneaky_javascript(new):\n                        # Something tricky is going on...\n                        el.text = '/* deleted */'\n                    elif new != old:\n                        el.text = new\n        if self.comments:\n            kill_tags.add(etree.Comment)\n        if self.processing_instructions:\n            kill_tags.add(etree.ProcessingInstruction)\n        if self.style:\n            kill_tags.add('style')\n        if self.inline_style:\n            etree.strip_attributes(doc, 'style')\n        if self.links:\n            kill_tags.add('link')\n        elif self.style or self.javascript:\n            # We must get rid of included stylesheets if Javascript is not\n            # allowed, as you can put Javascript in them\n            for el in list(doc.iter('link')):\n                if 'stylesheet' in el.get('rel', '').lower():\n                    # Note this kills alternate stylesheets as well\n                    if not self.allow_element(el):\n                        el.drop_tree()\n        if self.meta:\n            kill_tags.add('meta')\n        if self.page_structure:\n            remove_tags.update(('head', 'html', 'title'))\n        if self.embedded:\n            # FIXME: is <layer> really embedded?\n            # We should get rid of any <param> tags not inside <applet>;\n            # These are not really valid anyway.\n            for el in list(doc.iter('param')):\n                parent = el.getparent()\n                while parent is not None and parent.tag not in ('applet', 'object'):\n                    parent = parent.getparent()\n                if parent is None:\n                    el.drop_tree()\n            kill_tags.update(('applet',))\n            # The alternate contents that are in an iframe are a good fallback:\n            remove_tags.update(('iframe', 'embed', 'layer', 'object', 'param'))\n        if self.frames:\n            # FIXME: ideally we should look at the frame links, but\n            # generally frames don't mix properly with an HTML\n            # fragment anyway.\n            kill_tags.update(defs.frame_tags)\n        if self.forms:\n            remove_tags.add('form')\n            kill_tags.update(('button', 'input', 'select', 'textarea'))\n        if self.annoying_tags:\n            remove_tags.update(('blink', 'marquee'))\n\n        _remove = []\n        _kill = []\n        for el in doc.iter():\n            if el.tag in kill_tags:\n                if self.allow_element(el):\n                    continue\n                _kill.append(el)\n            elif el.tag in remove_tags:\n                if self.allow_element(el):\n                    continue\n                _remove.append(el)\n\n        if _remove and _remove[0] == doc:\n            # We have to drop the parent-most tag, which we can't\n            # do.  Instead we'll rewrite it:\n            el = _remove.pop(0)\n            el.tag = 'div'\n            el.attrib.clear()\n        elif _kill and _kill[0] == doc:\n            # We have to drop the parent-most element, which we can't\n            # do.  Instead we'll clear it:\n            el = _kill.pop(0)\n            if el.tag != 'html':\n                el.tag = 'div'\n            el.clear()\n\n        _kill.reverse() # start with innermost tags\n        for el in _kill:\n            el.drop_tree()\n        for el in _remove:\n            el.drop_tag()\n\n        if self.remove_unknown_tags:\n            if allow_tags:\n                raise ValueError(\n                    \"It does not make sense to pass in both allow_tags and remove_unknown_tags\")\n            allow_tags = set(defs.tags)\n        if allow_tags:\n            # make sure we do not remove comments/PIs if users want them (which is rare enough)\n            if not self.comments:\n                allow_tags.add(etree.Comment)\n            if not self.processing_instructions:\n                allow_tags.add(etree.ProcessingInstruction)\n\n            bad = []\n            for el in doc.iter():\n                if el.tag not in allow_tags:\n                    bad.append(el)\n            if bad:\n                if bad[0] is doc:\n                    el = bad.pop(0)\n                    el.tag = 'div'\n                    el.attrib.clear()\n                for el in bad:\n                    el.drop_tag()\n        if self.add_nofollow:\n            for el in _find_external_links(doc):\n                if not self.allow_follow(el):\n                    rel = el.get('rel')\n                    if rel:\n                        if ('nofollow' in rel\n                                and ' nofollow ' in (' %s ' % rel)):\n                            continue\n                        rel = '%s nofollow' % rel\n                    else:\n                        rel = 'nofollow'\n                    el.set('rel', rel)\n\n    def allow_follow(self, anchor):\n        \"\"\"\n        Override to suppress rel=\"nofollow\" on some anchors.\n        \"\"\"\n        return False\n\n    def allow_element(self, el):\n        \"\"\"\n        Decide whether an element is configured to be accepted or rejected.\n\n        :param el: an element.\n        :return: true to accept the element or false to reject/discard it.\n        \"\"\"\n        if el.tag not in self._tag_link_attrs:\n            return False\n        attr = self._tag_link_attrs[el.tag]\n        if isinstance(attr, (list, tuple)):\n            for one_attr in attr:\n                url = el.get(one_attr)\n                if not url:\n                    return False\n                if not self.allow_embedded_url(el, url):\n                    return False\n            return True\n        else:\n            url = el.get(attr)\n            if not url:\n                return False\n            return self.allow_embedded_url(el, url)\n\n    def allow_embedded_url(self, el, url):\n        \"\"\"\n        Decide whether a URL that was found in an element's attributes or text\n        if configured to be accepted or rejected.\n\n        :param el: an element.\n        :param url: a URL found on the element.\n        :return: true to accept the URL and false to reject it.\n        \"\"\"\n        if self.whitelist_tags is not None and el.tag not in self.whitelist_tags:\n            return False\n        scheme, netloc, path, query, fragment = urlsplit(url)\n        netloc = netloc.lower().split(':', 1)[0]\n        if scheme not in ('http', 'https'):\n            return False\n        if netloc in self.host_whitelist:\n            return True\n        return False\n\n    def kill_conditional_comments(self, doc):\n        \"\"\"\n        IE conditional comments basically embed HTML that the parser\n        doesn't normally see.  We can't allow anything like that, so\n        we'll kill any comments that could be conditional.\n        \"\"\"\n        has_conditional_comment = _conditional_comment_re.search\n        self._kill_elements(\n            doc, lambda el: has_conditional_comment(el.text),\n            etree.Comment)                \n\n    def _kill_elements(self, doc, condition, iterate=None):\n        bad = []\n        for el in doc.iter(iterate):\n            if condition(el):\n                bad.append(el)\n        for el in bad:\n            el.drop_tree()\n\n    def _remove_javascript_link(self, link):\n        # links like \"j a v a s c r i p t:\" might be interpreted in IE\n        new = _substitute_whitespace('', unquote_plus(link))\n        if _is_javascript_scheme(new):\n            # FIXME: should this be None to delete?\n            return ''\n        return link\n\n    _substitute_comments = re.compile(r'/\\*.*?\\*/', re.S).sub\n\n    def _has_sneaky_javascript(self, style):\n        \"\"\"\n        Depending on the browser, stuff like ``e x p r e s s i o n(...)``\n        can get interpreted, or ``expre/* stuff */ssion(...)``.  This\n        checks for attempt to do stuff like this.\n\n        Typically the response will be to kill the entire style; if you\n        have just a bit of Javascript in the style another rule will catch\n        that and remove only the Javascript from the style; this catches\n        more sneaky attempts.\n        \"\"\"\n        style = self._substitute_comments('', style)\n        style = style.replace('\\\\', '')\n        style = _substitute_whitespace('', style)\n        style = style.lower()\n        if 'javascript:' in style:\n            return True\n        if 'expression(' in style:\n            return True\n        if '@import' in style:\n            return True\n        if '</noscript' in style:\n            # e.g. '<noscript><style><a title=\"</noscript><img src=x onerror=alert(1)>\">'\n            return True\n        if _looks_like_tag_content(style):\n            # e.g. '<math><style><img src=x onerror=alert(1)></style></math>'\n            return True\n        return False\n\n    def clean_html(self, html):\n        result_type = type(html)\n        if isinstance(html, basestring):\n            doc = fromstring(html)\n        else:\n            doc = copy.deepcopy(html)\n        self(doc)\n        return _transform_result(result_type, doc)", "target": 0}, {"function": "def autolink(el, link_regexes=_link_regexes,\n             avoid_elements=_avoid_elements,\n             avoid_hosts=_avoid_hosts,\n             avoid_classes=_avoid_classes):\n    \"\"\"\n    Turn any URLs into links.\n\n    It will search for links identified by the given regular\n    expressions (by default mailto and http(s) links).\n\n    It won't link text in an element in avoid_elements, or an element\n    with a class in avoid_classes.  It won't link to anything with a\n    host that matches one of the regular expressions in avoid_hosts\n    (default localhost and 127.0.0.1).\n\n    If you pass in an element, the element's tail will not be\n    substituted, only the contents of the element.\n    \"\"\"\n    if el.tag in avoid_elements:\n        return\n    class_name = el.get('class')\n    if class_name:\n        class_name = class_name.split()\n        for match_class in avoid_classes:\n            if match_class in class_name:\n                return\n    for child in list(el):\n        autolink(child, link_regexes=link_regexes,\n                 avoid_elements=avoid_elements,\n                 avoid_hosts=avoid_hosts,\n                 avoid_classes=avoid_classes)\n        if child.tail:\n            text, tail_children = _link_text(\n                child.tail, link_regexes, avoid_hosts, factory=el.makeelement)\n            if tail_children:\n                child.tail = text\n                index = el.index(child)\n                el[index+1:index+1] = tail_children\n    if el.text:\n        text, pre_children = _link_text(\n            el.text, link_regexes, avoid_hosts, factory=el.makeelement)\n        if pre_children:\n            el.text = text\n            el[:0] = pre_children", "target": 0}, {"function": "def _link_text(text, link_regexes, avoid_hosts, factory):\n    leading_text = ''\n    links = []\n    last_pos = 0\n    while 1:\n        best_match, best_pos = None, None\n        for regex in link_regexes:\n            regex_pos = last_pos\n            while 1:\n                match = regex.search(text, pos=regex_pos)\n                if match is None:\n                    break\n                host = match.group('host')\n                for host_regex in avoid_hosts:\n                    if host_regex.search(host):\n                        regex_pos = match.end()\n                        break\n                else:\n                    break\n            if match is None:\n                continue\n            if best_pos is None or match.start() < best_pos:\n                best_match = match\n                best_pos = match.start()\n        if best_match is None:\n            # No more matches\n            if links:\n                assert not links[-1].tail\n                links[-1].tail = text\n            else:\n                assert not leading_text\n                leading_text = text\n            break\n        link = best_match.group(0)\n        end = best_match.end()\n        if link.endswith('.') or link.endswith(','):\n            # These punctuation marks shouldn't end a link\n            end -= 1\n            link = link[:-1]\n        prev_text = text[:best_match.start()]\n        if links:\n            assert not links[-1].tail\n            links[-1].tail = prev_text\n        else:\n            assert not leading_text\n            leading_text = prev_text\n        anchor = factory('a')\n        anchor.set('href', link)\n        body = best_match.group('body')\n        if not body:\n            body = link\n        if body.endswith('.') or body.endswith(','):\n            body = body[:-1]\n        anchor.text = body\n        links.append(anchor)\n        text = text[end:]\n    return leading_text, links", "target": 0}, {"function": "def autolink_html(html, *args, **kw):\n    result_type = type(html)\n    if isinstance(html, basestring):\n        doc = fromstring(html)\n    else:\n        doc = copy.deepcopy(html)\n    autolink(doc, *args, **kw)\n    return _transform_result(result_type, doc)", "target": 0}, {"function": "def word_break(el, max_width=40,\n               avoid_elements=_avoid_word_break_elements,\n               avoid_classes=_avoid_word_break_classes,\n               break_character=unichr(0x200b)):\n    \"\"\"\n    Breaks any long words found in the body of the text (not attributes).\n\n    Doesn't effect any of the tags in avoid_elements, by default\n    ``<textarea>`` and ``<pre>``\n\n    Breaks words by inserting &#8203;, which is a unicode character\n    for Zero Width Space character.  This generally takes up no space\n    in rendering, but does copy as a space, and in monospace contexts\n    usually takes up space.\n\n    See http://www.cs.tut.fi/~jkorpela/html/nobr.html for a discussion\n    \"\"\"\n    # Character suggestion of &#8203 comes from:\n    #   http://www.cs.tut.fi/~jkorpela/html/nobr.html\n    if el.tag in _avoid_word_break_elements:\n        return\n    class_name = el.get('class')\n    if class_name:\n        dont_break = False\n        class_name = class_name.split()\n        for avoid in avoid_classes:\n            if avoid in class_name:\n                dont_break = True\n                break\n        if dont_break:\n            return\n    if el.text:\n        el.text = _break_text(el.text, max_width, break_character)\n    for child in el:\n        word_break(child, max_width=max_width,\n                   avoid_elements=avoid_elements,\n                   avoid_classes=avoid_classes,\n                   break_character=break_character)\n        if child.tail:\n            child.tail = _break_text(child.tail, max_width, break_character)", "target": 0}, {"function": "def word_break_html(html, *args, **kw):\n    result_type = type(html)\n    doc = fromstring(html)\n    word_break(doc, *args, **kw)\n    return _transform_result(result_type, doc)", "target": 0}, {"function": "def _break_text(text, max_width, break_character):\n    words = text.split()\n    for word in words:\n        if len(word) > max_width:\n            replacement = _insert_break(word, max_width, break_character)\n            text = text.replace(word, replacement)\n    return text", "target": 0}, {"function": "def _insert_break(word, width, break_character):\n    orig_word = word\n    result = ''\n    while len(word) > width:\n        start = word[:width]\n        breaks = list(_break_prefer_re.finditer(start))\n        if breaks:\n            last_break = breaks[-1]\n            # Only walk back up to 10 characters to find a nice break:\n            if last_break.end() > width-10:\n                # FIXME: should the break character be at the end of the\n                # chunk, or the beginning of the next chunk?\n                start = word[:last_break.end()]\n        result += start + break_character\n        word = word[len(start):]\n    result += word\n    return result", "target": 0}]}, {"raw_url": "https://github.com/lxml/lxml/raw/12fa9669007180a7bb87d990c375cf91ca5b664a/src%2Flxml%2Fhtml%2Ftests%2Ftest_clean.py", "code": "import unittest\nfrom lxml.tests.common_imports import make_doctest\n\nimport lxml.html\nfrom lxml.html.clean import Cleaner, clean_html\n\n\nclass CleanerTest(unittest.TestCase):\n    def test_allow_tags(self):\n        html = \"\"\"\n            <html>\n            <head>\n            </head>\n            <body>\n            <p>some text</p>\n            <table>\n            <tr>\n            <td>hello</td><td>world</td>\n            </tr>\n            <tr>\n            <td>hello</td><td>world</td>\n            </tr>\n            </table>\n            <img>\n            </body>\n            </html>\n            \"\"\"\n\n        html_root = lxml.html.document_fromstring(html)\n        cleaner = Cleaner(\n            remove_unknown_tags = False,\n            allow_tags = ['table', 'tr', 'td'])\n        result = cleaner.clean_html(html_root)\n\n        self.assertEqual(12-5+1, len(list(result.iter())))\n\n    def test_allow_and_remove(self):\n        with self.assertRaises(ValueError):\n            Cleaner(allow_tags=['a'], remove_unknown_tags=True)\n\n    def test_remove_unknown_tags(self):\n        html = \"\"\"<div><bun>lettuce, tomato, veggie patty</bun></div>\"\"\"\n        clean_html = \"\"\"<div>lettuce, tomato, veggie patty</div>\"\"\"\n        cleaner = Cleaner(remove_unknown_tags=True)\n        result = cleaner.clean_html(html)\n        self.assertEqual(\n            result,\n            clean_html,\n            msg=\"Unknown tags not removed. Got: %s\" % result,\n        )\n\n    def test_safe_attrs_included(self):\n        html = \"\"\"<p><span style=\"color: #00ffff;\">Cyan</span></p>\"\"\"\n\n        safe_attrs=set(lxml.html.defs.safe_attrs)\n        safe_attrs.add('style')\n\n        cleaner = Cleaner(\n            safe_attrs_only=True,\n            safe_attrs=safe_attrs)\n        result = cleaner.clean_html(html)\n\n        self.assertEqual(html, result)\n\n    def test_safe_attrs_excluded(self):\n        html = \"\"\"<p><span style=\"color: #00ffff;\">Cyan</span></p>\"\"\"\n        expected = \"\"\"<p><span>Cyan</span></p>\"\"\"\n\n        safe_attrs=set()\n\n        cleaner = Cleaner(\n            safe_attrs_only=True,\n            safe_attrs=safe_attrs)\n        result = cleaner.clean_html(html)\n\n        self.assertEqual(expected, result)\n\n    def test_clean_invalid_root_tag(self):\n        # only testing that cleaning with invalid root tags works at all\n        s = lxml.html.fromstring('parent <invalid tag>child</another>')\n        self.assertEqual('parent child', clean_html(s).text_content())\n\n        s = lxml.html.fromstring('<invalid tag>child</another>')\n        self.assertEqual('child', clean_html(s).text_content())\n\n    def test_clean_with_comments(self):\n        html = \"\"\"<p><span style=\"color: #00ffff;\">Cy<!-- xx -->an</span><!-- XXX --></p>\"\"\"\n        s = lxml.html.fragment_fromstring(html)\n\n        self.assertEqual(\n            b'<p><span>Cyan</span></p>',\n            lxml.html.tostring(clean_html(s)))\n        self.assertEqual(\n            '<p><span>Cyan</span></p>',\n            clean_html(html))\n\n        cleaner = Cleaner(comments=False)\n        result = cleaner.clean_html(s)\n        self.assertEqual(\n            b'<p><span>Cy<!-- xx -->an</span><!-- XXX --></p>',\n            lxml.html.tostring(result))\n        self.assertEqual(\n            '<p><span>Cy<!-- xx -->an</span><!-- XXX --></p>',\n            cleaner.clean_html(html))\n\n    def test_sneaky_noscript_in_style(self):\n        # This gets parsed as <noscript> -> <style>\"...</noscript>...\"</style>\n        # thus passing the </noscript> through into the output.\n        html = '<noscript><style><a title=\"</noscript><img src=x onerror=alert(1)>\">'\n        s = lxml.html.fragment_fromstring(html)\n\n        self.assertEqual(\n            b'<noscript><style>/* deleted */</style></noscript>',\n            lxml.html.tostring(clean_html(s)))\n\n    def test_sneaky_js_in_math_style(self):\n        # This gets parsed as <math> -> <style>\"...\"</style>\n        # thus passing any tag/script/whatever content through into the output.\n        html = '<math><style><img src=x onerror=alert(1)></style></math>'\n        s = lxml.html.fragment_fromstring(html)\n\n        self.assertEqual(\n            b'<math><style>/* deleted */</style></math>',\n            lxml.html.tostring(clean_html(s)))\n\n    def test_sneaky_import_in_style(self):\n        # Prevent \"@@importimport\" -> \"@import\" replacement.\n        style_codes = [\n            \"@@importimport(extstyle.css)\",\n            \"@ @  import import(extstyle.css)\",\n            \"@ @ importimport(extstyle.css)\",\n            \"@@  import import(extstyle.css)\",\n            \"@ @import import(extstyle.css)\",\n            \"@@importimport()\",\n        ]\n        for style_code in style_codes:\n            html = '<style>%s</style>' % style_code\n            s = lxml.html.fragment_fromstring(html)\n\n            cleaned = lxml.html.tostring(clean_html(s))\n            self.assertEqual(\n                b'<style>/* deleted */</style>',\n                cleaned,\n                \"%s  ->  %s\" % (style_code, cleaned))\n\n    def test_formaction_attribute_in_button_input(self):\n        # The formaction attribute overrides the form's action and should be\n        # treated as a malicious link attribute\n        html = ('<form id=\"test\"><input type=\"submit\" formaction=\"javascript:alert(1)\"></form>'\n        '<button form=\"test\" formaction=\"javascript:alert(1)\">X</button>')\n        expected = ('<div><form id=\"test\"><input type=\"submit\" formaction=\"\"></form>'\n        '<button form=\"test\" formaction=\"\">X</button></div>')\n        cleaner = Cleaner(\n            forms=False,\n            safe_attrs_only=False,\n        )\n        self.assertEqual(\n            expected,\n            cleaner.clean_html(html))\n\n\ndef test_suite():\n    suite = unittest.TestSuite()\n    suite.addTests([make_doctest('test_clean.txt')])\n    suite.addTests([make_doctest('test_clean_embed.txt')])\n    suite.addTests(unittest.makeSuite(CleanerTest))\n    return suite\n", "code_before": "import unittest\nfrom lxml.tests.common_imports import make_doctest\n\nimport lxml.html\nfrom lxml.html.clean import Cleaner, clean_html\n\n\nclass CleanerTest(unittest.TestCase):\n    def test_allow_tags(self):\n        html = \"\"\"\n            <html>\n            <head>\n            </head>\n            <body>\n            <p>some text</p>\n            <table>\n            <tr>\n            <td>hello</td><td>world</td>\n            </tr>\n            <tr>\n            <td>hello</td><td>world</td>\n            </tr>\n            </table>\n            <img>\n            </body>\n            </html>\n            \"\"\"\n\n        html_root = lxml.html.document_fromstring(html)\n        cleaner = Cleaner(\n            remove_unknown_tags = False,\n            allow_tags = ['table', 'tr', 'td'])\n        result = cleaner.clean_html(html_root)\n\n        self.assertEqual(12-5+1, len(list(result.iter())))\n\n    def test_allow_and_remove(self):\n        with self.assertRaises(ValueError):\n            Cleaner(allow_tags=['a'], remove_unknown_tags=True)\n\n    def test_remove_unknown_tags(self):\n        html = \"\"\"<div><bun>lettuce, tomato, veggie patty</bun></div>\"\"\"\n        clean_html = \"\"\"<div>lettuce, tomato, veggie patty</div>\"\"\"\n        cleaner = Cleaner(remove_unknown_tags=True)\n        result = cleaner.clean_html(html)\n        self.assertEqual(\n            result,\n            clean_html,\n            msg=\"Unknown tags not removed. Got: %s\" % result,\n        )\n\n    def test_safe_attrs_included(self):\n        html = \"\"\"<p><span style=\"color: #00ffff;\">Cyan</span></p>\"\"\"\n\n        safe_attrs=set(lxml.html.defs.safe_attrs)\n        safe_attrs.add('style')\n\n        cleaner = Cleaner(\n            safe_attrs_only=True,\n            safe_attrs=safe_attrs)\n        result = cleaner.clean_html(html)\n\n        self.assertEqual(html, result)\n\n    def test_safe_attrs_excluded(self):\n        html = \"\"\"<p><span style=\"color: #00ffff;\">Cyan</span></p>\"\"\"\n        expected = \"\"\"<p><span>Cyan</span></p>\"\"\"\n\n        safe_attrs=set()\n\n        cleaner = Cleaner(\n            safe_attrs_only=True,\n            safe_attrs=safe_attrs)\n        result = cleaner.clean_html(html)\n\n        self.assertEqual(expected, result)\n\n    def test_clean_invalid_root_tag(self):\n        # only testing that cleaning with invalid root tags works at all\n        s = lxml.html.fromstring('parent <invalid tag>child</another>')\n        self.assertEqual('parent child', clean_html(s).text_content())\n\n        s = lxml.html.fromstring('<invalid tag>child</another>')\n        self.assertEqual('child', clean_html(s).text_content())\n\n    def test_clean_with_comments(self):\n        html = \"\"\"<p><span style=\"color: #00ffff;\">Cy<!-- xx -->an</span><!-- XXX --></p>\"\"\"\n        s = lxml.html.fragment_fromstring(html)\n\n        self.assertEqual(\n            b'<p><span>Cyan</span></p>',\n            lxml.html.tostring(clean_html(s)))\n        self.assertEqual(\n            '<p><span>Cyan</span></p>',\n            clean_html(html))\n\n        cleaner = Cleaner(comments=False)\n        result = cleaner.clean_html(s)\n        self.assertEqual(\n            b'<p><span>Cy<!-- xx -->an</span><!-- XXX --></p>',\n            lxml.html.tostring(result))\n        self.assertEqual(\n            '<p><span>Cy<!-- xx -->an</span><!-- XXX --></p>',\n            cleaner.clean_html(html))\n\n    def test_sneaky_noscript_in_style(self):\n        # This gets parsed as <noscript> -> <style>\"...</noscript>...\"</style>\n        # thus passing the </noscript> through into the output.\n        html = '<noscript><style><a title=\"</noscript><img src=x onerror=alert(1)>\">'\n        s = lxml.html.fragment_fromstring(html)\n\n        self.assertEqual(\n            b'<noscript><style>/* deleted */</style></noscript>',\n            lxml.html.tostring(clean_html(s)))\n\n    def test_sneaky_js_in_math_style(self):\n        # This gets parsed as <math> -> <style>\"...\"</style>\n        # thus passing any tag/script/whatever content through into the output.\n        html = '<math><style><img src=x onerror=alert(1)></style></math>'\n        s = lxml.html.fragment_fromstring(html)\n\n        self.assertEqual(\n            b'<math><style>/* deleted */</style></math>',\n            lxml.html.tostring(clean_html(s)))\n\n    def test_formaction_attribute_in_button_input(self):\n        # The formaction attribute overrides the form's action and should be\n        # treated as a malicious link attribute\n        html = ('<form id=\"test\"><input type=\"submit\" formaction=\"javascript:alert(1)\"></form>'\n        '<button form=\"test\" formaction=\"javascript:alert(1)\">X</button>')\n        expected = ('<div><form id=\"test\"><input type=\"submit\" formaction=\"\"></form>'\n        '<button form=\"test\" formaction=\"\">X</button></div>')\n        cleaner = Cleaner(\n            forms=False,\n            safe_attrs_only=False,\n        )\n        self.assertEqual(\n            expected,\n            cleaner.clean_html(html))\n\n\ndef test_suite():\n    suite = unittest.TestSuite()\n    suite.addTests([make_doctest('test_clean.txt')])\n    suite.addTests([make_doctest('test_clean_embed.txt')])\n    suite.addTests(unittest.makeSuite(CleanerTest))\n    return suite\n", "patch": "@@ -123,6 +123,26 @@ def test_sneaky_js_in_math_style(self):\n             b'<math><style>/* deleted */</style></math>',\n             lxml.html.tostring(clean_html(s)))\n \n+    def test_sneaky_import_in_style(self):\n+        # Prevent \"@@importimport\" -> \"@import\" replacement.\n+        style_codes = [\n+            \"@@importimport(extstyle.css)\",\n+            \"@ @  import import(extstyle.css)\",\n+            \"@ @ importimport(extstyle.css)\",\n+            \"@@  import import(extstyle.css)\",\n+            \"@ @import import(extstyle.css)\",\n+            \"@@importimport()\",\n+        ]\n+        for style_code in style_codes:\n+            html = '<style>%s</style>' % style_code\n+            s = lxml.html.fragment_fromstring(html)\n+\n+            cleaned = lxml.html.tostring(clean_html(s))\n+            self.assertEqual(\n+                b'<style>/* deleted */</style>',\n+                cleaned,\n+                \"%s  ->  %s\" % (style_code, cleaned))\n+\n     def test_formaction_attribute_in_button_input(self):\n         # The formaction attribute overrides the form's action and should be\n         # treated as a malicious link attribute", "file_path": "files/2021_12/405", "file_language": "py", "file_name": "src/lxml/html/tests/test_clean.py", "outdated_file_modify": 1, "outdated_file_before": 0, "outdated_file_after": 1, "llm_check": 1, "static_check": 0, "static": {"rats": [false, []], "semgrep": [false, []]}, "target": -1, "function_before": [], "function_after": []}], "outdated": 1, "cwe_descripiton": "", "cwe_consequence": "", "cwe_method": "", "cwe_solution": ""}
