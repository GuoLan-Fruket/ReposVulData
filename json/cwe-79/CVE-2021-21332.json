{"index": 5521, "cve_id": "CVE-2021-21332", "cwe_id": ["CWE-79"], "cve_language": "Python", "cve_description": "Synapse is a Matrix reference homeserver written in python (pypi package matrix-synapse). Matrix is an ecosystem for open federated Instant Messaging and VoIP. In Synapse before version 1.27.0, the password reset endpoint served via Synapse was vulnerable to cross-site scripting (XSS) attacks. The impact depends on the configuration of the domain that Synapse is deployed on, but may allow access to cookies and other browser data, CSRF vulnerabilities, and access to other resources served on the same domain or parent domains. This is fixed in version 1.27.0.", "cvss": "8.2", "publish_date": "March 26, 2021", "AV": "NETWORK", "AC": "NETWORK", "PR": "NONE", "UI": "REQUIRED", "S": "CHANGED", "C": "HIGH", "I": "LOW", "A": "NONE", "commit_id": "e54746bdf7d5c831eabe4dcea76a7626f1de73df", "commit_message": "Clean-up the template loading code. (#9200)\n\n* Enables autoescape by default for HTML files.\r\n* Adds a new read_template method for reading a single template.\r\n* Some logic clean-up.", "commit_date": "2021-01-27T15:59:50Z", "project": "matrix-org/synapse", "url": "https://api.github.com/repos/matrix-org/synapse/commits/e54746bdf7d5c831eabe4dcea76a7626f1de73df", "html_url": "https://github.com/matrix-org/synapse/commit/e54746bdf7d5c831eabe4dcea76a7626f1de73df", "windows_before": [{"commit_id": "71c46652a29b7721b216cd8a5c74dd371b852f55", "commit_date": "Wed Jan 27 10:52:45 2021 -0500", "commit_message": "Copy the upgrade note to 1.26.0.", "files_name": ["CHANGES.md"]}, {"commit_id": "73ed289bd26819f9c73900f7e4cd8e4c2a2f6e0c", "commit_date": "Wed Jan 27 10:50:37 2021 -0500", "commit_message": "1.26.0", "files_name": ["CHANGES.md", "synapse/__init__.py"]}, {"commit_id": "93b61589b0bdb3845ee839e9c2a4e1adb06bd483", "commit_date": "Wed Jan 27 14:06:27 2021 +0000", "commit_message": "Add a note to changelog about redis usage (#9227)", "files_name": ["CHANGES.md", "changelog.d/9227.misc", "docs/workers.md"]}, {"commit_id": "cfcc4bfcaf3a0fa063c1f2de49ed7bf0929ff540", "commit_date": "Wed Jan 27 12:41:51 2021 +0000", "commit_message": "Merge branch 'social_login' into develop", "files_name": ["a737cc27134c50059440ca33510b0baea53b4225 - Wed Jan 27 12:41:24 2021 +0000 : Implement MSC2858 support (#9183)", "changelog.d/9183.feature", "synapse/config/_base.pyi", "synapse/config/experimental.py", "synapse/config/homeserver.py", "synapse/handlers/sso.py", "synapse/http/server.py", "synapse/rest/client/v1/login.py", "tests/rest/client/v1/test_login.py", "tests/utils.py"]}, {"commit_id": "a64c29926efd8460dfc9561d761898197638973d", "commit_date": "Wed Jan 27 11:49:31 2021 +0000", "commit_message": "Pass a dict, instead of None, to modules if a None config is specified in the homeserver config (#9229)", "files_name": ["changelog.d/9229.bugfix", "synapse/util/module_loader.py"]}, {"commit_id": "1baab2035265cf2543fe3c0ef5412c1ac0740c7e", "commit_date": "Tue Jan 26 10:50:21 2021 -0500", "commit_message": "Add type hints to various handlers. (#9223)", "files_name": ["changelog.d/9223.misc", "mypy.ini", "synapse/handlers/acme.py", "synapse/handlers/acme_issuing_service.py", "synapse/handlers/groups_local.py", "synapse/handlers/search.py", "synapse/handlers/set_password.py", "synapse/handlers/state_deltas.py", "synapse/handlers/stats.py", "synapse/handlers/typing.py", "synapse/handlers/user_directory.py", "synapse/storage/databases/main/search.py", "synapse/storage/databases/main/stats.py", "synapse/storage/databases/main/user_directory.py"]}, {"commit_id": "26837d5dbeae211968b3d52cdc10f005ba612a9f", "commit_date": "Tue Jan 26 10:49:25 2021 -0500", "commit_message": "Do not require the CAS service URL setting (use public_baseurl instead). (#9199)", "files_name": ["changelog.d/9199.removal", "docs/sample_config.yaml", "synapse/config/cas.py", "synapse/config/oidc_config.py", "synapse/handlers/cas_handler.py"]}, {"commit_id": "dd8da8c5f6ac525a7456437913a03f68d4504605", "commit_date": "Tue Jan 26 13:57:31 2021 +0000", "commit_message": "Precompute joined hosts and store in Redis (#9198)", "files_name": ["changelog.d/9198.misc", "stubs/txredisapi.pyi", "synapse/config/_base.pyi", "synapse/federation/sender/__init__.py", "synapse/handlers/federation.py", "synapse/handlers/message.py", "synapse/replication/tcp/external_cache.py", "synapse/replication/tcp/handler.py", "synapse/server.py", "synapse/state/__init__.py", "tests/replication/_base.py"]}, {"commit_id": "4937fe3d6be94222b02760866496781f8cc88751", "commit_date": "Tue Jan 26 07:32:17 2021 -0500", "commit_message": "Try to recover from unknown encodings when previewing media. (#9164)", "files_name": ["changelog.d/9164.bugfix", "synapse/rest/media/v1/preview_url_resource.py", "tests/test_preview.py"]}, {"commit_id": "e74bb9673315768287430bff2cb8bb0adb3e49ab", "commit_date": "Tue Jan 26 11:36:12 2021 +0000", "commit_message": "Update isort to v5.7.0 (#9222)", "files_name": ["changelog.d/9222.misc", "setup.py"]}, {"commit_id": "e5b659e9e12e0f7d1467a154b152666da31db02c", "commit_date": "Tue Jan 26 12:57:38 2021 +0200", "commit_message": "Merge pull request #9062 from matrix-org/jaywink/admin-forward-extremities", "files_name": ["a1ff1e967fb94411e806f69e6f026263be7a6790 - Tue Jan 26 10:54:54 2021 +0000 : Periodically send pings to detect dead Redis connections (#9218)", "changelog.d/9218.bugfix", "stubs/txredisapi.pyi", "synapse/replication/tcp/handler.py", "synapse/replication/tcp/redis.py"]}, {"commit_id": "4936fc59fcf23582c940cb1cbf4286039b3504de", "commit_date": "Tue Jan 26 10:21:02 2021 +0200", "commit_message": "Fix get forward extremities query", "files_name": ["synapse/storage/databases/main/events_forward_extremities.py"]}, {"commit_id": "cee4010f94f8f4dadbdaadac5a62c54c19e17505", "commit_date": "Tue Jan 26 10:15:32 2021 +0200", "commit_message": "Merge branch 'develop' into jaywink/admin-forward-extremities", "files_name": ["e20f18a76680bc16fd8299a61dd81dc07f1a3ffd - Tue Jan 26 10:13:35 2021 +0200 : Make natural join inner join", "synapse/storage/databases/main/events_forward_extremities.py"]}, {"commit_id": "fdf8346944eb0b9c720bb26677ce3f0fa61a9d3c", "commit_date": "Mon Jan 25 14:59:48 2021 -0500", "commit_message": "Merge remote-tracking branch 'origin/develop' into jaywink/admin-forward-extremities", "files_name": ["5b857b77f7de62bb9be0aa88a3fffcf7cb11efe6 - Mon Jan 25 14:52:30 2021 -0500 : Don't error if deleting a non-existent pusher. (#9121)", "changelog.d/9121.bugfix", "synapse/storage/databases/main/pusher.py"]}, {"commit_id": "4a55d267eef1388690e6781b580910e341358f95", "commit_date": "Mon Jan 25 14:49:39 2021 -0500", "commit_message": "Add an admin API for shadow-banning users. (#9209)", "files_name": ["changelog.d/9209.feature", "docs/admin_api/user_admin_api.rst", "stubs/txredisapi.pyi", "synapse/rest/admin/__init__.py", "synapse/rest/admin/users.py", "synapse/storage/databases/main/registration.py", "tests/rest/admin/test_user.py", "tests/rest/client/test_shadow_banned.py"]}, {"commit_id": "2547d9d4d73050b654fcd8c77bbe5430303c026b", "commit_date": "Mon Jan 25 14:22:35 2021 -0500", "commit_message": "Fix Python 3.5 old deps build by using a compatible pip version. (#9217)", "files_name": [".buildkite/scripts/test_old_deps.sh", "changelog.d/9217.misc", "tox.ini"]}, {"commit_id": "65fb3b2e254a2ec331ec46de470c9cebc9597b3a", "commit_date": "Mon Jan 25 19:37:58 2021 +0000", "commit_message": "Merge tag 'v1.26.0rc2' into social_login", "files_name": ["a71be9d62d0a8670f088ee4879ab5e72869dd9b1 - Mon Jan 25 14:22:35 2021 -0500 : Fix Python 3.5 old deps build by using a compatible pip version. (#9217)", ".buildkite/scripts/test_old_deps.sh", "changelog.d/9217.misc", "tox.ini"]}, {"commit_id": "fe18882bb5759133b8921b74d29d4a1906a69655", "commit_date": "Mon Jan 25 15:55:54 2021 +0200", "commit_message": "Merge remote-tracking branch 'origin/develop' into jaywink/admin-forward-extremities", "files_name": ["e448dbbf5b488be28a9bf6d86ebd90fa2eee5e39 - Mon Jan 25 08:51:45 2021 -0500 : Merge tag 'v1.26.0rc2' into develop", "69961c7e9fe5e7c4bad72b810f2bce7e8f15f17e - Mon Jan 25 08:26:42 2021 -0500 : Tweak changes.", "CHANGES.md"]}, {"commit_id": "a01605c13681eeeeaf6abce80737db8e02f587cc", "commit_date": "Mon Jan 25 08:25:40 2021 -0500", "commit_message": "1.26.0rc2", "files_name": ["CHANGES.md", "changelog.d/9189.misc", "changelog.d/9193.bugfix", "changelog.d/9195.bugfix", "changelog.d/9204.misc", "changelog.d/9210.bugfix", "synapse/__init__.py"]}, {"commit_id": "6f7417c3db54c9545e93b0428303f29973468d39", "commit_date": "Mon Jan 25 07:27:16 2021 -0500", "commit_message": "Handle missing content keys when calculating presentable names. (#9165)", "files_name": ["changelog.d/9165.bugfix", "synapse/push/presentable_names.py", "tests/push/test_presentable_names.py", "tests/push/test_push_rule_evaluator.py"]}, {"commit_id": "8965b6cfec8a1de847efe3d1be4b9babf4622e2e", "commit_date": "Sat Jan 23 21:41:35 2021 +0200", "commit_message": "Merge branch 'develop' into jaywink/admin-forward-extremities", "files_name": ["930ba009719788ebc2004c6ef89329dae1b9689b - Sat Jan 23 21:34:32 2021 +0200 : Add depth and received_ts to forward_extremities admin API response", "docs/admin_api/rooms.md", "synapse/storage/databases/main/events_forward_extremities.py"]}, {"commit_id": "056327457ff471495741a539e99c840ed54afccd", "commit_date": "Fri Jan 22 19:44:08 2021 +0000", "commit_message": "Fix chain cover update to handle events with duplicate auth events (#9210)", "files_name": ["changelog.d/9210.bugfix", "synapse/util/iterutils.py", "tests/util/test_itertools.py"]}, {"commit_id": "28f255d5f316d45b5e8b72e6c3da73a5a393eee2", "commit_date": "Fri Jan 22 11:14:49 2021 +0000", "commit_message": "Bump psycopg2 version (#9204)", "files_name": ["changelog.d/9204.misc", "synapse/python_dependencies.py", "tox.ini"]}, {"commit_id": "a7882f98874684969910d3a6ed7d85f99114cc45", "commit_date": "Thu Jan 21 14:53:58 2021 -0500", "commit_message": "Return a 404 if no valid thumbnail is found. (#9163)", "files_name": ["changelog.d/9163.bugfix", "synapse/rest/media/v1/_base.py", "synapse/rest/media/v1/thumbnail_resource.py", "tests/rest/media/v1/test_media_storage.py"]}, {"commit_id": "31c5382d7a439146b9e72590b634b1772b97a6f1", "commit_date": "Thu Jan 21 18:26:52 2021 +0000", "commit_message": "Align the directories linted in CI with the defaults in scripts-dev/lint.sh (#9191)", "files_name": ["changelog.d/9191.misc", "scripts-dev/lint.sh", "tox.ini"]}, {"commit_id": "758ed5f1bc16f4b73d73d94129761a8680fd71c5", "commit_date": "Thu Jan 21 17:00:12 2021 +0000", "commit_message": "Speed up chain cover calculation (#9176)", "files_name": ["changelog.d/9176.misc", "synapse/storage/databases/main/events.py", "synapse/storage/util/sequence.py"]}, {"commit_id": "12ec55bfaa30bc8040131c23f7c6728e40b21d01", "commit_date": "Thu Jan 21 16:31:51 2021 +0000", "commit_message": "Increase perf of handling concurrent use of StreamIDGenerators. (#9190)", "files_name": ["changelog.d/9190.misc", "synapse/storage/util/id_generators.py"]}, {"commit_id": "939ef657ce603dc0bd47dd66e8347ca5bb004241", "commit_date": "Thu Jan 21 16:05:13 2021 +0000", "commit_message": "Merge remote-tracking branch 'origin/release-v1.26.0' into develop", "files_name": ["ccfafac88245c806ad5bde1ebe9312ff1032d829 - Thu Jan 21 16:03:25 2021 +0000 : Add schema update to fix existing DBs affected by #9193 (#9195)", "changelog.d/9195.bugfix", "synapse/storage/databases/main/schema/delta/59/07shard_account_data_fix.sql", "synapse/storage/util/sequence.py"]}, {"commit_id": "b249f002b8d3f7fc7476b5e8f18f9e8d70c32fd5", "commit_date": "Thu Jan 21 15:09:30 2021 +0000", "commit_message": "Merge remote-tracking branch 'origin/release-v1.26.0' into develop", "files_name": ["2506074ef0a880b527d61457c32cd397a0d3ab2d - Thu Jan 21 15:09:09 2021 +0000 : Fix receipts or account data not being sent down sync (#9193)", "changelog.d/9193.bugfix", "synapse/storage/databases/main/account_data.py", "synapse/storage/databases/main/receipts.py", "synapse/storage/util/id_generators.py", "synapse/storage/util/sequence.py"]}, {"commit_id": "7a43482f1916622967f5a4b389f93944dd5deb07", "commit_date": "Thu Jan 21 14:44:12 2021 +0000", "commit_message": "Use execute_batch in more places (#9188)", "files_name": ["changelog.d/9188.misc", "synapse/storage/database.py", "synapse/storage/databases/main/devices.py"]}], "windows_after": [{"commit_id": "b685c5e7f193b1afb95b96d0a827d74f7691faef", "commit_date": "Wed Jan 27 11:02:04 2021 -0500", "commit_message": "Move note above changes.", "files_name": ["CHANGES.md"]}, {"commit_id": "17b713850f2de134512bd8fff87c74c07d88d719", "commit_date": "Wed Jan 27 11:13:21 2021 -0500", "commit_message": "Merge branch 'master' into develop", "files_name": ["7fa1346f9323222b19c5ab7c50b354099684788f - Wed Jan 27 17:27:24 2021 +0000 : Merge branch 'social_login' into develop", "fbd9de6d1f10562b3f00939d943b14f083474cb8 - Wed Jan 27 17:27:58 2021 +0000 : Merge tag 'v1.26.0' into social_login", "300d0d756a5a9a67d1838426d8b27eacd973b57a - Wed Jan 27 17:28:39 2021 +0000 : Merge branch 'social_login' into develop", "2e537a02804af47862b8c7e0454ae85fde616f2d - Wed Jan 27 23:08:08 2021 +0530 : Check if a user is in the room before sending a PowerLevel event on their behalf (#9235)", "changelog.d/9235.bugfix", "synapse/rest/admin/rooms.py"]}, {"commit_id": "ccb9616f26413db4b829536f454923f9edb75040", "commit_date": "Wed Jan 27 12:45:02 2021 -0500", "commit_message": "Update debian changelog.", "files_name": ["debian/changelog"]}, {"commit_id": "00e97a7774a6c91fb3b528a207a1c2613ff38036", "commit_date": "Wed Jan 27 12:51:49 2021 -0500", "commit_message": "Merge branch 'master' into develop", "files_name": ["869667760f571c9edebab660061e17035d57f182 - Wed Jan 27 21:28:59 2021 +0000 : Support for scraping email addresses from OIDC providers (#9245)", "changelog.d/9245.feature", "docs/sample_config.yaml", "synapse/config/oidc_config.py", "synapse/handlers/oidc_handler.py"]}, {"commit_id": "a083aea396dbd455858e93d6a57a236e192b68e2", "commit_date": "Wed Jan 27 21:31:45 2021 +0000", "commit_message": "Add 'brand' field to MSC2858 response (#9242)", "files_name": ["changelog.d/9183.feature", "changelog.d/9242.feature", "docs/openid.md", "docs/sample_config.yaml", "synapse/config/oidc_config.py", "synapse/handlers/cas_handler.py", "synapse/handlers/oidc_handler.py", "synapse/handlers/saml_handler.py", "synapse/handlers/sso.py", "synapse/rest/client/v1/login.py"]}, {"commit_id": "34efb4c604bc7c5052bc859a9382addc7373eec7", "commit_date": "Wed Jan 27 22:57:16 2021 +0000", "commit_message": "Add notes on integrating with Facebook for SSO login. (#9244)", "files_name": ["changelog.d/9244.doc", "docs/openid.md"]}, {"commit_id": "10332c175c829a21b6565bc5e865bca154ffb084", "commit_date": "Mon Jan 18 15:02:22 2021 +0100", "commit_message": "New API /_synapse/admin/rooms/{roomId}/context/{eventId}", "files_name": ["changelog.d/9150.feature", "synapse/handlers/room.py", "synapse/rest/admin/__init__.py", "synapse/rest/admin/rooms.py", "synapse/visibility.py", "tests/rest/admin/test_room.py"]}, {"commit_id": "fe52dae6bd8508bfb79ba5e534a384a9e5e96b5d", "commit_date": "Fri Jan 22 14:41:20 2021 +0100", "commit_message": "FIXUP: Documenting /_synapse/admin/v1/rooms/<room_id>/context/<event_id>", "files_name": ["docs/admin_api/rooms.md"]}, {"commit_id": "de7f049527c64470a16b2633862a1f1b8f0da9c2", "commit_date": "Mon Jan 25 18:02:35 2021 +0100", "commit_message": "FIXUP: Don't filter events at all for admin/v1/rooms/.../context/...", "files_name": ["synapse/handlers/room.py", "synapse/visibility.py"]}, {"commit_id": "b859919acc3ad6c61ba26a3c9b1e36c75a30c3fe", "commit_date": "Thu Jan 28 12:18:07 2021 +0100", "commit_message": "FIXUP: Now testing that the user is admin!", "files_name": ["changelog.d/9150.feature", "synapse/rest/admin/rooms.py", "tests/rest/admin/test_room.py"]}, {"commit_id": "a7648696231f3df7ec1f324a15dc308fbee2a985", "commit_date": "Thu Jan 28 12:19:39 2021 +0100", "commit_message": "FIXUP: Doc", "files_name": ["synapse/rest/admin/rooms.py"]}, {"commit_id": "b755f60ce2fb651356d8d588dcd7864b022023cd", "commit_date": "Thu Jan 28 12:23:19 2021 +0100", "commit_message": "FIXUP: Removing awaitable", "files_name": ["synapse/handlers/room.py"]}, {"commit_id": "93f84e037349cb3efddd8df5adf22512530a295c", "commit_date": "Thu Jan 28 12:27:30 2021 +0100", "commit_message": "FIXUP: Making get_event_context a bit more paranoid", "files_name": ["synapse/handlers/room.py", "synapse/rest/admin/rooms.py", "synapse/rest/client/v1/room.py"]}, {"commit_id": "a78016dadfb1680f5f77daae9948086b37cbeef8", "commit_date": "Thu Jan 28 08:34:19 2021 -0500", "commit_message": "Add type hints to E2E handler. (#9232)", "files_name": ["changelog.d/9232.misc", "mypy.ini", "synapse/handlers/device.py", "synapse/handlers/e2e_keys.py", "synapse/handlers/e2e_room_keys.py", "synapse/logging/opentracing.py", "synapse/storage/databases/main/end_to_end_keys.py"]}, {"commit_id": "31d072aea0a37ad5408995359b89080b5280f57d", "commit_date": "Thu Jan 28 16:53:40 2021 +0100", "commit_message": "FIXUP: linter", "files_name": ["synapse/handlers/room.py", "synapse/rest/admin/rooms.py", "tests/rest/admin/test_room.py"]}, {"commit_id": "54a6afeee3b1ae8f353edfdf1375aa73c1819e9e", "commit_date": "Thu Jan 28 17:38:59 2021 +0000", "commit_message": "Cache config options in SSL verification (#9255)", "files_name": ["changelog.d/9255.misc", "synapse/crypto/context_factory.py"]}, {"commit_id": "4b73488e811714089ba447884dccb9b6ae3ac16c", "commit_date": "Thu Jan 28 17:39:21 2021 +0000", "commit_message": "Ratelimit 3PID /requestToken API (#9238)", "files_name": ["changelog.d/9238.feature", "docs/sample_config.yaml", "synapse/config/_base.pyi", "synapse/config/ratelimiting.py", "synapse/handlers/identity.py", "synapse/rest/client/v2_alpha/account.py", "synapse/rest/client/v2_alpha/register.py", "tests/rest/client/v2_alpha/test_account.py", "tests/server.py", "tests/unittest.py", "tests/utils.py"]}, {"commit_id": "0d81a6fa3e1dc832f56ed09805229b9089758ba5", "commit_date": "Thu Jan 28 22:08:11 2021 +0000", "commit_message": "Merge branch 'social_login' into develop", "files_name": ["c14688d44a80be4a04b5b03976ee0059ff34107f - Fri Jan 29 11:27:43 2021 +0100 : Fix typo in UPGRADE.rst", "UPGRADE.rst"]}, {"commit_id": "e19396d62241c5619051e5aa15c9f53e2568fa45", "commit_date": "Fri Jan 29 14:56:04 2021 +0000", "commit_message": "Fix Debian builds on Xenial (#9254)", "files_name": ["changelog.d/9254.misc", "debian/build_virtualenv", "debian/changelog", "docker/Dockerfile-dhvirtualenv"]}, {"commit_id": "f2c1560eca1e2160087a280261ca78d0708ad721", "commit_date": "Fri Jan 29 16:38:29 2021 +0000", "commit_message": "Ratelimit invites by room and target user (#9258)", "files_name": ["changelog.d/9258.feature", "docs/sample_config.yaml", "synapse/config/ratelimiting.py", "synapse/federation/federation_client.py", "synapse/handlers/federation.py", "synapse/handlers/room.py", "synapse/handlers/room_member.py", "tests/handlers/test_federation.py", "tests/rest/client/v1/test_rooms.py"]}, {"commit_id": "13c7ab81817df8f6028668ca318c6de1ad498313", "commit_date": "Sat Jan 30 20:22:05 2021 +0300", "commit_message": "Fixes for PyPy compatibility (#9270)", "files_name": ["changelog.d/9270.misc", "synapse/app/_base.py"]}, {"commit_id": "f78d07bf005f7212bcc74256721677a3b255ea0e", "commit_date": "Mon Feb 1 13:15:51 2021 +0000", "commit_message": "Split out a separate endpoint to complete SSO registration (#9262)", "files_name": ["changelog.d/9262.feature", "synapse/app/homeserver.py", "synapse/handlers/sso.py", "synapse/http/server.py", "synapse/rest/synapse/client/pick_username.py", "synapse/rest/synapse/client/sso_register.py", "tests/rest/client/v1/test_login.py"]}, {"commit_id": "9c715a5f1981891815c124353ba15cf4d17bf9bb", "commit_date": "Mon Feb 1 15:47:59 2021 +0000", "commit_message": "Fix SSO on workers (#9271)", "files_name": ["changelog.d/9271.bugfix", "docs/workers.md", "synapse/app/generic_worker.py", "synapse/app/homeserver.py", "synapse/rest/synapse/client/__init__.py", "synapse/storage/databases/main/registration.py", "tests/rest/client/v1/test_login.py", "tests/rest/client/v2_alpha/test_auth.py"]}, {"commit_id": "8aed29dc615bee75019fc526a5c91cdc2638b665", "commit_date": "Mon Feb 1 15:50:56 2021 +0000", "commit_message": "Improve styling and wording of SSO redirect confirm template (#9272)", "files_name": ["changelog.d/9272.feature", "docs/sample_config.yaml", "synapse/config/sso.py", "synapse/handlers/auth.py", "synapse/handlers/sso.py", "synapse/module_api/__init__.py", "synapse/res/templates/sso.css", "synapse/res/templates/sso_redirect_confirm.html", "tests/handlers/test_cas.py", "tests/handlers/test_oidc.py", "tests/handlers/test_saml.py"]}, {"commit_id": "4167494c90bc0477bdf4855a79e81dc81bba1377", "commit_date": "Mon Feb 1 15:52:50 2021 +0000", "commit_message": "Replace username picker with a template (#9275)", "files_name": ["changelog.d/9275.feature", "docs/sample_config.yaml", "synapse/config/_base.py", "synapse/config/oidc_config.py", "synapse/config/sso.py", "synapse/handlers/sso.py", "synapse/res/templates/sso_auth_account_details.html", "synapse/res/templates/sso_auth_account_details.js", "synapse/res/username_picker/index.html", "synapse/res/username_picker/script.js", "synapse/res/username_picker/style.css", "synapse/rest/consent/consent_resource.py", "synapse/rest/synapse/client/pick_username.py", "synapse/util/templates.py", "tests/rest/client/v1/test_login.py"]}, {"commit_id": "a800603561c0cb58727474035b6b27ed9e5fc277", "commit_date": "Mon Feb 1 15:54:39 2021 +0000", "commit_message": "Prevent email UIA failures from raising a LoginError (#9265)", "files_name": ["changelog.d/9265.bugfix", "synapse/handlers/auth.py"]}, {"commit_id": "43dd93bb262c8fa7b6c201013891ef540c331682", "commit_date": "Mon Feb 1 18:06:22 2021 +0100", "commit_message": "Add phone home stats for encrypted messages. (#9283)", "files_name": ["changelog.d/9283.feature", "synapse/app/phone_stats_home.py", "synapse/storage/databases/main/metrics.py"]}, {"commit_id": "18ab35284a2270efe01815911885e45b0f743453", "commit_date": "Mon Feb 1 17:28:37 2021 +0000", "commit_message": "Merge branch 'social_login' into develop", "files_name": ["85c56b5a679add887ec9716f176949561dca581b - Mon Feb 1 17:30:42 2021 +0000 : Make importing display name and email optional (#9277)", "changelog.d/9277.feature", "synapse/handlers/register.py"]}], "parents": [{"commit_id_before": "93b61589b0bdb3845ee839e9c2a4e1adb06bd483", "url_before": "https://api.github.com/repos/matrix-org/synapse/commits/93b61589b0bdb3845ee839e9c2a4e1adb06bd483", "html_url_before": "https://github.com/matrix-org/synapse/commit/93b61589b0bdb3845ee839e9c2a4e1adb06bd483"}], "details": [{"raw_url": "https://github.com/matrix-org/synapse/raw/e54746bdf7d5c831eabe4dcea76a7626f1de73df/UPGRADE.rst", "code": "Upgrading Synapse\n=================\n\nBefore upgrading check if any special steps are required to upgrade from the\nversion you currently have installed to the current version of Synapse. The extra\ninstructions that may be required are listed later in this document.\n\n* Check that your versions of Python and PostgreSQL are still supported.\n\n  Synapse follows upstream lifecycles for `Python`_ and `PostgreSQL`_, and\n  removes support for versions which are no longer maintained.\n\n  The website https://endoflife.date also offers convenient summaries.\n\n  .. _Python: https://devguide.python.org/devcycle/#end-of-life-branches\n  .. _PostgreSQL: https://www.postgresql.org/support/versioning/\n\n* If Synapse was installed using `prebuilt packages\n  <INSTALL.md#prebuilt-packages>`_, you will need to follow the normal process\n  for upgrading those packages.\n\n* If Synapse was installed from source, then:\n\n  1. Activate the virtualenv before upgrading. For example, if Synapse is\n     installed in a virtualenv in ``~/synapse/env`` then run:\n\n     .. code:: bash\n\n       source ~/synapse/env/bin/activate\n\n  2. If Synapse was installed using pip then upgrade to the latest version by\n     running:\n\n     .. code:: bash\n\n       pip install --upgrade matrix-synapse\n\n     If Synapse was installed using git then upgrade to the latest version by\n     running:\n\n     .. code:: bash\n\n       git pull\n       pip install --upgrade .\n\n  3. Restart Synapse:\n\n     .. code:: bash\n\n       ./synctl restart\n\nTo check whether your update was successful, you can check the running server\nversion with:\n\n.. code:: bash\n\n    # you may need to replace 'localhost:8008' if synapse is not configured\n    # to listen on port 8008.\n\n    curl http://localhost:8008/_synapse/admin/v1/server_version\n\nRolling back to older versions\n------------------------------\n\nRolling back to previous releases can be difficult, due to database schema\nchanges between releases. Where we have been able to test the rollback process,\nthis will be noted below.\n\nIn general, you will need to undo any changes made during the upgrade process,\nfor example:\n\n* pip:\n\n  .. code:: bash\n\n     source env/bin/activate\n     # replace `1.3.0` accordingly:\n     pip install matrix-synapse==1.3.0\n\n* Debian:\n\n  .. code:: bash\n\n     # replace `1.3.0` and `stretch` accordingly:\n     wget https://packages.matrix.org/debian/pool/main/m/matrix-synapse-py3/matrix-synapse-py3_1.3.0+stretch1_amd64.deb\n     dpkg -i matrix-synapse-py3_1.3.0+stretch1_amd64.deb\n\nUpgrading to v1.27.0\n====================\n\nChanges to HTML templates\n-------------------------\n\nThe HTML templates for SSO and email notifications now have `Jinja2's autoescape <https://jinja.palletsprojects.com/en/2.11.x/api/#autoescaping>`_\nenabled for files ending in ``.html``, ``.htm``, and ``.xml``. If you hae customised\nthese templates and see issues when viewing them you might need to update them.\nIt is expected that most configurations will need no changes.\n\nIf you have customised the templates *names* for these templates it is recommended\nto verify they end in ``.html`` to ensure autoescape is enabled.\n\nThe above applies to the following templates:\n\n* ``add_threepid.html``\n* ``add_threepid_failure.html``\n* ``add_threepid_success.html``\n* ``notice_expiry.html``\n* ``notice_expiry.html``\n* ``notif_mail.html`` (which, by default, includes ``room.html`` and ``notif.html``)\n* ``password_reset.html``\n* ``password_reset_confirmation.html``\n* ``password_reset_failure.html``\n* ``password_reset_success.html``\n* ``registration.html``\n* ``registration_failure.html``\n* ``registration_success.html``\n* ``sso_account_deactivated.html``\n* ``sso_auth_bad_user.html``\n* ``sso_auth_confirm.html``\n* ``sso_auth_success.html``\n* ``sso_error.html``\n* ``sso_login_idp_picker.html``\n* ``sso_redirect_confirm.html``\n\nUpgrading to v1.26.0\n====================\n\nRolling back to v1.25.0 after a failed upgrade\n----------------------------------------------\n\nv1.26.0 includes a lot of large changes. If something problematic occurs, you\nmay want to roll-back to a previous version of Synapse. Because v1.26.0 also\nincludes a new database schema version, reverting that version is also required\nalongside the generic rollback instructions mentioned above. In short, to roll\nback to v1.25.0 you need to:\n\n1. Stop the server\n2. Decrease the schema version in the database:\n\n   .. code:: sql\n\n      UPDATE schema_version SET version = 58;\n\n3. Delete the ignored users & chain cover data:\n\n   .. code:: sql\n\n      DROP TABLE IF EXISTS ignored_users;\n      UPDATE rooms SET has_auth_chain_index = false;\n\n   For PostgreSQL run:\n\n   .. code:: sql\n\n      TRUNCATE event_auth_chain_links;\n      TRUNCATE event_auth_chains;\n\n   For SQLite run:\n\n   .. code:: sql\n\n      DELETE FROM event_auth_chain_links;\n      DELETE FROM event_auth_chains;\n\n4. Mark the deltas as not run (so they will re-run on upgrade).\n\n   .. code:: sql\n\n      DELETE FROM applied_schema_deltas WHERE version = 59 AND file = \"59/01ignored_user.py\";\n      DELETE FROM applied_schema_deltas WHERE version = 59 AND file = \"59/06chain_cover_index.sql\";\n\n5. Downgrade Synapse by following the instructions for your installation method\n   in the \"Rolling back to older versions\" section above.\n\nUpgrading to v1.25.0\n====================\n\nLast release supporting Python 3.5\n----------------------------------\n\nThis is the last release of Synapse which guarantees support with Python 3.5,\nwhich passed its upstream End of Life date several months ago.\n\nWe will attempt to maintain support through March 2021, but without guarantees.\n\nIn the future, Synapse will follow upstream schedules for ending support of\nolder versions of Python and PostgreSQL. Please upgrade to at least Python 3.6\nand PostgreSQL 9.6 as soon as possible.\n\nBlacklisting IP ranges\n----------------------\n\nSynapse v1.25.0 includes new settings, ``ip_range_blacklist`` and\n``ip_range_whitelist``, for controlling outgoing requests from Synapse for federation,\nidentity servers, push, and for checking key validity for third-party invite events.\nThe previous setting, ``federation_ip_range_blacklist``, is deprecated. The new\n``ip_range_blacklist`` defaults to private IP ranges if it is not defined.\n\nIf you have never customised ``federation_ip_range_blacklist`` it is recommended\nthat you remove that setting.\n\nIf you have customised ``federation_ip_range_blacklist`` you should update the\nsetting name to ``ip_range_blacklist``.\n\nIf you have a custom push server that is reached via private IP space you may\nneed to customise ``ip_range_blacklist`` or ``ip_range_whitelist``.\n\nUpgrading to v1.24.0\n====================\n\nCustom OpenID Connect mapping provider breaking change\n------------------------------------------------------\n\nThis release allows the OpenID Connect mapping provider to perform normalisation\nof the localpart of the Matrix ID. This allows for the mapping provider to\nspecify different algorithms, instead of the [default way](https://matrix.org/docs/spec/appendices#mapping-from-other-character-sets).\n\nIf your Synapse configuration uses a custom mapping provider\n(`oidc_config.user_mapping_provider.module` is specified and not equal to\n`synapse.handlers.oidc_handler.JinjaOidcMappingProvider`) then you *must* ensure\nthat `map_user_attributes` of the mapping provider performs some normalisation\nof the `localpart` returned. To match previous behaviour you can use the\n`map_username_to_mxid_localpart` function provided by Synapse. An example is\nshown below:\n\n.. code-block:: python\n\n  from synapse.types import map_username_to_mxid_localpart\n\n  class MyMappingProvider:\n      def map_user_attributes(self, userinfo, token):\n          # ... your custom logic ...\n          sso_user_id = ...\n          localpart = map_username_to_mxid_localpart(sso_user_id)\n\n          return {\"localpart\": localpart}\n\nRemoval historical Synapse Admin API \n------------------------------------\n\nHistorically, the Synapse Admin API has been accessible under:\n\n* ``/_matrix/client/api/v1/admin``\n* ``/_matrix/client/unstable/admin``\n* ``/_matrix/client/r0/admin``\n* ``/_synapse/admin/v1``\n\nThe endpoints with ``/_matrix/client/*`` prefixes have been removed as of v1.24.0.\nThe Admin API is now only accessible under:\n\n* ``/_synapse/admin/v1``\n\nThe only exception is the `/admin/whois` endpoint, which is\n`also available via the client-server API <https://matrix.org/docs/spec/client_server/r0.6.1#get-matrix-client-r0-admin-whois-userid>`_.\n\nThe deprecation of the old endpoints was announced with Synapse 1.20.0 (released\non 2020-09-22) and makes it easier for homeserver admins to lock down external\naccess to the Admin API endpoints.\n\nUpgrading to v1.23.0\n====================\n\nStructured logging configuration breaking changes\n-------------------------------------------------\n\nThis release deprecates use of the ``structured: true`` logging configuration for\nstructured logging. If your logging configuration contains ``structured: true``\nthen it should be modified based on the `structured logging documentation\n<https://github.com/matrix-org/synapse/blob/master/docs/structured_logging.md>`_.\n\nThe ``structured`` and ``drains`` logging options are now deprecated and should\nbe replaced by standard logging configuration of ``handlers`` and ``formatters``.\n\nA future will release of Synapse will make using ``structured: true`` an error.\n\nUpgrading to v1.22.0\n====================\n\nThirdPartyEventRules breaking changes\n-------------------------------------\n\nThis release introduces a backwards-incompatible change to modules making use of\n``ThirdPartyEventRules`` in Synapse. If you make use of a module defined under the\n``third_party_event_rules`` config option, please make sure it is updated to handle\nthe below change:\n\nThe ``http_client`` argument is no longer passed to modules as they are initialised. Instead,\nmodules are expected to make use of the ``http_client`` property on the ``ModuleApi`` class.\nModules are now passed a ``module_api`` argument during initialisation, which is an instance of\n``ModuleApi``. ``ModuleApi`` instances have a ``http_client`` property which acts the same as\nthe ``http_client`` argument previously passed to ``ThirdPartyEventRules`` modules.\n\nUpgrading to v1.21.0\n====================\n\nForwarding ``/_synapse/client`` through your reverse proxy\n----------------------------------------------------------\n\nThe `reverse proxy documentation\n<https://github.com/matrix-org/synapse/blob/develop/docs/reverse_proxy.md>`_ has been updated\nto include reverse proxy directives for ``/_synapse/client/*`` endpoints. As the user password\nreset flow now uses endpoints under this prefix, **you must update your reverse proxy\nconfigurations for user password reset to work**.\n\nAdditionally, note that the `Synapse worker documentation\n<https://github.com/matrix-org/synapse/blob/develop/docs/workers.md>`_ has been updated to\n state that the ``/_synapse/client/password_reset/email/submit_token`` endpoint can be handled\nby all workers. If you make use of Synapse's worker feature, please update your reverse proxy\nconfiguration to reflect this change.\n\nNew HTML templates\n------------------\n\nA new HTML template,\n`password_reset_confirmation.html <https://github.com/matrix-org/synapse/blob/develop/synapse/res/templates/password_reset_confirmation.html>`_,\nhas been added to the ``synapse/res/templates`` directory. If you are using a\ncustom template directory, you may want to copy the template over and modify it.\n\nNote that as of v1.20.0, templates do not need to be included in custom template\ndirectories for Synapse to start. The default templates will be used if a custom\ntemplate cannot be found.\n\nThis page will appear to the user after clicking a password reset link that has\nbeen emailed to them.\n\nTo complete password reset, the page must include a way to make a `POST`\nrequest to\n``/_synapse/client/password_reset/{medium}/submit_token``\nwith the query parameters from the original link, presented as a URL-encoded form. See the file\nitself for more details.\n\nUpdated Single Sign-on HTML Templates\n-------------------------------------\n\nThe ``saml_error.html`` template was removed from Synapse and replaced with the\n``sso_error.html`` template. If your Synapse is configured to use SAML and a\ncustom ``sso_redirect_confirm_template_dir`` configuration then any customisations\nof the ``saml_error.html`` template will need to be merged into the ``sso_error.html``\ntemplate. These templates are similar, but the parameters are slightly different:\n\n* The ``msg`` parameter should be renamed to ``error_description``.\n* There is no longer a ``code`` parameter for the response code.\n* A string ``error`` parameter is available that includes a short hint of why a\n  user is seeing the error page.\n\nUpgrading to v1.18.0\n====================\n\nDocker `-py3` suffix will be removed in future versions\n-------------------------------------------------------\n\nFrom 10th August 2020, we will no longer publish Docker images with the `-py3` tag suffix. The images tagged with the `-py3` suffix have been identical to the non-suffixed tags since release 0.99.0, and the suffix is obsolete.\n\nOn 10th August, we will remove the `latest-py3` tag. Existing per-release tags (such as `v1.18.0-py3`) will not be removed, but no new `-py3` tags will be added.\n\nScripts relying on the `-py3` suffix will need to be updated.\n\nRedis replication is now recommended in lieu of TCP replication\n---------------------------------------------------------------\n\nWhen setting up worker processes, we now recommend the use of a Redis server for replication. **The old direct TCP connection method is deprecated and will be removed in a future release.**\nSee `docs/workers.md <docs/workers.md>`_ for more details.\n\nUpgrading to v1.14.0\n====================\n\nThis version includes a database update which is run as part of the upgrade,\nand which may take a couple of minutes in the case of a large server. Synapse\nwill not respond to HTTP requests while this update is taking place.\n\nUpgrading to v1.13.0\n====================\n\nIncorrect database migration in old synapse versions\n----------------------------------------------------\n\nA bug was introduced in Synapse 1.4.0 which could cause the room directory to\nbe incomplete or empty if Synapse was upgraded directly from v1.2.1 or\nearlier, to versions between v1.4.0 and v1.12.x.\n\nThis will *not* be a problem for Synapse installations which were:\n * created at v1.4.0 or later,\n * upgraded via v1.3.x, or\n * upgraded straight from v1.2.1 or earlier to v1.13.0 or later.\n\nIf completeness of the room directory is a concern, installations which are\naffected can be repaired as follows:\n\n1. Run the following sql from a `psql` or `sqlite3` console:\n\n   .. code:: sql\n\n     INSERT INTO background_updates (update_name, progress_json, depends_on) VALUES\n        ('populate_stats_process_rooms', '{}', 'current_state_events_membership');\n\n     INSERT INTO background_updates (update_name, progress_json, depends_on) VALUES\n        ('populate_stats_process_users', '{}', 'populate_stats_process_rooms');\n\n2. Restart synapse.\n\nNew Single Sign-on HTML Templates\n---------------------------------\n\nNew templates (``sso_auth_confirm.html``, ``sso_auth_success.html``, and\n``sso_account_deactivated.html``) were added to Synapse. If your Synapse is\nconfigured to use SSO and a custom  ``sso_redirect_confirm_template_dir``\nconfiguration then these templates will need to be copied from\n`synapse/res/templates <synapse/res/templates>`_ into that directory.\n\nSynapse SSO Plugins Method Deprecation\n--------------------------------------\n\nPlugins using the ``complete_sso_login`` method of\n``synapse.module_api.ModuleApi`` should update to using the async/await\nversion ``complete_sso_login_async`` which includes additional checks. The\nnon-async version is considered deprecated.\n\nRolling back to v1.12.4 after a failed upgrade\n----------------------------------------------\n\nv1.13.0 includes a lot of large changes. If something problematic occurs, you\nmay want to roll-back to a previous version of Synapse. Because v1.13.0 also\nincludes a new database schema version, reverting that version is also required\nalongside the generic rollback instructions mentioned above. In short, to roll\nback to v1.12.4 you need to:\n\n1. Stop the server\n2. Decrease the schema version in the database:\n\n   .. code:: sql\n\n      UPDATE schema_version SET version = 57;\n\n3. Downgrade Synapse by following the instructions for your installation method\n   in the \"Rolling back to older versions\" section above.\n\n\nUpgrading to v1.12.0\n====================\n\nThis version includes a database update which is run as part of the upgrade,\nand which may take some time (several hours in the case of a large\nserver). Synapse will not respond to HTTP requests while this update is taking\nplace.\n\nThis is only likely to be a problem in the case of a server which is\nparticipating in many rooms.\n\n0. As with all upgrades, it is recommended that you have a recent backup of\n   your database which can be used for recovery in the event of any problems.\n\n1. As an initial check to see if you will be affected, you can try running the\n   following query from the `psql` or `sqlite3` console. It is safe to run it\n   while Synapse is still running.\n\n   .. code:: sql\n\n      SELECT MAX(q.v) FROM (\n        SELECT (\n          SELECT ej.json AS v\n          FROM state_events se INNER JOIN event_json ej USING (event_id)\n          WHERE se.room_id=rooms.room_id AND se.type='m.room.create' AND se.state_key=''\n          LIMIT 1\n        ) FROM rooms WHERE rooms.room_version IS NULL\n      ) q;\n\n   This query will take about the same amount of time as the upgrade process: ie,\n   if it takes 5 minutes, then it is likely that Synapse will be unresponsive for\n   5 minutes during the upgrade.\n\n   If you consider an outage of this duration to be acceptable, no further\n   action is necessary and you can simply start Synapse 1.12.0.\n\n   If you would prefer to reduce the downtime, continue with the steps below.\n\n2. The easiest workaround for this issue is to manually\n   create a new index before upgrading. On PostgreSQL, his can be done as follows:\n\n   .. code:: sql\n\n      CREATE INDEX CONCURRENTLY tmp_upgrade_1_12_0_index\n      ON state_events(room_id) WHERE type = 'm.room.create';\n\n   The above query may take some time, but is also safe to run while Synapse is\n   running.\n\n   We assume that no SQLite users have databases large enough to be\n   affected. If you *are* affected, you can run a similar query, omitting the\n   ``CONCURRENTLY`` keyword. Note however that this operation may in itself cause\n   Synapse to stop running for some time. Synapse admins are reminded that\n   `SQLite is not recommended for use outside a test\n   environment <https://github.com/matrix-org/synapse/blob/master/README.rst#using-postgresql>`_.\n\n3. Once the index has been created, the ``SELECT`` query in step 1 above should\n   complete quickly. It is therefore safe to upgrade to Synapse 1.12.0.\n\n4. Once Synapse 1.12.0 has successfully started and is responding to HTTP\n   requests, the temporary index can be removed:\n\n   .. code:: sql\n\n      DROP INDEX tmp_upgrade_1_12_0_index;\n\nUpgrading to v1.10.0\n====================\n\nSynapse will now log a warning on start up if used with a PostgreSQL database\nthat has a non-recommended locale set.\n\nSee `docs/postgres.md <docs/postgres.md>`_ for details.\n\n\nUpgrading to v1.8.0\n===================\n\nSpecifying a ``log_file`` config option will now cause Synapse to refuse to\nstart, and should be replaced by with the ``log_config`` option. Support for\nthe ``log_file`` option was removed in v1.3.0 and has since had no effect.\n\n\nUpgrading to v1.7.0\n===================\n\nIn an attempt to configure Synapse in a privacy preserving way, the default\nbehaviours of ``allow_public_rooms_without_auth`` and\n``allow_public_rooms_over_federation`` have been inverted. This means that by\ndefault, only authenticated users querying the Client/Server API will be able\nto query the room directory, and relatedly that the server will not share\nroom directory information with other servers over federation.\n\nIf your installation does not explicitly set these settings one way or the other\nand you want either setting to be ``true`` then it will necessary to update\nyour homeserver configuration file accordingly.\n\nFor more details on the surrounding context see our `explainer\n<https://matrix.org/blog/2019/11/09/avoiding-unwelcome-visitors-on-private-matrix-servers>`_.\n\n\nUpgrading to v1.5.0\n===================\n\nThis release includes a database migration which may take several minutes to\ncomplete if there are a large number (more than a million or so) of entries in\nthe ``devices`` table. This is only likely to a be a problem on very large\ninstallations.\n\n\nUpgrading to v1.4.0\n===================\n\nNew custom templates\n--------------------\n\nIf you have configured a custom template directory with the\n``email.template_dir`` option, be aware that there are new templates regarding\nregistration and threepid management (see below) that must be included.\n\n* ``registration.html`` and ``registration.txt``\n* ``registration_success.html`` and ``registration_failure.html``\n* ``add_threepid.html`` and  ``add_threepid.txt``\n* ``add_threepid_failure.html`` and ``add_threepid_success.html``\n\nSynapse will expect these files to exist inside the configured template\ndirectory, and **will fail to start** if they are absent.\nTo view the default templates, see `synapse/res/templates\n<https://github.com/matrix-org/synapse/tree/master/synapse/res/templates>`_.\n\n3pid verification changes\n-------------------------\n\n**Note: As of this release, users will be unable to add phone numbers or email\naddresses to their accounts, without changes to the Synapse configuration. This\nincludes adding an email address during registration.**\n\nIt is possible for a user to associate an email address or phone number\nwith their account, for a number of reasons:\n\n* for use when logging in, as an alternative to the user id.\n* in the case of email, as an alternative contact to help with account recovery.\n* in the case of email, to receive notifications of missed messages.\n\nBefore an email address or phone number can be added to a user's account,\nor before such an address is used to carry out a password-reset, Synapse must\nconfirm the operation with the owner of the email address or phone number.\nIt does this by sending an email or text giving the user a link or token to confirm\nreceipt. This process is known as '3pid verification'. ('3pid', or 'threepid',\nstands for third-party identifier, and we use it to refer to external\nidentifiers such as email addresses and phone numbers.)\n\nPrevious versions of Synapse delegated the task of 3pid verification to an\nidentity server by default. In most cases this server is ``vector.im`` or\n``matrix.org``.\n\nIn Synapse 1.4.0, for security and privacy reasons, the homeserver will no\nlonger delegate this task to an identity server by default. Instead,\nthe server administrator will need to explicitly decide how they would like the\nverification messages to be sent.\n\nIn the medium term, the ``vector.im`` and ``matrix.org`` identity servers will\ndisable support for delegated 3pid verification entirely. However, in order to\nease the transition, they will retain the capability for a limited\nperiod. Delegated email verification will be disabled on Monday 2nd December\n2019 (giving roughly 2 months notice). Disabling delegated SMS verification\nwill follow some time after that once SMS verification support lands in\nSynapse.\n\nOnce delegated 3pid verification support has been disabled in the ``vector.im`` and\n``matrix.org`` identity servers, all Synapse versions that depend on those\ninstances will be unable to verify email and phone numbers through them. There\nare no imminent plans to remove delegated 3pid verification from Sydent\ngenerally. (Sydent is the identity server project that backs the ``vector.im`` and\n``matrix.org`` instances).\n\nEmail\n~~~~~\nFollowing upgrade, to continue verifying email (e.g. as part of the\nregistration process), admins can either:-\n\n* Configure Synapse to use an email server.\n* Run or choose an identity server which allows delegated email verification\n  and delegate to it.\n\nConfigure SMTP in Synapse\n+++++++++++++++++++++++++\n\nTo configure an SMTP server for Synapse, modify the configuration section\nheaded ``email``, and be sure to have at least the ``smtp_host, smtp_port``\nand ``notif_from`` fields filled out.\n\nYou may also need to set ``smtp_user``, ``smtp_pass``, and\n``require_transport_security``.\n\nSee the `sample configuration file <docs/sample_config.yaml>`_ for more details\non these settings.\n\nDelegate email to an identity server\n++++++++++++++++++++++++++++++++++++\n\nSome admins will wish to continue using email verification as part of the\nregistration process, but will not immediately have an appropriate SMTP server\nat hand.\n\nTo this end, we will continue to support email verification delegation via the\n``vector.im`` and ``matrix.org`` identity servers for two months. Support for\ndelegated email verification will be disabled on Monday 2nd December.\n\nThe ``account_threepid_delegates`` dictionary defines whether the homeserver\nshould delegate an external server (typically an `identity server\n<https://matrix.org/docs/spec/identity_service/r0.2.1>`_) to handle sending\nconfirmation messages via email and SMS.\n\nSo to delegate email verification, in ``homeserver.yaml``, set\n``account_threepid_delegates.email`` to the base URL of an identity server. For\nexample:\n\n.. code:: yaml\n\n   account_threepid_delegates:\n       email: https://example.com     # Delegate email sending to example.com\n\nNote that ``account_threepid_delegates.email`` replaces the deprecated\n``email.trust_identity_server_for_password_resets``: if\n``email.trust_identity_server_for_password_resets`` is set to ``true``, and\n``account_threepid_delegates.email`` is not set, then the first entry in\n``trusted_third_party_id_servers`` will be used as the\n``account_threepid_delegate`` for email. This is to ensure compatibility with\nexisting Synapse installs that set up external server handling for these tasks\nbefore v1.4.0. If ``email.trust_identity_server_for_password_resets`` is\n``true`` and no trusted identity server domains are configured, Synapse will\nreport an error and refuse to start.\n\nIf ``email.trust_identity_server_for_password_resets`` is ``false`` or absent\nand no ``email`` delegate is configured in ``account_threepid_delegates``,\nthen Synapse will send email verification messages itself, using the configured\nSMTP server (see above).\nthat type.\n\nPhone numbers\n~~~~~~~~~~~~~\n\nSynapse does not support phone-number verification itself, so the only way to\nmaintain the ability for users to add phone numbers to their accounts will be\nby continuing to delegate phone number verification to the ``matrix.org`` and\n``vector.im`` identity servers (or another identity server that supports SMS\nsending).\n\nThe ``account_threepid_delegates`` dictionary defines whether the homeserver\nshould delegate an external server (typically an `identity server\n<https://matrix.org/docs/spec/identity_service/r0.2.1>`_) to handle sending\nconfirmation messages via email and SMS.\n\nSo to delegate phone number verification, in ``homeserver.yaml``, set\n``account_threepid_delegates.msisdn`` to the base URL of an identity\nserver. For example:\n\n.. code:: yaml\n\n   account_threepid_delegates:\n       msisdn: https://example.com     # Delegate sms sending to example.com\n\nThe ``matrix.org`` and ``vector.im`` identity servers will continue to support\ndelegated phone number verification via SMS until such time as it is possible\nfor admins to configure their servers to perform phone number verification\ndirectly. More details will follow in a future release.\n\nRolling back to v1.3.1\n----------------------\n\nIf you encounter problems with v1.4.0, it should be possible to roll back to\nv1.3.1, subject to the following:\n\n* The 'room statistics' engine was heavily reworked in this release (see\n  `#5971 <https://github.com/matrix-org/synapse/pull/5971>`_), including\n  significant changes to the database schema, which are not easily\n  reverted. This will cause the room statistics engine to stop updating when\n  you downgrade.\n\n  The room statistics are essentially unused in v1.3.1 (in future versions of\n  Synapse, they will be used to populate the room directory), so there should\n  be no loss of functionality. However, the statistics engine will write errors\n  to the logs, which can be avoided by setting the following in\n  `homeserver.yaml`:\n\n  .. code:: yaml\n\n    stats:\n      enabled: false\n\n  Don't forget to re-enable it when you upgrade again, in preparation for its\n  use in the room directory!\n\nUpgrading to v1.2.0\n===================\n\nSome counter metrics have been renamed, with the old names deprecated. See\n`the metrics documentation <docs/metrics-howto.md#renaming-of-metrics--deprecation-of-old-names-in-12>`_\nfor details.\n\nUpgrading to v1.1.0\n===================\n\nSynapse v1.1.0 removes support for older Python and PostgreSQL versions, as\noutlined in `our deprecation notice <https://matrix.org/blog/2019/04/08/synapse-deprecating-postgres-9-4-and-python-2-x>`_.\n\nMinimum Python Version\n----------------------\n\nSynapse v1.1.0 has a minimum Python requirement of Python 3.5. Python 3.6 or\nPython 3.7 are recommended as they have improved internal string handling,\nsignificantly reducing memory usage.\n\nIf you use current versions of the Matrix.org-distributed Debian packages or\nDocker images, action is not required.\n\nIf you install Synapse in a Python virtual environment, please see \"Upgrading to\nv0.34.0\" for notes on setting up a new virtualenv under Python 3.\n\nMinimum PostgreSQL Version\n--------------------------\n\nIf using PostgreSQL under Synapse, you will need to use PostgreSQL 9.5 or above.\nPlease see the\n`PostgreSQL documentation <https://www.postgresql.org/docs/11/upgrading.html>`_\nfor more details on upgrading your database.\n\nUpgrading to v1.0\n=================\n\nValidation of TLS certificates\n------------------------------\n\nSynapse v1.0 is the first release to enforce\nvalidation of TLS certificates for the federation API. It is therefore\nessential that your certificates are correctly configured. See the `FAQ\n<docs/MSC1711_certificates_FAQ.md>`_ for more information.\n\nNote, v1.0 installations will also no longer be able to federate with servers\nthat have not correctly configured their certificates.\n\nIn rare cases, it may be desirable to disable certificate checking: for\nexample, it might be essential to be able to federate with a given legacy\nserver in a closed federation. This can be done in one of two ways:-\n\n* Configure the global switch ``federation_verify_certificates`` to ``false``.\n* Configure a whitelist of server domains to trust via ``federation_certificate_verification_whitelist``.\n\nSee the `sample configuration file <docs/sample_config.yaml>`_\nfor more details on these settings.\n\nEmail\n-----\nWhen a user requests a password reset, Synapse will send an email to the\nuser to confirm the request.\n\nPrevious versions of Synapse delegated the job of sending this email to an\nidentity server. If the identity server was somehow malicious or became\ncompromised, it would be theoretically possible to hijack an account through\nthis means.\n\nTherefore, by default, Synapse v1.0 will send the confirmation email itself. If\nSynapse is not configured with an SMTP server, password reset via email will be\ndisabled.\n\nTo configure an SMTP server for Synapse, modify the configuration section\nheaded ``email``, and be sure to have at least the ``smtp_host``, ``smtp_port``\nand ``notif_from`` fields filled out. You may also need to set ``smtp_user``,\n``smtp_pass``, and ``require_transport_security``.\n\nIf you are absolutely certain that you wish to continue using an identity\nserver for password resets, set ``trust_identity_server_for_password_resets`` to ``true``.\n\nSee the `sample configuration file <docs/sample_config.yaml>`_\nfor more details on these settings.\n\nNew email templates\n---------------\nSome new templates have been added to the default template directory for the purpose of the\nhomeserver sending its own password reset emails. If you have configured a custom\n``template_dir`` in your Synapse config, these files will need to be added.\n\n``password_reset.html`` and ``password_reset.txt`` are HTML and plain text templates\nrespectively that contain the contents of what will be emailed to the user upon attempting to\nreset their password via email. ``password_reset_success.html`` and\n``password_reset_failure.html`` are HTML files that the content of which (assuming no redirect\nURL is set) will be shown to the user after they attempt to click the link in the email sent\nto them.\n\nUpgrading to v0.99.0\n====================\n\nPlease be aware that, before Synapse v1.0 is released around March 2019, you\nwill need to replace any self-signed certificates with those verified by a\nroot CA. Information on how to do so can be found at `the ACME docs\n<docs/ACME.md>`_.\n\nFor more information on configuring TLS certificates see the `FAQ <docs/MSC1711_certificates_FAQ.md>`_.\n\nUpgrading to v0.34.0\n====================\n\n1. This release is the first to fully support Python 3. Synapse will now run on\n   Python versions 3.5, or 3.6 (as well as 2.7). We recommend switching to\n   Python 3, as it has been shown to give performance improvements.\n\n   For users who have installed Synapse into a virtualenv, we recommend doing\n   this by creating a new virtualenv. For example::\n\n       virtualenv -p python3 ~/synapse/env3\n       source ~/synapse/env3/bin/activate\n       pip install matrix-synapse\n\n   You can then start synapse as normal, having activated the new virtualenv::\n\n       cd ~/synapse\n       source env3/bin/activate\n       synctl start\n\n   Users who have installed from distribution packages should see the relevant\n   package documentation. See below for notes on Debian packages.\n\n   * When upgrading to Python 3, you **must** make sure that your log files are\n     configured as UTF-8, by adding ``encoding: utf8`` to the\n     ``RotatingFileHandler`` configuration (if you have one) in your\n     ``<server>.log.config`` file. For example, if your ``log.config`` file\n     contains::\n\n       handlers:\n         file:\n           class: logging.handlers.RotatingFileHandler\n           formatter: precise\n           filename: homeserver.log\n           maxBytes: 104857600\n           backupCount: 10\n           filters: [context]\n         console:\n           class: logging.StreamHandler\n           formatter: precise\n           filters: [context]\n\n     Then you should update this to be::\n\n       handlers:\n         file:\n           class: logging.handlers.RotatingFileHandler\n           formatter: precise\n           filename: homeserver.log\n           maxBytes: 104857600\n           backupCount: 10\n           filters: [context]\n           encoding: utf8\n         console:\n           class: logging.StreamHandler\n           formatter: precise\n           filters: [context]\n\n     There is no need to revert this change if downgrading to Python 2.\n\n   We are also making available Debian packages which will run Synapse on\n   Python 3. You can switch to these packages with ``apt-get install\n   matrix-synapse-py3``, however, please read `debian/NEWS\n   <https://github.com/matrix-org/synapse/blob/release-v0.34.0/debian/NEWS>`_\n   before doing so. The existing ``matrix-synapse`` packages will continue to\n   use Python 2 for the time being.\n\n2. This release removes the ``riot.im`` from the default list of trusted\n   identity servers.\n\n   If ``riot.im`` is in your homeserver's list of\n   ``trusted_third_party_id_servers``, you should remove it. It was added in\n   case a hypothetical future identity server was put there. If you don't\n   remove it, users may be unable to deactivate their accounts.\n\n3. This release no longer installs the (unmaintained) Matrix Console web client\n   as part of the default installation. It is possible to re-enable it by\n   installing it separately and setting the ``web_client_location`` config\n   option, but please consider switching to another client.\n\nUpgrading to v0.33.7\n====================\n\nThis release removes the example email notification templates from\n``res/templates`` (they are now internal to the python package). This should\nonly affect you if you (a) deploy your Synapse instance from a git checkout or\na github snapshot URL, and (b) have email notifications enabled.\n\nIf you have email notifications enabled, you should ensure that\n``email.template_dir`` is either configured to point at a directory where you\nhave installed customised templates, or leave it unset to use the default\ntemplates.\n\nUpgrading to v0.27.3\n====================\n\nThis release expands the anonymous usage stats sent if the opt-in\n``report_stats`` configuration is set to ``true``. We now capture RSS memory\nand cpu use at a very coarse level. This requires administrators to install\nthe optional ``psutil`` python module.\n\nWe would appreciate it if you could assist by ensuring this module is available\nand ``report_stats`` is enabled. This will let us see if performance changes to\nsynapse are having an impact to the general community.\n\nUpgrading to v0.15.0\n====================\n\nIf you want to use the new URL previewing API (/_matrix/media/r0/preview_url)\nthen you have to explicitly enable it in the config and update your dependencies\ndependencies.  See README.rst for details.\n\n\nUpgrading to v0.11.0\n====================\n\nThis release includes the option to send anonymous usage stats to matrix.org,\nand requires that administrators explictly opt in or out by setting the\n``report_stats`` option to either ``true`` or ``false``.\n\nWe would really appreciate it if you could help our project out by reporting\nanonymized usage statistics from your homeserver. Only very basic aggregate\ndata (e.g. number of users) will be reported, but it helps us to track the\ngrowth of the Matrix community, and helps us to make Matrix a success, as well\nas to convince other networks that they should peer with us.\n\n\nUpgrading to v0.9.0\n===================\n\nApplication services have had a breaking API change in this version.\n\nThey can no longer register themselves with a home server using the AS HTTP API. This\ndecision was made because a compromised application service with free reign to register\nany regex in effect grants full read/write access to the home server if a regex of ``.*``\nis used. An attack where a compromised AS re-registers itself with ``.*`` was deemed too\nbig of a security risk to ignore, and so the ability to register with the HS remotely has\nbeen removed.\n\nIt has been replaced by specifying a list of application service registrations in\n``homeserver.yaml``::\n\n  app_service_config_files: [\"registration-01.yaml\", \"registration-02.yaml\"]\n\nWhere ``registration-01.yaml`` looks like::\n\n  url: <String>  # e.g. \"https://my.application.service.com\"\n  as_token: <String>\n  hs_token: <String>\n  sender_localpart: <String>  # This is a new field which denotes the user_id localpart when using the AS token\n  namespaces:\n    users:\n      - exclusive: <Boolean>\n        regex: <String>  # e.g. \"@prefix_.*\"\n    aliases:\n      - exclusive: <Boolean>\n        regex: <String>\n    rooms:\n      - exclusive: <Boolean>\n        regex: <String>\n\nUpgrading to v0.8.0\n===================\n\nServers which use captchas will need to add their public key to::\n\n  static/client/register/register_config.js\n\n    window.matrixRegistrationConfig = {\n        recaptcha_public_key: \"YOUR_PUBLIC_KEY\"\n    };\n\nThis is required in order to support registration fallback (typically used on\nmobile devices).\n\n\nUpgrading to v0.7.0\n===================\n\nNew dependencies are:\n\n- pydenticon\n- simplejson\n- syutil\n- matrix-angular-sdk\n\nTo pull in these dependencies in a virtual env, run::\n\n    python synapse/python_dependencies.py | xargs -n 1 pip install\n\nUpgrading to v0.6.0\n===================\n\nTo pull in new dependencies, run::\n\n    python setup.py develop --user\n\nThis update includes a change to the database schema. To upgrade you first need\nto upgrade the database by running::\n\n    python scripts/upgrade_db_to_v0.6.0.py <db> <server_name> <signing_key>\n\nWhere `<db>` is the location of the database, `<server_name>` is the\nserver name as specified in the synapse configuration, and `<signing_key>` is\nthe location of the signing key as specified in the synapse configuration.\n\nThis may take some time to complete. Failures of signatures and content hashes\ncan safely be ignored.\n\n\nUpgrading to v0.5.1\n===================\n\nDepending on precisely when you installed v0.5.0 you may have ended up with\na stale release of the reference matrix webclient installed as a python module.\nTo uninstall it and ensure you are depending on the latest module, please run::\n\n    $ pip uninstall syweb\n\nUpgrading to v0.5.0\n===================\n\nThe webclient has been split out into a seperate repository/pacakage in this\nrelease. Before you restart your homeserver you will need to pull in the\nwebclient package by running::\n\n  python setup.py develop --user\n\nThis release completely changes the database schema and so requires upgrading\nit before starting the new version of the homeserver.\n\nThe script \"database-prepare-for-0.5.0.sh\" should be used to upgrade the\ndatabase. This will save all user information, such as logins and profiles,\nbut will otherwise purge the database. This includes messages, which\nrooms the home server was a member of and room alias mappings.\n\nIf you would like to keep your history, please take a copy of your database\nfile and ask for help in #matrix:matrix.org. The upgrade process is,\nunfortunately, non trivial and requires human intervention to resolve any\nresulting conflicts during the upgrade process.\n\nBefore running the command the homeserver should be first completely\nshutdown. To run it, simply specify the location of the database, e.g.:\n\n  ./scripts/database-prepare-for-0.5.0.sh \"homeserver.db\"\n\nOnce this has successfully completed it will be safe to restart the\nhomeserver. You may notice that the homeserver takes a few seconds longer to\nrestart than usual as it reinitializes the database.\n\nOn startup of the new version, users can either rejoin remote rooms using room\naliases or by being reinvited. Alternatively, if any other homeserver sends a\nmessage to a room that the homeserver was previously in the local HS will\nautomatically rejoin the room.\n\nUpgrading to v0.4.0\n===================\n\nThis release needs an updated syutil version. Run::\n\n    python setup.py develop\n\nYou will also need to upgrade your configuration as the signing key format has\nchanged. Run::\n\n    python -m synapse.app.homeserver --config-path <CONFIG> --generate-config\n\n\nUpgrading to v0.3.0\n===================\n\nThis registration API now closely matches the login API. This introduces a bit\nmore backwards and forwards between the HS and the client, but this improves\nthe overall flexibility of the API. You can now GET on /register to retrieve a list\nof valid registration flows. Upon choosing one, they are submitted in the same\nway as login, e.g::\n\n  {\n    type: m.login.password,\n    user: foo,\n    password: bar\n  }\n\nThe default HS supports 2 flows, with and without Identity Server email\nauthentication. Enabling captcha on the HS will add in an extra step to all\nflows: ``m.login.recaptcha`` which must be completed before you can transition\nto the next stage. There is a new login type: ``m.login.email.identity`` which\ncontains the ``threepidCreds`` key which were previously sent in the original\nregister request. For more information on this, see the specification.\n\nWeb Client\n----------\n\nThe VoIP specification has changed between v0.2.0 and v0.3.0. Users should\nrefresh any browser tabs to get the latest web client code. Users on\nv0.2.0 of the web client will not be able to call those on v0.3.0 and\nvice versa.\n\n\nUpgrading to v0.2.0\n===================\n\nThe home server now requires setting up of SSL config before it can run. To\nautomatically generate default config use::\n\n    $ python synapse/app/homeserver.py \\\n        --server-name machine.my.domain.name \\\n        --bind-port 8448 \\\n        --config-path homeserver.config \\\n        --generate-config\n\nThis config can be edited if desired, for example to specify a different SSL\ncertificate to use. Once done you can run the home server using::\n\n    $ python synapse/app/homeserver.py --config-path homeserver.config\n\nSee the README.rst for more information.\n\nAlso note that some config options have been renamed, including:\n\n- \"host\" to \"server-name\"\n- \"database\" to \"database-path\"\n- \"port\" to \"bind-port\" and \"unsecure-port\"\n\n\nUpgrading to v0.0.1\n===================\n\nThis release completely changes the database schema and so requires upgrading\nit before starting the new version of the homeserver.\n\nThe script \"database-prepare-for-0.0.1.sh\" should be used to upgrade the\ndatabase. This will save all user information, such as logins and profiles,\nbut will otherwise purge the database. This includes messages, which\nrooms the home server was a member of and room alias mappings.\n\nBefore running the command the homeserver should be first completely\nshutdown. To run it, simply specify the location of the database, e.g.:\n\n  ./scripts/database-prepare-for-0.0.1.sh \"homeserver.db\"\n\nOnce this has successfully completed it will be safe to restart the\nhomeserver. You may notice that the homeserver takes a few seconds longer to\nrestart than usual as it reinitializes the database.\n\nOn startup of the new version, users can either rejoin remote rooms using room\naliases or by being reinvited. Alternatively, if any other homeserver sends a\nmessage to a room that the homeserver was previously in the local HS will\nautomatically rejoin the room.\n", "code_before": "Upgrading Synapse\n=================\n\nBefore upgrading check if any special steps are required to upgrade from the\nversion you currently have installed to the current version of Synapse. The extra\ninstructions that may be required are listed later in this document.\n\n* Check that your versions of Python and PostgreSQL are still supported.\n\n  Synapse follows upstream lifecycles for `Python`_ and `PostgreSQL`_, and\n  removes support for versions which are no longer maintained.\n\n  The website https://endoflife.date also offers convenient summaries.\n\n  .. _Python: https://devguide.python.org/devcycle/#end-of-life-branches\n  .. _PostgreSQL: https://www.postgresql.org/support/versioning/\n\n* If Synapse was installed using `prebuilt packages\n  <INSTALL.md#prebuilt-packages>`_, you will need to follow the normal process\n  for upgrading those packages.\n\n* If Synapse was installed from source, then:\n\n  1. Activate the virtualenv before upgrading. For example, if Synapse is\n     installed in a virtualenv in ``~/synapse/env`` then run:\n\n     .. code:: bash\n\n       source ~/synapse/env/bin/activate\n\n  2. If Synapse was installed using pip then upgrade to the latest version by\n     running:\n\n     .. code:: bash\n\n       pip install --upgrade matrix-synapse\n\n     If Synapse was installed using git then upgrade to the latest version by\n     running:\n\n     .. code:: bash\n\n       git pull\n       pip install --upgrade .\n\n  3. Restart Synapse:\n\n     .. code:: bash\n\n       ./synctl restart\n\nTo check whether your update was successful, you can check the running server\nversion with:\n\n.. code:: bash\n\n    # you may need to replace 'localhost:8008' if synapse is not configured\n    # to listen on port 8008.\n\n    curl http://localhost:8008/_synapse/admin/v1/server_version\n\nRolling back to older versions\n------------------------------\n\nRolling back to previous releases can be difficult, due to database schema\nchanges between releases. Where we have been able to test the rollback process,\nthis will be noted below.\n\nIn general, you will need to undo any changes made during the upgrade process,\nfor example:\n\n* pip:\n\n  .. code:: bash\n\n     source env/bin/activate\n     # replace `1.3.0` accordingly:\n     pip install matrix-synapse==1.3.0\n\n* Debian:\n\n  .. code:: bash\n\n     # replace `1.3.0` and `stretch` accordingly:\n     wget https://packages.matrix.org/debian/pool/main/m/matrix-synapse-py3/matrix-synapse-py3_1.3.0+stretch1_amd64.deb\n     dpkg -i matrix-synapse-py3_1.3.0+stretch1_amd64.deb\n\nUpgrading to v1.26.0\n====================\n\nRolling back to v1.25.0 after a failed upgrade\n----------------------------------------------\n\nv1.26.0 includes a lot of large changes. If something problematic occurs, you\nmay want to roll-back to a previous version of Synapse. Because v1.26.0 also\nincludes a new database schema version, reverting that version is also required\nalongside the generic rollback instructions mentioned above. In short, to roll\nback to v1.25.0 you need to:\n\n1. Stop the server\n2. Decrease the schema version in the database:\n\n   .. code:: sql\n\n      UPDATE schema_version SET version = 58;\n\n3. Delete the ignored users & chain cover data:\n\n   .. code:: sql\n\n      DROP TABLE IF EXISTS ignored_users;\n      UPDATE rooms SET has_auth_chain_index = false;\n\n   For PostgreSQL run:\n\n   .. code:: sql\n\n      TRUNCATE event_auth_chain_links;\n      TRUNCATE event_auth_chains;\n\n   For SQLite run:\n\n   .. code:: sql\n\n      DELETE FROM event_auth_chain_links;\n      DELETE FROM event_auth_chains;\n\n4. Mark the deltas as not run (so they will re-run on upgrade).\n\n   .. code:: sql\n\n      DELETE FROM applied_schema_deltas WHERE version = 59 AND file = \"59/01ignored_user.py\";\n      DELETE FROM applied_schema_deltas WHERE version = 59 AND file = \"59/06chain_cover_index.sql\";\n\n5. Downgrade Synapse by following the instructions for your installation method\n   in the \"Rolling back to older versions\" section above.\n\nUpgrading to v1.25.0\n====================\n\nLast release supporting Python 3.5\n----------------------------------\n\nThis is the last release of Synapse which guarantees support with Python 3.5,\nwhich passed its upstream End of Life date several months ago.\n\nWe will attempt to maintain support through March 2021, but without guarantees.\n\nIn the future, Synapse will follow upstream schedules for ending support of\nolder versions of Python and PostgreSQL. Please upgrade to at least Python 3.6\nand PostgreSQL 9.6 as soon as possible.\n\nBlacklisting IP ranges\n----------------------\n\nSynapse v1.25.0 includes new settings, ``ip_range_blacklist`` and\n``ip_range_whitelist``, for controlling outgoing requests from Synapse for federation,\nidentity servers, push, and for checking key validity for third-party invite events.\nThe previous setting, ``federation_ip_range_blacklist``, is deprecated. The new\n``ip_range_blacklist`` defaults to private IP ranges if it is not defined.\n\nIf you have never customised ``federation_ip_range_blacklist`` it is recommended\nthat you remove that setting.\n\nIf you have customised ``federation_ip_range_blacklist`` you should update the\nsetting name to ``ip_range_blacklist``.\n\nIf you have a custom push server that is reached via private IP space you may\nneed to customise ``ip_range_blacklist`` or ``ip_range_whitelist``.\n\nUpgrading to v1.24.0\n====================\n\nCustom OpenID Connect mapping provider breaking change\n------------------------------------------------------\n\nThis release allows the OpenID Connect mapping provider to perform normalisation\nof the localpart of the Matrix ID. This allows for the mapping provider to\nspecify different algorithms, instead of the [default way](https://matrix.org/docs/spec/appendices#mapping-from-other-character-sets).\n\nIf your Synapse configuration uses a custom mapping provider\n(`oidc_config.user_mapping_provider.module` is specified and not equal to\n`synapse.handlers.oidc_handler.JinjaOidcMappingProvider`) then you *must* ensure\nthat `map_user_attributes` of the mapping provider performs some normalisation\nof the `localpart` returned. To match previous behaviour you can use the\n`map_username_to_mxid_localpart` function provided by Synapse. An example is\nshown below:\n\n.. code-block:: python\n\n  from synapse.types import map_username_to_mxid_localpart\n\n  class MyMappingProvider:\n      def map_user_attributes(self, userinfo, token):\n          # ... your custom logic ...\n          sso_user_id = ...\n          localpart = map_username_to_mxid_localpart(sso_user_id)\n\n          return {\"localpart\": localpart}\n\nRemoval historical Synapse Admin API \n------------------------------------\n\nHistorically, the Synapse Admin API has been accessible under:\n\n* ``/_matrix/client/api/v1/admin``\n* ``/_matrix/client/unstable/admin``\n* ``/_matrix/client/r0/admin``\n* ``/_synapse/admin/v1``\n\nThe endpoints with ``/_matrix/client/*`` prefixes have been removed as of v1.24.0.\nThe Admin API is now only accessible under:\n\n* ``/_synapse/admin/v1``\n\nThe only exception is the `/admin/whois` endpoint, which is\n`also available via the client-server API <https://matrix.org/docs/spec/client_server/r0.6.1#get-matrix-client-r0-admin-whois-userid>`_.\n\nThe deprecation of the old endpoints was announced with Synapse 1.20.0 (released\non 2020-09-22) and makes it easier for homeserver admins to lock down external\naccess to the Admin API endpoints.\n\nUpgrading to v1.23.0\n====================\n\nStructured logging configuration breaking changes\n-------------------------------------------------\n\nThis release deprecates use of the ``structured: true`` logging configuration for\nstructured logging. If your logging configuration contains ``structured: true``\nthen it should be modified based on the `structured logging documentation\n<https://github.com/matrix-org/synapse/blob/master/docs/structured_logging.md>`_.\n\nThe ``structured`` and ``drains`` logging options are now deprecated and should\nbe replaced by standard logging configuration of ``handlers`` and ``formatters``.\n\nA future will release of Synapse will make using ``structured: true`` an error.\n\nUpgrading to v1.22.0\n====================\n\nThirdPartyEventRules breaking changes\n-------------------------------------\n\nThis release introduces a backwards-incompatible change to modules making use of\n``ThirdPartyEventRules`` in Synapse. If you make use of a module defined under the\n``third_party_event_rules`` config option, please make sure it is updated to handle\nthe below change:\n\nThe ``http_client`` argument is no longer passed to modules as they are initialised. Instead,\nmodules are expected to make use of the ``http_client`` property on the ``ModuleApi`` class.\nModules are now passed a ``module_api`` argument during initialisation, which is an instance of\n``ModuleApi``. ``ModuleApi`` instances have a ``http_client`` property which acts the same as\nthe ``http_client`` argument previously passed to ``ThirdPartyEventRules`` modules.\n\nUpgrading to v1.21.0\n====================\n\nForwarding ``/_synapse/client`` through your reverse proxy\n----------------------------------------------------------\n\nThe `reverse proxy documentation\n<https://github.com/matrix-org/synapse/blob/develop/docs/reverse_proxy.md>`_ has been updated\nto include reverse proxy directives for ``/_synapse/client/*`` endpoints. As the user password\nreset flow now uses endpoints under this prefix, **you must update your reverse proxy\nconfigurations for user password reset to work**.\n\nAdditionally, note that the `Synapse worker documentation\n<https://github.com/matrix-org/synapse/blob/develop/docs/workers.md>`_ has been updated to\n state that the ``/_synapse/client/password_reset/email/submit_token`` endpoint can be handled\nby all workers. If you make use of Synapse's worker feature, please update your reverse proxy\nconfiguration to reflect this change.\n\nNew HTML templates\n------------------\n\nA new HTML template,\n`password_reset_confirmation.html <https://github.com/matrix-org/synapse/blob/develop/synapse/res/templates/password_reset_confirmation.html>`_,\nhas been added to the ``synapse/res/templates`` directory. If you are using a\ncustom template directory, you may want to copy the template over and modify it.\n\nNote that as of v1.20.0, templates do not need to be included in custom template\ndirectories for Synapse to start. The default templates will be used if a custom\ntemplate cannot be found.\n\nThis page will appear to the user after clicking a password reset link that has\nbeen emailed to them.\n\nTo complete password reset, the page must include a way to make a `POST`\nrequest to\n``/_synapse/client/password_reset/{medium}/submit_token``\nwith the query parameters from the original link, presented as a URL-encoded form. See the file\nitself for more details.\n\nUpdated Single Sign-on HTML Templates\n-------------------------------------\n\nThe ``saml_error.html`` template was removed from Synapse and replaced with the\n``sso_error.html`` template. If your Synapse is configured to use SAML and a\ncustom ``sso_redirect_confirm_template_dir`` configuration then any customisations\nof the ``saml_error.html`` template will need to be merged into the ``sso_error.html``\ntemplate. These templates are similar, but the parameters are slightly different:\n\n* The ``msg`` parameter should be renamed to ``error_description``.\n* There is no longer a ``code`` parameter for the response code.\n* A string ``error`` parameter is available that includes a short hint of why a\n  user is seeing the error page.\n\nUpgrading to v1.18.0\n====================\n\nDocker `-py3` suffix will be removed in future versions\n-------------------------------------------------------\n\nFrom 10th August 2020, we will no longer publish Docker images with the `-py3` tag suffix. The images tagged with the `-py3` suffix have been identical to the non-suffixed tags since release 0.99.0, and the suffix is obsolete.\n\nOn 10th August, we will remove the `latest-py3` tag. Existing per-release tags (such as `v1.18.0-py3`) will not be removed, but no new `-py3` tags will be added.\n\nScripts relying on the `-py3` suffix will need to be updated.\n\nRedis replication is now recommended in lieu of TCP replication\n---------------------------------------------------------------\n\nWhen setting up worker processes, we now recommend the use of a Redis server for replication. **The old direct TCP connection method is deprecated and will be removed in a future release.**\nSee `docs/workers.md <docs/workers.md>`_ for more details.\n\nUpgrading to v1.14.0\n====================\n\nThis version includes a database update which is run as part of the upgrade,\nand which may take a couple of minutes in the case of a large server. Synapse\nwill not respond to HTTP requests while this update is taking place.\n\nUpgrading to v1.13.0\n====================\n\nIncorrect database migration in old synapse versions\n----------------------------------------------------\n\nA bug was introduced in Synapse 1.4.0 which could cause the room directory to\nbe incomplete or empty if Synapse was upgraded directly from v1.2.1 or\nearlier, to versions between v1.4.0 and v1.12.x.\n\nThis will *not* be a problem for Synapse installations which were:\n * created at v1.4.0 or later,\n * upgraded via v1.3.x, or\n * upgraded straight from v1.2.1 or earlier to v1.13.0 or later.\n\nIf completeness of the room directory is a concern, installations which are\naffected can be repaired as follows:\n\n1. Run the following sql from a `psql` or `sqlite3` console:\n\n   .. code:: sql\n\n     INSERT INTO background_updates (update_name, progress_json, depends_on) VALUES\n        ('populate_stats_process_rooms', '{}', 'current_state_events_membership');\n\n     INSERT INTO background_updates (update_name, progress_json, depends_on) VALUES\n        ('populate_stats_process_users', '{}', 'populate_stats_process_rooms');\n\n2. Restart synapse.\n\nNew Single Sign-on HTML Templates\n---------------------------------\n\nNew templates (``sso_auth_confirm.html``, ``sso_auth_success.html``, and\n``sso_account_deactivated.html``) were added to Synapse. If your Synapse is\nconfigured to use SSO and a custom  ``sso_redirect_confirm_template_dir``\nconfiguration then these templates will need to be copied from\n`synapse/res/templates <synapse/res/templates>`_ into that directory.\n\nSynapse SSO Plugins Method Deprecation\n--------------------------------------\n\nPlugins using the ``complete_sso_login`` method of\n``synapse.module_api.ModuleApi`` should update to using the async/await\nversion ``complete_sso_login_async`` which includes additional checks. The\nnon-async version is considered deprecated.\n\nRolling back to v1.12.4 after a failed upgrade\n----------------------------------------------\n\nv1.13.0 includes a lot of large changes. If something problematic occurs, you\nmay want to roll-back to a previous version of Synapse. Because v1.13.0 also\nincludes a new database schema version, reverting that version is also required\nalongside the generic rollback instructions mentioned above. In short, to roll\nback to v1.12.4 you need to:\n\n1. Stop the server\n2. Decrease the schema version in the database:\n\n   .. code:: sql\n\n      UPDATE schema_version SET version = 57;\n\n3. Downgrade Synapse by following the instructions for your installation method\n   in the \"Rolling back to older versions\" section above.\n\n\nUpgrading to v1.12.0\n====================\n\nThis version includes a database update which is run as part of the upgrade,\nand which may take some time (several hours in the case of a large\nserver). Synapse will not respond to HTTP requests while this update is taking\nplace.\n\nThis is only likely to be a problem in the case of a server which is\nparticipating in many rooms.\n\n0. As with all upgrades, it is recommended that you have a recent backup of\n   your database which can be used for recovery in the event of any problems.\n\n1. As an initial check to see if you will be affected, you can try running the\n   following query from the `psql` or `sqlite3` console. It is safe to run it\n   while Synapse is still running.\n\n   .. code:: sql\n\n      SELECT MAX(q.v) FROM (\n        SELECT (\n          SELECT ej.json AS v\n          FROM state_events se INNER JOIN event_json ej USING (event_id)\n          WHERE se.room_id=rooms.room_id AND se.type='m.room.create' AND se.state_key=''\n          LIMIT 1\n        ) FROM rooms WHERE rooms.room_version IS NULL\n      ) q;\n\n   This query will take about the same amount of time as the upgrade process: ie,\n   if it takes 5 minutes, then it is likely that Synapse will be unresponsive for\n   5 minutes during the upgrade.\n\n   If you consider an outage of this duration to be acceptable, no further\n   action is necessary and you can simply start Synapse 1.12.0.\n\n   If you would prefer to reduce the downtime, continue with the steps below.\n\n2. The easiest workaround for this issue is to manually\n   create a new index before upgrading. On PostgreSQL, his can be done as follows:\n\n   .. code:: sql\n\n      CREATE INDEX CONCURRENTLY tmp_upgrade_1_12_0_index\n      ON state_events(room_id) WHERE type = 'm.room.create';\n\n   The above query may take some time, but is also safe to run while Synapse is\n   running.\n\n   We assume that no SQLite users have databases large enough to be\n   affected. If you *are* affected, you can run a similar query, omitting the\n   ``CONCURRENTLY`` keyword. Note however that this operation may in itself cause\n   Synapse to stop running for some time. Synapse admins are reminded that\n   `SQLite is not recommended for use outside a test\n   environment <https://github.com/matrix-org/synapse/blob/master/README.rst#using-postgresql>`_.\n\n3. Once the index has been created, the ``SELECT`` query in step 1 above should\n   complete quickly. It is therefore safe to upgrade to Synapse 1.12.0.\n\n4. Once Synapse 1.12.0 has successfully started and is responding to HTTP\n   requests, the temporary index can be removed:\n\n   .. code:: sql\n\n      DROP INDEX tmp_upgrade_1_12_0_index;\n\nUpgrading to v1.10.0\n====================\n\nSynapse will now log a warning on start up if used with a PostgreSQL database\nthat has a non-recommended locale set.\n\nSee `docs/postgres.md <docs/postgres.md>`_ for details.\n\n\nUpgrading to v1.8.0\n===================\n\nSpecifying a ``log_file`` config option will now cause Synapse to refuse to\nstart, and should be replaced by with the ``log_config`` option. Support for\nthe ``log_file`` option was removed in v1.3.0 and has since had no effect.\n\n\nUpgrading to v1.7.0\n===================\n\nIn an attempt to configure Synapse in a privacy preserving way, the default\nbehaviours of ``allow_public_rooms_without_auth`` and\n``allow_public_rooms_over_federation`` have been inverted. This means that by\ndefault, only authenticated users querying the Client/Server API will be able\nto query the room directory, and relatedly that the server will not share\nroom directory information with other servers over federation.\n\nIf your installation does not explicitly set these settings one way or the other\nand you want either setting to be ``true`` then it will necessary to update\nyour homeserver configuration file accordingly.\n\nFor more details on the surrounding context see our `explainer\n<https://matrix.org/blog/2019/11/09/avoiding-unwelcome-visitors-on-private-matrix-servers>`_.\n\n\nUpgrading to v1.5.0\n===================\n\nThis release includes a database migration which may take several minutes to\ncomplete if there are a large number (more than a million or so) of entries in\nthe ``devices`` table. This is only likely to a be a problem on very large\ninstallations.\n\n\nUpgrading to v1.4.0\n===================\n\nNew custom templates\n--------------------\n\nIf you have configured a custom template directory with the\n``email.template_dir`` option, be aware that there are new templates regarding\nregistration and threepid management (see below) that must be included.\n\n* ``registration.html`` and ``registration.txt``\n* ``registration_success.html`` and ``registration_failure.html``\n* ``add_threepid.html`` and  ``add_threepid.txt``\n* ``add_threepid_failure.html`` and ``add_threepid_success.html``\n\nSynapse will expect these files to exist inside the configured template\ndirectory, and **will fail to start** if they are absent.\nTo view the default templates, see `synapse/res/templates\n<https://github.com/matrix-org/synapse/tree/master/synapse/res/templates>`_.\n\n3pid verification changes\n-------------------------\n\n**Note: As of this release, users will be unable to add phone numbers or email\naddresses to their accounts, without changes to the Synapse configuration. This\nincludes adding an email address during registration.**\n\nIt is possible for a user to associate an email address or phone number\nwith their account, for a number of reasons:\n\n* for use when logging in, as an alternative to the user id.\n* in the case of email, as an alternative contact to help with account recovery.\n* in the case of email, to receive notifications of missed messages.\n\nBefore an email address or phone number can be added to a user's account,\nor before such an address is used to carry out a password-reset, Synapse must\nconfirm the operation with the owner of the email address or phone number.\nIt does this by sending an email or text giving the user a link or token to confirm\nreceipt. This process is known as '3pid verification'. ('3pid', or 'threepid',\nstands for third-party identifier, and we use it to refer to external\nidentifiers such as email addresses and phone numbers.)\n\nPrevious versions of Synapse delegated the task of 3pid verification to an\nidentity server by default. In most cases this server is ``vector.im`` or\n``matrix.org``.\n\nIn Synapse 1.4.0, for security and privacy reasons, the homeserver will no\nlonger delegate this task to an identity server by default. Instead,\nthe server administrator will need to explicitly decide how they would like the\nverification messages to be sent.\n\nIn the medium term, the ``vector.im`` and ``matrix.org`` identity servers will\ndisable support for delegated 3pid verification entirely. However, in order to\nease the transition, they will retain the capability for a limited\nperiod. Delegated email verification will be disabled on Monday 2nd December\n2019 (giving roughly 2 months notice). Disabling delegated SMS verification\nwill follow some time after that once SMS verification support lands in\nSynapse.\n\nOnce delegated 3pid verification support has been disabled in the ``vector.im`` and\n``matrix.org`` identity servers, all Synapse versions that depend on those\ninstances will be unable to verify email and phone numbers through them. There\nare no imminent plans to remove delegated 3pid verification from Sydent\ngenerally. (Sydent is the identity server project that backs the ``vector.im`` and\n``matrix.org`` instances).\n\nEmail\n~~~~~\nFollowing upgrade, to continue verifying email (e.g. as part of the\nregistration process), admins can either:-\n\n* Configure Synapse to use an email server.\n* Run or choose an identity server which allows delegated email verification\n  and delegate to it.\n\nConfigure SMTP in Synapse\n+++++++++++++++++++++++++\n\nTo configure an SMTP server for Synapse, modify the configuration section\nheaded ``email``, and be sure to have at least the ``smtp_host, smtp_port``\nand ``notif_from`` fields filled out.\n\nYou may also need to set ``smtp_user``, ``smtp_pass``, and\n``require_transport_security``.\n\nSee the `sample configuration file <docs/sample_config.yaml>`_ for more details\non these settings.\n\nDelegate email to an identity server\n++++++++++++++++++++++++++++++++++++\n\nSome admins will wish to continue using email verification as part of the\nregistration process, but will not immediately have an appropriate SMTP server\nat hand.\n\nTo this end, we will continue to support email verification delegation via the\n``vector.im`` and ``matrix.org`` identity servers for two months. Support for\ndelegated email verification will be disabled on Monday 2nd December.\n\nThe ``account_threepid_delegates`` dictionary defines whether the homeserver\nshould delegate an external server (typically an `identity server\n<https://matrix.org/docs/spec/identity_service/r0.2.1>`_) to handle sending\nconfirmation messages via email and SMS.\n\nSo to delegate email verification, in ``homeserver.yaml``, set\n``account_threepid_delegates.email`` to the base URL of an identity server. For\nexample:\n\n.. code:: yaml\n\n   account_threepid_delegates:\n       email: https://example.com     # Delegate email sending to example.com\n\nNote that ``account_threepid_delegates.email`` replaces the deprecated\n``email.trust_identity_server_for_password_resets``: if\n``email.trust_identity_server_for_password_resets`` is set to ``true``, and\n``account_threepid_delegates.email`` is not set, then the first entry in\n``trusted_third_party_id_servers`` will be used as the\n``account_threepid_delegate`` for email. This is to ensure compatibility with\nexisting Synapse installs that set up external server handling for these tasks\nbefore v1.4.0. If ``email.trust_identity_server_for_password_resets`` is\n``true`` and no trusted identity server domains are configured, Synapse will\nreport an error and refuse to start.\n\nIf ``email.trust_identity_server_for_password_resets`` is ``false`` or absent\nand no ``email`` delegate is configured in ``account_threepid_delegates``,\nthen Synapse will send email verification messages itself, using the configured\nSMTP server (see above).\nthat type.\n\nPhone numbers\n~~~~~~~~~~~~~\n\nSynapse does not support phone-number verification itself, so the only way to\nmaintain the ability for users to add phone numbers to their accounts will be\nby continuing to delegate phone number verification to the ``matrix.org`` and\n``vector.im`` identity servers (or another identity server that supports SMS\nsending).\n\nThe ``account_threepid_delegates`` dictionary defines whether the homeserver\nshould delegate an external server (typically an `identity server\n<https://matrix.org/docs/spec/identity_service/r0.2.1>`_) to handle sending\nconfirmation messages via email and SMS.\n\nSo to delegate phone number verification, in ``homeserver.yaml``, set\n``account_threepid_delegates.msisdn`` to the base URL of an identity\nserver. For example:\n\n.. code:: yaml\n\n   account_threepid_delegates:\n       msisdn: https://example.com     # Delegate sms sending to example.com\n\nThe ``matrix.org`` and ``vector.im`` identity servers will continue to support\ndelegated phone number verification via SMS until such time as it is possible\nfor admins to configure their servers to perform phone number verification\ndirectly. More details will follow in a future release.\n\nRolling back to v1.3.1\n----------------------\n\nIf you encounter problems with v1.4.0, it should be possible to roll back to\nv1.3.1, subject to the following:\n\n* The 'room statistics' engine was heavily reworked in this release (see\n  `#5971 <https://github.com/matrix-org/synapse/pull/5971>`_), including\n  significant changes to the database schema, which are not easily\n  reverted. This will cause the room statistics engine to stop updating when\n  you downgrade.\n\n  The room statistics are essentially unused in v1.3.1 (in future versions of\n  Synapse, they will be used to populate the room directory), so there should\n  be no loss of functionality. However, the statistics engine will write errors\n  to the logs, which can be avoided by setting the following in\n  `homeserver.yaml`:\n\n  .. code:: yaml\n\n    stats:\n      enabled: false\n\n  Don't forget to re-enable it when you upgrade again, in preparation for its\n  use in the room directory!\n\nUpgrading to v1.2.0\n===================\n\nSome counter metrics have been renamed, with the old names deprecated. See\n`the metrics documentation <docs/metrics-howto.md#renaming-of-metrics--deprecation-of-old-names-in-12>`_\nfor details.\n\nUpgrading to v1.1.0\n===================\n\nSynapse v1.1.0 removes support for older Python and PostgreSQL versions, as\noutlined in `our deprecation notice <https://matrix.org/blog/2019/04/08/synapse-deprecating-postgres-9-4-and-python-2-x>`_.\n\nMinimum Python Version\n----------------------\n\nSynapse v1.1.0 has a minimum Python requirement of Python 3.5. Python 3.6 or\nPython 3.7 are recommended as they have improved internal string handling,\nsignificantly reducing memory usage.\n\nIf you use current versions of the Matrix.org-distributed Debian packages or\nDocker images, action is not required.\n\nIf you install Synapse in a Python virtual environment, please see \"Upgrading to\nv0.34.0\" for notes on setting up a new virtualenv under Python 3.\n\nMinimum PostgreSQL Version\n--------------------------\n\nIf using PostgreSQL under Synapse, you will need to use PostgreSQL 9.5 or above.\nPlease see the\n`PostgreSQL documentation <https://www.postgresql.org/docs/11/upgrading.html>`_\nfor more details on upgrading your database.\n\nUpgrading to v1.0\n=================\n\nValidation of TLS certificates\n------------------------------\n\nSynapse v1.0 is the first release to enforce\nvalidation of TLS certificates for the federation API. It is therefore\nessential that your certificates are correctly configured. See the `FAQ\n<docs/MSC1711_certificates_FAQ.md>`_ for more information.\n\nNote, v1.0 installations will also no longer be able to federate with servers\nthat have not correctly configured their certificates.\n\nIn rare cases, it may be desirable to disable certificate checking: for\nexample, it might be essential to be able to federate with a given legacy\nserver in a closed federation. This can be done in one of two ways:-\n\n* Configure the global switch ``federation_verify_certificates`` to ``false``.\n* Configure a whitelist of server domains to trust via ``federation_certificate_verification_whitelist``.\n\nSee the `sample configuration file <docs/sample_config.yaml>`_\nfor more details on these settings.\n\nEmail\n-----\nWhen a user requests a password reset, Synapse will send an email to the\nuser to confirm the request.\n\nPrevious versions of Synapse delegated the job of sending this email to an\nidentity server. If the identity server was somehow malicious or became\ncompromised, it would be theoretically possible to hijack an account through\nthis means.\n\nTherefore, by default, Synapse v1.0 will send the confirmation email itself. If\nSynapse is not configured with an SMTP server, password reset via email will be\ndisabled.\n\nTo configure an SMTP server for Synapse, modify the configuration section\nheaded ``email``, and be sure to have at least the ``smtp_host``, ``smtp_port``\nand ``notif_from`` fields filled out. You may also need to set ``smtp_user``,\n``smtp_pass``, and ``require_transport_security``.\n\nIf you are absolutely certain that you wish to continue using an identity\nserver for password resets, set ``trust_identity_server_for_password_resets`` to ``true``.\n\nSee the `sample configuration file <docs/sample_config.yaml>`_\nfor more details on these settings.\n\nNew email templates\n---------------\nSome new templates have been added to the default template directory for the purpose of the\nhomeserver sending its own password reset emails. If you have configured a custom\n``template_dir`` in your Synapse config, these files will need to be added.\n\n``password_reset.html`` and ``password_reset.txt`` are HTML and plain text templates\nrespectively that contain the contents of what will be emailed to the user upon attempting to\nreset their password via email. ``password_reset_success.html`` and\n``password_reset_failure.html`` are HTML files that the content of which (assuming no redirect\nURL is set) will be shown to the user after they attempt to click the link in the email sent\nto them.\n\nUpgrading to v0.99.0\n====================\n\nPlease be aware that, before Synapse v1.0 is released around March 2019, you\nwill need to replace any self-signed certificates with those verified by a\nroot CA. Information on how to do so can be found at `the ACME docs\n<docs/ACME.md>`_.\n\nFor more information on configuring TLS certificates see the `FAQ <docs/MSC1711_certificates_FAQ.md>`_.\n\nUpgrading to v0.34.0\n====================\n\n1. This release is the first to fully support Python 3. Synapse will now run on\n   Python versions 3.5, or 3.6 (as well as 2.7). We recommend switching to\n   Python 3, as it has been shown to give performance improvements.\n\n   For users who have installed Synapse into a virtualenv, we recommend doing\n   this by creating a new virtualenv. For example::\n\n       virtualenv -p python3 ~/synapse/env3\n       source ~/synapse/env3/bin/activate\n       pip install matrix-synapse\n\n   You can then start synapse as normal, having activated the new virtualenv::\n\n       cd ~/synapse\n       source env3/bin/activate\n       synctl start\n\n   Users who have installed from distribution packages should see the relevant\n   package documentation. See below for notes on Debian packages.\n\n   * When upgrading to Python 3, you **must** make sure that your log files are\n     configured as UTF-8, by adding ``encoding: utf8`` to the\n     ``RotatingFileHandler`` configuration (if you have one) in your\n     ``<server>.log.config`` file. For example, if your ``log.config`` file\n     contains::\n\n       handlers:\n         file:\n           class: logging.handlers.RotatingFileHandler\n           formatter: precise\n           filename: homeserver.log\n           maxBytes: 104857600\n           backupCount: 10\n           filters: [context]\n         console:\n           class: logging.StreamHandler\n           formatter: precise\n           filters: [context]\n\n     Then you should update this to be::\n\n       handlers:\n         file:\n           class: logging.handlers.RotatingFileHandler\n           formatter: precise\n           filename: homeserver.log\n           maxBytes: 104857600\n           backupCount: 10\n           filters: [context]\n           encoding: utf8\n         console:\n           class: logging.StreamHandler\n           formatter: precise\n           filters: [context]\n\n     There is no need to revert this change if downgrading to Python 2.\n\n   We are also making available Debian packages which will run Synapse on\n   Python 3. You can switch to these packages with ``apt-get install\n   matrix-synapse-py3``, however, please read `debian/NEWS\n   <https://github.com/matrix-org/synapse/blob/release-v0.34.0/debian/NEWS>`_\n   before doing so. The existing ``matrix-synapse`` packages will continue to\n   use Python 2 for the time being.\n\n2. This release removes the ``riot.im`` from the default list of trusted\n   identity servers.\n\n   If ``riot.im`` is in your homeserver's list of\n   ``trusted_third_party_id_servers``, you should remove it. It was added in\n   case a hypothetical future identity server was put there. If you don't\n   remove it, users may be unable to deactivate their accounts.\n\n3. This release no longer installs the (unmaintained) Matrix Console web client\n   as part of the default installation. It is possible to re-enable it by\n   installing it separately and setting the ``web_client_location`` config\n   option, but please consider switching to another client.\n\nUpgrading to v0.33.7\n====================\n\nThis release removes the example email notification templates from\n``res/templates`` (they are now internal to the python package). This should\nonly affect you if you (a) deploy your Synapse instance from a git checkout or\na github snapshot URL, and (b) have email notifications enabled.\n\nIf you have email notifications enabled, you should ensure that\n``email.template_dir`` is either configured to point at a directory where you\nhave installed customised templates, or leave it unset to use the default\ntemplates.\n\nUpgrading to v0.27.3\n====================\n\nThis release expands the anonymous usage stats sent if the opt-in\n``report_stats`` configuration is set to ``true``. We now capture RSS memory\nand cpu use at a very coarse level. This requires administrators to install\nthe optional ``psutil`` python module.\n\nWe would appreciate it if you could assist by ensuring this module is available\nand ``report_stats`` is enabled. This will let us see if performance changes to\nsynapse are having an impact to the general community.\n\nUpgrading to v0.15.0\n====================\n\nIf you want to use the new URL previewing API (/_matrix/media/r0/preview_url)\nthen you have to explicitly enable it in the config and update your dependencies\ndependencies.  See README.rst for details.\n\n\nUpgrading to v0.11.0\n====================\n\nThis release includes the option to send anonymous usage stats to matrix.org,\nand requires that administrators explictly opt in or out by setting the\n``report_stats`` option to either ``true`` or ``false``.\n\nWe would really appreciate it if you could help our project out by reporting\nanonymized usage statistics from your homeserver. Only very basic aggregate\ndata (e.g. number of users) will be reported, but it helps us to track the\ngrowth of the Matrix community, and helps us to make Matrix a success, as well\nas to convince other networks that they should peer with us.\n\n\nUpgrading to v0.9.0\n===================\n\nApplication services have had a breaking API change in this version.\n\nThey can no longer register themselves with a home server using the AS HTTP API. This\ndecision was made because a compromised application service with free reign to register\nany regex in effect grants full read/write access to the home server if a regex of ``.*``\nis used. An attack where a compromised AS re-registers itself with ``.*`` was deemed too\nbig of a security risk to ignore, and so the ability to register with the HS remotely has\nbeen removed.\n\nIt has been replaced by specifying a list of application service registrations in\n``homeserver.yaml``::\n\n  app_service_config_files: [\"registration-01.yaml\", \"registration-02.yaml\"]\n\nWhere ``registration-01.yaml`` looks like::\n\n  url: <String>  # e.g. \"https://my.application.service.com\"\n  as_token: <String>\n  hs_token: <String>\n  sender_localpart: <String>  # This is a new field which denotes the user_id localpart when using the AS token\n  namespaces:\n    users:\n      - exclusive: <Boolean>\n        regex: <String>  # e.g. \"@prefix_.*\"\n    aliases:\n      - exclusive: <Boolean>\n        regex: <String>\n    rooms:\n      - exclusive: <Boolean>\n        regex: <String>\n\nUpgrading to v0.8.0\n===================\n\nServers which use captchas will need to add their public key to::\n\n  static/client/register/register_config.js\n\n    window.matrixRegistrationConfig = {\n        recaptcha_public_key: \"YOUR_PUBLIC_KEY\"\n    };\n\nThis is required in order to support registration fallback (typically used on\nmobile devices).\n\n\nUpgrading to v0.7.0\n===================\n\nNew dependencies are:\n\n- pydenticon\n- simplejson\n- syutil\n- matrix-angular-sdk\n\nTo pull in these dependencies in a virtual env, run::\n\n    python synapse/python_dependencies.py | xargs -n 1 pip install\n\nUpgrading to v0.6.0\n===================\n\nTo pull in new dependencies, run::\n\n    python setup.py develop --user\n\nThis update includes a change to the database schema. To upgrade you first need\nto upgrade the database by running::\n\n    python scripts/upgrade_db_to_v0.6.0.py <db> <server_name> <signing_key>\n\nWhere `<db>` is the location of the database, `<server_name>` is the\nserver name as specified in the synapse configuration, and `<signing_key>` is\nthe location of the signing key as specified in the synapse configuration.\n\nThis may take some time to complete. Failures of signatures and content hashes\ncan safely be ignored.\n\n\nUpgrading to v0.5.1\n===================\n\nDepending on precisely when you installed v0.5.0 you may have ended up with\na stale release of the reference matrix webclient installed as a python module.\nTo uninstall it and ensure you are depending on the latest module, please run::\n\n    $ pip uninstall syweb\n\nUpgrading to v0.5.0\n===================\n\nThe webclient has been split out into a seperate repository/pacakage in this\nrelease. Before you restart your homeserver you will need to pull in the\nwebclient package by running::\n\n  python setup.py develop --user\n\nThis release completely changes the database schema and so requires upgrading\nit before starting the new version of the homeserver.\n\nThe script \"database-prepare-for-0.5.0.sh\" should be used to upgrade the\ndatabase. This will save all user information, such as logins and profiles,\nbut will otherwise purge the database. This includes messages, which\nrooms the home server was a member of and room alias mappings.\n\nIf you would like to keep your history, please take a copy of your database\nfile and ask for help in #matrix:matrix.org. The upgrade process is,\nunfortunately, non trivial and requires human intervention to resolve any\nresulting conflicts during the upgrade process.\n\nBefore running the command the homeserver should be first completely\nshutdown. To run it, simply specify the location of the database, e.g.:\n\n  ./scripts/database-prepare-for-0.5.0.sh \"homeserver.db\"\n\nOnce this has successfully completed it will be safe to restart the\nhomeserver. You may notice that the homeserver takes a few seconds longer to\nrestart than usual as it reinitializes the database.\n\nOn startup of the new version, users can either rejoin remote rooms using room\naliases or by being reinvited. Alternatively, if any other homeserver sends a\nmessage to a room that the homeserver was previously in the local HS will\nautomatically rejoin the room.\n\nUpgrading to v0.4.0\n===================\n\nThis release needs an updated syutil version. Run::\n\n    python setup.py develop\n\nYou will also need to upgrade your configuration as the signing key format has\nchanged. Run::\n\n    python -m synapse.app.homeserver --config-path <CONFIG> --generate-config\n\n\nUpgrading to v0.3.0\n===================\n\nThis registration API now closely matches the login API. This introduces a bit\nmore backwards and forwards between the HS and the client, but this improves\nthe overall flexibility of the API. You can now GET on /register to retrieve a list\nof valid registration flows. Upon choosing one, they are submitted in the same\nway as login, e.g::\n\n  {\n    type: m.login.password,\n    user: foo,\n    password: bar\n  }\n\nThe default HS supports 2 flows, with and without Identity Server email\nauthentication. Enabling captcha on the HS will add in an extra step to all\nflows: ``m.login.recaptcha`` which must be completed before you can transition\nto the next stage. There is a new login type: ``m.login.email.identity`` which\ncontains the ``threepidCreds`` key which were previously sent in the original\nregister request. For more information on this, see the specification.\n\nWeb Client\n----------\n\nThe VoIP specification has changed between v0.2.0 and v0.3.0. Users should\nrefresh any browser tabs to get the latest web client code. Users on\nv0.2.0 of the web client will not be able to call those on v0.3.0 and\nvice versa.\n\n\nUpgrading to v0.2.0\n===================\n\nThe home server now requires setting up of SSL config before it can run. To\nautomatically generate default config use::\n\n    $ python synapse/app/homeserver.py \\\n        --server-name machine.my.domain.name \\\n        --bind-port 8448 \\\n        --config-path homeserver.config \\\n        --generate-config\n\nThis config can be edited if desired, for example to specify a different SSL\ncertificate to use. Once done you can run the home server using::\n\n    $ python synapse/app/homeserver.py --config-path homeserver.config\n\nSee the README.rst for more information.\n\nAlso note that some config options have been renamed, including:\n\n- \"host\" to \"server-name\"\n- \"database\" to \"database-path\"\n- \"port\" to \"bind-port\" and \"unsecure-port\"\n\n\nUpgrading to v0.0.1\n===================\n\nThis release completely changes the database schema and so requires upgrading\nit before starting the new version of the homeserver.\n\nThe script \"database-prepare-for-0.0.1.sh\" should be used to upgrade the\ndatabase. This will save all user information, such as logins and profiles,\nbut will otherwise purge the database. This includes messages, which\nrooms the home server was a member of and room alias mappings.\n\nBefore running the command the homeserver should be first completely\nshutdown. To run it, simply specify the location of the database, e.g.:\n\n  ./scripts/database-prepare-for-0.0.1.sh \"homeserver.db\"\n\nOnce this has successfully completed it will be safe to restart the\nhomeserver. You may notice that the homeserver takes a few seconds longer to\nrestart than usual as it reinitializes the database.\n\nOn startup of the new version, users can either rejoin remote rooms using room\naliases or by being reinvited. Alternatively, if any other homeserver sends a\nmessage to a room that the homeserver was previously in the local HS will\nautomatically rejoin the room.\n", "patch": "@@ -85,6 +85,43 @@ for example:\n      wget https://packages.matrix.org/debian/pool/main/m/matrix-synapse-py3/matrix-synapse-py3_1.3.0+stretch1_amd64.deb\n      dpkg -i matrix-synapse-py3_1.3.0+stretch1_amd64.deb\n \n+Upgrading to v1.27.0\n+====================\n+\n+Changes to HTML templates\n+-------------------------\n+\n+The HTML templates for SSO and email notifications now have `Jinja2's autoescape <https://jinja.palletsprojects.com/en/2.11.x/api/#autoescaping>`_\n+enabled for files ending in ``.html``, ``.htm``, and ``.xml``. If you hae customised\n+these templates and see issues when viewing them you might need to update them.\n+It is expected that most configurations will need no changes.\n+\n+If you have customised the templates *names* for these templates it is recommended\n+to verify they end in ``.html`` to ensure autoescape is enabled.\n+\n+The above applies to the following templates:\n+\n+* ``add_threepid.html``\n+* ``add_threepid_failure.html``\n+* ``add_threepid_success.html``\n+* ``notice_expiry.html``\n+* ``notice_expiry.html``\n+* ``notif_mail.html`` (which, by default, includes ``room.html`` and ``notif.html``)\n+* ``password_reset.html``\n+* ``password_reset_confirmation.html``\n+* ``password_reset_failure.html``\n+* ``password_reset_success.html``\n+* ``registration.html``\n+* ``registration_failure.html``\n+* ``registration_success.html``\n+* ``sso_account_deactivated.html``\n+* ``sso_auth_bad_user.html``\n+* ``sso_auth_confirm.html``\n+* ``sso_auth_success.html``\n+* ``sso_error.html``\n+* ``sso_login_idp_picker.html``\n+* ``sso_redirect_confirm.html``\n+\n Upgrading to v1.26.0\n ====================\n ", "file_path": "files/2021_3/62", "file_language": "rst", "file_name": "UPGRADE.rst", "outdated_file_modify": 0, "outdated_file_before": 0, "outdated_file_after": 0}, {"raw_url": "https://github.com/matrix-org/synapse/raw/e54746bdf7d5c831eabe4dcea76a7626f1de73df/changelog.d%2F9200.misc", "code": "Clean-up template loading code.\n", "code_before": "", "patch": "@@ -0,0 +1 @@\n+Clean-up template loading code.", "file_path": "files/2021_3/63", "file_language": "misc", "file_name": "changelog.d/9200.misc", "outdated_file_modify": 0, "outdated_file_before": 0, "outdated_file_after": 0}, {"raw_url": "https://github.com/matrix-org/synapse/raw/e54746bdf7d5c831eabe4dcea76a7626f1de73df/synapse%2Fconfig%2F_base.py", "code": "# -*- coding: utf-8 -*-\n# Copyright 2014-2016 OpenMarket Ltd\n# Copyright 2017-2018 New Vector Ltd\n# Copyright 2019 The Matrix.org Foundation C.I.C.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport argparse\nimport errno\nimport os\nimport time\nimport urllib.parse\nfrom collections import OrderedDict\nfrom hashlib import sha256\nfrom textwrap import dedent\nfrom typing import Any, Callable, Iterable, List, MutableMapping, Optional\n\nimport attr\nimport jinja2\nimport pkg_resources\nimport yaml\n\n\nclass ConfigError(Exception):\n    \"\"\"Represents a problem parsing the configuration\n\n    Args:\n        msg:  A textual description of the error.\n        path: Where appropriate, an indication of where in the configuration\n           the problem lies.\n    \"\"\"\n\n    def __init__(self, msg: str, path: Optional[Iterable[str]] = None):\n        self.msg = msg\n        self.path = path\n\n\n# We split these messages out to allow packages to override with package\n# specific instructions.\nMISSING_REPORT_STATS_CONFIG_INSTRUCTIONS = \"\"\"\\\nPlease opt in or out of reporting anonymized homeserver usage statistics, by\nsetting the `report_stats` key in your config file to either True or False.\n\"\"\"\n\nMISSING_REPORT_STATS_SPIEL = \"\"\"\\\nWe would really appreciate it if you could help our project out by reporting\nanonymized usage statistics from your homeserver. Only very basic aggregate\ndata (e.g. number of users) will be reported, but it helps us to track the\ngrowth of the Matrix community, and helps us to make Matrix a success, as well\nas to convince other networks that they should peer with us.\n\nThank you.\n\"\"\"\n\nMISSING_SERVER_NAME = \"\"\"\\\nMissing mandatory `server_name` config option.\n\"\"\"\n\n\nCONFIG_FILE_HEADER = \"\"\"\\\n# Configuration file for Synapse.\n#\n# This is a YAML file: see [1] for a quick introduction. Note in particular\n# that *indentation is important*: all the elements of a list or dictionary\n# should have the same indentation.\n#\n# [1] https://docs.ansible.com/ansible/latest/reference_appendices/YAMLSyntax.html\n\n\"\"\"\n\n\ndef path_exists(file_path):\n    \"\"\"Check if a file exists\n\n    Unlike os.path.exists, this throws an exception if there is an error\n    checking if the file exists (for example, if there is a perms error on\n    the parent dir).\n\n    Returns:\n        bool: True if the file exists; False if not.\n    \"\"\"\n    try:\n        os.stat(file_path)\n        return True\n    except OSError as e:\n        if e.errno != errno.ENOENT:\n            raise e\n        return False\n\n\nclass Config:\n    \"\"\"\n    A configuration section, containing configuration keys and values.\n\n    Attributes:\n        section (str): The section title of this config object, such as\n            \"tls\" or \"logger\". This is used to refer to it on the root\n            logger (for example, `config.tls.some_option`). Must be\n            defined in subclasses.\n    \"\"\"\n\n    section = None\n\n    def __init__(self, root_config=None):\n        self.root = root_config\n\n        # Get the path to the default Synapse template directory\n        self.default_template_dir = pkg_resources.resource_filename(\n            \"synapse\", \"res/templates\"\n        )\n\n    def __getattr__(self, item: str) -> Any:\n        \"\"\"\n        Try and fetch a configuration option that does not exist on this class.\n\n        This is so that existing configs that rely on `self.value`, where value\n        is actually from a different config section, continue to work.\n        \"\"\"\n        if item in [\"generate_config_section\", \"read_config\"]:\n            raise AttributeError(item)\n\n        if self.root is None:\n            raise AttributeError(item)\n        else:\n            return self.root._get_unclassed_config(self.section, item)\n\n    @staticmethod\n    def parse_size(value):\n        if isinstance(value, int):\n            return value\n        sizes = {\"K\": 1024, \"M\": 1024 * 1024}\n        size = 1\n        suffix = value[-1]\n        if suffix in sizes:\n            value = value[:-1]\n            size = sizes[suffix]\n        return int(value) * size\n\n    @staticmethod\n    def parse_duration(value):\n        if isinstance(value, int):\n            return value\n        second = 1000\n        minute = 60 * second\n        hour = 60 * minute\n        day = 24 * hour\n        week = 7 * day\n        year = 365 * day\n        sizes = {\"s\": second, \"m\": minute, \"h\": hour, \"d\": day, \"w\": week, \"y\": year}\n        size = 1\n        suffix = value[-1]\n        if suffix in sizes:\n            value = value[:-1]\n            size = sizes[suffix]\n        return int(value) * size\n\n    @staticmethod\n    def abspath(file_path):\n        return os.path.abspath(file_path) if file_path else file_path\n\n    @classmethod\n    def path_exists(cls, file_path):\n        return path_exists(file_path)\n\n    @classmethod\n    def check_file(cls, file_path, config_name):\n        if file_path is None:\n            raise ConfigError(\"Missing config for %s.\" % (config_name,))\n        try:\n            os.stat(file_path)\n        except OSError as e:\n            raise ConfigError(\n                \"Error accessing file '%s' (config for %s): %s\"\n                % (file_path, config_name, e.strerror)\n            )\n        return cls.abspath(file_path)\n\n    @classmethod\n    def ensure_directory(cls, dir_path):\n        dir_path = cls.abspath(dir_path)\n        try:\n            os.makedirs(dir_path)\n        except OSError as e:\n            if e.errno != errno.EEXIST:\n                raise\n        if not os.path.isdir(dir_path):\n            raise ConfigError(\"%s is not a directory\" % (dir_path,))\n        return dir_path\n\n    @classmethod\n    def read_file(cls, file_path, config_name):\n        cls.check_file(file_path, config_name)\n        with open(file_path) as file_stream:\n            return file_stream.read()\n\n    def read_template(self, filename: str) -> jinja2.Template:\n        \"\"\"Load a template file from disk.\n\n        This function will attempt to load the given template from the default Synapse\n        template directory.\n\n        Files read are treated as Jinja templates. The templates is not rendered yet\n        and has autoescape enabled.\n\n        Args:\n            filename: A template filename to read.\n\n        Raises:\n            ConfigError: if the file's path is incorrect or otherwise cannot be read.\n\n        Returns:\n            A jinja2 template.\n        \"\"\"\n        return self.read_templates([filename])[0]\n\n    def read_templates(\n        self, filenames: List[str], custom_template_directory: Optional[str] = None,\n    ) -> List[jinja2.Template]:\n        \"\"\"Load a list of template files from disk using the given variables.\n\n        This function will attempt to load the given templates from the default Synapse\n        template directory. If `custom_template_directory` is supplied, that directory\n        is tried first.\n\n        Files read are treated as Jinja templates. The templates are not rendered yet\n        and have autoescape enabled.\n\n        Args:\n            filenames: A list of template filenames to read.\n\n            custom_template_directory: A directory to try to look for the templates\n                before using the default Synapse template directory instead.\n\n        Raises:\n            ConfigError: if the file's path is incorrect or otherwise cannot be read.\n\n        Returns:\n            A list of jinja2 templates.\n        \"\"\"\n        search_directories = [self.default_template_dir]\n\n        # The loader will first look in the custom template directory (if specified) for the\n        # given filename. If it doesn't find it, it will use the default template dir instead\n        if custom_template_directory:\n            # Check that the given template directory exists\n            if not self.path_exists(custom_template_directory):\n                raise ConfigError(\n                    \"Configured template directory does not exist: %s\"\n                    % (custom_template_directory,)\n                )\n\n            # Search the custom template directory as well\n            search_directories.insert(0, custom_template_directory)\n\n        loader = jinja2.FileSystemLoader(search_directories)\n        env = jinja2.Environment(loader=loader, autoescape=jinja2.select_autoescape(),)\n\n        # Update the environment with our custom filters\n        env.filters.update(\n            {\n                \"format_ts\": _format_ts_filter,\n                \"mxc_to_http\": _create_mxc_to_http_filter(self.public_baseurl),\n            }\n        )\n\n        # Load the templates\n        return [env.get_template(filename) for filename in filenames]\n\n\ndef _format_ts_filter(value: int, format: str):\n    return time.strftime(format, time.localtime(value / 1000))\n\n\ndef _create_mxc_to_http_filter(public_baseurl: str) -> Callable:\n    \"\"\"Create and return a jinja2 filter that converts MXC urls to HTTP\n\n    Args:\n        public_baseurl: The public, accessible base URL of the homeserver\n    \"\"\"\n\n    def mxc_to_http_filter(value, width, height, resize_method=\"crop\"):\n        if value[0:6] != \"mxc://\":\n            return \"\"\n\n        server_and_media_id = value[6:]\n        fragment = None\n        if \"#\" in server_and_media_id:\n            server_and_media_id, fragment = server_and_media_id.split(\"#\", 1)\n            fragment = \"#\" + fragment\n\n        params = {\"width\": width, \"height\": height, \"method\": resize_method}\n        return \"%s_matrix/media/v1/thumbnail/%s?%s%s\" % (\n            public_baseurl,\n            server_and_media_id,\n            urllib.parse.urlencode(params),\n            fragment or \"\",\n        )\n\n    return mxc_to_http_filter\n\n\nclass RootConfig:\n    \"\"\"\n    Holder of an application's configuration.\n\n    What configuration this object holds is defined by `config_classes`, a list\n    of Config classes that will be instantiated and given the contents of a\n    configuration file to read. They can then be accessed on this class by their\n    section name, defined in the Config or dynamically set to be the name of the\n    class, lower-cased and with \"Config\" removed.\n    \"\"\"\n\n    config_classes = []\n\n    def __init__(self):\n        self._configs = OrderedDict()\n\n        for config_class in self.config_classes:\n            if config_class.section is None:\n                raise ValueError(\"%r requires a section name\" % (config_class,))\n\n            try:\n                conf = config_class(self)\n            except Exception as e:\n                raise Exception(\"Failed making %s: %r\" % (config_class.section, e))\n            self._configs[config_class.section] = conf\n\n    def __getattr__(self, item: str) -> Any:\n        \"\"\"\n        Redirect lookups on this object either to config objects, or values on\n        config objects, so that `config.tls.blah` works, as well as legacy uses\n        of things like `config.server_name`. It will first look up the config\n        section name, and then values on those config classes.\n        \"\"\"\n        if item in self._configs.keys():\n            return self._configs[item]\n\n        return self._get_unclassed_config(None, item)\n\n    def _get_unclassed_config(self, asking_section: Optional[str], item: str):\n        \"\"\"\n        Fetch a config value from one of the instantiated config classes that\n        has not been fetched directly.\n\n        Args:\n            asking_section: If this check is coming from a Config child, which\n                one? This section will not be asked if it has the value.\n            item: The configuration value key.\n\n        Raises:\n            AttributeError if no config classes have the config key. The body\n                will contain what sections were checked.\n        \"\"\"\n        for key, val in self._configs.items():\n            if key == asking_section:\n                continue\n\n            if item in dir(val):\n                return getattr(val, item)\n\n        raise AttributeError(item, \"not found in %s\" % (list(self._configs.keys()),))\n\n    def invoke_all(self, func_name: str, *args, **kwargs) -> MutableMapping[str, Any]:\n        \"\"\"\n        Invoke a function on all instantiated config objects this RootConfig is\n        configured to use.\n\n        Args:\n            func_name: Name of function to invoke\n            *args\n            **kwargs\n        Returns:\n            ordered dictionary of config section name and the result of the\n            function from it.\n        \"\"\"\n        res = OrderedDict()\n\n        for name, config in self._configs.items():\n            if hasattr(config, func_name):\n                res[name] = getattr(config, func_name)(*args, **kwargs)\n\n        return res\n\n    @classmethod\n    def invoke_all_static(cls, func_name: str, *args, **kwargs):\n        \"\"\"\n        Invoke a static function on config objects this RootConfig is\n        configured to use.\n\n        Args:\n            func_name: Name of function to invoke\n            *args\n            **kwargs\n        Returns:\n            ordered dictionary of config section name and the result of the\n            function from it.\n        \"\"\"\n        for config in cls.config_classes:\n            if hasattr(config, func_name):\n                getattr(config, func_name)(*args, **kwargs)\n\n    def generate_config(\n        self,\n        config_dir_path,\n        data_dir_path,\n        server_name,\n        generate_secrets=False,\n        report_stats=None,\n        open_private_ports=False,\n        listeners=None,\n        tls_certificate_path=None,\n        tls_private_key_path=None,\n        acme_domain=None,\n    ):\n        \"\"\"\n        Build a default configuration file\n\n        This is used when the user explicitly asks us to generate a config file\n        (eg with --generate_config).\n\n        Args:\n            config_dir_path (str): The path where the config files are kept. Used to\n                create filenames for things like the log config and the signing key.\n\n            data_dir_path (str): The path where the data files are kept. Used to create\n                filenames for things like the database and media store.\n\n            server_name (str): The server name. Used to initialise the server_name\n                config param, but also used in the names of some of the config files.\n\n            generate_secrets (bool): True if we should generate new secrets for things\n                like the macaroon_secret_key. If False, these parameters will be left\n                unset.\n\n            report_stats (bool|None): Initial setting for the report_stats setting.\n                If None, report_stats will be left unset.\n\n            open_private_ports (bool): True to leave private ports (such as the non-TLS\n                HTTP listener) open to the internet.\n\n            listeners (list(dict)|None): A list of descriptions of the listeners\n                synapse should start with each of which specifies a port (str), a list of\n                resources (list(str)), tls (bool) and type (str). For example:\n                [{\n                    \"port\": 8448,\n                    \"resources\": [{\"names\": [\"federation\"]}],\n                    \"tls\": True,\n                    \"type\": \"http\",\n                },\n                {\n                    \"port\": 443,\n                    \"resources\": [{\"names\": [\"client\"]}],\n                    \"tls\": False,\n                    \"type\": \"http\",\n                }],\n\n\n            database (str|None): The database type to configure, either `psycog2`\n                or `sqlite3`.\n\n            tls_certificate_path (str|None): The path to the tls certificate.\n\n            tls_private_key_path (str|None): The path to the tls private key.\n\n            acme_domain (str|None): The domain acme will try to validate. If\n                specified acme will be enabled.\n\n        Returns:\n            str: the yaml config file\n        \"\"\"\n\n        return CONFIG_FILE_HEADER + \"\\n\\n\".join(\n            dedent(conf)\n            for conf in self.invoke_all(\n                \"generate_config_section\",\n                config_dir_path=config_dir_path,\n                data_dir_path=data_dir_path,\n                server_name=server_name,\n                generate_secrets=generate_secrets,\n                report_stats=report_stats,\n                open_private_ports=open_private_ports,\n                listeners=listeners,\n                tls_certificate_path=tls_certificate_path,\n                tls_private_key_path=tls_private_key_path,\n                acme_domain=acme_domain,\n            ).values()\n        )\n\n    @classmethod\n    def load_config(cls, description, argv):\n        \"\"\"Parse the commandline and config files\n\n        Doesn't support config-file-generation: used by the worker apps.\n\n        Returns: Config object.\n        \"\"\"\n        config_parser = argparse.ArgumentParser(description=description)\n        cls.add_arguments_to_parser(config_parser)\n        obj, _ = cls.load_config_with_parser(config_parser, argv)\n\n        return obj\n\n    @classmethod\n    def add_arguments_to_parser(cls, config_parser):\n        \"\"\"Adds all the config flags to an ArgumentParser.\n\n        Doesn't support config-file-generation: used by the worker apps.\n\n        Used for workers where we want to add extra flags/subcommands.\n\n        Args:\n            config_parser (ArgumentParser): App description\n        \"\"\"\n\n        config_parser.add_argument(\n            \"-c\",\n            \"--config-path\",\n            action=\"append\",\n            metavar=\"CONFIG_FILE\",\n            help=\"Specify config file. Can be given multiple times and\"\n            \" may specify directories containing *.yaml files.\",\n        )\n\n        config_parser.add_argument(\n            \"--keys-directory\",\n            metavar=\"DIRECTORY\",\n            help=\"Where files such as certs and signing keys are stored when\"\n            \" their location is not given explicitly in the config.\"\n            \" Defaults to the directory containing the last config file\",\n        )\n\n        cls.invoke_all_static(\"add_arguments\", config_parser)\n\n    @classmethod\n    def load_config_with_parser(cls, parser, argv):\n        \"\"\"Parse the commandline and config files with the given parser\n\n        Doesn't support config-file-generation: used by the worker apps.\n\n        Used for workers where we want to add extra flags/subcommands.\n\n        Args:\n            parser (ArgumentParser)\n            argv (list[str])\n\n        Returns:\n            tuple[HomeServerConfig, argparse.Namespace]: Returns the parsed\n            config object and the parsed argparse.Namespace object from\n            `parser.parse_args(..)`\n        \"\"\"\n\n        obj = cls()\n\n        config_args = parser.parse_args(argv)\n\n        config_files = find_config_files(search_paths=config_args.config_path)\n\n        if not config_files:\n            parser.error(\"Must supply a config file.\")\n\n        if config_args.keys_directory:\n            config_dir_path = config_args.keys_directory\n        else:\n            config_dir_path = os.path.dirname(config_files[-1])\n        config_dir_path = os.path.abspath(config_dir_path)\n        data_dir_path = os.getcwd()\n\n        config_dict = read_config_files(config_files)\n        obj.parse_config_dict(\n            config_dict, config_dir_path=config_dir_path, data_dir_path=data_dir_path\n        )\n\n        obj.invoke_all(\"read_arguments\", config_args)\n\n        return obj, config_args\n\n    @classmethod\n    def load_or_generate_config(cls, description, argv):\n        \"\"\"Parse the commandline and config files\n\n        Supports generation of config files, so is used for the main homeserver app.\n\n        Returns: Config object, or None if --generate-config or --generate-keys was set\n        \"\"\"\n        parser = argparse.ArgumentParser(description=description)\n        parser.add_argument(\n            \"-c\",\n            \"--config-path\",\n            action=\"append\",\n            metavar=\"CONFIG_FILE\",\n            help=\"Specify config file. Can be given multiple times and\"\n            \" may specify directories containing *.yaml files.\",\n        )\n\n        generate_group = parser.add_argument_group(\"Config generation\")\n        generate_group.add_argument(\n            \"--generate-config\",\n            action=\"store_true\",\n            help=\"Generate a config file, then exit.\",\n        )\n        generate_group.add_argument(\n            \"--generate-missing-configs\",\n            \"--generate-keys\",\n            action=\"store_true\",\n            help=\"Generate any missing additional config files, then exit.\",\n        )\n        generate_group.add_argument(\n            \"-H\", \"--server-name\", help=\"The server name to generate a config file for.\"\n        )\n        generate_group.add_argument(\n            \"--report-stats\",\n            action=\"store\",\n            help=\"Whether the generated config reports anonymized usage statistics.\",\n            choices=[\"yes\", \"no\"],\n        )\n        generate_group.add_argument(\n            \"--config-directory\",\n            \"--keys-directory\",\n            metavar=\"DIRECTORY\",\n            help=(\n                \"Specify where additional config files such as signing keys and log\"\n                \" config should be stored. Defaults to the same directory as the last\"\n                \" config file.\"\n            ),\n        )\n        generate_group.add_argument(\n            \"--data-directory\",\n            metavar=\"DIRECTORY\",\n            help=(\n                \"Specify where data such as the media store and database file should be\"\n                \" stored. Defaults to the current working directory.\"\n            ),\n        )\n        generate_group.add_argument(\n            \"--open-private-ports\",\n            action=\"store_true\",\n            help=(\n                \"Leave private ports (such as the non-TLS HTTP listener) open to the\"\n                \" internet. Do not use this unless you know what you are doing.\"\n            ),\n        )\n\n        cls.invoke_all_static(\"add_arguments\", parser)\n        config_args = parser.parse_args(argv)\n\n        config_files = find_config_files(search_paths=config_args.config_path)\n\n        if not config_files:\n            parser.error(\n                \"Must supply a config file.\\nA config file can be automatically\"\n                ' generated using \"--generate-config -H SERVER_NAME'\n                ' -c CONFIG-FILE\"'\n            )\n\n        if config_args.config_directory:\n            config_dir_path = config_args.config_directory\n        else:\n            config_dir_path = os.path.dirname(config_files[-1])\n        config_dir_path = os.path.abspath(config_dir_path)\n        data_dir_path = os.getcwd()\n\n        generate_missing_configs = config_args.generate_missing_configs\n\n        obj = cls()\n\n        if config_args.generate_config:\n            if config_args.report_stats is None:\n                parser.error(\n                    \"Please specify either --report-stats=yes or --report-stats=no\\n\\n\"\n                    + MISSING_REPORT_STATS_SPIEL\n                )\n\n            (config_path,) = config_files\n            if not path_exists(config_path):\n                print(\"Generating config file %s\" % (config_path,))\n\n                if config_args.data_directory:\n                    data_dir_path = config_args.data_directory\n                else:\n                    data_dir_path = os.getcwd()\n                data_dir_path = os.path.abspath(data_dir_path)\n\n                server_name = config_args.server_name\n                if not server_name:\n                    raise ConfigError(\n                        \"Must specify a server_name to a generate config for.\"\n                        \" Pass -H server.name.\"\n                    )\n\n                config_str = obj.generate_config(\n                    config_dir_path=config_dir_path,\n                    data_dir_path=data_dir_path,\n                    server_name=server_name,\n                    report_stats=(config_args.report_stats == \"yes\"),\n                    generate_secrets=True,\n                    open_private_ports=config_args.open_private_ports,\n                )\n\n                if not path_exists(config_dir_path):\n                    os.makedirs(config_dir_path)\n                with open(config_path, \"w\") as config_file:\n                    config_file.write(config_str)\n                    config_file.write(\"\\n\\n# vim:ft=yaml\")\n\n                config_dict = yaml.safe_load(config_str)\n                obj.generate_missing_files(config_dict, config_dir_path)\n\n                print(\n                    (\n                        \"A config file has been generated in %r for server name\"\n                        \" %r. Please review this file and customise it\"\n                        \" to your needs.\"\n                    )\n                    % (config_path, server_name)\n                )\n                return\n            else:\n                print(\n                    (\n                        \"Config file %r already exists. Generating any missing config\"\n                        \" files.\"\n                    )\n                    % (config_path,)\n                )\n                generate_missing_configs = True\n\n        config_dict = read_config_files(config_files)\n        if generate_missing_configs:\n            obj.generate_missing_files(config_dict, config_dir_path)\n            return None\n\n        obj.parse_config_dict(\n            config_dict, config_dir_path=config_dir_path, data_dir_path=data_dir_path\n        )\n        obj.invoke_all(\"read_arguments\", config_args)\n\n        return obj\n\n    def parse_config_dict(self, config_dict, config_dir_path=None, data_dir_path=None):\n        \"\"\"Read the information from the config dict into this Config object.\n\n        Args:\n            config_dict (dict): Configuration data, as read from the yaml\n\n            config_dir_path (str): The path where the config files are kept. Used to\n                create filenames for things like the log config and the signing key.\n\n            data_dir_path (str): The path where the data files are kept. Used to create\n                filenames for things like the database and media store.\n        \"\"\"\n        self.invoke_all(\n            \"read_config\",\n            config_dict,\n            config_dir_path=config_dir_path,\n            data_dir_path=data_dir_path,\n        )\n\n    def generate_missing_files(self, config_dict, config_dir_path):\n        self.invoke_all(\"generate_files\", config_dict, config_dir_path)\n\n\ndef read_config_files(config_files):\n    \"\"\"Read the config files into a dict\n\n    Args:\n        config_files (iterable[str]): A list of the config files to read\n\n    Returns: dict\n    \"\"\"\n    specified_config = {}\n    for config_file in config_files:\n        with open(config_file) as file_stream:\n            yaml_config = yaml.safe_load(file_stream)\n\n        if not isinstance(yaml_config, dict):\n            err = \"File %r is empty or doesn't parse into a key-value map. IGNORING.\"\n            print(err % (config_file,))\n            continue\n\n        specified_config.update(yaml_config)\n\n    if \"server_name\" not in specified_config:\n        raise ConfigError(MISSING_SERVER_NAME)\n\n    if \"report_stats\" not in specified_config:\n        raise ConfigError(\n            MISSING_REPORT_STATS_CONFIG_INSTRUCTIONS + \"\\n\" + MISSING_REPORT_STATS_SPIEL\n        )\n    return specified_config\n\n\ndef find_config_files(search_paths):\n    \"\"\"Finds config files using a list of search paths. If a path is a file\n    then that file path is added to the list. If a search path is a directory\n    then all the \"*.yaml\" files in that directory are added to the list in\n    sorted order.\n\n    Args:\n        search_paths(list(str)): A list of paths to search.\n\n    Returns:\n        list(str): A list of file paths.\n    \"\"\"\n\n    config_files = []\n    if search_paths:\n        for config_path in search_paths:\n            if os.path.isdir(config_path):\n                # We accept specifying directories as config paths, we search\n                # inside that directory for all files matching *.yaml, and then\n                # we apply them in *sorted* order.\n                files = []\n                for entry in os.listdir(config_path):\n                    entry_path = os.path.join(config_path, entry)\n                    if not os.path.isfile(entry_path):\n                        err = \"Found subdirectory in config directory: %r. IGNORING.\"\n                        print(err % (entry_path,))\n                        continue\n\n                    if not entry.endswith(\".yaml\"):\n                        err = (\n                            \"Found file in config directory that does not end in \"\n                            \"'.yaml': %r. IGNORING.\"\n                        )\n                        print(err % (entry_path,))\n                        continue\n\n                    files.append(entry_path)\n\n                config_files.extend(sorted(files))\n            else:\n                config_files.append(config_path)\n    return config_files\n\n\n@attr.s\nclass ShardedWorkerHandlingConfig:\n    \"\"\"Algorithm for choosing which instance is responsible for handling some\n    sharded work.\n\n    For example, the federation senders use this to determine which instances\n    handles sending stuff to a given destination (which is used as the `key`\n    below).\n    \"\"\"\n\n    instances = attr.ib(type=List[str])\n\n    def should_handle(self, instance_name: str, key: str) -> bool:\n        \"\"\"Whether this instance is responsible for handling the given key.\n        \"\"\"\n        # If multiple instances are not defined we always return true\n        if not self.instances or len(self.instances) == 1:\n            return True\n\n        return self.get_instance(key) == instance_name\n\n    def get_instance(self, key: str) -> str:\n        \"\"\"Get the instance responsible for handling the given key.\n\n        Note: For things like federation sending the config for which instance\n        is sending is known only to the sender instance if there is only one.\n        Therefore `should_handle` should be used where possible.\n        \"\"\"\n\n        if not self.instances:\n            return \"master\"\n\n        if len(self.instances) == 1:\n            return self.instances[0]\n\n        # We shard by taking the hash, modulo it by the number of instances and\n        # then checking whether this instance matches the instance at that\n        # index.\n        #\n        # (Technically this introduces some bias and is not entirely uniform,\n        # but since the hash is so large the bias is ridiculously small).\n        dest_hash = sha256(key.encode(\"utf8\")).digest()\n        dest_int = int.from_bytes(dest_hash, byteorder=\"little\")\n        remainder = dest_int % (len(self.instances))\n        return self.instances[remainder]\n\n\n__all__ = [\"Config\", \"RootConfig\", \"ShardedWorkerHandlingConfig\"]\n", "code_before": "# -*- coding: utf-8 -*-\n# Copyright 2014-2016 OpenMarket Ltd\n# Copyright 2017-2018 New Vector Ltd\n# Copyright 2019 The Matrix.org Foundation C.I.C.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport argparse\nimport errno\nimport os\nimport time\nimport urllib.parse\nfrom collections import OrderedDict\nfrom hashlib import sha256\nfrom textwrap import dedent\nfrom typing import Any, Callable, Iterable, List, MutableMapping, Optional\n\nimport attr\nimport jinja2\nimport pkg_resources\nimport yaml\n\n\nclass ConfigError(Exception):\n    \"\"\"Represents a problem parsing the configuration\n\n    Args:\n        msg:  A textual description of the error.\n        path: Where appropriate, an indication of where in the configuration\n           the problem lies.\n    \"\"\"\n\n    def __init__(self, msg: str, path: Optional[Iterable[str]] = None):\n        self.msg = msg\n        self.path = path\n\n\n# We split these messages out to allow packages to override with package\n# specific instructions.\nMISSING_REPORT_STATS_CONFIG_INSTRUCTIONS = \"\"\"\\\nPlease opt in or out of reporting anonymized homeserver usage statistics, by\nsetting the `report_stats` key in your config file to either True or False.\n\"\"\"\n\nMISSING_REPORT_STATS_SPIEL = \"\"\"\\\nWe would really appreciate it if you could help our project out by reporting\nanonymized usage statistics from your homeserver. Only very basic aggregate\ndata (e.g. number of users) will be reported, but it helps us to track the\ngrowth of the Matrix community, and helps us to make Matrix a success, as well\nas to convince other networks that they should peer with us.\n\nThank you.\n\"\"\"\n\nMISSING_SERVER_NAME = \"\"\"\\\nMissing mandatory `server_name` config option.\n\"\"\"\n\n\nCONFIG_FILE_HEADER = \"\"\"\\\n# Configuration file for Synapse.\n#\n# This is a YAML file: see [1] for a quick introduction. Note in particular\n# that *indentation is important*: all the elements of a list or dictionary\n# should have the same indentation.\n#\n# [1] https://docs.ansible.com/ansible/latest/reference_appendices/YAMLSyntax.html\n\n\"\"\"\n\n\ndef path_exists(file_path):\n    \"\"\"Check if a file exists\n\n    Unlike os.path.exists, this throws an exception if there is an error\n    checking if the file exists (for example, if there is a perms error on\n    the parent dir).\n\n    Returns:\n        bool: True if the file exists; False if not.\n    \"\"\"\n    try:\n        os.stat(file_path)\n        return True\n    except OSError as e:\n        if e.errno != errno.ENOENT:\n            raise e\n        return False\n\n\nclass Config:\n    \"\"\"\n    A configuration section, containing configuration keys and values.\n\n    Attributes:\n        section (str): The section title of this config object, such as\n            \"tls\" or \"logger\". This is used to refer to it on the root\n            logger (for example, `config.tls.some_option`). Must be\n            defined in subclasses.\n    \"\"\"\n\n    section = None\n\n    def __init__(self, root_config=None):\n        self.root = root_config\n\n        # Get the path to the default Synapse template directory\n        self.default_template_dir = pkg_resources.resource_filename(\n            \"synapse\", \"res/templates\"\n        )\n\n    def __getattr__(self, item: str) -> Any:\n        \"\"\"\n        Try and fetch a configuration option that does not exist on this class.\n\n        This is so that existing configs that rely on `self.value`, where value\n        is actually from a different config section, continue to work.\n        \"\"\"\n        if item in [\"generate_config_section\", \"read_config\"]:\n            raise AttributeError(item)\n\n        if self.root is None:\n            raise AttributeError(item)\n        else:\n            return self.root._get_unclassed_config(self.section, item)\n\n    @staticmethod\n    def parse_size(value):\n        if isinstance(value, int):\n            return value\n        sizes = {\"K\": 1024, \"M\": 1024 * 1024}\n        size = 1\n        suffix = value[-1]\n        if suffix in sizes:\n            value = value[:-1]\n            size = sizes[suffix]\n        return int(value) * size\n\n    @staticmethod\n    def parse_duration(value):\n        if isinstance(value, int):\n            return value\n        second = 1000\n        minute = 60 * second\n        hour = 60 * minute\n        day = 24 * hour\n        week = 7 * day\n        year = 365 * day\n        sizes = {\"s\": second, \"m\": minute, \"h\": hour, \"d\": day, \"w\": week, \"y\": year}\n        size = 1\n        suffix = value[-1]\n        if suffix in sizes:\n            value = value[:-1]\n            size = sizes[suffix]\n        return int(value) * size\n\n    @staticmethod\n    def abspath(file_path):\n        return os.path.abspath(file_path) if file_path else file_path\n\n    @classmethod\n    def path_exists(cls, file_path):\n        return path_exists(file_path)\n\n    @classmethod\n    def check_file(cls, file_path, config_name):\n        if file_path is None:\n            raise ConfigError(\"Missing config for %s.\" % (config_name,))\n        try:\n            os.stat(file_path)\n        except OSError as e:\n            raise ConfigError(\n                \"Error accessing file '%s' (config for %s): %s\"\n                % (file_path, config_name, e.strerror)\n            )\n        return cls.abspath(file_path)\n\n    @classmethod\n    def ensure_directory(cls, dir_path):\n        dir_path = cls.abspath(dir_path)\n        try:\n            os.makedirs(dir_path)\n        except OSError as e:\n            if e.errno != errno.EEXIST:\n                raise\n        if not os.path.isdir(dir_path):\n            raise ConfigError(\"%s is not a directory\" % (dir_path,))\n        return dir_path\n\n    @classmethod\n    def read_file(cls, file_path, config_name):\n        cls.check_file(file_path, config_name)\n        with open(file_path) as file_stream:\n            return file_stream.read()\n\n    def read_templates(\n        self,\n        filenames: List[str],\n        custom_template_directory: Optional[str] = None,\n        autoescape: bool = False,\n    ) -> List[jinja2.Template]:\n        \"\"\"Load a list of template files from disk using the given variables.\n\n        This function will attempt to load the given templates from the default Synapse\n        template directory. If `custom_template_directory` is supplied, that directory\n        is tried first.\n\n        Files read are treated as Jinja templates. These templates are not rendered yet.\n\n        Args:\n            filenames: A list of template filenames to read.\n\n            custom_template_directory: A directory to try to look for the templates\n                before using the default Synapse template directory instead.\n\n            autoescape: Whether to autoescape variables before inserting them into the\n                template.\n\n        Raises:\n            ConfigError: if the file's path is incorrect or otherwise cannot be read.\n\n        Returns:\n            A list of jinja2 templates.\n        \"\"\"\n        templates = []\n        search_directories = [self.default_template_dir]\n\n        # The loader will first look in the custom template directory (if specified) for the\n        # given filename. If it doesn't find it, it will use the default template dir instead\n        if custom_template_directory:\n            # Check that the given template directory exists\n            if not self.path_exists(custom_template_directory):\n                raise ConfigError(\n                    \"Configured template directory does not exist: %s\"\n                    % (custom_template_directory,)\n                )\n\n            # Search the custom template directory as well\n            search_directories.insert(0, custom_template_directory)\n\n        loader = jinja2.FileSystemLoader(search_directories)\n        env = jinja2.Environment(loader=loader, autoescape=autoescape)\n\n        # Update the environment with our custom filters\n        env.filters.update(\n            {\n                \"format_ts\": _format_ts_filter,\n                \"mxc_to_http\": _create_mxc_to_http_filter(self.public_baseurl),\n            }\n        )\n\n        for filename in filenames:\n            # Load the template\n            template = env.get_template(filename)\n            templates.append(template)\n\n        return templates\n\n\ndef _format_ts_filter(value: int, format: str):\n    return time.strftime(format, time.localtime(value / 1000))\n\n\ndef _create_mxc_to_http_filter(public_baseurl: str) -> Callable:\n    \"\"\"Create and return a jinja2 filter that converts MXC urls to HTTP\n\n    Args:\n        public_baseurl: The public, accessible base URL of the homeserver\n    \"\"\"\n\n    def mxc_to_http_filter(value, width, height, resize_method=\"crop\"):\n        if value[0:6] != \"mxc://\":\n            return \"\"\n\n        server_and_media_id = value[6:]\n        fragment = None\n        if \"#\" in server_and_media_id:\n            server_and_media_id, fragment = server_and_media_id.split(\"#\", 1)\n            fragment = \"#\" + fragment\n\n        params = {\"width\": width, \"height\": height, \"method\": resize_method}\n        return \"%s_matrix/media/v1/thumbnail/%s?%s%s\" % (\n            public_baseurl,\n            server_and_media_id,\n            urllib.parse.urlencode(params),\n            fragment or \"\",\n        )\n\n    return mxc_to_http_filter\n\n\nclass RootConfig:\n    \"\"\"\n    Holder of an application's configuration.\n\n    What configuration this object holds is defined by `config_classes`, a list\n    of Config classes that will be instantiated and given the contents of a\n    configuration file to read. They can then be accessed on this class by their\n    section name, defined in the Config or dynamically set to be the name of the\n    class, lower-cased and with \"Config\" removed.\n    \"\"\"\n\n    config_classes = []\n\n    def __init__(self):\n        self._configs = OrderedDict()\n\n        for config_class in self.config_classes:\n            if config_class.section is None:\n                raise ValueError(\"%r requires a section name\" % (config_class,))\n\n            try:\n                conf = config_class(self)\n            except Exception as e:\n                raise Exception(\"Failed making %s: %r\" % (config_class.section, e))\n            self._configs[config_class.section] = conf\n\n    def __getattr__(self, item: str) -> Any:\n        \"\"\"\n        Redirect lookups on this object either to config objects, or values on\n        config objects, so that `config.tls.blah` works, as well as legacy uses\n        of things like `config.server_name`. It will first look up the config\n        section name, and then values on those config classes.\n        \"\"\"\n        if item in self._configs.keys():\n            return self._configs[item]\n\n        return self._get_unclassed_config(None, item)\n\n    def _get_unclassed_config(self, asking_section: Optional[str], item: str):\n        \"\"\"\n        Fetch a config value from one of the instantiated config classes that\n        has not been fetched directly.\n\n        Args:\n            asking_section: If this check is coming from a Config child, which\n                one? This section will not be asked if it has the value.\n            item: The configuration value key.\n\n        Raises:\n            AttributeError if no config classes have the config key. The body\n                will contain what sections were checked.\n        \"\"\"\n        for key, val in self._configs.items():\n            if key == asking_section:\n                continue\n\n            if item in dir(val):\n                return getattr(val, item)\n\n        raise AttributeError(item, \"not found in %s\" % (list(self._configs.keys()),))\n\n    def invoke_all(self, func_name: str, *args, **kwargs) -> MutableMapping[str, Any]:\n        \"\"\"\n        Invoke a function on all instantiated config objects this RootConfig is\n        configured to use.\n\n        Args:\n            func_name: Name of function to invoke\n            *args\n            **kwargs\n        Returns:\n            ordered dictionary of config section name and the result of the\n            function from it.\n        \"\"\"\n        res = OrderedDict()\n\n        for name, config in self._configs.items():\n            if hasattr(config, func_name):\n                res[name] = getattr(config, func_name)(*args, **kwargs)\n\n        return res\n\n    @classmethod\n    def invoke_all_static(cls, func_name: str, *args, **kwargs):\n        \"\"\"\n        Invoke a static function on config objects this RootConfig is\n        configured to use.\n\n        Args:\n            func_name: Name of function to invoke\n            *args\n            **kwargs\n        Returns:\n            ordered dictionary of config section name and the result of the\n            function from it.\n        \"\"\"\n        for config in cls.config_classes:\n            if hasattr(config, func_name):\n                getattr(config, func_name)(*args, **kwargs)\n\n    def generate_config(\n        self,\n        config_dir_path,\n        data_dir_path,\n        server_name,\n        generate_secrets=False,\n        report_stats=None,\n        open_private_ports=False,\n        listeners=None,\n        tls_certificate_path=None,\n        tls_private_key_path=None,\n        acme_domain=None,\n    ):\n        \"\"\"\n        Build a default configuration file\n\n        This is used when the user explicitly asks us to generate a config file\n        (eg with --generate_config).\n\n        Args:\n            config_dir_path (str): The path where the config files are kept. Used to\n                create filenames for things like the log config and the signing key.\n\n            data_dir_path (str): The path where the data files are kept. Used to create\n                filenames for things like the database and media store.\n\n            server_name (str): The server name. Used to initialise the server_name\n                config param, but also used in the names of some of the config files.\n\n            generate_secrets (bool): True if we should generate new secrets for things\n                like the macaroon_secret_key. If False, these parameters will be left\n                unset.\n\n            report_stats (bool|None): Initial setting for the report_stats setting.\n                If None, report_stats will be left unset.\n\n            open_private_ports (bool): True to leave private ports (such as the non-TLS\n                HTTP listener) open to the internet.\n\n            listeners (list(dict)|None): A list of descriptions of the listeners\n                synapse should start with each of which specifies a port (str), a list of\n                resources (list(str)), tls (bool) and type (str). For example:\n                [{\n                    \"port\": 8448,\n                    \"resources\": [{\"names\": [\"federation\"]}],\n                    \"tls\": True,\n                    \"type\": \"http\",\n                },\n                {\n                    \"port\": 443,\n                    \"resources\": [{\"names\": [\"client\"]}],\n                    \"tls\": False,\n                    \"type\": \"http\",\n                }],\n\n\n            database (str|None): The database type to configure, either `psycog2`\n                or `sqlite3`.\n\n            tls_certificate_path (str|None): The path to the tls certificate.\n\n            tls_private_key_path (str|None): The path to the tls private key.\n\n            acme_domain (str|None): The domain acme will try to validate. If\n                specified acme will be enabled.\n\n        Returns:\n            str: the yaml config file\n        \"\"\"\n\n        return CONFIG_FILE_HEADER + \"\\n\\n\".join(\n            dedent(conf)\n            for conf in self.invoke_all(\n                \"generate_config_section\",\n                config_dir_path=config_dir_path,\n                data_dir_path=data_dir_path,\n                server_name=server_name,\n                generate_secrets=generate_secrets,\n                report_stats=report_stats,\n                open_private_ports=open_private_ports,\n                listeners=listeners,\n                tls_certificate_path=tls_certificate_path,\n                tls_private_key_path=tls_private_key_path,\n                acme_domain=acme_domain,\n            ).values()\n        )\n\n    @classmethod\n    def load_config(cls, description, argv):\n        \"\"\"Parse the commandline and config files\n\n        Doesn't support config-file-generation: used by the worker apps.\n\n        Returns: Config object.\n        \"\"\"\n        config_parser = argparse.ArgumentParser(description=description)\n        cls.add_arguments_to_parser(config_parser)\n        obj, _ = cls.load_config_with_parser(config_parser, argv)\n\n        return obj\n\n    @classmethod\n    def add_arguments_to_parser(cls, config_parser):\n        \"\"\"Adds all the config flags to an ArgumentParser.\n\n        Doesn't support config-file-generation: used by the worker apps.\n\n        Used for workers where we want to add extra flags/subcommands.\n\n        Args:\n            config_parser (ArgumentParser): App description\n        \"\"\"\n\n        config_parser.add_argument(\n            \"-c\",\n            \"--config-path\",\n            action=\"append\",\n            metavar=\"CONFIG_FILE\",\n            help=\"Specify config file. Can be given multiple times and\"\n            \" may specify directories containing *.yaml files.\",\n        )\n\n        config_parser.add_argument(\n            \"--keys-directory\",\n            metavar=\"DIRECTORY\",\n            help=\"Where files such as certs and signing keys are stored when\"\n            \" their location is not given explicitly in the config.\"\n            \" Defaults to the directory containing the last config file\",\n        )\n\n        cls.invoke_all_static(\"add_arguments\", config_parser)\n\n    @classmethod\n    def load_config_with_parser(cls, parser, argv):\n        \"\"\"Parse the commandline and config files with the given parser\n\n        Doesn't support config-file-generation: used by the worker apps.\n\n        Used for workers where we want to add extra flags/subcommands.\n\n        Args:\n            parser (ArgumentParser)\n            argv (list[str])\n\n        Returns:\n            tuple[HomeServerConfig, argparse.Namespace]: Returns the parsed\n            config object and the parsed argparse.Namespace object from\n            `parser.parse_args(..)`\n        \"\"\"\n\n        obj = cls()\n\n        config_args = parser.parse_args(argv)\n\n        config_files = find_config_files(search_paths=config_args.config_path)\n\n        if not config_files:\n            parser.error(\"Must supply a config file.\")\n\n        if config_args.keys_directory:\n            config_dir_path = config_args.keys_directory\n        else:\n            config_dir_path = os.path.dirname(config_files[-1])\n        config_dir_path = os.path.abspath(config_dir_path)\n        data_dir_path = os.getcwd()\n\n        config_dict = read_config_files(config_files)\n        obj.parse_config_dict(\n            config_dict, config_dir_path=config_dir_path, data_dir_path=data_dir_path\n        )\n\n        obj.invoke_all(\"read_arguments\", config_args)\n\n        return obj, config_args\n\n    @classmethod\n    def load_or_generate_config(cls, description, argv):\n        \"\"\"Parse the commandline and config files\n\n        Supports generation of config files, so is used for the main homeserver app.\n\n        Returns: Config object, or None if --generate-config or --generate-keys was set\n        \"\"\"\n        parser = argparse.ArgumentParser(description=description)\n        parser.add_argument(\n            \"-c\",\n            \"--config-path\",\n            action=\"append\",\n            metavar=\"CONFIG_FILE\",\n            help=\"Specify config file. Can be given multiple times and\"\n            \" may specify directories containing *.yaml files.\",\n        )\n\n        generate_group = parser.add_argument_group(\"Config generation\")\n        generate_group.add_argument(\n            \"--generate-config\",\n            action=\"store_true\",\n            help=\"Generate a config file, then exit.\",\n        )\n        generate_group.add_argument(\n            \"--generate-missing-configs\",\n            \"--generate-keys\",\n            action=\"store_true\",\n            help=\"Generate any missing additional config files, then exit.\",\n        )\n        generate_group.add_argument(\n            \"-H\", \"--server-name\", help=\"The server name to generate a config file for.\"\n        )\n        generate_group.add_argument(\n            \"--report-stats\",\n            action=\"store\",\n            help=\"Whether the generated config reports anonymized usage statistics.\",\n            choices=[\"yes\", \"no\"],\n        )\n        generate_group.add_argument(\n            \"--config-directory\",\n            \"--keys-directory\",\n            metavar=\"DIRECTORY\",\n            help=(\n                \"Specify where additional config files such as signing keys and log\"\n                \" config should be stored. Defaults to the same directory as the last\"\n                \" config file.\"\n            ),\n        )\n        generate_group.add_argument(\n            \"--data-directory\",\n            metavar=\"DIRECTORY\",\n            help=(\n                \"Specify where data such as the media store and database file should be\"\n                \" stored. Defaults to the current working directory.\"\n            ),\n        )\n        generate_group.add_argument(\n            \"--open-private-ports\",\n            action=\"store_true\",\n            help=(\n                \"Leave private ports (such as the non-TLS HTTP listener) open to the\"\n                \" internet. Do not use this unless you know what you are doing.\"\n            ),\n        )\n\n        cls.invoke_all_static(\"add_arguments\", parser)\n        config_args = parser.parse_args(argv)\n\n        config_files = find_config_files(search_paths=config_args.config_path)\n\n        if not config_files:\n            parser.error(\n                \"Must supply a config file.\\nA config file can be automatically\"\n                ' generated using \"--generate-config -H SERVER_NAME'\n                ' -c CONFIG-FILE\"'\n            )\n\n        if config_args.config_directory:\n            config_dir_path = config_args.config_directory\n        else:\n            config_dir_path = os.path.dirname(config_files[-1])\n        config_dir_path = os.path.abspath(config_dir_path)\n        data_dir_path = os.getcwd()\n\n        generate_missing_configs = config_args.generate_missing_configs\n\n        obj = cls()\n\n        if config_args.generate_config:\n            if config_args.report_stats is None:\n                parser.error(\n                    \"Please specify either --report-stats=yes or --report-stats=no\\n\\n\"\n                    + MISSING_REPORT_STATS_SPIEL\n                )\n\n            (config_path,) = config_files\n            if not path_exists(config_path):\n                print(\"Generating config file %s\" % (config_path,))\n\n                if config_args.data_directory:\n                    data_dir_path = config_args.data_directory\n                else:\n                    data_dir_path = os.getcwd()\n                data_dir_path = os.path.abspath(data_dir_path)\n\n                server_name = config_args.server_name\n                if not server_name:\n                    raise ConfigError(\n                        \"Must specify a server_name to a generate config for.\"\n                        \" Pass -H server.name.\"\n                    )\n\n                config_str = obj.generate_config(\n                    config_dir_path=config_dir_path,\n                    data_dir_path=data_dir_path,\n                    server_name=server_name,\n                    report_stats=(config_args.report_stats == \"yes\"),\n                    generate_secrets=True,\n                    open_private_ports=config_args.open_private_ports,\n                )\n\n                if not path_exists(config_dir_path):\n                    os.makedirs(config_dir_path)\n                with open(config_path, \"w\") as config_file:\n                    config_file.write(config_str)\n                    config_file.write(\"\\n\\n# vim:ft=yaml\")\n\n                config_dict = yaml.safe_load(config_str)\n                obj.generate_missing_files(config_dict, config_dir_path)\n\n                print(\n                    (\n                        \"A config file has been generated in %r for server name\"\n                        \" %r. Please review this file and customise it\"\n                        \" to your needs.\"\n                    )\n                    % (config_path, server_name)\n                )\n                return\n            else:\n                print(\n                    (\n                        \"Config file %r already exists. Generating any missing config\"\n                        \" files.\"\n                    )\n                    % (config_path,)\n                )\n                generate_missing_configs = True\n\n        config_dict = read_config_files(config_files)\n        if generate_missing_configs:\n            obj.generate_missing_files(config_dict, config_dir_path)\n            return None\n\n        obj.parse_config_dict(\n            config_dict, config_dir_path=config_dir_path, data_dir_path=data_dir_path\n        )\n        obj.invoke_all(\"read_arguments\", config_args)\n\n        return obj\n\n    def parse_config_dict(self, config_dict, config_dir_path=None, data_dir_path=None):\n        \"\"\"Read the information from the config dict into this Config object.\n\n        Args:\n            config_dict (dict): Configuration data, as read from the yaml\n\n            config_dir_path (str): The path where the config files are kept. Used to\n                create filenames for things like the log config and the signing key.\n\n            data_dir_path (str): The path where the data files are kept. Used to create\n                filenames for things like the database and media store.\n        \"\"\"\n        self.invoke_all(\n            \"read_config\",\n            config_dict,\n            config_dir_path=config_dir_path,\n            data_dir_path=data_dir_path,\n        )\n\n    def generate_missing_files(self, config_dict, config_dir_path):\n        self.invoke_all(\"generate_files\", config_dict, config_dir_path)\n\n\ndef read_config_files(config_files):\n    \"\"\"Read the config files into a dict\n\n    Args:\n        config_files (iterable[str]): A list of the config files to read\n\n    Returns: dict\n    \"\"\"\n    specified_config = {}\n    for config_file in config_files:\n        with open(config_file) as file_stream:\n            yaml_config = yaml.safe_load(file_stream)\n\n        if not isinstance(yaml_config, dict):\n            err = \"File %r is empty or doesn't parse into a key-value map. IGNORING.\"\n            print(err % (config_file,))\n            continue\n\n        specified_config.update(yaml_config)\n\n    if \"server_name\" not in specified_config:\n        raise ConfigError(MISSING_SERVER_NAME)\n\n    if \"report_stats\" not in specified_config:\n        raise ConfigError(\n            MISSING_REPORT_STATS_CONFIG_INSTRUCTIONS + \"\\n\" + MISSING_REPORT_STATS_SPIEL\n        )\n    return specified_config\n\n\ndef find_config_files(search_paths):\n    \"\"\"Finds config files using a list of search paths. If a path is a file\n    then that file path is added to the list. If a search path is a directory\n    then all the \"*.yaml\" files in that directory are added to the list in\n    sorted order.\n\n    Args:\n        search_paths(list(str)): A list of paths to search.\n\n    Returns:\n        list(str): A list of file paths.\n    \"\"\"\n\n    config_files = []\n    if search_paths:\n        for config_path in search_paths:\n            if os.path.isdir(config_path):\n                # We accept specifying directories as config paths, we search\n                # inside that directory for all files matching *.yaml, and then\n                # we apply them in *sorted* order.\n                files = []\n                for entry in os.listdir(config_path):\n                    entry_path = os.path.join(config_path, entry)\n                    if not os.path.isfile(entry_path):\n                        err = \"Found subdirectory in config directory: %r. IGNORING.\"\n                        print(err % (entry_path,))\n                        continue\n\n                    if not entry.endswith(\".yaml\"):\n                        err = (\n                            \"Found file in config directory that does not end in \"\n                            \"'.yaml': %r. IGNORING.\"\n                        )\n                        print(err % (entry_path,))\n                        continue\n\n                    files.append(entry_path)\n\n                config_files.extend(sorted(files))\n            else:\n                config_files.append(config_path)\n    return config_files\n\n\n@attr.s\nclass ShardedWorkerHandlingConfig:\n    \"\"\"Algorithm for choosing which instance is responsible for handling some\n    sharded work.\n\n    For example, the federation senders use this to determine which instances\n    handles sending stuff to a given destination (which is used as the `key`\n    below).\n    \"\"\"\n\n    instances = attr.ib(type=List[str])\n\n    def should_handle(self, instance_name: str, key: str) -> bool:\n        \"\"\"Whether this instance is responsible for handling the given key.\n        \"\"\"\n        # If multiple instances are not defined we always return true\n        if not self.instances or len(self.instances) == 1:\n            return True\n\n        return self.get_instance(key) == instance_name\n\n    def get_instance(self, key: str) -> str:\n        \"\"\"Get the instance responsible for handling the given key.\n\n        Note: For things like federation sending the config for which instance\n        is sending is known only to the sender instance if there is only one.\n        Therefore `should_handle` should be used where possible.\n        \"\"\"\n\n        if not self.instances:\n            return \"master\"\n\n        if len(self.instances) == 1:\n            return self.instances[0]\n\n        # We shard by taking the hash, modulo it by the number of instances and\n        # then checking whether this instance matches the instance at that\n        # index.\n        #\n        # (Technically this introduces some bias and is not entirely uniform,\n        # but since the hash is so large the bias is ridiculously small).\n        dest_hash = sha256(key.encode(\"utf8\")).digest()\n        dest_int = int.from_bytes(dest_hash, byteorder=\"little\")\n        remainder = dest_int % (len(self.instances))\n        return self.instances[remainder]\n\n\n__all__ = [\"Config\", \"RootConfig\", \"ShardedWorkerHandlingConfig\"]\n", "patch": "@@ -203,36 +203,50 @@ def read_file(cls, file_path, config_name):\n         with open(file_path) as file_stream:\n             return file_stream.read()\n \n+    def read_template(self, filename: str) -> jinja2.Template:\n+        \"\"\"Load a template file from disk.\n+\n+        This function will attempt to load the given template from the default Synapse\n+        template directory.\n+\n+        Files read are treated as Jinja templates. The templates is not rendered yet\n+        and has autoescape enabled.\n+\n+        Args:\n+            filename: A template filename to read.\n+\n+        Raises:\n+            ConfigError: if the file's path is incorrect or otherwise cannot be read.\n+\n+        Returns:\n+            A jinja2 template.\n+        \"\"\"\n+        return self.read_templates([filename])[0]\n+\n     def read_templates(\n-        self,\n-        filenames: List[str],\n-        custom_template_directory: Optional[str] = None,\n-        autoescape: bool = False,\n+        self, filenames: List[str], custom_template_directory: Optional[str] = None,\n     ) -> List[jinja2.Template]:\n         \"\"\"Load a list of template files from disk using the given variables.\n \n         This function will attempt to load the given templates from the default Synapse\n         template directory. If `custom_template_directory` is supplied, that directory\n         is tried first.\n \n-        Files read are treated as Jinja templates. These templates are not rendered yet.\n+        Files read are treated as Jinja templates. The templates are not rendered yet\n+        and have autoescape enabled.\n \n         Args:\n             filenames: A list of template filenames to read.\n \n             custom_template_directory: A directory to try to look for the templates\n                 before using the default Synapse template directory instead.\n \n-            autoescape: Whether to autoescape variables before inserting them into the\n-                template.\n-\n         Raises:\n             ConfigError: if the file's path is incorrect or otherwise cannot be read.\n \n         Returns:\n             A list of jinja2 templates.\n         \"\"\"\n-        templates = []\n         search_directories = [self.default_template_dir]\n \n         # The loader will first look in the custom template directory (if specified) for the\n@@ -249,7 +263,7 @@ def read_templates(\n             search_directories.insert(0, custom_template_directory)\n \n         loader = jinja2.FileSystemLoader(search_directories)\n-        env = jinja2.Environment(loader=loader, autoescape=autoescape)\n+        env = jinja2.Environment(loader=loader, autoescape=jinja2.select_autoescape(),)\n \n         # Update the environment with our custom filters\n         env.filters.update(\n@@ -259,12 +273,8 @@ def read_templates(\n             }\n         )\n \n-        for filename in filenames:\n-            # Load the template\n-            template = env.get_template(filename)\n-            templates.append(template)\n-\n-        return templates\n+        # Load the templates\n+        return [env.get_template(filename) for filename in filenames]\n \n \n def _format_ts_filter(value: int, format: str):", "file_path": "files/2021_3/64", "file_language": "py", "file_name": "synapse/config/_base.py", "outdated_file_modify": 0, "outdated_file_before": 0, "outdated_file_after": 0, "llm_check": 1, "static_check": 1, "static": {"rats": [false, []], "semgrep": [true, ["       python.flask.security.xss.audit.direct-use-of-jinja2.direct-use-of-jinja2                     \n          Detected direct use of jinja2. If not done properly, this may bypass HTML escaping which   \n          opens up the application to cross-site scripting (XSS) vulnerabilities. Prefer using the   \n          Flask method 'render_template()' and templates with a '.html' extension in order to prevent\n          XSS.                                                                                       \n          Details: https://sg.run/RoKe                                                               \n          252\u2506 env = jinja2.Environment(loader=loader, autoescape=autoescape)"]]}, "target": 1, "function_before": [{"function": "class ConfigError(Exception):\n    \"\"\"Represents a problem parsing the configuration\n\n    Args:\n        msg:  A textual description of the error.\n        path: Where appropriate, an indication of where in the configuration\n           the problem lies.\n    \"\"\"\n\n    def __init__(self, msg: str, path: Optional[Iterable[str]] = None):\n        self.msg = msg\n        self.path = path", "target": 0}, {"function": "def path_exists(file_path):\n    \"\"\"Check if a file exists\n\n    Unlike os.path.exists, this throws an exception if there is an error\n    checking if the file exists (for example, if there is a perms error on\n    the parent dir).\n\n    Returns:\n        bool: True if the file exists; False if not.\n    \"\"\"\n    try:\n        os.stat(file_path)\n        return True\n    except OSError as e:\n        if e.errno != errno.ENOENT:\n            raise e\n        return False", "target": 0}, {"function": "class Config:\n    \"\"\"\n    A configuration section, containing configuration keys and values.\n\n    Attributes:\n        section (str): The section title of this config object, such as\n            \"tls\" or \"logger\". This is used to refer to it on the root\n            logger (for example, `config.tls.some_option`). Must be\n            defined in subclasses.\n    \"\"\"\n\n    section = None\n\n    def __init__(self, root_config=None):\n        self.root = root_config\n\n        # Get the path to the default Synapse template directory\n        self.default_template_dir = pkg_resources.resource_filename(\n            \"synapse\", \"res/templates\"\n        )\n\n    def __getattr__(self, item: str) -> Any:\n        \"\"\"\n        Try and fetch a configuration option that does not exist on this class.\n\n        This is so that existing configs that rely on `self.value`, where value\n        is actually from a different config section, continue to work.\n        \"\"\"\n        if item in [\"generate_config_section\", \"read_config\"]:\n            raise AttributeError(item)\n\n        if self.root is None:\n            raise AttributeError(item)\n        else:\n            return self.root._get_unclassed_config(self.section, item)\n\n    @staticmethod\n    def parse_size(value):\n        if isinstance(value, int):\n            return value\n        sizes = {\"K\": 1024, \"M\": 1024 * 1024}\n        size = 1\n        suffix = value[-1]\n        if suffix in sizes:\n            value = value[:-1]\n            size = sizes[suffix]\n        return int(value) * size\n\n    @staticmethod\n    def parse_duration(value):\n        if isinstance(value, int):\n            return value\n        second = 1000\n        minute = 60 * second\n        hour = 60 * minute\n        day = 24 * hour\n        week = 7 * day\n        year = 365 * day\n        sizes = {\"s\": second, \"m\": minute, \"h\": hour, \"d\": day, \"w\": week, \"y\": year}\n        size = 1\n        suffix = value[-1]\n        if suffix in sizes:\n            value = value[:-1]\n            size = sizes[suffix]\n        return int(value) * size\n\n    @staticmethod\n    def abspath(file_path):\n        return os.path.abspath(file_path) if file_path else file_path\n\n    @classmethod\n    def path_exists(cls, file_path):\n        return path_exists(file_path)\n\n    @classmethod\n    def check_file(cls, file_path, config_name):\n        if file_path is None:\n            raise ConfigError(\"Missing config for %s.\" % (config_name,))\n        try:\n            os.stat(file_path)\n        except OSError as e:\n            raise ConfigError(\n                \"Error accessing file '%s' (config for %s): %s\"\n                % (file_path, config_name, e.strerror)\n            )\n        return cls.abspath(file_path)\n\n    @classmethod\n    def ensure_directory(cls, dir_path):\n        dir_path = cls.abspath(dir_path)\n        try:\n            os.makedirs(dir_path)\n        except OSError as e:\n            if e.errno != errno.EEXIST:\n                raise\n        if not os.path.isdir(dir_path):\n            raise ConfigError(\"%s is not a directory\" % (dir_path,))\n        return dir_path\n\n    @classmethod\n    def read_file(cls, file_path, config_name):\n        cls.check_file(file_path, config_name)\n        with open(file_path) as file_stream:\n            return file_stream.read()\n\n    def read_templates(\n        self,\n        filenames: List[str],\n        custom_template_directory: Optional[str] = None,\n        autoescape: bool = False,\n    ) -> List[jinja2.Template]:\n        \"\"\"Load a list of template files from disk using the given variables.\n\n        This function will attempt to load the given templates from the default Synapse\n        template directory. If `custom_template_directory` is supplied, that directory\n        is tried first.\n\n        Files read are treated as Jinja templates. These templates are not rendered yet.\n\n        Args:\n            filenames: A list of template filenames to read.\n\n            custom_template_directory: A directory to try to look for the templates\n                before using the default Synapse template directory instead.\n\n            autoescape: Whether to autoescape variables before inserting them into the\n                template.\n\n        Raises:\n            ConfigError: if the file's path is incorrect or otherwise cannot be read.\n\n        Returns:\n            A list of jinja2 templates.\n        \"\"\"\n        templates = []\n        search_directories = [self.default_template_dir]\n\n        # The loader will first look in the custom template directory (if specified) for the\n        # given filename. If it doesn't find it, it will use the default template dir instead\n        if custom_template_directory:\n            # Check that the given template directory exists\n            if not self.path_exists(custom_template_directory):\n                raise ConfigError(\n                    \"Configured template directory does not exist: %s\"\n                    % (custom_template_directory,)\n                )\n\n            # Search the custom template directory as well\n            search_directories.insert(0, custom_template_directory)\n\n        loader = jinja2.FileSystemLoader(search_directories)\n        env = jinja2.Environment(loader=loader, autoescape=autoescape)\n\n        # Update the environment with our custom filters\n        env.filters.update(\n            {\n                \"format_ts\": _format_ts_filter,\n                \"mxc_to_http\": _create_mxc_to_http_filter(self.public_baseurl),\n            }\n        )\n\n        for filename in filenames:\n            # Load the template\n            template = env.get_template(filename)\n            templates.append(template)\n\n        return templates", "target": 1, "line": "@@  -203,36 +203,50  @@ def read_file(cls, file_path, config_name):\n         with open(file_path) as file_stream:\n             return file_stream.read()\n \n+    def read_template(self, filename: str) -> jinja2.Template:\n+        \"\"\"Load a template file from disk.\n+\n+        This function will attempt to load the given template from the default Synapse\n+        template directory.\n+\n+        Files read are treated as Jinja templates. The templates is not rendered yet\n+        and has autoescape enabled.\n+\n+        Args:\n+            filename: A template filename to read.\n+\n+        Raises:\n+            ConfigError: if the file's path is incorrect or otherwise cannot be read.\n+\n+        Returns:\n+            A jinja2 template.\n+        \"\"\"\n+        return self.read_templates([filename])[0]\n+\n     def read_templates(\n-        self,\n-        filenames: List[str],\n-        custom_template_directory: Optional[str] = None,\n-        autoescape: bool = False,\n+        self, filenames: List[str], custom_template_directory: Optional[str] = None,\n     ) -> List[jinja2.Template]:\n         \"\"\"Load a list of template files from disk using the given variables.\n \n         This function will attempt to load the given templates from the default Synapse\n         template directory. If `custom_template_directory` is supplied, that directory\n         is tried first.\n \n-        Files read are treated as Jinja templates. These templates are not rendered yet.\n+        Files read are treated as Jinja templates. The templates are not rendered yet\n+        and have autoescape enabled.\n \n         Args:\n             filenames: A list of template filenames to read.\n \n             custom_template_directory: A directory to try to look for the templates\n                 before using the default Synapse template directory instead.\n \n-            autoescape: Whether to autoescape variables before inserting them into the\n-                template.\n-\n         Raises:\n             ConfigError: if the file's path is incorrect or otherwise cannot be read.\n \n         Returns:\n             A list of jinja2 templates.\n         \"\"\"\n-        templates = []\n         search_directories = [self.default_template_dir]\n \n         # The loader will first look in the custom template directory (if specified) for the\n@@  -249,7 +263,7  @@ def read_templates(\n             search_directories.insert(0, custom_template_directory)\n \n         loader = jinja2.FileSystemLoader(search_directories)\n-        env = jinja2.Environment(loader=loader, autoescape=autoescape)\n+        env = jinja2.Environment(loader=loader, autoescape=jinja2.select_autoescape(),)\n \n         # Update the environment with our custom filters\n         env.filters.update(\n@@  -259,12 +273,8  @@ def read_templates(\n             }\n         )\n \n-        for filename in filenames:\n-            # Load the template\n-            template = env.get_template(filename)\n-            templates.append(template)\n-\n-        return templates\n+        # Load the templates\n+        return [env.get_template(filename) for filename in filenames]\n \n \n def _format_ts_filter(value: int, format: str):"}, {"function": "def _format_ts_filter(value: int, format: str):\n    return time.strftime(format, time.localtime(value / 1000))", "target": 1, "line": "@@  -259,12 +273,8  @@ def read_templates(\n             }\n         )\n \n-        for filename in filenames:\n-            # Load the template\n-            template = env.get_template(filename)\n-            templates.append(template)\n-\n-        return templates\n+        # Load the templates\n+        return [env.get_template(filename) for filename in filenames]\n \n \n def _format_ts_filter(value: int, format: str):"}, {"function": "def _create_mxc_to_http_filter(public_baseurl: str) -> Callable:\n    \"\"\"Create and return a jinja2 filter that converts MXC urls to HTTP\n\n    Args:\n        public_baseurl: The public, accessible base URL of the homeserver\n    \"\"\"\n\n    def mxc_to_http_filter(value, width, height, resize_method=\"crop\"):\n        if value[0:6] != \"mxc://\":\n            return \"\"\n\n        server_and_media_id = value[6:]\n        fragment = None\n        if \"#\" in server_and_media_id:\n            server_and_media_id, fragment = server_and_media_id.split(\"#\", 1)\n            fragment = \"#\" + fragment\n\n        params = {\"width\": width, \"height\": height, \"method\": resize_method}\n        return \"%s_matrix/media/v1/thumbnail/%s?%s%s\" % (\n            public_baseurl,\n            server_and_media_id,\n            urllib.parse.urlencode(params),\n            fragment or \"\",\n        )\n\n    return mxc_to_http_filter", "target": 0}, {"function": "class RootConfig:\n    \"\"\"\n    Holder of an application's configuration.\n\n    What configuration this object holds is defined by `config_classes`, a list\n    of Config classes that will be instantiated and given the contents of a\n    configuration file to read. They can then be accessed on this class by their\n    section name, defined in the Config or dynamically set to be the name of the\n    class, lower-cased and with \"Config\" removed.\n    \"\"\"\n\n    config_classes = []\n\n    def __init__(self):\n        self._configs = OrderedDict()\n\n        for config_class in self.config_classes:\n            if config_class.section is None:\n                raise ValueError(\"%r requires a section name\" % (config_class,))\n\n            try:\n                conf = config_class(self)\n            except Exception as e:\n                raise Exception(\"Failed making %s: %r\" % (config_class.section, e))\n            self._configs[config_class.section] = conf\n\n    def __getattr__(self, item: str) -> Any:\n        \"\"\"\n        Redirect lookups on this object either to config objects, or values on\n        config objects, so that `config.tls.blah` works, as well as legacy uses\n        of things like `config.server_name`. It will first look up the config\n        section name, and then values on those config classes.\n        \"\"\"\n        if item in self._configs.keys():\n            return self._configs[item]\n\n        return self._get_unclassed_config(None, item)\n\n    def _get_unclassed_config(self, asking_section: Optional[str], item: str):\n        \"\"\"\n        Fetch a config value from one of the instantiated config classes that\n        has not been fetched directly.\n\n        Args:\n            asking_section: If this check is coming from a Config child, which\n                one? This section will not be asked if it has the value.\n            item: The configuration value key.\n\n        Raises:\n            AttributeError if no config classes have the config key. The body\n                will contain what sections were checked.\n        \"\"\"\n        for key, val in self._configs.items():\n            if key == asking_section:\n                continue\n\n            if item in dir(val):\n                return getattr(val, item)\n\n        raise AttributeError(item, \"not found in %s\" % (list(self._configs.keys()),))\n\n    def invoke_all(self, func_name: str, *args, **kwargs) -> MutableMapping[str, Any]:\n        \"\"\"\n        Invoke a function on all instantiated config objects this RootConfig is\n        configured to use.\n\n        Args:\n            func_name: Name of function to invoke\n            *args\n            **kwargs\n        Returns:\n            ordered dictionary of config section name and the result of the\n            function from it.\n        \"\"\"\n        res = OrderedDict()\n\n        for name, config in self._configs.items():\n            if hasattr(config, func_name):\n                res[name] = getattr(config, func_name)(*args, **kwargs)\n\n        return res\n\n    @classmethod\n    def invoke_all_static(cls, func_name: str, *args, **kwargs):\n        \"\"\"\n        Invoke a static function on config objects this RootConfig is\n        configured to use.\n\n        Args:\n            func_name: Name of function to invoke\n            *args\n            **kwargs\n        Returns:\n            ordered dictionary of config section name and the result of the\n            function from it.\n        \"\"\"\n        for config in cls.config_classes:\n            if hasattr(config, func_name):\n                getattr(config, func_name)(*args, **kwargs)\n\n    def generate_config(\n        self,\n        config_dir_path,\n        data_dir_path,\n        server_name,\n        generate_secrets=False,\n        report_stats=None,\n        open_private_ports=False,\n        listeners=None,\n        tls_certificate_path=None,\n        tls_private_key_path=None,\n        acme_domain=None,\n    ):\n        \"\"\"\n        Build a default configuration file\n\n        This is used when the user explicitly asks us to generate a config file\n        (eg with --generate_config).\n\n        Args:\n            config_dir_path (str): The path where the config files are kept. Used to\n                create filenames for things like the log config and the signing key.\n\n            data_dir_path (str): The path where the data files are kept. Used to create\n                filenames for things like the database and media store.\n\n            server_name (str): The server name. Used to initialise the server_name\n                config param, but also used in the names of some of the config files.\n\n            generate_secrets (bool): True if we should generate new secrets for things\n                like the macaroon_secret_key. If False, these parameters will be left\n                unset.\n\n            report_stats (bool|None): Initial setting for the report_stats setting.\n                If None, report_stats will be left unset.\n\n            open_private_ports (bool): True to leave private ports (such as the non-TLS\n                HTTP listener) open to the internet.\n\n            listeners (list(dict)|None): A list of descriptions of the listeners\n                synapse should start with each of which specifies a port (str), a list of\n                resources (list(str)), tls (bool) and type (str). For example:\n                [{\n                    \"port\": 8448,\n                    \"resources\": [{\"names\": [\"federation\"]}],\n                    \"tls\": True,\n                    \"type\": \"http\",\n                },\n                {\n                    \"port\": 443,\n                    \"resources\": [{\"names\": [\"client\"]}],\n                    \"tls\": False,\n                    \"type\": \"http\",\n                }],\n\n\n            database (str|None): The database type to configure, either `psycog2`\n                or `sqlite3`.\n\n            tls_certificate_path (str|None): The path to the tls certificate.\n\n            tls_private_key_path (str|None): The path to the tls private key.\n\n            acme_domain (str|None): The domain acme will try to validate. If\n                specified acme will be enabled.\n\n        Returns:\n            str: the yaml config file\n        \"\"\"\n\n        return CONFIG_FILE_HEADER + \"\\n\\n\".join(\n            dedent(conf)\n            for conf in self.invoke_all(\n                \"generate_config_section\",\n                config_dir_path=config_dir_path,\n                data_dir_path=data_dir_path,\n                server_name=server_name,\n                generate_secrets=generate_secrets,\n                report_stats=report_stats,\n                open_private_ports=open_private_ports,\n                listeners=listeners,\n                tls_certificate_path=tls_certificate_path,\n                tls_private_key_path=tls_private_key_path,\n                acme_domain=acme_domain,\n            ).values()\n        )\n\n    @classmethod\n    def load_config(cls, description, argv):\n        \"\"\"Parse the commandline and config files\n\n        Doesn't support config-file-generation: used by the worker apps.\n\n        Returns: Config object.\n        \"\"\"\n        config_parser = argparse.ArgumentParser(description=description)\n        cls.add_arguments_to_parser(config_parser)\n        obj, _ = cls.load_config_with_parser(config_parser, argv)\n\n        return obj\n\n    @classmethod\n    def add_arguments_to_parser(cls, config_parser):\n        \"\"\"Adds all the config flags to an ArgumentParser.\n\n        Doesn't support config-file-generation: used by the worker apps.\n\n        Used for workers where we want to add extra flags/subcommands.\n\n        Args:\n            config_parser (ArgumentParser): App description\n        \"\"\"\n\n        config_parser.add_argument(\n            \"-c\",\n            \"--config-path\",\n            action=\"append\",\n            metavar=\"CONFIG_FILE\",\n            help=\"Specify config file. Can be given multiple times and\"\n            \" may specify directories containing *.yaml files.\",\n        )\n\n        config_parser.add_argument(\n            \"--keys-directory\",\n            metavar=\"DIRECTORY\",\n            help=\"Where files such as certs and signing keys are stored when\"\n            \" their location is not given explicitly in the config.\"\n            \" Defaults to the directory containing the last config file\",\n        )\n\n        cls.invoke_all_static(\"add_arguments\", config_parser)\n\n    @classmethod\n    def load_config_with_parser(cls, parser, argv):\n        \"\"\"Parse the commandline and config files with the given parser\n\n        Doesn't support config-file-generation: used by the worker apps.\n\n        Used for workers where we want to add extra flags/subcommands.\n\n        Args:\n            parser (ArgumentParser)\n            argv (list[str])\n\n        Returns:\n            tuple[HomeServerConfig, argparse.Namespace]: Returns the parsed\n            config object and the parsed argparse.Namespace object from\n            `parser.parse_args(..)`\n        \"\"\"\n\n        obj = cls()\n\n        config_args = parser.parse_args(argv)\n\n        config_files = find_config_files(search_paths=config_args.config_path)\n\n        if not config_files:\n            parser.error(\"Must supply a config file.\")\n\n        if config_args.keys_directory:\n            config_dir_path = config_args.keys_directory\n        else:\n            config_dir_path = os.path.dirname(config_files[-1])\n        config_dir_path = os.path.abspath(config_dir_path)\n        data_dir_path = os.getcwd()\n\n        config_dict = read_config_files(config_files)\n        obj.parse_config_dict(\n            config_dict, config_dir_path=config_dir_path, data_dir_path=data_dir_path\n        )\n\n        obj.invoke_all(\"read_arguments\", config_args)\n\n        return obj, config_args\n\n    @classmethod\n    def load_or_generate_config(cls, description, argv):\n        \"\"\"Parse the commandline and config files\n\n        Supports generation of config files, so is used for the main homeserver app.\n\n        Returns: Config object, or None if --generate-config or --generate-keys was set\n        \"\"\"\n        parser = argparse.ArgumentParser(description=description)\n        parser.add_argument(\n            \"-c\",\n            \"--config-path\",\n            action=\"append\",\n            metavar=\"CONFIG_FILE\",\n            help=\"Specify config file. Can be given multiple times and\"\n            \" may specify directories containing *.yaml files.\",\n        )\n\n        generate_group = parser.add_argument_group(\"Config generation\")\n        generate_group.add_argument(\n            \"--generate-config\",\n            action=\"store_true\",\n            help=\"Generate a config file, then exit.\",\n        )\n        generate_group.add_argument(\n            \"--generate-missing-configs\",\n            \"--generate-keys\",\n            action=\"store_true\",\n            help=\"Generate any missing additional config files, then exit.\",\n        )\n        generate_group.add_argument(\n            \"-H\", \"--server-name\", help=\"The server name to generate a config file for.\"\n        )\n        generate_group.add_argument(\n            \"--report-stats\",\n            action=\"store\",\n            help=\"Whether the generated config reports anonymized usage statistics.\",\n            choices=[\"yes\", \"no\"],\n        )\n        generate_group.add_argument(\n            \"--config-directory\",\n            \"--keys-directory\",\n            metavar=\"DIRECTORY\",\n            help=(\n                \"Specify where additional config files such as signing keys and log\"\n                \" config should be stored. Defaults to the same directory as the last\"\n                \" config file.\"\n            ),\n        )\n        generate_group.add_argument(\n            \"--data-directory\",\n            metavar=\"DIRECTORY\",\n            help=(\n                \"Specify where data such as the media store and database file should be\"\n                \" stored. Defaults to the current working directory.\"\n            ),\n        )\n        generate_group.add_argument(\n            \"--open-private-ports\",\n            action=\"store_true\",\n            help=(\n                \"Leave private ports (such as the non-TLS HTTP listener) open to the\"\n                \" internet. Do not use this unless you know what you are doing.\"\n            ),\n        )\n\n        cls.invoke_all_static(\"add_arguments\", parser)\n        config_args = parser.parse_args(argv)\n\n        config_files = find_config_files(search_paths=config_args.config_path)\n\n        if not config_files:\n            parser.error(\n                \"Must supply a config file.\\nA config file can be automatically\"\n                ' generated using \"--generate-config -H SERVER_NAME'\n                ' -c CONFIG-FILE\"'\n            )\n\n        if config_args.config_directory:\n            config_dir_path = config_args.config_directory\n        else:\n            config_dir_path = os.path.dirname(config_files[-1])\n        config_dir_path = os.path.abspath(config_dir_path)\n        data_dir_path = os.getcwd()\n\n        generate_missing_configs = config_args.generate_missing_configs\n\n        obj = cls()\n\n        if config_args.generate_config:\n            if config_args.report_stats is None:\n                parser.error(\n                    \"Please specify either --report-stats=yes or --report-stats=no\\n\\n\"\n                    + MISSING_REPORT_STATS_SPIEL\n                )\n\n            (config_path,) = config_files\n            if not path_exists(config_path):\n                print(\"Generating config file %s\" % (config_path,))\n\n                if config_args.data_directory:\n                    data_dir_path = config_args.data_directory\n                else:\n                    data_dir_path = os.getcwd()\n                data_dir_path = os.path.abspath(data_dir_path)\n\n                server_name = config_args.server_name\n                if not server_name:\n                    raise ConfigError(\n                        \"Must specify a server_name to a generate config for.\"\n                        \" Pass -H server.name.\"\n                    )\n\n                config_str = obj.generate_config(\n                    config_dir_path=config_dir_path,\n                    data_dir_path=data_dir_path,\n                    server_name=server_name,\n                    report_stats=(config_args.report_stats == \"yes\"),\n                    generate_secrets=True,\n                    open_private_ports=config_args.open_private_ports,\n                )\n\n                if not path_exists(config_dir_path):\n                    os.makedirs(config_dir_path)\n                with open(config_path, \"w\") as config_file:\n                    config_file.write(config_str)\n                    config_file.write(\"\\n\\n# vim:ft=yaml\")\n\n                config_dict = yaml.safe_load(config_str)\n                obj.generate_missing_files(config_dict, config_dir_path)\n\n                print(\n                    (\n                        \"A config file has been generated in %r for server name\"\n                        \" %r. Please review this file and customise it\"\n                        \" to your needs.\"\n                    )\n                    % (config_path, server_name)\n                )\n                return\n            else:\n                print(\n                    (\n                        \"Config file %r already exists. Generating any missing config\"\n                        \" files.\"\n                    )\n                    % (config_path,)\n                )\n                generate_missing_configs = True\n\n        config_dict = read_config_files(config_files)\n        if generate_missing_configs:\n            obj.generate_missing_files(config_dict, config_dir_path)\n            return None\n\n        obj.parse_config_dict(\n            config_dict, config_dir_path=config_dir_path, data_dir_path=data_dir_path\n        )\n        obj.invoke_all(\"read_arguments\", config_args)\n\n        return obj\n\n    def parse_config_dict(self, config_dict, config_dir_path=None, data_dir_path=None):\n        \"\"\"Read the information from the config dict into this Config object.\n\n        Args:\n            config_dict (dict): Configuration data, as read from the yaml\n\n            config_dir_path (str): The path where the config files are kept. Used to\n                create filenames for things like the log config and the signing key.\n\n            data_dir_path (str): The path where the data files are kept. Used to create\n                filenames for things like the database and media store.\n        \"\"\"\n        self.invoke_all(\n            \"read_config\",\n            config_dict,\n            config_dir_path=config_dir_path,\n            data_dir_path=data_dir_path,\n        )\n\n    def generate_missing_files(self, config_dict, config_dir_path):\n        self.invoke_all(\"generate_files\", config_dict, config_dir_path)", "target": 0}, {"function": "def read_config_files(config_files):\n    \"\"\"Read the config files into a dict\n\n    Args:\n        config_files (iterable[str]): A list of the config files to read\n\n    Returns: dict\n    \"\"\"\n    specified_config = {}\n    for config_file in config_files:\n        with open(config_file) as file_stream:\n            yaml_config = yaml.safe_load(file_stream)\n\n        if not isinstance(yaml_config, dict):\n            err = \"File %r is empty or doesn't parse into a key-value map. IGNORING.\"\n            print(err % (config_file,))\n            continue\n\n        specified_config.update(yaml_config)\n\n    if \"server_name\" not in specified_config:\n        raise ConfigError(MISSING_SERVER_NAME)\n\n    if \"report_stats\" not in specified_config:\n        raise ConfigError(\n            MISSING_REPORT_STATS_CONFIG_INSTRUCTIONS + \"\\n\" + MISSING_REPORT_STATS_SPIEL\n        )\n    return specified_config", "target": 0}, {"function": "def find_config_files(search_paths):\n    \"\"\"Finds config files using a list of search paths. If a path is a file\n    then that file path is added to the list. If a search path is a directory\n    then all the \"*.yaml\" files in that directory are added to the list in\n    sorted order.\n\n    Args:\n        search_paths(list(str)): A list of paths to search.\n\n    Returns:\n        list(str): A list of file paths.\n    \"\"\"\n\n    config_files = []\n    if search_paths:\n        for config_path in search_paths:\n            if os.path.isdir(config_path):\n                # We accept specifying directories as config paths, we search\n                # inside that directory for all files matching *.yaml, and then\n                # we apply them in *sorted* order.\n                files = []\n                for entry in os.listdir(config_path):\n                    entry_path = os.path.join(config_path, entry)\n                    if not os.path.isfile(entry_path):\n                        err = \"Found subdirectory in config directory: %r. IGNORING.\"\n                        print(err % (entry_path,))\n                        continue\n\n                    if not entry.endswith(\".yaml\"):\n                        err = (\n                            \"Found file in config directory that does not end in \"\n                            \"'.yaml': %r. IGNORING.\"\n                        )\n                        print(err % (entry_path,))\n                        continue\n\n                    files.append(entry_path)\n\n                config_files.extend(sorted(files))\n            else:\n                config_files.append(config_path)\n    return config_files", "target": 0}], "function_after": [{"function": "class ConfigError(Exception):\n    \"\"\"Represents a problem parsing the configuration\n\n    Args:\n        msg:  A textual description of the error.\n        path: Where appropriate, an indication of where in the configuration\n           the problem lies.\n    \"\"\"\n\n    def __init__(self, msg: str, path: Optional[Iterable[str]] = None):\n        self.msg = msg\n        self.path = path", "target": 0}, {"function": "def path_exists(file_path):\n    \"\"\"Check if a file exists\n\n    Unlike os.path.exists, this throws an exception if there is an error\n    checking if the file exists (for example, if there is a perms error on\n    the parent dir).\n\n    Returns:\n        bool: True if the file exists; False if not.\n    \"\"\"\n    try:\n        os.stat(file_path)\n        return True\n    except OSError as e:\n        if e.errno != errno.ENOENT:\n            raise e\n        return False", "target": 0}, {"function": "class Config:\n    \"\"\"\n    A configuration section, containing configuration keys and values.\n\n    Attributes:\n        section (str): The section title of this config object, such as\n            \"tls\" or \"logger\". This is used to refer to it on the root\n            logger (for example, `config.tls.some_option`). Must be\n            defined in subclasses.\n    \"\"\"\n\n    section = None\n\n    def __init__(self, root_config=None):\n        self.root = root_config\n\n        # Get the path to the default Synapse template directory\n        self.default_template_dir = pkg_resources.resource_filename(\n            \"synapse\", \"res/templates\"\n        )\n\n    def __getattr__(self, item: str) -> Any:\n        \"\"\"\n        Try and fetch a configuration option that does not exist on this class.\n\n        This is so that existing configs that rely on `self.value`, where value\n        is actually from a different config section, continue to work.\n        \"\"\"\n        if item in [\"generate_config_section\", \"read_config\"]:\n            raise AttributeError(item)\n\n        if self.root is None:\n            raise AttributeError(item)\n        else:\n            return self.root._get_unclassed_config(self.section, item)\n\n    @staticmethod\n    def parse_size(value):\n        if isinstance(value, int):\n            return value\n        sizes = {\"K\": 1024, \"M\": 1024 * 1024}\n        size = 1\n        suffix = value[-1]\n        if suffix in sizes:\n            value = value[:-1]\n            size = sizes[suffix]\n        return int(value) * size\n\n    @staticmethod\n    def parse_duration(value):\n        if isinstance(value, int):\n            return value\n        second = 1000\n        minute = 60 * second\n        hour = 60 * minute\n        day = 24 * hour\n        week = 7 * day\n        year = 365 * day\n        sizes = {\"s\": second, \"m\": minute, \"h\": hour, \"d\": day, \"w\": week, \"y\": year}\n        size = 1\n        suffix = value[-1]\n        if suffix in sizes:\n            value = value[:-1]\n            size = sizes[suffix]\n        return int(value) * size\n\n    @staticmethod\n    def abspath(file_path):\n        return os.path.abspath(file_path) if file_path else file_path\n\n    @classmethod\n    def path_exists(cls, file_path):\n        return path_exists(file_path)\n\n    @classmethod\n    def check_file(cls, file_path, config_name):\n        if file_path is None:\n            raise ConfigError(\"Missing config for %s.\" % (config_name,))\n        try:\n            os.stat(file_path)\n        except OSError as e:\n            raise ConfigError(\n                \"Error accessing file '%s' (config for %s): %s\"\n                % (file_path, config_name, e.strerror)\n            )\n        return cls.abspath(file_path)\n\n    @classmethod\n    def ensure_directory(cls, dir_path):\n        dir_path = cls.abspath(dir_path)\n        try:\n            os.makedirs(dir_path)\n        except OSError as e:\n            if e.errno != errno.EEXIST:\n                raise\n        if not os.path.isdir(dir_path):\n            raise ConfigError(\"%s is not a directory\" % (dir_path,))\n        return dir_path\n\n    @classmethod\n    def read_file(cls, file_path, config_name):\n        cls.check_file(file_path, config_name)\n        with open(file_path) as file_stream:\n            return file_stream.read()\n\n    def read_template(self, filename: str) -> jinja2.Template:\n        \"\"\"Load a template file from disk.\n\n        This function will attempt to load the given template from the default Synapse\n        template directory.\n\n        Files read are treated as Jinja templates. The templates is not rendered yet\n        and has autoescape enabled.\n\n        Args:\n            filename: A template filename to read.\n\n        Raises:\n            ConfigError: if the file's path is incorrect or otherwise cannot be read.\n\n        Returns:\n            A jinja2 template.\n        \"\"\"\n        return self.read_templates([filename])[0]\n\n    def read_templates(\n        self, filenames: List[str], custom_template_directory: Optional[str] = None,\n    ) -> List[jinja2.Template]:\n        \"\"\"Load a list of template files from disk using the given variables.\n\n        This function will attempt to load the given templates from the default Synapse\n        template directory. If `custom_template_directory` is supplied, that directory\n        is tried first.\n\n        Files read are treated as Jinja templates. The templates are not rendered yet\n        and have autoescape enabled.\n\n        Args:\n            filenames: A list of template filenames to read.\n\n            custom_template_directory: A directory to try to look for the templates\n                before using the default Synapse template directory instead.\n\n        Raises:\n            ConfigError: if the file's path is incorrect or otherwise cannot be read.\n\n        Returns:\n            A list of jinja2 templates.\n        \"\"\"\n        search_directories = [self.default_template_dir]\n\n        # The loader will first look in the custom template directory (if specified) for the\n        # given filename. If it doesn't find it, it will use the default template dir instead\n        if custom_template_directory:\n            # Check that the given template directory exists\n            if not self.path_exists(custom_template_directory):\n                raise ConfigError(\n                    \"Configured template directory does not exist: %s\"\n                    % (custom_template_directory,)\n                )\n\n            # Search the custom template directory as well\n            search_directories.insert(0, custom_template_directory)\n\n        loader = jinja2.FileSystemLoader(search_directories)\n        env = jinja2.Environment(loader=loader, autoescape=jinja2.select_autoescape(),)\n\n        # Update the environment with our custom filters\n        env.filters.update(\n            {\n                \"format_ts\": _format_ts_filter,\n                \"mxc_to_http\": _create_mxc_to_http_filter(self.public_baseurl),\n            }\n        )\n\n        # Load the templates\n        return [env.get_template(filename) for filename in filenames]", "target": 0}, {"function": "def _format_ts_filter(value: int, format: str):\n    return time.strftime(format, time.localtime(value / 1000))", "target": 0}, {"function": "def _create_mxc_to_http_filter(public_baseurl: str) -> Callable:\n    \"\"\"Create and return a jinja2 filter that converts MXC urls to HTTP\n\n    Args:\n        public_baseurl: The public, accessible base URL of the homeserver\n    \"\"\"\n\n    def mxc_to_http_filter(value, width, height, resize_method=\"crop\"):\n        if value[0:6] != \"mxc://\":\n            return \"\"\n\n        server_and_media_id = value[6:]\n        fragment = None\n        if \"#\" in server_and_media_id:\n            server_and_media_id, fragment = server_and_media_id.split(\"#\", 1)\n            fragment = \"#\" + fragment\n\n        params = {\"width\": width, \"height\": height, \"method\": resize_method}\n        return \"%s_matrix/media/v1/thumbnail/%s?%s%s\" % (\n            public_baseurl,\n            server_and_media_id,\n            urllib.parse.urlencode(params),\n            fragment or \"\",\n        )\n\n    return mxc_to_http_filter", "target": 0}, {"function": "class RootConfig:\n    \"\"\"\n    Holder of an application's configuration.\n\n    What configuration this object holds is defined by `config_classes`, a list\n    of Config classes that will be instantiated and given the contents of a\n    configuration file to read. They can then be accessed on this class by their\n    section name, defined in the Config or dynamically set to be the name of the\n    class, lower-cased and with \"Config\" removed.\n    \"\"\"\n\n    config_classes = []\n\n    def __init__(self):\n        self._configs = OrderedDict()\n\n        for config_class in self.config_classes:\n            if config_class.section is None:\n                raise ValueError(\"%r requires a section name\" % (config_class,))\n\n            try:\n                conf = config_class(self)\n            except Exception as e:\n                raise Exception(\"Failed making %s: %r\" % (config_class.section, e))\n            self._configs[config_class.section] = conf\n\n    def __getattr__(self, item: str) -> Any:\n        \"\"\"\n        Redirect lookups on this object either to config objects, or values on\n        config objects, so that `config.tls.blah` works, as well as legacy uses\n        of things like `config.server_name`. It will first look up the config\n        section name, and then values on those config classes.\n        \"\"\"\n        if item in self._configs.keys():\n            return self._configs[item]\n\n        return self._get_unclassed_config(None, item)\n\n    def _get_unclassed_config(self, asking_section: Optional[str], item: str):\n        \"\"\"\n        Fetch a config value from one of the instantiated config classes that\n        has not been fetched directly.\n\n        Args:\n            asking_section: If this check is coming from a Config child, which\n                one? This section will not be asked if it has the value.\n            item: The configuration value key.\n\n        Raises:\n            AttributeError if no config classes have the config key. The body\n                will contain what sections were checked.\n        \"\"\"\n        for key, val in self._configs.items():\n            if key == asking_section:\n                continue\n\n            if item in dir(val):\n                return getattr(val, item)\n\n        raise AttributeError(item, \"not found in %s\" % (list(self._configs.keys()),))\n\n    def invoke_all(self, func_name: str, *args, **kwargs) -> MutableMapping[str, Any]:\n        \"\"\"\n        Invoke a function on all instantiated config objects this RootConfig is\n        configured to use.\n\n        Args:\n            func_name: Name of function to invoke\n            *args\n            **kwargs\n        Returns:\n            ordered dictionary of config section name and the result of the\n            function from it.\n        \"\"\"\n        res = OrderedDict()\n\n        for name, config in self._configs.items():\n            if hasattr(config, func_name):\n                res[name] = getattr(config, func_name)(*args, **kwargs)\n\n        return res\n\n    @classmethod\n    def invoke_all_static(cls, func_name: str, *args, **kwargs):\n        \"\"\"\n        Invoke a static function on config objects this RootConfig is\n        configured to use.\n\n        Args:\n            func_name: Name of function to invoke\n            *args\n            **kwargs\n        Returns:\n            ordered dictionary of config section name and the result of the\n            function from it.\n        \"\"\"\n        for config in cls.config_classes:\n            if hasattr(config, func_name):\n                getattr(config, func_name)(*args, **kwargs)\n\n    def generate_config(\n        self,\n        config_dir_path,\n        data_dir_path,\n        server_name,\n        generate_secrets=False,\n        report_stats=None,\n        open_private_ports=False,\n        listeners=None,\n        tls_certificate_path=None,\n        tls_private_key_path=None,\n        acme_domain=None,\n    ):\n        \"\"\"\n        Build a default configuration file\n\n        This is used when the user explicitly asks us to generate a config file\n        (eg with --generate_config).\n\n        Args:\n            config_dir_path (str): The path where the config files are kept. Used to\n                create filenames for things like the log config and the signing key.\n\n            data_dir_path (str): The path where the data files are kept. Used to create\n                filenames for things like the database and media store.\n\n            server_name (str): The server name. Used to initialise the server_name\n                config param, but also used in the names of some of the config files.\n\n            generate_secrets (bool): True if we should generate new secrets for things\n                like the macaroon_secret_key. If False, these parameters will be left\n                unset.\n\n            report_stats (bool|None): Initial setting for the report_stats setting.\n                If None, report_stats will be left unset.\n\n            open_private_ports (bool): True to leave private ports (such as the non-TLS\n                HTTP listener) open to the internet.\n\n            listeners (list(dict)|None): A list of descriptions of the listeners\n                synapse should start with each of which specifies a port (str), a list of\n                resources (list(str)), tls (bool) and type (str). For example:\n                [{\n                    \"port\": 8448,\n                    \"resources\": [{\"names\": [\"federation\"]}],\n                    \"tls\": True,\n                    \"type\": \"http\",\n                },\n                {\n                    \"port\": 443,\n                    \"resources\": [{\"names\": [\"client\"]}],\n                    \"tls\": False,\n                    \"type\": \"http\",\n                }],\n\n\n            database (str|None): The database type to configure, either `psycog2`\n                or `sqlite3`.\n\n            tls_certificate_path (str|None): The path to the tls certificate.\n\n            tls_private_key_path (str|None): The path to the tls private key.\n\n            acme_domain (str|None): The domain acme will try to validate. If\n                specified acme will be enabled.\n\n        Returns:\n            str: the yaml config file\n        \"\"\"\n\n        return CONFIG_FILE_HEADER + \"\\n\\n\".join(\n            dedent(conf)\n            for conf in self.invoke_all(\n                \"generate_config_section\",\n                config_dir_path=config_dir_path,\n                data_dir_path=data_dir_path,\n                server_name=server_name,\n                generate_secrets=generate_secrets,\n                report_stats=report_stats,\n                open_private_ports=open_private_ports,\n                listeners=listeners,\n                tls_certificate_path=tls_certificate_path,\n                tls_private_key_path=tls_private_key_path,\n                acme_domain=acme_domain,\n            ).values()\n        )\n\n    @classmethod\n    def load_config(cls, description, argv):\n        \"\"\"Parse the commandline and config files\n\n        Doesn't support config-file-generation: used by the worker apps.\n\n        Returns: Config object.\n        \"\"\"\n        config_parser = argparse.ArgumentParser(description=description)\n        cls.add_arguments_to_parser(config_parser)\n        obj, _ = cls.load_config_with_parser(config_parser, argv)\n\n        return obj\n\n    @classmethod\n    def add_arguments_to_parser(cls, config_parser):\n        \"\"\"Adds all the config flags to an ArgumentParser.\n\n        Doesn't support config-file-generation: used by the worker apps.\n\n        Used for workers where we want to add extra flags/subcommands.\n\n        Args:\n            config_parser (ArgumentParser): App description\n        \"\"\"\n\n        config_parser.add_argument(\n            \"-c\",\n            \"--config-path\",\n            action=\"append\",\n            metavar=\"CONFIG_FILE\",\n            help=\"Specify config file. Can be given multiple times and\"\n            \" may specify directories containing *.yaml files.\",\n        )\n\n        config_parser.add_argument(\n            \"--keys-directory\",\n            metavar=\"DIRECTORY\",\n            help=\"Where files such as certs and signing keys are stored when\"\n            \" their location is not given explicitly in the config.\"\n            \" Defaults to the directory containing the last config file\",\n        )\n\n        cls.invoke_all_static(\"add_arguments\", config_parser)\n\n    @classmethod\n    def load_config_with_parser(cls, parser, argv):\n        \"\"\"Parse the commandline and config files with the given parser\n\n        Doesn't support config-file-generation: used by the worker apps.\n\n        Used for workers where we want to add extra flags/subcommands.\n\n        Args:\n            parser (ArgumentParser)\n            argv (list[str])\n\n        Returns:\n            tuple[HomeServerConfig, argparse.Namespace]: Returns the parsed\n            config object and the parsed argparse.Namespace object from\n            `parser.parse_args(..)`\n        \"\"\"\n\n        obj = cls()\n\n        config_args = parser.parse_args(argv)\n\n        config_files = find_config_files(search_paths=config_args.config_path)\n\n        if not config_files:\n            parser.error(\"Must supply a config file.\")\n\n        if config_args.keys_directory:\n            config_dir_path = config_args.keys_directory\n        else:\n            config_dir_path = os.path.dirname(config_files[-1])\n        config_dir_path = os.path.abspath(config_dir_path)\n        data_dir_path = os.getcwd()\n\n        config_dict = read_config_files(config_files)\n        obj.parse_config_dict(\n            config_dict, config_dir_path=config_dir_path, data_dir_path=data_dir_path\n        )\n\n        obj.invoke_all(\"read_arguments\", config_args)\n\n        return obj, config_args\n\n    @classmethod\n    def load_or_generate_config(cls, description, argv):\n        \"\"\"Parse the commandline and config files\n\n        Supports generation of config files, so is used for the main homeserver app.\n\n        Returns: Config object, or None if --generate-config or --generate-keys was set\n        \"\"\"\n        parser = argparse.ArgumentParser(description=description)\n        parser.add_argument(\n            \"-c\",\n            \"--config-path\",\n            action=\"append\",\n            metavar=\"CONFIG_FILE\",\n            help=\"Specify config file. Can be given multiple times and\"\n            \" may specify directories containing *.yaml files.\",\n        )\n\n        generate_group = parser.add_argument_group(\"Config generation\")\n        generate_group.add_argument(\n            \"--generate-config\",\n            action=\"store_true\",\n            help=\"Generate a config file, then exit.\",\n        )\n        generate_group.add_argument(\n            \"--generate-missing-configs\",\n            \"--generate-keys\",\n            action=\"store_true\",\n            help=\"Generate any missing additional config files, then exit.\",\n        )\n        generate_group.add_argument(\n            \"-H\", \"--server-name\", help=\"The server name to generate a config file for.\"\n        )\n        generate_group.add_argument(\n            \"--report-stats\",\n            action=\"store\",\n            help=\"Whether the generated config reports anonymized usage statistics.\",\n            choices=[\"yes\", \"no\"],\n        )\n        generate_group.add_argument(\n            \"--config-directory\",\n            \"--keys-directory\",\n            metavar=\"DIRECTORY\",\n            help=(\n                \"Specify where additional config files such as signing keys and log\"\n                \" config should be stored. Defaults to the same directory as the last\"\n                \" config file.\"\n            ),\n        )\n        generate_group.add_argument(\n            \"--data-directory\",\n            metavar=\"DIRECTORY\",\n            help=(\n                \"Specify where data such as the media store and database file should be\"\n                \" stored. Defaults to the current working directory.\"\n            ),\n        )\n        generate_group.add_argument(\n            \"--open-private-ports\",\n            action=\"store_true\",\n            help=(\n                \"Leave private ports (such as the non-TLS HTTP listener) open to the\"\n                \" internet. Do not use this unless you know what you are doing.\"\n            ),\n        )\n\n        cls.invoke_all_static(\"add_arguments\", parser)\n        config_args = parser.parse_args(argv)\n\n        config_files = find_config_files(search_paths=config_args.config_path)\n\n        if not config_files:\n            parser.error(\n                \"Must supply a config file.\\nA config file can be automatically\"\n                ' generated using \"--generate-config -H SERVER_NAME'\n                ' -c CONFIG-FILE\"'\n            )\n\n        if config_args.config_directory:\n            config_dir_path = config_args.config_directory\n        else:\n            config_dir_path = os.path.dirname(config_files[-1])\n        config_dir_path = os.path.abspath(config_dir_path)\n        data_dir_path = os.getcwd()\n\n        generate_missing_configs = config_args.generate_missing_configs\n\n        obj = cls()\n\n        if config_args.generate_config:\n            if config_args.report_stats is None:\n                parser.error(\n                    \"Please specify either --report-stats=yes or --report-stats=no\\n\\n\"\n                    + MISSING_REPORT_STATS_SPIEL\n                )\n\n            (config_path,) = config_files\n            if not path_exists(config_path):\n                print(\"Generating config file %s\" % (config_path,))\n\n                if config_args.data_directory:\n                    data_dir_path = config_args.data_directory\n                else:\n                    data_dir_path = os.getcwd()\n                data_dir_path = os.path.abspath(data_dir_path)\n\n                server_name = config_args.server_name\n                if not server_name:\n                    raise ConfigError(\n                        \"Must specify a server_name to a generate config for.\"\n                        \" Pass -H server.name.\"\n                    )\n\n                config_str = obj.generate_config(\n                    config_dir_path=config_dir_path,\n                    data_dir_path=data_dir_path,\n                    server_name=server_name,\n                    report_stats=(config_args.report_stats == \"yes\"),\n                    generate_secrets=True,\n                    open_private_ports=config_args.open_private_ports,\n                )\n\n                if not path_exists(config_dir_path):\n                    os.makedirs(config_dir_path)\n                with open(config_path, \"w\") as config_file:\n                    config_file.write(config_str)\n                    config_file.write(\"\\n\\n# vim:ft=yaml\")\n\n                config_dict = yaml.safe_load(config_str)\n                obj.generate_missing_files(config_dict, config_dir_path)\n\n                print(\n                    (\n                        \"A config file has been generated in %r for server name\"\n                        \" %r. Please review this file and customise it\"\n                        \" to your needs.\"\n                    )\n                    % (config_path, server_name)\n                )\n                return\n            else:\n                print(\n                    (\n                        \"Config file %r already exists. Generating any missing config\"\n                        \" files.\"\n                    )\n                    % (config_path,)\n                )\n                generate_missing_configs = True\n\n        config_dict = read_config_files(config_files)\n        if generate_missing_configs:\n            obj.generate_missing_files(config_dict, config_dir_path)\n            return None\n\n        obj.parse_config_dict(\n            config_dict, config_dir_path=config_dir_path, data_dir_path=data_dir_path\n        )\n        obj.invoke_all(\"read_arguments\", config_args)\n\n        return obj\n\n    def parse_config_dict(self, config_dict, config_dir_path=None, data_dir_path=None):\n        \"\"\"Read the information from the config dict into this Config object.\n\n        Args:\n            config_dict (dict): Configuration data, as read from the yaml\n\n            config_dir_path (str): The path where the config files are kept. Used to\n                create filenames for things like the log config and the signing key.\n\n            data_dir_path (str): The path where the data files are kept. Used to create\n                filenames for things like the database and media store.\n        \"\"\"\n        self.invoke_all(\n            \"read_config\",\n            config_dict,\n            config_dir_path=config_dir_path,\n            data_dir_path=data_dir_path,\n        )\n\n    def generate_missing_files(self, config_dict, config_dir_path):\n        self.invoke_all(\"generate_files\", config_dict, config_dir_path)", "target": 0}, {"function": "def read_config_files(config_files):\n    \"\"\"Read the config files into a dict\n\n    Args:\n        config_files (iterable[str]): A list of the config files to read\n\n    Returns: dict\n    \"\"\"\n    specified_config = {}\n    for config_file in config_files:\n        with open(config_file) as file_stream:\n            yaml_config = yaml.safe_load(file_stream)\n\n        if not isinstance(yaml_config, dict):\n            err = \"File %r is empty or doesn't parse into a key-value map. IGNORING.\"\n            print(err % (config_file,))\n            continue\n\n        specified_config.update(yaml_config)\n\n    if \"server_name\" not in specified_config:\n        raise ConfigError(MISSING_SERVER_NAME)\n\n    if \"report_stats\" not in specified_config:\n        raise ConfigError(\n            MISSING_REPORT_STATS_CONFIG_INSTRUCTIONS + \"\\n\" + MISSING_REPORT_STATS_SPIEL\n        )\n    return specified_config", "target": 0}, {"function": "def find_config_files(search_paths):\n    \"\"\"Finds config files using a list of search paths. If a path is a file\n    then that file path is added to the list. If a search path is a directory\n    then all the \"*.yaml\" files in that directory are added to the list in\n    sorted order.\n\n    Args:\n        search_paths(list(str)): A list of paths to search.\n\n    Returns:\n        list(str): A list of file paths.\n    \"\"\"\n\n    config_files = []\n    if search_paths:\n        for config_path in search_paths:\n            if os.path.isdir(config_path):\n                # We accept specifying directories as config paths, we search\n                # inside that directory for all files matching *.yaml, and then\n                # we apply them in *sorted* order.\n                files = []\n                for entry in os.listdir(config_path):\n                    entry_path = os.path.join(config_path, entry)\n                    if not os.path.isfile(entry_path):\n                        err = \"Found subdirectory in config directory: %r. IGNORING.\"\n                        print(err % (entry_path,))\n                        continue\n\n                    if not entry.endswith(\".yaml\"):\n                        err = (\n                            \"Found file in config directory that does not end in \"\n                            \"'.yaml': %r. IGNORING.\"\n                        )\n                        print(err % (entry_path,))\n                        continue\n\n                    files.append(entry_path)\n\n                config_files.extend(sorted(files))\n            else:\n                config_files.append(config_path)\n    return config_files", "target": 0}]}, {"raw_url": "https://github.com/matrix-org/synapse/raw/e54746bdf7d5c831eabe4dcea76a7626f1de73df/synapse%2Fconfig%2Fcaptcha.py", "code": "# Copyright 2014-2016 OpenMarket Ltd\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom ._base import Config\n\n\nclass CaptchaConfig(Config):\n    section = \"captcha\"\n\n    def read_config(self, config, **kwargs):\n        self.recaptcha_private_key = config.get(\"recaptcha_private_key\")\n        self.recaptcha_public_key = config.get(\"recaptcha_public_key\")\n        self.enable_registration_captcha = config.get(\n            \"enable_registration_captcha\", False\n        )\n        self.recaptcha_siteverify_api = config.get(\n            \"recaptcha_siteverify_api\",\n            \"https://www.recaptcha.net/recaptcha/api/siteverify\",\n        )\n        self.recaptcha_template = self.read_template(\"recaptcha.html\")\n\n    def generate_config_section(self, **kwargs):\n        return \"\"\"\\\n        ## Captcha ##\n        # See docs/CAPTCHA_SETUP.md for full details of configuring this.\n\n        # This homeserver's ReCAPTCHA public key. Must be specified if\n        # enable_registration_captcha is enabled.\n        #\n        #recaptcha_public_key: \"YOUR_PUBLIC_KEY\"\n\n        # This homeserver's ReCAPTCHA private key. Must be specified if\n        # enable_registration_captcha is enabled.\n        #\n        #recaptcha_private_key: \"YOUR_PRIVATE_KEY\"\n\n        # Uncomment to enable ReCaptcha checks when registering, preventing signup\n        # unless a captcha is answered. Requires a valid ReCaptcha\n        # public/private key. Defaults to 'false'.\n        #\n        #enable_registration_captcha: true\n\n        # The API endpoint to use for verifying m.login.recaptcha responses.\n        # Defaults to \"https://www.recaptcha.net/recaptcha/api/siteverify\".\n        #\n        #recaptcha_siteverify_api: \"https://my.recaptcha.site\"\n        \"\"\"\n", "code_before": "# Copyright 2014-2016 OpenMarket Ltd\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom ._base import Config\n\n\nclass CaptchaConfig(Config):\n    section = \"captcha\"\n\n    def read_config(self, config, **kwargs):\n        self.recaptcha_private_key = config.get(\"recaptcha_private_key\")\n        self.recaptcha_public_key = config.get(\"recaptcha_public_key\")\n        self.enable_registration_captcha = config.get(\n            \"enable_registration_captcha\", False\n        )\n        self.recaptcha_siteverify_api = config.get(\n            \"recaptcha_siteverify_api\",\n            \"https://www.recaptcha.net/recaptcha/api/siteverify\",\n        )\n        self.recaptcha_template = self.read_templates(\n            [\"recaptcha.html\"], autoescape=True\n        )[0]\n\n    def generate_config_section(self, **kwargs):\n        return \"\"\"\\\n        ## Captcha ##\n        # See docs/CAPTCHA_SETUP.md for full details of configuring this.\n\n        # This homeserver's ReCAPTCHA public key. Must be specified if\n        # enable_registration_captcha is enabled.\n        #\n        #recaptcha_public_key: \"YOUR_PUBLIC_KEY\"\n\n        # This homeserver's ReCAPTCHA private key. Must be specified if\n        # enable_registration_captcha is enabled.\n        #\n        #recaptcha_private_key: \"YOUR_PRIVATE_KEY\"\n\n        # Uncomment to enable ReCaptcha checks when registering, preventing signup\n        # unless a captcha is answered. Requires a valid ReCaptcha\n        # public/private key. Defaults to 'false'.\n        #\n        #enable_registration_captcha: true\n\n        # The API endpoint to use for verifying m.login.recaptcha responses.\n        # Defaults to \"https://www.recaptcha.net/recaptcha/api/siteverify\".\n        #\n        #recaptcha_siteverify_api: \"https://my.recaptcha.site\"\n        \"\"\"\n", "patch": "@@ -28,9 +28,7 @@ def read_config(self, config, **kwargs):\n             \"recaptcha_siteverify_api\",\n             \"https://www.recaptcha.net/recaptcha/api/siteverify\",\n         )\n-        self.recaptcha_template = self.read_templates(\n-            [\"recaptcha.html\"], autoescape=True\n-        )[0]\n+        self.recaptcha_template = self.read_template(\"recaptcha.html\")\n \n     def generate_config_section(self, **kwargs):\n         return \"\"\"\\", "file_path": "files/2021_3/65", "file_language": "py", "file_name": "synapse/config/captcha.py", "outdated_file_modify": 0, "outdated_file_before": 0, "outdated_file_after": 0, "llm_check": 0, "static_check": 0, "static": {"rats": [false, []], "semgrep": [false, []]}, "target": 0, "function_before": [{"function": "class CaptchaConfig(Config):\n    section = \"captcha\"\n\n    def read_config(self, config, **kwargs):\n        self.recaptcha_private_key = config.get(\"recaptcha_private_key\")\n        self.recaptcha_public_key = config.get(\"recaptcha_public_key\")\n        self.enable_registration_captcha = config.get(\n            \"enable_registration_captcha\", False\n        )\n        self.recaptcha_siteverify_api = config.get(\n            \"recaptcha_siteverify_api\",\n            \"https://www.recaptcha.net/recaptcha/api/siteverify\",\n        )\n        self.recaptcha_template = self.read_templates(\n            [\"recaptcha.html\"], autoescape=True\n        )[0]\n\n    def generate_config_section(self, **kwargs):\n        return \"\"\"\\\n        ## Captcha ##\n        # See docs/CAPTCHA_SETUP.md for full details of configuring this.\n\n        # This homeserver's ReCAPTCHA public key. Must be specified if\n        # enable_registration_captcha is enabled.\n        #\n        #recaptcha_public_key: \"YOUR_PUBLIC_KEY\"\n\n        # This homeserver's ReCAPTCHA private key. Must be specified if\n        # enable_registration_captcha is enabled.\n        #\n        #recaptcha_private_key: \"YOUR_PRIVATE_KEY\"\n\n        # Uncomment to enable ReCaptcha checks when registering, preventing signup\n        # unless a captcha is answered. Requires a valid ReCaptcha\n        # public/private key. Defaults to 'false'.\n        #\n        #enable_registration_captcha: true\n\n        # The API endpoint to use for verifying m.login.recaptcha responses.\n        # Defaults to \"https://www.recaptcha.net/recaptcha/api/siteverify\".\n        #\n        #recaptcha_siteverify_api: \"https://my.recaptcha.site\"\n        \"\"\"", "target": 0}], "function_after": [{"function": "class CaptchaConfig(Config):\n    section = \"captcha\"\n\n    def read_config(self, config, **kwargs):\n        self.recaptcha_private_key = config.get(\"recaptcha_private_key\")\n        self.recaptcha_public_key = config.get(\"recaptcha_public_key\")\n        self.enable_registration_captcha = config.get(\n            \"enable_registration_captcha\", False\n        )\n        self.recaptcha_siteverify_api = config.get(\n            \"recaptcha_siteverify_api\",\n            \"https://www.recaptcha.net/recaptcha/api/siteverify\",\n        )\n        self.recaptcha_template = self.read_template(\"recaptcha.html\")\n\n    def generate_config_section(self, **kwargs):\n        return \"\"\"\\\n        ## Captcha ##\n        # See docs/CAPTCHA_SETUP.md for full details of configuring this.\n\n        # This homeserver's ReCAPTCHA public key. Must be specified if\n        # enable_registration_captcha is enabled.\n        #\n        #recaptcha_public_key: \"YOUR_PUBLIC_KEY\"\n\n        # This homeserver's ReCAPTCHA private key. Must be specified if\n        # enable_registration_captcha is enabled.\n        #\n        #recaptcha_private_key: \"YOUR_PRIVATE_KEY\"\n\n        # Uncomment to enable ReCaptcha checks when registering, preventing signup\n        # unless a captcha is answered. Requires a valid ReCaptcha\n        # public/private key. Defaults to 'false'.\n        #\n        #enable_registration_captcha: true\n\n        # The API endpoint to use for verifying m.login.recaptcha responses.\n        # Defaults to \"https://www.recaptcha.net/recaptcha/api/siteverify\".\n        #\n        #recaptcha_siteverify_api: \"https://my.recaptcha.site\"\n        \"\"\"", "target": 0}]}, {"raw_url": "https://github.com/matrix-org/synapse/raw/e54746bdf7d5c831eabe4dcea76a7626f1de73df/synapse%2Fconfig%2Fconsent_config.py", "code": "# -*- coding: utf-8 -*-\n# Copyright 2018 New Vector Ltd\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom os import path\n\nfrom synapse.config import ConfigError\n\nfrom ._base import Config\n\nDEFAULT_CONFIG = \"\"\"\\\n# User Consent configuration\n#\n# for detailed instructions, see\n# https://github.com/matrix-org/synapse/blob/master/docs/consent_tracking.md\n#\n# Parts of this section are required if enabling the 'consent' resource under\n# 'listeners', in particular 'template_dir' and 'version'.\n#\n# 'template_dir' gives the location of the templates for the HTML forms.\n# This directory should contain one subdirectory per language (eg, 'en', 'fr'),\n# and each language directory should contain the policy document (named as\n# '<version>.html') and a success page (success.html).\n#\n# 'version' specifies the 'current' version of the policy document. It defines\n# the version to be served by the consent resource if there is no 'v'\n# parameter.\n#\n# 'server_notice_content', if enabled, will send a user a \"Server Notice\"\n# asking them to consent to the privacy policy. The 'server_notices' section\n# must also be configured for this to work. Notices will *not* be sent to\n# guest users unless 'send_server_notice_to_guests' is set to true.\n#\n# 'block_events_error', if set, will block any attempts to send events\n# until the user consents to the privacy policy. The value of the setting is\n# used as the text of the error.\n#\n# 'require_at_registration', if enabled, will add a step to the registration\n# process, similar to how captcha works. Users will be required to accept the\n# policy before their account is created.\n#\n# 'policy_name' is the display name of the policy users will see when registering\n# for an account. Has no effect unless `require_at_registration` is enabled.\n# Defaults to \"Privacy Policy\".\n#\n#user_consent:\n#  template_dir: res/templates/privacy\n#  version: 1.0\n#  server_notice_content:\n#    msgtype: m.text\n#    body: >-\n#      To continue using this homeserver you must review and agree to the\n#      terms and conditions at %(consent_uri)s\n#  send_server_notice_to_guests: true\n#  block_events_error: >-\n#    To continue using this homeserver you must review and agree to the\n#    terms and conditions at %(consent_uri)s\n#  require_at_registration: false\n#  policy_name: Privacy Policy\n#\n\"\"\"\n\n\nclass ConsentConfig(Config):\n\n    section = \"consent\"\n\n    def __init__(self, *args):\n        super().__init__(*args)\n\n        self.user_consent_version = None\n        self.user_consent_template_dir = None\n        self.user_consent_server_notice_content = None\n        self.user_consent_server_notice_to_guests = False\n        self.block_events_without_consent_error = None\n        self.user_consent_at_registration = False\n        self.user_consent_policy_name = \"Privacy Policy\"\n\n    def read_config(self, config, **kwargs):\n        consent_config = config.get(\"user_consent\")\n        self.terms_template = self.read_template(\"terms.html\")\n\n        if consent_config is None:\n            return\n        self.user_consent_version = str(consent_config[\"version\"])\n        self.user_consent_template_dir = self.abspath(consent_config[\"template_dir\"])\n        if not path.isdir(self.user_consent_template_dir):\n            raise ConfigError(\n                \"Could not find template directory '%s'\"\n                % (self.user_consent_template_dir,)\n            )\n        self.user_consent_server_notice_content = consent_config.get(\n            \"server_notice_content\"\n        )\n        self.block_events_without_consent_error = consent_config.get(\n            \"block_events_error\"\n        )\n        self.user_consent_server_notice_to_guests = bool(\n            consent_config.get(\"send_server_notice_to_guests\", False)\n        )\n        self.user_consent_at_registration = bool(\n            consent_config.get(\"require_at_registration\", False)\n        )\n        self.user_consent_policy_name = consent_config.get(\n            \"policy_name\", \"Privacy Policy\"\n        )\n\n    def generate_config_section(self, **kwargs):\n        return DEFAULT_CONFIG\n", "code_before": "# -*- coding: utf-8 -*-\n# Copyright 2018 New Vector Ltd\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nfrom os import path\n\nfrom synapse.config import ConfigError\n\nfrom ._base import Config\n\nDEFAULT_CONFIG = \"\"\"\\\n# User Consent configuration\n#\n# for detailed instructions, see\n# https://github.com/matrix-org/synapse/blob/master/docs/consent_tracking.md\n#\n# Parts of this section are required if enabling the 'consent' resource under\n# 'listeners', in particular 'template_dir' and 'version'.\n#\n# 'template_dir' gives the location of the templates for the HTML forms.\n# This directory should contain one subdirectory per language (eg, 'en', 'fr'),\n# and each language directory should contain the policy document (named as\n# '<version>.html') and a success page (success.html).\n#\n# 'version' specifies the 'current' version of the policy document. It defines\n# the version to be served by the consent resource if there is no 'v'\n# parameter.\n#\n# 'server_notice_content', if enabled, will send a user a \"Server Notice\"\n# asking them to consent to the privacy policy. The 'server_notices' section\n# must also be configured for this to work. Notices will *not* be sent to\n# guest users unless 'send_server_notice_to_guests' is set to true.\n#\n# 'block_events_error', if set, will block any attempts to send events\n# until the user consents to the privacy policy. The value of the setting is\n# used as the text of the error.\n#\n# 'require_at_registration', if enabled, will add a step to the registration\n# process, similar to how captcha works. Users will be required to accept the\n# policy before their account is created.\n#\n# 'policy_name' is the display name of the policy users will see when registering\n# for an account. Has no effect unless `require_at_registration` is enabled.\n# Defaults to \"Privacy Policy\".\n#\n#user_consent:\n#  template_dir: res/templates/privacy\n#  version: 1.0\n#  server_notice_content:\n#    msgtype: m.text\n#    body: >-\n#      To continue using this homeserver you must review and agree to the\n#      terms and conditions at %(consent_uri)s\n#  send_server_notice_to_guests: true\n#  block_events_error: >-\n#    To continue using this homeserver you must review and agree to the\n#    terms and conditions at %(consent_uri)s\n#  require_at_registration: false\n#  policy_name: Privacy Policy\n#\n\"\"\"\n\n\nclass ConsentConfig(Config):\n\n    section = \"consent\"\n\n    def __init__(self, *args):\n        super().__init__(*args)\n\n        self.user_consent_version = None\n        self.user_consent_template_dir = None\n        self.user_consent_server_notice_content = None\n        self.user_consent_server_notice_to_guests = False\n        self.block_events_without_consent_error = None\n        self.user_consent_at_registration = False\n        self.user_consent_policy_name = \"Privacy Policy\"\n\n    def read_config(self, config, **kwargs):\n        consent_config = config.get(\"user_consent\")\n        self.terms_template = self.read_templates([\"terms.html\"], autoescape=True)[0]\n\n        if consent_config is None:\n            return\n        self.user_consent_version = str(consent_config[\"version\"])\n        self.user_consent_template_dir = self.abspath(consent_config[\"template_dir\"])\n        if not path.isdir(self.user_consent_template_dir):\n            raise ConfigError(\n                \"Could not find template directory '%s'\"\n                % (self.user_consent_template_dir,)\n            )\n        self.user_consent_server_notice_content = consent_config.get(\n            \"server_notice_content\"\n        )\n        self.block_events_without_consent_error = consent_config.get(\n            \"block_events_error\"\n        )\n        self.user_consent_server_notice_to_guests = bool(\n            consent_config.get(\"send_server_notice_to_guests\", False)\n        )\n        self.user_consent_at_registration = bool(\n            consent_config.get(\"require_at_registration\", False)\n        )\n        self.user_consent_policy_name = consent_config.get(\n            \"policy_name\", \"Privacy Policy\"\n        )\n\n    def generate_config_section(self, **kwargs):\n        return DEFAULT_CONFIG\n", "patch": "@@ -89,7 +89,7 @@ def __init__(self, *args):\n \n     def read_config(self, config, **kwargs):\n         consent_config = config.get(\"user_consent\")\n-        self.terms_template = self.read_templates([\"terms.html\"], autoescape=True)[0]\n+        self.terms_template = self.read_template(\"terms.html\")\n \n         if consent_config is None:\n             return", "file_path": "files/2021_3/66", "file_language": "py", "file_name": "synapse/config/consent_config.py", "outdated_file_modify": 0, "outdated_file_before": 0, "outdated_file_after": 0, "llm_check": 0, "static_check": 0, "static": {"rats": [false, []], "semgrep": [false, []]}, "target": 0, "function_before": [{"function": "class ConsentConfig(Config):\n\n    section = \"consent\"\n\n    def __init__(self, *args):\n        super().__init__(*args)\n\n        self.user_consent_version = None\n        self.user_consent_template_dir = None\n        self.user_consent_server_notice_content = None\n        self.user_consent_server_notice_to_guests = False\n        self.block_events_without_consent_error = None\n        self.user_consent_at_registration = False\n        self.user_consent_policy_name = \"Privacy Policy\"\n\n    def read_config(self, config, **kwargs):\n        consent_config = config.get(\"user_consent\")\n        self.terms_template = self.read_templates([\"terms.html\"], autoescape=True)[0]\n\n        if consent_config is None:\n            return\n        self.user_consent_version = str(consent_config[\"version\"])\n        self.user_consent_template_dir = self.abspath(consent_config[\"template_dir\"])\n        if not path.isdir(self.user_consent_template_dir):\n            raise ConfigError(\n                \"Could not find template directory '%s'\"\n                % (self.user_consent_template_dir,)\n            )\n        self.user_consent_server_notice_content = consent_config.get(\n            \"server_notice_content\"\n        )\n        self.block_events_without_consent_error = consent_config.get(\n            \"block_events_error\"\n        )\n        self.user_consent_server_notice_to_guests = bool(\n            consent_config.get(\"send_server_notice_to_guests\", False)\n        )\n        self.user_consent_at_registration = bool(\n            consent_config.get(\"require_at_registration\", False)\n        )\n        self.user_consent_policy_name = consent_config.get(\n            \"policy_name\", \"Privacy Policy\"\n        )\n\n    def generate_config_section(self, **kwargs):\n        return DEFAULT_CONFIG", "target": 0}], "function_after": [{"function": "class ConsentConfig(Config):\n\n    section = \"consent\"\n\n    def __init__(self, *args):\n        super().__init__(*args)\n\n        self.user_consent_version = None\n        self.user_consent_template_dir = None\n        self.user_consent_server_notice_content = None\n        self.user_consent_server_notice_to_guests = False\n        self.block_events_without_consent_error = None\n        self.user_consent_at_registration = False\n        self.user_consent_policy_name = \"Privacy Policy\"\n\n    def read_config(self, config, **kwargs):\n        consent_config = config.get(\"user_consent\")\n        self.terms_template = self.read_template(\"terms.html\")\n\n        if consent_config is None:\n            return\n        self.user_consent_version = str(consent_config[\"version\"])\n        self.user_consent_template_dir = self.abspath(consent_config[\"template_dir\"])\n        if not path.isdir(self.user_consent_template_dir):\n            raise ConfigError(\n                \"Could not find template directory '%s'\"\n                % (self.user_consent_template_dir,)\n            )\n        self.user_consent_server_notice_content = consent_config.get(\n            \"server_notice_content\"\n        )\n        self.block_events_without_consent_error = consent_config.get(\n            \"block_events_error\"\n        )\n        self.user_consent_server_notice_to_guests = bool(\n            consent_config.get(\"send_server_notice_to_guests\", False)\n        )\n        self.user_consent_at_registration = bool(\n            consent_config.get(\"require_at_registration\", False)\n        )\n        self.user_consent_policy_name = consent_config.get(\n            \"policy_name\", \"Privacy Policy\"\n        )\n\n    def generate_config_section(self, **kwargs):\n        return DEFAULT_CONFIG", "target": 0}]}, {"raw_url": "https://github.com/matrix-org/synapse/raw/e54746bdf7d5c831eabe4dcea76a7626f1de73df/synapse%2Fconfig%2Fregistration.py", "code": "# -*- coding: utf-8 -*-\n# Copyright 2015, 2016 OpenMarket Ltd\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport os\n\nimport pkg_resources\n\nfrom synapse.api.constants import RoomCreationPreset\nfrom synapse.config._base import Config, ConfigError\nfrom synapse.types import RoomAlias, UserID\nfrom synapse.util.stringutils import random_string_with_symbols, strtobool\n\n\nclass AccountValidityConfig(Config):\n    section = \"accountvalidity\"\n\n    def __init__(self, config, synapse_config):\n        if config is None:\n            return\n        super().__init__()\n        self.enabled = config.get(\"enabled\", False)\n        self.renew_by_email_enabled = \"renew_at\" in config\n\n        if self.enabled:\n            if \"period\" in config:\n                self.period = self.parse_duration(config[\"period\"])\n            else:\n                raise ConfigError(\"'period' is required when using account validity\")\n\n            if \"renew_at\" in config:\n                self.renew_at = self.parse_duration(config[\"renew_at\"])\n\n            if \"renew_email_subject\" in config:\n                self.renew_email_subject = config[\"renew_email_subject\"]\n            else:\n                self.renew_email_subject = \"Renew your %(app)s account\"\n\n            self.startup_job_max_delta = self.period * 10.0 / 100.0\n\n        template_dir = config.get(\"template_dir\")\n\n        if not template_dir:\n            template_dir = pkg_resources.resource_filename(\"synapse\", \"res/templates\")\n\n        if \"account_renewed_html_path\" in config:\n            file_path = os.path.join(template_dir, config[\"account_renewed_html_path\"])\n\n            self.account_renewed_html_content = self.read_file(\n                file_path, \"account_validity.account_renewed_html_path\"\n            )\n        else:\n            self.account_renewed_html_content = (\n                \"<html><body>Your account has been successfully renewed.</body><html>\"\n            )\n\n        if \"invalid_token_html_path\" in config:\n            file_path = os.path.join(template_dir, config[\"invalid_token_html_path\"])\n\n            self.invalid_token_html_content = self.read_file(\n                file_path, \"account_validity.invalid_token_html_path\"\n            )\n        else:\n            self.invalid_token_html_content = (\n                \"<html><body>Invalid renewal token.</body><html>\"\n            )\n\n\nclass RegistrationConfig(Config):\n    section = \"registration\"\n\n    def read_config(self, config, **kwargs):\n        self.enable_registration = strtobool(\n            str(config.get(\"enable_registration\", False))\n        )\n        if \"disable_registration\" in config:\n            self.enable_registration = not strtobool(\n                str(config[\"disable_registration\"])\n            )\n\n        self.account_validity = AccountValidityConfig(\n            config.get(\"account_validity\") or {}, config\n        )\n\n        self.registrations_require_3pid = config.get(\"registrations_require_3pid\", [])\n        self.allowed_local_3pids = config.get(\"allowed_local_3pids\", [])\n        self.enable_3pid_lookup = config.get(\"enable_3pid_lookup\", True)\n        self.registration_shared_secret = config.get(\"registration_shared_secret\")\n\n        self.bcrypt_rounds = config.get(\"bcrypt_rounds\", 12)\n        self.trusted_third_party_id_servers = config.get(\n            \"trusted_third_party_id_servers\", [\"matrix.org\", \"vector.im\"]\n        )\n        account_threepid_delegates = config.get(\"account_threepid_delegates\") or {}\n        self.account_threepid_delegate_email = account_threepid_delegates.get(\"email\")\n        self.account_threepid_delegate_msisdn = account_threepid_delegates.get(\"msisdn\")\n\n        self.default_identity_server = config.get(\"default_identity_server\")\n        self.allow_guest_access = config.get(\"allow_guest_access\", False)\n\n        if config.get(\"invite_3pid_guest\", False):\n            raise ConfigError(\"invite_3pid_guest is no longer supported\")\n\n        self.auto_join_rooms = config.get(\"auto_join_rooms\", [])\n        for room_alias in self.auto_join_rooms:\n            if not RoomAlias.is_valid(room_alias):\n                raise ConfigError(\"Invalid auto_join_rooms entry %s\" % (room_alias,))\n\n        # Options for creating auto-join rooms if they do not exist yet.\n        self.autocreate_auto_join_rooms = config.get(\"autocreate_auto_join_rooms\", True)\n        self.autocreate_auto_join_rooms_federated = config.get(\n            \"autocreate_auto_join_rooms_federated\", True\n        )\n        self.autocreate_auto_join_room_preset = (\n            config.get(\"autocreate_auto_join_room_preset\")\n            or RoomCreationPreset.PUBLIC_CHAT\n        )\n        self.auto_join_room_requires_invite = self.autocreate_auto_join_room_preset in {\n            RoomCreationPreset.PRIVATE_CHAT,\n            RoomCreationPreset.TRUSTED_PRIVATE_CHAT,\n        }\n\n        # Pull the creator/inviter from the configuration, this gets used to\n        # send invites for invite-only rooms.\n        mxid_localpart = config.get(\"auto_join_mxid_localpart\")\n        self.auto_join_user_id = None\n        if mxid_localpart:\n            # Convert the localpart to a full mxid.\n            self.auto_join_user_id = UserID(\n                mxid_localpart, self.server_name\n            ).to_string()\n\n        if self.autocreate_auto_join_rooms:\n            # Ensure the preset is a known value.\n            if self.autocreate_auto_join_room_preset not in {\n                RoomCreationPreset.PUBLIC_CHAT,\n                RoomCreationPreset.PRIVATE_CHAT,\n                RoomCreationPreset.TRUSTED_PRIVATE_CHAT,\n            }:\n                raise ConfigError(\"Invalid value for autocreate_auto_join_room_preset\")\n            # If the preset requires invitations to be sent, ensure there's a\n            # configured user to send them from.\n            if self.auto_join_room_requires_invite:\n                if not mxid_localpart:\n                    raise ConfigError(\n                        \"The configuration option `auto_join_mxid_localpart` is required if \"\n                        \"`autocreate_auto_join_room_preset` is set to private_chat or trusted_private_chat, such that \"\n                        \"Synapse knows who to send invitations from. Please \"\n                        \"configure `auto_join_mxid_localpart`.\"\n                    )\n\n        self.auto_join_rooms_for_guests = config.get(\"auto_join_rooms_for_guests\", True)\n\n        self.enable_set_displayname = config.get(\"enable_set_displayname\", True)\n        self.enable_set_avatar_url = config.get(\"enable_set_avatar_url\", True)\n        self.enable_3pid_changes = config.get(\"enable_3pid_changes\", True)\n\n        self.disable_msisdn_registration = config.get(\n            \"disable_msisdn_registration\", False\n        )\n\n        session_lifetime = config.get(\"session_lifetime\")\n        if session_lifetime is not None:\n            session_lifetime = self.parse_duration(session_lifetime)\n        self.session_lifetime = session_lifetime\n\n        # The success template used during fallback auth.\n        self.fallback_success_template = self.read_template(\"auth_success.html\")\n\n    def generate_config_section(self, generate_secrets=False, **kwargs):\n        if generate_secrets:\n            registration_shared_secret = 'registration_shared_secret: \"%s\"' % (\n                random_string_with_symbols(50),\n            )\n        else:\n            registration_shared_secret = \"#registration_shared_secret: <PRIVATE STRING>\"\n\n        return (\n            \"\"\"\\\n        ## Registration ##\n        #\n        # Registration can be rate-limited using the parameters in the \"Ratelimiting\"\n        # section of this file.\n\n        # Enable registration for new users.\n        #\n        #enable_registration: false\n\n        # Optional account validity configuration. This allows for accounts to be denied\n        # any request after a given period.\n        #\n        # Once this feature is enabled, Synapse will look for registered users without an\n        # expiration date at startup and will add one to every account it found using the\n        # current settings at that time.\n        # This means that, if a validity period is set, and Synapse is restarted (it will\n        # then derive an expiration date from the current validity period), and some time\n        # after that the validity period changes and Synapse is restarted, the users'\n        # expiration dates won't be updated unless their account is manually renewed. This\n        # date will be randomly selected within a range [now + period - d ; now + period],\n        # where d is equal to 10%% of the validity period.\n        #\n        account_validity:\n          # The account validity feature is disabled by default. Uncomment the\n          # following line to enable it.\n          #\n          #enabled: true\n\n          # The period after which an account is valid after its registration. When\n          # renewing the account, its validity period will be extended by this amount\n          # of time. This parameter is required when using the account validity\n          # feature.\n          #\n          #period: 6w\n\n          # The amount of time before an account's expiry date at which Synapse will\n          # send an email to the account's email address with a renewal link. By\n          # default, no such emails are sent.\n          #\n          # If you enable this setting, you will also need to fill out the 'email'\n          # configuration section. You should also check that 'public_baseurl' is set\n          # correctly.\n          #\n          #renew_at: 1w\n\n          # The subject of the email sent out with the renewal link. '%%(app)s' can be\n          # used as a placeholder for the 'app_name' parameter from the 'email'\n          # section.\n          #\n          # Note that the placeholder must be written '%%(app)s', including the\n          # trailing 's'.\n          #\n          # If this is not set, a default value is used.\n          #\n          #renew_email_subject: \"Renew your %%(app)s account\"\n\n          # Directory in which Synapse will try to find templates for the HTML files to\n          # serve to the user when trying to renew an account. If not set, default\n          # templates from within the Synapse package will be used.\n          #\n          #template_dir: \"res/templates\"\n\n          # File within 'template_dir' giving the HTML to be displayed to the user after\n          # they successfully renewed their account. If not set, default text is used.\n          #\n          #account_renewed_html_path: \"account_renewed.html\"\n\n          # File within 'template_dir' giving the HTML to be displayed when the user\n          # tries to renew an account with an invalid renewal token. If not set,\n          # default text is used.\n          #\n          #invalid_token_html_path: \"invalid_token.html\"\n\n        # Time that a user's session remains valid for, after they log in.\n        #\n        # Note that this is not currently compatible with guest logins.\n        #\n        # Note also that this is calculated at login time: changes are not applied\n        # retrospectively to users who have already logged in.\n        #\n        # By default, this is infinite.\n        #\n        #session_lifetime: 24h\n\n        # The user must provide all of the below types of 3PID when registering.\n        #\n        #registrations_require_3pid:\n        #  - email\n        #  - msisdn\n\n        # Explicitly disable asking for MSISDNs from the registration\n        # flow (overrides registrations_require_3pid if MSISDNs are set as required)\n        #\n        #disable_msisdn_registration: true\n\n        # Mandate that users are only allowed to associate certain formats of\n        # 3PIDs with accounts on this server.\n        #\n        #allowed_local_3pids:\n        #  - medium: email\n        #    pattern: '.*@matrix\\\\.org'\n        #  - medium: email\n        #    pattern: '.*@vector\\\\.im'\n        #  - medium: msisdn\n        #    pattern: '\\\\+44'\n\n        # Enable 3PIDs lookup requests to identity servers from this server.\n        #\n        #enable_3pid_lookup: true\n\n        # If set, allows registration of standard or admin accounts by anyone who\n        # has the shared secret, even if registration is otherwise disabled.\n        #\n        %(registration_shared_secret)s\n\n        # Set the number of bcrypt rounds used to generate password hash.\n        # Larger numbers increase the work factor needed to generate the hash.\n        # The default number is 12 (which equates to 2^12 rounds).\n        # N.B. that increasing this will exponentially increase the time required\n        # to register or login - e.g. 24 => 2^24 rounds which will take >20 mins.\n        #\n        #bcrypt_rounds: 12\n\n        # Allows users to register as guests without a password/email/etc, and\n        # participate in rooms hosted on this server which have been made\n        # accessible to anonymous users.\n        #\n        #allow_guest_access: false\n\n        # The identity server which we suggest that clients should use when users log\n        # in on this server.\n        #\n        # (By default, no suggestion is made, so it is left up to the client.)\n        #\n        #default_identity_server: https://matrix.org\n\n        # Handle threepid (email/phone etc) registration and password resets through a set of\n        # *trusted* identity servers. Note that this allows the configured identity server to\n        # reset passwords for accounts!\n        #\n        # Be aware that if `email` is not set, and SMTP options have not been\n        # configured in the email config block, registration and user password resets via\n        # email will be globally disabled.\n        #\n        # Additionally, if `msisdn` is not set, registration and password resets via msisdn\n        # will be disabled regardless, and users will not be able to associate an msisdn\n        # identifier to their account. This is due to Synapse currently not supporting\n        # any method of sending SMS messages on its own.\n        #\n        # To enable using an identity server for operations regarding a particular third-party\n        # identifier type, set the value to the URL of that identity server as shown in the\n        # examples below.\n        #\n        # Servers handling the these requests must answer the `/requestToken` endpoints defined\n        # by the Matrix Identity Service API specification:\n        # https://matrix.org/docs/spec/identity_service/latest\n        #\n        account_threepid_delegates:\n            #email: https://example.com     # Delegate email sending to example.com\n            #msisdn: http://localhost:8090  # Delegate SMS sending to this local process\n\n        # Whether users are allowed to change their displayname after it has\n        # been initially set. Useful when provisioning users based on the\n        # contents of a third-party directory.\n        #\n        # Does not apply to server administrators. Defaults to 'true'\n        #\n        #enable_set_displayname: false\n\n        # Whether users are allowed to change their avatar after it has been\n        # initially set. Useful when provisioning users based on the contents\n        # of a third-party directory.\n        #\n        # Does not apply to server administrators. Defaults to 'true'\n        #\n        #enable_set_avatar_url: false\n\n        # Whether users can change the 3PIDs associated with their accounts\n        # (email address and msisdn).\n        #\n        # Defaults to 'true'\n        #\n        #enable_3pid_changes: false\n\n        # Users who register on this homeserver will automatically be joined\n        # to these rooms.\n        #\n        # By default, any room aliases included in this list will be created\n        # as a publicly joinable room when the first user registers for the\n        # homeserver. This behaviour can be customised with the settings below.\n        #\n        #auto_join_rooms:\n        #  - \"#example:example.com\"\n\n        # Where auto_join_rooms are specified, setting this flag ensures that the\n        # the rooms exist by creating them when the first user on the\n        # homeserver registers.\n        #\n        # By default the auto-created rooms are publicly joinable from any federated\n        # server. Use the autocreate_auto_join_rooms_federated and\n        # autocreate_auto_join_room_preset settings below to customise this behaviour.\n        #\n        # Setting to false means that if the rooms are not manually created,\n        # users cannot be auto-joined since they do not exist.\n        #\n        # Defaults to true. Uncomment the following line to disable automatically\n        # creating auto-join rooms.\n        #\n        #autocreate_auto_join_rooms: false\n\n        # Whether the auto_join_rooms that are auto-created are available via\n        # federation. Only has an effect if autocreate_auto_join_rooms is true.\n        #\n        # Note that whether a room is federated cannot be modified after\n        # creation.\n        #\n        # Defaults to true: the room will be joinable from other servers.\n        # Uncomment the following to prevent users from other homeservers from\n        # joining these rooms.\n        #\n        #autocreate_auto_join_rooms_federated: false\n\n        # The room preset to use when auto-creating one of auto_join_rooms. Only has an\n        # effect if autocreate_auto_join_rooms is true.\n        #\n        # This can be one of \"public_chat\", \"private_chat\", or \"trusted_private_chat\".\n        # If a value of \"private_chat\" or \"trusted_private_chat\" is used then\n        # auto_join_mxid_localpart must also be configured.\n        #\n        # Defaults to \"public_chat\", meaning that the room is joinable by anyone, including\n        # federated servers if autocreate_auto_join_rooms_federated is true (the default).\n        # Uncomment the following to require an invitation to join these rooms.\n        #\n        #autocreate_auto_join_room_preset: private_chat\n\n        # The local part of the user id which is used to create auto_join_rooms if\n        # autocreate_auto_join_rooms is true. If this is not provided then the\n        # initial user account that registers will be used to create the rooms.\n        #\n        # The user id is also used to invite new users to any auto-join rooms which\n        # are set to invite-only.\n        #\n        # It *must* be configured if autocreate_auto_join_room_preset is set to\n        # \"private_chat\" or \"trusted_private_chat\".\n        #\n        # Note that this must be specified in order for new users to be correctly\n        # invited to any auto-join rooms which have been set to invite-only (either\n        # at the time of creation or subsequently).\n        #\n        # Note that, if the room already exists, this user must be joined and\n        # have the appropriate permissions to invite new members.\n        #\n        #auto_join_mxid_localpart: system\n\n        # When auto_join_rooms is specified, setting this flag to false prevents\n        # guest accounts from being automatically joined to the rooms.\n        #\n        # Defaults to true.\n        #\n        #auto_join_rooms_for_guests: false\n        \"\"\"\n            % locals()\n        )\n\n    @staticmethod\n    def add_arguments(parser):\n        reg_group = parser.add_argument_group(\"registration\")\n        reg_group.add_argument(\n            \"--enable-registration\",\n            action=\"store_true\",\n            default=None,\n            help=\"Enable registration for new users.\",\n        )\n\n    def read_arguments(self, args):\n        if args.enable_registration is not None:\n            self.enable_registration = bool(strtobool(str(args.enable_registration)))\n", "code_before": "# -*- coding: utf-8 -*-\n# Copyright 2015, 2016 OpenMarket Ltd\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport os\n\nimport pkg_resources\n\nfrom synapse.api.constants import RoomCreationPreset\nfrom synapse.config._base import Config, ConfigError\nfrom synapse.types import RoomAlias, UserID\nfrom synapse.util.stringutils import random_string_with_symbols, strtobool\n\n\nclass AccountValidityConfig(Config):\n    section = \"accountvalidity\"\n\n    def __init__(self, config, synapse_config):\n        if config is None:\n            return\n        super().__init__()\n        self.enabled = config.get(\"enabled\", False)\n        self.renew_by_email_enabled = \"renew_at\" in config\n\n        if self.enabled:\n            if \"period\" in config:\n                self.period = self.parse_duration(config[\"period\"])\n            else:\n                raise ConfigError(\"'period' is required when using account validity\")\n\n            if \"renew_at\" in config:\n                self.renew_at = self.parse_duration(config[\"renew_at\"])\n\n            if \"renew_email_subject\" in config:\n                self.renew_email_subject = config[\"renew_email_subject\"]\n            else:\n                self.renew_email_subject = \"Renew your %(app)s account\"\n\n            self.startup_job_max_delta = self.period * 10.0 / 100.0\n\n        template_dir = config.get(\"template_dir\")\n\n        if not template_dir:\n            template_dir = pkg_resources.resource_filename(\"synapse\", \"res/templates\")\n\n        if \"account_renewed_html_path\" in config:\n            file_path = os.path.join(template_dir, config[\"account_renewed_html_path\"])\n\n            self.account_renewed_html_content = self.read_file(\n                file_path, \"account_validity.account_renewed_html_path\"\n            )\n        else:\n            self.account_renewed_html_content = (\n                \"<html><body>Your account has been successfully renewed.</body><html>\"\n            )\n\n        if \"invalid_token_html_path\" in config:\n            file_path = os.path.join(template_dir, config[\"invalid_token_html_path\"])\n\n            self.invalid_token_html_content = self.read_file(\n                file_path, \"account_validity.invalid_token_html_path\"\n            )\n        else:\n            self.invalid_token_html_content = (\n                \"<html><body>Invalid renewal token.</body><html>\"\n            )\n\n\nclass RegistrationConfig(Config):\n    section = \"registration\"\n\n    def read_config(self, config, **kwargs):\n        self.enable_registration = strtobool(\n            str(config.get(\"enable_registration\", False))\n        )\n        if \"disable_registration\" in config:\n            self.enable_registration = not strtobool(\n                str(config[\"disable_registration\"])\n            )\n\n        self.account_validity = AccountValidityConfig(\n            config.get(\"account_validity\") or {}, config\n        )\n\n        self.registrations_require_3pid = config.get(\"registrations_require_3pid\", [])\n        self.allowed_local_3pids = config.get(\"allowed_local_3pids\", [])\n        self.enable_3pid_lookup = config.get(\"enable_3pid_lookup\", True)\n        self.registration_shared_secret = config.get(\"registration_shared_secret\")\n\n        self.bcrypt_rounds = config.get(\"bcrypt_rounds\", 12)\n        self.trusted_third_party_id_servers = config.get(\n            \"trusted_third_party_id_servers\", [\"matrix.org\", \"vector.im\"]\n        )\n        account_threepid_delegates = config.get(\"account_threepid_delegates\") or {}\n        self.account_threepid_delegate_email = account_threepid_delegates.get(\"email\")\n        self.account_threepid_delegate_msisdn = account_threepid_delegates.get(\"msisdn\")\n\n        self.default_identity_server = config.get(\"default_identity_server\")\n        self.allow_guest_access = config.get(\"allow_guest_access\", False)\n\n        if config.get(\"invite_3pid_guest\", False):\n            raise ConfigError(\"invite_3pid_guest is no longer supported\")\n\n        self.auto_join_rooms = config.get(\"auto_join_rooms\", [])\n        for room_alias in self.auto_join_rooms:\n            if not RoomAlias.is_valid(room_alias):\n                raise ConfigError(\"Invalid auto_join_rooms entry %s\" % (room_alias,))\n\n        # Options for creating auto-join rooms if they do not exist yet.\n        self.autocreate_auto_join_rooms = config.get(\"autocreate_auto_join_rooms\", True)\n        self.autocreate_auto_join_rooms_federated = config.get(\n            \"autocreate_auto_join_rooms_federated\", True\n        )\n        self.autocreate_auto_join_room_preset = (\n            config.get(\"autocreate_auto_join_room_preset\")\n            or RoomCreationPreset.PUBLIC_CHAT\n        )\n        self.auto_join_room_requires_invite = self.autocreate_auto_join_room_preset in {\n            RoomCreationPreset.PRIVATE_CHAT,\n            RoomCreationPreset.TRUSTED_PRIVATE_CHAT,\n        }\n\n        # Pull the creator/inviter from the configuration, this gets used to\n        # send invites for invite-only rooms.\n        mxid_localpart = config.get(\"auto_join_mxid_localpart\")\n        self.auto_join_user_id = None\n        if mxid_localpart:\n            # Convert the localpart to a full mxid.\n            self.auto_join_user_id = UserID(\n                mxid_localpart, self.server_name\n            ).to_string()\n\n        if self.autocreate_auto_join_rooms:\n            # Ensure the preset is a known value.\n            if self.autocreate_auto_join_room_preset not in {\n                RoomCreationPreset.PUBLIC_CHAT,\n                RoomCreationPreset.PRIVATE_CHAT,\n                RoomCreationPreset.TRUSTED_PRIVATE_CHAT,\n            }:\n                raise ConfigError(\"Invalid value for autocreate_auto_join_room_preset\")\n            # If the preset requires invitations to be sent, ensure there's a\n            # configured user to send them from.\n            if self.auto_join_room_requires_invite:\n                if not mxid_localpart:\n                    raise ConfigError(\n                        \"The configuration option `auto_join_mxid_localpart` is required if \"\n                        \"`autocreate_auto_join_room_preset` is set to private_chat or trusted_private_chat, such that \"\n                        \"Synapse knows who to send invitations from. Please \"\n                        \"configure `auto_join_mxid_localpart`.\"\n                    )\n\n        self.auto_join_rooms_for_guests = config.get(\"auto_join_rooms_for_guests\", True)\n\n        self.enable_set_displayname = config.get(\"enable_set_displayname\", True)\n        self.enable_set_avatar_url = config.get(\"enable_set_avatar_url\", True)\n        self.enable_3pid_changes = config.get(\"enable_3pid_changes\", True)\n\n        self.disable_msisdn_registration = config.get(\n            \"disable_msisdn_registration\", False\n        )\n\n        session_lifetime = config.get(\"session_lifetime\")\n        if session_lifetime is not None:\n            session_lifetime = self.parse_duration(session_lifetime)\n        self.session_lifetime = session_lifetime\n\n        # The success template used during fallback auth.\n        self.fallback_success_template = self.read_templates(\n            [\"auth_success.html\"], autoescape=True\n        )[0]\n\n    def generate_config_section(self, generate_secrets=False, **kwargs):\n        if generate_secrets:\n            registration_shared_secret = 'registration_shared_secret: \"%s\"' % (\n                random_string_with_symbols(50),\n            )\n        else:\n            registration_shared_secret = \"#registration_shared_secret: <PRIVATE STRING>\"\n\n        return (\n            \"\"\"\\\n        ## Registration ##\n        #\n        # Registration can be rate-limited using the parameters in the \"Ratelimiting\"\n        # section of this file.\n\n        # Enable registration for new users.\n        #\n        #enable_registration: false\n\n        # Optional account validity configuration. This allows for accounts to be denied\n        # any request after a given period.\n        #\n        # Once this feature is enabled, Synapse will look for registered users without an\n        # expiration date at startup and will add one to every account it found using the\n        # current settings at that time.\n        # This means that, if a validity period is set, and Synapse is restarted (it will\n        # then derive an expiration date from the current validity period), and some time\n        # after that the validity period changes and Synapse is restarted, the users'\n        # expiration dates won't be updated unless their account is manually renewed. This\n        # date will be randomly selected within a range [now + period - d ; now + period],\n        # where d is equal to 10%% of the validity period.\n        #\n        account_validity:\n          # The account validity feature is disabled by default. Uncomment the\n          # following line to enable it.\n          #\n          #enabled: true\n\n          # The period after which an account is valid after its registration. When\n          # renewing the account, its validity period will be extended by this amount\n          # of time. This parameter is required when using the account validity\n          # feature.\n          #\n          #period: 6w\n\n          # The amount of time before an account's expiry date at which Synapse will\n          # send an email to the account's email address with a renewal link. By\n          # default, no such emails are sent.\n          #\n          # If you enable this setting, you will also need to fill out the 'email'\n          # configuration section. You should also check that 'public_baseurl' is set\n          # correctly.\n          #\n          #renew_at: 1w\n\n          # The subject of the email sent out with the renewal link. '%%(app)s' can be\n          # used as a placeholder for the 'app_name' parameter from the 'email'\n          # section.\n          #\n          # Note that the placeholder must be written '%%(app)s', including the\n          # trailing 's'.\n          #\n          # If this is not set, a default value is used.\n          #\n          #renew_email_subject: \"Renew your %%(app)s account\"\n\n          # Directory in which Synapse will try to find templates for the HTML files to\n          # serve to the user when trying to renew an account. If not set, default\n          # templates from within the Synapse package will be used.\n          #\n          #template_dir: \"res/templates\"\n\n          # File within 'template_dir' giving the HTML to be displayed to the user after\n          # they successfully renewed their account. If not set, default text is used.\n          #\n          #account_renewed_html_path: \"account_renewed.html\"\n\n          # File within 'template_dir' giving the HTML to be displayed when the user\n          # tries to renew an account with an invalid renewal token. If not set,\n          # default text is used.\n          #\n          #invalid_token_html_path: \"invalid_token.html\"\n\n        # Time that a user's session remains valid for, after they log in.\n        #\n        # Note that this is not currently compatible with guest logins.\n        #\n        # Note also that this is calculated at login time: changes are not applied\n        # retrospectively to users who have already logged in.\n        #\n        # By default, this is infinite.\n        #\n        #session_lifetime: 24h\n\n        # The user must provide all of the below types of 3PID when registering.\n        #\n        #registrations_require_3pid:\n        #  - email\n        #  - msisdn\n\n        # Explicitly disable asking for MSISDNs from the registration\n        # flow (overrides registrations_require_3pid if MSISDNs are set as required)\n        #\n        #disable_msisdn_registration: true\n\n        # Mandate that users are only allowed to associate certain formats of\n        # 3PIDs with accounts on this server.\n        #\n        #allowed_local_3pids:\n        #  - medium: email\n        #    pattern: '.*@matrix\\\\.org'\n        #  - medium: email\n        #    pattern: '.*@vector\\\\.im'\n        #  - medium: msisdn\n        #    pattern: '\\\\+44'\n\n        # Enable 3PIDs lookup requests to identity servers from this server.\n        #\n        #enable_3pid_lookup: true\n\n        # If set, allows registration of standard or admin accounts by anyone who\n        # has the shared secret, even if registration is otherwise disabled.\n        #\n        %(registration_shared_secret)s\n\n        # Set the number of bcrypt rounds used to generate password hash.\n        # Larger numbers increase the work factor needed to generate the hash.\n        # The default number is 12 (which equates to 2^12 rounds).\n        # N.B. that increasing this will exponentially increase the time required\n        # to register or login - e.g. 24 => 2^24 rounds which will take >20 mins.\n        #\n        #bcrypt_rounds: 12\n\n        # Allows users to register as guests without a password/email/etc, and\n        # participate in rooms hosted on this server which have been made\n        # accessible to anonymous users.\n        #\n        #allow_guest_access: false\n\n        # The identity server which we suggest that clients should use when users log\n        # in on this server.\n        #\n        # (By default, no suggestion is made, so it is left up to the client.)\n        #\n        #default_identity_server: https://matrix.org\n\n        # Handle threepid (email/phone etc) registration and password resets through a set of\n        # *trusted* identity servers. Note that this allows the configured identity server to\n        # reset passwords for accounts!\n        #\n        # Be aware that if `email` is not set, and SMTP options have not been\n        # configured in the email config block, registration and user password resets via\n        # email will be globally disabled.\n        #\n        # Additionally, if `msisdn` is not set, registration and password resets via msisdn\n        # will be disabled regardless, and users will not be able to associate an msisdn\n        # identifier to their account. This is due to Synapse currently not supporting\n        # any method of sending SMS messages on its own.\n        #\n        # To enable using an identity server for operations regarding a particular third-party\n        # identifier type, set the value to the URL of that identity server as shown in the\n        # examples below.\n        #\n        # Servers handling the these requests must answer the `/requestToken` endpoints defined\n        # by the Matrix Identity Service API specification:\n        # https://matrix.org/docs/spec/identity_service/latest\n        #\n        account_threepid_delegates:\n            #email: https://example.com     # Delegate email sending to example.com\n            #msisdn: http://localhost:8090  # Delegate SMS sending to this local process\n\n        # Whether users are allowed to change their displayname after it has\n        # been initially set. Useful when provisioning users based on the\n        # contents of a third-party directory.\n        #\n        # Does not apply to server administrators. Defaults to 'true'\n        #\n        #enable_set_displayname: false\n\n        # Whether users are allowed to change their avatar after it has been\n        # initially set. Useful when provisioning users based on the contents\n        # of a third-party directory.\n        #\n        # Does not apply to server administrators. Defaults to 'true'\n        #\n        #enable_set_avatar_url: false\n\n        # Whether users can change the 3PIDs associated with their accounts\n        # (email address and msisdn).\n        #\n        # Defaults to 'true'\n        #\n        #enable_3pid_changes: false\n\n        # Users who register on this homeserver will automatically be joined\n        # to these rooms.\n        #\n        # By default, any room aliases included in this list will be created\n        # as a publicly joinable room when the first user registers for the\n        # homeserver. This behaviour can be customised with the settings below.\n        #\n        #auto_join_rooms:\n        #  - \"#example:example.com\"\n\n        # Where auto_join_rooms are specified, setting this flag ensures that the\n        # the rooms exist by creating them when the first user on the\n        # homeserver registers.\n        #\n        # By default the auto-created rooms are publicly joinable from any federated\n        # server. Use the autocreate_auto_join_rooms_federated and\n        # autocreate_auto_join_room_preset settings below to customise this behaviour.\n        #\n        # Setting to false means that if the rooms are not manually created,\n        # users cannot be auto-joined since they do not exist.\n        #\n        # Defaults to true. Uncomment the following line to disable automatically\n        # creating auto-join rooms.\n        #\n        #autocreate_auto_join_rooms: false\n\n        # Whether the auto_join_rooms that are auto-created are available via\n        # federation. Only has an effect if autocreate_auto_join_rooms is true.\n        #\n        # Note that whether a room is federated cannot be modified after\n        # creation.\n        #\n        # Defaults to true: the room will be joinable from other servers.\n        # Uncomment the following to prevent users from other homeservers from\n        # joining these rooms.\n        #\n        #autocreate_auto_join_rooms_federated: false\n\n        # The room preset to use when auto-creating one of auto_join_rooms. Only has an\n        # effect if autocreate_auto_join_rooms is true.\n        #\n        # This can be one of \"public_chat\", \"private_chat\", or \"trusted_private_chat\".\n        # If a value of \"private_chat\" or \"trusted_private_chat\" is used then\n        # auto_join_mxid_localpart must also be configured.\n        #\n        # Defaults to \"public_chat\", meaning that the room is joinable by anyone, including\n        # federated servers if autocreate_auto_join_rooms_federated is true (the default).\n        # Uncomment the following to require an invitation to join these rooms.\n        #\n        #autocreate_auto_join_room_preset: private_chat\n\n        # The local part of the user id which is used to create auto_join_rooms if\n        # autocreate_auto_join_rooms is true. If this is not provided then the\n        # initial user account that registers will be used to create the rooms.\n        #\n        # The user id is also used to invite new users to any auto-join rooms which\n        # are set to invite-only.\n        #\n        # It *must* be configured if autocreate_auto_join_room_preset is set to\n        # \"private_chat\" or \"trusted_private_chat\".\n        #\n        # Note that this must be specified in order for new users to be correctly\n        # invited to any auto-join rooms which have been set to invite-only (either\n        # at the time of creation or subsequently).\n        #\n        # Note that, if the room already exists, this user must be joined and\n        # have the appropriate permissions to invite new members.\n        #\n        #auto_join_mxid_localpart: system\n\n        # When auto_join_rooms is specified, setting this flag to false prevents\n        # guest accounts from being automatically joined to the rooms.\n        #\n        # Defaults to true.\n        #\n        #auto_join_rooms_for_guests: false\n        \"\"\"\n            % locals()\n        )\n\n    @staticmethod\n    def add_arguments(parser):\n        reg_group = parser.add_argument_group(\"registration\")\n        reg_group.add_argument(\n            \"--enable-registration\",\n            action=\"store_true\",\n            default=None,\n            help=\"Enable registration for new users.\",\n        )\n\n    def read_arguments(self, args):\n        if args.enable_registration is not None:\n            self.enable_registration = bool(strtobool(str(args.enable_registration)))\n", "patch": "@@ -176,9 +176,7 @@ def read_config(self, config, **kwargs):\n         self.session_lifetime = session_lifetime\n \n         # The success template used during fallback auth.\n-        self.fallback_success_template = self.read_templates(\n-            [\"auth_success.html\"], autoescape=True\n-        )[0]\n+        self.fallback_success_template = self.read_template(\"auth_success.html\")\n \n     def generate_config_section(self, generate_secrets=False, **kwargs):\n         if generate_secrets:", "file_path": "files/2021_3/67", "file_language": "py", "file_name": "synapse/config/registration.py", "outdated_file_modify": 0, "outdated_file_before": 0, "outdated_file_after": 0, "llm_check": 0, "static_check": 0, "static": {"rats": [false, []], "semgrep": [false, []]}, "target": 0, "function_before": [{"function": "class AccountValidityConfig(Config):\n    section = \"accountvalidity\"\n\n    def __init__(self, config, synapse_config):\n        if config is None:\n            return\n        super().__init__()\n        self.enabled = config.get(\"enabled\", False)\n        self.renew_by_email_enabled = \"renew_at\" in config\n\n        if self.enabled:\n            if \"period\" in config:\n                self.period = self.parse_duration(config[\"period\"])\n            else:\n                raise ConfigError(\"'period' is required when using account validity\")\n\n            if \"renew_at\" in config:\n                self.renew_at = self.parse_duration(config[\"renew_at\"])\n\n            if \"renew_email_subject\" in config:\n                self.renew_email_subject = config[\"renew_email_subject\"]\n            else:\n                self.renew_email_subject = \"Renew your %(app)s account\"\n\n            self.startup_job_max_delta = self.period * 10.0 / 100.0\n\n        template_dir = config.get(\"template_dir\")\n\n        if not template_dir:\n            template_dir = pkg_resources.resource_filename(\"synapse\", \"res/templates\")\n\n        if \"account_renewed_html_path\" in config:\n            file_path = os.path.join(template_dir, config[\"account_renewed_html_path\"])\n\n            self.account_renewed_html_content = self.read_file(\n                file_path, \"account_validity.account_renewed_html_path\"\n            )\n        else:\n            self.account_renewed_html_content = (\n                \"<html><body>Your account has been successfully renewed.</body><html>\"\n            )\n\n        if \"invalid_token_html_path\" in config:\n            file_path = os.path.join(template_dir, config[\"invalid_token_html_path\"])\n\n            self.invalid_token_html_content = self.read_file(\n                file_path, \"account_validity.invalid_token_html_path\"\n            )\n        else:\n            self.invalid_token_html_content = (\n                \"<html><body>Invalid renewal token.</body><html>\"\n            )", "target": 0}, {"function": "class RegistrationConfig(Config):\n    section = \"registration\"\n\n    def read_config(self, config, **kwargs):\n        self.enable_registration = strtobool(\n            str(config.get(\"enable_registration\", False))\n        )\n        if \"disable_registration\" in config:\n            self.enable_registration = not strtobool(\n                str(config[\"disable_registration\"])\n            )\n\n        self.account_validity = AccountValidityConfig(\n            config.get(\"account_validity\") or {}, config\n        )\n\n        self.registrations_require_3pid = config.get(\"registrations_require_3pid\", [])\n        self.allowed_local_3pids = config.get(\"allowed_local_3pids\", [])\n        self.enable_3pid_lookup = config.get(\"enable_3pid_lookup\", True)\n        self.registration_shared_secret = config.get(\"registration_shared_secret\")\n\n        self.bcrypt_rounds = config.get(\"bcrypt_rounds\", 12)\n        self.trusted_third_party_id_servers = config.get(\n            \"trusted_third_party_id_servers\", [\"matrix.org\", \"vector.im\"]\n        )\n        account_threepid_delegates = config.get(\"account_threepid_delegates\") or {}\n        self.account_threepid_delegate_email = account_threepid_delegates.get(\"email\")\n        self.account_threepid_delegate_msisdn = account_threepid_delegates.get(\"msisdn\")\n\n        self.default_identity_server = config.get(\"default_identity_server\")\n        self.allow_guest_access = config.get(\"allow_guest_access\", False)\n\n        if config.get(\"invite_3pid_guest\", False):\n            raise ConfigError(\"invite_3pid_guest is no longer supported\")\n\n        self.auto_join_rooms = config.get(\"auto_join_rooms\", [])\n        for room_alias in self.auto_join_rooms:\n            if not RoomAlias.is_valid(room_alias):\n                raise ConfigError(\"Invalid auto_join_rooms entry %s\" % (room_alias,))\n\n        # Options for creating auto-join rooms if they do not exist yet.\n        self.autocreate_auto_join_rooms = config.get(\"autocreate_auto_join_rooms\", True)\n        self.autocreate_auto_join_rooms_federated = config.get(\n            \"autocreate_auto_join_rooms_federated\", True\n        )\n        self.autocreate_auto_join_room_preset = (\n            config.get(\"autocreate_auto_join_room_preset\")\n            or RoomCreationPreset.PUBLIC_CHAT\n        )\n        self.auto_join_room_requires_invite = self.autocreate_auto_join_room_preset in {\n            RoomCreationPreset.PRIVATE_CHAT,\n            RoomCreationPreset.TRUSTED_PRIVATE_CHAT,\n        }\n\n        # Pull the creator/inviter from the configuration, this gets used to\n        # send invites for invite-only rooms.\n        mxid_localpart = config.get(\"auto_join_mxid_localpart\")\n        self.auto_join_user_id = None\n        if mxid_localpart:\n            # Convert the localpart to a full mxid.\n            self.auto_join_user_id = UserID(\n                mxid_localpart, self.server_name\n            ).to_string()\n\n        if self.autocreate_auto_join_rooms:\n            # Ensure the preset is a known value.\n            if self.autocreate_auto_join_room_preset not in {\n                RoomCreationPreset.PUBLIC_CHAT,\n                RoomCreationPreset.PRIVATE_CHAT,\n                RoomCreationPreset.TRUSTED_PRIVATE_CHAT,\n            }:\n                raise ConfigError(\"Invalid value for autocreate_auto_join_room_preset\")\n            # If the preset requires invitations to be sent, ensure there's a\n            # configured user to send them from.\n            if self.auto_join_room_requires_invite:\n                if not mxid_localpart:\n                    raise ConfigError(\n                        \"The configuration option `auto_join_mxid_localpart` is required if \"\n                        \"`autocreate_auto_join_room_preset` is set to private_chat or trusted_private_chat, such that \"\n                        \"Synapse knows who to send invitations from. Please \"\n                        \"configure `auto_join_mxid_localpart`.\"\n                    )\n\n        self.auto_join_rooms_for_guests = config.get(\"auto_join_rooms_for_guests\", True)\n\n        self.enable_set_displayname = config.get(\"enable_set_displayname\", True)\n        self.enable_set_avatar_url = config.get(\"enable_set_avatar_url\", True)\n        self.enable_3pid_changes = config.get(\"enable_3pid_changes\", True)\n\n        self.disable_msisdn_registration = config.get(\n            \"disable_msisdn_registration\", False\n        )\n\n        session_lifetime = config.get(\"session_lifetime\")\n        if session_lifetime is not None:\n            session_lifetime = self.parse_duration(session_lifetime)\n        self.session_lifetime = session_lifetime\n\n        # The success template used during fallback auth.\n        self.fallback_success_template = self.read_templates(\n            [\"auth_success.html\"], autoescape=True\n        )[0]\n\n    def generate_config_section(self, generate_secrets=False, **kwargs):\n        if generate_secrets:\n            registration_shared_secret = 'registration_shared_secret: \"%s\"' % (\n                random_string_with_symbols(50),\n            )\n        else:\n            registration_shared_secret = \"#registration_shared_secret: <PRIVATE STRING>\"\n\n        return (\n            \"\"\"\\\n        ## Registration ##\n        #\n        # Registration can be rate-limited using the parameters in the \"Ratelimiting\"\n        # section of this file.\n\n        # Enable registration for new users.\n        #\n        #enable_registration: false\n\n        # Optional account validity configuration. This allows for accounts to be denied\n        # any request after a given period.\n        #\n        # Once this feature is enabled, Synapse will look for registered users without an\n        # expiration date at startup and will add one to every account it found using the\n        # current settings at that time.\n        # This means that, if a validity period is set, and Synapse is restarted (it will\n        # then derive an expiration date from the current validity period), and some time\n        # after that the validity period changes and Synapse is restarted, the users'\n        # expiration dates won't be updated unless their account is manually renewed. This\n        # date will be randomly selected within a range [now + period - d ; now + period],\n        # where d is equal to 10%% of the validity period.\n        #\n        account_validity:\n          # The account validity feature is disabled by default. Uncomment the\n          # following line to enable it.\n          #\n          #enabled: true\n\n          # The period after which an account is valid after its registration. When\n          # renewing the account, its validity period will be extended by this amount\n          # of time. This parameter is required when using the account validity\n          # feature.\n          #\n          #period: 6w\n\n          # The amount of time before an account's expiry date at which Synapse will\n          # send an email to the account's email address with a renewal link. By\n          # default, no such emails are sent.\n          #\n          # If you enable this setting, you will also need to fill out the 'email'\n          # configuration section. You should also check that 'public_baseurl' is set\n          # correctly.\n          #\n          #renew_at: 1w\n\n          # The subject of the email sent out with the renewal link. '%%(app)s' can be\n          # used as a placeholder for the 'app_name' parameter from the 'email'\n          # section.\n          #\n          # Note that the placeholder must be written '%%(app)s', including the\n          # trailing 's'.\n          #\n          # If this is not set, a default value is used.\n          #\n          #renew_email_subject: \"Renew your %%(app)s account\"\n\n          # Directory in which Synapse will try to find templates for the HTML files to\n          # serve to the user when trying to renew an account. If not set, default\n          # templates from within the Synapse package will be used.\n          #\n          #template_dir: \"res/templates\"\n\n          # File within 'template_dir' giving the HTML to be displayed to the user after\n          # they successfully renewed their account. If not set, default text is used.\n          #\n          #account_renewed_html_path: \"account_renewed.html\"\n\n          # File within 'template_dir' giving the HTML to be displayed when the user\n          # tries to renew an account with an invalid renewal token. If not set,\n          # default text is used.\n          #\n          #invalid_token_html_path: \"invalid_token.html\"\n\n        # Time that a user's session remains valid for, after they log in.\n        #\n        # Note that this is not currently compatible with guest logins.\n        #\n        # Note also that this is calculated at login time: changes are not applied\n        # retrospectively to users who have already logged in.\n        #\n        # By default, this is infinite.\n        #\n        #session_lifetime: 24h\n\n        # The user must provide all of the below types of 3PID when registering.\n        #\n        #registrations_require_3pid:\n        #  - email\n        #  - msisdn\n\n        # Explicitly disable asking for MSISDNs from the registration\n        # flow (overrides registrations_require_3pid if MSISDNs are set as required)\n        #\n        #disable_msisdn_registration: true\n\n        # Mandate that users are only allowed to associate certain formats of\n        # 3PIDs with accounts on this server.\n        #\n        #allowed_local_3pids:\n        #  - medium: email\n        #    pattern: '.*@matrix\\\\.org'\n        #  - medium: email\n        #    pattern: '.*@vector\\\\.im'\n        #  - medium: msisdn\n        #    pattern: '\\\\+44'\n\n        # Enable 3PIDs lookup requests to identity servers from this server.\n        #\n        #enable_3pid_lookup: true\n\n        # If set, allows registration of standard or admin accounts by anyone who\n        # has the shared secret, even if registration is otherwise disabled.\n        #\n        %(registration_shared_secret)s\n\n        # Set the number of bcrypt rounds used to generate password hash.\n        # Larger numbers increase the work factor needed to generate the hash.\n        # The default number is 12 (which equates to 2^12 rounds).\n        # N.B. that increasing this will exponentially increase the time required\n        # to register or login - e.g. 24 => 2^24 rounds which will take >20 mins.\n        #\n        #bcrypt_rounds: 12\n\n        # Allows users to register as guests without a password/email/etc, and\n        # participate in rooms hosted on this server which have been made\n        # accessible to anonymous users.\n        #\n        #allow_guest_access: false\n\n        # The identity server which we suggest that clients should use when users log\n        # in on this server.\n        #\n        # (By default, no suggestion is made, so it is left up to the client.)\n        #\n        #default_identity_server: https://matrix.org\n\n        # Handle threepid (email/phone etc) registration and password resets through a set of\n        # *trusted* identity servers. Note that this allows the configured identity server to\n        # reset passwords for accounts!\n        #\n        # Be aware that if `email` is not set, and SMTP options have not been\n        # configured in the email config block, registration and user password resets via\n        # email will be globally disabled.\n        #\n        # Additionally, if `msisdn` is not set, registration and password resets via msisdn\n        # will be disabled regardless, and users will not be able to associate an msisdn\n        # identifier to their account. This is due to Synapse currently not supporting\n        # any method of sending SMS messages on its own.\n        #\n        # To enable using an identity server for operations regarding a particular third-party\n        # identifier type, set the value to the URL of that identity server as shown in the\n        # examples below.\n        #\n        # Servers handling the these requests must answer the `/requestToken` endpoints defined\n        # by the Matrix Identity Service API specification:\n        # https://matrix.org/docs/spec/identity_service/latest\n        #\n        account_threepid_delegates:\n            #email: https://example.com     # Delegate email sending to example.com\n            #msisdn: http://localhost:8090  # Delegate SMS sending to this local process\n\n        # Whether users are allowed to change their displayname after it has\n        # been initially set. Useful when provisioning users based on the\n        # contents of a third-party directory.\n        #\n        # Does not apply to server administrators. Defaults to 'true'\n        #\n        #enable_set_displayname: false\n\n        # Whether users are allowed to change their avatar after it has been\n        # initially set. Useful when provisioning users based on the contents\n        # of a third-party directory.\n        #\n        # Does not apply to server administrators. Defaults to 'true'\n        #\n        #enable_set_avatar_url: false\n\n        # Whether users can change the 3PIDs associated with their accounts\n        # (email address and msisdn).\n        #\n        # Defaults to 'true'\n        #\n        #enable_3pid_changes: false\n\n        # Users who register on this homeserver will automatically be joined\n        # to these rooms.\n        #\n        # By default, any room aliases included in this list will be created\n        # as a publicly joinable room when the first user registers for the\n        # homeserver. This behaviour can be customised with the settings below.\n        #\n        #auto_join_rooms:\n        #  - \"#example:example.com\"\n\n        # Where auto_join_rooms are specified, setting this flag ensures that the\n        # the rooms exist by creating them when the first user on the\n        # homeserver registers.\n        #\n        # By default the auto-created rooms are publicly joinable from any federated\n        # server. Use the autocreate_auto_join_rooms_federated and\n        # autocreate_auto_join_room_preset settings below to customise this behaviour.\n        #\n        # Setting to false means that if the rooms are not manually created,\n        # users cannot be auto-joined since they do not exist.\n        #\n        # Defaults to true. Uncomment the following line to disable automatically\n        # creating auto-join rooms.\n        #\n        #autocreate_auto_join_rooms: false\n\n        # Whether the auto_join_rooms that are auto-created are available via\n        # federation. Only has an effect if autocreate_auto_join_rooms is true.\n        #\n        # Note that whether a room is federated cannot be modified after\n        # creation.\n        #\n        # Defaults to true: the room will be joinable from other servers.\n        # Uncomment the following to prevent users from other homeservers from\n        # joining these rooms.\n        #\n        #autocreate_auto_join_rooms_federated: false\n\n        # The room preset to use when auto-creating one of auto_join_rooms. Only has an\n        # effect if autocreate_auto_join_rooms is true.\n        #\n        # This can be one of \"public_chat\", \"private_chat\", or \"trusted_private_chat\".\n        # If a value of \"private_chat\" or \"trusted_private_chat\" is used then\n        # auto_join_mxid_localpart must also be configured.\n        #\n        # Defaults to \"public_chat\", meaning that the room is joinable by anyone, including\n        # federated servers if autocreate_auto_join_rooms_federated is true (the default).\n        # Uncomment the following to require an invitation to join these rooms.\n        #\n        #autocreate_auto_join_room_preset: private_chat\n\n        # The local part of the user id which is used to create auto_join_rooms if\n        # autocreate_auto_join_rooms is true. If this is not provided then the\n        # initial user account that registers will be used to create the rooms.\n        #\n        # The user id is also used to invite new users to any auto-join rooms which\n        # are set to invite-only.\n        #\n        # It *must* be configured if autocreate_auto_join_room_preset is set to\n        # \"private_chat\" or \"trusted_private_chat\".\n        #\n        # Note that this must be specified in order for new users to be correctly\n        # invited to any auto-join rooms which have been set to invite-only (either\n        # at the time of creation or subsequently).\n        #\n        # Note that, if the room already exists, this user must be joined and\n        # have the appropriate permissions to invite new members.\n        #\n        #auto_join_mxid_localpart: system\n\n        # When auto_join_rooms is specified, setting this flag to false prevents\n        # guest accounts from being automatically joined to the rooms.\n        #\n        # Defaults to true.\n        #\n        #auto_join_rooms_for_guests: false\n        \"\"\"\n            % locals()\n        )\n\n    @staticmethod\n    def add_arguments(parser):\n        reg_group = parser.add_argument_group(\"registration\")\n        reg_group.add_argument(\n            \"--enable-registration\",\n            action=\"store_true\",\n            default=None,\n            help=\"Enable registration for new users.\",\n        )\n\n    def read_arguments(self, args):\n        if args.enable_registration is not None:\n            self.enable_registration = bool(strtobool(str(args.enable_registration)))", "target": 0}], "function_after": [{"function": "class AccountValidityConfig(Config):\n    section = \"accountvalidity\"\n\n    def __init__(self, config, synapse_config):\n        if config is None:\n            return\n        super().__init__()\n        self.enabled = config.get(\"enabled\", False)\n        self.renew_by_email_enabled = \"renew_at\" in config\n\n        if self.enabled:\n            if \"period\" in config:\n                self.period = self.parse_duration(config[\"period\"])\n            else:\n                raise ConfigError(\"'period' is required when using account validity\")\n\n            if \"renew_at\" in config:\n                self.renew_at = self.parse_duration(config[\"renew_at\"])\n\n            if \"renew_email_subject\" in config:\n                self.renew_email_subject = config[\"renew_email_subject\"]\n            else:\n                self.renew_email_subject = \"Renew your %(app)s account\"\n\n            self.startup_job_max_delta = self.period * 10.0 / 100.0\n\n        template_dir = config.get(\"template_dir\")\n\n        if not template_dir:\n            template_dir = pkg_resources.resource_filename(\"synapse\", \"res/templates\")\n\n        if \"account_renewed_html_path\" in config:\n            file_path = os.path.join(template_dir, config[\"account_renewed_html_path\"])\n\n            self.account_renewed_html_content = self.read_file(\n                file_path, \"account_validity.account_renewed_html_path\"\n            )\n        else:\n            self.account_renewed_html_content = (\n                \"<html><body>Your account has been successfully renewed.</body><html>\"\n            )\n\n        if \"invalid_token_html_path\" in config:\n            file_path = os.path.join(template_dir, config[\"invalid_token_html_path\"])\n\n            self.invalid_token_html_content = self.read_file(\n                file_path, \"account_validity.invalid_token_html_path\"\n            )\n        else:\n            self.invalid_token_html_content = (\n                \"<html><body>Invalid renewal token.</body><html>\"\n            )", "target": 0}, {"function": "class RegistrationConfig(Config):\n    section = \"registration\"\n\n    def read_config(self, config, **kwargs):\n        self.enable_registration = strtobool(\n            str(config.get(\"enable_registration\", False))\n        )\n        if \"disable_registration\" in config:\n            self.enable_registration = not strtobool(\n                str(config[\"disable_registration\"])\n            )\n\n        self.account_validity = AccountValidityConfig(\n            config.get(\"account_validity\") or {}, config\n        )\n\n        self.registrations_require_3pid = config.get(\"registrations_require_3pid\", [])\n        self.allowed_local_3pids = config.get(\"allowed_local_3pids\", [])\n        self.enable_3pid_lookup = config.get(\"enable_3pid_lookup\", True)\n        self.registration_shared_secret = config.get(\"registration_shared_secret\")\n\n        self.bcrypt_rounds = config.get(\"bcrypt_rounds\", 12)\n        self.trusted_third_party_id_servers = config.get(\n            \"trusted_third_party_id_servers\", [\"matrix.org\", \"vector.im\"]\n        )\n        account_threepid_delegates = config.get(\"account_threepid_delegates\") or {}\n        self.account_threepid_delegate_email = account_threepid_delegates.get(\"email\")\n        self.account_threepid_delegate_msisdn = account_threepid_delegates.get(\"msisdn\")\n\n        self.default_identity_server = config.get(\"default_identity_server\")\n        self.allow_guest_access = config.get(\"allow_guest_access\", False)\n\n        if config.get(\"invite_3pid_guest\", False):\n            raise ConfigError(\"invite_3pid_guest is no longer supported\")\n\n        self.auto_join_rooms = config.get(\"auto_join_rooms\", [])\n        for room_alias in self.auto_join_rooms:\n            if not RoomAlias.is_valid(room_alias):\n                raise ConfigError(\"Invalid auto_join_rooms entry %s\" % (room_alias,))\n\n        # Options for creating auto-join rooms if they do not exist yet.\n        self.autocreate_auto_join_rooms = config.get(\"autocreate_auto_join_rooms\", True)\n        self.autocreate_auto_join_rooms_federated = config.get(\n            \"autocreate_auto_join_rooms_federated\", True\n        )\n        self.autocreate_auto_join_room_preset = (\n            config.get(\"autocreate_auto_join_room_preset\")\n            or RoomCreationPreset.PUBLIC_CHAT\n        )\n        self.auto_join_room_requires_invite = self.autocreate_auto_join_room_preset in {\n            RoomCreationPreset.PRIVATE_CHAT,\n            RoomCreationPreset.TRUSTED_PRIVATE_CHAT,\n        }\n\n        # Pull the creator/inviter from the configuration, this gets used to\n        # send invites for invite-only rooms.\n        mxid_localpart = config.get(\"auto_join_mxid_localpart\")\n        self.auto_join_user_id = None\n        if mxid_localpart:\n            # Convert the localpart to a full mxid.\n            self.auto_join_user_id = UserID(\n                mxid_localpart, self.server_name\n            ).to_string()\n\n        if self.autocreate_auto_join_rooms:\n            # Ensure the preset is a known value.\n            if self.autocreate_auto_join_room_preset not in {\n                RoomCreationPreset.PUBLIC_CHAT,\n                RoomCreationPreset.PRIVATE_CHAT,\n                RoomCreationPreset.TRUSTED_PRIVATE_CHAT,\n            }:\n                raise ConfigError(\"Invalid value for autocreate_auto_join_room_preset\")\n            # If the preset requires invitations to be sent, ensure there's a\n            # configured user to send them from.\n            if self.auto_join_room_requires_invite:\n                if not mxid_localpart:\n                    raise ConfigError(\n                        \"The configuration option `auto_join_mxid_localpart` is required if \"\n                        \"`autocreate_auto_join_room_preset` is set to private_chat or trusted_private_chat, such that \"\n                        \"Synapse knows who to send invitations from. Please \"\n                        \"configure `auto_join_mxid_localpart`.\"\n                    )\n\n        self.auto_join_rooms_for_guests = config.get(\"auto_join_rooms_for_guests\", True)\n\n        self.enable_set_displayname = config.get(\"enable_set_displayname\", True)\n        self.enable_set_avatar_url = config.get(\"enable_set_avatar_url\", True)\n        self.enable_3pid_changes = config.get(\"enable_3pid_changes\", True)\n\n        self.disable_msisdn_registration = config.get(\n            \"disable_msisdn_registration\", False\n        )\n\n        session_lifetime = config.get(\"session_lifetime\")\n        if session_lifetime is not None:\n            session_lifetime = self.parse_duration(session_lifetime)\n        self.session_lifetime = session_lifetime\n\n        # The success template used during fallback auth.\n        self.fallback_success_template = self.read_template(\"auth_success.html\")\n\n    def generate_config_section(self, generate_secrets=False, **kwargs):\n        if generate_secrets:\n            registration_shared_secret = 'registration_shared_secret: \"%s\"' % (\n                random_string_with_symbols(50),\n            )\n        else:\n            registration_shared_secret = \"#registration_shared_secret: <PRIVATE STRING>\"\n\n        return (\n            \"\"\"\\\n        ## Registration ##\n        #\n        # Registration can be rate-limited using the parameters in the \"Ratelimiting\"\n        # section of this file.\n\n        # Enable registration for new users.\n        #\n        #enable_registration: false\n\n        # Optional account validity configuration. This allows for accounts to be denied\n        # any request after a given period.\n        #\n        # Once this feature is enabled, Synapse will look for registered users without an\n        # expiration date at startup and will add one to every account it found using the\n        # current settings at that time.\n        # This means that, if a validity period is set, and Synapse is restarted (it will\n        # then derive an expiration date from the current validity period), and some time\n        # after that the validity period changes and Synapse is restarted, the users'\n        # expiration dates won't be updated unless their account is manually renewed. This\n        # date will be randomly selected within a range [now + period - d ; now + period],\n        # where d is equal to 10%% of the validity period.\n        #\n        account_validity:\n          # The account validity feature is disabled by default. Uncomment the\n          # following line to enable it.\n          #\n          #enabled: true\n\n          # The period after which an account is valid after its registration. When\n          # renewing the account, its validity period will be extended by this amount\n          # of time. This parameter is required when using the account validity\n          # feature.\n          #\n          #period: 6w\n\n          # The amount of time before an account's expiry date at which Synapse will\n          # send an email to the account's email address with a renewal link. By\n          # default, no such emails are sent.\n          #\n          # If you enable this setting, you will also need to fill out the 'email'\n          # configuration section. You should also check that 'public_baseurl' is set\n          # correctly.\n          #\n          #renew_at: 1w\n\n          # The subject of the email sent out with the renewal link. '%%(app)s' can be\n          # used as a placeholder for the 'app_name' parameter from the 'email'\n          # section.\n          #\n          # Note that the placeholder must be written '%%(app)s', including the\n          # trailing 's'.\n          #\n          # If this is not set, a default value is used.\n          #\n          #renew_email_subject: \"Renew your %%(app)s account\"\n\n          # Directory in which Synapse will try to find templates for the HTML files to\n          # serve to the user when trying to renew an account. If not set, default\n          # templates from within the Synapse package will be used.\n          #\n          #template_dir: \"res/templates\"\n\n          # File within 'template_dir' giving the HTML to be displayed to the user after\n          # they successfully renewed their account. If not set, default text is used.\n          #\n          #account_renewed_html_path: \"account_renewed.html\"\n\n          # File within 'template_dir' giving the HTML to be displayed when the user\n          # tries to renew an account with an invalid renewal token. If not set,\n          # default text is used.\n          #\n          #invalid_token_html_path: \"invalid_token.html\"\n\n        # Time that a user's session remains valid for, after they log in.\n        #\n        # Note that this is not currently compatible with guest logins.\n        #\n        # Note also that this is calculated at login time: changes are not applied\n        # retrospectively to users who have already logged in.\n        #\n        # By default, this is infinite.\n        #\n        #session_lifetime: 24h\n\n        # The user must provide all of the below types of 3PID when registering.\n        #\n        #registrations_require_3pid:\n        #  - email\n        #  - msisdn\n\n        # Explicitly disable asking for MSISDNs from the registration\n        # flow (overrides registrations_require_3pid if MSISDNs are set as required)\n        #\n        #disable_msisdn_registration: true\n\n        # Mandate that users are only allowed to associate certain formats of\n        # 3PIDs with accounts on this server.\n        #\n        #allowed_local_3pids:\n        #  - medium: email\n        #    pattern: '.*@matrix\\\\.org'\n        #  - medium: email\n        #    pattern: '.*@vector\\\\.im'\n        #  - medium: msisdn\n        #    pattern: '\\\\+44'\n\n        # Enable 3PIDs lookup requests to identity servers from this server.\n        #\n        #enable_3pid_lookup: true\n\n        # If set, allows registration of standard or admin accounts by anyone who\n        # has the shared secret, even if registration is otherwise disabled.\n        #\n        %(registration_shared_secret)s\n\n        # Set the number of bcrypt rounds used to generate password hash.\n        # Larger numbers increase the work factor needed to generate the hash.\n        # The default number is 12 (which equates to 2^12 rounds).\n        # N.B. that increasing this will exponentially increase the time required\n        # to register or login - e.g. 24 => 2^24 rounds which will take >20 mins.\n        #\n        #bcrypt_rounds: 12\n\n        # Allows users to register as guests without a password/email/etc, and\n        # participate in rooms hosted on this server which have been made\n        # accessible to anonymous users.\n        #\n        #allow_guest_access: false\n\n        # The identity server which we suggest that clients should use when users log\n        # in on this server.\n        #\n        # (By default, no suggestion is made, so it is left up to the client.)\n        #\n        #default_identity_server: https://matrix.org\n\n        # Handle threepid (email/phone etc) registration and password resets through a set of\n        # *trusted* identity servers. Note that this allows the configured identity server to\n        # reset passwords for accounts!\n        #\n        # Be aware that if `email` is not set, and SMTP options have not been\n        # configured in the email config block, registration and user password resets via\n        # email will be globally disabled.\n        #\n        # Additionally, if `msisdn` is not set, registration and password resets via msisdn\n        # will be disabled regardless, and users will not be able to associate an msisdn\n        # identifier to their account. This is due to Synapse currently not supporting\n        # any method of sending SMS messages on its own.\n        #\n        # To enable using an identity server for operations regarding a particular third-party\n        # identifier type, set the value to the URL of that identity server as shown in the\n        # examples below.\n        #\n        # Servers handling the these requests must answer the `/requestToken` endpoints defined\n        # by the Matrix Identity Service API specification:\n        # https://matrix.org/docs/spec/identity_service/latest\n        #\n        account_threepid_delegates:\n            #email: https://example.com     # Delegate email sending to example.com\n            #msisdn: http://localhost:8090  # Delegate SMS sending to this local process\n\n        # Whether users are allowed to change their displayname after it has\n        # been initially set. Useful when provisioning users based on the\n        # contents of a third-party directory.\n        #\n        # Does not apply to server administrators. Defaults to 'true'\n        #\n        #enable_set_displayname: false\n\n        # Whether users are allowed to change their avatar after it has been\n        # initially set. Useful when provisioning users based on the contents\n        # of a third-party directory.\n        #\n        # Does not apply to server administrators. Defaults to 'true'\n        #\n        #enable_set_avatar_url: false\n\n        # Whether users can change the 3PIDs associated with their accounts\n        # (email address and msisdn).\n        #\n        # Defaults to 'true'\n        #\n        #enable_3pid_changes: false\n\n        # Users who register on this homeserver will automatically be joined\n        # to these rooms.\n        #\n        # By default, any room aliases included in this list will be created\n        # as a publicly joinable room when the first user registers for the\n        # homeserver. This behaviour can be customised with the settings below.\n        #\n        #auto_join_rooms:\n        #  - \"#example:example.com\"\n\n        # Where auto_join_rooms are specified, setting this flag ensures that the\n        # the rooms exist by creating them when the first user on the\n        # homeserver registers.\n        #\n        # By default the auto-created rooms are publicly joinable from any federated\n        # server. Use the autocreate_auto_join_rooms_federated and\n        # autocreate_auto_join_room_preset settings below to customise this behaviour.\n        #\n        # Setting to false means that if the rooms are not manually created,\n        # users cannot be auto-joined since they do not exist.\n        #\n        # Defaults to true. Uncomment the following line to disable automatically\n        # creating auto-join rooms.\n        #\n        #autocreate_auto_join_rooms: false\n\n        # Whether the auto_join_rooms that are auto-created are available via\n        # federation. Only has an effect if autocreate_auto_join_rooms is true.\n        #\n        # Note that whether a room is federated cannot be modified after\n        # creation.\n        #\n        # Defaults to true: the room will be joinable from other servers.\n        # Uncomment the following to prevent users from other homeservers from\n        # joining these rooms.\n        #\n        #autocreate_auto_join_rooms_federated: false\n\n        # The room preset to use when auto-creating one of auto_join_rooms. Only has an\n        # effect if autocreate_auto_join_rooms is true.\n        #\n        # This can be one of \"public_chat\", \"private_chat\", or \"trusted_private_chat\".\n        # If a value of \"private_chat\" or \"trusted_private_chat\" is used then\n        # auto_join_mxid_localpart must also be configured.\n        #\n        # Defaults to \"public_chat\", meaning that the room is joinable by anyone, including\n        # federated servers if autocreate_auto_join_rooms_federated is true (the default).\n        # Uncomment the following to require an invitation to join these rooms.\n        #\n        #autocreate_auto_join_room_preset: private_chat\n\n        # The local part of the user id which is used to create auto_join_rooms if\n        # autocreate_auto_join_rooms is true. If this is not provided then the\n        # initial user account that registers will be used to create the rooms.\n        #\n        # The user id is also used to invite new users to any auto-join rooms which\n        # are set to invite-only.\n        #\n        # It *must* be configured if autocreate_auto_join_room_preset is set to\n        # \"private_chat\" or \"trusted_private_chat\".\n        #\n        # Note that this must be specified in order for new users to be correctly\n        # invited to any auto-join rooms which have been set to invite-only (either\n        # at the time of creation or subsequently).\n        #\n        # Note that, if the room already exists, this user must be joined and\n        # have the appropriate permissions to invite new members.\n        #\n        #auto_join_mxid_localpart: system\n\n        # When auto_join_rooms is specified, setting this flag to false prevents\n        # guest accounts from being automatically joined to the rooms.\n        #\n        # Defaults to true.\n        #\n        #auto_join_rooms_for_guests: false\n        \"\"\"\n            % locals()\n        )\n\n    @staticmethod\n    def add_arguments(parser):\n        reg_group = parser.add_argument_group(\"registration\")\n        reg_group.add_argument(\n            \"--enable-registration\",\n            action=\"store_true\",\n            default=None,\n            help=\"Enable registration for new users.\",\n        )\n\n    def read_arguments(self, args):\n        if args.enable_registration is not None:\n            self.enable_registration = bool(strtobool(str(args.enable_registration)))", "target": 0}]}, {"raw_url": "https://github.com/matrix-org/synapse/raw/e54746bdf7d5c831eabe4dcea76a7626f1de73df/synapse%2Fpush%2Fmailer.py", "code": "# -*- coding: utf-8 -*-\n# Copyright 2016 OpenMarket Ltd\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport email.mime.multipart\nimport email.utils\nimport logging\nimport urllib.parse\nfrom email.mime.multipart import MIMEMultipart\nfrom email.mime.text import MIMEText\nfrom typing import TYPE_CHECKING, Any, Dict, Iterable, List, Optional, TypeVar\n\nimport bleach\nimport jinja2\n\nfrom synapse.api.constants import EventTypes, Membership\nfrom synapse.api.errors import StoreError\nfrom synapse.config.emailconfig import EmailSubjectConfig\nfrom synapse.events import EventBase\nfrom synapse.logging.context import make_deferred_yieldable\nfrom synapse.push.presentable_names import (\n    calculate_room_name,\n    descriptor_from_member_events,\n    name_from_member_event,\n)\nfrom synapse.types import StateMap, UserID\nfrom synapse.util.async_helpers import concurrently_execute\nfrom synapse.visibility import filter_events_for_client\n\nif TYPE_CHECKING:\n    from synapse.app.homeserver import HomeServer\n\nlogger = logging.getLogger(__name__)\n\nT = TypeVar(\"T\")\n\n\nCONTEXT_BEFORE = 1\nCONTEXT_AFTER = 1\n\n# From https://github.com/matrix-org/matrix-react-sdk/blob/master/src/HtmlUtils.js\nALLOWED_TAGS = [\n    \"font\",  # custom to matrix for IRC-style font coloring\n    \"del\",  # for markdown\n    # deliberately no h1/h2 to stop people shouting.\n    \"h3\",\n    \"h4\",\n    \"h5\",\n    \"h6\",\n    \"blockquote\",\n    \"p\",\n    \"a\",\n    \"ul\",\n    \"ol\",\n    \"nl\",\n    \"li\",\n    \"b\",\n    \"i\",\n    \"u\",\n    \"strong\",\n    \"em\",\n    \"strike\",\n    \"code\",\n    \"hr\",\n    \"br\",\n    \"div\",\n    \"table\",\n    \"thead\",\n    \"caption\",\n    \"tbody\",\n    \"tr\",\n    \"th\",\n    \"td\",\n    \"pre\",\n]\nALLOWED_ATTRS = {\n    # custom ones first:\n    \"font\": [\"color\"],  # custom to matrix\n    \"a\": [\"href\", \"name\", \"target\"],  # remote target: custom to matrix\n    # We don't currently allow img itself by default, but this\n    # would make sense if we did\n    \"img\": [\"src\"],\n}\n# When bleach release a version with this option, we can specify schemes\n# ALLOWED_SCHEMES = [\"http\", \"https\", \"ftp\", \"mailto\"]\n\n\nclass Mailer:\n    def __init__(\n        self,\n        hs: \"HomeServer\",\n        app_name: str,\n        template_html: jinja2.Template,\n        template_text: jinja2.Template,\n    ):\n        self.hs = hs\n        self.template_html = template_html\n        self.template_text = template_text\n\n        self.sendmail = self.hs.get_sendmail()\n        self.store = self.hs.get_datastore()\n        self.macaroon_gen = self.hs.get_macaroon_generator()\n        self.state_handler = self.hs.get_state_handler()\n        self.storage = hs.get_storage()\n        self.app_name = app_name\n        self.email_subjects = hs.config.email_subjects  # type: EmailSubjectConfig\n\n        logger.info(\"Created Mailer for app_name %s\" % app_name)\n\n    async def send_password_reset_mail(\n        self, email_address: str, token: str, client_secret: str, sid: str\n    ) -> None:\n        \"\"\"Send an email with a password reset link to a user\n\n        Args:\n            email_address: Email address we're sending the password\n                reset to\n            token: Unique token generated by the server to verify\n                the email was received\n            client_secret: Unique token generated by the client to\n                group together multiple email sending attempts\n            sid: The generated session ID\n        \"\"\"\n        params = {\"token\": token, \"client_secret\": client_secret, \"sid\": sid}\n        link = (\n            self.hs.config.public_baseurl\n            + \"_synapse/client/password_reset/email/submit_token?%s\"\n            % urllib.parse.urlencode(params)\n        )\n\n        template_vars = {\"link\": link}\n\n        await self.send_email(\n            email_address,\n            self.email_subjects.password_reset\n            % {\"server_name\": self.hs.config.server_name},\n            template_vars,\n        )\n\n    async def send_registration_mail(\n        self, email_address: str, token: str, client_secret: str, sid: str\n    ) -> None:\n        \"\"\"Send an email with a registration confirmation link to a user\n\n        Args:\n            email_address: Email address we're sending the registration\n                link to\n            token: Unique token generated by the server to verify\n                the email was received\n            client_secret: Unique token generated by the client to\n                group together multiple email sending attempts\n            sid: The generated session ID\n        \"\"\"\n        params = {\"token\": token, \"client_secret\": client_secret, \"sid\": sid}\n        link = (\n            self.hs.config.public_baseurl\n            + \"_matrix/client/unstable/registration/email/submit_token?%s\"\n            % urllib.parse.urlencode(params)\n        )\n\n        template_vars = {\"link\": link}\n\n        await self.send_email(\n            email_address,\n            self.email_subjects.email_validation\n            % {\"server_name\": self.hs.config.server_name},\n            template_vars,\n        )\n\n    async def send_add_threepid_mail(\n        self, email_address: str, token: str, client_secret: str, sid: str\n    ) -> None:\n        \"\"\"Send an email with a validation link to a user for adding a 3pid to their account\n\n        Args:\n            email_address: Email address we're sending the validation link to\n\n            token: Unique token generated by the server to verify the email was received\n\n            client_secret: Unique token generated by the client to group together\n                multiple email sending attempts\n\n            sid: The generated session ID\n        \"\"\"\n        params = {\"token\": token, \"client_secret\": client_secret, \"sid\": sid}\n        link = (\n            self.hs.config.public_baseurl\n            + \"_matrix/client/unstable/add_threepid/email/submit_token?%s\"\n            % urllib.parse.urlencode(params)\n        )\n\n        template_vars = {\"link\": link}\n\n        await self.send_email(\n            email_address,\n            self.email_subjects.email_validation\n            % {\"server_name\": self.hs.config.server_name},\n            template_vars,\n        )\n\n    async def send_notification_mail(\n        self,\n        app_id: str,\n        user_id: str,\n        email_address: str,\n        push_actions: Iterable[Dict[str, Any]],\n        reason: Dict[str, Any],\n    ) -> None:\n        \"\"\"Send email regarding a user's room notifications\"\"\"\n        rooms_in_order = deduped_ordered_list([pa[\"room_id\"] for pa in push_actions])\n\n        notif_events = await self.store.get_events(\n            [pa[\"event_id\"] for pa in push_actions]\n        )\n\n        notifs_by_room = {}  # type: Dict[str, List[Dict[str, Any]]]\n        for pa in push_actions:\n            notifs_by_room.setdefault(pa[\"room_id\"], []).append(pa)\n\n        # collect the current state for all the rooms in which we have\n        # notifications\n        state_by_room = {}\n\n        try:\n            user_display_name = await self.store.get_profile_displayname(\n                UserID.from_string(user_id).localpart\n            )\n            if user_display_name is None:\n                user_display_name = user_id\n        except StoreError:\n            user_display_name = user_id\n\n        async def _fetch_room_state(room_id):\n            room_state = await self.store.get_current_state_ids(room_id)\n            state_by_room[room_id] = room_state\n\n        # Run at most 3 of these at once: sync does 10 at a time but email\n        # notifs are much less realtime than sync so we can afford to wait a bit.\n        await concurrently_execute(_fetch_room_state, rooms_in_order, 3)\n\n        # actually sort our so-called rooms_in_order list, most recent room first\n        rooms_in_order.sort(key=lambda r: -(notifs_by_room[r][-1][\"received_ts\"] or 0))\n\n        rooms = []\n\n        for r in rooms_in_order:\n            roomvars = await self.get_room_vars(\n                r, user_id, notifs_by_room[r], notif_events, state_by_room[r]\n            )\n            rooms.append(roomvars)\n\n        reason[\"room_name\"] = await calculate_room_name(\n            self.store,\n            state_by_room[reason[\"room_id\"]],\n            user_id,\n            fallback_to_members=True,\n        )\n\n        summary_text = await self.make_summary_text(\n            notifs_by_room, state_by_room, notif_events, user_id, reason\n        )\n\n        template_vars = {\n            \"user_display_name\": user_display_name,\n            \"unsubscribe_link\": self.make_unsubscribe_link(\n                user_id, app_id, email_address\n            ),\n            \"summary_text\": summary_text,\n            \"rooms\": rooms,\n            \"reason\": reason,\n        }\n\n        await self.send_email(email_address, summary_text, template_vars)\n\n    async def send_email(\n        self, email_address: str, subject: str, extra_template_vars: Dict[str, Any]\n    ) -> None:\n        \"\"\"Send an email with the given information and template text\"\"\"\n        try:\n            from_string = self.hs.config.email_notif_from % {\"app\": self.app_name}\n        except TypeError:\n            from_string = self.hs.config.email_notif_from\n\n        raw_from = email.utils.parseaddr(from_string)[1]\n        raw_to = email.utils.parseaddr(email_address)[1]\n\n        if raw_to == \"\":\n            raise RuntimeError(\"Invalid 'to' address\")\n\n        template_vars = {\n            \"app_name\": self.app_name,\n            \"server_name\": self.hs.config.server.server_name,\n        }\n\n        template_vars.update(extra_template_vars)\n\n        html_text = self.template_html.render(**template_vars)\n        html_part = MIMEText(html_text, \"html\", \"utf8\")\n\n        plain_text = self.template_text.render(**template_vars)\n        text_part = MIMEText(plain_text, \"plain\", \"utf8\")\n\n        multipart_msg = MIMEMultipart(\"alternative\")\n        multipart_msg[\"Subject\"] = subject\n        multipart_msg[\"From\"] = from_string\n        multipart_msg[\"To\"] = email_address\n        multipart_msg[\"Date\"] = email.utils.formatdate()\n        multipart_msg[\"Message-ID\"] = email.utils.make_msgid()\n        multipart_msg.attach(text_part)\n        multipart_msg.attach(html_part)\n\n        logger.info(\"Sending email to %s\" % email_address)\n\n        await make_deferred_yieldable(\n            self.sendmail(\n                self.hs.config.email_smtp_host,\n                raw_from,\n                raw_to,\n                multipart_msg.as_string().encode(\"utf8\"),\n                reactor=self.hs.get_reactor(),\n                port=self.hs.config.email_smtp_port,\n                requireAuthentication=self.hs.config.email_smtp_user is not None,\n                username=self.hs.config.email_smtp_user,\n                password=self.hs.config.email_smtp_pass,\n                requireTransportSecurity=self.hs.config.require_transport_security,\n            )\n        )\n\n    async def get_room_vars(\n        self,\n        room_id: str,\n        user_id: str,\n        notifs: Iterable[Dict[str, Any]],\n        notif_events: Dict[str, EventBase],\n        room_state_ids: StateMap[str],\n    ) -> Dict[str, Any]:\n        # Check if one of the notifs is an invite event for the user.\n        is_invite = False\n        for n in notifs:\n            ev = notif_events[n[\"event_id\"]]\n            if ev.type == EventTypes.Member and ev.state_key == user_id:\n                if ev.content.get(\"membership\") == Membership.INVITE:\n                    is_invite = True\n                    break\n\n        room_name = await calculate_room_name(self.store, room_state_ids, user_id)\n\n        room_vars = {\n            \"title\": room_name,\n            \"hash\": string_ordinal_total(room_id),  # See sender avatar hash\n            \"notifs\": [],\n            \"invite\": is_invite,\n            \"link\": self.make_room_link(room_id),\n        }  # type: Dict[str, Any]\n\n        if not is_invite:\n            for n in notifs:\n                notifvars = await self.get_notif_vars(\n                    n, user_id, notif_events[n[\"event_id\"]], room_state_ids\n                )\n\n                # merge overlapping notifs together.\n                # relies on the notifs being in chronological order.\n                merge = False\n                if room_vars[\"notifs\"] and \"messages\" in room_vars[\"notifs\"][-1]:\n                    prev_messages = room_vars[\"notifs\"][-1][\"messages\"]\n                    for message in notifvars[\"messages\"]:\n                        pm = list(\n                            filter(lambda pm: pm[\"id\"] == message[\"id\"], prev_messages)\n                        )\n                        if pm:\n                            if not message[\"is_historical\"]:\n                                pm[0][\"is_historical\"] = False\n                            merge = True\n                        elif merge:\n                            # we're merging, so append any remaining messages\n                            # in this notif to the previous one\n                            prev_messages.append(message)\n\n                if not merge:\n                    room_vars[\"notifs\"].append(notifvars)\n\n        return room_vars\n\n    async def get_notif_vars(\n        self,\n        notif: Dict[str, Any],\n        user_id: str,\n        notif_event: EventBase,\n        room_state_ids: StateMap[str],\n    ) -> Dict[str, Any]:\n        results = await self.store.get_events_around(\n            notif[\"room_id\"],\n            notif[\"event_id\"],\n            before_limit=CONTEXT_BEFORE,\n            after_limit=CONTEXT_AFTER,\n        )\n\n        ret = {\n            \"link\": self.make_notif_link(notif),\n            \"ts\": notif[\"received_ts\"],\n            \"messages\": [],\n        }\n\n        the_events = await filter_events_for_client(\n            self.storage, user_id, results[\"events_before\"]\n        )\n        the_events.append(notif_event)\n\n        for event in the_events:\n            messagevars = await self.get_message_vars(notif, event, room_state_ids)\n            if messagevars is not None:\n                ret[\"messages\"].append(messagevars)\n\n        return ret\n\n    async def get_message_vars(\n        self, notif: Dict[str, Any], event: EventBase, room_state_ids: StateMap[str]\n    ) -> Optional[Dict[str, Any]]:\n        if event.type != EventTypes.Message and event.type != EventTypes.Encrypted:\n            return None\n\n        sender_state_event_id = room_state_ids[(\"m.room.member\", event.sender)]\n        sender_state_event = await self.store.get_event(sender_state_event_id)\n        sender_name = name_from_member_event(sender_state_event)\n        sender_avatar_url = sender_state_event.content.get(\"avatar_url\")\n\n        # 'hash' for deterministically picking default images: use\n        # sender_hash % the number of default images to choose from\n        sender_hash = string_ordinal_total(event.sender)\n\n        ret = {\n            \"event_type\": event.type,\n            \"is_historical\": event.event_id != notif[\"event_id\"],\n            \"id\": event.event_id,\n            \"ts\": event.origin_server_ts,\n            \"sender_name\": sender_name,\n            \"sender_avatar_url\": sender_avatar_url,\n            \"sender_hash\": sender_hash,\n        }\n\n        # Encrypted messages don't have any additional useful information.\n        if event.type == EventTypes.Encrypted:\n            return ret\n\n        msgtype = event.content.get(\"msgtype\")\n\n        ret[\"msgtype\"] = msgtype\n\n        if msgtype == \"m.text\":\n            self.add_text_message_vars(ret, event)\n        elif msgtype == \"m.image\":\n            self.add_image_message_vars(ret, event)\n\n        if \"body\" in event.content:\n            ret[\"body_text_plain\"] = event.content[\"body\"]\n\n        return ret\n\n    def add_text_message_vars(\n        self, messagevars: Dict[str, Any], event: EventBase\n    ) -> None:\n        msgformat = event.content.get(\"format\")\n\n        messagevars[\"format\"] = msgformat\n\n        formatted_body = event.content.get(\"formatted_body\")\n        body = event.content.get(\"body\")\n\n        if msgformat == \"org.matrix.custom.html\" and formatted_body:\n            messagevars[\"body_text_html\"] = safe_markup(formatted_body)\n        elif body:\n            messagevars[\"body_text_html\"] = safe_text(body)\n\n    def add_image_message_vars(\n        self, messagevars: Dict[str, Any], event: EventBase\n    ) -> None:\n        \"\"\"\n        Potentially add an image URL to the message variables.\n        \"\"\"\n        if \"url\" in event.content:\n            messagevars[\"image_url\"] = event.content[\"url\"]\n\n    async def make_summary_text(\n        self,\n        notifs_by_room: Dict[str, List[Dict[str, Any]]],\n        room_state_ids: Dict[str, StateMap[str]],\n        notif_events: Dict[str, EventBase],\n        user_id: str,\n        reason: Dict[str, Any],\n    ):\n        if len(notifs_by_room) == 1:\n            # Only one room has new stuff\n            room_id = list(notifs_by_room.keys())[0]\n\n            # If the room has some kind of name, use it, but we don't\n            # want the generated-from-names one here otherwise we'll\n            # end up with, \"new message from Bob in the Bob room\"\n            room_name = await calculate_room_name(\n                self.store, room_state_ids[room_id], user_id, fallback_to_members=False\n            )\n\n            # See if one of the notifs is an invite event for the user\n            invite_event = None\n            for n in notifs_by_room[room_id]:\n                ev = notif_events[n[\"event_id\"]]\n                if ev.type == EventTypes.Member and ev.state_key == user_id:\n                    if ev.content.get(\"membership\") == Membership.INVITE:\n                        invite_event = ev\n                        break\n\n            if invite_event:\n                inviter_member_event_id = room_state_ids[room_id].get(\n                    (\"m.room.member\", invite_event.sender)\n                )\n                inviter_name = invite_event.sender\n                if inviter_member_event_id:\n                    inviter_member_event = await self.store.get_event(\n                        inviter_member_event_id, allow_none=True\n                    )\n                    if inviter_member_event:\n                        inviter_name = name_from_member_event(inviter_member_event)\n\n                if room_name is None:\n                    return self.email_subjects.invite_from_person % {\n                        \"person\": inviter_name,\n                        \"app\": self.app_name,\n                    }\n                else:\n                    return self.email_subjects.invite_from_person_to_room % {\n                        \"person\": inviter_name,\n                        \"room\": room_name,\n                        \"app\": self.app_name,\n                    }\n\n            sender_name = None\n            if len(notifs_by_room[room_id]) == 1:\n                # There is just the one notification, so give some detail\n                event = notif_events[notifs_by_room[room_id][0][\"event_id\"]]\n                if (\"m.room.member\", event.sender) in room_state_ids[room_id]:\n                    state_event_id = room_state_ids[room_id][\n                        (\"m.room.member\", event.sender)\n                    ]\n                    state_event = await self.store.get_event(state_event_id)\n                    sender_name = name_from_member_event(state_event)\n\n                if sender_name is not None and room_name is not None:\n                    return self.email_subjects.message_from_person_in_room % {\n                        \"person\": sender_name,\n                        \"room\": room_name,\n                        \"app\": self.app_name,\n                    }\n                elif sender_name is not None:\n                    return self.email_subjects.message_from_person % {\n                        \"person\": sender_name,\n                        \"app\": self.app_name,\n                    }\n            else:\n                # There's more than one notification for this room, so just\n                # say there are several\n                if room_name is not None:\n                    return self.email_subjects.messages_in_room % {\n                        \"room\": room_name,\n                        \"app\": self.app_name,\n                    }\n                else:\n                    # If the room doesn't have a name, say who the messages\n                    # are from explicitly to avoid, \"messages in the Bob room\"\n                    sender_ids = list(\n                        {\n                            notif_events[n[\"event_id\"]].sender\n                            for n in notifs_by_room[room_id]\n                        }\n                    )\n\n                    member_events = await self.store.get_events(\n                        [\n                            room_state_ids[room_id][(\"m.room.member\", s)]\n                            for s in sender_ids\n                        ]\n                    )\n\n                    return self.email_subjects.messages_from_person % {\n                        \"person\": descriptor_from_member_events(member_events.values()),\n                        \"app\": self.app_name,\n                    }\n        else:\n            # Stuff's happened in multiple different rooms\n\n            # ...but we still refer to the 'reason' room which triggered the mail\n            if reason[\"room_name\"] is not None:\n                return self.email_subjects.messages_in_room_and_others % {\n                    \"room\": reason[\"room_name\"],\n                    \"app\": self.app_name,\n                }\n            else:\n                # If the reason room doesn't have a name, say who the messages\n                # are from explicitly to avoid, \"messages in the Bob room\"\n                room_id = reason[\"room_id\"]\n\n                sender_ids = list(\n                    {\n                        notif_events[n[\"event_id\"]].sender\n                        for n in notifs_by_room[room_id]\n                    }\n                )\n\n                member_events = await self.store.get_events(\n                    [room_state_ids[room_id][(\"m.room.member\", s)] for s in sender_ids]\n                )\n\n                return self.email_subjects.messages_from_person_and_others % {\n                    \"person\": descriptor_from_member_events(member_events.values()),\n                    \"app\": self.app_name,\n                }\n\n    def make_room_link(self, room_id: str) -> str:\n        if self.hs.config.email_riot_base_url:\n            base_url = \"%s/#/room\" % (self.hs.config.email_riot_base_url)\n        elif self.app_name == \"Vector\":\n            # need /beta for Universal Links to work on iOS\n            base_url = \"https://vector.im/beta/#/room\"\n        else:\n            base_url = \"https://matrix.to/#\"\n        return \"%s/%s\" % (base_url, room_id)\n\n    def make_notif_link(self, notif: Dict[str, str]) -> str:\n        if self.hs.config.email_riot_base_url:\n            return \"%s/#/room/%s/%s\" % (\n                self.hs.config.email_riot_base_url,\n                notif[\"room_id\"],\n                notif[\"event_id\"],\n            )\n        elif self.app_name == \"Vector\":\n            # need /beta for Universal Links to work on iOS\n            return \"https://vector.im/beta/#/room/%s/%s\" % (\n                notif[\"room_id\"],\n                notif[\"event_id\"],\n            )\n        else:\n            return \"https://matrix.to/#/%s/%s\" % (notif[\"room_id\"], notif[\"event_id\"])\n\n    def make_unsubscribe_link(\n        self, user_id: str, app_id: str, email_address: str\n    ) -> str:\n        params = {\n            \"access_token\": self.macaroon_gen.generate_delete_pusher_token(user_id),\n            \"app_id\": app_id,\n            \"pushkey\": email_address,\n        }\n\n        # XXX: make r0 once API is stable\n        return \"%s_matrix/client/unstable/pushers/remove?%s\" % (\n            self.hs.config.public_baseurl,\n            urllib.parse.urlencode(params),\n        )\n\n\ndef safe_markup(raw_html: str) -> jinja2.Markup:\n    \"\"\"\n    Sanitise a raw HTML string to a set of allowed tags and attributes, and linkify any bare URLs.\n\n    Args\n        raw_html: Unsafe HTML.\n\n    Returns:\n        A Markup object ready to safely use in a Jinja template.\n    \"\"\"\n    return jinja2.Markup(\n        bleach.linkify(\n            bleach.clean(\n                raw_html,\n                tags=ALLOWED_TAGS,\n                attributes=ALLOWED_ATTRS,\n                # bleach master has this, but it isn't released yet\n                # protocols=ALLOWED_SCHEMES,\n                strip=True,\n            )\n        )\n    )\n\n\ndef safe_text(raw_text: str) -> jinja2.Markup:\n    \"\"\"\n    Sanitise text (escape any HTML tags), and then linkify any bare URLs.\n\n    Args\n        raw_text: Unsafe text which might include HTML markup.\n\n    Returns:\n        A Markup object ready to safely use in a Jinja template.\n    \"\"\"\n    return jinja2.Markup(\n        bleach.linkify(bleach.clean(raw_text, tags=[], attributes={}, strip=False))\n    )\n\n\ndef deduped_ordered_list(it: Iterable[T]) -> List[T]:\n    seen = set()\n    ret = []\n    for item in it:\n        if item not in seen:\n            seen.add(item)\n            ret.append(item)\n    return ret\n\n\ndef string_ordinal_total(s: str) -> int:\n    tot = 0\n    for c in s:\n        tot += ord(c)\n    return tot\n", "code_before": "# -*- coding: utf-8 -*-\n# Copyright 2016 OpenMarket Ltd\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport email.mime.multipart\nimport email.utils\nimport logging\nimport urllib.parse\nfrom email.mime.multipart import MIMEMultipart\nfrom email.mime.text import MIMEText\nfrom typing import TYPE_CHECKING, Any, Dict, Iterable, List, Optional, TypeVar\n\nimport bleach\nimport jinja2\n\nfrom synapse.api.constants import EventTypes, Membership\nfrom synapse.api.errors import StoreError\nfrom synapse.config.emailconfig import EmailSubjectConfig\nfrom synapse.events import EventBase\nfrom synapse.logging.context import make_deferred_yieldable\nfrom synapse.push.presentable_names import (\n    calculate_room_name,\n    descriptor_from_member_events,\n    name_from_member_event,\n)\nfrom synapse.types import StateMap, UserID\nfrom synapse.util.async_helpers import concurrently_execute\nfrom synapse.visibility import filter_events_for_client\n\nif TYPE_CHECKING:\n    from synapse.app.homeserver import HomeServer\n\nlogger = logging.getLogger(__name__)\n\nT = TypeVar(\"T\")\n\n\nCONTEXT_BEFORE = 1\nCONTEXT_AFTER = 1\n\n# From https://github.com/matrix-org/matrix-react-sdk/blob/master/src/HtmlUtils.js\nALLOWED_TAGS = [\n    \"font\",  # custom to matrix for IRC-style font coloring\n    \"del\",  # for markdown\n    # deliberately no h1/h2 to stop people shouting.\n    \"h3\",\n    \"h4\",\n    \"h5\",\n    \"h6\",\n    \"blockquote\",\n    \"p\",\n    \"a\",\n    \"ul\",\n    \"ol\",\n    \"nl\",\n    \"li\",\n    \"b\",\n    \"i\",\n    \"u\",\n    \"strong\",\n    \"em\",\n    \"strike\",\n    \"code\",\n    \"hr\",\n    \"br\",\n    \"div\",\n    \"table\",\n    \"thead\",\n    \"caption\",\n    \"tbody\",\n    \"tr\",\n    \"th\",\n    \"td\",\n    \"pre\",\n]\nALLOWED_ATTRS = {\n    # custom ones first:\n    \"font\": [\"color\"],  # custom to matrix\n    \"a\": [\"href\", \"name\", \"target\"],  # remote target: custom to matrix\n    # We don't currently allow img itself by default, but this\n    # would make sense if we did\n    \"img\": [\"src\"],\n}\n# When bleach release a version with this option, we can specify schemes\n# ALLOWED_SCHEMES = [\"http\", \"https\", \"ftp\", \"mailto\"]\n\n\nclass Mailer:\n    def __init__(\n        self,\n        hs: \"HomeServer\",\n        app_name: str,\n        template_html: jinja2.Template,\n        template_text: jinja2.Template,\n    ):\n        self.hs = hs\n        self.template_html = template_html\n        self.template_text = template_text\n\n        self.sendmail = self.hs.get_sendmail()\n        self.store = self.hs.get_datastore()\n        self.macaroon_gen = self.hs.get_macaroon_generator()\n        self.state_handler = self.hs.get_state_handler()\n        self.storage = hs.get_storage()\n        self.app_name = app_name\n        self.email_subjects = hs.config.email_subjects  # type: EmailSubjectConfig\n\n        logger.info(\"Created Mailer for app_name %s\" % app_name)\n\n    async def send_password_reset_mail(\n        self, email_address: str, token: str, client_secret: str, sid: str\n    ) -> None:\n        \"\"\"Send an email with a password reset link to a user\n\n        Args:\n            email_address: Email address we're sending the password\n                reset to\n            token: Unique token generated by the server to verify\n                the email was received\n            client_secret: Unique token generated by the client to\n                group together multiple email sending attempts\n            sid: The generated session ID\n        \"\"\"\n        params = {\"token\": token, \"client_secret\": client_secret, \"sid\": sid}\n        link = (\n            self.hs.config.public_baseurl\n            + \"_synapse/client/password_reset/email/submit_token?%s\"\n            % urllib.parse.urlencode(params)\n        )\n\n        template_vars = {\"link\": link}\n\n        await self.send_email(\n            email_address,\n            self.email_subjects.password_reset\n            % {\"server_name\": self.hs.config.server_name},\n            template_vars,\n        )\n\n    async def send_registration_mail(\n        self, email_address: str, token: str, client_secret: str, sid: str\n    ) -> None:\n        \"\"\"Send an email with a registration confirmation link to a user\n\n        Args:\n            email_address: Email address we're sending the registration\n                link to\n            token: Unique token generated by the server to verify\n                the email was received\n            client_secret: Unique token generated by the client to\n                group together multiple email sending attempts\n            sid: The generated session ID\n        \"\"\"\n        params = {\"token\": token, \"client_secret\": client_secret, \"sid\": sid}\n        link = (\n            self.hs.config.public_baseurl\n            + \"_matrix/client/unstable/registration/email/submit_token?%s\"\n            % urllib.parse.urlencode(params)\n        )\n\n        template_vars = {\"link\": link}\n\n        await self.send_email(\n            email_address,\n            self.email_subjects.email_validation\n            % {\"server_name\": self.hs.config.server_name},\n            template_vars,\n        )\n\n    async def send_add_threepid_mail(\n        self, email_address: str, token: str, client_secret: str, sid: str\n    ) -> None:\n        \"\"\"Send an email with a validation link to a user for adding a 3pid to their account\n\n        Args:\n            email_address: Email address we're sending the validation link to\n\n            token: Unique token generated by the server to verify the email was received\n\n            client_secret: Unique token generated by the client to group together\n                multiple email sending attempts\n\n            sid: The generated session ID\n        \"\"\"\n        params = {\"token\": token, \"client_secret\": client_secret, \"sid\": sid}\n        link = (\n            self.hs.config.public_baseurl\n            + \"_matrix/client/unstable/add_threepid/email/submit_token?%s\"\n            % urllib.parse.urlencode(params)\n        )\n\n        template_vars = {\"link\": link}\n\n        await self.send_email(\n            email_address,\n            self.email_subjects.email_validation\n            % {\"server_name\": self.hs.config.server_name},\n            template_vars,\n        )\n\n    async def send_notification_mail(\n        self,\n        app_id: str,\n        user_id: str,\n        email_address: str,\n        push_actions: Iterable[Dict[str, Any]],\n        reason: Dict[str, Any],\n    ) -> None:\n        \"\"\"Send email regarding a user's room notifications\"\"\"\n        rooms_in_order = deduped_ordered_list([pa[\"room_id\"] for pa in push_actions])\n\n        notif_events = await self.store.get_events(\n            [pa[\"event_id\"] for pa in push_actions]\n        )\n\n        notifs_by_room = {}  # type: Dict[str, List[Dict[str, Any]]]\n        for pa in push_actions:\n            notifs_by_room.setdefault(pa[\"room_id\"], []).append(pa)\n\n        # collect the current state for all the rooms in which we have\n        # notifications\n        state_by_room = {}\n\n        try:\n            user_display_name = await self.store.get_profile_displayname(\n                UserID.from_string(user_id).localpart\n            )\n            if user_display_name is None:\n                user_display_name = user_id\n        except StoreError:\n            user_display_name = user_id\n\n        async def _fetch_room_state(room_id):\n            room_state = await self.store.get_current_state_ids(room_id)\n            state_by_room[room_id] = room_state\n\n        # Run at most 3 of these at once: sync does 10 at a time but email\n        # notifs are much less realtime than sync so we can afford to wait a bit.\n        await concurrently_execute(_fetch_room_state, rooms_in_order, 3)\n\n        # actually sort our so-called rooms_in_order list, most recent room first\n        rooms_in_order.sort(key=lambda r: -(notifs_by_room[r][-1][\"received_ts\"] or 0))\n\n        rooms = []\n\n        for r in rooms_in_order:\n            roomvars = await self.get_room_vars(\n                r, user_id, notifs_by_room[r], notif_events, state_by_room[r]\n            )\n            rooms.append(roomvars)\n\n        reason[\"room_name\"] = await calculate_room_name(\n            self.store,\n            state_by_room[reason[\"room_id\"]],\n            user_id,\n            fallback_to_members=True,\n        )\n\n        summary_text = await self.make_summary_text(\n            notifs_by_room, state_by_room, notif_events, user_id, reason\n        )\n\n        template_vars = {\n            \"user_display_name\": user_display_name,\n            \"unsubscribe_link\": self.make_unsubscribe_link(\n                user_id, app_id, email_address\n            ),\n            \"summary_text\": summary_text,\n            \"rooms\": rooms,\n            \"reason\": reason,\n        }\n\n        await self.send_email(email_address, summary_text, template_vars)\n\n    async def send_email(\n        self, email_address: str, subject: str, extra_template_vars: Dict[str, Any]\n    ) -> None:\n        \"\"\"Send an email with the given information and template text\"\"\"\n        try:\n            from_string = self.hs.config.email_notif_from % {\"app\": self.app_name}\n        except TypeError:\n            from_string = self.hs.config.email_notif_from\n\n        raw_from = email.utils.parseaddr(from_string)[1]\n        raw_to = email.utils.parseaddr(email_address)[1]\n\n        if raw_to == \"\":\n            raise RuntimeError(\"Invalid 'to' address\")\n\n        template_vars = {\n            \"app_name\": self.app_name,\n            \"server_name\": self.hs.config.server.server_name,\n        }\n\n        template_vars.update(extra_template_vars)\n\n        html_text = self.template_html.render(**template_vars)\n        html_part = MIMEText(html_text, \"html\", \"utf8\")\n\n        plain_text = self.template_text.render(**template_vars)\n        text_part = MIMEText(plain_text, \"plain\", \"utf8\")\n\n        multipart_msg = MIMEMultipart(\"alternative\")\n        multipart_msg[\"Subject\"] = subject\n        multipart_msg[\"From\"] = from_string\n        multipart_msg[\"To\"] = email_address\n        multipart_msg[\"Date\"] = email.utils.formatdate()\n        multipart_msg[\"Message-ID\"] = email.utils.make_msgid()\n        multipart_msg.attach(text_part)\n        multipart_msg.attach(html_part)\n\n        logger.info(\"Sending email to %s\" % email_address)\n\n        await make_deferred_yieldable(\n            self.sendmail(\n                self.hs.config.email_smtp_host,\n                raw_from,\n                raw_to,\n                multipart_msg.as_string().encode(\"utf8\"),\n                reactor=self.hs.get_reactor(),\n                port=self.hs.config.email_smtp_port,\n                requireAuthentication=self.hs.config.email_smtp_user is not None,\n                username=self.hs.config.email_smtp_user,\n                password=self.hs.config.email_smtp_pass,\n                requireTransportSecurity=self.hs.config.require_transport_security,\n            )\n        )\n\n    async def get_room_vars(\n        self,\n        room_id: str,\n        user_id: str,\n        notifs: Iterable[Dict[str, Any]],\n        notif_events: Dict[str, EventBase],\n        room_state_ids: StateMap[str],\n    ) -> Dict[str, Any]:\n        # Check if one of the notifs is an invite event for the user.\n        is_invite = False\n        for n in notifs:\n            ev = notif_events[n[\"event_id\"]]\n            if ev.type == EventTypes.Member and ev.state_key == user_id:\n                if ev.content.get(\"membership\") == Membership.INVITE:\n                    is_invite = True\n                    break\n\n        room_name = await calculate_room_name(self.store, room_state_ids, user_id)\n\n        room_vars = {\n            \"title\": room_name,\n            \"hash\": string_ordinal_total(room_id),  # See sender avatar hash\n            \"notifs\": [],\n            \"invite\": is_invite,\n            \"link\": self.make_room_link(room_id),\n        }  # type: Dict[str, Any]\n\n        if not is_invite:\n            for n in notifs:\n                notifvars = await self.get_notif_vars(\n                    n, user_id, notif_events[n[\"event_id\"]], room_state_ids\n                )\n\n                # merge overlapping notifs together.\n                # relies on the notifs being in chronological order.\n                merge = False\n                if room_vars[\"notifs\"] and \"messages\" in room_vars[\"notifs\"][-1]:\n                    prev_messages = room_vars[\"notifs\"][-1][\"messages\"]\n                    for message in notifvars[\"messages\"]:\n                        pm = list(\n                            filter(lambda pm: pm[\"id\"] == message[\"id\"], prev_messages)\n                        )\n                        if pm:\n                            if not message[\"is_historical\"]:\n                                pm[0][\"is_historical\"] = False\n                            merge = True\n                        elif merge:\n                            # we're merging, so append any remaining messages\n                            # in this notif to the previous one\n                            prev_messages.append(message)\n\n                if not merge:\n                    room_vars[\"notifs\"].append(notifvars)\n\n        return room_vars\n\n    async def get_notif_vars(\n        self,\n        notif: Dict[str, Any],\n        user_id: str,\n        notif_event: EventBase,\n        room_state_ids: StateMap[str],\n    ) -> Dict[str, Any]:\n        results = await self.store.get_events_around(\n            notif[\"room_id\"],\n            notif[\"event_id\"],\n            before_limit=CONTEXT_BEFORE,\n            after_limit=CONTEXT_AFTER,\n        )\n\n        ret = {\n            \"link\": self.make_notif_link(notif),\n            \"ts\": notif[\"received_ts\"],\n            \"messages\": [],\n        }\n\n        the_events = await filter_events_for_client(\n            self.storage, user_id, results[\"events_before\"]\n        )\n        the_events.append(notif_event)\n\n        for event in the_events:\n            messagevars = await self.get_message_vars(notif, event, room_state_ids)\n            if messagevars is not None:\n                ret[\"messages\"].append(messagevars)\n\n        return ret\n\n    async def get_message_vars(\n        self, notif: Dict[str, Any], event: EventBase, room_state_ids: StateMap[str]\n    ) -> Optional[Dict[str, Any]]:\n        if event.type != EventTypes.Message and event.type != EventTypes.Encrypted:\n            return None\n\n        sender_state_event_id = room_state_ids[(\"m.room.member\", event.sender)]\n        sender_state_event = await self.store.get_event(sender_state_event_id)\n        sender_name = name_from_member_event(sender_state_event)\n        sender_avatar_url = sender_state_event.content.get(\"avatar_url\")\n\n        # 'hash' for deterministically picking default images: use\n        # sender_hash % the number of default images to choose from\n        sender_hash = string_ordinal_total(event.sender)\n\n        ret = {\n            \"event_type\": event.type,\n            \"is_historical\": event.event_id != notif[\"event_id\"],\n            \"id\": event.event_id,\n            \"ts\": event.origin_server_ts,\n            \"sender_name\": sender_name,\n            \"sender_avatar_url\": sender_avatar_url,\n            \"sender_hash\": sender_hash,\n        }\n\n        # Encrypted messages don't have any additional useful information.\n        if event.type == EventTypes.Encrypted:\n            return ret\n\n        msgtype = event.content.get(\"msgtype\")\n\n        ret[\"msgtype\"] = msgtype\n\n        if msgtype == \"m.text\":\n            self.add_text_message_vars(ret, event)\n        elif msgtype == \"m.image\":\n            self.add_image_message_vars(ret, event)\n\n        if \"body\" in event.content:\n            ret[\"body_text_plain\"] = event.content[\"body\"]\n\n        return ret\n\n    def add_text_message_vars(\n        self, messagevars: Dict[str, Any], event: EventBase\n    ) -> None:\n        msgformat = event.content.get(\"format\")\n\n        messagevars[\"format\"] = msgformat\n\n        formatted_body = event.content.get(\"formatted_body\")\n        body = event.content.get(\"body\")\n\n        if msgformat == \"org.matrix.custom.html\" and formatted_body:\n            messagevars[\"body_text_html\"] = safe_markup(formatted_body)\n        elif body:\n            messagevars[\"body_text_html\"] = safe_text(body)\n\n    def add_image_message_vars(\n        self, messagevars: Dict[str, Any], event: EventBase\n    ) -> None:\n        \"\"\"\n        Potentially add an image URL to the message variables.\n        \"\"\"\n        if \"url\" in event.content:\n            messagevars[\"image_url\"] = event.content[\"url\"]\n\n    async def make_summary_text(\n        self,\n        notifs_by_room: Dict[str, List[Dict[str, Any]]],\n        room_state_ids: Dict[str, StateMap[str]],\n        notif_events: Dict[str, EventBase],\n        user_id: str,\n        reason: Dict[str, Any],\n    ):\n        if len(notifs_by_room) == 1:\n            # Only one room has new stuff\n            room_id = list(notifs_by_room.keys())[0]\n\n            # If the room has some kind of name, use it, but we don't\n            # want the generated-from-names one here otherwise we'll\n            # end up with, \"new message from Bob in the Bob room\"\n            room_name = await calculate_room_name(\n                self.store, room_state_ids[room_id], user_id, fallback_to_members=False\n            )\n\n            # See if one of the notifs is an invite event for the user\n            invite_event = None\n            for n in notifs_by_room[room_id]:\n                ev = notif_events[n[\"event_id\"]]\n                if ev.type == EventTypes.Member and ev.state_key == user_id:\n                    if ev.content.get(\"membership\") == Membership.INVITE:\n                        invite_event = ev\n                        break\n\n            if invite_event:\n                inviter_member_event_id = room_state_ids[room_id].get(\n                    (\"m.room.member\", invite_event.sender)\n                )\n                inviter_name = invite_event.sender\n                if inviter_member_event_id:\n                    inviter_member_event = await self.store.get_event(\n                        inviter_member_event_id, allow_none=True\n                    )\n                    if inviter_member_event:\n                        inviter_name = name_from_member_event(inviter_member_event)\n\n                if room_name is None:\n                    return self.email_subjects.invite_from_person % {\n                        \"person\": inviter_name,\n                        \"app\": self.app_name,\n                    }\n                else:\n                    return self.email_subjects.invite_from_person_to_room % {\n                        \"person\": inviter_name,\n                        \"room\": room_name,\n                        \"app\": self.app_name,\n                    }\n\n            sender_name = None\n            if len(notifs_by_room[room_id]) == 1:\n                # There is just the one notification, so give some detail\n                event = notif_events[notifs_by_room[room_id][0][\"event_id\"]]\n                if (\"m.room.member\", event.sender) in room_state_ids[room_id]:\n                    state_event_id = room_state_ids[room_id][\n                        (\"m.room.member\", event.sender)\n                    ]\n                    state_event = await self.store.get_event(state_event_id)\n                    sender_name = name_from_member_event(state_event)\n\n                if sender_name is not None and room_name is not None:\n                    return self.email_subjects.message_from_person_in_room % {\n                        \"person\": sender_name,\n                        \"room\": room_name,\n                        \"app\": self.app_name,\n                    }\n                elif sender_name is not None:\n                    return self.email_subjects.message_from_person % {\n                        \"person\": sender_name,\n                        \"app\": self.app_name,\n                    }\n            else:\n                # There's more than one notification for this room, so just\n                # say there are several\n                if room_name is not None:\n                    return self.email_subjects.messages_in_room % {\n                        \"room\": room_name,\n                        \"app\": self.app_name,\n                    }\n                else:\n                    # If the room doesn't have a name, say who the messages\n                    # are from explicitly to avoid, \"messages in the Bob room\"\n                    sender_ids = list(\n                        {\n                            notif_events[n[\"event_id\"]].sender\n                            for n in notifs_by_room[room_id]\n                        }\n                    )\n\n                    member_events = await self.store.get_events(\n                        [\n                            room_state_ids[room_id][(\"m.room.member\", s)]\n                            for s in sender_ids\n                        ]\n                    )\n\n                    return self.email_subjects.messages_from_person % {\n                        \"person\": descriptor_from_member_events(member_events.values()),\n                        \"app\": self.app_name,\n                    }\n        else:\n            # Stuff's happened in multiple different rooms\n\n            # ...but we still refer to the 'reason' room which triggered the mail\n            if reason[\"room_name\"] is not None:\n                return self.email_subjects.messages_in_room_and_others % {\n                    \"room\": reason[\"room_name\"],\n                    \"app\": self.app_name,\n                }\n            else:\n                # If the reason room doesn't have a name, say who the messages\n                # are from explicitly to avoid, \"messages in the Bob room\"\n                room_id = reason[\"room_id\"]\n\n                sender_ids = list(\n                    {\n                        notif_events[n[\"event_id\"]].sender\n                        for n in notifs_by_room[room_id]\n                    }\n                )\n\n                member_events = await self.store.get_events(\n                    [room_state_ids[room_id][(\"m.room.member\", s)] for s in sender_ids]\n                )\n\n                return self.email_subjects.messages_from_person_and_others % {\n                    \"person\": descriptor_from_member_events(member_events.values()),\n                    \"app\": self.app_name,\n                }\n\n    def make_room_link(self, room_id: str) -> str:\n        if self.hs.config.email_riot_base_url:\n            base_url = \"%s/#/room\" % (self.hs.config.email_riot_base_url)\n        elif self.app_name == \"Vector\":\n            # need /beta for Universal Links to work on iOS\n            base_url = \"https://vector.im/beta/#/room\"\n        else:\n            base_url = \"https://matrix.to/#\"\n        return \"%s/%s\" % (base_url, room_id)\n\n    def make_notif_link(self, notif: Dict[str, str]) -> str:\n        if self.hs.config.email_riot_base_url:\n            return \"%s/#/room/%s/%s\" % (\n                self.hs.config.email_riot_base_url,\n                notif[\"room_id\"],\n                notif[\"event_id\"],\n            )\n        elif self.app_name == \"Vector\":\n            # need /beta for Universal Links to work on iOS\n            return \"https://vector.im/beta/#/room/%s/%s\" % (\n                notif[\"room_id\"],\n                notif[\"event_id\"],\n            )\n        else:\n            return \"https://matrix.to/#/%s/%s\" % (notif[\"room_id\"], notif[\"event_id\"])\n\n    def make_unsubscribe_link(\n        self, user_id: str, app_id: str, email_address: str\n    ) -> str:\n        params = {\n            \"access_token\": self.macaroon_gen.generate_delete_pusher_token(user_id),\n            \"app_id\": app_id,\n            \"pushkey\": email_address,\n        }\n\n        # XXX: make r0 once API is stable\n        return \"%s_matrix/client/unstable/pushers/remove?%s\" % (\n            self.hs.config.public_baseurl,\n            urllib.parse.urlencode(params),\n        )\n\n\ndef safe_markup(raw_html: str) -> jinja2.Markup:\n    return jinja2.Markup(\n        bleach.linkify(\n            bleach.clean(\n                raw_html,\n                tags=ALLOWED_TAGS,\n                attributes=ALLOWED_ATTRS,\n                # bleach master has this, but it isn't released yet\n                # protocols=ALLOWED_SCHEMES,\n                strip=True,\n            )\n        )\n    )\n\n\ndef safe_text(raw_text: str) -> jinja2.Markup:\n    \"\"\"\n    Process text: treat it as HTML but escape any tags (ie. just escape the\n    HTML) then linkify it.\n    \"\"\"\n    return jinja2.Markup(\n        bleach.linkify(bleach.clean(raw_text, tags=[], attributes={}, strip=False))\n    )\n\n\ndef deduped_ordered_list(it: Iterable[T]) -> List[T]:\n    seen = set()\n    ret = []\n    for item in it:\n        if item not in seen:\n            seen.add(item)\n            ret.append(item)\n    return ret\n\n\ndef string_ordinal_total(s: str) -> int:\n    tot = 0\n    for c in s:\n        tot += ord(c)\n    return tot\n", "patch": "@@ -668,6 +668,15 @@ def make_unsubscribe_link(\n \n \n def safe_markup(raw_html: str) -> jinja2.Markup:\n+    \"\"\"\n+    Sanitise a raw HTML string to a set of allowed tags and attributes, and linkify any bare URLs.\n+\n+    Args\n+        raw_html: Unsafe HTML.\n+\n+    Returns:\n+        A Markup object ready to safely use in a Jinja template.\n+    \"\"\"\n     return jinja2.Markup(\n         bleach.linkify(\n             bleach.clean(\n@@ -684,8 +693,13 @@ def safe_markup(raw_html: str) -> jinja2.Markup:\n \n def safe_text(raw_text: str) -> jinja2.Markup:\n     \"\"\"\n-    Process text: treat it as HTML but escape any tags (ie. just escape the\n-    HTML) then linkify it.\n+    Sanitise text (escape any HTML tags), and then linkify any bare URLs.\n+\n+    Args\n+        raw_text: Unsafe text which might include HTML markup.\n+\n+    Returns:\n+        A Markup object ready to safely use in a Jinja template.\n     \"\"\"\n     return jinja2.Markup(\n         bleach.linkify(bleach.clean(raw_text, tags=[], attributes={}, strip=False))", "file_path": "files/2021_3/68", "file_language": "py", "file_name": "synapse/push/mailer.py", "outdated_file_modify": 0, "outdated_file_before": 0, "outdated_file_after": 0, "llm_check": 1, "static_check": 0, "static": {"rats": [false, []], "semgrep": [false, []]}, "target": -1, "function_before": [], "function_after": []}, {"raw_url": "https://github.com/matrix-org/synapse/raw/e54746bdf7d5c831eabe4dcea76a7626f1de73df/synapse%2Fres%2Ftemplates%2Fsso_auth_bad_user.html", "code": "<html>\n<head>\n    <title>Authentication Failed</title>\n</head>\n    <body>\n        <div>\n            <p>\n                We were unable to validate your <tt>{{ server_name }}</tt> account via\n                single-sign-on (SSO), because the SSO Identity Provider returned\n                different details than when you logged in.\n            </p>\n            <p>\n                Try the operation again, and ensure that you use the same details on\n                the Identity Provider as when you log into your account.\n            </p>\n        </div>\n    </body>\n</html>\n", "code_before": "<html>\n<head>\n    <title>Authentication Failed</title>\n</head>\n    <body>\n        <div>\n            <p>\n                We were unable to validate your <tt>{{server_name | e}}</tt> account via\n                single-sign-on (SSO), because the SSO Identity Provider returned\n                different details than when you logged in.\n            </p>\n            <p>\n                Try the operation again, and ensure that you use the same details on\n                the Identity Provider as when you log into your account.\n            </p>\n        </div>\n    </body>\n</html>\n", "patch": "@@ -5,7 +5,7 @@\n     <body>\n         <div>\n             <p>\n-                We were unable to validate your <tt>{{server_name | e}}</tt> account via\n+                We were unable to validate your <tt>{{ server_name }}</tt> account via\n                 single-sign-on (SSO), because the SSO Identity Provider returned\n                 different details than when you logged in.\n             </p>", "file_path": "files/2021_3/69", "file_language": "html", "file_name": "synapse/res/templates/sso_auth_bad_user.html", "outdated_file_modify": 0, "outdated_file_before": 0, "outdated_file_after": 0}, {"raw_url": "https://github.com/matrix-org/synapse/raw/e54746bdf7d5c831eabe4dcea76a7626f1de73df/synapse%2Fres%2Ftemplates%2Fsso_auth_confirm.html", "code": "<html>\n<head>\n    <title>Authentication</title>\n</head>\n    <body>\n        <div>\n            <p>\n                A client is trying to {{ description }}. To confirm this action,\n                <a href=\"{{ redirect_url }}\">re-authenticate with single sign-on</a>.\n                If you did not expect this, your account may be compromised!\n            </p>\n        </div>\n    </body>\n</html>\n", "code_before": "<html>\n<head>\n    <title>Authentication</title>\n</head>\n    <body>\n        <div>\n            <p>\n                A client is trying to {{ description | e }}. To confirm this action,\n                <a href=\"{{ redirect_url | e }}\">re-authenticate with single sign-on</a>.\n                If you did not expect this, your account may be compromised!\n            </p>\n        </div>\n    </body>\n</html>\n", "patch": "@@ -5,8 +5,8 @@\n     <body>\n         <div>\n             <p>\n-                A client is trying to {{ description | e }}. To confirm this action,\n-                <a href=\"{{ redirect_url | e }}\">re-authenticate with single sign-on</a>.\n+                A client is trying to {{ description }}. To confirm this action,\n+                <a href=\"{{ redirect_url }}\">re-authenticate with single sign-on</a>.\n                 If you did not expect this, your account may be compromised!\n             </p>\n         </div>", "file_path": "files/2021_3/70", "file_language": "html", "file_name": "synapse/res/templates/sso_auth_confirm.html", "outdated_file_modify": 0, "outdated_file_before": 0, "outdated_file_after": 0}, {"raw_url": "https://github.com/matrix-org/synapse/raw/e54746bdf7d5c831eabe4dcea76a7626f1de73df/synapse%2Fres%2Ftemplates%2Fsso_error.html", "code": "<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <title>SSO error</title>\n</head>\n<body>\n{# If an error of unauthorised is returned it means we have actively rejected their login #}\n{% if error == \"unauthorised\" %}\n    <p>You are not allowed to log in here.</p>\n{% else %}\n    <p>\n        There was an error during authentication:\n    </p>\n    <div id=\"errormsg\" style=\"margin:20px 80px\">{{ error_description }}</div>\n    <p>\n        If you are seeing this page after clicking a link sent to you via email, make\n        sure you only click the confirmation link once, and that you open the\n        validation link in the same client you're logging in from.\n    </p>\n    <p>\n        Try logging in again from your Matrix client and if the problem persists\n        please contact the server's administrator.\n    </p>\n    <p>Error: <code>{{ error }}</code></p>\n\n    <script type=\"text/javascript\">\n        // Error handling to support Auth0 errors that we might get through a GET request\n        // to the validation endpoint. If an error is provided, it's either going to be\n        // located in the query string or in a query string-like URI fragment.\n        // We try to locate the error from any of these two locations, but if we can't\n        // we just don't print anything specific.\n        let searchStr = \"\";\n        if (window.location.search) {\n            // window.location.searchParams isn't always defined when\n            // window.location.search is, so it's more reliable to parse the latter.\n            searchStr = window.location.search;\n        } else if (window.location.hash) {\n            // Replace the # with a ? so that URLSearchParams does the right thing and\n            // doesn't parse the first parameter incorrectly.\n            searchStr = window.location.hash.replace(\"#\", \"?\");\n        }\n\n        // We might end up with no error in the URL, so we need to check if we have one\n        // to print one.\n        let errorDesc = new URLSearchParams(searchStr).get(\"error_description\")\n        if (errorDesc) {\n            document.getElementById(\"errormsg\").innerText = errorDesc;\n        }\n    </script>\n{% endif %}\n</body>\n</html>\n", "code_before": "<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <title>SSO error</title>\n</head>\n<body>\n{# If an error of unauthorised is returned it means we have actively rejected their login #}\n{% if error == \"unauthorised\" %}\n    <p>You are not allowed to log in here.</p>\n{% else %}\n    <p>\n        There was an error during authentication:\n    </p>\n    <div id=\"errormsg\" style=\"margin:20px 80px\">{{ error_description | e }}</div>\n    <p>\n        If you are seeing this page after clicking a link sent to you via email, make\n        sure you only click the confirmation link once, and that you open the\n        validation link in the same client you're logging in from.\n    </p>\n    <p>\n        Try logging in again from your Matrix client and if the problem persists\n        please contact the server's administrator.\n    </p>\n    <p>Error: <code>{{ error }}</code></p>\n\n    <script type=\"text/javascript\">\n        // Error handling to support Auth0 errors that we might get through a GET request\n        // to the validation endpoint. If an error is provided, it's either going to be\n        // located in the query string or in a query string-like URI fragment.\n        // We try to locate the error from any of these two locations, but if we can't\n        // we just don't print anything specific.\n        let searchStr = \"\";\n        if (window.location.search) {\n            // window.location.searchParams isn't always defined when\n            // window.location.search is, so it's more reliable to parse the latter.\n            searchStr = window.location.search;\n        } else if (window.location.hash) {\n            // Replace the # with a ? so that URLSearchParams does the right thing and\n            // doesn't parse the first parameter incorrectly.\n            searchStr = window.location.hash.replace(\"#\", \"?\");\n        }\n\n        // We might end up with no error in the URL, so we need to check if we have one\n        // to print one.\n        let errorDesc = new URLSearchParams(searchStr).get(\"error_description\")\n        if (errorDesc) {\n            document.getElementById(\"errormsg\").innerText = errorDesc;\n        }\n    </script>\n{% endif %}\n</body>\n</html>\n", "patch": "@@ -12,7 +12,7 @@\n     <p>\n         There was an error during authentication:\n     </p>\n-    <div id=\"errormsg\" style=\"margin:20px 80px\">{{ error_description | e }}</div>\n+    <div id=\"errormsg\" style=\"margin:20px 80px\">{{ error_description }}</div>\n     <p>\n         If you are seeing this page after clicking a link sent to you via email, make\n         sure you only click the confirmation link once, and that you open the", "file_path": "files/2021_3/71", "file_language": "html", "file_name": "synapse/res/templates/sso_error.html", "outdated_file_modify": 0, "outdated_file_before": 0, "outdated_file_after": 0}, {"raw_url": "https://github.com/matrix-org/synapse/raw/e54746bdf7d5c831eabe4dcea76a7626f1de73df/synapse%2Fres%2Ftemplates%2Fsso_login_idp_picker.html", "code": "<!DOCTYPE html>\n<html lang=\"en\">\n    <head>\n        <meta charset=\"UTF-8\">\n        <link rel=\"stylesheet\" href=\"/_matrix/static/client/login/style.css\">\n        <title>{{ server_name }} Login</title>\n    </head>\n    <body>\n        <div id=\"container\">\n            <h1 id=\"title\">{{ server_name }} Login</h1>\n            <div class=\"login_flow\">\n                <p>Choose one of the following identity providers:</p>\n            <form>\n                <input type=\"hidden\" name=\"redirectUrl\" value=\"{{ redirect_url }}\">\n                <ul class=\"radiobuttons\">\n{% for p in providers %}\n                    <li>\n                        <input type=\"radio\" name=\"idp\" id=\"prov{{ loop.index }}\" value=\"{{ p.idp_id }}\">\n                        <label for=\"prov{{ loop.index }}\">{{ p.idp_name }}</label>\n{% if p.idp_icon %}\n                        <img src=\"{{ p.idp_icon | mxc_to_http(32, 32) }}\"/>\n{% endif %}\n                    </li>\n{% endfor %}\n                </ul>\n                <input type=\"submit\" class=\"button button--full-width\" id=\"button-submit\" value=\"Submit\">\n            </form>\n            </div>\n        </div>\n    </body>\n</html>\n", "code_before": "<!DOCTYPE html>\n<html lang=\"en\">\n    <head>\n        <meta charset=\"UTF-8\">\n        <link rel=\"stylesheet\" href=\"/_matrix/static/client/login/style.css\">\n        <title>{{server_name | e}} Login</title>\n    </head>\n    <body>\n        <div id=\"container\">\n            <h1 id=\"title\">{{server_name | e}} Login</h1>\n            <div class=\"login_flow\">\n                <p>Choose one of the following identity providers:</p>\n            <form>\n                <input type=\"hidden\" name=\"redirectUrl\" value=\"{{redirect_url | e}}\">\n                <ul class=\"radiobuttons\">\n{% for p in providers %}\n                    <li>\n                        <input type=\"radio\" name=\"idp\" id=\"prov{{loop.index}}\" value=\"{{p.idp_id}}\">\n                        <label for=\"prov{{loop.index}}\">{{p.idp_name | e}}</label>\n{% if p.idp_icon %}\n                        <img src=\"{{p.idp_icon | mxc_to_http(32, 32)}}\"/>\n{% endif %}\n                    </li>\n{% endfor %}\n                </ul>\n                <input type=\"submit\" class=\"button button--full-width\" id=\"button-submit\" value=\"Submit\">\n            </form>\n            </div>\n        </div>\n    </body>\n</html>\n", "patch": "@@ -3,22 +3,22 @@\n     <head>\n         <meta charset=\"UTF-8\">\n         <link rel=\"stylesheet\" href=\"/_matrix/static/client/login/style.css\">\n-        <title>{{server_name | e}} Login</title>\n+        <title>{{ server_name }} Login</title>\n     </head>\n     <body>\n         <div id=\"container\">\n-            <h1 id=\"title\">{{server_name | e}} Login</h1>\n+            <h1 id=\"title\">{{ server_name }} Login</h1>\n             <div class=\"login_flow\">\n                 <p>Choose one of the following identity providers:</p>\n             <form>\n-                <input type=\"hidden\" name=\"redirectUrl\" value=\"{{redirect_url | e}}\">\n+                <input type=\"hidden\" name=\"redirectUrl\" value=\"{{ redirect_url }}\">\n                 <ul class=\"radiobuttons\">\n {% for p in providers %}\n                     <li>\n-                        <input type=\"radio\" name=\"idp\" id=\"prov{{loop.index}}\" value=\"{{p.idp_id}}\">\n-                        <label for=\"prov{{loop.index}}\">{{p.idp_name | e}}</label>\n+                        <input type=\"radio\" name=\"idp\" id=\"prov{{ loop.index }}\" value=\"{{ p.idp_id }}\">\n+                        <label for=\"prov{{ loop.index }}\">{{ p.idp_name }}</label>\n {% if p.idp_icon %}\n-                        <img src=\"{{p.idp_icon | mxc_to_http(32, 32)}}\"/>\n+                        <img src=\"{{ p.idp_icon | mxc_to_http(32, 32) }}\"/>\n {% endif %}\n                     </li>\n {% endfor %}", "file_path": "files/2021_3/72", "file_language": "html", "file_name": "synapse/res/templates/sso_login_idp_picker.html", "outdated_file_modify": 0, "outdated_file_before": 0, "outdated_file_after": 0}, {"raw_url": "https://github.com/matrix-org/synapse/raw/e54746bdf7d5c831eabe4dcea76a7626f1de73df/synapse%2Fres%2Ftemplates%2Fsso_redirect_confirm.html", "code": "<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <title>SSO redirect confirmation</title>\n</head>\n    <body>\n        <p>The application at <span style=\"font-weight:bold\">{{ display_url }}</span> is requesting full access to your <span style=\"font-weight:bold\">{{ server_name }}</span> Matrix account.</p>\n        <p>If you don't recognise this address, you should ignore this and close this tab.</p>\n        <p>\n            <a href=\"{{ redirect_url }}\">I trust this address</a>\n        </p>\n    </body>\n</html>\n", "code_before": "<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <title>SSO redirect confirmation</title>\n</head>\n    <body>\n        <p>The application at <span style=\"font-weight:bold\">{{ display_url | e }}</span> is requesting full access to your <span style=\"font-weight:bold\">{{ server_name }}</span> Matrix account.</p>\n        <p>If you don't recognise this address, you should ignore this and close this tab.</p>\n        <p>\n            <a href=\"{{ redirect_url | e }}\">I trust this address</a>\n        </p>\n    </body>\n</html>", "patch": "@@ -5,10 +5,10 @@\n     <title>SSO redirect confirmation</title>\n </head>\n     <body>\n-        <p>The application at <span style=\"font-weight:bold\">{{ display_url | e }}</span> is requesting full access to your <span style=\"font-weight:bold\">{{ server_name }}</span> Matrix account.</p>\n+        <p>The application at <span style=\"font-weight:bold\">{{ display_url }}</span> is requesting full access to your <span style=\"font-weight:bold\">{{ server_name }}</span> Matrix account.</p>\n         <p>If you don't recognise this address, you should ignore this and close this tab.</p>\n         <p>\n-            <a href=\"{{ redirect_url | e }}\">I trust this address</a>\n+            <a href=\"{{ redirect_url }}\">I trust this address</a>\n         </p>\n     </body>\n-</html>\n\\ No newline at end of file\n+</html>", "file_path": "files/2021_3/73", "file_language": "html", "file_name": "synapse/res/templates/sso_redirect_confirm.html", "outdated_file_modify": 0, "outdated_file_before": 0, "outdated_file_after": 0}], "outdated": 0, "cwe_descripiton": "", "cwe_consequence": "", "cwe_method": "", "cwe_solution": ""}
