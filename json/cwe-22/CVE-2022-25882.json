{"index": 10220, "cve_id": "CVE-2022-25882", "cwe_id": ["CWE-22"], "cve_language": "Python", "cve_description": "Versions of the package onnx before 1.13.0 are vulnerable to Directory Traversal as the external_data field of the tensor proto can have a path to the file which is outside the model current directory or user-provided directory, for example \"../../../etc/passwd\"", "cvss": "7.5", "publish_date": "January 26, 2023", "AV": "NETWORK", "AC": "NETWORK", "PR": "NONE", "UI": "NONE", "S": "UNCHANGED", "C": "HIGH", "I": "NONE", "A": "NONE", "commit_id": "f369b0e859024095d721f1d1612da5a8fa38988d", "commit_message": "Do not allow to read tensor's external_data outside the model directory (#4400)\n\n* Not allow to read tensor external_data outside the model directory\r\n\r\nSigned-off-by: jnovikov <johnnovikov0@gmail.com>\r\n\r\n* Fix formatting errors\r\n\r\nSigned-off-by: jnovikov <johnnovikov0@gmail.com>\r\n\r\n* Disable segfaulty test\r\n\r\nSigned-off-by: jnovikov <johnnovikov0@gmail.com>\r\n\r\n* Fix cpp tests\r\n\r\nSigned-off-by: jnovikov <johnnovikov0@gmail.com>\r\n\r\n* Fix UB while removing ../\r\n\r\nSigned-off-by: jnovikov <johnnovikov0@gmail.com>\r\n\r\n* Fix clang-format\r\n\r\nSigned-off-by: jnovikov <johnnovikov0@gmail.com>\r\n\r\n* Check for symlinks only on POSIX systems\r\n\r\nSigned-off-by: jnovikov <johnnovikov0@gmail.com>\r\n\r\n* Add specific to Windows external_data test\r\n\r\nSigned-off-by: jnovikov <johnnovikov0@gmail.com>\r\n\r\n* Change specific Windows external_data test decorator tofix mypy\r\n\r\nSigned-off-by: jnovikov <johnnovikov0@gmail.com>\r\n\r\n* Remove unused pathlib\r\n\r\nSigned-off-by: jnovikov <johnnovikov0@gmail.com>\r\n\r\nSigned-off-by: jnovikov <johnnovikov0@gmail.com>", "commit_date": "2022-08-10T15:35:50Z", "project": "onnx/onnx", "url": "https://api.github.com/repos/onnx/onnx/commits/f369b0e859024095d721f1d1612da5a8fa38988d", "html_url": "https://github.com/onnx/onnx/commit/f369b0e859024095d721f1d1612da5a8fa38988d", "windows_before": [{"commit_id": "eb634addcbb23ec1baf4d548d826bf3932527533", "commit_date": "Sat Aug 6 08:21:53 2022 +0200", "commit_message": "Allow for both scales and sizes to be provided when one of them is an empty constant (#4388)", "files_name": ["onnx/defs/tensor/utils.cc", "onnx/test/shape_inference_test.py"]}, {"commit_id": "b47107e163a8a5bb1cd056af5a37fa181812d183", "commit_date": "Fri Aug 5 17:24:09 2022 -0700", "commit_message": "improve cast spec (#4351)", "files_name": ["docs/Changelog.md", "docs/Operators.md", "onnx/defs/tensor/defs.cc"]}, {"commit_id": "4239e3965ab95ee657d381ae8cbd346e696131e3", "commit_date": "Fri Aug 5 18:20:16 2022 +0300", "commit_message": "Make C++ and Python check_model consistent (#4386)", "files_name": ["onnx/checker.cc", "onnx/checker.h", "onnx/checker.py", "onnx/cpp2py_export.cc", "onnx/onnx_cpp2py_export/checker.pyi"]}, {"commit_id": "8910f00b5976000e79111325bcdaad1a62811cde", "commit_date": "Fri Aug 5 22:30:41 2022 +0800", "commit_message": "fix bugs and add .clang-tidy (#4391)", "files_name": [".clang-tidy", "onnx/common/assertions.h", "onnx/common/graph_node_list.h", "onnx/common/ir.h", "onnx/common/ir_pb_converter.cc", "onnx/common/ir_pb_converter.h", "onnx/common/tensor.h"]}, {"commit_id": "d10e15fa963720b5dfea690b030ee752006d8c1d", "commit_date": "Thu Aug 4 07:33:56 2022 -0700", "commit_message": "Use fully qualified pathname when loading DLL to prevent security vulnerability (#4377)", "files_name": ["onnx/onnxifi_loader.c"]}, {"commit_id": "3bc634c8185a01be540075f6827ed5c6e632e478", "commit_date": "Thu Aug 4 06:58:58 2022 -0700", "commit_message": "Add new Lint Python CI in the CI document (#4332)", "files_name": ["docs/CIPipelines.md", "docs/CONTRIBUTING.md"]}, {"commit_id": "55d3b80f3ea1261f3f74f2e35844c204de85835a", "commit_date": "Wed Aug 3 17:22:05 2022 -0700", "commit_message": "Upgrade to macos-11 due to macos-10.15 deprecation (#4379)", "files_name": [".github/workflows/release_mac.yml", "docs/CIPipelines.md"]}, {"commit_id": "5f3fb1f1bd0989a0b25c347ad0346dfcce3c2cd4", "commit_date": "Tue Aug 2 12:21:42 2022 -0700", "commit_message": "Extend printer to handle non-standard domain (#4372)", "files_name": ["onnx/defs/printer.cc", "onnx/test/cpp/parser_test.cc"]}, {"commit_id": "2071a273adfdd3a44bdbf4d24fc797c7e4e951d0", "commit_date": "Tue Aug 2 11:44:53 2022 -0700", "commit_message": "add docs for cpp tests requiring built libraries (#4401)", "files_name": ["docs/CONTRIBUTING.md"]}, {"commit_id": "9fdb3bbd7b8c99b7b6e356069193ba7150405fce", "commit_date": "Wed Aug 3 01:54:33 2022 +0800", "commit_message": "use CMAKE_INSTALL_LIBDIR to avoid hardcoded path (#4395)", "files_name": ["CMakeLists.txt", "README.md"]}, {"commit_id": "5e1c1bbe63d95165cc85e816da906578ad637b68", "commit_date": "Tue Aug 2 19:06:38 2022 +0200", "commit_message": "Clarify and add helper for making attribute references (#4393)", "files_name": ["docs/IR.md", "onnx/helper.py"]}, {"commit_id": "66480ce6ab0f4c56e27bb120f246c3ddd0d1e19e", "commit_date": "Mon Aug 1 23:45:12 2022 +0800", "commit_message": "Fix errors reported by flake8 5.0.2 (#4397)", "files_name": ["onnx/test/shape_inference_test.py", "onnx/utils.py", "requirements-dev.txt", "setup.py"]}, {"commit_id": "84f6ff689da8ec930877478d3a50fe5081ad582f", "commit_date": "Wed Jul 27 17:55:17 2022 +0200", "commit_message": "Implement mish as a function (#4350)", "files_name": ["docs/Changelog.md", "docs/Operators.md", "docs/TestCoverage.md", "onnx/backend/test/case/node/mish.py", "onnx/backend/test/data/node/test_mish/model.onnx", "onnx/backend/test/data/node/test_mish/test_data_set_0/input_0.pb", "onnx/backend/test/data/node/test_mish/test_data_set_0/output_0.pb", "onnx/backend/test/data/node/test_mish_expanded/model.onnx", "onnx/backend/test/data/node/test_mish_expanded/test_data_set_0/input_0.pb", "onnx/backend/test/data/node/test_mish_expanded/test_data_set_0/output_0.pb", "onnx/defs/math/defs.cc", "onnx/defs/operator_sets.h", "onnx/test/automatic_upgrade_test.py", "onnx/test/test_with_ort.py"]}, {"commit_id": "9042bb13fd8574bc44d8e257eb1aae69214692dc", "commit_date": "Wed Jul 27 22:50:57 2022 +0800", "commit_message": "add uint64_t implement of ParseData function (#4285)", "files_name": ["onnx/defs/tensor_util.cc"]}, {"commit_id": "765c523eebe18e0790cd4e85b64234901b5f10ec", "commit_date": "Wed Jul 27 11:48:20 2022 +0800", "commit_message": "print model name in the exception message (#4378)", "files_name": ["onnx/hub.py"]}, {"commit_id": "ae3c87bca9e5bf233a07b8c9677a3cc957d43604", "commit_date": "Tue Jul 26 08:08:26 2022 -0700", "commit_message": "Test lower protoc version in Linux CI (#4365)", "files_name": [".azure-pipelines/Linux-CI.yml", ".github/workflows/manylinux/entrypoint.sh", ".github/workflows/release_mac.yml", "README.md", "docs/CIPipelines.md", "docs/CONTRIBUTING.md", "onnx/test/cpp/data_propagation_test.cc", "onnx/test/cpp/shape_inference_test.cc"]}, {"commit_id": "2f3d7fa1e3d82923fc5c5e0a23f24ab54ab30282", "commit_date": "Fri Jul 22 10:37:03 2022 -0700", "commit_message": "Remove pyflakes (#4371)", "files_name": [".github/workflows/lint.yaml"]}, {"commit_id": "e45ca037ef9c1776414fe5fcc1349aff61869e1b", "commit_date": "Thu Jul 21 14:03:08 2022 -0700", "commit_message": "Enhance test_backend_test.py and simplify backend test CI (#3393)", "files_name": [".azure-pipelines/Linux-CI.yml", ".github/workflows/release_linux_aarch64.yml", ".github/workflows/release_linux_x86_64.yml", ".github/workflows/release_mac.yml", ".github/workflows/release_win.yml", "onnx/backend/test/data/pytorch-converted/test_PixelShuffle/model.onnx", "onnx/backend/test/data/pytorch-operator/test_operator_repeat/model.onnx", "onnx/backend/test/data/pytorch-operator/test_operator_repeat_dim_overflow/model.onnx", "onnx/test/test_backend_test.py", "workflow_scripts/test_generated_backend.py"]}, {"commit_id": "2637680715cf034192112c4d820311b760dd77a2", "commit_date": "Thu Jul 21 22:24:46 2022 +0200", "commit_message": "Clarify minimum version of Protobuf required by ONNX (#4360)", "files_name": ["README.md"]}, {"commit_id": "190b8802472b61303b0f5cb306685ef53eced1e7", "commit_date": "Wed Jul 20 18:03:06 2022 -0700", "commit_message": "Add detailed error message for saving 2GB proto (#4366)", "files_name": ["onnx/__init__.py"]}, {"commit_id": "b1d5cfac490e4f689269e29ea1b2b994e0be8ef6", "commit_date": "Wed Jul 20 17:18:30 2022 -0700", "commit_message": "Clarify in the doc that ONNX should use rc as release candidate (#4333)", "files_name": ["docs/OnnxReleases.md"]}, {"commit_id": "e5e6c0d965fcd1fd5412a5c66e2182005864c8f9", "commit_date": "Mon Jul 18 19:21:37 2022 +0200", "commit_message": "Use RepeatedPtrField::Get instead of RepeatedPtrField::operator[], to be compatible with protobuf 3.0 API (#4354)", "files_name": ["onnx/defs/sequence/defs.cc"]}, {"commit_id": "e450bc038115dd9ff5ab47670eeaf2a584105064", "commit_date": "Fri Jul 15 15:07:45 2022 -0700", "commit_message": "Set up black and isort (#4361)", "files_name": [".azure-pipelines/Linux-CI.yml", ".github/workflows/lint.yaml", "pyproject.toml", "requirements-dev.txt", "setup.cfg"]}, {"commit_id": "d93ab21f1e1bc04d3f53e2ea2d2e281a3092b4c8", "commit_date": "Thu Jul 14 12:58:08 2022 -0700", "commit_message": "Ignore noisy pylint warnings (#4359)", "files_name": ["setup.cfg"]}, {"commit_id": "0fc92e41e3d66796b65ca67140e80640d834b27e", "commit_date": "Wed Jul 13 02:08:48 2022 +0200", "commit_message": "Update AddNewOp.md (#4353)", "files_name": ["docs/AddNewOp.md"]}, {"commit_id": "1400c9814cac735d325d29e8040c0d48c6c08a8a", "commit_date": "Tue Jul 12 18:12:02 2022 +0200", "commit_message": "Introduce CenterCropPad, add `axes` to Pad (#4190)", "files_name": ["docs/Changelog.md", "docs/Operators.md", "docs/TestCoverage.md", "onnx/backend/test/case/node/center_crop_pad.py", "onnx/backend/test/case/node/pad.py", "onnx/backend/test/data/node/test_center_crop_pad_crop/model.onnx", "onnx/backend/test/data/node/test_center_crop_pad_crop/test_data_set_0/input_0.pb", "onnx/backend/test/data/node/test_center_crop_pad_crop/test_data_set_0/input_1.pb", "onnx/backend/test/data/node/test_center_crop_pad_crop/test_data_set_0/output_0.pb", "onnx/backend/test/data/node/test_center_crop_pad_crop_and_pad/model.onnx", "onnx/backend/test/data/node/test_center_crop_pad_crop_and_pad/test_data_set_0/input_0.pb", "onnx/backend/test/data/node/test_center_crop_pad_crop_and_pad/test_data_set_0/input_1.pb", "onnx/backend/test/data/node/test_center_crop_pad_crop_and_pad/test_data_set_0/output_0.pb", "onnx/backend/test/data/node/test_center_crop_pad_crop_and_pad_expanded/model.onnx", "onnx/backend/test/data/node/test_center_crop_pad_crop_and_pad_expanded/test_data_set_0/input_0.pb", "onnx/backend/test/data/node/test_center_crop_pad_crop_and_pad_expanded/test_data_set_0/input_1.pb", "onnx/backend/test/data/node/test_center_crop_pad_crop_and_pad_expanded/test_data_set_0/output_0.pb", "onnx/backend/test/data/node/test_center_crop_pad_crop_axes_chw/model.onnx", "onnx/backend/test/data/node/test_center_crop_pad_crop_axes_chw/test_data_set_0/input_0.pb", "onnx/backend/test/data/node/test_center_crop_pad_crop_axes_chw/test_data_set_0/input_1.pb", "onnx/backend/test/data/node/test_center_crop_pad_crop_axes_chw/test_data_set_0/output_0.pb", "onnx/backend/test/data/node/test_center_crop_pad_crop_axes_chw_expanded/model.onnx", "onnx/backend/test/data/node/test_center_crop_pad_crop_axes_chw_expanded/test_data_set_0/input_0.pb", "onnx/backend/test/data/node/test_center_crop_pad_crop_axes_chw_expanded/test_data_set_0/input_1.pb", "onnx/backend/test/data/node/test_center_crop_pad_crop_axes_chw_expanded/test_data_set_0/output_0.pb", "onnx/backend/test/data/node/test_center_crop_pad_crop_axes_hwc/model.onnx", "onnx/backend/test/data/node/test_center_crop_pad_crop_axes_hwc/test_data_set_0/input_0.pb", "onnx/backend/test/data/node/test_center_crop_pad_crop_axes_hwc/test_data_set_0/input_1.pb", "onnx/backend/test/data/node/test_center_crop_pad_crop_axes_hwc/test_data_set_0/output_0.pb", "onnx/backend/test/data/node/test_center_crop_pad_crop_axes_hwc_expanded/model.onnx", "onnx/backend/test/data/node/test_center_crop_pad_crop_axes_hwc_expanded/test_data_set_0/input_0.pb", "onnx/backend/test/data/node/test_center_crop_pad_crop_axes_hwc_expanded/test_data_set_0/input_1.pb", "onnx/backend/test/data/node/test_center_crop_pad_crop_axes_hwc_expanded/test_data_set_0/output_0.pb", "onnx/backend/test/data/node/test_center_crop_pad_crop_expanded/model.onnx", "onnx/backend/test/data/node/test_center_crop_pad_crop_expanded/test_data_set_0/input_0.pb", "onnx/backend/test/data/node/test_center_crop_pad_crop_expanded/test_data_set_0/input_1.pb", "onnx/backend/test/data/node/test_center_crop_pad_crop_expanded/test_data_set_0/output_0.pb", "onnx/backend/test/data/node/test_center_crop_pad_pad/model.onnx", "onnx/backend/test/data/node/test_center_crop_pad_pad/test_data_set_0/input_0.pb", "onnx/backend/test/data/node/test_center_crop_pad_pad/test_data_set_0/input_1.pb", "onnx/backend/test/data/node/test_center_crop_pad_pad/test_data_set_0/output_0.pb", "onnx/backend/test/data/node/test_center_crop_pad_pad_expanded/model.onnx", "onnx/backend/test/data/node/test_center_crop_pad_pad_expanded/test_data_set_0/input_0.pb", "onnx/backend/test/data/node/test_center_crop_pad_pad_expanded/test_data_set_0/input_1.pb", "onnx/backend/test/data/node/test_center_crop_pad_pad_expanded/test_data_set_0/output_0.pb", "onnx/backend/test/data/node/test_constant_pad/model.onnx", "onnx/backend/test/data/node/test_constant_pad_axes/model.onnx", "onnx/backend/test/data/node/test_constant_pad_axes/test_data_set_0/input_0.pb", "onnx/backend/test/data/node/test_constant_pad_axes/test_data_set_0/input_1.pb", "onnx/backend/test/data/node/test_constant_pad_axes/test_data_set_0/input_2.pb", "onnx/backend/test/data/node/test_constant_pad_axes/test_data_set_0/input_3.pb", "onnx/backend/test/data/node/test_constant_pad_axes/test_data_set_0/output_0.pb", "onnx/backend/test/data/node/test_edge_pad/model.onnx", "onnx/backend/test/data/node/test_reflect_pad/model.onnx", "onnx/defs/operator_sets.h", "onnx/defs/tensor/defs.cc", "onnx/defs/tensor/old.cc", "onnx/test/automatic_upgrade_test.py", "onnx/test/shape_inference_test.py", "onnx/version_converter/convert.h"]}, {"commit_id": "500c3f482e0ca64580f47db707ee02a8453e16df", "commit_date": "Tue Jul 12 01:00:48 2022 +0200", "commit_message": "Add Resize-18: Antialiasing, axes and keep_aspect_ratio_policy (#4126)", "files_name": ["docs/Changelog.md"]}], "windows_after": [{"commit_id": "baffc9220765c33ab6b947c0cba05c6f59a1f973", "commit_date": "Thu Aug 11 01:12:33 2022 +0800", "commit_message": "Modify the annotation: fix the label serial number mistake (#4426)", "files_name": ["onnx/common/ir_pb_converter.cc"]}, {"commit_id": "ff95f7dd11afff226468a0140a7aa2e197bef9ee", "commit_date": "Wed Aug 10 11:11:22 2022 -0700", "commit_message": "[ci] Install ONNX before linting (#4428)", "files_name": [".github/workflows/lint.yaml"]}, {"commit_id": "c69e1562aeddacbfcbeee2644fbfaa84a274a270", "commit_date": "Wed Aug 10 13:29:03 2022 -0700", "commit_message": "Set up VS Code to format python code at save (#4430)", "files_name": [".gitignore", ".vscode/settings.json"]}, {"commit_id": "fddb2b6d4ea3fb3dba751d884865042503260899", "commit_date": "Wed Aug 10 14:20:52 2022 -0700", "commit_message": "Format all python code with black and isort - take 2 (#4427)", "files_name": [".azure-pipelines/Linux-CI.yml", "docs/Operators.md", "docs/TestCoverage.md", "onnx/__init__.py", "onnx/backend/base.py", "onnx/backend/sample/ops/__init__.py", "onnx/backend/test/__init__.py", "onnx/backend/test/case/__init__.py", "onnx/backend/test/case/base.py", "onnx/backend/test/case/model/__init__.py", "onnx/backend/test/case/model/expand.py", "onnx/backend/test/case/model/gradient.py", "onnx/backend/test/case/model/sequence.py", "onnx/backend/test/case/model/shrink.py", "onnx/backend/test/case/model/sign.py", "onnx/backend/test/case/model/single-relu.py", "onnx/backend/test/case/model/stringnormalizer.py", "onnx/backend/test/case/node/__init__.py", "onnx/backend/test/case/node/abs.py", "onnx/backend/test/case/node/acos.py", "onnx/backend/test/case/node/acosh.py", "onnx/backend/test/case/node/adagrad.py", "onnx/backend/test/case/node/adam.py", "onnx/backend/test/case/node/add.py", "onnx/backend/test/case/node/and.py", "onnx/backend/test/case/node/argmax.py", "onnx/backend/test/case/node/argmin.py", "onnx/backend/test/case/node/asin.py", "onnx/backend/test/case/node/asinh.py", "onnx/backend/test/case/node/atan.py", "onnx/backend/test/case/node/atanh.py", "onnx/backend/test/case/node/averagepool.py", "onnx/backend/test/case/node/batchnorm.py", "onnx/backend/test/case/node/bernoulli.py", "onnx/backend/test/case/node/bitshift.py", "onnx/backend/test/case/node/blackmanwindow.py", "onnx/backend/test/case/node/cast.py", "onnx/backend/test/case/node/castlike.py", "onnx/backend/test/case/node/ceil.py", "onnx/backend/test/case/node/celu.py", "onnx/backend/test/case/node/center_crop_pad.py", "onnx/backend/test/case/node/clip.py", "onnx/backend/test/case/node/compress.py", "onnx/backend/test/case/node/concat.py", "onnx/backend/test/case/node/constant.py", "onnx/backend/test/case/node/constantofshape.py", "onnx/backend/test/case/node/conv.py", "onnx/backend/test/case/node/convinteger.py", "onnx/backend/test/case/node/convtranspose.py", "onnx/backend/test/case/node/cos.py", "onnx/backend/test/case/node/cosh.py", "onnx/backend/test/case/node/cumsum.py", "onnx/backend/test/case/node/depthtospace.py", "onnx/backend/test/case/node/dequantizelinear.py", "onnx/backend/test/case/node/det.py", "onnx/backend/test/case/node/dft.py", "onnx/backend/test/case/node/div.py", "onnx/backend/test/case/node/dropout.py", "onnx/backend/test/case/node/dynamicquantizelinear.py", "onnx/backend/test/case/node/einsum.py", "onnx/backend/test/case/node/elu.py", "onnx/backend/test/case/node/equal.py", "onnx/backend/test/case/node/erf.py", "onnx/backend/test/case/node/exp.py", "onnx/backend/test/case/node/expand.py", "onnx/backend/test/case/node/eyelike.py", "onnx/backend/test/case/node/flatten.py", "onnx/backend/test/case/node/floor.py", "onnx/backend/test/case/node/gather.py", "onnx/backend/test/case/node/gatherelements.py", "onnx/backend/test/case/node/gathernd.py", "onnx/backend/test/case/node/gemm.py", "onnx/backend/test/case/node/globalaveragepool.py", "onnx/backend/test/case/node/globalmaxpool.py", "onnx/backend/test/case/node/greater.py", "onnx/backend/test/case/node/greater_equal.py", "onnx/backend/test/case/node/gridsample.py", "onnx/backend/test/case/node/gru.py", "onnx/backend/test/case/node/hammingwindow.py", "onnx/backend/test/case/node/hannwindow.py", "onnx/backend/test/case/node/hardmax.py", "onnx/backend/test/case/node/hardsigmoid.py", "onnx/backend/test/case/node/hardswish.py", "onnx/backend/test/case/node/identity.py", "onnx/backend/test/case/node/if.py", "onnx/backend/test/case/node/instancenorm.py", "onnx/backend/test/case/node/isinf.py", "onnx/backend/test/case/node/isnan.py", "onnx/backend/test/case/node/layernormalization.py", "onnx/backend/test/case/node/leakyrelu.py", "onnx/backend/test/case/node/less.py", "onnx/backend/test/case/node/less_equal.py", "onnx/backend/test/case/node/log.py", "onnx/backend/test/case/node/logsoftmax.py", "onnx/backend/test/case/node/loop.py", "onnx/backend/test/case/node/lrn.py", "onnx/backend/test/case/node/lstm.py", "onnx/backend/test/case/node/matmul.py", "onnx/backend/test/case/node/matmulinteger.py", "onnx/backend/test/case/node/max.py", "onnx/backend/test/case/node/maxpool.py", "onnx/backend/test/case/node/maxunpool.py", "onnx/backend/test/case/node/mean.py", "onnx/backend/test/case/node/meanvariancenormalization.py", "onnx/backend/test/case/node/melweightmatrix.py", "onnx/backend/test/case/node/min.py", "onnx/backend/test/case/node/mish.py", "onnx/backend/test/case/node/mod.py", "onnx/backend/test/case/node/momentum.py", "onnx/backend/test/case/node/mul.py", "onnx/backend/test/case/node/neg.py", "onnx/backend/test/case/node/negativeloglikelihoodloss.py", "onnx/backend/test/case/node/nonmaxsuppression.py", "onnx/backend/test/case/node/nonzero.py", "onnx/backend/test/case/node/not.py", "onnx/backend/test/case/node/onehot.py", "onnx/backend/test/case/node/optionalgetelement.py", "onnx/backend/test/case/node/optionalhaselement.py", "onnx/backend/test/case/node/or.py", "onnx/backend/test/case/node/pad.py", "onnx/backend/test/case/node/pool_op_common.py", "onnx/backend/test/case/node/pow.py", "onnx/backend/test/case/node/prelu.py", "onnx/backend/test/case/node/qlinearconv.py", "onnx/backend/test/case/node/qlinearmatmul.py", "onnx/backend/test/case/node/quantizelinear.py", "onnx/backend/test/case/node/rangeop.py", "onnx/backend/test/case/node/reciprocal.py", "onnx/backend/test/case/node/reduce_log_sum.py", "onnx/backend/test/case/node/reduce_log_sum_exp.py", "onnx/backend/test/case/node/reducel1.py", "onnx/backend/test/case/node/reducel2.py", "onnx/backend/test/case/node/reducemax.py", "onnx/backend/test/case/node/reducemean.py", "onnx/backend/test/case/node/reducemin.py", "onnx/backend/test/case/node/reduceprod.py", "onnx/backend/test/case/node/reducesum.py", "onnx/backend/test/case/node/reducesumsquare.py", "onnx/backend/test/case/node/relu.py", "onnx/backend/test/case/node/reshape.py", "onnx/backend/test/case/node/resize.py", "onnx/backend/test/case/node/reversesequence.py", "onnx/backend/test/case/node/rnn.py", "onnx/backend/test/case/node/roialign.py", "onnx/backend/test/case/node/round.py", "onnx/backend/test/case/node/scan.py", "onnx/backend/test/case/node/scatter.py", "onnx/backend/test/case/node/scatterelements.py", "onnx/backend/test/case/node/scatternd.py", "onnx/backend/test/case/node/selu.py", "onnx/backend/test/case/node/sequence_map.py", "onnx/backend/test/case/node/sequenceinsert.py", "onnx/backend/test/case/node/shape.py", "onnx/backend/test/case/node/shrink.py", "onnx/backend/test/case/node/sigmoid.py", "onnx/backend/test/case/node/sign.py", "onnx/backend/test/case/node/sin.py", "onnx/backend/test/case/node/sinh.py", "onnx/backend/test/case/node/size.py", "onnx/backend/test/case/node/slice.py", "onnx/backend/test/case/node/softmax.py", "onnx/backend/test/case/node/softmaxcrossentropy.py", "onnx/backend/test/case/node/softplus.py", "onnx/backend/test/case/node/softsign.py", "onnx/backend/test/case/node/spacetodepth.py", "onnx/backend/test/case/node/split.py", "onnx/backend/test/case/node/sqrt.py", "onnx/backend/test/case/node/squeeze.py", "onnx/backend/test/case/node/stft.py", "onnx/backend/test/case/node/stringnormalizer.py", "onnx/backend/test/case/node/sub.py", "onnx/backend/test/case/node/sum.py", "onnx/backend/test/case/node/tan.py", "onnx/backend/test/case/node/tanh.py", "onnx/backend/test/case/node/tfidfvectorizer.py", "onnx/backend/test/case/node/thresholdedrelu.py", "onnx/backend/test/case/node/tile.py", "onnx/backend/test/case/node/topk.py", "onnx/backend/test/case/node/transpose.py", "onnx/backend/test/case/node/trilu.py", "onnx/backend/test/case/node/unique.py", "onnx/backend/test/case/node/unsqueeze.py"]}], "parents": [{"commit_id_before": "eb634addcbb23ec1baf4d548d826bf3932527533", "url_before": "https://api.github.com/repos/onnx/onnx/commits/eb634addcbb23ec1baf4d548d826bf3932527533", "html_url_before": "https://github.com/onnx/onnx/commit/eb634addcbb23ec1baf4d548d826bf3932527533"}], "details": [{"raw_url": "https://github.com/onnx/onnx/raw/f369b0e859024095d721f1d1612da5a8fa38988d/onnx%2Fchecker.cc", "code": "/*\n * SPDX-License-Identifier: Apache-2.0\n */\n\n#include \"onnx/checker.h\"\n#include \"onnx/common/file_utils.h\"\n#include \"onnx/common/path.h\"\n#include \"onnx/defs/schema.h\"\n#include \"onnx/defs/tensor_proto_util.h\"\n#include \"onnx/proto_utils.h\"\n#include \"onnx/shape_inference/implementation.h\"\n#include \"onnx/string_utils.h\"\n\n#include <fstream>\n#include <iterator>\n#include <unordered_set>\n\n#ifdef _WIN32\n#include <direct.h>\n#else // POSIX\n#include <sys/stat.h>\n#endif\n\nnamespace ONNX_NAMESPACE {\nnamespace checker {\n\n#define enforce_has_field(proto, field)                                              \\\n  do {                                                                               \\\n    if (!proto.has_##field()) {                                                      \\\n      fail_check(\"Field '\", #field, \"' of '\", #proto, \"' is required but missing.\"); \\\n    }                                                                                \\\n  } while (0)\n\n#define enforce_has_repeated_field(proto, field)                                              \\\n  do {                                                                                        \\\n    if (!proto.field##_size()) {                                                              \\\n      fail_check(\"Repeated Field '\", #field, \"' of '\", #proto, \"' is required but missing.\"); \\\n    }                                                                                         \\\n  } while (0)\n\n#define enforce_non_empty_field(proto, field)                                            \\\n  do {                                                                                   \\\n    if (proto.field().empty()) {                                                         \\\n      fail_check(\"Field '\", #field, \"' of '\", #proto, \"' is required to be non-empty.\"); \\\n    }                                                                                    \\\n  } while (0)\n\nvoid check_value_info(const ValueInfoProto& value_info, const CheckerContext& ctx) {\n  enforce_non_empty_field(value_info, name);\n  // Relax constraint for subgraph input/output.\n  if (!ctx.is_main_graph())\n    return;\n  enforce_has_field(value_info, type);\n  const auto value_case = value_info.type().value_case();\n  switch (value_case) {\n    case TypeProto::kTensorType: {\n      const auto& type = value_info.type().tensor_type();\n      enforce_has_field(type, elem_type);\n      enforce_has_field(type, shape);\n    } break;\n    case TypeProto::kOptionalType: {\n      const auto& type = value_info.type().optional_type();\n      enforce_has_field(type, elem_type);\n    } break;\n    case TypeProto::kSequenceType: {\n      const auto& type = value_info.type().sequence_type();\n      enforce_has_field(type, elem_type);\n    } break;\n    case TypeProto::kMapType: {\n      const auto& type = value_info.type().map_type();\n      enforce_has_field(type, key_type);\n      enforce_has_field(type, value_type);\n    } break;\n#ifdef ONNX_ML\n    case TypeProto::kOpaqueType:\n      break;\n#endif\n    case TypeProto::kSparseTensorType: {\n      const auto& type = value_info.type().sparse_tensor_type();\n      enforce_has_field(type, elem_type);\n      enforce_has_field(type, shape);\n    } break;\n\n    default:\n      fail_check(\"Unrecognized type value case (value_info name: \", value_info.name(), \"): \", value_case);\n  }\n}\n\nvoid check_tensor(const TensorProto& tensor, const CheckerContext& ctx) {\n  enforce_has_field(tensor, data_type);\n  if (tensor.data_type() == TensorProto::UNDEFINED) {\n    fail_check(\"setting data_type field (tensor name: \", tensor.name(), \") to UNDEFINED is not allowed\");\n  }\n\n  int num_value_fields = 0;\n\n  const char* value_field = nullptr;\n\n#define check_data_field(field)             \\\n  bool has_##field = tensor.field().size(); \\\n  if (has_##field) {                        \\\n    ++num_value_fields;                     \\\n    value_field = #field;                   \\\n  }\n\n  check_data_field(float_data);\n  check_data_field(int32_data);\n  check_data_field(string_data);\n  check_data_field(int64_data);\n  check_data_field(raw_data);\n  check_data_field(double_data);\n  check_data_field(uint64_data);\n\n#undef check_data_field\n\n  bool stored_externally = tensor.has_data_location() && tensor.data_location() == TensorProto::EXTERNAL;\n  if (stored_externally) {\n    if (num_value_fields != 0) {\n      fail_check(\n          \"Data of TensorProto ( tensor name: \",\n          tensor.name(),\n          \") is stored externally and should not have data field.\",\n          value_field);\n    }\n\n    bool has_location = false;\n    for (const StringStringEntryProto& entry : tensor.external_data()) {\n      if (entry.has_key() && entry.has_value() && entry.key() == \"location\") {\n        has_location = true;\n        std::string relative_path = clean_relative_path(entry.value());\n        // Check that normalized relative path starts with \"../\" or \"..\\\" on windows.\n        if (relative_path.rfind(\"..\" + k_preferred_path_separator, 0) == 0) {\n          fail_check(\n              \"Data of TensorProto ( tensor name: \",\n              tensor.name(),\n              \") should be file inside the \",\n              ctx.get_model_dir(),\n              \", but the '\",\n              entry.value(),\n              \"' points outside the directory\");\n        }\n\n        std::string data_path = path_join(ctx.get_model_dir(), relative_path);\n        // use stat to check whether the file exists\n        struct stat buffer;\n        if (stat((data_path).c_str(), &buffer) != 0) {\n          fail_check(\n              \"Data of TensorProto ( tensor name: \",\n              tensor.name(),\n              \") should be stored in \",\n              data_path,\n              \", but it doesn't exist or is not accessible.\");\n        }\n#ifdef _WIN32\n#else // POSIX\n      //  Do not allow symlinks or directories.\n        if (!S_ISREG(buffer.st_mode)) {\n          fail_check(\n              \"Data of TensorProto ( tensor name: \",\n              tensor.name(),\n              \") should be stored in \",\n              data_path,\n              \", but it is not regular file.\");\n        }\n#endif\n      }\n    }\n    if (!has_location) {\n      fail_check(\"TensorProto ( tensor name: \", tensor.name(), \") is stored externally but doesn't have a location.\");\n    }\n    return;\n  }\n  int64_t nelem = 1;\n  for (auto x : tensor.dims()) {\n    nelem *= x;\n  }\n  if (nelem == 0 && num_value_fields != 0) {\n    fail_check(\"TensorProto (tensor name: \", tensor.name(), \") is 0-element but contains data!\");\n  }\n  if (nelem != 0 && num_value_fields != 1) {\n    fail_check(\"TensorProto (tensor name: \", tensor.name(), \") should contain one and only one value field.\");\n  }\n  if (has_raw_data) {\n    if (tensor.data_type() == TensorProto::STRING) {\n      fail_check(\"STRING data (tensor name: \", tensor.name(), \") should not be stored in raw_data field\");\n    }\n    return;\n  } else {\n#define check_field(field)               \\\n  if (nelem != 0 && !has_##field) {      \\\n    fail_check(                          \\\n        \"values of data_type '\",         \\\n        tensor.data_type(),              \\\n        \"' should be stored in field '\", \\\n        #field,                          \\\n        \"' instead of '\",                \\\n        value_field,                     \\\n        \"'\");                            \\\n  }\n\n    switch (tensor.data_type()) {\n      case TensorProto::FLOAT:\n      case TensorProto::COMPLEX64:\n        check_field(float_data);\n        break;\n\n      case TensorProto::DOUBLE:\n      case TensorProto::COMPLEX128:\n        check_field(double_data);\n        break;\n\n      case TensorProto::INT32:\n      case TensorProto::UINT8:\n      case TensorProto::INT8:\n      case TensorProto::UINT16:\n      case TensorProto::INT16:\n      case TensorProto::BOOL:\n      case TensorProto::FLOAT16:\n      case TensorProto::BFLOAT16:\n        check_field(int32_data);\n        break;\n\n      case TensorProto::INT64:\n        check_field(int64_data);\n        break;\n\n      case TensorProto::UINT32:\n      case TensorProto::UINT64:\n        check_field(uint64_data);\n        break;\n\n      case TensorProto::STRING:\n        check_field(string_data);\n        break;\n\n      default:\n        fail_check(\"Unrecognized data_type (tensor name: \", tensor.name(), \"): \", tensor.data_type());\n    }\n  }\n\n#undef check_field\n}\n\nvoid check_sequence(const SequenceProto& sequence, const CheckerContext& ctx) {\n  enforce_has_field(sequence, elem_type);\n  if (sequence.elem_type() == SequenceProto::TENSOR) {\n    for (const TensorProto& tensor : sequence.tensor_values()) {\n      check_tensor(tensor, ctx);\n    }\n  } else if (sequence.elem_type() == SequenceProto::SPARSE_TENSOR) {\n    for (const SparseTensorProto& sparse_tensor : sequence.sparse_tensor_values()) {\n      check_sparse_tensor(sparse_tensor, ctx);\n    }\n  } else if (sequence.elem_type() == SequenceProto::SEQUENCE) {\n    for (const SequenceProto& seq : sequence.sequence_values()) {\n      check_sequence(seq, ctx);\n    }\n  } else if (sequence.elem_type() == SequenceProto::MAP) {\n    for (const MapProto& map : sequence.map_values()) {\n      check_map(map, ctx);\n    }\n  } else {\n    fail_check(\n        \"Sequence ( Structure name: \",\n        sequence.name(),\n        \", elem_type: \",\n        sequence.elem_type(),\n        \") is not have a valid element type.\");\n  }\n}\n\nvoid check_optional(const OptionalProto& optional, const CheckerContext& ctx) {\n  enforce_has_field(optional, elem_type);\n  if (optional.elem_type() == OptionalProto::UNDEFINED) {\n    return;\n  } else if (optional.elem_type() == OptionalProto::TENSOR) {\n    if (optional.has_tensor_value())\n      check_tensor(optional.tensor_value(), ctx);\n  } else if (optional.elem_type() == OptionalProto::SPARSE_TENSOR) {\n    if (optional.has_sparse_tensor_value())\n      check_sparse_tensor(optional.sparse_tensor_value(), ctx);\n  } else if (optional.elem_type() == OptionalProto::SEQUENCE) {\n    if (optional.has_sequence_value())\n      check_sequence(optional.sequence_value(), ctx);\n  } else if (optional.elem_type() == OptionalProto::MAP) {\n    if (optional.has_map_value())\n      check_map(optional.map_value(), ctx);\n  } else {\n    fail_check(\n        \"Optional ( Structure name: \",\n        optional.name(),\n        \", elem_type: \",\n        optional.elem_type(),\n        \") is not have a valid element type.\");\n  }\n}\n\nvoid check_map(const MapProto& map, const CheckerContext& ctx) {\n  enforce_has_field(map, key_type);\n  if (map.key_type() == TensorProto::UNDEFINED) {\n    fail_check(\"setting key_type field (map name: \", map.name(), \") to UNDEFINED is not allowed\");\n  }\n  // Check if key is a valid type, specifically INT8, INT16, INT32, INT64,\n  // UINT8, UINT16, UINT32, UINT64, or STRING.\n  if ((map.key_type() == TensorProto::FLOAT) || (map.key_type() == TensorProto::BOOL) ||\n      (map.key_type() == TensorProto::FLOAT16) || (map.key_type() == TensorProto::COMPLEX64) ||\n      (map.key_type() == TensorProto::COMPLEX128)) {\n    fail_check(\n        \"setting key_type field (map name: \",\n        map.name(),\n        \") to invalid TensorProto key_type \",\n        map.key_type(),\n        \" is not allowed\");\n  }\n\n  // MapProto will use either keys or string_keys, so only one should be > 0.\n  if ((map.keys_size() > 0) && (map.string_keys_size() > 0)) {\n    fail_check(\"Map (name: \", map.name(), \") should not contain more than one keys field.\");\n  }\n\n  int num_keys = map.keys_size() + map.string_keys_size();\n  int num_values = 0;\n\n  enforce_has_field(map, values);\n  check_sequence(map.values(), ctx);\n\n  if (map.values().elem_type() == SequenceProto::TENSOR) {\n    num_values = map.values().tensor_values_size();\n  } else if (map.values().elem_type() == SequenceProto::SPARSE_TENSOR) {\n    num_values = map.values().sparse_tensor_values_size();\n  } else if (map.values().elem_type() == SequenceProto::SEQUENCE) {\n    num_values = map.values().sequence_values_size();\n  } else if (map.values().elem_type() == SequenceProto::MAP) {\n    num_values = map.values().map_values_size();\n  }\n\n  if (num_keys != num_values) {\n    fail_check(\"Length of map keys and map values are not the same (map name: \", map.name(), \")\");\n  }\n}\n\n// Check that the index data stored in a SparseTensorProto is valid.\n// indices: a 1-dimensional tensor; indices[i] represents the\n// linearized index value for the i-th nonzero value.\nvoid check_sparse_tensor_indices_1(\n    const TensorProto& indices,\n    const SparseTensorProto& sparse_tensor_proto,\n    size_t nnz) {\n  int dense_rank = sparse_tensor_proto.dims_size();\n  int64_t dense_size = 1;\n  for (int i = 0; i < dense_rank; ++i)\n    dense_size *= sparse_tensor_proto.dims(i);\n  if (static_cast<size_t>(indices.dims(0)) != nnz) {\n    fail_check(\"Sparse tensor indices (\", indices.name(), \") has \", indices.dims(0), \" values, but NNZ is \", nnz);\n  }\n\n  // Check if indices appear in ascending order, and if they have valid\n  // values. The i-th value in index_data is the linear index of the i-th\n  // non-zero value.\n  const std::vector<int64_t> index_data = ParseData<int64_t>(&indices);\n\n  int64_t prev_index = -1;\n  for (size_t i = 0; i < nnz; ++i) {\n    int64_t curr_index = index_data[i]; // linearized index of i-th value\n    if (curr_index < 0 || curr_index >= dense_size) {\n      fail_check(\n          \"Sparse tensor (\",\n          indices.name(),\n          \") index value at position [\",\n          i,\n          \"] out of range [0, \",\n          dense_size - 1,\n          \"]\");\n    }\n    if (curr_index <= prev_index) {\n      fail_check(\"Sparse tensor (\", indices.name(), \") index value at position [\", i, \"] not in sorted order.\");\n    }\n    prev_index = curr_index;\n  }\n}\n\n// Check that the index data stored in a SparseTensorProto is valid.\n// indices: a 2-dimensional tensor; indices[i,j] represents the j-th\n// index value for the i-th nonzero value.\nvoid check_sparse_tensor_indices_2(\n    const TensorProto& indices,\n    const SparseTensorProto& sparse_tensor_proto,\n    size_t nnz) {\n  int dense_rank = sparse_tensor_proto.dims_size();\n  if (static_cast<size_t>(indices.dims(0)) != nnz) {\n    fail_check(\"Sparse tensor indices (\", indices.name(), \") first dimension size does not equal NNZ.\");\n  }\n  if (indices.dims(1) != dense_rank) {\n    fail_check(\"Sparse tensor indices (\", indices.name(), \") second dimension size does not match rank of tensor.\");\n  }\n\n  // Check if indices appear in ascending order, and if they have valid\n  // values.\n  const std::vector<int64_t> index_data = ParseData<int64_t>(&indices);\n  int64_t prev_index = -1;\n  for (size_t i = 0; i < nnz; ++i) {\n    int64_t curr_index = 0; // linearized index of i-th value\n    for (int j = 0; j < dense_rank; ++j) {\n      auto index_ij = index_data[i * dense_rank + j];\n      if ((index_ij < 0) || (index_ij >= sparse_tensor_proto.dims(j))) {\n        fail_check(\"Sparse tensor (\", indices.name(), \") index value at position [\", i, \",\", j, \"] out of range.\");\n      }\n      curr_index = curr_index * sparse_tensor_proto.dims(j) + index_ij;\n    }\n    if (curr_index <= prev_index) {\n      fail_check(\n          \"Sparse tensor (\", indices.name(), \") index value at position [\", i, \"] not in lexicographic sorted order.\");\n    }\n    prev_index = curr_index;\n  }\n}\n\nvoid check_sparse_tensor(const SparseTensorProto& sparse_tensor_proto, const CheckerContext& ctx) {\n  enforce_has_field(sparse_tensor_proto, values);\n\n  const TensorProto& values = sparse_tensor_proto.values();\n  check_tensor(values, ctx);\n\n  // values must be a tensor of shape [NNZ]\n  // Currently we restrict the value associated with a particular index-tuple\n  // to be a single value. In the future, if there is a requirement,\n  // we may extend this to permit the value to be a \"sub-tensor\", in which\n  // case values will have dimension > 1.\n  if (values.dims_size() != 1) {\n    fail_check(\"Sparse tensor values (\", values.name(), \") must have rank 1.\");\n  }\n  size_t nnz = static_cast<size_t>(values.dims(0));\n  int dense_rank = sparse_tensor_proto.dims_size();\n  if (dense_rank == 0) {\n    fail_check(\"Sparse tensor (\", values.name(), \") must have a dense-rank > 0\");\n  }\n  for (int i = 0; i < dense_rank; ++i) {\n    if (sparse_tensor_proto.dims(i) <= 0) {\n      fail_check(\"Sparse tensor (\", values.name(), \") dimensions are not positive.\");\n    }\n  }\n\n  if (sparse_tensor_proto.has_indices()) {\n    const TensorProto& indices = sparse_tensor_proto.indices();\n    check_tensor(indices, ctx);\n    if (indices.data_type() != TensorProto::INT64) {\n      fail_check(\"Sparse tensor indices (\", indices.name(), \") must have INT64 type.\");\n    }\n    switch (indices.dims().size()) {\n      case 1:\n        // Indices in linearized format\n        check_sparse_tensor_indices_1(indices, sparse_tensor_proto, nnz);\n        return;\n      case 2:\n        // Check COO-style index. E.g., an index for a 3D tensor is a 3-tuple.\n        check_sparse_tensor_indices_2(indices, sparse_tensor_proto, nnz);\n        return;\n      default:\n        fail_check(\"Sparse tensor indices (\", indices.name(), \") must have rank 1 or 2.\");\n    }\n  } else if (nnz != 0) {\n    fail_check(\"Sparse tensor (\", values.name(), \") has no index values.\");\n  }\n}\n\n// NB: This is a generic \"attribute well-formedness\" check, it doesn't\n// actually test if an attribute is valid per a schema\nvoid check_attribute(const AttributeProto& attr, const CheckerContext& ctx, const LexicalScopeContext& lex_ctx) {\n  enforce_non_empty_field(attr, name);\n\n  if (ctx.get_ir_version() >= 0x00000002) {\n    enforce_has_field(attr, type);\n  }\n\n  int used_fields = 0;\n\n#define check_type(expected_type)                                                     \\\n  if (attr.has_type() && attr.type() != expected_type) {                              \\\n    fail_check(\"type field and data field mismatch in attribute \", attr.name(), \".\"); \\\n  }\n\n#define check_singular_field(field, type) \\\n  if (attr.has_##field()) {               \\\n    ++used_fields;                        \\\n    check_type(type);                     \\\n  }\n\n#define check_repeated_field(field, type) \\\n  if (attr.field##_size() > 0) {          \\\n    ++used_fields;                        \\\n    check_type(type);                     \\\n  }\n\n  check_singular_field(f, AttributeProto::FLOAT);\n  check_singular_field(i, AttributeProto::INT);\n  check_singular_field(s, AttributeProto::STRING);\n  check_singular_field(t, AttributeProto::TENSOR);\n  check_singular_field(g, AttributeProto::GRAPH);\n  check_singular_field(tp, AttributeProto::TYPE_PROTO);\n  check_singular_field(sparse_tensor, AttributeProto::SPARSE_TENSOR);\n  check_repeated_field(floats, AttributeProto::FLOATS);\n  check_repeated_field(ints, AttributeProto::INTS);\n  check_repeated_field(strings, AttributeProto::STRINGS);\n  check_repeated_field(tensors, AttributeProto::TENSORS);\n  check_repeated_field(graphs, AttributeProto::GRAPHS);\n  check_repeated_field(sparse_tensors, AttributeProto::SPARSE_TENSORS);\n  check_repeated_field(type_protos, AttributeProto::TYPE_PROTOS);\n\n#undef check_type\n#undef check_singular_field\n#undef check_repeated_field\n\n  // Normally, used_fields is expected to be 1.\n  // In proto3, when the value to be set is type default value (say 0 for\n  // int), used_fields may be 0.\n  if (used_fields > 1) {\n    fail_check(\"Attribute (name: \", attr.name(), \") should not contain more than one value field.\");\n  }\n\n  if (!ctx.is_main_graph()) {\n    // It's an attribute of a node in function body.\n    if (attr.has_ref_attr_name() && used_fields != 0) {\n      // The attribute proto is supposed to refer to data outside and does not\n      // have its own value field set.\n      fail_check(\"Attribute (name: \", attr.name(), \") should refer to attribute in parent node.\");\n    }\n  }\n\n  if (attr.has_t()) {\n    check_tensor(attr.t(), ctx);\n  }\n\n  if (attr.has_sparse_tensor()) {\n    check_sparse_tensor(attr.sparse_tensor(), ctx);\n  }\n\n  if (attr.has_g()) {\n    CheckerContext subgraph_ctx(ctx);\n    subgraph_ctx.set_is_main_graph(false);\n    check_graph(attr.g(), subgraph_ctx, lex_ctx);\n  }\n\n  for (const auto& tensor : attr.tensors()) {\n    check_tensor(tensor, ctx);\n  }\n  for (const auto& sparse_tensor : attr.sparse_tensors()) {\n    check_sparse_tensor(sparse_tensor, ctx);\n  }\n  if (attr.graphs().size() > 0) {\n    CheckerContext subgraph_ctx(ctx);\n    subgraph_ctx.set_is_main_graph(false);\n    for (const auto& graph : attr.graphs()) {\n      check_graph(graph, subgraph_ctx, lex_ctx);\n    }\n  }\n}\n\nvoid check_node(const NodeProto& node, const CheckerContext& ctx, const LexicalScopeContext& lex_ctx) {\n  enforce_non_empty_field(node, op_type);\n\n  if (node.input().empty() && node.output().empty()) {\n    fail_check(\"NodeProto (name: \", node.name(), \", type: \", node.op_type(), \") has zero input and zero output.\");\n  }\n\n  // If encounter experimental op, stop checking\n  if (check_is_experimental_op(node.op_type())) {\n    std::cerr << \"Warning: Checker does not support models with experimental ops: \" << node.op_type() << std::endl;\n    return;\n  }\n\n  // Resolve domain for node\n  const auto& opset_imports = ctx.get_opset_imports();\n  auto dit = opset_imports.find(node.domain());\n  if (dit == opset_imports.end()) {\n    fail_check(\"No opset import for domain '\" + node.domain() + \"'\");\n  }\n  auto domain_version = dit->second;\n\n  for (const auto& attr : node.attribute()) {\n    check_attribute(attr, ctx, lex_ctx);\n  }\n\n  const auto* schema = ctx.get_schema_registry()->GetSchema(node.op_type(), domain_version, node.domain());\n  if (!schema) {\n    if (node.domain() == ONNX_DOMAIN || node.domain() == AI_ONNX_ML_DOMAIN || node.domain() == \"ai.onnx\" ||\n        node.domain() == AI_ONNX_TRAINING_DOMAIN) {\n      // fail the checker if op in built-in domains has no schema\n      fail_check(\n          \"No Op registered for \" + node.op_type() + \" with domain_version of \" +\n          ONNX_NAMESPACE::to_string(domain_version));\n    } else {\n      // TODO: expose the registration of the op schemas appropriately in\n      // python, so we can load and register operators in other domains\n      //\n      // before we complete the above todo, let's skip the schema check for\n      // now\n    }\n  } else if (schema->Deprecated()) {\n    fail_check(\n        \"Op registered for \" + node.op_type() + \" is deprecated in domain_version of \" +\n        ONNX_NAMESPACE::to_string(domain_version));\n  } else {\n    schema->Verify(node);\n  }\n}\n\nvoid check_graph(const GraphProto& graph, const CheckerContext& ctx, const LexicalScopeContext& parent_lex) {\n  enforce_non_empty_field(graph, name);\n\n  for (const auto& value_info : graph.input()) {\n    check_value_info(value_info, ctx);\n  }\n  for (const auto& value_info : graph.output()) {\n    check_value_info(value_info, ctx);\n  }\n\n  // Inherit values available in outer scope\n  // Note that we do not allow shadowing, so the presence of an already-defined\n  // name is always an error.\n  LexicalScopeContext lex_ctx{parent_lex};\n\n  for (const auto& value_info : graph.input()) {\n    // TODO: If shadowing isn't allowed, this should maybe use\n    // this_or_ancestor_graph_has\n    if (lex_ctx.this_graph_has(value_info.name())) {\n      fail_check(\n          \"Graph must be in single static assignment (SSA) form, however '\",\n          value_info.name(),\n          \"' has been used as graph input names multiple times.\");\n    }\n    lex_ctx.add(value_info.name());\n  }\n\n  std::unordered_set<std::reference_wrapper<const std::string>, std::hash<std::string>, std::equal_to<std::string>>\n      initializer_name_checker;\n\n  for (const auto& init : graph.initializer()) {\n    enforce_has_field(init, name);\n    const auto& name = init.name();\n    if (name.empty()) {\n      fail_check(\"Tensor initializers must have a non-empty name\");\n    }\n\n    if (!initializer_name_checker.insert(std::cref(name)).second) {\n      fail_check(name + \" initializer name is not unique\");\n    }\n\n    check_tensor(init, ctx);\n\n    if (ctx.get_ir_version() <= 0x00000003) {\n      // Initializers are a subset of graph inputs for IR_VERSION <= 3\n      if (!lex_ctx.this_graph_has(name)) {\n        fail_check(name + \" in initializer but not in graph input\");\n      }\n    } else {\n      // An initializer is allowed to have the same name as an input,\n      // but is not required to (for IR_VERSION >= 4)\n      lex_ctx.add(name);\n    }\n  }\n\n  for (const auto& sparse_init : graph.sparse_initializer()) {\n    const auto& values = sparse_init.values();\n    enforce_has_field(values, name);\n    const auto& name = values.name();\n    if (name.empty()) {\n      fail_check(\"Sparse tensor initializers must have a non-empty name\");\n    }\n    if (!initializer_name_checker.insert(std::cref(name)).second) {\n      fail_check(name + \" sparse initializer name is not unique across initializers and sparse_initializers\");\n    }\n    check_sparse_tensor(sparse_init, ctx);\n    lex_ctx.add(name);\n  }\n\n  for (const auto& node : graph.node()) {\n    // nodes must be in topologically sorted order\n    for (const auto& input : node.input()) {\n      // explicit optional input\n      if (input.empty()) {\n        continue;\n      }\n      if (!lex_ctx.this_or_ancestor_graph_has(input)) {\n        fail_check(\n            \"Nodes in a graph must be topologically sorted, however input '\",\n            input,\n            \"' of node: \\n\",\n            \"name: \",\n            node.name(),\n            \" OpType: \",\n            node.op_type(),\n            \"\\n is not output of any previous nodes.\");\n      }\n    }\n\n    // This needs to happen before SSA check since we don't want to recurse and\n    // find that outputs from control flow ops are colliding with names in the\n    // inner block\n\n    ONNX_TRY {\n      check_node(node, ctx, lex_ctx);\n    }\n    ONNX_CATCH(ValidationError & ex) {\n      ONNX_HANDLE_EXCEPTION([&]() {\n        ex.AppendContext(\"Bad node spec for node. Name: \" + node.name() + \" OpType: \" + node.op_type());\n        ONNX_THROW_EX(ex);\n      });\n    }\n    // check for SSA form\n    for (const auto& output : node.output()) {\n      // optional output\n      if (output.empty()) {\n        continue;\n      }\n\n      if (lex_ctx.this_or_ancestor_graph_has(output)) {\n        fail_check(\n            \"Graph must be in single static assignment (SSA) form, however '\",\n            output,\n            \"' has been used as output names multiple times.\");\n      }\n      lex_ctx.add(output);\n    }\n  }\n}\n\n// Utilify function to get the imported version of domain from opset imports\n// Returns -1 if requested domain is not found in the opset_imports\nint get_version_for_domain(const std::string& domain, const std::unordered_map<std::string, int>& opset_imports) {\n  auto it = opset_imports.find(domain);\n  if (it == opset_imports.end()) {\n    return -1;\n  }\n\n  return it->second;\n}\n\nvoid check_opset_compatibility(\n    const NodeProto& node,\n    const CheckerContext& ctx,\n    const std::unordered_map<std::string, int>& func_opset_imports,\n    const std::unordered_map<std::string, int>& model_opset_imports) {\n  auto func_opset_version = get_version_for_domain(node.domain(), func_opset_imports);\n  auto model_opset_version = get_version_for_domain(node.domain(), model_opset_imports);\n\n  if (func_opset_version == -1) {\n    fail_check(\"No Opset registered for domain \" + node.domain());\n  }\n\n  if (model_opset_version == -1) {\n    // model does not include opset import for a node present in function body.\n    // This is ok as along as the opset import is present in function level opset imports.\n    return;\n  }\n\n  if (func_opset_version == model_opset_version) {\n    // both versions are same, no need to verify schema.\n    return;\n  }\n\n  const auto* schema_for_model_import =\n      ctx.get_schema_registry()->GetSchema(node.op_type(), model_opset_version, node.domain());\n\n  const auto* schema_for_function_import =\n      ctx.get_schema_registry()->GetSchema(node.op_type(), func_opset_version, node.domain());\n\n  if (!schema_for_model_import && !schema_for_function_import) {\n    // the op belongs to a custom domain so we cannot verify schema\n    return;\n  }\n\n  // if schema is present for 1 but not other or the schema since versions do not match then raise an error\n  if (!schema_for_model_import || !schema_for_function_import ||\n      schema_for_function_import->since_version() != schema_for_model_import->since_version()) {\n    fail_check(\n        \"Opset import for domain \" + node.domain() + \" in function op \" + node.op_type() +\n        \"is not compatible with the version imported by model. FunctionOp imports version \" +\n        ONNX_NAMESPACE::to_string(func_opset_version) + \"whereas model imports version \" +\n        ONNX_NAMESPACE::to_string(model_opset_version));\n  }\n}\n\nvoid check_model_local_functions(\n    const ModelProto& model,\n    const CheckerContext& ctx,\n    const LexicalScopeContext& parent_lex) {\n  // make a copy of model opset imports to maintain a main copy of opset imports across the model and\n  // all model local functions to verify opset compatibility\n  std::unordered_map<std::string, int> model_opset_imports(ctx.get_opset_imports());\n\n  // merge the opset imports from every function in model_opset_imports\n  // only add the opset import if an entry for it does not exist in model_opset_imports\n  // if there is an entry then the compatibility will be checked later on in check_opset_compatibility\n  // called by check_function.\n  for (const auto& function_proto : model.functions()) {\n    for (const auto& opset_import : function_proto.opset_import()) {\n      if (get_version_for_domain(opset_import.domain(), model_opset_imports) == -1) {\n        model_opset_imports[opset_import.domain()] = opset_import.version();\n      }\n    }\n  }\n\n  CheckerContext ctx_copy = ctx;\n  ctx_copy.set_opset_imports(model_opset_imports);\n\n  for (const auto& function_proto : model.functions()) {\n    check_function(function_proto, ctx_copy, parent_lex);\n  }\n}\n\nvoid check_function(const FunctionProto& function, const CheckerContext& ctx, const LexicalScopeContext& parent_lex) {\n  enforce_non_empty_field(function, name);\n\n  if (ctx.get_ir_version() >= 0x00000008) {\n    enforce_has_field(function, domain);\n  }\n\n  const auto& model_opset_imports = ctx.get_opset_imports();\n  CheckerContext ctx_copy = ctx;\n\n  std::unordered_map<std::string, int> func_opset_imports;\n  for (auto& relied_opset : function.opset_import()) {\n    func_opset_imports[relied_opset.domain()] = static_cast<int>(relied_opset.version());\n  }\n\n  ctx_copy.set_opset_imports(func_opset_imports);\n\n  LexicalScopeContext lex_ctx{parent_lex};\n\n  for (const auto& input : function.input()) {\n    // TODO: If shadowing isn't allowed, this should maybe use\n    // this_or_ancestor_graph_has\n    if (lex_ctx.this_graph_has(input)) {\n      fail_check(\n          \"Graph must be in single static assignment (SSA) form, however '\", input, \"' has been used multiple times.\");\n    }\n    lex_ctx.add(input);\n  }\n\n  std::unordered_set<std::string> outputs;\n  for (const auto& output : function.output()) {\n    auto result = outputs.insert(output);\n    if (!result.second) {\n      fail_check(\"function (\", function.name(), \") should not have duplicate outputs specified.\");\n    }\n  }\n\n  std::unordered_set<std::string> attrs;\n  for (const auto& attr : function.attribute()) {\n    auto result = attrs.insert(attr);\n    if (!result.second) {\n      fail_check(\"function (\", function.name(), \") should not have duplicate attributes specified.\");\n    }\n  }\n\n  for (const auto& node : function.node()) {\n    // nodes must be in topologically sorted order\n    for (const auto& input : node.input()) {\n      // explicit optional input\n      if (input.empty()) {\n        continue;\n      }\n      if (!lex_ctx.this_graph_has(input)) {\n        fail_check(\n            \"Nodes in a function must be topologically sorted, however input '\",\n            input,\n            \"' of node: \\n\",\n            \"Name: \",\n            node.name(),\n            \" OpType: \",\n            node.op_type(),\n            \"\\n is neither output of any previous nodes nor input of the function.\");\n      }\n    }\n\n    // check whether the opset version imported for a domain by function and model are\n    // compatible\n    check_opset_compatibility(node, ctx_copy, func_opset_imports, model_opset_imports);\n\n    check_node(node, ctx_copy, lex_ctx);\n\n    // check for SSA form\n    for (const auto& output : node.output()) {\n      // optional output\n      if (output.empty()) {\n        continue;\n      }\n      if (lex_ctx.this_or_ancestor_graph_has(output)) {\n        fail_check(\n            \"Function must be in single static assignment (SSA) form, however '\",\n            output,\n            \"' has been used as output names multiple times.\");\n      }\n      lex_ctx.add(output);\n    }\n  }\n}\n\nvoid check_model(const ModelProto& model, CheckerContext& ctx) {\n  if (!model.ir_version()) {\n    fail_check(\"The model does not have an ir_version set properly.\");\n  }\n  if (model.ir_version() > IR_VERSION) {\n    fail_check(\"Your model ir_version is higher than the checker's.\");\n  }\n  if (model.metadata_props_size() > 1) {\n    std::unordered_set<std::string> keys;\n    for (const StringStringEntryProto& entry : model.metadata_props()) {\n      auto i = keys.insert(entry.key());\n      if (!i.second) {\n        fail_check(\"Your model has duplicate keys in metadata_props.\");\n      }\n    }\n  }\n  std::unordered_map<std::string, int> versions;\n  ctx.set_ir_version(static_cast<int>(model.ir_version()));\n  std::unordered_map<std::string, int> opset_imports;\n  for (const auto& opset_import : model.opset_import()) {\n    opset_imports[opset_import.domain()] = static_cast<int>(opset_import.version());\n  }\n  if (model.ir_version() >= 3) {\n    if (opset_imports.empty()) {\n      fail_check(\"model with IR version >= 3 must specify opset_import for ONNX\");\n    }\n  } else {\n    if (opset_imports.empty())\n      opset_imports[ONNX_DOMAIN] = 1;\n    else {\n      fail_check(\"model with IR version < 3 cannot have opset_import specified\");\n    }\n  }\n  ctx.set_opset_imports(opset_imports);\n  LexicalScopeContext lex_ctx;\n  check_graph(model.graph(), ctx, lex_ctx);\n\n  if (ctx.get_ir_version() >= 0x00000008) {\n    check_model_local_functions(model, ctx, lex_ctx);\n  }\n}\n\nvoid check_model(const std::string& model_path, bool full_check) {\n  ModelProto model;\n  LoadProtoFromPath(model_path, model);\n\n  CheckerContext ctx;\n  std::string model_dir;\n  size_t pos = model_path.find_last_of(\"\\\\/\");\n  if (pos != std::string::npos) {\n    model_dir = model_path.substr(0, pos + 1);\n  }\n  ctx.set_model_dir(model_dir);\n  check_model(model, ctx);\n\n  if (full_check) {\n    ShapeInferenceOptions options{true, 1, false};\n    ONNX_NAMESPACE::shape_inference::InferShapes(model, ctx.get_schema_registry(), options);\n  }\n}\n\nvoid check_model(const ModelProto& model) {\n  CheckerContext ctx;\n  check_model(model, ctx);\n}\n\nvoid check_model(ModelProto& model, bool full_check) {\n  CheckerContext ctx;\n  check_model(model, ctx);\n\n  if (full_check) {\n    ShapeInferenceOptions options{true, 1, false};\n    ONNX_NAMESPACE::shape_inference::InferShapes(model, ctx.get_schema_registry(), options);\n  }\n}\n\nstd::set<std::string> experimental_ops = {\n    \"ATen\",\n    \"Affine\",\n    \"ConstantFill\",\n    \"Crop\",\n    \"DynamicSlice\",\n    \"GRUUnit\",\n    \"GivenTensorFill\",\n    \"ImageScaler\",\n    \"ParametricSoftplus\",\n    \"Scale\",\n    \"ScaledTanh\"};\n\nbool check_is_experimental_op(std::string node_op_type) {\n  return (experimental_ops.count(node_op_type)) ? true : false;\n}\n\n#undef fail_check\n#undef enforce_has_field\n#undef enforce_has_repeated_field\n#undef enforce_non_empty_field\n\n} // namespace checker\n} // namespace ONNX_NAMESPACE\n", "code_before": "/*\n * SPDX-License-Identifier: Apache-2.0\n */\n\n#include \"onnx/checker.h\"\n#include \"onnx/common/file_utils.h\"\n#include \"onnx/common/path.h\"\n#include \"onnx/defs/schema.h\"\n#include \"onnx/defs/tensor_proto_util.h\"\n#include \"onnx/proto_utils.h\"\n#include \"onnx/shape_inference/implementation.h\"\n#include \"onnx/string_utils.h\"\n\n#include <fstream>\n#include <iterator>\n#include <unordered_set>\n\n#ifdef _WIN32\n#include <direct.h>\n#else // POSIX\n#include <sys/stat.h>\n#endif\n\nnamespace ONNX_NAMESPACE {\nnamespace checker {\n\n#define enforce_has_field(proto, field)                                              \\\n  do {                                                                               \\\n    if (!proto.has_##field()) {                                                      \\\n      fail_check(\"Field '\", #field, \"' of '\", #proto, \"' is required but missing.\"); \\\n    }                                                                                \\\n  } while (0)\n\n#define enforce_has_repeated_field(proto, field)                                              \\\n  do {                                                                                        \\\n    if (!proto.field##_size()) {                                                              \\\n      fail_check(\"Repeated Field '\", #field, \"' of '\", #proto, \"' is required but missing.\"); \\\n    }                                                                                         \\\n  } while (0)\n\n#define enforce_non_empty_field(proto, field)                                            \\\n  do {                                                                                   \\\n    if (proto.field().empty()) {                                                         \\\n      fail_check(\"Field '\", #field, \"' of '\", #proto, \"' is required to be non-empty.\"); \\\n    }                                                                                    \\\n  } while (0)\n\nvoid check_value_info(const ValueInfoProto& value_info, const CheckerContext& ctx) {\n  enforce_non_empty_field(value_info, name);\n  // Relax constraint for subgraph input/output.\n  if (!ctx.is_main_graph())\n    return;\n  enforce_has_field(value_info, type);\n  const auto value_case = value_info.type().value_case();\n  switch (value_case) {\n    case TypeProto::kTensorType: {\n      const auto& type = value_info.type().tensor_type();\n      enforce_has_field(type, elem_type);\n      enforce_has_field(type, shape);\n    } break;\n    case TypeProto::kOptionalType: {\n      const auto& type = value_info.type().optional_type();\n      enforce_has_field(type, elem_type);\n    } break;\n    case TypeProto::kSequenceType: {\n      const auto& type = value_info.type().sequence_type();\n      enforce_has_field(type, elem_type);\n    } break;\n    case TypeProto::kMapType: {\n      const auto& type = value_info.type().map_type();\n      enforce_has_field(type, key_type);\n      enforce_has_field(type, value_type);\n    } break;\n#ifdef ONNX_ML\n    case TypeProto::kOpaqueType:\n      break;\n#endif\n    case TypeProto::kSparseTensorType: {\n      const auto& type = value_info.type().sparse_tensor_type();\n      enforce_has_field(type, elem_type);\n      enforce_has_field(type, shape);\n    } break;\n\n    default:\n      fail_check(\"Unrecognized type value case (value_info name: \", value_info.name(), \"): \", value_case);\n  }\n}\n\nvoid check_tensor(const TensorProto& tensor, const CheckerContext& ctx) {\n  enforce_has_field(tensor, data_type);\n  if (tensor.data_type() == TensorProto::UNDEFINED) {\n    fail_check(\"setting data_type field (tensor name: \", tensor.name(), \") to UNDEFINED is not allowed\");\n  }\n\n  int num_value_fields = 0;\n\n  const char* value_field = nullptr;\n\n#define check_data_field(field)             \\\n  bool has_##field = tensor.field().size(); \\\n  if (has_##field) {                        \\\n    ++num_value_fields;                     \\\n    value_field = #field;                   \\\n  }\n\n  check_data_field(float_data);\n  check_data_field(int32_data);\n  check_data_field(string_data);\n  check_data_field(int64_data);\n  check_data_field(raw_data);\n  check_data_field(double_data);\n  check_data_field(uint64_data);\n\n#undef check_data_field\n\n  bool stored_externally = tensor.has_data_location() && tensor.data_location() == TensorProto::EXTERNAL;\n  if (stored_externally) {\n    if (num_value_fields != 0) {\n      fail_check(\n          \"Data of TensorProto ( tensor name: \",\n          tensor.name(),\n          \") is stored externally and should not have data field.\",\n          value_field);\n    }\n\n    bool has_location = false;\n    for (const StringStringEntryProto& entry : tensor.external_data()) {\n      if (entry.has_key() && entry.has_value() && entry.key() == \"location\") {\n        has_location = true;\n        std::string data_path = path_join(ctx.get_model_dir(), entry.value());\n        // use stat to check whether the file exists\n        struct stat buffer;\n        if (stat((data_path).c_str(), &buffer) != 0) {\n          fail_check(\n              \"Data of TensorProto ( tensor name: \",\n              tensor.name(),\n              \") should be stored in \",\n              data_path,\n              \", but it doesn't exist or is not accessible.\");\n        }\n      }\n    }\n    if (!has_location) {\n      fail_check(\"TensorProto ( tensor name: \", tensor.name(), \") is stored externally but doesn't have a location.\");\n    }\n    return;\n  }\n  int64_t nelem = 1;\n  for (auto x : tensor.dims()) {\n    nelem *= x;\n  }\n  if (nelem == 0 && num_value_fields != 0) {\n    fail_check(\"TensorProto (tensor name: \", tensor.name(), \") is 0-element but contains data!\");\n  }\n  if (nelem != 0 && num_value_fields != 1) {\n    fail_check(\"TensorProto (tensor name: \", tensor.name(), \") should contain one and only one value field.\");\n  }\n  if (has_raw_data) {\n    if (tensor.data_type() == TensorProto::STRING) {\n      fail_check(\"STRING data (tensor name: \", tensor.name(), \") should not be stored in raw_data field\");\n    }\n    return;\n  } else {\n#define check_field(field)               \\\n  if (nelem != 0 && !has_##field) {      \\\n    fail_check(                          \\\n        \"values of data_type '\",         \\\n        tensor.data_type(),              \\\n        \"' should be stored in field '\", \\\n        #field,                          \\\n        \"' instead of '\",                \\\n        value_field,                     \\\n        \"'\");                            \\\n  }\n\n    switch (tensor.data_type()) {\n      case TensorProto::FLOAT:\n      case TensorProto::COMPLEX64:\n        check_field(float_data);\n        break;\n\n      case TensorProto::DOUBLE:\n      case TensorProto::COMPLEX128:\n        check_field(double_data);\n        break;\n\n      case TensorProto::INT32:\n      case TensorProto::UINT8:\n      case TensorProto::INT8:\n      case TensorProto::UINT16:\n      case TensorProto::INT16:\n      case TensorProto::BOOL:\n      case TensorProto::FLOAT16:\n      case TensorProto::BFLOAT16:\n        check_field(int32_data);\n        break;\n\n      case TensorProto::INT64:\n        check_field(int64_data);\n        break;\n\n      case TensorProto::UINT32:\n      case TensorProto::UINT64:\n        check_field(uint64_data);\n        break;\n\n      case TensorProto::STRING:\n        check_field(string_data);\n        break;\n\n      default:\n        fail_check(\"Unrecognized data_type (tensor name: \", tensor.name(), \"): \", tensor.data_type());\n    }\n  }\n\n#undef check_field\n}\n\nvoid check_sequence(const SequenceProto& sequence, const CheckerContext& ctx) {\n  enforce_has_field(sequence, elem_type);\n  if (sequence.elem_type() == SequenceProto::TENSOR) {\n    for (const TensorProto& tensor : sequence.tensor_values()) {\n      check_tensor(tensor, ctx);\n    }\n  } else if (sequence.elem_type() == SequenceProto::SPARSE_TENSOR) {\n    for (const SparseTensorProto& sparse_tensor : sequence.sparse_tensor_values()) {\n      check_sparse_tensor(sparse_tensor, ctx);\n    }\n  } else if (sequence.elem_type() == SequenceProto::SEQUENCE) {\n    for (const SequenceProto& seq : sequence.sequence_values()) {\n      check_sequence(seq, ctx);\n    }\n  } else if (sequence.elem_type() == SequenceProto::MAP) {\n    for (const MapProto& map : sequence.map_values()) {\n      check_map(map, ctx);\n    }\n  } else {\n    fail_check(\n        \"Sequence ( Structure name: \",\n        sequence.name(),\n        \", elem_type: \",\n        sequence.elem_type(),\n        \") is not have a valid element type.\");\n  }\n}\n\nvoid check_optional(const OptionalProto& optional, const CheckerContext& ctx) {\n  enforce_has_field(optional, elem_type);\n  if (optional.elem_type() == OptionalProto::UNDEFINED) {\n    return;\n  } else if (optional.elem_type() == OptionalProto::TENSOR) {\n    if (optional.has_tensor_value())\n      check_tensor(optional.tensor_value(), ctx);\n  } else if (optional.elem_type() == OptionalProto::SPARSE_TENSOR) {\n    if (optional.has_sparse_tensor_value())\n      check_sparse_tensor(optional.sparse_tensor_value(), ctx);\n  } else if (optional.elem_type() == OptionalProto::SEQUENCE) {\n    if (optional.has_sequence_value())\n      check_sequence(optional.sequence_value(), ctx);\n  } else if (optional.elem_type() == OptionalProto::MAP) {\n    if (optional.has_map_value())\n      check_map(optional.map_value(), ctx);\n  } else {\n    fail_check(\n        \"Optional ( Structure name: \",\n        optional.name(),\n        \", elem_type: \",\n        optional.elem_type(),\n        \") is not have a valid element type.\");\n  }\n}\n\nvoid check_map(const MapProto& map, const CheckerContext& ctx) {\n  enforce_has_field(map, key_type);\n  if (map.key_type() == TensorProto::UNDEFINED) {\n    fail_check(\"setting key_type field (map name: \", map.name(), \") to UNDEFINED is not allowed\");\n  }\n  // Check if key is a valid type, specifically INT8, INT16, INT32, INT64,\n  // UINT8, UINT16, UINT32, UINT64, or STRING.\n  if ((map.key_type() == TensorProto::FLOAT) || (map.key_type() == TensorProto::BOOL) ||\n      (map.key_type() == TensorProto::FLOAT16) || (map.key_type() == TensorProto::COMPLEX64) ||\n      (map.key_type() == TensorProto::COMPLEX128)) {\n    fail_check(\n        \"setting key_type field (map name: \",\n        map.name(),\n        \") to invalid TensorProto key_type \",\n        map.key_type(),\n        \" is not allowed\");\n  }\n\n  // MapProto will use either keys or string_keys, so only one should be > 0.\n  if ((map.keys_size() > 0) && (map.string_keys_size() > 0)) {\n    fail_check(\"Map (name: \", map.name(), \") should not contain more than one keys field.\");\n  }\n\n  int num_keys = map.keys_size() + map.string_keys_size();\n  int num_values = 0;\n\n  enforce_has_field(map, values);\n  check_sequence(map.values(), ctx);\n\n  if (map.values().elem_type() == SequenceProto::TENSOR) {\n    num_values = map.values().tensor_values_size();\n  } else if (map.values().elem_type() == SequenceProto::SPARSE_TENSOR) {\n    num_values = map.values().sparse_tensor_values_size();\n  } else if (map.values().elem_type() == SequenceProto::SEQUENCE) {\n    num_values = map.values().sequence_values_size();\n  } else if (map.values().elem_type() == SequenceProto::MAP) {\n    num_values = map.values().map_values_size();\n  }\n\n  if (num_keys != num_values) {\n    fail_check(\"Length of map keys and map values are not the same (map name: \", map.name(), \")\");\n  }\n}\n\n// Check that the index data stored in a SparseTensorProto is valid.\n// indices: a 1-dimensional tensor; indices[i] represents the\n// linearized index value for the i-th nonzero value.\nvoid check_sparse_tensor_indices_1(\n    const TensorProto& indices,\n    const SparseTensorProto& sparse_tensor_proto,\n    size_t nnz) {\n  int dense_rank = sparse_tensor_proto.dims_size();\n  int64_t dense_size = 1;\n  for (int i = 0; i < dense_rank; ++i)\n    dense_size *= sparse_tensor_proto.dims(i);\n  if (static_cast<size_t>(indices.dims(0)) != nnz) {\n    fail_check(\"Sparse tensor indices (\", indices.name(), \") has \", indices.dims(0), \" values, but NNZ is \", nnz);\n  }\n\n  // Check if indices appear in ascending order, and if they have valid\n  // values. The i-th value in index_data is the linear index of the i-th\n  // non-zero value.\n  const std::vector<int64_t> index_data = ParseData<int64_t>(&indices);\n\n  int64_t prev_index = -1;\n  for (size_t i = 0; i < nnz; ++i) {\n    int64_t curr_index = index_data[i]; // linearized index of i-th value\n    if (curr_index < 0 || curr_index >= dense_size) {\n      fail_check(\n          \"Sparse tensor (\",\n          indices.name(),\n          \") index value at position [\",\n          i,\n          \"] out of range [0, \",\n          dense_size - 1,\n          \"]\");\n    }\n    if (curr_index <= prev_index) {\n      fail_check(\"Sparse tensor (\", indices.name(), \") index value at position [\", i, \"] not in sorted order.\");\n    }\n    prev_index = curr_index;\n  }\n}\n\n// Check that the index data stored in a SparseTensorProto is valid.\n// indices: a 2-dimensional tensor; indices[i,j] represents the j-th\n// index value for the i-th nonzero value.\nvoid check_sparse_tensor_indices_2(\n    const TensorProto& indices,\n    const SparseTensorProto& sparse_tensor_proto,\n    size_t nnz) {\n  int dense_rank = sparse_tensor_proto.dims_size();\n  if (static_cast<size_t>(indices.dims(0)) != nnz) {\n    fail_check(\"Sparse tensor indices (\", indices.name(), \") first dimension size does not equal NNZ.\");\n  }\n  if (indices.dims(1) != dense_rank) {\n    fail_check(\"Sparse tensor indices (\", indices.name(), \") second dimension size does not match rank of tensor.\");\n  }\n\n  // Check if indices appear in ascending order, and if they have valid\n  // values.\n  const std::vector<int64_t> index_data = ParseData<int64_t>(&indices);\n  int64_t prev_index = -1;\n  for (size_t i = 0; i < nnz; ++i) {\n    int64_t curr_index = 0; // linearized index of i-th value\n    for (int j = 0; j < dense_rank; ++j) {\n      auto index_ij = index_data[i * dense_rank + j];\n      if ((index_ij < 0) || (index_ij >= sparse_tensor_proto.dims(j))) {\n        fail_check(\"Sparse tensor (\", indices.name(), \") index value at position [\", i, \",\", j, \"] out of range.\");\n      }\n      curr_index = curr_index * sparse_tensor_proto.dims(j) + index_ij;\n    }\n    if (curr_index <= prev_index) {\n      fail_check(\n          \"Sparse tensor (\", indices.name(), \") index value at position [\", i, \"] not in lexicographic sorted order.\");\n    }\n    prev_index = curr_index;\n  }\n}\n\nvoid check_sparse_tensor(const SparseTensorProto& sparse_tensor_proto, const CheckerContext& ctx) {\n  enforce_has_field(sparse_tensor_proto, values);\n\n  const TensorProto& values = sparse_tensor_proto.values();\n  check_tensor(values, ctx);\n\n  // values must be a tensor of shape [NNZ]\n  // Currently we restrict the value associated with a particular index-tuple\n  // to be a single value. In the future, if there is a requirement,\n  // we may extend this to permit the value to be a \"sub-tensor\", in which\n  // case values will have dimension > 1.\n  if (values.dims_size() != 1) {\n    fail_check(\"Sparse tensor values (\", values.name(), \") must have rank 1.\");\n  }\n  size_t nnz = static_cast<size_t>(values.dims(0));\n  int dense_rank = sparse_tensor_proto.dims_size();\n  if (dense_rank == 0) {\n    fail_check(\"Sparse tensor (\", values.name(), \") must have a dense-rank > 0\");\n  }\n  for (int i = 0; i < dense_rank; ++i) {\n    if (sparse_tensor_proto.dims(i) <= 0) {\n      fail_check(\"Sparse tensor (\", values.name(), \") dimensions are not positive.\");\n    }\n  }\n\n  if (sparse_tensor_proto.has_indices()) {\n    const TensorProto& indices = sparse_tensor_proto.indices();\n    check_tensor(indices, ctx);\n    if (indices.data_type() != TensorProto::INT64) {\n      fail_check(\"Sparse tensor indices (\", indices.name(), \") must have INT64 type.\");\n    }\n    switch (indices.dims().size()) {\n      case 1:\n        // Indices in linearized format\n        check_sparse_tensor_indices_1(indices, sparse_tensor_proto, nnz);\n        return;\n      case 2:\n        // Check COO-style index. E.g., an index for a 3D tensor is a 3-tuple.\n        check_sparse_tensor_indices_2(indices, sparse_tensor_proto, nnz);\n        return;\n      default:\n        fail_check(\"Sparse tensor indices (\", indices.name(), \") must have rank 1 or 2.\");\n    }\n  } else if (nnz != 0) {\n    fail_check(\"Sparse tensor (\", values.name(), \") has no index values.\");\n  }\n}\n\n// NB: This is a generic \"attribute well-formedness\" check, it doesn't\n// actually test if an attribute is valid per a schema\nvoid check_attribute(const AttributeProto& attr, const CheckerContext& ctx, const LexicalScopeContext& lex_ctx) {\n  enforce_non_empty_field(attr, name);\n\n  if (ctx.get_ir_version() >= 0x00000002) {\n    enforce_has_field(attr, type);\n  }\n\n  int used_fields = 0;\n\n#define check_type(expected_type)                                                     \\\n  if (attr.has_type() && attr.type() != expected_type) {                              \\\n    fail_check(\"type field and data field mismatch in attribute \", attr.name(), \".\"); \\\n  }\n\n#define check_singular_field(field, type) \\\n  if (attr.has_##field()) {               \\\n    ++used_fields;                        \\\n    check_type(type);                     \\\n  }\n\n#define check_repeated_field(field, type) \\\n  if (attr.field##_size() > 0) {          \\\n    ++used_fields;                        \\\n    check_type(type);                     \\\n  }\n\n  check_singular_field(f, AttributeProto::FLOAT);\n  check_singular_field(i, AttributeProto::INT);\n  check_singular_field(s, AttributeProto::STRING);\n  check_singular_field(t, AttributeProto::TENSOR);\n  check_singular_field(g, AttributeProto::GRAPH);\n  check_singular_field(tp, AttributeProto::TYPE_PROTO);\n  check_singular_field(sparse_tensor, AttributeProto::SPARSE_TENSOR);\n  check_repeated_field(floats, AttributeProto::FLOATS);\n  check_repeated_field(ints, AttributeProto::INTS);\n  check_repeated_field(strings, AttributeProto::STRINGS);\n  check_repeated_field(tensors, AttributeProto::TENSORS);\n  check_repeated_field(graphs, AttributeProto::GRAPHS);\n  check_repeated_field(sparse_tensors, AttributeProto::SPARSE_TENSORS);\n  check_repeated_field(type_protos, AttributeProto::TYPE_PROTOS);\n\n#undef check_type\n#undef check_singular_field\n#undef check_repeated_field\n\n  // Normally, used_fields is expected to be 1.\n  // In proto3, when the value to be set is type default value (say 0 for\n  // int), used_fields may be 0.\n  if (used_fields > 1) {\n    fail_check(\"Attribute (name: \", attr.name(), \") should not contain more than one value field.\");\n  }\n\n  if (!ctx.is_main_graph()) {\n    // It's an attribute of a node in function body.\n    if (attr.has_ref_attr_name() && used_fields != 0) {\n      // The attribute proto is supposed to refer to data outside and does not\n      // have its own value field set.\n      fail_check(\"Attribute (name: \", attr.name(), \") should refer to attribute in parent node.\");\n    }\n  }\n\n  if (attr.has_t()) {\n    check_tensor(attr.t(), ctx);\n  }\n\n  if (attr.has_sparse_tensor()) {\n    check_sparse_tensor(attr.sparse_tensor(), ctx);\n  }\n\n  if (attr.has_g()) {\n    CheckerContext subgraph_ctx(ctx);\n    subgraph_ctx.set_is_main_graph(false);\n    check_graph(attr.g(), subgraph_ctx, lex_ctx);\n  }\n\n  for (const auto& tensor : attr.tensors()) {\n    check_tensor(tensor, ctx);\n  }\n  for (const auto& sparse_tensor : attr.sparse_tensors()) {\n    check_sparse_tensor(sparse_tensor, ctx);\n  }\n  if (attr.graphs().size() > 0) {\n    CheckerContext subgraph_ctx(ctx);\n    subgraph_ctx.set_is_main_graph(false);\n    for (const auto& graph : attr.graphs()) {\n      check_graph(graph, subgraph_ctx, lex_ctx);\n    }\n  }\n}\n\nvoid check_node(const NodeProto& node, const CheckerContext& ctx, const LexicalScopeContext& lex_ctx) {\n  enforce_non_empty_field(node, op_type);\n\n  if (node.input().empty() && node.output().empty()) {\n    fail_check(\"NodeProto (name: \", node.name(), \", type: \", node.op_type(), \") has zero input and zero output.\");\n  }\n\n  // If encounter experimental op, stop checking\n  if (check_is_experimental_op(node.op_type())) {\n    std::cerr << \"Warning: Checker does not support models with experimental ops: \" << node.op_type() << std::endl;\n    return;\n  }\n\n  // Resolve domain for node\n  const auto& opset_imports = ctx.get_opset_imports();\n  auto dit = opset_imports.find(node.domain());\n  if (dit == opset_imports.end()) {\n    fail_check(\"No opset import for domain '\" + node.domain() + \"'\");\n  }\n  auto domain_version = dit->second;\n\n  for (const auto& attr : node.attribute()) {\n    check_attribute(attr, ctx, lex_ctx);\n  }\n\n  const auto* schema = ctx.get_schema_registry()->GetSchema(node.op_type(), domain_version, node.domain());\n  if (!schema) {\n    if (node.domain() == ONNX_DOMAIN || node.domain() == AI_ONNX_ML_DOMAIN || node.domain() == \"ai.onnx\" ||\n        node.domain() == AI_ONNX_TRAINING_DOMAIN) {\n      // fail the checker if op in built-in domains has no schema\n      fail_check(\n          \"No Op registered for \" + node.op_type() + \" with domain_version of \" +\n          ONNX_NAMESPACE::to_string(domain_version));\n    } else {\n      // TODO: expose the registration of the op schemas appropriately in\n      // python, so we can load and register operators in other domains\n      //\n      // before we complete the above todo, let's skip the schema check for\n      // now\n    }\n  } else if (schema->Deprecated()) {\n    fail_check(\n        \"Op registered for \" + node.op_type() + \" is deprecated in domain_version of \" +\n        ONNX_NAMESPACE::to_string(domain_version));\n  } else {\n    schema->Verify(node);\n  }\n}\n\nvoid check_graph(const GraphProto& graph, const CheckerContext& ctx, const LexicalScopeContext& parent_lex) {\n  enforce_non_empty_field(graph, name);\n\n  for (const auto& value_info : graph.input()) {\n    check_value_info(value_info, ctx);\n  }\n  for (const auto& value_info : graph.output()) {\n    check_value_info(value_info, ctx);\n  }\n\n  // Inherit values available in outer scope\n  // Note that we do not allow shadowing, so the presence of an already-defined\n  // name is always an error.\n  LexicalScopeContext lex_ctx{parent_lex};\n\n  for (const auto& value_info : graph.input()) {\n    // TODO: If shadowing isn't allowed, this should maybe use\n    // this_or_ancestor_graph_has\n    if (lex_ctx.this_graph_has(value_info.name())) {\n      fail_check(\n          \"Graph must be in single static assignment (SSA) form, however '\",\n          value_info.name(),\n          \"' has been used as graph input names multiple times.\");\n    }\n    lex_ctx.add(value_info.name());\n  }\n\n  std::unordered_set<std::reference_wrapper<const std::string>, std::hash<std::string>, std::equal_to<std::string>>\n      initializer_name_checker;\n\n  for (const auto& init : graph.initializer()) {\n    enforce_has_field(init, name);\n    const auto& name = init.name();\n    if (name.empty()) {\n      fail_check(\"Tensor initializers must have a non-empty name\");\n    }\n\n    if (!initializer_name_checker.insert(std::cref(name)).second) {\n      fail_check(name + \" initializer name is not unique\");\n    }\n\n    check_tensor(init, ctx);\n\n    if (ctx.get_ir_version() <= 0x00000003) {\n      // Initializers are a subset of graph inputs for IR_VERSION <= 3\n      if (!lex_ctx.this_graph_has(name)) {\n        fail_check(name + \" in initializer but not in graph input\");\n      }\n    } else {\n      // An initializer is allowed to have the same name as an input,\n      // but is not required to (for IR_VERSION >= 4)\n      lex_ctx.add(name);\n    }\n  }\n\n  for (const auto& sparse_init : graph.sparse_initializer()) {\n    const auto& values = sparse_init.values();\n    enforce_has_field(values, name);\n    const auto& name = values.name();\n    if (name.empty()) {\n      fail_check(\"Sparse tensor initializers must have a non-empty name\");\n    }\n    if (!initializer_name_checker.insert(std::cref(name)).second) {\n      fail_check(name + \" sparse initializer name is not unique across initializers and sparse_initializers\");\n    }\n    check_sparse_tensor(sparse_init, ctx);\n    lex_ctx.add(name);\n  }\n\n  for (const auto& node : graph.node()) {\n    // nodes must be in topologically sorted order\n    for (const auto& input : node.input()) {\n      // explicit optional input\n      if (input.empty()) {\n        continue;\n      }\n      if (!lex_ctx.this_or_ancestor_graph_has(input)) {\n        fail_check(\n            \"Nodes in a graph must be topologically sorted, however input '\",\n            input,\n            \"' of node: \\n\",\n            \"name: \",\n            node.name(),\n            \" OpType: \",\n            node.op_type(),\n            \"\\n is not output of any previous nodes.\");\n      }\n    }\n\n    // This needs to happen before SSA check since we don't want to recurse and\n    // find that outputs from control flow ops are colliding with names in the\n    // inner block\n\n    ONNX_TRY {\n      check_node(node, ctx, lex_ctx);\n    }\n    ONNX_CATCH(ValidationError & ex) {\n      ONNX_HANDLE_EXCEPTION([&]() {\n        ex.AppendContext(\"Bad node spec for node. Name: \" + node.name() + \" OpType: \" + node.op_type());\n        ONNX_THROW_EX(ex);\n      });\n    }\n    // check for SSA form\n    for (const auto& output : node.output()) {\n      // optional output\n      if (output.empty()) {\n        continue;\n      }\n\n      if (lex_ctx.this_or_ancestor_graph_has(output)) {\n        fail_check(\n            \"Graph must be in single static assignment (SSA) form, however '\",\n            output,\n            \"' has been used as output names multiple times.\");\n      }\n      lex_ctx.add(output);\n    }\n  }\n}\n\n// Utilify function to get the imported version of domain from opset imports\n// Returns -1 if requested domain is not found in the opset_imports\nint get_version_for_domain(const std::string& domain, const std::unordered_map<std::string, int>& opset_imports) {\n  auto it = opset_imports.find(domain);\n  if (it == opset_imports.end()) {\n    return -1;\n  }\n\n  return it->second;\n}\n\nvoid check_opset_compatibility(\n    const NodeProto& node,\n    const CheckerContext& ctx,\n    const std::unordered_map<std::string, int>& func_opset_imports,\n    const std::unordered_map<std::string, int>& model_opset_imports) {\n  auto func_opset_version = get_version_for_domain(node.domain(), func_opset_imports);\n  auto model_opset_version = get_version_for_domain(node.domain(), model_opset_imports);\n\n  if (func_opset_version == -1) {\n    fail_check(\"No Opset registered for domain \" + node.domain());\n  }\n\n  if (model_opset_version == -1) {\n    // model does not include opset import for a node present in function body.\n    // This is ok as along as the opset import is present in function level opset imports.\n    return;\n  }\n\n  if (func_opset_version == model_opset_version) {\n    // both versions are same, no need to verify schema.\n    return;\n  }\n\n  const auto* schema_for_model_import =\n      ctx.get_schema_registry()->GetSchema(node.op_type(), model_opset_version, node.domain());\n\n  const auto* schema_for_function_import =\n      ctx.get_schema_registry()->GetSchema(node.op_type(), func_opset_version, node.domain());\n\n  if (!schema_for_model_import && !schema_for_function_import) {\n    // the op belongs to a custom domain so we cannot verify schema\n    return;\n  }\n\n  // if schema is present for 1 but not other or the schema since versions do not match then raise an error\n  if (!schema_for_model_import || !schema_for_function_import ||\n      schema_for_function_import->since_version() != schema_for_model_import->since_version()) {\n    fail_check(\n        \"Opset import for domain \" + node.domain() + \" in function op \" + node.op_type() +\n        \"is not compatible with the version imported by model. FunctionOp imports version \" +\n        ONNX_NAMESPACE::to_string(func_opset_version) + \"whereas model imports version \" +\n        ONNX_NAMESPACE::to_string(model_opset_version));\n  }\n}\n\nvoid check_model_local_functions(\n    const ModelProto& model,\n    const CheckerContext& ctx,\n    const LexicalScopeContext& parent_lex) {\n  // make a copy of model opset imports to maintain a main copy of opset imports across the model and\n  // all model local functions to verify opset compatibility\n  std::unordered_map<std::string, int> model_opset_imports(ctx.get_opset_imports());\n\n  // merge the opset imports from every function in model_opset_imports\n  // only add the opset import if an entry for it does not exist in model_opset_imports\n  // if there is an entry then the compatibility will be checked later on in check_opset_compatibility\n  // called by check_function.\n  for (const auto& function_proto : model.functions()) {\n    for (const auto& opset_import : function_proto.opset_import()) {\n      if (get_version_for_domain(opset_import.domain(), model_opset_imports) == -1) {\n        model_opset_imports[opset_import.domain()] = opset_import.version();\n      }\n    }\n  }\n\n  CheckerContext ctx_copy = ctx;\n  ctx_copy.set_opset_imports(model_opset_imports);\n\n  for (const auto& function_proto : model.functions()) {\n    check_function(function_proto, ctx_copy, parent_lex);\n  }\n}\n\nvoid check_function(const FunctionProto& function, const CheckerContext& ctx, const LexicalScopeContext& parent_lex) {\n  enforce_non_empty_field(function, name);\n\n  if (ctx.get_ir_version() >= 0x00000008) {\n    enforce_has_field(function, domain);\n  }\n\n  const auto& model_opset_imports = ctx.get_opset_imports();\n  CheckerContext ctx_copy = ctx;\n\n  std::unordered_map<std::string, int> func_opset_imports;\n  for (auto& relied_opset : function.opset_import()) {\n    func_opset_imports[relied_opset.domain()] = static_cast<int>(relied_opset.version());\n  }\n\n  ctx_copy.set_opset_imports(func_opset_imports);\n\n  LexicalScopeContext lex_ctx{parent_lex};\n\n  for (const auto& input : function.input()) {\n    // TODO: If shadowing isn't allowed, this should maybe use\n    // this_or_ancestor_graph_has\n    if (lex_ctx.this_graph_has(input)) {\n      fail_check(\n          \"Graph must be in single static assignment (SSA) form, however '\", input, \"' has been used multiple times.\");\n    }\n    lex_ctx.add(input);\n  }\n\n  std::unordered_set<std::string> outputs;\n  for (const auto& output : function.output()) {\n    auto result = outputs.insert(output);\n    if (!result.second) {\n      fail_check(\"function (\", function.name(), \") should not have duplicate outputs specified.\");\n    }\n  }\n\n  std::unordered_set<std::string> attrs;\n  for (const auto& attr : function.attribute()) {\n    auto result = attrs.insert(attr);\n    if (!result.second) {\n      fail_check(\"function (\", function.name(), \") should not have duplicate attributes specified.\");\n    }\n  }\n\n  for (const auto& node : function.node()) {\n    // nodes must be in topologically sorted order\n    for (const auto& input : node.input()) {\n      // explicit optional input\n      if (input.empty()) {\n        continue;\n      }\n      if (!lex_ctx.this_graph_has(input)) {\n        fail_check(\n            \"Nodes in a function must be topologically sorted, however input '\",\n            input,\n            \"' of node: \\n\",\n            \"Name: \",\n            node.name(),\n            \" OpType: \",\n            node.op_type(),\n            \"\\n is neither output of any previous nodes nor input of the function.\");\n      }\n    }\n\n    // check whether the opset version imported for a domain by function and model are\n    // compatible\n    check_opset_compatibility(node, ctx_copy, func_opset_imports, model_opset_imports);\n\n    check_node(node, ctx_copy, lex_ctx);\n\n    // check for SSA form\n    for (const auto& output : node.output()) {\n      // optional output\n      if (output.empty()) {\n        continue;\n      }\n      if (lex_ctx.this_or_ancestor_graph_has(output)) {\n        fail_check(\n            \"Function must be in single static assignment (SSA) form, however '\",\n            output,\n            \"' has been used as output names multiple times.\");\n      }\n      lex_ctx.add(output);\n    }\n  }\n}\n\nvoid check_model(const ModelProto& model, CheckerContext& ctx) {\n  if (!model.ir_version()) {\n    fail_check(\"The model does not have an ir_version set properly.\");\n  }\n  if (model.ir_version() > IR_VERSION) {\n    fail_check(\"Your model ir_version is higher than the checker's.\");\n  }\n  if (model.metadata_props_size() > 1) {\n    std::unordered_set<std::string> keys;\n    for (const StringStringEntryProto& entry : model.metadata_props()) {\n      auto i = keys.insert(entry.key());\n      if (!i.second) {\n        fail_check(\"Your model has duplicate keys in metadata_props.\");\n      }\n    }\n  }\n  std::unordered_map<std::string, int> versions;\n  ctx.set_ir_version(static_cast<int>(model.ir_version()));\n  std::unordered_map<std::string, int> opset_imports;\n  for (const auto& opset_import : model.opset_import()) {\n    opset_imports[opset_import.domain()] = static_cast<int>(opset_import.version());\n  }\n  if (model.ir_version() >= 3) {\n    if (opset_imports.empty()) {\n      fail_check(\"model with IR version >= 3 must specify opset_import for ONNX\");\n    }\n  } else {\n    if (opset_imports.empty())\n      opset_imports[ONNX_DOMAIN] = 1;\n    else {\n      fail_check(\"model with IR version < 3 cannot have opset_import specified\");\n    }\n  }\n  ctx.set_opset_imports(opset_imports);\n  LexicalScopeContext lex_ctx;\n  check_graph(model.graph(), ctx, lex_ctx);\n\n  if (ctx.get_ir_version() >= 0x00000008) {\n    check_model_local_functions(model, ctx, lex_ctx);\n  }\n}\n\nvoid check_model(const std::string& model_path, bool full_check) {\n  ModelProto model;\n  LoadProtoFromPath(model_path, model);\n\n  CheckerContext ctx;\n  std::string model_dir;\n  size_t pos = model_path.find_last_of(\"\\\\/\");\n  if (pos != std::string::npos) {\n    model_dir = model_path.substr(0, pos + 1);\n  }\n  ctx.set_model_dir(model_dir);\n  check_model(model, ctx);\n\n  if (full_check) {\n    ShapeInferenceOptions options{true, 1, false};\n    ONNX_NAMESPACE::shape_inference::InferShapes(model, ctx.get_schema_registry(), options);\n  }\n}\n\nvoid check_model(const ModelProto& model) {\n  CheckerContext ctx;\n  check_model(model, ctx);\n}\n\nvoid check_model(ModelProto& model, bool full_check) {\n  CheckerContext ctx;\n  check_model(model, ctx);\n\n  if (full_check) {\n    ShapeInferenceOptions options{true, 1, false};\n    ONNX_NAMESPACE::shape_inference::InferShapes(model, ctx.get_schema_registry(), options);\n  }\n}\n\nstd::set<std::string> experimental_ops = {\n    \"ATen\",\n    \"Affine\",\n    \"ConstantFill\",\n    \"Crop\",\n    \"DynamicSlice\",\n    \"GRUUnit\",\n    \"GivenTensorFill\",\n    \"ImageScaler\",\n    \"ParametricSoftplus\",\n    \"Scale\",\n    \"ScaledTanh\"};\n\nbool check_is_experimental_op(std::string node_op_type) {\n  return (experimental_ops.count(node_op_type)) ? true : false;\n}\n\n#undef fail_check\n#undef enforce_has_field\n#undef enforce_has_repeated_field\n#undef enforce_non_empty_field\n\n} // namespace checker\n} // namespace ONNX_NAMESPACE\n", "patch": "@@ -127,7 +127,20 @@ void check_tensor(const TensorProto& tensor, const CheckerContext& ctx) {\n     for (const StringStringEntryProto& entry : tensor.external_data()) {\n       if (entry.has_key() && entry.has_value() && entry.key() == \"location\") {\n         has_location = true;\n-        std::string data_path = path_join(ctx.get_model_dir(), entry.value());\n+        std::string relative_path = clean_relative_path(entry.value());\n+        // Check that normalized relative path starts with \"../\" or \"..\\\" on windows.\n+        if (relative_path.rfind(\"..\" + k_preferred_path_separator, 0) == 0) {\n+          fail_check(\n+              \"Data of TensorProto ( tensor name: \",\n+              tensor.name(),\n+              \") should be file inside the \",\n+              ctx.get_model_dir(),\n+              \", but the '\",\n+              entry.value(),\n+              \"' points outside the directory\");\n+        }\n+\n+        std::string data_path = path_join(ctx.get_model_dir(), relative_path);\n         // use stat to check whether the file exists\n         struct stat buffer;\n         if (stat((data_path).c_str(), &buffer) != 0) {\n@@ -138,6 +151,18 @@ void check_tensor(const TensorProto& tensor, const CheckerContext& ctx) {\n               data_path,\n               \", but it doesn't exist or is not accessible.\");\n         }\n+#ifdef _WIN32\n+#else // POSIX\n+      //  Do not allow symlinks or directories.\n+        if (!S_ISREG(buffer.st_mode)) {\n+          fail_check(\n+              \"Data of TensorProto ( tensor name: \",\n+              tensor.name(),\n+              \") should be stored in \",\n+              data_path,\n+              \", but it is not regular file.\");\n+        }\n+#endif\n       }\n     }\n     if (!has_location) {", "file_path": "files/2023_1/700", "file_language": "cc", "file_name": "onnx/checker.cc", "outdated_file_modify": 0, "outdated_file_before": 0, "outdated_file_after": 0}, {"raw_url": "https://github.com/onnx/onnx/raw/f369b0e859024095d721f1d1612da5a8fa38988d/onnx%2Fcommon%2Fpath.cc", "code": "/*\n * SPDX-License-Identifier: Apache-2.0\n */\n\n// Copyright (c) ONNX Project Contributors.\n// Licensed under the MIT license.\n\n#include \"onnx/common/path.h\"\n\nnamespace ONNX_NAMESPACE {\n\nbool is_path_separator(char c) {\n  // Windows accept / as path separator.\n  if (k_preferred_path_separator == \"\\\\\") {\n    return c == '\\\\' || c == '/';\n  }\n\n  return c == k_preferred_path_separator[0];\n}\n\nvoid normalize_separator(std::string& path) {\n  char preferred_sep = k_preferred_path_separator[0];\n  if (preferred_sep == '/') {\n    // Do nothing on linux.\n    return;\n  }\n\n  for (size_t i = 0; i < path.size(); i++) {\n    if (is_path_separator(path[i]) && path[i] != preferred_sep) {\n      path[i] = preferred_sep;\n    }\n  }\n}\n\nstd::string path_join(const std::string& origin, const std::string& append) {\n  if (origin.find_last_of(k_preferred_path_separator) != origin.length() - k_preferred_path_separator.length()) {\n    return origin + k_preferred_path_separator + append;\n  }\n  return origin + append;\n}\n\nstd::string clean_relative_path(const std::string& path) {\n  if (path.empty()) {\n    return \".\";\n  }\n\n  std::string out;\n\n  char sep = k_preferred_path_separator[0];\n  size_t n = path.size();\n\n  size_t r = 0;\n  size_t dotdot = 0;\n\n  while (r < n) {\n    if (is_path_separator(path[r])) {\n      r++;\n      continue;\n    }\n\n    if (path[r] == '.' && (r + 1 == n || is_path_separator(path[r + 1]))) {\n      r++;\n      continue;\n    }\n\n    if (path[r] == '.' && path[r + 1] == '.' && (r + 2 == n || is_path_separator(path[r + 2]))) {\n      r += 2;\n\n      if (out.size() > dotdot) {\n        while (out.size() > dotdot && !is_path_separator(out.back())) {\n          out.pop_back();\n        }\n        if (!out.empty())\n          out.pop_back();\n      } else {\n        if (!out.empty()) {\n          out.push_back(sep);\n        }\n\n        out.push_back('.');\n        out.push_back('.');\n        dotdot = out.size();\n      }\n\n      continue;\n    }\n\n    if (!out.empty() && out.back() != sep) {\n      out.push_back(sep);\n    }\n\n    for (; r < n && !is_path_separator(path[r]); r++) {\n      out.push_back(path[r]);\n    }\n  }\n\n  if (out.empty()) {\n    out.push_back('.');\n  }\n\n  // Use 1 separator in path.\n  normalize_separator(out);\n\n  return out;\n}\n\n} // namespace ONNX_NAMESPACE\n", "code_before": "/*\n * SPDX-License-Identifier: Apache-2.0\n */\n\n// Copyright (c) ONNX Project Contributors.\n// Licensed under the MIT license.\n\n#include \"onnx/common/path.h\"\n\nnamespace ONNX_NAMESPACE {\n\nstd::string path_join(const std::string& origin, const std::string& append) {\n  if (origin.find_last_of(k_preferred_path_separator) != origin.length() - k_preferred_path_separator.length()) {\n    return origin + k_preferred_path_separator + append;\n  }\n  return origin + append;\n}\n\n} // namespace ONNX_NAMESPACE\n", "patch": "@@ -9,11 +9,99 @@\n \n namespace ONNX_NAMESPACE {\n \n+bool is_path_separator(char c) {\n+  // Windows accept / as path separator.\n+  if (k_preferred_path_separator == \"\\\\\") {\n+    return c == '\\\\' || c == '/';\n+  }\n+\n+  return c == k_preferred_path_separator[0];\n+}\n+\n+void normalize_separator(std::string& path) {\n+  char preferred_sep = k_preferred_path_separator[0];\n+  if (preferred_sep == '/') {\n+    // Do nothing on linux.\n+    return;\n+  }\n+\n+  for (size_t i = 0; i < path.size(); i++) {\n+    if (is_path_separator(path[i]) && path[i] != preferred_sep) {\n+      path[i] = preferred_sep;\n+    }\n+  }\n+}\n+\n std::string path_join(const std::string& origin, const std::string& append) {\n   if (origin.find_last_of(k_preferred_path_separator) != origin.length() - k_preferred_path_separator.length()) {\n     return origin + k_preferred_path_separator + append;\n   }\n   return origin + append;\n }\n \n+std::string clean_relative_path(const std::string& path) {\n+  if (path.empty()) {\n+    return \".\";\n+  }\n+\n+  std::string out;\n+\n+  char sep = k_preferred_path_separator[0];\n+  size_t n = path.size();\n+\n+  size_t r = 0;\n+  size_t dotdot = 0;\n+\n+  while (r < n) {\n+    if (is_path_separator(path[r])) {\n+      r++;\n+      continue;\n+    }\n+\n+    if (path[r] == '.' && (r + 1 == n || is_path_separator(path[r + 1]))) {\n+      r++;\n+      continue;\n+    }\n+\n+    if (path[r] == '.' && path[r + 1] == '.' && (r + 2 == n || is_path_separator(path[r + 2]))) {\n+      r += 2;\n+\n+      if (out.size() > dotdot) {\n+        while (out.size() > dotdot && !is_path_separator(out.back())) {\n+          out.pop_back();\n+        }\n+        if (!out.empty())\n+          out.pop_back();\n+      } else {\n+        if (!out.empty()) {\n+          out.push_back(sep);\n+        }\n+\n+        out.push_back('.');\n+        out.push_back('.');\n+        dotdot = out.size();\n+      }\n+\n+      continue;\n+    }\n+\n+    if (!out.empty() && out.back() != sep) {\n+      out.push_back(sep);\n+    }\n+\n+    for (; r < n && !is_path_separator(path[r]); r++) {\n+      out.push_back(path[r]);\n+    }\n+  }\n+\n+  if (out.empty()) {\n+    out.push_back('.');\n+  }\n+\n+  // Use 1 separator in path.\n+  normalize_separator(out);\n+\n+  return out;\n+}\n+\n } // namespace ONNX_NAMESPACE", "file_path": "files/2023_1/701", "file_language": "cc", "file_name": "onnx/common/path.cc", "outdated_file_modify": 0, "outdated_file_before": 0, "outdated_file_after": 0}, {"raw_url": "https://github.com/onnx/onnx/raw/f369b0e859024095d721f1d1612da5a8fa38988d/onnx%2Fcommon%2Fpath.h", "code": "/*\n * SPDX-License-Identifier: Apache-2.0\n */\n\n// Copyright (c) ONNX Project Contributors.\n// Licensed under the MIT license.\n\n#pragma once\n\n#include <string>\n\nnamespace ONNX_NAMESPACE {\n\n#ifdef _WIN32\nconst std::string k_preferred_path_separator = \"\\\\\";\n#else // POSIX\nconst std::string k_preferred_path_separator = \"/\";\n#endif\n\nstd::string path_join(const std::string& origin, const std::string& append);\nvoid normalize_separator(std::string& path);\nstd::string clean_relative_path(const std::string& path);\n\n} // namespace ONNX_NAMESPACE\n", "code_before": "/*\n * SPDX-License-Identifier: Apache-2.0\n */\n\n// Copyright (c) ONNX Project Contributors.\n// Licensed under the MIT license.\n\n#pragma once\n\n#include <string>\n\nnamespace ONNX_NAMESPACE {\n\n#ifdef _WIN32\nconst std::string k_preferred_path_separator = \"\\\\\";\n#else // POSIX\nconst std::string k_preferred_path_separator = \"/\";\n#endif\n\nstd::string path_join(const std::string& origin, const std::string& append);\n\n} // namespace ONNX_NAMESPACE\n", "patch": "@@ -18,5 +18,7 @@ const std::string k_preferred_path_separator = \"/\";\n #endif\n \n std::string path_join(const std::string& origin, const std::string& append);\n+void normalize_separator(std::string& path);\n+std::string clean_relative_path(const std::string& path);\n \n } // namespace ONNX_NAMESPACE", "file_path": "files/2023_1/702", "file_language": "h", "file_name": "onnx/common/path.h", "outdated_file_modify": 0, "outdated_file_before": 0, "outdated_file_after": 0}, {"raw_url": "https://github.com/onnx/onnx/raw/f369b0e859024095d721f1d1612da5a8fa38988d/onnx%2Ftest%2Fcpp%2Fcommon_path_test.cc", "code": "/*\n * SPDX-License-Identifier: Apache-2.0\n */\n\n#include <list>\n#include <utility>\n#include \"gtest/gtest.h\"\n\n#include \"onnx/common/path.h\"\n\nusing namespace ONNX_NAMESPACE;\n\nnamespace ONNX_NAMESPACE {\nnamespace Test {\nnamespace {\nstd::string fix_sep(std::string path) {\n  std::string out = path;\n  normalize_separator(out);\n  return out;\n}\n} // namespace\n\nTEST(PathTest, CleanRelativePathTest) {\n  // Already normal.\n  EXPECT_EQ(clean_relative_path(\"abc\"), fix_sep(\"abc\"));\n  EXPECT_EQ(clean_relative_path(\"abc/def\"), fix_sep(\"abc/def\"));\n  EXPECT_EQ(clean_relative_path(\"a/b/c\"), fix_sep(\"a/b/c\"));\n  EXPECT_EQ(clean_relative_path(\".\"), fix_sep(\".\"));\n  EXPECT_EQ(clean_relative_path(\"..\"), fix_sep(\"..\"));\n  EXPECT_EQ(clean_relative_path(\"../..\"), fix_sep(\"../..\"));\n  EXPECT_EQ(clean_relative_path(\"../../abc\"), fix_sep(\"../../abc\"));\n  // Remove leading slash\n  EXPECT_EQ(clean_relative_path(\"/abc\"), fix_sep(\"abc\"));\n  EXPECT_EQ(clean_relative_path(\"/\"), fix_sep(\".\"));\n  // Remove trailing slash\n  EXPECT_EQ(clean_relative_path(\"abc/\"), fix_sep(\"abc\"));\n  EXPECT_EQ(clean_relative_path(\"abc/def/\"), fix_sep(\"abc/def\"));\n  EXPECT_EQ(clean_relative_path(\"a/b/c/\"), fix_sep(\"a/b/c\"));\n  EXPECT_EQ(clean_relative_path(\"./\"), fix_sep(\".\"));\n  EXPECT_EQ(clean_relative_path(\"../\"), fix_sep(\"..\"));\n  EXPECT_EQ(clean_relative_path(\"../../\"), fix_sep(\"../..\"));\n  EXPECT_EQ(clean_relative_path(\"/abc/\"), fix_sep(\"abc\"));\n  // Remove doubled slash\n  EXPECT_EQ(clean_relative_path(\"abc//def//ghi\"), fix_sep(\"abc/def/ghi\"));\n  EXPECT_EQ(clean_relative_path(\"//abc\"), fix_sep(\"abc\"));\n  EXPECT_EQ(clean_relative_path(\"///abc\"), fix_sep(\"abc\"));\n  EXPECT_EQ(clean_relative_path(\"//abc//\"), fix_sep(\"abc\"));\n  EXPECT_EQ(clean_relative_path(\"abc//\"), fix_sep(\"abc\"));\n  // Remove . elements\n  EXPECT_EQ(clean_relative_path(\"abc/./def\"), fix_sep(\"abc/def\"));\n  EXPECT_EQ(clean_relative_path(\"/./abc/def\"), fix_sep(\"abc/def\"));\n  EXPECT_EQ(clean_relative_path(\"abc/.\"), fix_sep(\"abc\"));\n  // Remove .. elements\n  EXPECT_EQ(clean_relative_path(\"abc/def/ghi/../jkl\"), fix_sep(\"abc/def/jkl\"));\n  EXPECT_EQ(clean_relative_path(\"abc/def/../ghi/../jkl\"), fix_sep(\"abc/jkl\"));\n  EXPECT_EQ(clean_relative_path(\"abc/def/..\"), fix_sep(\"abc\"));\n  EXPECT_EQ(clean_relative_path(\"abc/def/../..\"), fix_sep(\".\"));\n  EXPECT_EQ(clean_relative_path(\"/abc/def/../..\"), fix_sep(\".\"));\n  EXPECT_EQ(clean_relative_path(\"abc/def/../../..\"), fix_sep(\"..\"));\n  EXPECT_EQ(clean_relative_path(\"/abc/def/../../..\"), fix_sep(\"..\"));\n  EXPECT_EQ(clean_relative_path(\"abc/def/../../../ghi/jkl/../../../mno\"), fix_sep(\"../../mno\"));\n  EXPECT_EQ(clean_relative_path(\"/../abc\"), fix_sep(\"../abc\"));\n  // Combinations\n  EXPECT_EQ(clean_relative_path(\"abc/./../def\"), fix_sep(\"def\"));\n  EXPECT_EQ(clean_relative_path(\"abc//./../def\"), fix_sep(\"def\"));\n  EXPECT_EQ(clean_relative_path(\"abc/../../././../def\"), fix_sep(\"../../def\"));\n}\n\n} // namespace Test\n} // namespace ONNX_NAMESPACE\n", "code_before": "", "patch": "@@ -0,0 +1,70 @@\n+/*\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+#include <list>\n+#include <utility>\n+#include \"gtest/gtest.h\"\n+\n+#include \"onnx/common/path.h\"\n+\n+using namespace ONNX_NAMESPACE;\n+\n+namespace ONNX_NAMESPACE {\n+namespace Test {\n+namespace {\n+std::string fix_sep(std::string path) {\n+  std::string out = path;\n+  normalize_separator(out);\n+  return out;\n+}\n+} // namespace\n+\n+TEST(PathTest, CleanRelativePathTest) {\n+  // Already normal.\n+  EXPECT_EQ(clean_relative_path(\"abc\"), fix_sep(\"abc\"));\n+  EXPECT_EQ(clean_relative_path(\"abc/def\"), fix_sep(\"abc/def\"));\n+  EXPECT_EQ(clean_relative_path(\"a/b/c\"), fix_sep(\"a/b/c\"));\n+  EXPECT_EQ(clean_relative_path(\".\"), fix_sep(\".\"));\n+  EXPECT_EQ(clean_relative_path(\"..\"), fix_sep(\"..\"));\n+  EXPECT_EQ(clean_relative_path(\"../..\"), fix_sep(\"../..\"));\n+  EXPECT_EQ(clean_relative_path(\"../../abc\"), fix_sep(\"../../abc\"));\n+  // Remove leading slash\n+  EXPECT_EQ(clean_relative_path(\"/abc\"), fix_sep(\"abc\"));\n+  EXPECT_EQ(clean_relative_path(\"/\"), fix_sep(\".\"));\n+  // Remove trailing slash\n+  EXPECT_EQ(clean_relative_path(\"abc/\"), fix_sep(\"abc\"));\n+  EXPECT_EQ(clean_relative_path(\"abc/def/\"), fix_sep(\"abc/def\"));\n+  EXPECT_EQ(clean_relative_path(\"a/b/c/\"), fix_sep(\"a/b/c\"));\n+  EXPECT_EQ(clean_relative_path(\"./\"), fix_sep(\".\"));\n+  EXPECT_EQ(clean_relative_path(\"../\"), fix_sep(\"..\"));\n+  EXPECT_EQ(clean_relative_path(\"../../\"), fix_sep(\"../..\"));\n+  EXPECT_EQ(clean_relative_path(\"/abc/\"), fix_sep(\"abc\"));\n+  // Remove doubled slash\n+  EXPECT_EQ(clean_relative_path(\"abc//def//ghi\"), fix_sep(\"abc/def/ghi\"));\n+  EXPECT_EQ(clean_relative_path(\"//abc\"), fix_sep(\"abc\"));\n+  EXPECT_EQ(clean_relative_path(\"///abc\"), fix_sep(\"abc\"));\n+  EXPECT_EQ(clean_relative_path(\"//abc//\"), fix_sep(\"abc\"));\n+  EXPECT_EQ(clean_relative_path(\"abc//\"), fix_sep(\"abc\"));\n+  // Remove . elements\n+  EXPECT_EQ(clean_relative_path(\"abc/./def\"), fix_sep(\"abc/def\"));\n+  EXPECT_EQ(clean_relative_path(\"/./abc/def\"), fix_sep(\"abc/def\"));\n+  EXPECT_EQ(clean_relative_path(\"abc/.\"), fix_sep(\"abc\"));\n+  // Remove .. elements\n+  EXPECT_EQ(clean_relative_path(\"abc/def/ghi/../jkl\"), fix_sep(\"abc/def/jkl\"));\n+  EXPECT_EQ(clean_relative_path(\"abc/def/../ghi/../jkl\"), fix_sep(\"abc/jkl\"));\n+  EXPECT_EQ(clean_relative_path(\"abc/def/..\"), fix_sep(\"abc\"));\n+  EXPECT_EQ(clean_relative_path(\"abc/def/../..\"), fix_sep(\".\"));\n+  EXPECT_EQ(clean_relative_path(\"/abc/def/../..\"), fix_sep(\".\"));\n+  EXPECT_EQ(clean_relative_path(\"abc/def/../../..\"), fix_sep(\"..\"));\n+  EXPECT_EQ(clean_relative_path(\"/abc/def/../../..\"), fix_sep(\"..\"));\n+  EXPECT_EQ(clean_relative_path(\"abc/def/../../../ghi/jkl/../../../mno\"), fix_sep(\"../../mno\"));\n+  EXPECT_EQ(clean_relative_path(\"/../abc\"), fix_sep(\"../abc\"));\n+  // Combinations\n+  EXPECT_EQ(clean_relative_path(\"abc/./../def\"), fix_sep(\"def\"));\n+  EXPECT_EQ(clean_relative_path(\"abc//./../def\"), fix_sep(\"def\"));\n+  EXPECT_EQ(clean_relative_path(\"abc/../../././../def\"), fix_sep(\"../../def\"));\n+}\n+\n+} // namespace Test\n+} // namespace ONNX_NAMESPACE", "file_path": "files/2023_1/703", "file_language": "cc", "file_name": "onnx/test/cpp/common_path_test.cc", "outdated_file_modify": 0, "outdated_file_before": 0, "outdated_file_after": 0}, {"raw_url": "https://github.com/onnx/onnx/raw/f369b0e859024095d721f1d1612da5a8fa38988d/onnx%2Ftest%2Ftest_external_data.py", "code": "# SPDX-License-Identifier: Apache-2.0\nimport tempfile\nimport unittest\nimport uuid\n\nimport numpy as np  # type: ignore\nimport shutil\n\nimport os\nimport os.path as Path\n\nimport onnx\nfrom onnx import checker, helper, shape_inference\nfrom onnx import ModelProto, TensorProto\nfrom onnx.external_data_helper import set_external_data\nfrom onnx.external_data_helper import convert_model_to_external_data\nfrom onnx.external_data_helper import convert_model_from_external_data\nfrom onnx.external_data_helper import load_external_data_for_model, load_external_data_for_tensor\nfrom onnx.numpy_helper import to_array, from_array\nfrom typing import Any, Tuple, List\nimport pytest  # type: ignore\nimport sys\n\n\nclass TestLoadExternalDataBase(unittest.TestCase):\n\n    def setUp(self) -> None:\n        self.temp_dir: str = tempfile.mkdtemp()\n        self.initializer_value = np.arange(6).reshape(3, 2).astype(np.float32) + 512\n        self.attribute_value = np.arange(6).reshape(2, 3).astype(np.float32) + 256\n        self.model_filename = self.create_test_model()\n\n    def tearDown(self) -> None:\n        shutil.rmtree(self.temp_dir)\n\n    def get_temp_model_filename(self) -> str:\n        return os.path.join(self.temp_dir, str(uuid.uuid4()) + '.onnx')\n\n    def create_external_data_tensor(self, value: List[Any], tensor_name: str) -> TensorProto:\n        tensor = from_array(np.array(value))\n        tensor.name = tensor_name\n        tensor_filename = f\"{tensor_name}.bin\"\n        set_external_data(tensor, location=tensor_filename)\n\n        with open(os.path.join(self.temp_dir, tensor_filename), 'wb') as data_file:\n            data_file.write(tensor.raw_data)\n        tensor.ClearField('raw_data')\n        tensor.data_location = onnx.TensorProto.EXTERNAL\n        return tensor\n\n    def create_test_model(self) -> str:\n        constant_node = onnx.helper.make_node(\n            'Constant',\n            inputs=[],\n            outputs=['values'],\n            value=self.create_external_data_tensor(self.attribute_value, \"attribute_value\")\n        )\n\n        initializers = [self.create_external_data_tensor(self.initializer_value, \"input_value\")]\n        inputs = [helper.make_tensor_value_info(\"input_value\",\n                                                onnx.TensorProto.FLOAT,\n                                                self.initializer_value.shape)]\n\n        graph = helper.make_graph([constant_node], \"test_graph\",\n                                  inputs=inputs, outputs=[],\n                                  initializer=initializers)\n        model = helper.make_model(graph)\n\n        model_filename = os.path.join(self.temp_dir, \"model.onnx\")\n        with open(model_filename, \"wb\") as model_file:\n            model_file.write(model.SerializeToString())\n\n        return model_filename\n\n    def test_check_model(self) -> None:\n        checker.check_model(self.model_filename)\n\n\nclass TestLoadExternalData(TestLoadExternalDataBase):\n\n    def test_load_external_data(self) -> None:\n        model = onnx.load_model(self.model_filename)\n        initializer_tensor = model.graph.initializer[0]\n        self.assertTrue(np.allclose(to_array(initializer_tensor), self.initializer_value))\n\n        attribute_tensor = model.graph.node[0].attribute[0].t\n        self.assertTrue(np.allclose(to_array(attribute_tensor), self.attribute_value))\n\n    def test_load_external_data_for_model(self) -> None:\n        model = onnx.load_model(self.model_filename, load_external_data=False)\n        load_external_data_for_model(model, self.temp_dir)\n        initializer_tensor = model.graph.initializer[0]\n        self.assertTrue(np.allclose(to_array(initializer_tensor), self.initializer_value))\n\n        attribute_tensor = model.graph.node[0].attribute[0].t\n        self.assertTrue(np.allclose(to_array(attribute_tensor), self.attribute_value))\n\n    def test_save_external_data(self) -> None:\n        model = onnx.load_model(self.model_filename)\n\n        temp_dir = os.path.join(self.temp_dir, \"save_copy\")\n        os.mkdir(temp_dir)\n        new_model_filename = os.path.join(temp_dir, 'model.onnx')\n        onnx.save_model(model, new_model_filename)\n\n        new_model = onnx.load_model(new_model_filename)\n        initializer_tensor = new_model.graph.initializer[0]\n        self.assertTrue(np.allclose(to_array(initializer_tensor), self.initializer_value))\n\n        attribute_tensor = new_model.graph.node[0].attribute[0].t\n        self.assertTrue(np.allclose(to_array(attribute_tensor), self.attribute_value))\n\n\nclass TestLoadExternalDataSingleFile(TestLoadExternalDataBase):\n\n    def create_external_data_tensors(self, tensors_data: List[Tuple[List[Any], Any]]) -> List[TensorProto]:\n        tensor_filename = \"tensors.bin\"\n        tensors = []\n\n        with open(os.path.join(self.temp_dir, tensor_filename), 'ab') as data_file:\n            for (value, tensor_name) in tensors_data:\n                tensor = from_array(np.array(value))\n                offset = data_file.tell()\n                if offset % 4096 != 0:\n                    data_file.write(b\"\\0\" * (4096 - offset % 4096))\n                    offset = offset + 4096 - offset % 4096\n\n                data_file.write(tensor.raw_data)\n                set_external_data(tensor, location=tensor_filename, offset=offset, length=data_file.tell() - offset)\n                tensor.name = tensor_name\n                tensor.ClearField(\"raw_data\")\n                tensor.data_location = onnx.TensorProto.EXTERNAL\n                tensors.append(tensor)\n\n        return tensors\n\n    def test_load_external_single_file_data(self) -> None:\n        model = onnx.load_model(self.model_filename)\n\n        initializer_tensor = model.graph.initializer[0]\n        self.assertTrue(np.allclose(to_array(initializer_tensor), self.initializer_value))\n\n        attribute_tensor = model.graph.node[0].attribute[0].t\n        self.assertTrue(np.allclose(to_array(attribute_tensor), self.attribute_value))\n\n    def test_save_external_single_file_data(self) -> None:\n        model = onnx.load_model(self.model_filename)\n\n        temp_dir = os.path.join(self.temp_dir, \"save_copy\")\n        os.mkdir(temp_dir)\n        new_model_filename = os.path.join(temp_dir, 'model.onnx')\n        onnx.save_model(model, new_model_filename)\n\n        new_model = onnx.load_model(new_model_filename)\n        initializer_tensor = new_model.graph.initializer[0]\n        self.assertTrue(np.allclose(to_array(initializer_tensor), self.initializer_value))\n\n        attribute_tensor = new_model.graph.node[0].attribute[0].t\n        self.assertTrue(np.allclose(to_array(attribute_tensor), self.attribute_value))\n\n\nclass TestSaveAllTensorsAsExternalData(TestLoadExternalDataBase):\n\n    def setUp(self) -> None:\n        self.temp_dir: str = tempfile.mkdtemp()\n        self.initializer_value = np.arange(6).reshape(3, 2).astype(np.float32) + 512\n        self.attribute_value = np.arange(6).reshape(2, 3).astype(np.float32) + 256\n        self.model = self.create_test_model_proto()\n\n    def create_data_tensors(self, tensors_data: List[Tuple[List[Any], Any]]) -> List[TensorProto]:\n        tensors = []\n        for (value, tensor_name) in tensors_data:\n            tensor = from_array(np.array(value))\n            tensor.name = tensor_name\n            tensors.append(tensor)\n\n        return tensors\n\n    def create_test_model_proto(self) -> ModelProto:\n        tensors = self.create_data_tensors([\n            (self.attribute_value, \"attribute_value\"),\n            (self.initializer_value, \"input_value\"),\n        ])\n\n        constant_node = onnx.helper.make_node(\n            'Constant',\n            inputs=[],\n            outputs=['values'],\n            value=tensors[0]\n        )\n\n        inputs = [helper.make_tensor_value_info(\"input_value\",\n                                                onnx.TensorProto.FLOAT,\n                                                self.initializer_value.shape)]\n\n        graph = helper.make_graph([constant_node], \"test_graph\",\n                                  inputs=inputs, outputs=[],\n                                  initializer=[tensors[1]])\n        return helper.make_model(graph)\n\n    def test_check_model(self) -> None:\n        checker.check_model(self.model)\n\n    def test_convert_model_to_external_data_with_size_threshold(self) -> None:\n        model_file_path = self.get_temp_model_filename()\n\n        convert_model_to_external_data(self.model, size_threshold=1024)\n        onnx.save_model(self.model, model_file_path)\n\n        model = onnx.load_model(model_file_path)\n        initializer_tensor = model.graph.initializer[0]\n        self.assertFalse(initializer_tensor.HasField(\"data_location\"))\n\n    def test_convert_model_to_external_data_without_size_threshold(self) -> None:\n        model_file_path = self.get_temp_model_filename()\n        convert_model_to_external_data(self.model, size_threshold=0)\n        onnx.save_model(self.model, model_file_path)\n\n        model = onnx.load_model(model_file_path)\n        initializer_tensor = model.graph.initializer[0]\n        self.assertTrue(initializer_tensor.HasField(\"data_location\"))\n        self.assertTrue(np.allclose(to_array(initializer_tensor), self.initializer_value))\n\n    def test_convert_model_to_external_data_from_one_file_with_location(self) -> None:\n        model_file_path = self.get_temp_model_filename()\n        external_data_file = str(uuid.uuid4())\n\n        convert_model_to_external_data(self.model, size_threshold=0, all_tensors_to_one_file=True,\n                                       location=external_data_file)\n        onnx.save_model(self.model, model_file_path)\n\n        self.assertTrue(Path.isfile(os.path.join(self.temp_dir, external_data_file)))\n\n        model = onnx.load_model(model_file_path)\n\n        # test convert model from external data\n        convert_model_from_external_data(model)\n        model_file_path = self.get_temp_model_filename()\n        onnx.save_model(model, model_file_path)\n        model = onnx.load_model(model_file_path)\n        initializer_tensor = model.graph.initializer[0]\n        self.assertFalse(len(initializer_tensor.external_data))\n        self.assertEqual(initializer_tensor.data_location, TensorProto.DEFAULT)\n        self.assertTrue(np.allclose(to_array(initializer_tensor), self.initializer_value))\n\n        attribute_tensor = model.graph.node[0].attribute[0].t\n        self.assertFalse(len(attribute_tensor.external_data))\n        self.assertEqual(attribute_tensor.data_location, TensorProto.DEFAULT)\n        self.assertTrue(np.allclose(to_array(attribute_tensor), self.attribute_value))\n\n    def test_convert_model_to_external_data_from_one_file_without_location_uses_model_name(self) -> None:\n        model_file_path = self.get_temp_model_filename()\n\n        convert_model_to_external_data(self.model, size_threshold=0, all_tensors_to_one_file=True)\n        onnx.save_model(self.model, model_file_path)\n\n        self.assertTrue(Path.isfile(model_file_path))\n        self.assertTrue(Path.isfile(os.path.join(self.temp_dir, model_file_path)))\n\n    def test_convert_model_to_external_data_one_file_per_tensor_without_attribute(self) -> None:\n        model_file_path = self.get_temp_model_filename()\n\n        convert_model_to_external_data(self.model, size_threshold=0, all_tensors_to_one_file=False,\n                                       convert_attribute=False)\n        onnx.save_model(self.model, model_file_path)\n\n        self.assertTrue(Path.isfile(model_file_path))\n        self.assertTrue(Path.isfile(os.path.join(self.temp_dir, \"input_value\")))\n        self.assertFalse(Path.isfile(os.path.join(self.temp_dir, \"attribute_value\")))\n\n    def test_convert_model_to_external_data_one_file_per_tensor_with_attribute(self) -> None:\n        model_file_path = self.get_temp_model_filename()\n\n        convert_model_to_external_data(self.model, size_threshold=0, all_tensors_to_one_file=False,\n                                       convert_attribute=True)\n        onnx.save_model(self.model, model_file_path)\n\n        self.assertTrue(Path.isfile(model_file_path))\n        self.assertTrue(Path.isfile(os.path.join(self.temp_dir, \"input_value\")))\n        self.assertTrue(Path.isfile(os.path.join(self.temp_dir, \"attribute_value\")))\n\n    def test_convert_model_to_external_data_does_not_convert_attribute_values(self) -> None:\n        model_file_path = self.get_temp_model_filename()\n\n        convert_model_to_external_data(self.model, size_threshold=0, convert_attribute=False,\n                                       all_tensors_to_one_file=False)\n        onnx.save_model(self.model, model_file_path)\n\n        self.assertTrue(Path.isfile(os.path.join(self.temp_dir, \"input_value\")))\n        self.assertFalse(Path.isfile(os.path.join(self.temp_dir, \"attribute_value\")))\n\n        model = onnx.load_model(model_file_path)\n        initializer_tensor = model.graph.initializer[0]\n        self.assertTrue(initializer_tensor.HasField(\"data_location\"))\n\n        attribute_tensor = model.graph.node[0].attribute[0].t\n        self.assertFalse(attribute_tensor.HasField(\"data_location\"))\n\n    def test_convert_model_to_external_data_converts_attribute_values(self) -> None:\n        model_file_path = self.get_temp_model_filename()\n\n        convert_model_to_external_data(self.model, size_threshold=0, convert_attribute=True)\n        onnx.save_model(self.model, model_file_path)\n\n        model = onnx.load_model(model_file_path)\n\n        initializer_tensor = model.graph.initializer[0]\n        self.assertTrue(np.allclose(to_array(initializer_tensor), self.initializer_value))\n        self.assertTrue(initializer_tensor.HasField(\"data_location\"))\n\n        attribute_tensor = model.graph.node[0].attribute[0].t\n        self.assertTrue(np.allclose(to_array(attribute_tensor), self.attribute_value))\n        self.assertTrue(attribute_tensor.HasField(\"data_location\"))\n\n    def test_save_model_does_not_convert_to_external_data_and_saves_the_model(self) -> None:\n        model_file_path = self.get_temp_model_filename()\n        onnx.save_model(self.model, model_file_path, save_as_external_data=False)\n        self.assertTrue(Path.isfile(model_file_path))\n\n        model = onnx.load_model(model_file_path)\n        initializer_tensor = model.graph.initializer[0]\n        self.assertFalse(initializer_tensor.HasField(\"data_location\"))\n\n        attribute_tensor = model.graph.node[0].attribute[0].t\n        self.assertFalse(attribute_tensor.HasField(\"data_location\"))\n\n    def test_save_model_does_convert_and_saves_the_model(self) -> None:\n        model_file_path = self.get_temp_model_filename()\n        onnx.save_model(self.model,\n                        model_file_path,\n                        save_as_external_data=True,\n                        all_tensors_to_one_file=True,\n                        location=None,\n                        size_threshold=0,\n                        convert_attribute=False)\n\n        model = onnx.load_model(model_file_path)\n\n        initializer_tensor = model.graph.initializer[0]\n        self.assertTrue(initializer_tensor.HasField(\"data_location\"))\n        self.assertTrue(np.allclose(to_array(initializer_tensor), self.initializer_value))\n\n        attribute_tensor = model.graph.node[0].attribute[0].t\n        self.assertFalse(attribute_tensor.HasField(\"data_location\"))\n        self.assertTrue(np.allclose(to_array(attribute_tensor), self.attribute_value))\n\n    def test_save_model_without_loading_external_data(self) -> None:\n        model_file_path = self.get_temp_model_filename()\n        onnx.save_model(self.model,\n                        model_file_path,\n                        save_as_external_data=True,\n                        location=None,\n                        size_threshold=0,\n                        convert_attribute=False)\n        # Save without load_external_data\n        model = onnx.load_model(model_file_path, load_external_data=False)\n        onnx.save_model(model,\n                        model_file_path,\n                        save_as_external_data=True,\n                        location=None,\n                        size_threshold=0,\n                        convert_attribute=False)\n        # Load the saved model again; Only works if the saved path is under the same directory\n        model = onnx.load_model(model_file_path)\n\n        initializer_tensor = model.graph.initializer[0]\n        self.assertTrue(initializer_tensor.HasField(\"data_location\"))\n        self.assertTrue(np.allclose(to_array(initializer_tensor), self.initializer_value))\n\n        attribute_tensor = model.graph.node[0].attribute[0].t\n        self.assertFalse(attribute_tensor.HasField(\"data_location\"))\n        self.assertTrue(np.allclose(to_array(attribute_tensor), self.attribute_value))\n\n    def test_save_model_with_existing_raw_data_should_override(self) -> None:\n        model_file_path = self.get_temp_model_filename()\n        original_raw_data = self.model.graph.initializer[0].raw_data\n        onnx.save_model(self.model, model_file_path, save_as_external_data=True, size_threshold=0)\n        self.assertTrue(Path.isfile(model_file_path))\n\n        model = onnx.load_model(model_file_path, load_external_data=False)\n        initializer_tensor = model.graph.initializer[0]\n        initializer_tensor.raw_data = b'dummpy_raw_data'\n        # If raw_data and external tensor exist at the same time, override existing raw_data\n        load_external_data_for_tensor(initializer_tensor, self.temp_dir)\n        self.assertEqual(initializer_tensor.raw_data, original_raw_data)\n\n\nclass TestExternalDataToArray(unittest.TestCase):\n    def setUp(self) -> None:\n        self.temp_dir: str = tempfile.mkdtemp()\n        self.model_file_path: str = os.path.join(self.temp_dir, 'model.onnx')\n        self.large_data = np.random.rand(10, 60, 100).astype(np.float32)\n        self.small_data = (200, 300)\n        self.model = self.create_test_model()\n\n    def tearDown(self) -> None:\n        shutil.rmtree(self.temp_dir)\n\n    def get_temp_model_filename(self) -> str:\n        return os.path.join(self.temp_dir, str(uuid.uuid4()) + '.onnx')\n\n    def create_test_model(self) -> ModelProto:\n        X = helper.make_tensor_value_info('X', TensorProto.FLOAT, self.large_data.shape)\n        input_init = helper.make_tensor(name='X', data_type=TensorProto.FLOAT,\n                                        dims=self.large_data.shape, vals=self.large_data.tobytes(), raw=True)\n\n        shape_data = np.array(self.small_data, np.int64)\n        shape_init = helper.make_tensor(name='Shape', data_type=TensorProto.INT64,\n                                        dims=shape_data.shape, vals=shape_data.tobytes(), raw=True)\n        C = helper.make_tensor_value_info('C', TensorProto.INT64, self.small_data)\n\n        reshape = onnx.helper.make_node(\n            'Reshape',\n            inputs=['X', 'Shape'],\n            outputs=['Y'],\n        )\n        cast = onnx.helper.make_node(\n            'Cast',\n            inputs=['Y'],\n            outputs=['C'],\n            to=getattr(TensorProto, 'INT64')\n        )\n\n        graph_def = helper.make_graph(\n            [reshape, cast],\n            'test-model',\n            [X],\n            [C],\n            initializer=[input_init, shape_init],\n        )\n        model = helper.make_model(graph_def, producer_name='onnx-example')\n        return model\n\n    def test_check_model(self) -> None:\n        checker.check_model(self.model)\n\n    def test_reshape_inference_with_external_data_fail(self) -> None:\n        onnx.save_model(self.model, self.model_file_path, save_as_external_data=True, all_tensors_to_one_file=False,\n                        size_threshold=0)\n        model_without_external_data = onnx.load(self.model_file_path, load_external_data=False)\n        # Shape inference of Reshape uses ParseData\n        # ParseData cannot handle external data and should throw the error as follows:\n        # Cannot parse data from external tensors. Please load external data into raw data for tensor: Shape\n        self.assertRaises(shape_inference.InferenceError, shape_inference.infer_shapes,\n                          model_without_external_data, strict_mode=True)\n\n    def test_to_array_with_external_data(self) -> None:\n        onnx.save_model(self.model,\n                        self.model_file_path,\n                        save_as_external_data=True,\n                        all_tensors_to_one_file=False,\n                        size_threshold=0)\n        # raw_data of external tensor is not loaded\n        model = onnx.load(self.model_file_path, load_external_data=False)\n        # Specify self.temp_dir to load external tensor\n        loaded_large_data = to_array(model.graph.initializer[0], self.temp_dir)\n        self.assertTrue(np.allclose(loaded_large_data, self.large_data))\n\n    def test_save_model_with_external_data_multiple_times(self) -> None:\n        # Test onnx.save should respectively handle typical tensor and external tensor properly\n        # 1st save: save two tensors which have raw_data\n        # Only w_large will be stored as external tensors since it's larger than 1024\n        onnx.save_model(self.model,\n                        self.model_file_path,\n                        save_as_external_data=True,\n                        all_tensors_to_one_file=False,\n                        location=None,\n                        size_threshold=1024,\n                        convert_attribute=True)\n        model_without_loading_external = onnx.load(self.model_file_path, load_external_data=False)\n        large_input_tensor = model_without_loading_external.graph.initializer[0]\n        self.assertTrue(large_input_tensor.HasField(\"data_location\"))\n        self.assertTrue(np.allclose(to_array(large_input_tensor, self.temp_dir), self.large_data))\n\n        small_shape_tensor = model_without_loading_external.graph.initializer[1]\n        self.assertTrue(not small_shape_tensor.HasField(\"data_location\"))\n        self.assertTrue(np.allclose(to_array(small_shape_tensor), self.small_data))\n\n        # 2nd save: one tensor has raw_data (small); one external tensor (large)\n        # Save them both as external tensors this time\n        onnx.save_model(model_without_loading_external,\n                        self.model_file_path,\n                        save_as_external_data=True,\n                        all_tensors_to_one_file=False,\n                        location=None,\n                        size_threshold=0,\n                        convert_attribute=True)\n\n        model_without_loading_external = onnx.load(self.model_file_path, load_external_data=False)\n        large_input_tensor = model_without_loading_external.graph.initializer[0]\n        self.assertTrue(large_input_tensor.HasField(\"data_location\"))\n        self.assertTrue(np.allclose(to_array(large_input_tensor, self.temp_dir), self.large_data))\n\n        small_shape_tensor = model_without_loading_external.graph.initializer[1]\n        self.assertTrue(small_shape_tensor.HasField(\"data_location\"))\n        self.assertTrue(np.allclose(to_array(small_shape_tensor, self.temp_dir), self.small_data))\n\n\nclass TestNotAllowToLoadExternalDataOutsideModelDirectory(TestLoadExternalDataBase):\n    \"\"\"Essential test to check that onnx (validate) C++ code will not allow to load external_data outside the model\n    directory. \"\"\"\n\n    def create_external_data_tensor(self, value: List[Any], tensor_name: str) -> TensorProto:\n        tensor = from_array(np.array(value))\n        tensor.name = tensor_name\n\n        set_external_data(tensor, location=\"../../file.bin\")\n\n        tensor.ClearField('raw_data')\n        tensor.data_location = onnx.TensorProto.EXTERNAL\n        return tensor\n\n    def test_check_model(self) -> None:\n        \"\"\"We only test the model validation as onnxruntime uses this to load the model. \"\"\"\n        with self.assertRaises(onnx.checker.ValidationError):\n            checker.check_model(self.model_filename)\n\n\n@pytest.mark.skipif(os.name != 'nt', reason='Skip Windows test')\nclass TestNotAllowToLoadExternalDataOutsideModelDirectoryOnWindows(TestLoadExternalDataBase):\n    \"\"\"Essential test to check that onnx (validate) C++ code will not allow to load external_data outside the model\n    directory. \"\"\"\n\n    def create_external_data_tensor(self, value: List[Any], tensor_name: str) -> TensorProto:\n        tensor = from_array(np.array(value))\n        tensor.name = tensor_name\n\n        set_external_data(tensor, location=\"..\\\\..\\\\file.bin\")\n\n        tensor.ClearField('raw_data')\n        tensor.data_location = onnx.TensorProto.EXTERNAL\n        return tensor\n\n    def test_check_model(self) -> None:\n        \"\"\"We only test the model validation as onnxruntime uses this to load the model. \"\"\"\n        with self.assertRaises(onnx.checker.ValidationError):\n            checker.check_model(self.model_filename)\n\n\nif __name__ == '__main__':\n    unittest.main()\n", "code_before": "# SPDX-License-Identifier: Apache-2.0\nimport tempfile\nimport unittest\nimport uuid\n\nimport numpy as np  # type: ignore\nimport shutil\n\nimport os\nimport os.path as Path\n\nimport onnx\nfrom onnx import checker, helper, shape_inference\nfrom onnx import ModelProto, TensorProto\nfrom onnx.external_data_helper import set_external_data\nfrom onnx.external_data_helper import convert_model_to_external_data\nfrom onnx.external_data_helper import convert_model_from_external_data\nfrom onnx.external_data_helper import load_external_data_for_model, load_external_data_for_tensor\nfrom onnx.numpy_helper import to_array, from_array\nfrom typing import Any, Tuple, List\nimport pytest  # type: ignore\nimport sys\n\n\nclass TestLoadExternalDataBase(unittest.TestCase):\n\n    def setUp(self) -> None:\n        self.temp_dir: str = tempfile.mkdtemp()\n        self.initializer_value = np.arange(6).reshape(3, 2).astype(np.float32) + 512\n        self.attribute_value = np.arange(6).reshape(2, 3).astype(np.float32) + 256\n        self.model_filename = self.create_test_model()\n\n    def tearDown(self) -> None:\n        shutil.rmtree(self.temp_dir)\n\n    def get_temp_model_filename(self) -> str:\n        return os.path.join(self.temp_dir, str(uuid.uuid4()) + '.onnx')\n\n    def create_external_data_tensor(self, value: List[Any], tensor_name: str) -> TensorProto:\n        tensor = from_array(np.array(value))\n        tensor.name = tensor_name\n        tensor_filename = f\"{tensor_name}.bin\"\n        set_external_data(tensor, location=tensor_filename)\n\n        with open(os.path.join(self.temp_dir, tensor_filename), 'wb') as data_file:\n            data_file.write(tensor.raw_data)\n        tensor.ClearField('raw_data')\n        tensor.data_location = onnx.TensorProto.EXTERNAL\n        return tensor\n\n    def create_test_model(self) -> str:\n\n        constant_node = onnx.helper.make_node(\n            'Constant',\n            inputs=[],\n            outputs=['values'],\n            value=self.create_external_data_tensor(self.attribute_value, \"attribute_value\")\n        )\n\n        initializers = [self.create_external_data_tensor(self.initializer_value, \"input_value\")]\n        inputs = [helper.make_tensor_value_info(\"input_value\",\n                                                onnx.TensorProto.FLOAT,\n                                                self.initializer_value.shape)]\n\n        graph = helper.make_graph([constant_node], \"test_graph\",\n                                  inputs=inputs, outputs=[],\n                                  initializer=initializers)\n        model = helper.make_model(graph)\n\n        model_filename = os.path.join(self.temp_dir, \"model.onnx\")\n        with open(model_filename, \"wb\") as model_file:\n            model_file.write(model.SerializeToString())\n\n        return model_filename\n\n    def test_check_model(self) -> None:\n        checker.check_model(self.model_filename)\n\n\nclass TestLoadExternalData(TestLoadExternalDataBase):\n\n    def test_load_external_data(self) -> None:\n        model = onnx.load_model(self.model_filename)\n        initializer_tensor = model.graph.initializer[0]\n        self.assertTrue(np.allclose(to_array(initializer_tensor), self.initializer_value))\n\n        attribute_tensor = model.graph.node[0].attribute[0].t\n        self.assertTrue(np.allclose(to_array(attribute_tensor), self.attribute_value))\n\n    def test_load_external_data_for_model(self) -> None:\n        model = onnx.load_model(self.model_filename, load_external_data=False)\n        load_external_data_for_model(model, self.temp_dir)\n        initializer_tensor = model.graph.initializer[0]\n        self.assertTrue(np.allclose(to_array(initializer_tensor), self.initializer_value))\n\n        attribute_tensor = model.graph.node[0].attribute[0].t\n        self.assertTrue(np.allclose(to_array(attribute_tensor), self.attribute_value))\n\n    def test_save_external_data(self) -> None:\n        model = onnx.load_model(self.model_filename)\n\n        temp_dir = os.path.join(self.temp_dir, \"save_copy\")\n        os.mkdir(temp_dir)\n        new_model_filename = os.path.join(temp_dir, 'model.onnx')\n        onnx.save_model(model, new_model_filename)\n\n        new_model = onnx.load_model(new_model_filename)\n        initializer_tensor = new_model.graph.initializer[0]\n        self.assertTrue(np.allclose(to_array(initializer_tensor), self.initializer_value))\n\n        attribute_tensor = new_model.graph.node[0].attribute[0].t\n        self.assertTrue(np.allclose(to_array(attribute_tensor), self.attribute_value))\n\n\nclass TestLoadExternalDataSingleFile(TestLoadExternalDataBase):\n\n    def create_external_data_tensors(self, tensors_data: List[Tuple[List[Any], Any]]) -> List[TensorProto]:\n        tensor_filename = \"tensors.bin\"\n        tensors = []\n\n        with open(os.path.join(self.temp_dir, tensor_filename), 'ab') as data_file:\n            for (value, tensor_name) in tensors_data:\n                tensor = from_array(np.array(value))\n                offset = data_file.tell()\n                if offset % 4096 != 0:\n                    data_file.write(b\"\\0\" * (4096 - offset % 4096))\n                    offset = offset + 4096 - offset % 4096\n\n                data_file.write(tensor.raw_data)\n                set_external_data(tensor, location=tensor_filename, offset=offset, length=data_file.tell() - offset)\n                tensor.name = tensor_name\n                tensor.ClearField(\"raw_data\")\n                tensor.data_location = onnx.TensorProto.EXTERNAL\n                tensors.append(tensor)\n\n        return tensors\n\n    def test_load_external_single_file_data(self) -> None:\n        model = onnx.load_model(self.model_filename)\n\n        initializer_tensor = model.graph.initializer[0]\n        self.assertTrue(np.allclose(to_array(initializer_tensor), self.initializer_value))\n\n        attribute_tensor = model.graph.node[0].attribute[0].t\n        self.assertTrue(np.allclose(to_array(attribute_tensor), self.attribute_value))\n\n    def test_save_external_single_file_data(self) -> None:\n        model = onnx.load_model(self.model_filename)\n\n        temp_dir = os.path.join(self.temp_dir, \"save_copy\")\n        os.mkdir(temp_dir)\n        new_model_filename = os.path.join(temp_dir, 'model.onnx')\n        onnx.save_model(model, new_model_filename)\n\n        new_model = onnx.load_model(new_model_filename)\n        initializer_tensor = new_model.graph.initializer[0]\n        self.assertTrue(np.allclose(to_array(initializer_tensor), self.initializer_value))\n\n        attribute_tensor = new_model.graph.node[0].attribute[0].t\n        self.assertTrue(np.allclose(to_array(attribute_tensor), self.attribute_value))\n\n\nclass TestSaveAllTensorsAsExternalData(TestLoadExternalDataBase):\n\n    def setUp(self) -> None:\n        self.temp_dir: str = tempfile.mkdtemp()\n        self.initializer_value = np.arange(6).reshape(3, 2).astype(np.float32) + 512\n        self.attribute_value = np.arange(6).reshape(2, 3).astype(np.float32) + 256\n        self.model = self.create_test_model_proto()\n\n    def create_data_tensors(self, tensors_data: List[Tuple[List[Any], Any]]) -> List[TensorProto]:\n        tensors = []\n        for (value, tensor_name) in tensors_data:\n            tensor = from_array(np.array(value))\n            tensor.name = tensor_name\n            tensors.append(tensor)\n\n        return tensors\n\n    def create_test_model_proto(self) -> ModelProto:\n        tensors = self.create_data_tensors([\n            (self.attribute_value, \"attribute_value\"),\n            (self.initializer_value, \"input_value\"),\n        ])\n\n        constant_node = onnx.helper.make_node(\n            'Constant',\n            inputs=[],\n            outputs=['values'],\n            value=tensors[0]\n        )\n\n        inputs = [helper.make_tensor_value_info(\"input_value\",\n                                                onnx.TensorProto.FLOAT,\n                                                self.initializer_value.shape)]\n\n        graph = helper.make_graph([constant_node], \"test_graph\",\n                                  inputs=inputs, outputs=[],\n                                  initializer=[tensors[1]])\n        return helper.make_model(graph)\n\n    def test_check_model(self) -> None:\n        checker.check_model(self.model)\n\n    def test_convert_model_to_external_data_with_size_threshold(self) -> None:\n        model_file_path = self.get_temp_model_filename()\n\n        convert_model_to_external_data(self.model, size_threshold=1024)\n        onnx.save_model(self.model, model_file_path)\n\n        model = onnx.load_model(model_file_path)\n        initializer_tensor = model.graph.initializer[0]\n        self.assertFalse(initializer_tensor.HasField(\"data_location\"))\n\n    def test_convert_model_to_external_data_without_size_threshold(self) -> None:\n        model_file_path = self.get_temp_model_filename()\n        convert_model_to_external_data(self.model, size_threshold=0)\n        onnx.save_model(self.model, model_file_path)\n\n        model = onnx.load_model(model_file_path)\n        initializer_tensor = model.graph.initializer[0]\n        self.assertTrue(initializer_tensor.HasField(\"data_location\"))\n        self.assertTrue(np.allclose(to_array(initializer_tensor), self.initializer_value))\n\n    def test_convert_model_to_external_data_from_one_file_with_location(self) -> None:\n        model_file_path = self.get_temp_model_filename()\n        external_data_file = str(uuid.uuid4())\n\n        convert_model_to_external_data(self.model, size_threshold=0, all_tensors_to_one_file=True, location=external_data_file)\n        onnx.save_model(self.model, model_file_path)\n\n        self.assertTrue(Path.isfile(os.path.join(self.temp_dir, external_data_file)))\n\n        model = onnx.load_model(model_file_path)\n\n        # test convert model from external data\n        convert_model_from_external_data(model)\n        model_file_path = self.get_temp_model_filename()\n        onnx.save_model(model, model_file_path)\n        model = onnx.load_model(model_file_path)\n        initializer_tensor = model.graph.initializer[0]\n        self.assertFalse(len(initializer_tensor.external_data))\n        self.assertEqual(initializer_tensor.data_location, TensorProto.DEFAULT)\n        self.assertTrue(np.allclose(to_array(initializer_tensor), self.initializer_value))\n\n        attribute_tensor = model.graph.node[0].attribute[0].t\n        self.assertFalse(len(attribute_tensor.external_data))\n        self.assertEqual(attribute_tensor.data_location, TensorProto.DEFAULT)\n        self.assertTrue(np.allclose(to_array(attribute_tensor), self.attribute_value))\n\n    def test_convert_model_to_external_data_from_one_file_without_location_uses_model_name(self) -> None:\n        model_file_path = self.get_temp_model_filename()\n\n        convert_model_to_external_data(self.model, size_threshold=0, all_tensors_to_one_file=True)\n        onnx.save_model(self.model, model_file_path)\n\n        self.assertTrue(Path.isfile(model_file_path))\n        self.assertTrue(Path.isfile(os.path.join(self.temp_dir, model_file_path)))\n\n    def test_convert_model_to_external_data_one_file_per_tensor_without_attribute(self) -> None:\n        model_file_path = self.get_temp_model_filename()\n\n        convert_model_to_external_data(self.model, size_threshold=0, all_tensors_to_one_file=False, convert_attribute=False)\n        onnx.save_model(self.model, model_file_path)\n\n        self.assertTrue(Path.isfile(model_file_path))\n        self.assertTrue(Path.isfile(os.path.join(self.temp_dir, \"input_value\")))\n        self.assertFalse(Path.isfile(os.path.join(self.temp_dir, \"attribute_value\")))\n\n    def test_convert_model_to_external_data_one_file_per_tensor_with_attribute(self) -> None:\n        model_file_path = self.get_temp_model_filename()\n\n        convert_model_to_external_data(self.model, size_threshold=0, all_tensors_to_one_file=False, convert_attribute=True)\n        onnx.save_model(self.model, model_file_path)\n\n        self.assertTrue(Path.isfile(model_file_path))\n        self.assertTrue(Path.isfile(os.path.join(self.temp_dir, \"input_value\")))\n        self.assertTrue(Path.isfile(os.path.join(self.temp_dir, \"attribute_value\")))\n\n    def test_convert_model_to_external_data_does_not_convert_attribute_values(self) -> None:\n        model_file_path = self.get_temp_model_filename()\n\n        convert_model_to_external_data(self.model, size_threshold=0, convert_attribute=False, all_tensors_to_one_file=False)\n        onnx.save_model(self.model, model_file_path)\n\n        self.assertTrue(Path.isfile(os.path.join(self.temp_dir, \"input_value\")))\n        self.assertFalse(Path.isfile(os.path.join(self.temp_dir, \"attribute_value\")))\n\n        model = onnx.load_model(model_file_path)\n        initializer_tensor = model.graph.initializer[0]\n        self.assertTrue(initializer_tensor.HasField(\"data_location\"))\n\n        attribute_tensor = model.graph.node[0].attribute[0].t\n        self.assertFalse(attribute_tensor.HasField(\"data_location\"))\n\n    def test_convert_model_to_external_data_converts_attribute_values(self) -> None:\n        model_file_path = self.get_temp_model_filename()\n\n        convert_model_to_external_data(self.model, size_threshold=0, convert_attribute=True)\n        onnx.save_model(self.model, model_file_path)\n\n        model = onnx.load_model(model_file_path)\n\n        initializer_tensor = model.graph.initializer[0]\n        self.assertTrue(np.allclose(to_array(initializer_tensor), self.initializer_value))\n        self.assertTrue(initializer_tensor.HasField(\"data_location\"))\n\n        attribute_tensor = model.graph.node[0].attribute[0].t\n        self.assertTrue(np.allclose(to_array(attribute_tensor), self.attribute_value))\n        self.assertTrue(attribute_tensor.HasField(\"data_location\"))\n\n    def test_save_model_does_not_convert_to_external_data_and_saves_the_model(self) -> None:\n        model_file_path = self.get_temp_model_filename()\n        onnx.save_model(self.model, model_file_path, save_as_external_data=False)\n        self.assertTrue(Path.isfile(model_file_path))\n\n        model = onnx.load_model(model_file_path)\n        initializer_tensor = model.graph.initializer[0]\n        self.assertFalse(initializer_tensor.HasField(\"data_location\"))\n\n        attribute_tensor = model.graph.node[0].attribute[0].t\n        self.assertFalse(attribute_tensor.HasField(\"data_location\"))\n\n    def test_save_model_does_convert_and_saves_the_model(self) -> None:\n        model_file_path = self.get_temp_model_filename()\n        onnx.save_model(self.model,\n                        model_file_path,\n                        save_as_external_data=True,\n                        all_tensors_to_one_file=True,\n                        location=None,\n                        size_threshold=0,\n                        convert_attribute=False)\n\n        model = onnx.load_model(model_file_path)\n\n        initializer_tensor = model.graph.initializer[0]\n        self.assertTrue(initializer_tensor.HasField(\"data_location\"))\n        self.assertTrue(np.allclose(to_array(initializer_tensor), self.initializer_value))\n\n        attribute_tensor = model.graph.node[0].attribute[0].t\n        self.assertFalse(attribute_tensor.HasField(\"data_location\"))\n        self.assertTrue(np.allclose(to_array(attribute_tensor), self.attribute_value))\n\n    def test_save_model_without_loading_external_data(self) -> None:\n        model_file_path = self.get_temp_model_filename()\n        onnx.save_model(self.model,\n                        model_file_path,\n                        save_as_external_data=True,\n                        location=None,\n                        size_threshold=0,\n                        convert_attribute=False)\n        # Save without load_external_data\n        model = onnx.load_model(model_file_path, load_external_data=False)\n        onnx.save_model(model,\n                        model_file_path,\n                        save_as_external_data=True,\n                        location=None,\n                        size_threshold=0,\n                        convert_attribute=False)\n        # Load the saved model again; Only works if the saved path is under the same directory\n        model = onnx.load_model(model_file_path)\n\n        initializer_tensor = model.graph.initializer[0]\n        self.assertTrue(initializer_tensor.HasField(\"data_location\"))\n        self.assertTrue(np.allclose(to_array(initializer_tensor), self.initializer_value))\n\n        attribute_tensor = model.graph.node[0].attribute[0].t\n        self.assertFalse(attribute_tensor.HasField(\"data_location\"))\n        self.assertTrue(np.allclose(to_array(attribute_tensor), self.attribute_value))\n\n    def test_save_model_with_existing_raw_data_should_override(self) -> None:\n        model_file_path = self.get_temp_model_filename()\n        original_raw_data = self.model.graph.initializer[0].raw_data\n        onnx.save_model(self.model, model_file_path, save_as_external_data=True, size_threshold=0)\n        self.assertTrue(Path.isfile(model_file_path))\n\n        model = onnx.load_model(model_file_path, load_external_data=False)\n        initializer_tensor = model.graph.initializer[0]\n        initializer_tensor.raw_data = b'dummpy_raw_data'\n        # If raw_data and external tensor exist at the same time, override existing raw_data\n        load_external_data_for_tensor(initializer_tensor, self.temp_dir)\n        self.assertEqual(initializer_tensor.raw_data, original_raw_data)\n\n\nclass TestExternalDataToArray(unittest.TestCase):\n    def setUp(self) -> None:\n        self.temp_dir: str = tempfile.mkdtemp()\n        self.model_file_path: str = os.path.join(self.temp_dir, 'model.onnx')\n        self.large_data = np.random.rand(10, 60, 100).astype(np.float32)\n        self.small_data = (200, 300)\n        self.model = self.create_test_model()\n\n    def tearDown(self) -> None:\n        shutil.rmtree(self.temp_dir)\n\n    def get_temp_model_filename(self) -> str:\n        return os.path.join(self.temp_dir, str(uuid.uuid4()) + '.onnx')\n\n    def create_test_model(self) -> ModelProto:\n        X = helper.make_tensor_value_info('X', TensorProto.FLOAT, self.large_data.shape)\n        input_init = helper.make_tensor(name='X', data_type=TensorProto.FLOAT,\n            dims=self.large_data.shape, vals=self.large_data.tobytes(), raw=True)\n\n        shape_data = np.array(self.small_data, np.int64)\n        shape_init = helper.make_tensor(name='Shape', data_type=TensorProto.INT64,\n            dims=shape_data.shape, vals=shape_data.tobytes(), raw=True)\n        C = helper.make_tensor_value_info('C', TensorProto.INT64, self.small_data)\n\n        reshape = onnx.helper.make_node(\n            'Reshape',\n            inputs=['X', 'Shape'],\n            outputs=['Y'],\n        )\n        cast = onnx.helper.make_node(\n            'Cast',\n            inputs=['Y'],\n            outputs=['C'],\n            to=getattr(TensorProto, 'INT64')\n        )\n\n        graph_def = helper.make_graph(\n            [reshape, cast],\n            'test-model',\n            [X],\n            [C],\n            initializer=[input_init, shape_init],\n        )\n        model = helper.make_model(graph_def, producer_name='onnx-example')\n        return model\n\n    def test_check_model(self) -> None:\n        checker.check_model(self.model)\n\n    def test_reshape_inference_with_external_data_fail(self) -> None:\n        onnx.save_model(self.model, self.model_file_path, save_as_external_data=True, all_tensors_to_one_file=False, size_threshold=0)\n        model_without_external_data = onnx.load(self.model_file_path, load_external_data=False)\n        # Shape inference of Reshape uses ParseData\n        # ParseData cannot handle external data and should throw the error as follows:\n        # Cannot parse data from external tensors. Please load external data into raw data for tensor: Shape\n        self.assertRaises(shape_inference.InferenceError, shape_inference.infer_shapes,\n            model_without_external_data, strict_mode=True)\n\n    def test_to_array_with_external_data(self) -> None:\n        onnx.save_model(self.model,\n                        self.model_file_path,\n                        save_as_external_data=True,\n                        all_tensors_to_one_file=False,\n                        size_threshold=0)\n        # raw_data of external tensor is not loaded\n        model = onnx.load(self.model_file_path, load_external_data=False)\n        # Specify self.temp_dir to load external tensor\n        loaded_large_data = to_array(model.graph.initializer[0], self.temp_dir)\n        self.assertTrue(np.allclose(loaded_large_data, self.large_data))\n\n    def test_save_model_with_external_data_multiple_times(self) -> None:\n        # Test onnx.save should respectively handle typical tensor and external tensor properly\n        # 1st save: save two tensors which have raw_data\n        # Only w_large will be stored as external tensors since it's larger than 1024\n        onnx.save_model(self.model,\n                        self.model_file_path,\n                        save_as_external_data=True,\n                        all_tensors_to_one_file=False,\n                        location=None,\n                        size_threshold=1024,\n                        convert_attribute=True)\n        model_without_loading_external = onnx.load(self.model_file_path, load_external_data=False)\n        large_input_tensor = model_without_loading_external.graph.initializer[0]\n        self.assertTrue(large_input_tensor.HasField(\"data_location\"))\n        self.assertTrue(np.allclose(to_array(large_input_tensor, self.temp_dir), self.large_data))\n\n        small_shape_tensor = model_without_loading_external.graph.initializer[1]\n        self.assertTrue(not small_shape_tensor.HasField(\"data_location\"))\n        self.assertTrue(np.allclose(to_array(small_shape_tensor), self.small_data))\n\n        # 2nd save: one tensor has raw_data (small); one external tensor (large)\n        # Save them both as external tensors this time\n        onnx.save_model(model_without_loading_external,\n                        self.model_file_path,\n                        save_as_external_data=True,\n                        all_tensors_to_one_file=False,\n                        location=None,\n                        size_threshold=0,\n                        convert_attribute=True)\n\n        model_without_loading_external = onnx.load(self.model_file_path, load_external_data=False)\n        large_input_tensor = model_without_loading_external.graph.initializer[0]\n        self.assertTrue(large_input_tensor.HasField(\"data_location\"))\n        self.assertTrue(np.allclose(to_array(large_input_tensor, self.temp_dir), self.large_data))\n\n        small_shape_tensor = model_without_loading_external.graph.initializer[1]\n        self.assertTrue(small_shape_tensor.HasField(\"data_location\"))\n        self.assertTrue(np.allclose(to_array(small_shape_tensor, self.temp_dir), self.small_data))\n\n\nif __name__ == '__main__':\n    unittest.main()\n", "patch": "@@ -49,7 +49,6 @@ def create_external_data_tensor(self, value: List[Any], tensor_name: str) -> Ten\n         return tensor\n \n     def create_test_model(self) -> str:\n-\n         constant_node = onnx.helper.make_node(\n             'Constant',\n             inputs=[],\n@@ -226,7 +225,8 @@ def test_convert_model_to_external_data_from_one_file_with_location(self) -> Non\n         model_file_path = self.get_temp_model_filename()\n         external_data_file = str(uuid.uuid4())\n \n-        convert_model_to_external_data(self.model, size_threshold=0, all_tensors_to_one_file=True, location=external_data_file)\n+        convert_model_to_external_data(self.model, size_threshold=0, all_tensors_to_one_file=True,\n+                                       location=external_data_file)\n         onnx.save_model(self.model, model_file_path)\n \n         self.assertTrue(Path.isfile(os.path.join(self.temp_dir, external_data_file)))\n@@ -260,7 +260,8 @@ def test_convert_model_to_external_data_from_one_file_without_location_uses_mode\n     def test_convert_model_to_external_data_one_file_per_tensor_without_attribute(self) -> None:\n         model_file_path = self.get_temp_model_filename()\n \n-        convert_model_to_external_data(self.model, size_threshold=0, all_tensors_to_one_file=False, convert_attribute=False)\n+        convert_model_to_external_data(self.model, size_threshold=0, all_tensors_to_one_file=False,\n+                                       convert_attribute=False)\n         onnx.save_model(self.model, model_file_path)\n \n         self.assertTrue(Path.isfile(model_file_path))\n@@ -270,7 +271,8 @@ def test_convert_model_to_external_data_one_file_per_tensor_without_attribute(se\n     def test_convert_model_to_external_data_one_file_per_tensor_with_attribute(self) -> None:\n         model_file_path = self.get_temp_model_filename()\n \n-        convert_model_to_external_data(self.model, size_threshold=0, all_tensors_to_one_file=False, convert_attribute=True)\n+        convert_model_to_external_data(self.model, size_threshold=0, all_tensors_to_one_file=False,\n+                                       convert_attribute=True)\n         onnx.save_model(self.model, model_file_path)\n \n         self.assertTrue(Path.isfile(model_file_path))\n@@ -280,7 +282,8 @@ def test_convert_model_to_external_data_one_file_per_tensor_with_attribute(self)\n     def test_convert_model_to_external_data_does_not_convert_attribute_values(self) -> None:\n         model_file_path = self.get_temp_model_filename()\n \n-        convert_model_to_external_data(self.model, size_threshold=0, convert_attribute=False, all_tensors_to_one_file=False)\n+        convert_model_to_external_data(self.model, size_threshold=0, convert_attribute=False,\n+                                       all_tensors_to_one_file=False)\n         onnx.save_model(self.model, model_file_path)\n \n         self.assertTrue(Path.isfile(os.path.join(self.temp_dir, \"input_value\")))\n@@ -399,11 +402,11 @@ def get_temp_model_filename(self) -> str:\n     def create_test_model(self) -> ModelProto:\n         X = helper.make_tensor_value_info('X', TensorProto.FLOAT, self.large_data.shape)\n         input_init = helper.make_tensor(name='X', data_type=TensorProto.FLOAT,\n-            dims=self.large_data.shape, vals=self.large_data.tobytes(), raw=True)\n+                                        dims=self.large_data.shape, vals=self.large_data.tobytes(), raw=True)\n \n         shape_data = np.array(self.small_data, np.int64)\n         shape_init = helper.make_tensor(name='Shape', data_type=TensorProto.INT64,\n-            dims=shape_data.shape, vals=shape_data.tobytes(), raw=True)\n+                                        dims=shape_data.shape, vals=shape_data.tobytes(), raw=True)\n         C = helper.make_tensor_value_info('C', TensorProto.INT64, self.small_data)\n \n         reshape = onnx.helper.make_node(\n@@ -432,13 +435,14 @@ def test_check_model(self) -> None:\n         checker.check_model(self.model)\n \n     def test_reshape_inference_with_external_data_fail(self) -> None:\n-        onnx.save_model(self.model, self.model_file_path, save_as_external_data=True, all_tensors_to_one_file=False, size_threshold=0)\n+        onnx.save_model(self.model, self.model_file_path, save_as_external_data=True, all_tensors_to_one_file=False,\n+                        size_threshold=0)\n         model_without_external_data = onnx.load(self.model_file_path, load_external_data=False)\n         # Shape inference of Reshape uses ParseData\n         # ParseData cannot handle external data and should throw the error as follows:\n         # Cannot parse data from external tensors. Please load external data into raw data for tensor: Shape\n         self.assertRaises(shape_inference.InferenceError, shape_inference.infer_shapes,\n-            model_without_external_data, strict_mode=True)\n+                          model_without_external_data, strict_mode=True)\n \n     def test_to_array_with_external_data(self) -> None:\n         onnx.save_model(self.model,\n@@ -492,5 +496,46 @@ def test_save_model_with_external_data_multiple_times(self) -> None:\n         self.assertTrue(np.allclose(to_array(small_shape_tensor, self.temp_dir), self.small_data))\n \n \n+class TestNotAllowToLoadExternalDataOutsideModelDirectory(TestLoadExternalDataBase):\n+    \"\"\"Essential test to check that onnx (validate) C++ code will not allow to load external_data outside the model\n+    directory. \"\"\"\n+\n+    def create_external_data_tensor(self, value: List[Any], tensor_name: str) -> TensorProto:\n+        tensor = from_array(np.array(value))\n+        tensor.name = tensor_name\n+\n+        set_external_data(tensor, location=\"../../file.bin\")\n+\n+        tensor.ClearField('raw_data')\n+        tensor.data_location = onnx.TensorProto.EXTERNAL\n+        return tensor\n+\n+    def test_check_model(self) -> None:\n+        \"\"\"We only test the model validation as onnxruntime uses this to load the model. \"\"\"\n+        with self.assertRaises(onnx.checker.ValidationError):\n+            checker.check_model(self.model_filename)\n+\n+\n+@pytest.mark.skipif(os.name != 'nt', reason='Skip Windows test')\n+class TestNotAllowToLoadExternalDataOutsideModelDirectoryOnWindows(TestLoadExternalDataBase):\n+    \"\"\"Essential test to check that onnx (validate) C++ code will not allow to load external_data outside the model\n+    directory. \"\"\"\n+\n+    def create_external_data_tensor(self, value: List[Any], tensor_name: str) -> TensorProto:\n+        tensor = from_array(np.array(value))\n+        tensor.name = tensor_name\n+\n+        set_external_data(tensor, location=\"..\\\\..\\\\file.bin\")\n+\n+        tensor.ClearField('raw_data')\n+        tensor.data_location = onnx.TensorProto.EXTERNAL\n+        return tensor\n+\n+    def test_check_model(self) -> None:\n+        \"\"\"We only test the model validation as onnxruntime uses this to load the model. \"\"\"\n+        with self.assertRaises(onnx.checker.ValidationError):\n+            checker.check_model(self.model_filename)\n+\n+\n if __name__ == '__main__':\n     unittest.main()", "file_path": "files/2023_1/704", "file_language": "py", "file_name": "onnx/test/test_external_data.py", "outdated_file_modify": 0, "outdated_file_before": 0, "outdated_file_after": 0, "llm_check": 0, "static_check": 0, "static": {"rats": [false, []], "semgrep": [false, []]}, "target": 0, "function_before": [{"function": "class TestLoadExternalDataBase(unittest.TestCase):\n\n    def setUp(self) -> None:\n        self.temp_dir: str = tempfile.mkdtemp()\n        self.initializer_value = np.arange(6).reshape(3, 2).astype(np.float32) + 512\n        self.attribute_value = np.arange(6).reshape(2, 3).astype(np.float32) + 256\n        self.model_filename = self.create_test_model()\n\n    def tearDown(self) -> None:\n        shutil.rmtree(self.temp_dir)\n\n    def get_temp_model_filename(self) -> str:\n        return os.path.join(self.temp_dir, str(uuid.uuid4()) + '.onnx')\n\n    def create_external_data_tensor(self, value: List[Any], tensor_name: str) -> TensorProto:\n        tensor = from_array(np.array(value))\n        tensor.name = tensor_name\n        tensor_filename = f\"{tensor_name}.bin\"\n        set_external_data(tensor, location=tensor_filename)\n\n        with open(os.path.join(self.temp_dir, tensor_filename), 'wb') as data_file:\n            data_file.write(tensor.raw_data)\n        tensor.ClearField('raw_data')\n        tensor.data_location = onnx.TensorProto.EXTERNAL\n        return tensor\n\n    def create_test_model(self) -> str:\n\n        constant_node = onnx.helper.make_node(\n            'Constant',\n            inputs=[],\n            outputs=['values'],\n            value=self.create_external_data_tensor(self.attribute_value, \"attribute_value\")\n        )\n\n        initializers = [self.create_external_data_tensor(self.initializer_value, \"input_value\")]\n        inputs = [helper.make_tensor_value_info(\"input_value\",\n                                                onnx.TensorProto.FLOAT,\n                                                self.initializer_value.shape)]\n\n        graph = helper.make_graph([constant_node], \"test_graph\",\n                                  inputs=inputs, outputs=[],\n                                  initializer=initializers)\n        model = helper.make_model(graph)\n\n        model_filename = os.path.join(self.temp_dir, \"model.onnx\")\n        with open(model_filename, \"wb\") as model_file:\n            model_file.write(model.SerializeToString())\n\n        return model_filename\n\n    def test_check_model(self) -> None:\n        checker.check_model(self.model_filename)", "target": 0}, {"function": "class TestLoadExternalData(TestLoadExternalDataBase):\n\n    def test_load_external_data(self) -> None:\n        model = onnx.load_model(self.model_filename)\n        initializer_tensor = model.graph.initializer[0]\n        self.assertTrue(np.allclose(to_array(initializer_tensor), self.initializer_value))\n\n        attribute_tensor = model.graph.node[0].attribute[0].t\n        self.assertTrue(np.allclose(to_array(attribute_tensor), self.attribute_value))\n\n    def test_load_external_data_for_model(self) -> None:\n        model = onnx.load_model(self.model_filename, load_external_data=False)\n        load_external_data_for_model(model, self.temp_dir)\n        initializer_tensor = model.graph.initializer[0]\n        self.assertTrue(np.allclose(to_array(initializer_tensor), self.initializer_value))\n\n        attribute_tensor = model.graph.node[0].attribute[0].t\n        self.assertTrue(np.allclose(to_array(attribute_tensor), self.attribute_value))\n\n    def test_save_external_data(self) -> None:\n        model = onnx.load_model(self.model_filename)\n\n        temp_dir = os.path.join(self.temp_dir, \"save_copy\")\n        os.mkdir(temp_dir)\n        new_model_filename = os.path.join(temp_dir, 'model.onnx')\n        onnx.save_model(model, new_model_filename)\n\n        new_model = onnx.load_model(new_model_filename)\n        initializer_tensor = new_model.graph.initializer[0]\n        self.assertTrue(np.allclose(to_array(initializer_tensor), self.initializer_value))\n\n        attribute_tensor = new_model.graph.node[0].attribute[0].t\n        self.assertTrue(np.allclose(to_array(attribute_tensor), self.attribute_value))", "target": 0}, {"function": "class TestLoadExternalDataSingleFile(TestLoadExternalDataBase):\n\n    def create_external_data_tensors(self, tensors_data: List[Tuple[List[Any], Any]]) -> List[TensorProto]:\n        tensor_filename = \"tensors.bin\"\n        tensors = []\n\n        with open(os.path.join(self.temp_dir, tensor_filename), 'ab') as data_file:\n            for (value, tensor_name) in tensors_data:\n                tensor = from_array(np.array(value))\n                offset = data_file.tell()\n                if offset % 4096 != 0:\n                    data_file.write(b\"\\0\" * (4096 - offset % 4096))\n                    offset = offset + 4096 - offset % 4096\n\n                data_file.write(tensor.raw_data)\n                set_external_data(tensor, location=tensor_filename, offset=offset, length=data_file.tell() - offset)\n                tensor.name = tensor_name\n                tensor.ClearField(\"raw_data\")\n                tensor.data_location = onnx.TensorProto.EXTERNAL\n                tensors.append(tensor)\n\n        return tensors\n\n    def test_load_external_single_file_data(self) -> None:\n        model = onnx.load_model(self.model_filename)\n\n        initializer_tensor = model.graph.initializer[0]\n        self.assertTrue(np.allclose(to_array(initializer_tensor), self.initializer_value))\n\n        attribute_tensor = model.graph.node[0].attribute[0].t\n        self.assertTrue(np.allclose(to_array(attribute_tensor), self.attribute_value))\n\n    def test_save_external_single_file_data(self) -> None:\n        model = onnx.load_model(self.model_filename)\n\n        temp_dir = os.path.join(self.temp_dir, \"save_copy\")\n        os.mkdir(temp_dir)\n        new_model_filename = os.path.join(temp_dir, 'model.onnx')\n        onnx.save_model(model, new_model_filename)\n\n        new_model = onnx.load_model(new_model_filename)\n        initializer_tensor = new_model.graph.initializer[0]\n        self.assertTrue(np.allclose(to_array(initializer_tensor), self.initializer_value))\n\n        attribute_tensor = new_model.graph.node[0].attribute[0].t\n        self.assertTrue(np.allclose(to_array(attribute_tensor), self.attribute_value))", "target": 0}, {"function": "class TestSaveAllTensorsAsExternalData(TestLoadExternalDataBase):\n\n    def setUp(self) -> None:\n        self.temp_dir: str = tempfile.mkdtemp()\n        self.initializer_value = np.arange(6).reshape(3, 2).astype(np.float32) + 512\n        self.attribute_value = np.arange(6).reshape(2, 3).astype(np.float32) + 256\n        self.model = self.create_test_model_proto()\n\n    def create_data_tensors(self, tensors_data: List[Tuple[List[Any], Any]]) -> List[TensorProto]:\n        tensors = []\n        for (value, tensor_name) in tensors_data:\n            tensor = from_array(np.array(value))\n            tensor.name = tensor_name\n            tensors.append(tensor)\n\n        return tensors\n\n    def create_test_model_proto(self) -> ModelProto:\n        tensors = self.create_data_tensors([\n            (self.attribute_value, \"attribute_value\"),\n            (self.initializer_value, \"input_value\"),\n        ])\n\n        constant_node = onnx.helper.make_node(\n            'Constant',\n            inputs=[],\n            outputs=['values'],\n            value=tensors[0]\n        )\n\n        inputs = [helper.make_tensor_value_info(\"input_value\",\n                                                onnx.TensorProto.FLOAT,\n                                                self.initializer_value.shape)]\n\n        graph = helper.make_graph([constant_node], \"test_graph\",\n                                  inputs=inputs, outputs=[],\n                                  initializer=[tensors[1]])\n        return helper.make_model(graph)\n\n    def test_check_model(self) -> None:\n        checker.check_model(self.model)\n\n    def test_convert_model_to_external_data_with_size_threshold(self) -> None:\n        model_file_path = self.get_temp_model_filename()\n\n        convert_model_to_external_data(self.model, size_threshold=1024)\n        onnx.save_model(self.model, model_file_path)\n\n        model = onnx.load_model(model_file_path)\n        initializer_tensor = model.graph.initializer[0]\n        self.assertFalse(initializer_tensor.HasField(\"data_location\"))\n\n    def test_convert_model_to_external_data_without_size_threshold(self) -> None:\n        model_file_path = self.get_temp_model_filename()\n        convert_model_to_external_data(self.model, size_threshold=0)\n        onnx.save_model(self.model, model_file_path)\n\n        model = onnx.load_model(model_file_path)\n        initializer_tensor = model.graph.initializer[0]\n        self.assertTrue(initializer_tensor.HasField(\"data_location\"))\n        self.assertTrue(np.allclose(to_array(initializer_tensor), self.initializer_value))\n\n    def test_convert_model_to_external_data_from_one_file_with_location(self) -> None:\n        model_file_path = self.get_temp_model_filename()\n        external_data_file = str(uuid.uuid4())\n\n        convert_model_to_external_data(self.model, size_threshold=0, all_tensors_to_one_file=True, location=external_data_file)\n        onnx.save_model(self.model, model_file_path)\n\n        self.assertTrue(Path.isfile(os.path.join(self.temp_dir, external_data_file)))\n\n        model = onnx.load_model(model_file_path)\n\n        # test convert model from external data\n        convert_model_from_external_data(model)\n        model_file_path = self.get_temp_model_filename()\n        onnx.save_model(model, model_file_path)\n        model = onnx.load_model(model_file_path)\n        initializer_tensor = model.graph.initializer[0]\n        self.assertFalse(len(initializer_tensor.external_data))\n        self.assertEqual(initializer_tensor.data_location, TensorProto.DEFAULT)\n        self.assertTrue(np.allclose(to_array(initializer_tensor), self.initializer_value))\n\n        attribute_tensor = model.graph.node[0].attribute[0].t\n        self.assertFalse(len(attribute_tensor.external_data))\n        self.assertEqual(attribute_tensor.data_location, TensorProto.DEFAULT)\n        self.assertTrue(np.allclose(to_array(attribute_tensor), self.attribute_value))\n\n    def test_convert_model_to_external_data_from_one_file_without_location_uses_model_name(self) -> None:\n        model_file_path = self.get_temp_model_filename()\n\n        convert_model_to_external_data(self.model, size_threshold=0, all_tensors_to_one_file=True)\n        onnx.save_model(self.model, model_file_path)\n\n        self.assertTrue(Path.isfile(model_file_path))\n        self.assertTrue(Path.isfile(os.path.join(self.temp_dir, model_file_path)))\n\n    def test_convert_model_to_external_data_one_file_per_tensor_without_attribute(self) -> None:\n        model_file_path = self.get_temp_model_filename()\n\n        convert_model_to_external_data(self.model, size_threshold=0, all_tensors_to_one_file=False, convert_attribute=False)\n        onnx.save_model(self.model, model_file_path)\n\n        self.assertTrue(Path.isfile(model_file_path))\n        self.assertTrue(Path.isfile(os.path.join(self.temp_dir, \"input_value\")))\n        self.assertFalse(Path.isfile(os.path.join(self.temp_dir, \"attribute_value\")))\n\n    def test_convert_model_to_external_data_one_file_per_tensor_with_attribute(self) -> None:\n        model_file_path = self.get_temp_model_filename()\n\n        convert_model_to_external_data(self.model, size_threshold=0, all_tensors_to_one_file=False, convert_attribute=True)\n        onnx.save_model(self.model, model_file_path)\n\n        self.assertTrue(Path.isfile(model_file_path))\n        self.assertTrue(Path.isfile(os.path.join(self.temp_dir, \"input_value\")))\n        self.assertTrue(Path.isfile(os.path.join(self.temp_dir, \"attribute_value\")))\n\n    def test_convert_model_to_external_data_does_not_convert_attribute_values(self) -> None:\n        model_file_path = self.get_temp_model_filename()\n\n        convert_model_to_external_data(self.model, size_threshold=0, convert_attribute=False, all_tensors_to_one_file=False)\n        onnx.save_model(self.model, model_file_path)\n\n        self.assertTrue(Path.isfile(os.path.join(self.temp_dir, \"input_value\")))\n        self.assertFalse(Path.isfile(os.path.join(self.temp_dir, \"attribute_value\")))\n\n        model = onnx.load_model(model_file_path)\n        initializer_tensor = model.graph.initializer[0]\n        self.assertTrue(initializer_tensor.HasField(\"data_location\"))\n\n        attribute_tensor = model.graph.node[0].attribute[0].t\n        self.assertFalse(attribute_tensor.HasField(\"data_location\"))\n\n    def test_convert_model_to_external_data_converts_attribute_values(self) -> None:\n        model_file_path = self.get_temp_model_filename()\n\n        convert_model_to_external_data(self.model, size_threshold=0, convert_attribute=True)\n        onnx.save_model(self.model, model_file_path)\n\n        model = onnx.load_model(model_file_path)\n\n        initializer_tensor = model.graph.initializer[0]\n        self.assertTrue(np.allclose(to_array(initializer_tensor), self.initializer_value))\n        self.assertTrue(initializer_tensor.HasField(\"data_location\"))\n\n        attribute_tensor = model.graph.node[0].attribute[0].t\n        self.assertTrue(np.allclose(to_array(attribute_tensor), self.attribute_value))\n        self.assertTrue(attribute_tensor.HasField(\"data_location\"))\n\n    def test_save_model_does_not_convert_to_external_data_and_saves_the_model(self) -> None:\n        model_file_path = self.get_temp_model_filename()\n        onnx.save_model(self.model, model_file_path, save_as_external_data=False)\n        self.assertTrue(Path.isfile(model_file_path))\n\n        model = onnx.load_model(model_file_path)\n        initializer_tensor = model.graph.initializer[0]\n        self.assertFalse(initializer_tensor.HasField(\"data_location\"))\n\n        attribute_tensor = model.graph.node[0].attribute[0].t\n        self.assertFalse(attribute_tensor.HasField(\"data_location\"))\n\n    def test_save_model_does_convert_and_saves_the_model(self) -> None:\n        model_file_path = self.get_temp_model_filename()\n        onnx.save_model(self.model,\n                        model_file_path,\n                        save_as_external_data=True,\n                        all_tensors_to_one_file=True,\n                        location=None,\n                        size_threshold=0,\n                        convert_attribute=False)\n\n        model = onnx.load_model(model_file_path)\n\n        initializer_tensor = model.graph.initializer[0]\n        self.assertTrue(initializer_tensor.HasField(\"data_location\"))\n        self.assertTrue(np.allclose(to_array(initializer_tensor), self.initializer_value))\n\n        attribute_tensor = model.graph.node[0].attribute[0].t\n        self.assertFalse(attribute_tensor.HasField(\"data_location\"))\n        self.assertTrue(np.allclose(to_array(attribute_tensor), self.attribute_value))\n\n    def test_save_model_without_loading_external_data(self) -> None:\n        model_file_path = self.get_temp_model_filename()\n        onnx.save_model(self.model,\n                        model_file_path,\n                        save_as_external_data=True,\n                        location=None,\n                        size_threshold=0,\n                        convert_attribute=False)\n        # Save without load_external_data\n        model = onnx.load_model(model_file_path, load_external_data=False)\n        onnx.save_model(model,\n                        model_file_path,\n                        save_as_external_data=True,\n                        location=None,\n                        size_threshold=0,\n                        convert_attribute=False)\n        # Load the saved model again; Only works if the saved path is under the same directory\n        model = onnx.load_model(model_file_path)\n\n        initializer_tensor = model.graph.initializer[0]\n        self.assertTrue(initializer_tensor.HasField(\"data_location\"))\n        self.assertTrue(np.allclose(to_array(initializer_tensor), self.initializer_value))\n\n        attribute_tensor = model.graph.node[0].attribute[0].t\n        self.assertFalse(attribute_tensor.HasField(\"data_location\"))\n        self.assertTrue(np.allclose(to_array(attribute_tensor), self.attribute_value))\n\n    def test_save_model_with_existing_raw_data_should_override(self) -> None:\n        model_file_path = self.get_temp_model_filename()\n        original_raw_data = self.model.graph.initializer[0].raw_data\n        onnx.save_model(self.model, model_file_path, save_as_external_data=True, size_threshold=0)\n        self.assertTrue(Path.isfile(model_file_path))\n\n        model = onnx.load_model(model_file_path, load_external_data=False)\n        initializer_tensor = model.graph.initializer[0]\n        initializer_tensor.raw_data = b'dummpy_raw_data'\n        # If raw_data and external tensor exist at the same time, override existing raw_data\n        load_external_data_for_tensor(initializer_tensor, self.temp_dir)\n        self.assertEqual(initializer_tensor.raw_data, original_raw_data)", "target": 0}, {"function": "class TestExternalDataToArray(unittest.TestCase):\n    def setUp(self) -> None:\n        self.temp_dir: str = tempfile.mkdtemp()\n        self.model_file_path: str = os.path.join(self.temp_dir, 'model.onnx')\n        self.large_data = np.random.rand(10, 60, 100).astype(np.float32)\n        self.small_data = (200, 300)\n        self.model = self.create_test_model()\n\n    def tearDown(self) -> None:\n        shutil.rmtree(self.temp_dir)\n\n    def get_temp_model_filename(self) -> str:\n        return os.path.join(self.temp_dir, str(uuid.uuid4()) + '.onnx')\n\n    def create_test_model(self) -> ModelProto:\n        X = helper.make_tensor_value_info('X', TensorProto.FLOAT, self.large_data.shape)\n        input_init = helper.make_tensor(name='X', data_type=TensorProto.FLOAT,\n            dims=self.large_data.shape, vals=self.large_data.tobytes(), raw=True)\n\n        shape_data = np.array(self.small_data, np.int64)\n        shape_init = helper.make_tensor(name='Shape', data_type=TensorProto.INT64,\n            dims=shape_data.shape, vals=shape_data.tobytes(), raw=True)\n        C = helper.make_tensor_value_info('C', TensorProto.INT64, self.small_data)\n\n        reshape = onnx.helper.make_node(\n            'Reshape',\n            inputs=['X', 'Shape'],\n            outputs=['Y'],\n        )\n        cast = onnx.helper.make_node(\n            'Cast',\n            inputs=['Y'],\n            outputs=['C'],\n            to=getattr(TensorProto, 'INT64')\n        )\n\n        graph_def = helper.make_graph(\n            [reshape, cast],\n            'test-model',\n            [X],\n            [C],\n            initializer=[input_init, shape_init],\n        )\n        model = helper.make_model(graph_def, producer_name='onnx-example')\n        return model\n\n    def test_check_model(self) -> None:\n        checker.check_model(self.model)\n\n    def test_reshape_inference_with_external_data_fail(self) -> None:\n        onnx.save_model(self.model, self.model_file_path, save_as_external_data=True, all_tensors_to_one_file=False, size_threshold=0)\n        model_without_external_data = onnx.load(self.model_file_path, load_external_data=False)\n        # Shape inference of Reshape uses ParseData\n        # ParseData cannot handle external data and should throw the error as follows:\n        # Cannot parse data from external tensors. Please load external data into raw data for tensor: Shape\n        self.assertRaises(shape_inference.InferenceError, shape_inference.infer_shapes,\n            model_without_external_data, strict_mode=True)\n\n    def test_to_array_with_external_data(self) -> None:\n        onnx.save_model(self.model,\n                        self.model_file_path,\n                        save_as_external_data=True,\n                        all_tensors_to_one_file=False,\n                        size_threshold=0)\n        # raw_data of external tensor is not loaded\n        model = onnx.load(self.model_file_path, load_external_data=False)\n        # Specify self.temp_dir to load external tensor\n        loaded_large_data = to_array(model.graph.initializer[0], self.temp_dir)\n        self.assertTrue(np.allclose(loaded_large_data, self.large_data))\n\n    def test_save_model_with_external_data_multiple_times(self) -> None:\n        # Test onnx.save should respectively handle typical tensor and external tensor properly\n        # 1st save: save two tensors which have raw_data\n        # Only w_large will be stored as external tensors since it's larger than 1024\n        onnx.save_model(self.model,\n                        self.model_file_path,\n                        save_as_external_data=True,\n                        all_tensors_to_one_file=False,\n                        location=None,\n                        size_threshold=1024,\n                        convert_attribute=True)\n        model_without_loading_external = onnx.load(self.model_file_path, load_external_data=False)\n        large_input_tensor = model_without_loading_external.graph.initializer[0]\n        self.assertTrue(large_input_tensor.HasField(\"data_location\"))\n        self.assertTrue(np.allclose(to_array(large_input_tensor, self.temp_dir), self.large_data))\n\n        small_shape_tensor = model_without_loading_external.graph.initializer[1]\n        self.assertTrue(not small_shape_tensor.HasField(\"data_location\"))\n        self.assertTrue(np.allclose(to_array(small_shape_tensor), self.small_data))\n\n        # 2nd save: one tensor has raw_data (small); one external tensor (large)\n        # Save them both as external tensors this time\n        onnx.save_model(model_without_loading_external,\n                        self.model_file_path,\n                        save_as_external_data=True,\n                        all_tensors_to_one_file=False,\n                        location=None,\n                        size_threshold=0,\n                        convert_attribute=True)\n\n        model_without_loading_external = onnx.load(self.model_file_path, load_external_data=False)\n        large_input_tensor = model_without_loading_external.graph.initializer[0]\n        self.assertTrue(large_input_tensor.HasField(\"data_location\"))\n        self.assertTrue(np.allclose(to_array(large_input_tensor, self.temp_dir), self.large_data))\n\n        small_shape_tensor = model_without_loading_external.graph.initializer[1]\n        self.assertTrue(small_shape_tensor.HasField(\"data_location\"))\n        self.assertTrue(np.allclose(to_array(small_shape_tensor, self.temp_dir), self.small_data))", "target": 0}], "function_after": [{"function": "class TestLoadExternalDataBase(unittest.TestCase):\n\n    def setUp(self) -> None:\n        self.temp_dir: str = tempfile.mkdtemp()\n        self.initializer_value = np.arange(6).reshape(3, 2).astype(np.float32) + 512\n        self.attribute_value = np.arange(6).reshape(2, 3).astype(np.float32) + 256\n        self.model_filename = self.create_test_model()\n\n    def tearDown(self) -> None:\n        shutil.rmtree(self.temp_dir)\n\n    def get_temp_model_filename(self) -> str:\n        return os.path.join(self.temp_dir, str(uuid.uuid4()) + '.onnx')\n\n    def create_external_data_tensor(self, value: List[Any], tensor_name: str) -> TensorProto:\n        tensor = from_array(np.array(value))\n        tensor.name = tensor_name\n        tensor_filename = f\"{tensor_name}.bin\"\n        set_external_data(tensor, location=tensor_filename)\n\n        with open(os.path.join(self.temp_dir, tensor_filename), 'wb') as data_file:\n            data_file.write(tensor.raw_data)\n        tensor.ClearField('raw_data')\n        tensor.data_location = onnx.TensorProto.EXTERNAL\n        return tensor\n\n    def create_test_model(self) -> str:\n        constant_node = onnx.helper.make_node(\n            'Constant',\n            inputs=[],\n            outputs=['values'],\n            value=self.create_external_data_tensor(self.attribute_value, \"attribute_value\")\n        )\n\n        initializers = [self.create_external_data_tensor(self.initializer_value, \"input_value\")]\n        inputs = [helper.make_tensor_value_info(\"input_value\",\n                                                onnx.TensorProto.FLOAT,\n                                                self.initializer_value.shape)]\n\n        graph = helper.make_graph([constant_node], \"test_graph\",\n                                  inputs=inputs, outputs=[],\n                                  initializer=initializers)\n        model = helper.make_model(graph)\n\n        model_filename = os.path.join(self.temp_dir, \"model.onnx\")\n        with open(model_filename, \"wb\") as model_file:\n            model_file.write(model.SerializeToString())\n\n        return model_filename\n\n    def test_check_model(self) -> None:\n        checker.check_model(self.model_filename)", "target": 0}, {"function": "class TestLoadExternalData(TestLoadExternalDataBase):\n\n    def test_load_external_data(self) -> None:\n        model = onnx.load_model(self.model_filename)\n        initializer_tensor = model.graph.initializer[0]\n        self.assertTrue(np.allclose(to_array(initializer_tensor), self.initializer_value))\n\n        attribute_tensor = model.graph.node[0].attribute[0].t\n        self.assertTrue(np.allclose(to_array(attribute_tensor), self.attribute_value))\n\n    def test_load_external_data_for_model(self) -> None:\n        model = onnx.load_model(self.model_filename, load_external_data=False)\n        load_external_data_for_model(model, self.temp_dir)\n        initializer_tensor = model.graph.initializer[0]\n        self.assertTrue(np.allclose(to_array(initializer_tensor), self.initializer_value))\n\n        attribute_tensor = model.graph.node[0].attribute[0].t\n        self.assertTrue(np.allclose(to_array(attribute_tensor), self.attribute_value))\n\n    def test_save_external_data(self) -> None:\n        model = onnx.load_model(self.model_filename)\n\n        temp_dir = os.path.join(self.temp_dir, \"save_copy\")\n        os.mkdir(temp_dir)\n        new_model_filename = os.path.join(temp_dir, 'model.onnx')\n        onnx.save_model(model, new_model_filename)\n\n        new_model = onnx.load_model(new_model_filename)\n        initializer_tensor = new_model.graph.initializer[0]\n        self.assertTrue(np.allclose(to_array(initializer_tensor), self.initializer_value))\n\n        attribute_tensor = new_model.graph.node[0].attribute[0].t\n        self.assertTrue(np.allclose(to_array(attribute_tensor), self.attribute_value))", "target": 0}, {"function": "class TestLoadExternalDataSingleFile(TestLoadExternalDataBase):\n\n    def create_external_data_tensors(self, tensors_data: List[Tuple[List[Any], Any]]) -> List[TensorProto]:\n        tensor_filename = \"tensors.bin\"\n        tensors = []\n\n        with open(os.path.join(self.temp_dir, tensor_filename), 'ab') as data_file:\n            for (value, tensor_name) in tensors_data:\n                tensor = from_array(np.array(value))\n                offset = data_file.tell()\n                if offset % 4096 != 0:\n                    data_file.write(b\"\\0\" * (4096 - offset % 4096))\n                    offset = offset + 4096 - offset % 4096\n\n                data_file.write(tensor.raw_data)\n                set_external_data(tensor, location=tensor_filename, offset=offset, length=data_file.tell() - offset)\n                tensor.name = tensor_name\n                tensor.ClearField(\"raw_data\")\n                tensor.data_location = onnx.TensorProto.EXTERNAL\n                tensors.append(tensor)\n\n        return tensors\n\n    def test_load_external_single_file_data(self) -> None:\n        model = onnx.load_model(self.model_filename)\n\n        initializer_tensor = model.graph.initializer[0]\n        self.assertTrue(np.allclose(to_array(initializer_tensor), self.initializer_value))\n\n        attribute_tensor = model.graph.node[0].attribute[0].t\n        self.assertTrue(np.allclose(to_array(attribute_tensor), self.attribute_value))\n\n    def test_save_external_single_file_data(self) -> None:\n        model = onnx.load_model(self.model_filename)\n\n        temp_dir = os.path.join(self.temp_dir, \"save_copy\")\n        os.mkdir(temp_dir)\n        new_model_filename = os.path.join(temp_dir, 'model.onnx')\n        onnx.save_model(model, new_model_filename)\n\n        new_model = onnx.load_model(new_model_filename)\n        initializer_tensor = new_model.graph.initializer[0]\n        self.assertTrue(np.allclose(to_array(initializer_tensor), self.initializer_value))\n\n        attribute_tensor = new_model.graph.node[0].attribute[0].t\n        self.assertTrue(np.allclose(to_array(attribute_tensor), self.attribute_value))", "target": 0}, {"function": "class TestSaveAllTensorsAsExternalData(TestLoadExternalDataBase):\n\n    def setUp(self) -> None:\n        self.temp_dir: str = tempfile.mkdtemp()\n        self.initializer_value = np.arange(6).reshape(3, 2).astype(np.float32) + 512\n        self.attribute_value = np.arange(6).reshape(2, 3).astype(np.float32) + 256\n        self.model = self.create_test_model_proto()\n\n    def create_data_tensors(self, tensors_data: List[Tuple[List[Any], Any]]) -> List[TensorProto]:\n        tensors = []\n        for (value, tensor_name) in tensors_data:\n            tensor = from_array(np.array(value))\n            tensor.name = tensor_name\n            tensors.append(tensor)\n\n        return tensors\n\n    def create_test_model_proto(self) -> ModelProto:\n        tensors = self.create_data_tensors([\n            (self.attribute_value, \"attribute_value\"),\n            (self.initializer_value, \"input_value\"),\n        ])\n\n        constant_node = onnx.helper.make_node(\n            'Constant',\n            inputs=[],\n            outputs=['values'],\n            value=tensors[0]\n        )\n\n        inputs = [helper.make_tensor_value_info(\"input_value\",\n                                                onnx.TensorProto.FLOAT,\n                                                self.initializer_value.shape)]\n\n        graph = helper.make_graph([constant_node], \"test_graph\",\n                                  inputs=inputs, outputs=[],\n                                  initializer=[tensors[1]])\n        return helper.make_model(graph)\n\n    def test_check_model(self) -> None:\n        checker.check_model(self.model)\n\n    def test_convert_model_to_external_data_with_size_threshold(self) -> None:\n        model_file_path = self.get_temp_model_filename()\n\n        convert_model_to_external_data(self.model, size_threshold=1024)\n        onnx.save_model(self.model, model_file_path)\n\n        model = onnx.load_model(model_file_path)\n        initializer_tensor = model.graph.initializer[0]\n        self.assertFalse(initializer_tensor.HasField(\"data_location\"))\n\n    def test_convert_model_to_external_data_without_size_threshold(self) -> None:\n        model_file_path = self.get_temp_model_filename()\n        convert_model_to_external_data(self.model, size_threshold=0)\n        onnx.save_model(self.model, model_file_path)\n\n        model = onnx.load_model(model_file_path)\n        initializer_tensor = model.graph.initializer[0]\n        self.assertTrue(initializer_tensor.HasField(\"data_location\"))\n        self.assertTrue(np.allclose(to_array(initializer_tensor), self.initializer_value))\n\n    def test_convert_model_to_external_data_from_one_file_with_location(self) -> None:\n        model_file_path = self.get_temp_model_filename()\n        external_data_file = str(uuid.uuid4())\n\n        convert_model_to_external_data(self.model, size_threshold=0, all_tensors_to_one_file=True,\n                                       location=external_data_file)\n        onnx.save_model(self.model, model_file_path)\n\n        self.assertTrue(Path.isfile(os.path.join(self.temp_dir, external_data_file)))\n\n        model = onnx.load_model(model_file_path)\n\n        # test convert model from external data\n        convert_model_from_external_data(model)\n        model_file_path = self.get_temp_model_filename()\n        onnx.save_model(model, model_file_path)\n        model = onnx.load_model(model_file_path)\n        initializer_tensor = model.graph.initializer[0]\n        self.assertFalse(len(initializer_tensor.external_data))\n        self.assertEqual(initializer_tensor.data_location, TensorProto.DEFAULT)\n        self.assertTrue(np.allclose(to_array(initializer_tensor), self.initializer_value))\n\n        attribute_tensor = model.graph.node[0].attribute[0].t\n        self.assertFalse(len(attribute_tensor.external_data))\n        self.assertEqual(attribute_tensor.data_location, TensorProto.DEFAULT)\n        self.assertTrue(np.allclose(to_array(attribute_tensor), self.attribute_value))\n\n    def test_convert_model_to_external_data_from_one_file_without_location_uses_model_name(self) -> None:\n        model_file_path = self.get_temp_model_filename()\n\n        convert_model_to_external_data(self.model, size_threshold=0, all_tensors_to_one_file=True)\n        onnx.save_model(self.model, model_file_path)\n\n        self.assertTrue(Path.isfile(model_file_path))\n        self.assertTrue(Path.isfile(os.path.join(self.temp_dir, model_file_path)))\n\n    def test_convert_model_to_external_data_one_file_per_tensor_without_attribute(self) -> None:\n        model_file_path = self.get_temp_model_filename()\n\n        convert_model_to_external_data(self.model, size_threshold=0, all_tensors_to_one_file=False,\n                                       convert_attribute=False)\n        onnx.save_model(self.model, model_file_path)\n\n        self.assertTrue(Path.isfile(model_file_path))\n        self.assertTrue(Path.isfile(os.path.join(self.temp_dir, \"input_value\")))\n        self.assertFalse(Path.isfile(os.path.join(self.temp_dir, \"attribute_value\")))\n\n    def test_convert_model_to_external_data_one_file_per_tensor_with_attribute(self) -> None:\n        model_file_path = self.get_temp_model_filename()\n\n        convert_model_to_external_data(self.model, size_threshold=0, all_tensors_to_one_file=False,\n                                       convert_attribute=True)\n        onnx.save_model(self.model, model_file_path)\n\n        self.assertTrue(Path.isfile(model_file_path))\n        self.assertTrue(Path.isfile(os.path.join(self.temp_dir, \"input_value\")))\n        self.assertTrue(Path.isfile(os.path.join(self.temp_dir, \"attribute_value\")))\n\n    def test_convert_model_to_external_data_does_not_convert_attribute_values(self) -> None:\n        model_file_path = self.get_temp_model_filename()\n\n        convert_model_to_external_data(self.model, size_threshold=0, convert_attribute=False,\n                                       all_tensors_to_one_file=False)\n        onnx.save_model(self.model, model_file_path)\n\n        self.assertTrue(Path.isfile(os.path.join(self.temp_dir, \"input_value\")))\n        self.assertFalse(Path.isfile(os.path.join(self.temp_dir, \"attribute_value\")))\n\n        model = onnx.load_model(model_file_path)\n        initializer_tensor = model.graph.initializer[0]\n        self.assertTrue(initializer_tensor.HasField(\"data_location\"))\n\n        attribute_tensor = model.graph.node[0].attribute[0].t\n        self.assertFalse(attribute_tensor.HasField(\"data_location\"))\n\n    def test_convert_model_to_external_data_converts_attribute_values(self) -> None:\n        model_file_path = self.get_temp_model_filename()\n\n        convert_model_to_external_data(self.model, size_threshold=0, convert_attribute=True)\n        onnx.save_model(self.model, model_file_path)\n\n        model = onnx.load_model(model_file_path)\n\n        initializer_tensor = model.graph.initializer[0]\n        self.assertTrue(np.allclose(to_array(initializer_tensor), self.initializer_value))\n        self.assertTrue(initializer_tensor.HasField(\"data_location\"))\n\n        attribute_tensor = model.graph.node[0].attribute[0].t\n        self.assertTrue(np.allclose(to_array(attribute_tensor), self.attribute_value))\n        self.assertTrue(attribute_tensor.HasField(\"data_location\"))\n\n    def test_save_model_does_not_convert_to_external_data_and_saves_the_model(self) -> None:\n        model_file_path = self.get_temp_model_filename()\n        onnx.save_model(self.model, model_file_path, save_as_external_data=False)\n        self.assertTrue(Path.isfile(model_file_path))\n\n        model = onnx.load_model(model_file_path)\n        initializer_tensor = model.graph.initializer[0]\n        self.assertFalse(initializer_tensor.HasField(\"data_location\"))\n\n        attribute_tensor = model.graph.node[0].attribute[0].t\n        self.assertFalse(attribute_tensor.HasField(\"data_location\"))\n\n    def test_save_model_does_convert_and_saves_the_model(self) -> None:\n        model_file_path = self.get_temp_model_filename()\n        onnx.save_model(self.model,\n                        model_file_path,\n                        save_as_external_data=True,\n                        all_tensors_to_one_file=True,\n                        location=None,\n                        size_threshold=0,\n                        convert_attribute=False)\n\n        model = onnx.load_model(model_file_path)\n\n        initializer_tensor = model.graph.initializer[0]\n        self.assertTrue(initializer_tensor.HasField(\"data_location\"))\n        self.assertTrue(np.allclose(to_array(initializer_tensor), self.initializer_value))\n\n        attribute_tensor = model.graph.node[0].attribute[0].t\n        self.assertFalse(attribute_tensor.HasField(\"data_location\"))\n        self.assertTrue(np.allclose(to_array(attribute_tensor), self.attribute_value))\n\n    def test_save_model_without_loading_external_data(self) -> None:\n        model_file_path = self.get_temp_model_filename()\n        onnx.save_model(self.model,\n                        model_file_path,\n                        save_as_external_data=True,\n                        location=None,\n                        size_threshold=0,\n                        convert_attribute=False)\n        # Save without load_external_data\n        model = onnx.load_model(model_file_path, load_external_data=False)\n        onnx.save_model(model,\n                        model_file_path,\n                        save_as_external_data=True,\n                        location=None,\n                        size_threshold=0,\n                        convert_attribute=False)\n        # Load the saved model again; Only works if the saved path is under the same directory\n        model = onnx.load_model(model_file_path)\n\n        initializer_tensor = model.graph.initializer[0]\n        self.assertTrue(initializer_tensor.HasField(\"data_location\"))\n        self.assertTrue(np.allclose(to_array(initializer_tensor), self.initializer_value))\n\n        attribute_tensor = model.graph.node[0].attribute[0].t\n        self.assertFalse(attribute_tensor.HasField(\"data_location\"))\n        self.assertTrue(np.allclose(to_array(attribute_tensor), self.attribute_value))\n\n    def test_save_model_with_existing_raw_data_should_override(self) -> None:\n        model_file_path = self.get_temp_model_filename()\n        original_raw_data = self.model.graph.initializer[0].raw_data\n        onnx.save_model(self.model, model_file_path, save_as_external_data=True, size_threshold=0)\n        self.assertTrue(Path.isfile(model_file_path))\n\n        model = onnx.load_model(model_file_path, load_external_data=False)\n        initializer_tensor = model.graph.initializer[0]\n        initializer_tensor.raw_data = b'dummpy_raw_data'\n        # If raw_data and external tensor exist at the same time, override existing raw_data\n        load_external_data_for_tensor(initializer_tensor, self.temp_dir)\n        self.assertEqual(initializer_tensor.raw_data, original_raw_data)", "target": 0}, {"function": "class TestExternalDataToArray(unittest.TestCase):\n    def setUp(self) -> None:\n        self.temp_dir: str = tempfile.mkdtemp()\n        self.model_file_path: str = os.path.join(self.temp_dir, 'model.onnx')\n        self.large_data = np.random.rand(10, 60, 100).astype(np.float32)\n        self.small_data = (200, 300)\n        self.model = self.create_test_model()\n\n    def tearDown(self) -> None:\n        shutil.rmtree(self.temp_dir)\n\n    def get_temp_model_filename(self) -> str:\n        return os.path.join(self.temp_dir, str(uuid.uuid4()) + '.onnx')\n\n    def create_test_model(self) -> ModelProto:\n        X = helper.make_tensor_value_info('X', TensorProto.FLOAT, self.large_data.shape)\n        input_init = helper.make_tensor(name='X', data_type=TensorProto.FLOAT,\n                                        dims=self.large_data.shape, vals=self.large_data.tobytes(), raw=True)\n\n        shape_data = np.array(self.small_data, np.int64)\n        shape_init = helper.make_tensor(name='Shape', data_type=TensorProto.INT64,\n                                        dims=shape_data.shape, vals=shape_data.tobytes(), raw=True)\n        C = helper.make_tensor_value_info('C', TensorProto.INT64, self.small_data)\n\n        reshape = onnx.helper.make_node(\n            'Reshape',\n            inputs=['X', 'Shape'],\n            outputs=['Y'],\n        )\n        cast = onnx.helper.make_node(\n            'Cast',\n            inputs=['Y'],\n            outputs=['C'],\n            to=getattr(TensorProto, 'INT64')\n        )\n\n        graph_def = helper.make_graph(\n            [reshape, cast],\n            'test-model',\n            [X],\n            [C],\n            initializer=[input_init, shape_init],\n        )\n        model = helper.make_model(graph_def, producer_name='onnx-example')\n        return model\n\n    def test_check_model(self) -> None:\n        checker.check_model(self.model)\n\n    def test_reshape_inference_with_external_data_fail(self) -> None:\n        onnx.save_model(self.model, self.model_file_path, save_as_external_data=True, all_tensors_to_one_file=False,\n                        size_threshold=0)\n        model_without_external_data = onnx.load(self.model_file_path, load_external_data=False)\n        # Shape inference of Reshape uses ParseData\n        # ParseData cannot handle external data and should throw the error as follows:\n        # Cannot parse data from external tensors. Please load external data into raw data for tensor: Shape\n        self.assertRaises(shape_inference.InferenceError, shape_inference.infer_shapes,\n                          model_without_external_data, strict_mode=True)\n\n    def test_to_array_with_external_data(self) -> None:\n        onnx.save_model(self.model,\n                        self.model_file_path,\n                        save_as_external_data=True,\n                        all_tensors_to_one_file=False,\n                        size_threshold=0)\n        # raw_data of external tensor is not loaded\n        model = onnx.load(self.model_file_path, load_external_data=False)\n        # Specify self.temp_dir to load external tensor\n        loaded_large_data = to_array(model.graph.initializer[0], self.temp_dir)\n        self.assertTrue(np.allclose(loaded_large_data, self.large_data))\n\n    def test_save_model_with_external_data_multiple_times(self) -> None:\n        # Test onnx.save should respectively handle typical tensor and external tensor properly\n        # 1st save: save two tensors which have raw_data\n        # Only w_large will be stored as external tensors since it's larger than 1024\n        onnx.save_model(self.model,\n                        self.model_file_path,\n                        save_as_external_data=True,\n                        all_tensors_to_one_file=False,\n                        location=None,\n                        size_threshold=1024,\n                        convert_attribute=True)\n        model_without_loading_external = onnx.load(self.model_file_path, load_external_data=False)\n        large_input_tensor = model_without_loading_external.graph.initializer[0]\n        self.assertTrue(large_input_tensor.HasField(\"data_location\"))\n        self.assertTrue(np.allclose(to_array(large_input_tensor, self.temp_dir), self.large_data))\n\n        small_shape_tensor = model_without_loading_external.graph.initializer[1]\n        self.assertTrue(not small_shape_tensor.HasField(\"data_location\"))\n        self.assertTrue(np.allclose(to_array(small_shape_tensor), self.small_data))\n\n        # 2nd save: one tensor has raw_data (small); one external tensor (large)\n        # Save them both as external tensors this time\n        onnx.save_model(model_without_loading_external,\n                        self.model_file_path,\n                        save_as_external_data=True,\n                        all_tensors_to_one_file=False,\n                        location=None,\n                        size_threshold=0,\n                        convert_attribute=True)\n\n        model_without_loading_external = onnx.load(self.model_file_path, load_external_data=False)\n        large_input_tensor = model_without_loading_external.graph.initializer[0]\n        self.assertTrue(large_input_tensor.HasField(\"data_location\"))\n        self.assertTrue(np.allclose(to_array(large_input_tensor, self.temp_dir), self.large_data))\n\n        small_shape_tensor = model_without_loading_external.graph.initializer[1]\n        self.assertTrue(small_shape_tensor.HasField(\"data_location\"))\n        self.assertTrue(np.allclose(to_array(small_shape_tensor, self.temp_dir), self.small_data))", "target": 0}, {"function": "class TestNotAllowToLoadExternalDataOutsideModelDirectory(TestLoadExternalDataBase):\n    \"\"\"Essential test to check that onnx (validate) C++ code will not allow to load external_data outside the model\n    directory. \"\"\"\n\n    def create_external_data_tensor(self, value: List[Any], tensor_name: str) -> TensorProto:\n        tensor = from_array(np.array(value))\n        tensor.name = tensor_name\n\n        set_external_data(tensor, location=\"../../file.bin\")\n\n        tensor.ClearField('raw_data')\n        tensor.data_location = onnx.TensorProto.EXTERNAL\n        return tensor\n\n    def test_check_model(self) -> None:\n        \"\"\"We only test the model validation as onnxruntime uses this to load the model. \"\"\"\n        with self.assertRaises(onnx.checker.ValidationError):\n            checker.check_model(self.model_filename)", "target": 0}]}], "outdated": 0, "cwe_descripiton": "", "cwe_consequence": "", "cwe_method": "", "cwe_solution": ""}
