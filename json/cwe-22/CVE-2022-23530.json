{"index": 10043, "cve_id": "CVE-2022-23530", "cwe_id": ["CWE-22"], "cve_language": "Python", "cve_description": "GuardDog is a CLI tool to identify malicious PyPI packages. Versions prior to v0.1.8 are vulnerable to arbitrary file write when scanning a specially-crafted remote PyPI package. Extracting files using shutil.unpack_archive() from a potentially malicious tarball without validating that the destination file path is within the intended destination directory can cause files outside the destination directory to be overwritten. This issue is patched in version 0.1.8. Potential workarounds include using a safer module, like zipfile, and validating the location of the extracted files and discarding those with malicious paths.", "cvss": "6.5", "publish_date": "December 16, 2022", "AV": "NETWORK", "AC": "NETWORK", "PR": "NONE", "UI": "REQUIRED", "S": "UNCHANGED", "C": "NONE", "I": "HIGH", "A": "NONE", "commit_id": "37c7d0767ba28f4df46117d478f97652594c491c", "commit_message": "Securely extract PyPI .tar.gz archives (#102)\n\n* Add Semgrep rule and run custom Semgrep rules in CI for SAST\r\n\r\n* Securely extract remote .tar.gz files", "commit_date": "2022-12-05T16:08:54Z", "project": "datadog/guarddog", "url": "https://api.github.com/repos/DataDog/guarddog/commits/37c7d0767ba28f4df46117d478f97652594c491c", "html_url": "https://github.com/DataDog/guarddog/commit/37c7d0767ba28f4df46117d478f97652594c491c", "windows_before": [{"commit_id": "8e814deb3ae6457ea1a4f7b0d3a0e64db0734f13", "commit_date": "Mon Dec 5 09:38:36 2022 +0100", "commit_message": "Add Type checking and enforce lint (#98)", "files_name": [".github/workflows/test.yml", "Makefile", "README.md", "guarddog/__init__.py", "guarddog/analyzer/analyzer.py", "guarddog/analyzer/metadata/detector.py", "guarddog/analyzer/metadata/empty_information.py", "guarddog/analyzer/metadata/potentially_compromised_email_domain.py", "guarddog/analyzer/metadata/release_zero.py", "guarddog/analyzer/metadata/typosquatting.py", "guarddog/cli.py", "guarddog/scanners/package_scanner.py", "guarddog/scanners/project_scanner.py", "guarddog/utils/package_info.py", "poetry.lock", "requirements.txt"]}, {"commit_id": "a1d064ceb09d39bb28deb6972bc0a278756ea91f", "commit_date": "Thu Dec 1 09:44:22 2022 +0100", "commit_message": "Add missing project link to PyPI metadata (#97)", "files_name": ["pyproject.toml"]}, {"commit_id": "89fe1e547d93668bd5a8f66a60e21b8268ab3db1", "commit_date": "Thu Dec 1 09:43:58 2022 +0100", "commit_message": "Merge pull request #94 from zmallen/zma/update_poetry_python_requriements", "files_name": ["d806716f1482e787d72e2024de44569e65de334f - Wed Nov 30 17:06:08 2022 +0100 : Merge pull request #96 from DataDog/88-guarddog-fails-to-parse-the-whole-requirementstxt-after-encountering-package-name-starting-with-git+https", "ba49a7df252489b3e836952a22a91f561f51cb17 - Wed Nov 30 14:14:00 2022 +0100 : apply review comments", "guarddog/scanners/project_scanner.py"]}, {"commit_id": "affa0aab9bf7833b59d4b410d006d4e436876520", "commit_date": "Wed Nov 30 14:11:52 2022 +0100", "commit_message": "apply review comments", "files_name": ["tests/core/test_requirements_scanner.py"]}, {"commit_id": "d1c84985533ac38c765951ca16b4f5c02e7b57bc", "commit_date": "Wed Nov 30 13:45:14 2022 +0100", "commit_message": "Make GuardDog ignore lines in requirements that we can't parse and log a proper warning", "files_name": ["guarddog/scanners/project_scanner.py", "tests/core/test_requirements_scanner.py"]}, {"commit_id": "272a339b70d3c3fd07f0dae1191c4e348e5f7a04", "commit_date": "Tue Nov 29 22:14:34 2022 +0100", "commit_message": "Fix entrypoint (closes #92) (#95)", "files_name": [".github/workflows/test.yml", "pyproject.toml"]}, {"commit_id": "193232afdec05025a1bd10b2dbbfd6a36c155f7f", "commit_date": "Tue Nov 29 13:18:43 2022 -0500", "commit_message": "Add python version pin for poetry and update README", "files_name": ["README.md", "pyproject.toml"]}, {"commit_id": "e918bfd4e7497f9b54be1779381eb0dc52391084", "commit_date": "Tue Nov 29 17:11:24 2022 +0100", "commit_message": "Add Semgrep status badge", "files_name": ["README.md"]}, {"commit_id": "ea7f3e460aafe8b86091ce97481899977dcd4730", "commit_date": "Tue Nov 29 17:10:31 2022 +0100", "commit_message": "Add Semgrep scan integrated with GitHub Code Scanning on PRs (closes #91)", "files_name": [".github/workflows/semgrep.yml", ".semgrepignore"]}, {"commit_id": "36c00905bf8f4172aba86f40eb57fa78e15bbf90", "commit_date": "Tue Nov 29 11:40:57 2022 +0100", "commit_message": "Add security policy to report vulnerabilities", "files_name": ["SECURITY.md"]}, {"commit_id": "98af5c8c1e9c15fa888c900252e76116b0ec25d1", "commit_date": "Tue Nov 29 11:30:04 2022 +0100", "commit_message": "Use tarsafe instead of built-in tarfile to extract archives (#89)", "files_name": ["guarddog/scanners/package_scanner.py", "poetry.lock", "pyproject.toml", "requirements.txt"]}, {"commit_id": "14b3858005c52ccae64953b2920beefd0514a2e4", "commit_date": "Mon Nov 28 22:42:23 2022 +0100", "commit_message": "Adding exit codes (#76)", "files_name": ["guarddog/cli.py"]}, {"commit_id": "1c517ffafcf8907b159146ae51d897cd3bcddbfe", "commit_date": "Mon Nov 28 16:10:02 2022 +0100", "commit_message": "Add simple integration test (#85)", "files_name": [".github/workflows/test.yml", "poetry.lock"]}, {"commit_id": "b36c5fa25c64032899dcc376247c44bf7db1d0bb", "commit_date": "Mon Nov 28 15:42:29 2022 +0100", "commit_message": "Make GuardDog usable as a library rather than only a CLI (#82)", "files_name": ["docs/programmatic-usage.md", "guarddog/__init__.py", "guarddog/analyzer/analyzer.py", "guarddog/cli.py", "guarddog/scanners/package_scanner.py", "poetry.lock", "pyproject.toml"]}, {"commit_id": "9981051d206ad276eec9f58f1e63bc8695f1e845", "commit_date": "Mon Nov 28 14:06:52 2022 +0100", "commit_message": "Fix PyPI release", "files_name": [".github/workflows/pypi-release.yml"]}, {"commit_id": "eb1910260168e3c414ce0a71be236f192645a0ab", "commit_date": "Mon Nov 28 14:04:46 2022 +0100", "commit_message": "Fix PyPI release", "files_name": [".github/workflows/pypi-release.yml", "pyproject.toml"]}, {"commit_id": "02c8b9b7c695aeedc6e6ade04971416588184df2", "commit_date": "Mon Nov 28 13:54:57 2022 +0100", "commit_message": "Add PyPI-specific readme", "files_name": ["pypi.rst", "pyproject.toml"]}, {"commit_id": "3459c418c8517ffaf55f89fcafc98193a96a9391", "commit_date": "Mon Nov 28 13:35:43 2022 +0100", "commit_message": "Attempt to fix long_description for PyPI publishing (attempt 3)", "files_name": ["pyproject.toml"]}, {"commit_id": "d255e3a976ea8b8f128c7104e751b6f851a31e95", "commit_date": "Mon Nov 28 13:25:59 2022 +0100", "commit_message": "Attempt to fix long_description for PyPI publishing (attempt 2)", "files_name": ["pyproject.toml"]}, {"commit_id": "1117f3f56dd41bd4d733f00d8e71517934fabe39", "commit_date": "Mon Nov 28 13:23:39 2022 +0100", "commit_message": "Attempt to fix long_description for PyPI publishing", "files_name": ["pyproject.toml"]}, {"commit_id": "3ab6299de263fb6ff74ede0ab42a38dba24a2276", "commit_date": "Mon Nov 28 13:21:07 2022 +0100", "commit_message": "Adapt .gitignore (attempt 2)", "files_name": [".gitignore"]}, {"commit_id": "35685384f8e8a2072b5a5d23a5452690ce42c2ea", "commit_date": "Mon Nov 28 13:19:06 2022 +0100", "commit_message": "Move old folder under scripts folder", "files_name": ["scripts/evaluator/data/malicious/malware.zip", "scripts/evaluator/evaluator.py", "scripts/evaluator/logs/benign_logs.json", "scripts/evaluator/logs/malicious_ground_truth.json", "scripts/evaluator/logs/malicious_logs.json"]}, {"commit_id": "0de8756de69a10a89d3a16140472663ffbdea0d6", "commit_date": "Mon Nov 28 13:16:45 2022 +0100", "commit_message": "Change pyproject.toml build backend", "files_name": ["pyproject.toml"]}, {"commit_id": "4b098495d6203eec561bb0919f02307c713677c3", "commit_date": "Mon Nov 28 13:12:59 2022 +0100", "commit_message": "Specify dynamic version in pyproject.toml (attempt 2)", "files_name": ["pyproject.toml"]}, {"commit_id": "00aa37f04ebefb72856911953c22ad7bfc08202a", "commit_date": "Mon Nov 28 13:10:15 2022 +0100", "commit_message": "Specify dynamic version in pyproject.toml", "files_name": ["pyproject.toml"]}, {"commit_id": "b5d01df66fe91501584cb0f098d715b31e3e4d76", "commit_date": "Mon Nov 28 13:03:30 2022 +0100", "commit_message": "Adapt .gitignore", "files_name": [".gitignore"]}, {"commit_id": "0f8fb48986b1d606fbadc6eaee8bcc7943435769", "commit_date": "Mon Nov 28 13:02:01 2022 +0100", "commit_message": "Automatically figure out package version from git tags", "files_name": ["pyproject.toml"]}, {"commit_id": "614a432d08f105e867855cb68001b839c91daeb7", "commit_date": "Mon Nov 28 12:56:41 2022 +0100", "commit_message": "Specify readme in pyproject.toml", "files_name": ["pyproject.toml"]}, {"commit_id": "9e70da848dfe4e4aab78f1b780cc78b120c2f151", "commit_date": "Mon Nov 28 12:52:47 2022 +0100", "commit_message": "Fix pyproject.toml authors", "files_name": ["pyproject.toml"]}, {"commit_id": "ba68c62ebc042fa57f4959fa20f9b268ce713da1", "commit_date": "Mon Nov 28 12:49:48 2022 +0100", "commit_message": "README and pyproject.toml fixes", "files_name": ["README.md", "pyproject.toml"]}, {"commit_id": "939e766846693e09cd3dac42756e48b4d64cce05", "commit_date": "Mon Nov 28 12:38:18 2022 +0100", "commit_message": "Fix CI pipeline to publish to PyPI (v2)", "files_name": [".github/workflows/pypi-release.yml"]}, {"commit_id": "be27f8cf2fc65f1ffa985e5cd623d2d56211396c", "commit_date": "Mon Nov 28 12:36:16 2022 +0100", "commit_message": "Ignore packages that don't exist in PyPI (closes #78) (#83)", "files_name": [".github/workflows/test.yml", "Makefile", "guarddog/scanners/project_scanner.py", "pyproject.toml", "tests/core/test_requirements_scanner.py"]}, {"commit_id": "edfb5fb8457f9aa57676d32ddae13f8ac7895dcc", "commit_date": "Mon Nov 28 12:35:40 2022 +0100", "commit_message": "Fix CI pipeline to publish to PyPI", "files_name": [".github/workflows/pypi-release.yml"]}, {"commit_id": "538a83cdc7bc04baa0450b9c2b9652c83646f73f", "commit_date": "Mon Nov 28 12:31:49 2022 +0100", "commit_message": "Publish to pypi (closes #80) (#84)", "files_name": [".github/workflows/pypi-release.yml", "README.md"]}, {"commit_id": "ab604cc7728cf483c1e0a33a8927f997cad3649f", "commit_date": "Mon Nov 28 10:30:45 2022 +0100", "commit_message": "Fix pyproject.toml metadata", "files_name": ["pyproject.toml"]}, {"commit_id": "fb5e142bd03c563ada77828ba2293e6c8db01386", "commit_date": "Thu Nov 24 21:39:55 2022 +0100", "commit_message": "Added setuptools as dependency (#73)", "files_name": ["pyproject.toml", "requirements.txt"]}, {"commit_id": "a4a3d9e1f401fda9ddb261366431fdabb9b2c253", "commit_date": "Tue Nov 22 12:48:57 2022 -0500", "commit_message": "Enhance exception handling when a Semgrep rule fails to run (#69)", "files_name": ["guarddog/analyzer/analyzer.py"]}, {"commit_id": "44a32b4aff617fd26c71fceed8e3dd952c3f1edf", "commit_date": "Tue Nov 15 11:34:42 2022 +0100", "commit_message": "Remove old dist folder", "files_name": ["dist/guarddog-0.1.0-py2.py3-none-any.whl", "dist/guarddog-0.1.0-py3-none-any.whl", "dist/guarddog-0.1.0.tar.gz"]}, {"commit_id": "ec34524ef25033eaf463779bc1c241dd7edaf63d", "commit_date": "Sun Nov 13 17:16:24 2022 +0100", "commit_message": "Fix requirements.txt", "files_name": ["requirements.txt"]}, {"commit_id": "52e390061d56de24ec7a7448c2689e0f22fa0fc1", "commit_date": "Sun Nov 13 16:59:37 2022 +0100", "commit_message": "Readme formatting", "files_name": ["README.md"]}, {"commit_id": "9b0691380115f449bac851197a14afa41ee5d65d", "commit_date": "Sun Nov 13 16:57:04 2022 +0100", "commit_message": "Add Docker usage instructions", "files_name": ["README.md"]}, {"commit_id": "49ce0adbe85a7d1056f0b3ab1b503454488c2610", "commit_date": "Wed Nov 9 10:08:38 2022 +0100", "commit_message": "Merge pull request #61 from DataDog/stegano", "files_name": ["5d0699dd43a28db35bef353d60ae4c1fe34f41a8 - Wed Nov 9 10:00:54 2022 +0100 : New heuristic: execution of hidden data from an image", "README.md", "guarddog/analyzer/sourcecode/steganography.yml", "tests/analyzer/sourcecode/steganography.py"]}, {"commit_id": "3ff6c2c4703c8c2b993d5954a13382cc54e484d4", "commit_date": "Wed Nov 9 09:57:47 2022 +0100", "commit_message": "Properly print JSON output when --json is specified", "files_name": ["guarddog/cli.py"]}, {"commit_id": "c35082efd431b2d1547d24e9c8618bbf7050fb78", "commit_date": "Tue Nov 8 10:25:18 2022 +0100", "commit_message": "Merge pull request #60 from DataDog/new-metadata-rule", "files_name": ["da51415b2eecf61e6b8b515a17995283ff9907c9 - Tue Nov 8 10:09:14 2022 +0100 : Merge pull request #59 from DataDog/new-rule-obfuscation", "99da386e620a0945bc40f5f00dd597d78b383500 - Tue Nov 8 09:40:53 2022 +0100 : New metadata rule: package version to 0.0.0", "README.md", "guarddog/analyzer/analyzer.py", "guarddog/analyzer/metadata/release_zero.py", "tests/analyzer/metadata/test_release_zero.py"]}, {"commit_id": "daaa4eef89db83d782f0e2a14709d94baefe2bba", "commit_date": "Tue Nov 8 09:23:09 2022 +0100", "commit_message": "Add cookie exfiltration case to exfiltrate-sensitive-data rule", "files_name": ["guarddog/analyzer/sourcecode/exfiltrate-sensitive-data.yml", "tests/analyzer/sourcecode/exfiltrate-sensitive-data.py"]}, {"commit_id": "0da33f7eb399060019b864222e1e1c50d23c89fd", "commit_date": "Tue Nov 8 08:41:28 2022 +0100", "commit_message": "New rule: detection of common obfuscation methods", "files_name": ["README.md", "guarddog/analyzer/sourcecode/obfuscation.yml", "tests/analyzer/sourcecode/obfuscation.py"]}], "windows_after": [{"commit_id": "72fe2dbf392e62d96de8609123ec59c08e99dd5b", "commit_date": "Wed Dec 7 11:11:52 2022 +0100", "commit_message": "Bug fix: scanning zip packages (#105)", "files_name": [".github/workflows/test.yml", "guarddog/scanners/package_scanner.py", "guarddog/utils/archives.py"]}, {"commit_id": "d05e18f9e4a20651c50016fc83d5f023a87f6c75", "commit_date": "Wed Dec 7 11:31:51 2022 +0100", "commit_message": "Heuristic: identify usage of globals and __import__ (closes #62) (#106)", "files_name": ["guarddog/analyzer/sourcecode/code-execution.yml", "tests/analyzer/sourcecode/code-execution.py"]}, {"commit_id": "29662ec6360206eb0a1a1783234355e1f0995bb4", "commit_date": "Wed Dec 7 11:36:47 2022 +0100", "commit_message": "README: Use Makefile to run code quality checks", "files_name": ["README.md"]}, {"commit_id": "e2e05c757c6be903e072a33f78137fe9027b5aed", "commit_date": "Wed Dec 7 12:41:49 2022 +0100", "commit_message": "Add pre-commit hooks configuration for local development (#107)", "files_name": [".pre-commit-config.yaml", "README.md"]}, {"commit_id": "67963ee21cf4f4f970ee1d501085b6ee23142936", "commit_date": "Mon Dec 12 04:19:32 2022 -0500", "commit_message": "Fix false positives and duplicate errors in the typosquatting algorithm (#108)", "files_name": ["guarddog/analyzer/metadata/typosquatting.py", "requirements.txt", "tests/analyzer/metadata/test_typosquatting.py"]}, {"commit_id": "50ff5e76db9708427fbf21b3e6f7cdde8195c590", "commit_date": "Wed Dec 14 09:55:57 2022 +0100", "commit_message": "npm support (#101)", "files_name": [".github/workflows/test.yml", ".gitignore", "Makefile", "README.md", "docs/programmatic-usage.md", "guarddog/__init__.py", "guarddog/analyzer/analyzer.py", "guarddog/analyzer/metadata/__init__.py", "guarddog/analyzer/metadata/detector.py", "guarddog/analyzer/metadata/empty_information.py", "guarddog/analyzer/metadata/npm/__init__.py", "guarddog/analyzer/metadata/npm/empty_information.py", "guarddog/analyzer/metadata/npm/potentially_compromised_email_domain.py", "guarddog/analyzer/metadata/npm/release_zero.py", "guarddog/analyzer/metadata/potentially_compromised_email_domain.py", "guarddog/analyzer/metadata/pypi/__init__.py", "guarddog/analyzer/metadata/pypi/empty_information.py", "guarddog/analyzer/metadata/pypi/potentially_compromised_email_domain.py", "guarddog/analyzer/metadata/pypi/release_zero.py", "guarddog/analyzer/metadata/pypi/typosquatting.py", "guarddog/analyzer/metadata/release_zero.py", "guarddog/analyzer/metadata/typosquatting.py", "guarddog/analyzer/sourcecode/__init__.py", "guarddog/analyzer/sourcecode/eval-call.yml", "guarddog/analyzer/sourcecode/shady-links.yml", "guarddog/cli.py", "guarddog/ecosystems.py", "guarddog/scanners/__init__.py", "guarddog/scanners/npm_package_scanner.py", "guarddog/scanners/npm_project_scanner.py", "guarddog/scanners/package_scanner.py", "guarddog/scanners/pypi_package_scanner.py", "guarddog/scanners/pypi_project_scanner.py", "guarddog/scanners/scanner.py", "guarddog/utils/archives.py", "guarddog/utils/package_info.py", "poetry.lock", "pyproject.toml", "requirements.txt", "scripts/evaluator/evaluator.py", "tests/analyzer/metadata/resources/npm_data.json", "tests/analyzer/metadata/test_empty_information.py", "tests/analyzer/metadata/test_potentially_compromised_email_domain.py", "tests/analyzer/metadata/test_release_zero.py", "tests/analyzer/metadata/test_typosquatting.py", "tests/analyzer/sourcecode/test_eval_call.js", "tests/core/resources/package.json", "tests/core/test_npm_package_scanner.py", "tests/core/test_npm_requirements_scanner.py", "tests/core/test_pypi_requirements_scanner.py"]}, {"commit_id": "f82f073b23d561c5d6ccc0a70d328bd51352aece", "commit_date": "Thu Dec 15 16:33:46 2022 +0100", "commit_message": "Update README.md", "files_name": ["README.md"]}, {"commit_id": "a3dc5f8e1b91eecaf7f5d105164bab06c6bc38e3", "commit_date": "Thu Dec 15 16:36:02 2022 +0100", "commit_message": "Update README.md", "files_name": ["README.md"]}, {"commit_id": "7dca88d5f1c2070fba763bf2e2a68104f1cb10fe", "commit_date": "Mon Dec 19 16:38:43 2022 +0100", "commit_message": "chores: Bump certify version to fix GHSA-43fp-rhv2-5gv8 (#115)", "files_name": ["poetry.lock"]}, {"commit_id": "de5513c5d655faf1db2f7e3e942a8ceaffc7f0ce", "commit_date": "Mon Dec 19 16:38:57 2022 +0100", "commit_message": "Merge branch 'main' into v1.0-rc", "files_name": ["f8b4d414cbe4a4c83446bef5e7d1d5dedaf69763 - Tue Dec 20 16:39:35 2022 +0100 : Vdeturckheim/sarif output (#113)", ".github/workflows/semgrep.yml", ".github/workflows/test.yml", "Dockerfile", "README.md", "guarddog/analyzer/metadata/empty_information.py", "guarddog/analyzer/metadata/potentially_compromised_email_domain.py", "guarddog/analyzer/metadata/pypi/typosquatting.py", "guarddog/analyzer/metadata/release_zero.py", "guarddog/analyzer/metadata/typosquatting.py", "guarddog/analyzer/sourcecode/eval-call.yml", "guarddog/analyzer/sourcecode/exec-base64.yml", "guarddog/cli.py", "guarddog/reporters/__init__.py", "guarddog/reporters/sarif.py", "poetry.lock", "pyproject.toml", "requirements-dev.txt", "requirements.txt", "tests/core/resources/package.json", "tests/core/resources/requirements.txt", "tests/reporters/test_sarif.py"]}, {"commit_id": "39e97003bf53a2d32505b464d7b4795c57520531", "commit_date": "Tue Jan 3 22:05:52 2023 +0100", "commit_message": "New rule for \"silent execution\" of popen based on Pytorch attack. Some cleanup of processing whl files (#119)", "files_name": ["README.md", "guarddog/analyzer/sourcecode/silent-process-execution.yml", "guarddog/scanners/scanner.py", "guarddog/utils/archives.py", "tests/analyzer/sourcecode/silent-process-execution.py"]}, {"commit_id": "9d60fbf7da9e0994d152d4fb92f0bd1b14089f52", "commit_date": "Thu Jan 5 12:04:04 2023 +0100", "commit_message": "npm heuristic: detect silent process execution (closes #122) (#125)", "files_name": ["guarddog/analyzer/sourcecode/npm-silent-process-execution.yml", "tests/analyzer/sourcecode/npm-silent-process-execution.js"]}, {"commit_id": "81feb7201c137d03304a2968adc5b76516f203c3", "commit_date": "Tue Jan 10 10:22:52 2023 +0100", "commit_message": "npm squatting (#121)", "files_name": ["guarddog/analyzer/metadata/npm/__init__.py", "guarddog/analyzer/metadata/npm/typosquatting.py", "guarddog/analyzer/metadata/pypi/typosquatting.py", "guarddog/analyzer/metadata/resources/top_npm_packages.json", "guarddog/analyzer/metadata/typosquatting.py", "tests/analyzer/metadata/test_typosquatting.py"]}, {"commit_id": "06d782eda26385b1c27b334b0c4451332ef87d2f", "commit_date": "Tue Jan 10 10:24:20 2023 +0100", "commit_message": "Update npm rules (#120)", "files_name": ["guarddog/analyzer/sourcecode/exec-base64-js.yml", "guarddog/analyzer/sourcecode/serialize-environment.yml", "tests/analyzer/sourcecode/serialize-environment.js"]}, {"commit_id": "2da2ac9ec2282772afcdb16660250af3de7fcc95", "commit_date": "Tue Jan 10 11:40:46 2023 +0100", "commit_message": "Pypi to Github files integrity (#114)", "files_name": ["Dockerfile", "README.md", "guarddog/analyzer/analyzer.py", "guarddog/analyzer/metadata/detector.py", "guarddog/analyzer/metadata/empty_information.py", "guarddog/analyzer/metadata/npm/empty_information.py", "guarddog/analyzer/metadata/npm/release_zero.py", "guarddog/analyzer/metadata/npm/typosquatting.py", "guarddog/analyzer/metadata/potentially_compromised_email_domain.py", "guarddog/analyzer/metadata/pypi/__init__.py", "guarddog/analyzer/metadata/pypi/empty_information.py", "guarddog/analyzer/metadata/pypi/release_zero.py", "guarddog/analyzer/metadata/pypi/repository_integrity_mismatch.py", "guarddog/analyzer/metadata/pypi/typosquatting.py", "guarddog/analyzer/metadata/repository_integrity_mismatch.py", "guarddog/cli.py", "guarddog/scanners/scanner.py", "notebooks/repository_integrity_missmatch.ipynb", "notebooks/resources/all_package_info/build.py", "poetry.lock", "pyproject.toml", "requirements.txt", "scripts/evaluator/evaluator.py", "tests/analyzer/metadata/test_empty_information.py", "tests/analyzer/metadata/test_release_zero.py", "tests/analyzer/metadata/test_repository_integrity_mismatch.py"]}, {"commit_id": "238fdd193060d337a13c7e74630f83855d51de67", "commit_date": "Tue Jan 10 14:17:53 2023 +0100", "commit_message": "Add Dependabot config file", "files_name": [".github/dependabot.yml"]}, {"commit_id": "8508a0cf98c26fb011084af0a210bbc3d1954353", "commit_date": "Wed Jan 25 11:43:48 2023 +0100", "commit_message": "update banner with new logo (#127)", "files_name": ["README.md", "docs/images/banner.png", "docs/images/logo.png"]}, {"commit_id": "457389da98feb44e89bc79056c235f8821c28e20", "commit_date": "Tue Jan 31 13:27:25 2023 +0000", "commit_message": "npm heuristic: detect pre and post-install script (closes #124) (#130)", "files_name": ["guarddog/analyzer/sourcecode/__init__.py", "guarddog/analyzer/sourcecode/npm-install-script.yml", "tests/analyzer/sourcecode/npm-install-script.json"]}, {"commit_id": "7bccb25d7b9ba7dd922fbedc13d577f8f434668c", "commit_date": "Tue Jan 31 13:30:19 2023 +0000", "commit_message": "Rename npm rules with a 'npm-' prefix and add missing test file (#132)", "files_name": ["guarddog/analyzer/sourcecode/npm-exec-base64.yml", "guarddog/analyzer/sourcecode/npm-serialize-environment.yml", "tests/analyzer/sourcecode/npm-exec-base64.js", "tests/analyzer/sourcecode/npm-serialize-environment.js", "tests/analyzer/sourcecode/serialize-environment.js"]}, {"commit_id": "414db843ce73cfbab3a0741c16e1287723478731", "commit_date": "Thu Feb 2 09:42:48 2023 +0000", "commit_message": "Autogenerate 'list-rules' output and autoinject rules docs in README file (#133)", "files_name": [".pre-commit-config.yaml", "Makefile", "README.md", "guarddog/__init__.py", "guarddog/analyzer/metadata/__init__.py", "guarddog/analyzer/metadata/detector.py", "guarddog/analyzer/metadata/empty_information.py", "guarddog/analyzer/metadata/npm/__init__.py", "guarddog/analyzer/metadata/npm/potentially_compromised_email_domain.py", "guarddog/analyzer/metadata/npm/release_zero.py", "guarddog/analyzer/metadata/potentially_compromised_email_domain.py", "guarddog/analyzer/metadata/pypi/__init__.py", "guarddog/analyzer/metadata/pypi/potentially_compromised_email_domain.py", "guarddog/analyzer/metadata/release_zero.py", "guarddog/analyzer/metadata/repository_integrity_mismatch.py", "guarddog/analyzer/metadata/resources/top_pypi_packages.json"]}], "parents": [{"commit_id_before": "8e814deb3ae6457ea1a4f7b0d3a0e64db0734f13", "url_before": "https://api.github.com/repos/DataDog/guarddog/commits/8e814deb3ae6457ea1a4f7b0d3a0e64db0734f13", "html_url_before": "https://github.com/DataDog/guarddog/commit/8e814deb3ae6457ea1a4f7b0d3a0e64db0734f13"}], "details": [{"raw_url": "https://github.com/DataDog/guarddog/raw/37c7d0767ba28f4df46117d478f97652594c491c/.github%2Fsemgrep-rules%2Finsecure-unpack-archive.yml", "code": "rules:\n  - id: insecure-shutil-unpack-archive-use\n    message: The Python 'shutil' shutil.extract_archive is vulnerable to\n      arbitrary file overwrites\n    languages:\n      - python\n    severity: ERROR\n    metadata:\n      category: security\n      technology:\n        - python\n      owasp:\n        - A06:2017 - Security Misconfiguration\n        - A05:2021 - Security Misconfiguration\n      cwe:\n        - \"CWE-22: Improper Limitation of a Pathname to a Restricted Directory\n          ('Path Traversal')\"\n      license: Commons Clause License Condition v1.0[LGPL-2.1-only]\n    pattern-either:\n      - pattern: |\n          shutil.unpack_archive(...)", "code_before": "", "patch": "@@ -0,0 +1,21 @@\n+rules:\n+  - id: insecure-shutil-unpack-archive-use\n+    message: The Python 'shutil' shutil.extract_archive is vulnerable to\n+      arbitrary file overwrites\n+    languages:\n+      - python\n+    severity: ERROR\n+    metadata:\n+      category: security\n+      technology:\n+        - python\n+      owasp:\n+        - A06:2017 - Security Misconfiguration\n+        - A05:2021 - Security Misconfiguration\n+      cwe:\n+        - \"CWE-22: Improper Limitation of a Pathname to a Restricted Directory\n+          ('Path Traversal')\"\n+      license: Commons Clause License Condition v1.0[LGPL-2.1-only]\n+    pattern-either:\n+      - pattern: |\n+          shutil.unpack_archive(...)\n\\ No newline at end of file", "file_path": "files/2022_12/1323", "file_language": "yml", "file_name": ".github/semgrep-rules/insecure-unpack-archive.yml", "outdated_file_modify": 0, "outdated_file_before": 0, "outdated_file_after": 0}, {"raw_url": "https://github.com/DataDog/guarddog/raw/37c7d0767ba28f4df46117d478f97652594c491c/.github%2Fworkflows%2Fsemgrep.yml", "code": "name: Semgrep scan\n\non:\n  push:\n    branches: [\"main\"]\n  pull_request:\n    branches: [ \"main\" ]\n\npermissions:\n  contents: read\n\njobs:\n  semgrep:\n    permissions:\n      contents: read # for actions/checkout to fetch code\n      security-events: write # for github/codeql-action/upload-sarif to upload SARIF results\n    name: Scan\n    runs-on: ubuntu-latest\n    container:\n      image: returntocorp/semgrep\n\n    # Skip any PR created by dependabot to avoid permission issues:\n    if: (github.actor != 'dependabot[bot]')\n\n    steps:\n      - uses: actions/checkout@v3\n\n      - run: semgrep --config auto --sarif --output semgrep.sarif ./guarddog\n      - run: semgrep --config .github/semgrep-rules --sarif --output semgrep-custom.sarif ./guarddog\n\n      - name: Upload SARIF file for GitHub Advanced Security Dashboard\n        uses: github/codeql-action/upload-sarif@v2\n        with:\n          category: semgrep-builtin\n          sarif_file: semgrep.sarif\n\n      - name: Upload SARIF file for custom Semgrep rules for GitHub Advanced Security Dashboard\n        uses: github/codeql-action/upload-sarif@v2\n        with:\n          category: semgrep-custom\n          sarif_file: semgrep-custom.sarif\n          \n", "code_before": "name: Semgrep scan\n\non:\n  push:\n    branches: [\"main\"]\n  pull_request:\n    branches: [ \"main\" ]\n\npermissions:\n  contents: read\n\njobs:\n  semgrep:\n    permissions:\n      contents: read # for actions/checkout to fetch code\n      security-events: write # for github/codeql-action/upload-sarif to upload SARIF results\n    name: Scan\n    runs-on: ubuntu-latest\n    container:\n      image: returntocorp/semgrep\n\n    # Skip any PR created by dependabot to avoid permission issues:\n    if: (github.actor != 'dependabot[bot]')\n\n    steps:\n      - uses: actions/checkout@v3\n\n      - run: semgrep --config auto --sarif --output semgrep.sarif ./guarddog\n\n      - name: Upload SARIF file for GitHub Advanced Security Dashboard\n        uses: github/codeql-action/upload-sarif@v2\n        with:\n          sarif_file: semgrep.sarif\n        if: always()\n", "patch": "@@ -26,9 +26,17 @@ jobs:\n       - uses: actions/checkout@v3\n \n       - run: semgrep --config auto --sarif --output semgrep.sarif ./guarddog\n+      - run: semgrep --config .github/semgrep-rules --sarif --output semgrep-custom.sarif ./guarddog\n \n       - name: Upload SARIF file for GitHub Advanced Security Dashboard\n         uses: github/codeql-action/upload-sarif@v2\n         with:\n+          category: semgrep-builtin\n           sarif_file: semgrep.sarif\n-        if: always()\n+\n+      - name: Upload SARIF file for custom Semgrep rules for GitHub Advanced Security Dashboard\n+        uses: github/codeql-action/upload-sarif@v2\n+        with:\n+          category: semgrep-custom\n+          sarif_file: semgrep-custom.sarif\n+          ", "file_path": "files/2022_12/1324", "file_language": "yml", "file_name": ".github/workflows/semgrep.yml", "outdated_file_modify": 0, "outdated_file_before": 0, "outdated_file_after": 0}, {"raw_url": "https://github.com/DataDog/guarddog/raw/37c7d0767ba28f4df46117d478f97652594c491c/guarddog%2Fscanners%2Fpackage_scanner.py", "code": "import json\nimport os\nimport tarsafe  # type:ignore\nimport tempfile\nimport requests\n\nfrom guarddog.analyzer.analyzer import Analyzer\nfrom guarddog.scanners.scanner import Scanner\nfrom guarddog.utils.package_info import get_package_info\n\n\nclass PackageScanner(Scanner):\n    \"\"\"\n    Scans package for attack vectors based on source code and metadata rules\n\n    Attributes:\n        analyzer (Analyzer): Analyzer for source code and metadata rules\n    \"\"\"\n\n    def __init__(self) -> None:\n        self.analyzer = Analyzer()\n        super(Scanner)\n\n    def scan_local(self, path, rules=None) -> dict:\n        \"\"\"\n        Scans local package\n\n        Args:\n            path (str): path to package\n            rules (set, optional): Set of rule names to use. Defaults to all rules.\n\n        Raises:\n            Exception: Analyzer exception\n\n        Returns:\n            dict: Analyzer output with rules to results mapping\n        \"\"\"\n\n        if rules is not None:\n            rules = set(rules)\n\n        if os.path.exists(path):\n            if path.endswith('.tar.gz'):\n                with tempfile.TemporaryDirectory() as tmpdirname:\n                    tarsafe.open(path).extractall(tmpdirname)\n                    return self.analyzer.analyze_sourcecode(tmpdirname, rules=rules)\n            elif os.path.isdir(path):\n                return self.analyzer.analyze_sourcecode(path, rules=rules)\n            else:\n                raise Exception(f\"Path {path} is not a directory nor a tar.gz archive.\")\n        raise Exception(f\"Path {path} does not exist.\")\n\n    def _scan_remote(self, name, base_dir, version=None, rules=None, write_package_info=False):\n        directory = os.path.join(os.path.dirname(os.path.abspath(__file__)), base_dir)\n        file_path = os.path.join(directory, name)\n\n        self.download_package(name, directory, version)\n\n        package_info = get_package_info(name)\n\n        results = self.analyzer.analyze(file_path, package_info, rules)\n        if write_package_info:\n            suffix = f\"{name}-{version}\" if version is not None else name\n            with open(os.path.join(results[\"path\"], f'package_info-{suffix}.json'), \"w\") as file:\n                file.write(json.dumps(package_info))\n\n        return results\n\n    def scan_remote(self, name, version=None, rules=None, base_dir=None, write_package_info=False):\n        \"\"\"\n        Scans a remote package\n\n        Args:\n            * `name` (str): name of the package on PyPI\n            * `version` (str, optional): version of package (ex. 0.0.1). If not specified, the latest version is\n            assumed.\n            * `rules` (set, optional): Set of rule names to use. Defaults to all rules.\n            * `base_dir` (str, optional): directory to use to download package to. If not specified, a temporary folder\n            is created and cleaned up automatically. If not specified, the provided directory is not removed after the\n            scan.\n            * `write_package_info` (bool, default False): if set to true, the result of the PyPI metadata API is written\n             to a json file\n\n        Raises:\n            Exception: Analyzer exception\n\n        Returns:\n            dict: Analyzer output with rules to results mapping\n        \"\"\"\n        if (base_dir is not None):\n            return self._scan_remote(name, base_dir, version, rules, write_package_info)\n\n        with tempfile.TemporaryDirectory() as tmpdirname:\n            # Directory to download compressed and uncompressed package\n            return self._scan_remote(name, tmpdirname, version, rules, write_package_info)\n\n    def download_package(self, package_name, directory, version=None) -> None:\n        \"\"\"Downloads the PyPI distribution for a given package and version\n\n        Args:\n            package_name (str): name of the package\n            directory (str): directory to download package to\n            version (str): version of the package\n\n        Raises:\n            Exception: \"Received status code: \" + <not 200> + \" from PyPI\"\n            Exception: \"Version \" + version + \" for package \" + package_name + \" doesn't exist.\"\n            Exception: \"Compressed file for package does not exist.\"\n            Exception: \"Error retrieving package: \" + <error message>\n        Returns:\n            None\n        \"\"\"\n\n        data = get_package_info(package_name)\n        releases = data[\"releases\"]\n\n        if version is None:\n            version = data[\"info\"][\"version\"]\n\n        if version in releases:\n            files = releases[version]\n\n            url = None\n            file_extension = None\n\n            for file in files:\n                # Store url to compressed package and appropriate file extension\n                if file[\"filename\"].endswith(\".tar.gz\"):\n                    url = file[\"url\"]\n                    file_extension = \".tar.gz\"\n\n                if file[\"filename\"].endswith(\".egg\") or file[\"filename\"].endswith(\".whl\") \\\n                        or file[\"filename\"].endswith(\".zip\"):\n                    url = file[\"url\"]\n                    file_extension = \".zip\"\n\n            if url and file_extension:\n                # Path to compressed package\n                zippath = os.path.join(directory, package_name + file_extension)\n                unzippedpath = zippath.removesuffix(file_extension)\n\n                self.download_compressed(url, zippath, unzippedpath)\n            else:\n                raise Exception(f\"Compressed file for {package_name} does not exist on PyPI.\")\n        else:\n            raise Exception(\"Version \" + version + \" for package \" + package_name + \" doesn't exist.\")\n\n    def download_compressed(self, url, zippath, unzippedpath):\n        \"\"\"Downloads a compressed file and extracts it\n\n        Args:\n            url (str): download link\n            zippath (str): path to download compressed file\n            unzippedpath (str): path to unzip compressed file\n        \"\"\"\n\n        response = requests.get(url, stream=True)\n\n        with open(zippath, \"wb\") as f:\n            f.write(response.raw.read())\n\n        if zippath.endswith('.tar.gz'):\n            tarsafe.open(zippath).extractall(unzippedpath)\n            os.remove(zippath)\n        else:\n            raise ValueError(\"unsupported archive extension: \" + zippath)\n", "code_before": "import json\nimport os\nimport shutil\nimport tarsafe  # type: ignore\nimport tempfile\nimport requests\n\nfrom guarddog.analyzer.analyzer import Analyzer\nfrom guarddog.scanners.scanner import Scanner\nfrom guarddog.utils.package_info import get_package_info\n\n\nclass PackageScanner(Scanner):\n    \"\"\"\n    Scans package for attack vectors based on source code and metadata rules\n\n    Attributes:\n        analyzer (Analyzer): Analyzer for source code and metadata rules\n    \"\"\"\n\n    def __init__(self) -> None:\n        self.analyzer = Analyzer()\n        super(Scanner)\n\n    def scan_local(self, path, rules=None) -> dict:\n        \"\"\"\n        Scans local package\n\n        Args:\n            path (str): path to package\n            rules (set, optional): Set of rule names to use. Defaults to all rules.\n\n        Raises:\n            Exception: Analyzer exception\n\n        Returns:\n            dict: Analyzer output with rules to results mapping\n        \"\"\"\n\n        if rules is not None:\n            rules = set(rules)\n\n        if os.path.exists(path):\n            if path.endswith('.tar.gz'):\n                with tempfile.TemporaryDirectory() as tmpdirname:\n                    tarsafe.open(path).extractall(tmpdirname)\n                    return self.analyzer.analyze_sourcecode(tmpdirname, rules=rules)\n            elif os.path.isdir(path):\n                return self.analyzer.analyze_sourcecode(path, rules=rules)\n            else:\n                raise Exception(f\"Path {path} is not a directory nor a tar.gz archive.\")\n        raise Exception(f\"Path {path} does not exist.\")\n\n    def _scan_remote(self, name, base_dir, version=None, rules=None, write_package_info=False):\n        directory = os.path.join(os.path.dirname(os.path.abspath(__file__)), base_dir)\n        file_path = os.path.join(directory, name)\n\n        self.download_package(name, directory, version)\n\n        package_info = get_package_info(name)\n\n        results = self.analyzer.analyze(file_path, package_info, rules)\n        if write_package_info:\n            suffix = f\"{name}-{version}\" if version is not None else name\n            with open(os.path.join(results[\"path\"], f'package_info-{suffix}.json'), \"w\") as file:\n                file.write(json.dumps(package_info))\n\n        return results\n\n    def scan_remote(self, name, version=None, rules=None, base_dir=None, write_package_info=False):\n        \"\"\"\n        Scans a remote package\n\n        Args:\n            * `name` (str): name of the package on PyPI\n            * `version` (str, optional): version of package (ex. 0.0.1). If not specified, the latest version is\n            assumed.\n            * `rules` (set, optional): Set of rule names to use. Defaults to all rules.\n            * `base_dir` (str, optional): directory to use to download package to. If not specified, a temporary folder\n            is created and cleaned up automatically. If not specified, the provided directory is not removed after the\n            scan.\n            * `write_package_info` (bool, default False): if set to true, the result of the PyPI metadata API is written\n             to a json file\n\n        Raises:\n            Exception: Analyzer exception\n\n        Returns:\n            dict: Analyzer output with rules to results mapping\n        \"\"\"\n        if (base_dir is not None):\n            return self._scan_remote(name, base_dir, version, rules, write_package_info)\n\n        with tempfile.TemporaryDirectory() as tmpdirname:\n            # Directory to download compressed and uncompressed package\n            return self._scan_remote(name, tmpdirname, version, rules, write_package_info)\n\n    def download_package(self, package_name, directory, version=None) -> None:\n        \"\"\"Downloads the PyPI distribution for a given package and version\n\n        Args:\n            package_name (str): name of the package\n            directory (str): directory to download package to\n            version (str): version of the package\n\n        Raises:\n            Exception: \"Received status code: \" + <not 200> + \" from PyPI\"\n            Exception: \"Version \" + version + \" for package \" + package_name + \" doesn't exist.\"\n            Exception: \"Compressed file for package does not exist.\"\n            Exception: \"Error retrieving package: \" + <error message>\n        Returns:\n            None\n        \"\"\"\n\n        data = get_package_info(package_name)\n        releases = data[\"releases\"]\n\n        if version is None:\n            version = data[\"info\"][\"version\"]\n\n        if version in releases:\n            files = releases[version]\n\n            url = None\n            file_extension = None\n\n            for file in files:\n                # Store url to compressed package and appropriate file extension\n                if file[\"filename\"].endswith(\".tar.gz\"):\n                    url = file[\"url\"]\n                    file_extension = \".tar.gz\"\n\n                if file[\"filename\"].endswith(\".egg\") or file[\"filename\"].endswith(\".whl\") \\\n                        or file[\"filename\"].endswith(\".zip\"):\n                    url = file[\"url\"]\n                    file_extension = \".zip\"\n\n            if url and file_extension:\n                # Path to compressed package\n                zippath = os.path.join(directory, package_name + file_extension)\n                unzippedpath = zippath.removesuffix(file_extension)\n\n                self.download_compressed(url, zippath, unzippedpath)\n            else:\n                raise Exception(f\"Compressed file for {package_name} does not exist on PyPI.\")\n        else:\n            raise Exception(\"Version \" + version + \" for package \" + package_name + \" doesn't exist.\")\n\n    def download_compressed(self, url, zippath, unzippedpath):\n        \"\"\"Downloads a compressed file and extracts it\n\n        Args:\n            url (str): download link\n            zippath (str): path to download compressed file\n            unzippedpath (str): path to unzip compressed file\n        \"\"\"\n\n        response = requests.get(url, stream=True)\n\n        with open(zippath, \"wb\") as f:\n            f.write(response.raw.read())\n\n        shutil.unpack_archive(zippath, unzippedpath)\n        os.remove(zippath)\n", "patch": "@@ -1,7 +1,6 @@\n import json\n import os\n-import shutil\n-import tarsafe  # type: ignore\n+import tarsafe  # type:ignore\n import tempfile\n import requests\n \n@@ -160,5 +159,8 @@ def download_compressed(self, url, zippath, unzippedpath):\n         with open(zippath, \"wb\") as f:\n             f.write(response.raw.read())\n \n-        shutil.unpack_archive(zippath, unzippedpath)\n-        os.remove(zippath)\n+        if zippath.endswith('.tar.gz'):\n+            tarsafe.open(zippath).extractall(unzippedpath)\n+            os.remove(zippath)\n+        else:\n+            raise ValueError(\"unsupported archive extension: \" + zippath)", "file_path": "files/2022_12/1325", "file_language": "py", "file_name": "guarddog/scanners/package_scanner.py", "outdated_file_modify": 0, "outdated_file_before": 1, "outdated_file_after": 1, "llm_check": 1, "static_check": 0, "static": {"rats": [false, []], "semgrep": [false, []]}, "target": -1, "function_before": [], "function_after": []}], "outdated": 0, "cwe_descripiton": "", "cwe_consequence": "", "cwe_method": "", "cwe_solution": ""}
