{"index": 11198, "cve_id": "CVE-2023-30620", "cwe_id": ["CWE-22"], "cve_language": "Python", "cve_description": "mindsdb is a Machine Learning platform to help developers build AI solutions. In affected versions an unsafe extraction is being performed using `tarfile.extractall()` from a remotely retrieved tarball. Which may lead to the writing of the extracted files to an unintended location. Sometimes, the vulnerability is called a TarSlip or a ZipSlip variant. An attacker may leverage this vulnerability to overwrite any local file which the server process has access to. There is no risk of file exposure with this vulnerability. This issue has been addressed in release `23.2.1.0 `. Users are advised to upgrade. There are no known workarounds for this vulnerability.", "cvss": "7.5", "publish_date": "April 21, 2023", "AV": "NETWORK", "AC": "NETWORK", "PR": "NONE", "UI": "NONE", "S": "UNCHANGED", "C": "NONE", "I": "HIGH", "A": "NONE", "commit_id": "4419b0f0019c000db390b54d8b9d06e1d3670039", "commit_message": "Use safe extract to prevent CVE-2007-4559 bug", "commit_date": "2023-02-16T19:31:12Z", "project": "mindsdb/mindsdb", "url": "https://api.github.com/repos/mindsdb/mindsdb/commits/4419b0f0019c000db390b54d8b9d06e1d3670039", "html_url": "https://github.com/mindsdb/mindsdb/commit/4419b0f0019c000db390b54d8b9d06e1d3670039", "windows_before": [{"commit_id": "169dc42ba98ae11981727b22b20889ccc51c19bc", "commit_date": "Thu Feb 16 19:31:06 2023 +0100", "commit_message": "add query to quickstart.mdx (#4511)", "files_name": ["docs/quickstart.mdx"]}, {"commit_id": "c98b9385e9b5a4aba449243213f48bfd494bc0a9", "commit_date": "Thu Feb 16 19:30:00 2023 +0100", "commit_message": "@l0b64 has signed the CLA from Pull Request #4511", "files_name": ["assets/contributions-agreement/signatures/cla.json"]}, {"commit_id": "940359c8ee9fbc2c86a295a5d498a7ae519a4271", "commit_date": "Thu Feb 16 23:58:14 2023 +0530", "commit_message": "Fix file upload link in retrain doc page (#4508)", "files_name": ["docs/sql/api/retrain.mdx"]}, {"commit_id": "a766214959a39eaa768c0b7e4f75bbe024d52051", "commit_date": "Thu Feb 16 19:26:16 2023 +0100", "commit_message": "@ujwalkumar1995 has signed the CLA from Pull Request #4508", "files_name": ["assets/contributions-agreement/signatures/cla.json"]}, {"commit_id": "5701db970d429a2e900381765660ec3e8871efe4", "commit_date": "Thu Feb 16 19:12:31 2023 +0100", "commit_message": "completed docs and testing", "files_name": ["docs/sql/create/jobs.mdx"]}, {"commit_id": "abae7d940628f486ab6136e31a6b230a2c5642f3", "commit_date": "Thu Feb 16 16:42:24 2023 +0000", "commit_message": "fix CI by removing SF handler", "files_name": ["tests/unit/executor_test_base.py"]}, {"commit_id": "8beb9b492af129e8fc11e25c83c8c948962cb22a", "commit_date": "Thu Feb 16 19:42:00 2023 +0300", "commit_message": "Merge pull request #4505 from mindsdb/fix-4393", "files_name": ["cf3801f31c28018a3bbfd9b1af3b530f04988130 - Thu Feb 16 19:04:57 2023 +0300 : fix: limitStep brakes result", "mindsdb/api/mysql/mysql_proxy/classes/sql_query.py"]}, {"commit_id": "269e88f242557d2368d6d925240fe56be6da440a", "commit_date": "Thu Feb 16 16:54:31 2023 +0100", "commit_message": "Merge pull request #4487 from Sathvik1007/patch-5", "files_name": ["c97848d0e23f50060cc6c6f0b5395f35f2beda6b - Thu Feb 16 16:54:11 2023 +0100 : @ZoranPandovski has signed the CLA from Pull Request #4487", "assets/contributions-agreement/signatures/cla.json"]}, {"commit_id": "f2b78a6f5f760e00100eecc5ef48e17cc9642cf7", "commit_date": "Thu Feb 16 16:28:30 2023 +0100", "commit_message": "updated snowflake connection example", "files_name": ["docs/data-integrations/all-data-integrations.mdx"]}, {"commit_id": "a679200eff52f8ea9182c6f12188df193fae642c", "commit_date": "Thu Feb 16 15:07:45 2023 +0000", "commit_message": "remove statsforecast from CI", "files_name": [".github/workflows/mindsdb.yml"]}, {"commit_id": "3b8ec6a6216eb801c38b5d5dad53540aaf0fdae6", "commit_date": "Thu Feb 16 14:21:13 2023 +0000", "commit_message": "redirect on home btn click", "files_name": ["mindsdb/api/http/namespaces/default.py"]}, {"commit_id": "280201117bb983d05c9ff56d4cc8f96966449ffd", "commit_date": "Thu Feb 16 14:16:53 2023 +0000", "commit_message": "fix model save folder", "files_name": ["mindsdb/integrations/handlers/neuralforecast_handler/neuralforecast_handler.py"]}, {"commit_id": "83e71ba647864b501f614284d9e6eac80fbd3630", "commit_date": "Thu Feb 16 14:07:50 2023 +0000", "commit_message": "check for forbidden login", "files_name": ["mindsdb/api/http/namespaces/default.py"]}, {"commit_id": "ca9ec19cb8c81b8d2d6655e39561b18df03dd5e1", "commit_date": "Thu Feb 16 16:56:06 2023 +0300", "commit_message": "deleted", "files_name": ["mindsdb/.DS_Store", "mindsdb/integrations/.DS_Store"]}, {"commit_id": "d255ed018d32f2dde45bf386596a1c69170c02a2", "commit_date": "Thu Feb 16 16:50:48 2023 +0300", "commit_message": "flake8", "files_name": ["mindsdb/api/mysql/mysql_proxy/executor/executor_commands.py", "mindsdb/integrations/libs/api_handler.py"]}, {"commit_id": "0c29d213bd4d0e221808caf2f489751e0d171aca", "commit_date": "Thu Feb 16 16:49:23 2023 +0300", "commit_message": "Merge branch 'staging' into twitter", "files_name": ["34c0fbfdb32beaa75593809822bc4b004c988a09 - Thu Feb 16 13:43:27 2023 +0000 : add frequency arg", "mindsdb/integrations/handlers/neuralforecast_handler/neuralforecast_handler.py", "tests/unit/ml_handlers/test_neuralforecast.py"]}, {"commit_id": "389724b8f22eb949a9208ee1e9616e897acd0cbb", "commit_date": "Thu Feb 16 16:38:04 2023 +0300", "commit_message": "twitter handler tested", "files_name": ["mindsdb/api/mysql/mysql_proxy/classes/sql_query.py", "mindsdb/api/mysql/mysql_proxy/executor/executor_commands.py", "mindsdb/integrations/handlers/twitter_handler/Manual_QA.md", "mindsdb/integrations/handlers/twitter_handler/README.md", "mindsdb/integrations/handlers/twitter_handler/__about__.py", "mindsdb/integrations/handlers/twitter_handler/__init__.py", "mindsdb/integrations/handlers/twitter_handler/icon.svg", "mindsdb/integrations/handlers/twitter_handler/twitter_handler.py", "mindsdb/integrations/libs/api_handler.py", "mindsdb/integrations/libs/base.py"]}, {"commit_id": "6e85fea0709b7479958cf41b01a6321ccf92b96b", "commit_date": "Thu Feb 16 18:48:04 2023 +0530", "commit_message": " added the commutnity  tutorial links", "files_name": ["docs/connect/tableau.mdx"]}, {"commit_id": "5c439111a303178a67335a55df8bb7b38d2fd428", "commit_date": "Thu Feb 16 13:15:49 2023 +0000", "commit_message": "MWE with example in the docs", "files_name": ["mindsdb/integrations/handlers/neuralforecast_handler/__init__.py", "mindsdb/integrations/handlers/neuralforecast_handler/neuralforecast_handler.py"]}, {"commit_id": "04b6897586a112f0cf81389cb2209b3ba7950764", "commit_date": "Thu Feb 16 12:47:42 2023 +0000", "commit_message": "first version test", "files_name": ["mindsdb/integrations/handlers/neuralforecast_handler/neuralforecast_handler.py", "tests/unit/executor_test_base.py"]}, {"commit_id": "a25bf82caf30d112db2fabc7e48cfb59cd159025", "commit_date": "Thu Feb 16 12:36:26 2023 +0000", "commit_message": "multiple redirection links", "files_name": ["mindsdb/api/http/namespaces/default.py"]}, {"commit_id": "e70db66e6b02f9ba29df1420207bafd7a89ced51", "commit_date": "Thu Feb 16 11:12:11 2023 +0530", "commit_message": "Update tableau.mdx", "files_name": ["docs/connect/tableau.mdx"]}, {"commit_id": "26286b095ec6ab51a085660275f2162f61c53d90", "commit_date": "Wed Feb 15 14:49:28 2023 -0500", "commit_message": "Added community tips to what-is-mindsdb.mdx (#4464)", "files_name": ["docs/what-is-mindsdb.mdx"]}, {"commit_id": "4f05632127b19e484635683dc73dacc4771531dd", "commit_date": "Wed Feb 15 20:48:58 2023 +0100", "commit_message": "Merge pull request #4474 from mindsdb/docs-issue-84", "files_name": ["3c47e303a4dce7b790b0fab1ef6797c61a23c094 - Wed Feb 15 20:48:07 2023 +0100 : @ZepingSun has signed the CLA from Pull Request #4464", "assets/contributions-agreement/signatures/cla.json"]}, {"commit_id": "ccc4f5c068edbb1467ed1265549e915ab2ef03ba", "commit_date": "Wed Feb 15 20:39:52 2023 +0100", "commit_message": "updated syntax section", "files_name": ["docs/sql/create/jobs.mdx"]}, {"commit_id": "6b87bde58cc2484586383bfb4d042dd55eadff36", "commit_date": "Wed Feb 15 19:00:54 2023 +0100", "commit_message": "completed a doc page on issue labels", "files_name": ["docs/contribute/issue-labels.mdx"]}, {"commit_id": "ba53969c42ccb9448df1578d47e7be0fb6f8d0a7", "commit_date": "Wed Feb 15 12:44:14 2023 -0500", "commit_message": "Added my tutorial to the list", "files_name": ["docs/tutorials.mdx"]}, {"commit_id": "5198c48d4a98e8436bb8cec1aa47931d8816f91b", "commit_date": "Wed Feb 15 17:22:25 2023 +0100", "commit_message": "Merge pull request #4476 from Ivanncho/staging", "files_name": ["beac3570d11f5f20462dfdfbf294b51be8d35e1c - Wed Feb 15 17:22:12 2023 +0100 : @Ivanncho has signed the CLA from Pull Request #4476", "assets/contributions-agreement/signatures/cla.json"]}, {"commit_id": "84524a33c4a40ff009d97ea87ed8223b0b26f4d7", "commit_date": "Wed Feb 15 17:19:13 2023 +0100", "commit_message": "Update cloud.mdx", "files_name": ["docs/setup/cloud.mdx"]}, {"commit_id": "b1d7363454caa481861d56888e6da1257ad87227", "commit_date": "Wed Feb 15 17:16:48 2023 +0100", "commit_message": "Update cloud.mdx", "files_name": ["docs/setup/cloud.mdx"]}, {"commit_id": "4b6e03cafc5129a7434f113716d4e60de3752a5f", "commit_date": "Wed Feb 15 17:12:02 2023 +0100", "commit_message": "started working on issue labels page", "files_name": ["docs/contribute/issue-labels.mdx", "docs/mint.json"]}, {"commit_id": "b3acf6f70488f9d2476e394182208b28560692b2", "commit_date": "Wed Feb 15 17:06:37 2023 +0100", "commit_message": "Merge pull request #4472 from DuskoAtanasovski/staging", "files_name": ["a7735620ca7964fa47141ae6a488a5759c2e3315 - Wed Feb 15 17:06:26 2023 +0100 : @DuskoAtanasovski has signed the CLA from Pull Request #4472", "assets/contributions-agreement/signatures/cla.json"]}, {"commit_id": "26668cc27ce16a5055db88abc60f7bc014332415", "commit_date": "Wed Feb 15 17:01:44 2023 +0100", "commit_message": "Update sql.mdx", "files_name": ["docs/rest/sql.mdx"]}, {"commit_id": "55f62fbd61fd8defadc8f9f4ddfefba6dfa65ac6", "commit_date": "Wed Feb 15 15:52:34 2023 +0000", "commit_message": "first version of files to get failing test", "files_name": ["mindsdb/integrations/handlers/neuralforecast_handler/__about__.py", "mindsdb/integrations/handlers/neuralforecast_handler/__init__.py", "mindsdb/integrations/handlers/neuralforecast_handler/neuralforecast_handler.py", "mindsdb/integrations/handlers/neuralforecast_handler/requirements.txt", "mindsdb/integrations/handlers/neuralforecast_handler/setup.py", "tests/unit/ml_handlers/test_neuralforecast.py"]}, {"commit_id": "74d834a90158be54c1d5717fea4c92e2d5601fb4", "commit_date": "Wed Feb 15 15:39:11 2023 +0000", "commit_message": "redirections", "files_name": ["mindsdb/__main__.py", "mindsdb/api/http/namespaces/default.py", "mindsdb/utilities/config.py"]}, {"commit_id": "be60b708c886c523c99a6e4fdfc3a2f93d90b1f1", "commit_date": "Wed Feb 15 14:21:11 2023 +0100", "commit_message": "Update README.md", "files_name": ["README.md"]}, {"commit_id": "1424287562b236ce81aee14e0a8989eaf99cb24a", "commit_date": "Wed Feb 15 10:49:33 2023 +0300", "commit_message": "Merge branch 'staging' into byom-2", "files_name": ["ce056ae90f74ed1eadcb1cb04361bf344860132a - Wed Feb 15 10:44:20 2023 +0300 : raise error if problem with install module", "mindsdb/integrations/handlers/byom_handler/byom_handler.py"]}, {"commit_id": "9d3a1fa311c09e7965cb1fe535dc08afe561c83a", "commit_date": "Tue Feb 14 18:17:16 2023 -0300", "commit_message": "Merge pull request #4453 from mindsdb/modify_pdef_lw_handler", "files_name": ["7209391477de6ac1060d2b76edc7f283d5ec2cba - Tue Feb 14 20:02:30 2023 +0100 : updates in progress", "docs/sql/create/jobs.mdx"]}, {"commit_id": "c3360dbc511f5ef5b9b6224813a7198d628b58ce", "commit_date": "Tue Feb 14 20:22:00 2023 +0300", "commit_message": "removed leftover text", "files_name": ["mindsdb/integrations/handlers/byom_handler/byom_handler.py"]}, {"commit_id": "90d38c5f5cc222891e876d68bc034577a50ef5e3", "commit_date": "Tue Feb 14 17:01:37 2023 +0100", "commit_message": "Merge pull request #4458 from mindsdb/docs-issue-83", "files_name": ["08c0fd1d2e3dc82454fd6f0426b572cd78fbe70b - Tue Feb 14 16:57:55 2023 +0100 : added markdown link and tutorials directory", "docs/contribute/tutorials.mdx"]}, {"commit_id": "75e8ad07c4b4353e49b53abc6a735523fe7393d2", "commit_date": "Tue Feb 14 14:09:13 2023 +0000", "commit_message": "redirectiosn", "files_name": ["mindsdb/__main__.py", "mindsdb/api/http/namespaces/default.py"]}, {"commit_id": "58ff47936ac6c9889f430dae33ac3ee9fc95018b", "commit_date": "Tue Feb 14 12:13:51 2023 +0000", "commit_message": "register client", "files_name": ["mindsdb/__main__.py"]}, {"commit_id": "e8adc3f8c9e60fef430566601ff988b3d6960272", "commit_date": "Tue Feb 14 12:13:23 2023 +0000", "commit_message": "config update method", "files_name": ["mindsdb/api/http/namespaces/config.py", "mindsdb/utilities/config.py"]}, {"commit_id": "d3b50308c86dc339671e5afd855d39f175c4c95e", "commit_date": "Tue Feb 14 12:12:41 2023 +0000", "commit_message": "cloud_login route", "files_name": ["mindsdb/api/http/namespaces/default.py"]}, {"commit_id": "cac6eb463927f64583272eeb243e8adc43e7945d", "commit_date": "Tue Feb 14 12:03:24 2023 +0000", "commit_message": "replace dill with json storage", "files_name": ["mindsdb/integrations/handlers/statsforecast_handler/statsforecast_handler.py"]}, {"commit_id": "7683c82220a0155ce082b8a9917d7a2a2cbef6fc", "commit_date": "Tue Feb 14 15:00:04 2023 +0300", "commit_message": "Merge pull request #4455 from mindsdb/jobs-manage", "files_name": ["62a2cc7d46e8708be5e9091c1787c96e8697e43f - Tue Feb 14 11:48:32 2023 +0000 : Address PR comments up to json set vs file set", "mindsdb/integrations/handlers/statsforecast_handler/requirements.txt", "mindsdb/integrations/handlers/statsforecast_handler/statsforecast_handler.py", "tests/unit/ml_handlers/data/time_series_df.parquet", "tests/unit/ml_handlers/test_statsforecast.py"]}, {"commit_id": "ff24f25e58d2257854c27971c6b8f836c2d48168", "commit_date": "Tue Feb 14 14:28:05 2023 +0300", "commit_message": "Merge pull request #4457 from mindsdb/staging", "files_name": ["0dce9fed1da5f080c0ae3287cec97803af6570da - Tue Feb 14 10:41:59 2023 +0000 : bump version", "mindsdb/__about__.py"]}, {"commit_id": "f176ee28d6c971e81885c8c83aa699fccf4f088d", "commit_date": "Tue Feb 14 10:39:02 2023 +0000", "commit_message": "Merge branch 'staging' into oauth", "files_name": ["09e4eb42aaebf7e92bafd825a1237e806963a894 - Tue Feb 14 13:34:33 2023 +0300 : Merge pull request #4456 from mindsdb/logout-route", "e6069c0e1c672b0bdd7bd9bd1208e95894f443e4 - Tue Feb 14 10:07:30 2023 +0000 : logout test", "tests/integration_tests/flows/test_http.py"]}, {"commit_id": "180f4ec75a35e31cd3d5c6ee292b60106b17017a", "commit_date": "Tue Feb 14 10:03:28 2023 +0000", "commit_message": "logout route", "files_name": ["mindsdb/api/http/namespaces/default.py"]}, {"commit_id": "98c144facc266496f0beb689e9eebcafe33f6852", "commit_date": "Tue Feb 14 12:25:02 2023 +0300", "commit_message": "fix company id in job history", "files_name": ["mindsdb/interfaces/jobs/jobs_controller.py"]}, {"commit_id": "88bb3dcef4551deb6f1ed4c95a0bc003b33c9cc4", "commit_date": "Tue Feb 14 12:06:01 2023 +0300", "commit_message": "Merge pull request #4454 from mindsdb/jobs-manage", "files_name": ["9e2a555cbd7aba12ff147b7ce5caddd5ee403a44 - Tue Feb 14 11:37:37 2023 +0300 : fix working with projects", "mindsdb/interfaces/jobs/jobs_controller.py", "mindsdb/interfaces/storage/db.py", "mindsdb/migrations/versions/2023-02-02_b6d0a47294ac_jobs.py"]}], "windows_after": [{"commit_id": "a55551ed60bc2a5589aeeead59a0f1a1d8894c3d", "commit_date": "Fri Feb 17 11:47:27 2023 +0300", "commit_message": "Handle Mongo API requests in microservice mode (#4465)", "files_name": ["docker/docker-compose.yml", "mindsdb/api/mongo/classes/query_sql.py", "mindsdb/api/mysql/mysql_proxy/executor/executor.py", "mindsdb/api/mysql/mysql_proxy/executor/executor_grpc_client.py", "mindsdb/api/mysql/mysql_proxy/executor/executor_grpc_wrapper.py", "mindsdb/grpc/executor/executor_pb2.py", "mindsdb/grpc/executor/executor_pb2.pyi", "mindsdb/grpc/executor/executor_pb2_grpc.py", "mindsdb/utilities/config.py", "protos/executor.proto"]}, {"commit_id": "9980e3d1b4106026707e139b9beff5040d0bb0ed", "commit_date": "Fri Feb 17 13:58:11 2023 +0300", "commit_message": "set model.integration_id = None when ml engine is deleting #4255", "files_name": ["mindsdb/interfaces/database/integrations.py", "mindsdb/interfaces/storage/db.py"]}, {"commit_id": "46b74d8c5449f0b574a4e613e29e13669be8f38c", "commit_date": "Fri Feb 17 14:00:28 2023 +0300", "commit_message": "jobs project id is not nullable", "files_name": ["mindsdb/interfaces/storage/db.py"]}, {"commit_id": "083367f4bfaac6ee8c557cb02b4f00ee454c4173", "commit_date": "Fri Feb 17 14:02:59 2023 +0300", "commit_message": "+migration", "files_name": ["mindsdb/migrations/versions/2023-02-17_ee63d868fa84_predictor_integration_null.py"]}, {"commit_id": "5043fe42b6b5b05a3e22df19f225876fafe2e570", "commit_date": "Fri Feb 17 15:44:23 2023 +0300", "commit_message": "stop jobs without exception", "files_name": ["mindsdb/interfaces/jobs/scheduler.py"]}, {"commit_id": "e93d2c141897c176c0c598fc011604fc5a029f14", "commit_date": "Fri Feb 17 15:57:08 2023 +0300", "commit_message": "flake8", "files_name": ["mindsdb/interfaces/jobs/scheduler.py"]}, {"commit_id": "0bd2cda9cb98c5e797827df794747ca08493f5f2", "commit_date": "Fri Feb 17 14:11:14 2023 +0100", "commit_message": "Merge pull request #4452 from mindsdb/docs-issue-82", "files_name": ["59e2656ebc8bdde6973b67d9c5f9c5f2569195fb - Fri Feb 17 14:16:59 2023 +0100 : Merge pull request #4495 from mindsdb/docs-issue-85", "85e976472a12847ece0f9a2010be3503457958a8 - Fri Feb 17 14:20:19 2023 +0100 : Lint", "mindsdb/api/http/utils.py"]}, {"commit_id": "99b7b424ac0c2edd7e0389c08475808024a5ccbb", "commit_date": "Fri Feb 17 14:29:33 2023 +0000", "commit_message": "add instnace after login", "files_name": ["mindsdb/api/http/namespaces/default.py"]}, {"commit_id": "8955fadd3240f61ea309c3f38ef9e619aed1b008", "commit_date": "Fri Feb 17 14:29:52 2023 +0000", "commit_message": "better handler aws_metadata", "files_name": ["mindsdb/__main__.py"]}, {"commit_id": "4e2146b42262f213835fa98e250dbb5e88ded631", "commit_date": "Fri Feb 17 14:40:49 2023 +0000", "commit_message": "send ami_id", "files_name": ["mindsdb/api/http/namespaces/default.py"]}, {"commit_id": "e88f86f2446bb9a0af32f763257feed9130b8726", "commit_date": "Fri Feb 17 16:07:07 2023 +0100", "commit_message": "@sammiller06 has signed the CLA from Pull Request #4398", "files_name": ["assets/contributions-agreement/signatures/cla.json"]}, {"commit_id": "8fa2cfc9fec76e0eea083fd93fceed1b30c0bb86", "commit_date": "Fri Feb 17 15:20:38 2023 +0000", "commit_message": "fixes", "files_name": ["mindsdb/api/http/namespaces/default.py"]}, {"commit_id": "7f25f78e54ba1e95531cf1552407e9452d8cc931", "commit_date": "Fri Feb 17 15:26:18 2023 +0000", "commit_message": "fixes", "files_name": ["mindsdb/api/http/namespaces/default.py"]}, {"commit_id": "075f9b6178ccf70b7356a3e5c6e65d580280795e", "commit_date": "Fri Feb 17 15:30:20 2023 +0000", "commit_message": "fix", "files_name": ["mindsdb/api/http/namespaces/default.py"]}, {"commit_id": "38db1745e506871dceaab1f0ef01b5115340d091", "commit_date": "Fri Feb 17 15:33:00 2023 +0000", "commit_message": "fix", "files_name": ["mindsdb/api/http/namespaces/default.py"]}, {"commit_id": "9ca65bb775ca676383b612dd6f82062d6124dd6b", "commit_date": "Fri Feb 17 15:47:14 2023 +0000", "commit_message": "fix", "files_name": ["mindsdb/api/http/namespaces/default.py"]}, {"commit_id": "bd3676ca5d6f81cc826afbe54751c9563e5aff71", "commit_date": "Fri Feb 17 19:07:13 2023 +0100", "commit_message": "started updates to mongo connect pages", "files_name": ["docs/assets/connect_mongo_compass.png", "docs/assets/connect_mongo_compass_1.png", "docs/assets/connect_mongo_compass_2.png", "docs/assets/connect_mongo_compass_3.png", "docs/assets/connect_mongo_shell.png", "docs/connect/mongo-compass.mdx", "docs/connect/mongo-shell.mdx"]}, {"commit_id": "0f32ddc5f167361947810798c91f3e419fcc3056", "commit_date": "Sat Feb 18 01:48:43 2023 +0200", "commit_message": "Update links in Readme.md", "files_name": ["README.md"]}, {"commit_id": "28608835ef66b4d5df6fe07076131f6d3ad42ab0", "commit_date": "Sat Feb 18 08:59:25 2023 +0100", "commit_message": "docs: fix typo in api endpoint", "files_name": ["docs/rest/projects/get-projects.mdx"]}, {"commit_id": "d64e024d2c50f1224e744a5b47a02b4d058110c3", "commit_date": "Sat Feb 18 11:47:08 2023 +0100", "commit_message": "Add gitpod.yml", "files_name": ["gitpod.yml"]}, {"commit_id": "84d10cb93b6450280ac12e1cba0bbde59b4fe70f", "commit_date": "Sat Feb 18 11:53:46 2023 +0100", "commit_message": "Update gitpod.yml filename", "files_name": [".gitpod.yml"]}, {"commit_id": "93274240087c002dc22ea4218bbbac322d48fd01", "commit_date": "Sat Feb 18 12:27:55 2023 +0100", "commit_message": "Update gitpod.yml to follow recommended dev env setup", "files_name": [".gitpod.yml"]}, {"commit_id": "79d5cc12b6c5858c6b9e2fca8c5a9a713f84fca0", "commit_date": "Sat Feb 18 12:36:00 2023 +0100", "commit_message": "Add python virtual environment step", "files_name": [".gitpod.yml"]}, {"commit_id": "a5d33f8121450223fa50d937ab91a81f8b6877a6", "commit_date": "Sat Feb 18 12:30:20 2023 +0000", "commit_message": "Add specific image to gitpod config", "files_name": [".gitpod.yml"]}, {"commit_id": "492bfb720160da1322fdd299b3fc9b84cdd05924", "commit_date": "Sat Feb 18 12:39:02 2023 +0000", "commit_message": "Remove setup.py step", "files_name": [".gitpod.yml"]}, {"commit_id": "583b99f89332e3ebaec174aa4d16977ea79546ec", "commit_date": "Sat Feb 18 13:04:10 2023 +0000", "commit_message": "Add postgres", "files_name": [".gitpod.yml"]}, {"commit_id": "78710348822e1c3cb969f5049abdd06e07c9160c", "commit_date": "Sat Feb 18 13:45:54 2023 +0000", "commit_message": "Set python version in custom gitpod.Dockerfile", "files_name": [".gitpod.Dockerfile", ".gitpod.yml"]}, {"commit_id": "6f954fedee0ec1d17809512acf8b539d5a69224a", "commit_date": "Sat Feb 18 13:48:27 2023 +0000", "commit_message": "Update gitpod config to use custom Dockerfile", "files_name": [".gitpod.yml"]}, {"commit_id": "61fd0d4baf44c4b9bab939155068b2261b173118", "commit_date": "Sat Feb 18 14:56:57 2023 +0100", "commit_message": "Fix pyenv install python version already exist", "files_name": [".gitpod.Dockerfile"]}, {"commit_id": "68a6756dc369b88b9439c17c5d835a0440c08755", "commit_date": "Sat Feb 18 14:07:24 2023 +0000", "commit_message": "Add mintlify docs task to gitpod.yml", "files_name": [".gitpod.yml"]}, {"commit_id": "9b9c3842cb61d2bfc4536069426e88834cf61536", "commit_date": "Sat Feb 18 14:16:59 2023 +0000", "commit_message": "Update node version for gitpod", "files_name": [".gitpod.Dockerfile"]}, {"commit_id": "a0ed3b7099b3855ced6ddc7275e6ab67f695759e", "commit_date": "Sat Feb 18 14:23:45 2023 +0000", "commit_message": "Update mindsdb gitpod port", "files_name": [".gitpod.yml"]}, {"commit_id": "def21acfcfe9e4a1bee6d87efbe39102615a74b0", "commit_date": "Sat Feb 18 14:25:24 2023 +0000", "commit_message": "Add move to docs dir step to gitpod yml", "files_name": [".gitpod.yml"]}, {"commit_id": "ca9d3a0f3e9465779a486b8f459a59374d32ca5a", "commit_date": "Sat Feb 18 15:14:50 2023 +0000", "commit_message": "Remove mintlify docs gitpod task SSR from mintlify is not playing well with how gitpod handles urls and fails to load", "files_name": [".gitpod.yml"]}, {"commit_id": "fae418ff407945088f0d3ab25edda7bc45dce580", "commit_date": "Sat Feb 18 15:18:08 2023 +0000", "commit_message": "Add open in gitpod button", "files_name": ["README.md"]}, {"commit_id": "97726e57d52bb0b7046af0b1b4e7e091a2619686", "commit_date": "Sat Feb 18 20:05:23 2023 +0100", "commit_message": "@seuros has signed the CLA from Pull Request #4523", "files_name": ["assets/contributions-agreement/signatures/cla.json"]}, {"commit_id": "f2ea24fda442bb7c6f2a821685120444fe3f4e35", "commit_date": "Sun Feb 19 09:51:05 2023 +0530", "commit_message": "Update mongo-shell.mdx", "files_name": ["docs/connect/mongo-shell.mdx"]}, {"commit_id": "3b9b008d7020a3a54ec759d3f67f2972b1308ac3", "commit_date": "Sun Feb 19 09:10:38 2023 +0100", "commit_message": "Merge pull request #4523 from seuros/docs", "files_name": ["caf6075bc198d12bdc84e5976de2b0d7c2e97a98 - Sun Feb 19 15:10:51 2023 +0530 : added the icon for the handler", "mindsdb/integrations/handlers/aurora_handler/icon.png"]}, {"commit_id": "78bcbb0565b98757bf2839813a0a21dc517d2be4", "commit_date": "Sun Feb 19 15:16:37 2023 +0530", "commit_message": "updated the name that is passed into the individual handlers that are instantiated and removed db_engine when passing parameters to the PostgresHandler", "files_name": ["mindsdb/integrations/handlers/aurora_handler/aurora_handler.py"]}, {"commit_id": "61d7c93df7153ad1dfa5735bd1a98226e569fec6", "commit_date": "Sun Feb 19 18:12:31 2023 +0530", "commit_message": "added error handling to the get_database_engine() method and also for when the correct db_engine is not specified", "files_name": ["mindsdb/integrations/handlers/aurora_handler/aurora_handler.py"]}, {"commit_id": "26077d64bbe7d2abc5d4a03b4354f3e3673bc949", "commit_date": "Sun Feb 19 18:13:54 2023 +0530", "commit_message": "added db_engine as a parameter to connection_args_example", "files_name": ["mindsdb/integrations/handlers/aurora_handler/aurora_handler.py"]}, {"commit_id": "a2d43bbdc32b8b152f729b16f7c567e25ae11bcd", "commit_date": "Sun Feb 19 18:15:49 2023 +0530", "commit_message": "added separate unit test files to test MySQL and Postgres", "files_name": ["mindsdb/integrations/handlers/aurora_handler/tests/test_aurora_mysql_handler.py", "mindsdb/integrations/handlers/aurora_handler/tests/test_aurora_postgres_handler.py"]}, {"commit_id": "19897afd286d641508c56e092b18547be46f2e4d", "commit_date": "Sun Feb 19 18:20:40 2023 +0530", "commit_message": "updated the naming and some of the parameters of the unit test classes for each engine", "files_name": ["mindsdb/integrations/handlers/aurora_handler/tests/test_aurora_mysql_handler.py", "mindsdb/integrations/handlers/aurora_handler/tests/test_aurora_postgres_handler.py"]}, {"commit_id": "7184536463f65bebdd749e96d609b40ce3b059fc", "commit_date": "Sun Feb 19 19:09:10 2023 +0530", "commit_message": "improved some log messages", "files_name": ["mindsdb/integrations/handlers/aurora_handler/aurora_handler.py"]}, {"commit_id": "0073cf83cc00a63128cf4c0902e24a315d7640a3", "commit_date": "Sun Feb 19 19:09:46 2023 +0530", "commit_message": "implemented the unit tests, but removed sensitive information", "files_name": ["mindsdb/integrations/handlers/aurora_handler/tests/test_aurora_mysql_handler.py", "mindsdb/integrations/handlers/aurora_handler/tests/test_aurora_postgres_handler.py"]}, {"commit_id": "7f4070415883feb973bf226c73a81e87f9ea1c1e", "commit_date": "Sun Feb 19 22:13:04 2023 +0530", "commit_message": "added a README", "files_name": ["mindsdb/integrations/handlers/aurora_handler/README.md"]}, {"commit_id": "a2c632a55a91c148f7a5f5132c5546a6c7740f64", "commit_date": "Sun Feb 19 22:13:55 2023 +0530", "commit_message": "changed the host in connection_args_example dict", "files_name": ["mindsdb/integrations/handlers/aurora_handler/aurora_handler.py"]}, {"commit_id": "78dd8479ee6761fb6de59b6c4cb0352cf8f019f2", "commit_date": "Sun Feb 19 14:49:15 2023 -0500", "commit_message": "Update data-insights.mdx", "files_name": ["docs/sql/data-insights.mdx"]}, {"commit_id": "7e181252c4e582909dedccb0290c0ac14283443d", "commit_date": "Sun Feb 19 21:34:36 2023 +0100", "commit_message": "@ZoranPandovski has signed the CLA from Pull Request #4525", "files_name": ["assets/contributions-agreement/signatures/cla.json"]}, {"commit_id": "b0d375e20befaf53072aada8dbd55ed578632700", "commit_date": "Sun Feb 19 21:36:34 2023 +0100", "commit_message": "Merge pull request #4525 from ktyborowski/add-gitpod", "files_name": ["17d06732510cbe81992eb77ecaa415882a2bb34d - Sun Feb 19 22:07:08 2023 +0100 : @yosileyid has signed the CLA from Pull Request #4540", "assets/contributions-agreement/signatures/cla.json"]}, {"commit_id": "5c33286073f2348ab3a043a3c00ddea69a70a26f", "commit_date": "Sun Feb 19 22:38:58 2023 +0100", "commit_message": "add tutorial links #4481", "files_name": ["docs/connect/sql-alchemy.mdx"]}, {"commit_id": "8ed28dc785a454c516a611be4581799a11db837e", "commit_date": "Mon Feb 20 03:52:48 2023 +0100", "commit_message": "@souravpy has signed the CLA from Pull Request #4526", "files_name": ["assets/contributions-agreement/signatures/cla.json"]}, {"commit_id": "041c00ea9e98732e341c6024d0229c3feca1ffec", "commit_date": "Mon Feb 20 09:02:27 2023 +0100", "commit_message": "Duckdb handler initial commit", "files_name": ["mindsdb/integrations/handlers/duckdb_handler/README.md", "mindsdb/integrations/handlers/duckdb_handler/__about__.py", "mindsdb/integrations/handlers/duckdb_handler/__init__.py", "mindsdb/integrations/handlers/duckdb_handler/duckdb_handler.py", "mindsdb/integrations/handlers/duckdb_handler/icon.png", "mindsdb/integrations/handlers/duckdb_handler/requirements.txt"]}, {"commit_id": "ec01324280ed5f21790f40b4ce0436e059d79050", "commit_date": "Mon Feb 20 09:59:01 2023 +0000", "commit_message": "Merge branch 'staging' into oauth", "files_name": ["0e35e345b65cb35577f3491c91b47d72d7235de5 - Mon Feb 20 11:08:23 2023 +0000 : add created_at columns to `models` and `models_versions`", "mindsdb/api/mysql/mysql_proxy/datahub/datanodes/information_schema_datanode.py", "mindsdb/interfaces/database/projects.py"]}, {"commit_id": "ca4142fea595447e5806ebf34ed8fb5220adc81a", "commit_date": "Mon Feb 20 11:24:23 2023 +0000", "commit_message": "fix", "files_name": ["mindsdb/api/mysql/mysql_proxy/datahub/datanodes/information_schema_datanode.py"]}], "parents": [{"commit_id_before": "e83cdc52f5ec7cd7def1e20e8973931f9cc98f60", "url_before": "https://api.github.com/repos/mindsdb/mindsdb/commits/e83cdc52f5ec7cd7def1e20e8973931f9cc98f60", "html_url_before": "https://github.com/mindsdb/mindsdb/commit/e83cdc52f5ec7cd7def1e20e8973931f9cc98f60"}], "details": [{"raw_url": "https://github.com/mindsdb/mindsdb/raw/4419b0f0019c000db390b54d8b9d06e1d3670039/mindsdb%2Fapi%2Fhttp%2Fnamespaces%2Ffile.py", "code": "import os\nimport zipfile\nimport tarfile\n\nfrom flask import request, current_app as ca\nfrom flask_restx import Resource\nimport tempfile\nimport multipart\nimport requests\n\nfrom mindsdb.utilities import log\nfrom mindsdb.api.http.utils import http_error, safe_extract\nfrom mindsdb.api.http.namespaces.configs.files import ns_conf\nfrom mindsdb.utilities.config import Config\nfrom mindsdb.utilities.context import context as ctx\n\n\n@ns_conf.route('/')\nclass FilesList(Resource):\n    @ns_conf.doc('get_files_list')\n    def get(self):\n        '''List all files'''\n        return ca.file_controller.get_files()\n\n\n@ns_conf.route('/<name>')\n@ns_conf.param('name', \"MindsDB's name for file\")\nclass File(Resource):\n    @ns_conf.doc('put_file')\n    def put(self, name: str):\n        ''' add new file\n            params in FormData:\n                - file\n                - original_file_name [optional]\n        '''\n\n        data = {}\n        mindsdb_file_name = name\n\n        existing_file_names = ca.file_controller.get_files_names()\n\n        def on_field(field):\n            name = field.field_name.decode()\n            value = field.value.decode()\n            data[name] = value\n\n        file_object = None\n\n        def on_file(file):\n            nonlocal file_object\n            data['file'] = file.file_name.decode()\n            file_object = file.file_object\n\n        temp_dir_path = tempfile.mkdtemp(prefix='mindsdb_file_')\n\n        if request.headers['Content-Type'].startswith('multipart/form-data'):\n            parser = multipart.create_form_parser(\n                headers=request.headers,\n                on_field=on_field,\n                on_file=on_file,\n                config={\n                    'UPLOAD_DIR': temp_dir_path.encode(),    # bytes required\n                    'UPLOAD_KEEP_FILENAME': True,\n                    'UPLOAD_KEEP_EXTENSIONS': True,\n                    'MAX_MEMORY_FILE_SIZE': 0\n                }\n            )\n\n            while True:\n                chunk = request.stream.read(8192)\n                if not chunk:\n                    break\n                parser.write(chunk)\n            parser.finalize()\n            parser.close()\n\n            if file_object is not None and not file_object.closed:\n                file_object.close()\n        else:\n            data = request.json\n\n        if mindsdb_file_name in existing_file_names:\n            return http_error(\n                400,\n                \"File already exists\",\n                f\"File with name '{data['file']}' already exists\"\n            )\n\n        if data.get('source_type') == 'url':\n            url = data['source']\n            data['file'] = data['name']\n\n            config = Config()\n            is_cloud = config.get('cloud', False)\n            if is_cloud is True and ctx.user_class != 1:\n                info = requests.head(url)\n                file_size = info.headers.get('Content-Length')\n                try:\n                    file_size = int(file_size)\n                except Exception:\n                    pass\n\n                if file_size is None:\n                    return http_error(\n                        400,\n                        \"Error getting file info\",\n                        \"\u0421an't determine remote file size\"\n                    )\n                if file_size > 1024 * 1024 * 100:\n                    return http_error(\n                        400,\n                        \"File is too big\",\n                        \"Upload limit for file is 100Mb\"\n                    )\n            with requests.get(url, stream=True) as r:\n                if r.status_code != 200:\n                    return http_error(\n                        400,\n                        \"Error getting file\",\n                        f\"Got status code: {r.status_code}\"\n                    )\n                file_path = os.path.join(temp_dir_path, data['file'])\n                with open(file_path, 'wb') as f:\n                    for chunk in r.iter_content(chunk_size=8192):\n                        f.write(chunk)\n\n        original_file_name = data.get('original_file_name')\n\n        file_path = os.path.join(temp_dir_path, data['file'])\n        lp = file_path.lower()\n        if lp.endswith(('.zip', '.tar.gz')):\n            if lp.endswith('.zip'):\n                with zipfile.ZipFile(file_path) as f:\n                    f.extractall(temp_dir_path)\n            elif lp.endswith('.tar.gz'):\n                with tarfile.open(file_path) as f:\n                    safe_extract(f, temp_dir_path)\n            os.remove(file_path)\n            files = os.listdir(temp_dir_path)\n            if len(files) != 1:\n                os.rmdir(temp_dir_path)\n                return http_error(400, 'Wrong content.', 'Archive must contain only one data file.')\n            file_path = os.path.join(temp_dir_path, files[0])\n            mindsdb_file_name = files[0]\n            if not os.path.isfile(file_path):\n                os.rmdir(temp_dir_path)\n                return http_error(400, 'Wrong content.', 'Archive must contain data file in root.')\n\n        ca.file_controller.save_file(mindsdb_file_name, file_path, file_name=original_file_name)\n\n        os.rmdir(temp_dir_path)\n\n        return '', 200\n\n    @ns_conf.doc('delete_file')\n    def delete(self, name: str):\n        '''delete file'''\n\n        try:\n            ca.file_controller.delete_file(name)\n        except Exception as e:\n            log.logger.error(e)\n            return http_error(\n                400,\n                \"Error deleting file\",\n                f\"There was an error while tring to delete file with name '{name}'\"\n            )\n        return '', 200\n", "code_before": "import os\nimport zipfile\nimport tarfile\n\nfrom flask import request, current_app as ca\nfrom flask_restx import Resource\nimport tempfile\nimport multipart\nimport requests\n\nfrom mindsdb.utilities import log\nfrom mindsdb.api.http.utils import http_error\nfrom mindsdb.api.http.namespaces.configs.files import ns_conf\nfrom mindsdb.utilities.config import Config\nfrom mindsdb.utilities.context import context as ctx\n\n\n@ns_conf.route('/')\nclass FilesList(Resource):\n    @ns_conf.doc('get_files_list')\n    def get(self):\n        '''List all files'''\n        return ca.file_controller.get_files()\n\n\n@ns_conf.route('/<name>')\n@ns_conf.param('name', \"MindsDB's name for file\")\nclass File(Resource):\n    @ns_conf.doc('put_file')\n    def put(self, name: str):\n        ''' add new file\n            params in FormData:\n                - file\n                - original_file_name [optional]\n        '''\n\n        data = {}\n        mindsdb_file_name = name\n\n        existing_file_names = ca.file_controller.get_files_names()\n\n        def on_field(field):\n            name = field.field_name.decode()\n            value = field.value.decode()\n            data[name] = value\n\n        file_object = None\n\n        def on_file(file):\n            nonlocal file_object\n            data['file'] = file.file_name.decode()\n            file_object = file.file_object\n\n        temp_dir_path = tempfile.mkdtemp(prefix='mindsdb_file_')\n\n        if request.headers['Content-Type'].startswith('multipart/form-data'):\n            parser = multipart.create_form_parser(\n                headers=request.headers,\n                on_field=on_field,\n                on_file=on_file,\n                config={\n                    'UPLOAD_DIR': temp_dir_path.encode(),    # bytes required\n                    'UPLOAD_KEEP_FILENAME': True,\n                    'UPLOAD_KEEP_EXTENSIONS': True,\n                    'MAX_MEMORY_FILE_SIZE': 0\n                }\n            )\n\n            while True:\n                chunk = request.stream.read(8192)\n                if not chunk:\n                    break\n                parser.write(chunk)\n            parser.finalize()\n            parser.close()\n\n            if file_object is not None and not file_object.closed:\n                file_object.close()\n        else:\n            data = request.json\n\n        if mindsdb_file_name in existing_file_names:\n            return http_error(\n                400,\n                \"File already exists\",\n                f\"File with name '{data['file']}' already exists\"\n            )\n\n        if data.get('source_type') == 'url':\n            url = data['source']\n            data['file'] = data['name']\n\n            config = Config()\n            is_cloud = config.get('cloud', False)\n            if is_cloud is True and ctx.user_class != 1:\n                info = requests.head(url)\n                file_size = info.headers.get('Content-Length')\n                try:\n                    file_size = int(file_size)\n                except Exception:\n                    pass\n\n                if file_size is None:\n                    return http_error(\n                        400,\n                        \"Error getting file info\",\n                        \"\u0421an't determine remote file size\"\n                    )\n                if file_size > 1024 * 1024 * 100:\n                    return http_error(\n                        400,\n                        \"File is too big\",\n                        \"Upload limit for file is 100Mb\"\n                    )\n            with requests.get(url, stream=True) as r:\n                if r.status_code != 200:\n                    return http_error(\n                        400,\n                        \"Error getting file\",\n                        f\"Got status code: {r.status_code}\"\n                    )\n                file_path = os.path.join(temp_dir_path, data['file'])\n                with open(file_path, 'wb') as f:\n                    for chunk in r.iter_content(chunk_size=8192):\n                        f.write(chunk)\n\n        original_file_name = data.get('original_file_name')\n\n        file_path = os.path.join(temp_dir_path, data['file'])\n        lp = file_path.lower()\n        if lp.endswith(('.zip', '.tar.gz')):\n            if lp.endswith('.zip'):\n                with zipfile.ZipFile(file_path) as f:\n                    f.extractall(temp_dir_path)\n            elif lp.endswith('.tar.gz'):\n                with tarfile.open(file_path) as f:\n                    f.extractall(temp_dir_path)\n            os.remove(file_path)\n            files = os.listdir(temp_dir_path)\n            if len(files) != 1:\n                os.rmdir(temp_dir_path)\n                return http_error(400, 'Wrong content.', 'Archive must contain only one data file.')\n            file_path = os.path.join(temp_dir_path, files[0])\n            mindsdb_file_name = files[0]\n            if not os.path.isfile(file_path):\n                os.rmdir(temp_dir_path)\n                return http_error(400, 'Wrong content.', 'Archive must contain data file in root.')\n\n        ca.file_controller.save_file(mindsdb_file_name, file_path, file_name=original_file_name)\n\n        os.rmdir(temp_dir_path)\n\n        return '', 200\n\n    @ns_conf.doc('delete_file')\n    def delete(self, name: str):\n        '''delete file'''\n\n        try:\n            ca.file_controller.delete_file(name)\n        except Exception as e:\n            log.logger.error(e)\n            return http_error(\n                400,\n                \"Error deleting file\",\n                f\"There was an error while tring to delete file with name '{name}'\"\n            )\n        return '', 200\n", "patch": "@@ -9,7 +9,7 @@\n import requests\n \n from mindsdb.utilities import log\n-from mindsdb.api.http.utils import http_error\n+from mindsdb.api.http.utils import http_error, safe_extract\n from mindsdb.api.http.namespaces.configs.files import ns_conf\n from mindsdb.utilities.config import Config\n from mindsdb.utilities.context import context as ctx\n@@ -134,7 +134,7 @@ def on_file(file):\n                     f.extractall(temp_dir_path)\n             elif lp.endswith('.tar.gz'):\n                 with tarfile.open(file_path) as f:\n-                    f.extractall(temp_dir_path)\n+                    safe_extract(f, temp_dir_path)\n             os.remove(file_path)\n             files = os.listdir(temp_dir_path)\n             if len(files) != 1:", "file_path": "files/2023_4/203", "file_language": "py", "file_name": "mindsdb/api/http/namespaces/file.py", "outdated_file_modify": 0, "outdated_file_before": 0, "outdated_file_after": 0, "llm_check": 1, "static_check": 1, "static": {"rats": [false, []], "semgrep": [true, ["       trailofbits.python.tarfile-extractall-traversal.tarfile-extractall-traversal              \n          Possible path traversal through `tarfile.open($PATH).extractall()` if the source tar is\n          controlled by an attacker                                                              \n          Details: https://sg.run/2RLD                                                           \n\n          136\u2506 with tarfile.open(file_path) as f:          137\u2506     f.extractall(temp_dir_path)"]]}, "target": 1, "function_before": [], "function_after": []}, {"raw_url": "https://github.com/mindsdb/mindsdb/raw/4419b0f0019c000db390b54d8b9d06e1d3670039/mindsdb%2Fapi%2Fhttp%2Futils.py", "code": "import json\nimport os\n\nfrom flask import Response\n\n\ndef http_error(status_code, title, detail=''):\n    ''' Wrapper for error responce acoording with RFC 7807 (https://tools.ietf.org/html/rfc7807)\n\n        :param status_code: int - http status code for response\n        :param title: str\n        :param detail: str\n\n        :return: flask Response object\n    '''\n    return Response(\n        response=json.dumps({\n            'title': title,\n            'detail': detail\n        }),\n        status=status_code,\n        headers={\n            'Content-Type': 'application/problem+json'\n        }\n    )\n\ndef __is_within_directory(directory, target):\n    abs_directory = os.path.abspath(directory)\n    abs_target = os.path.abspath(target)\n    prefix = os.path.commonprefix([abs_directory, abs_target])\n    return prefix == abs_directory\n\ndef safe_extract(tar, path=\".\", members=None, *, numeric_owner=False):\n    for member in tar.getmembers():\n        member_path = os.path.join(path, member.name)\n        if not __is_within_directory(path, member_path):\n            raise Exception(\"Attempted Path Traversal in Tar File\")\n    tar.extractall(path, members, numeric_owner) \n\n", "code_before": "import json\n\nfrom flask import Response\n\n\ndef http_error(status_code, title, detail=''):\n    ''' Wrapper for error responce acoording with RFC 7807 (https://tools.ietf.org/html/rfc7807)\n\n        :param status_code: int - http status code for response\n        :param title: str\n        :param detail: str\n\n        :return: flask Response object\n    '''\n    return Response(\n        response=json.dumps({\n            'title': title,\n            'detail': detail\n        }),\n        status=status_code,\n        headers={\n            'Content-Type': 'application/problem+json'\n        }\n    )\n", "patch": "@@ -1,4 +1,5 @@\n import json\n+import os\n \n from flask import Response\n \n@@ -22,3 +23,17 @@ def http_error(status_code, title, detail=''):\n             'Content-Type': 'application/problem+json'\n         }\n     )\n+\n+def __is_within_directory(directory, target):\n+    abs_directory = os.path.abspath(directory)\n+    abs_target = os.path.abspath(target)\n+    prefix = os.path.commonprefix([abs_directory, abs_target])\n+    return prefix == abs_directory\n+\n+def safe_extract(tar, path=\".\", members=None, *, numeric_owner=False):\n+    for member in tar.getmembers():\n+        member_path = os.path.join(path, member.name)\n+        if not __is_within_directory(path, member_path):\n+            raise Exception(\"Attempted Path Traversal in Tar File\")\n+    tar.extractall(path, members, numeric_owner) \n+", "file_path": "files/2023_4/204", "file_language": "py", "file_name": "mindsdb/api/http/utils.py", "outdated_file_modify": 0, "outdated_file_before": 0, "outdated_file_after": 0, "llm_check": 1, "static_check": 0, "static": {"rats": [false, []], "semgrep": [false, []]}, "target": -1, "function_before": [], "function_after": []}], "outdated": 0, "cwe_descripiton": "", "cwe_consequence": "", "cwe_method": "", "cwe_solution": ""}
