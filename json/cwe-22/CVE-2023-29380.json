{"index": 11416, "cve_id": "CVE-2023-29380", "cwe_id": ["CWE-22"], "cve_language": "Python", "cve_description": "Warpinator before 1.6.0 allows remote file deletion via directory traversal in top_dir_basenames.", "cvss": "7.5", "publish_date": "May 28, 2023", "AV": "NETWORK", "AC": "NETWORK", "PR": "NONE", "UI": "NONE", "S": "UNCHANGED", "C": "NONE", "I": "NONE", "A": "HIGH", "commit_id": "9aae768522b7bbb09c836419893802a02221d663", "commit_message": "Improve incoming file path validation.\n\n- Refactor test.\n- Check top_dir_basenames when processing initial request, and\n  immediately fail the transfer if necessary.\n- Check individual files during transfer as before.\n\nThese are less important when using landlock/bubblewrap but will\nprovide better explanations for any issues than 'read only\nfilesystem'.", "commit_date": "2023-03-05T18:51:25Z", "project": "linuxmint/warpinator", "url": "https://api.github.com/repos/linuxmint/warpinator/commits/9aae768522b7bbb09c836419893802a02221d663", "html_url": "https://github.com/linuxmint/warpinator/commit/9aae768522b7bbb09c836419893802a02221d663", "windows_before": [{"commit_id": "1fb784f6e2942bdc7a7e68225969fd4de52001a1", "commit_date": "Sun Mar 5 11:47:16 2023 -0500", "commit_message": "Add warpinator-send utility.", "files_name": ["bin/meson.build", "bin/warpinator-send.in", "data/meson.build", "data/org.x.Warpinator.xml", "data/warpinator-send-check", "data/warpinator-send.nemo_action.in", "install-scripts/meson_install_bin_script.sh", "makepot", "src/dbus_service.py", "src/meson.build", "src/notifications.py", "src/ops.py", "src/remote.py", "src/warpinator.py"]}, {"commit_id": "8da5441f57d795662ffe30c6cca6f85c6f9235af", "commit_date": "Sat Mar 4 11:57:51 2023 -0500", "commit_message": "Move some util functions into a new file.", "files_name": ["src/meson.build", "src/misc.py", "src/notifications.py", "src/ops.py", "src/prefs.py", "src/remote.py", "src/server.py", "src/transfers.py", "src/util.py", "src/warpinator.py", "testing/testing.py"]}, {"commit_id": "f7714a2a3a252b47229833b39e6e685e1f5bd362", "commit_date": "Thu Mar 2 23:54:14 2023 -0500", "commit_message": "Check if recents can be written to before attempting it.", "files_name": ["src/util.py"]}, {"commit_id": "985794e2f0ad66e79af2e8b2f04ad94bb2afae43", "commit_date": "Wed Feb 22 19:55:09 2023 -0500", "commit_message": "Forbid some locations from being chosen as the save folder.", "files_name": ["src/util.py"]}, {"commit_id": "a4a0b0dfcc8175a006df888bd71b43793a99f5c5", "commit_date": "Wed Feb 22 14:09:16 2023 -0500", "commit_message": "Implement incoming folder isolation.", "files_name": ["bin/warpinator.in", "data/org.x.Warpinator.gschema.xml", "debian/warpinator.debhelper.log", "resources/main-window.ui", "resources/meson.build", "src/config.py.in", "src/launcher.py", "src/meson.build", "src/ops.py", "src/prefs.py", "src/remote.py", "src/server.py", "src/transfers.py", "src/util.py", "src/warpinator.py"]}, {"commit_id": "8e4f62a29b9d78e429d28e87fa4344d013745bb3", "commit_date": "Wed Feb 22 13:45:18 2023 -0500", "commit_message": "Include the python landlock module.", "files_name": ["meson.build", "meson_options.txt", "src/landlock/LICENSE", "src/landlock/__init__.py", "src/landlock/plumbing.py", "src/landlock/porcelain.py", "src/meson.build"]}, {"commit_id": "bed4cb236ab947d2d3fb17d7ab71826d14f18a05", "commit_date": "Wed Feb 22 13:41:52 2023 -0500", "commit_message": "Migrate group code and connect ids to gsettings.", "files_name": ["data/org.x.Warpinator.gschema.xml", "src/auth.py", "src/prefs.py", "src/server.py"]}, {"commit_id": "c25e8af408facfc5eaa3cce987dc6190834683af", "commit_date": "Wed Feb 22 14:37:54 2023 -0500", "commit_message": "remote: Improve readability of rpc calls.", "files_name": ["src/remote.py"]}, {"commit_id": "57c8c571ffa4f8de84905ee48ac6d1d4d53f6fce", "commit_date": "Wed Feb 22 13:32:18 2023 -0500", "commit_message": "Improve some logging.", "files_name": ["src/auth.py", "src/remote.py", "src/server.py"]}, {"commit_id": "e78375529e676aa6264187ec4e813fdbf0c5d3fb", "commit_date": "Wed Feb 22 13:51:41 2023 -0500", "commit_message": "notifications: Fix indentation.", "files_name": ["src/notifications.py"]}, {"commit_id": "d655bba8c3599dca3b805165fbed1bddd5a3b2a7", "commit_date": "Wed Feb 22 13:25:37 2023 -0500", "commit_message": "build: Fix deprecation warning.", "files_name": ["data/meson.build", "meson.build"]}, {"commit_id": "7390641ca1a7b4b80eaa748af64fc0d9accb9857", "commit_date": "Sun Feb 19 09:55:48 2023 +0000", "commit_message": "1.4.5", "files_name": ["debian/changelog", "meson.build"]}, {"commit_id": "b600450a5071978b7d4eddd7ed57e54449271a5e", "commit_date": "Wed Feb 15 09:51:41 2023 -0500", "commit_message": "Update README.md firewall section, and update the ufw script.", "files_name": ["README.md", "doc/firewall-1.png", "doc/firewall-2.png", "doc/firewall-3.png", "doc/firewall-4.png", "src/firewall/ufw-modify"]}, {"commit_id": "3c08a37bd445cf0e16ed3c3983ed6ca3516fb685", "commit_date": "Thu Feb 2 15:46:00 2023 +0100", "commit_message": "replace equality None check with identity None check (#152)", "files_name": ["src/auth.py", "src/networkmonitor.py", "src/ops.py", "src/prefs.py", "src/remote.py", "src/remote_registration.py", "src/server.py", "src/transfers.py", "src/util.py", "src/warpinator.py"]}, {"commit_id": "235837bf8c1bd961674feefd8d1ba9028857a6fb", "commit_date": "Sat Jan 28 13:15:25 2023 -0500", "commit_message": "remote_registration: Do not loop registration attempts.", "files_name": ["src/remote_registration.py", "src/server.py"]}, {"commit_id": "3894392fa113a1672bbc7c4f95fcbdcaebd22f11", "commit_date": "Thu Jan 26 12:00:00 2023 -0500", "commit_message": "Only raise the window the first time it's noticed that the save folder is bad.", "files_name": ["src/warpinator.py"]}, {"commit_id": "821a3b2d2e95384859e5db3e3bb509a46e3c26fb", "commit_date": "Thu Jan 26 11:59:12 2023 -0500", "commit_message": "Move default save folder to ~/Downloads/Warpinator.", "files_name": ["src/prefs.py"]}, {"commit_id": "34b18a19e4208da517668bf11f09c9e562f6ccc3", "commit_date": "Thu Jan 26 14:17:11 2023 +0000", "commit_message": "1.4.4", "files_name": ["debian/changelog", "meson.build"]}, {"commit_id": "2a48e80395aeb6c1412d71921134a9be3e797824", "commit_date": "Mon Jan 23 13:12:45 2023 -0500", "commit_message": "Notifications: re-enable actions in the flatpak version.", "files_name": ["src/notifications.py"]}, {"commit_id": "1889a484820969d8e71418e03bf024ead22a1662", "commit_date": "Mon Jan 16 08:52:00 2023 -0500", "commit_message": "transfers.py: Add missing import.", "files_name": ["src/transfers.py"]}, {"commit_id": "a3795bc929c20382304a674c80a7091ef758ee6d", "commit_date": "Mon Jan 16 08:37:01 2023 -0500", "commit_message": "transfers.py: Fix typo.", "files_name": ["src/transfers.py"]}, {"commit_id": "1773127d1f7fd5fca20610ed655df104e25177a4", "commit_date": "Fri Dec 16 13:19:51 2022 +0000", "commit_message": "1.4.3", "files_name": ["debian/changelog", "meson.build"]}, {"commit_id": "3a0a2a3f1038649da54146316c8f81fe6c8326ec", "commit_date": "Fri Dec 16 13:19:08 2022 +0000", "commit_message": "l10n: Update translations", "files_name": ["po/am.po", "po/ar.po", "po/be.po", "po/bg.po", "po/bn.po", "po/ca.po", "po/cs.po", "po/cy.po", "po/da.po", "po/de.po", "po/el.po", "po/en_CA.po", "po/en_GB.po", "po/eo.po", "po/es.po", "po/et.po", "po/eu.po", "po/fi.po", "po/fr.po", "po/fr_CA.po", "po/fy.po", "po/he.po", "po/hi.po", "po/hr.po", "po/hu.po", "po/ia.po", "po/id.po", "po/ie.po", "po/is.po", "po/it.po", "po/ja.po", "po/kab.po", "po/kk.po", "po/kn.po", "po/ko.po", "po/la.po", "po/lt.po", "po/ne.po", "po/nl.po", "po/oc.po", "po/pa.po", "po/pl.po", "po/pt.po", "po/pt_BR.po", "po/ro.po", "po/ru.po", "po/sk.po", "po/sl.po", "po/sr.po", "po/sr@latin.po", "po/sv.po", "po/tr.po", "po/uk.po", "po/uz.po", "po/vi.po", "po/zgh.po", "po/zh_CN.po", "po/zh_HK.po", "po/zh_TW.po"]}], "windows_after": [{"commit_id": "d655bba8c3599dca3b805165fbed1bddd5a3b2a7", "commit_date": "Wed Feb 22 13:25:37 2023 -0500", "commit_message": "build: Fix deprecation warning.", "files_name": ["data/meson.build", "meson.build"]}, {"commit_id": "e78375529e676aa6264187ec4e813fdbf0c5d3fb", "commit_date": "Wed Feb 22 13:51:41 2023 -0500", "commit_message": "notifications: Fix indentation.", "files_name": ["src/notifications.py"]}, {"commit_id": "57c8c571ffa4f8de84905ee48ac6d1d4d53f6fce", "commit_date": "Wed Feb 22 13:32:18 2023 -0500", "commit_message": "Improve some logging.", "files_name": ["src/auth.py", "src/remote.py", "src/server.py"]}, {"commit_id": "c25e8af408facfc5eaa3cce987dc6190834683af", "commit_date": "Wed Feb 22 14:37:54 2023 -0500", "commit_message": "remote: Improve readability of rpc calls.", "files_name": ["src/remote.py"]}, {"commit_id": "bed4cb236ab947d2d3fb17d7ab71826d14f18a05", "commit_date": "Wed Feb 22 13:41:52 2023 -0500", "commit_message": "Migrate group code and connect ids to gsettings.", "files_name": ["data/org.x.Warpinator.gschema.xml", "src/auth.py", "src/prefs.py", "src/server.py"]}, {"commit_id": "8e4f62a29b9d78e429d28e87fa4344d013745bb3", "commit_date": "Wed Feb 22 13:45:18 2023 -0500", "commit_message": "Include the python landlock module.", "files_name": ["meson.build", "meson_options.txt", "src/landlock/LICENSE", "src/landlock/__init__.py", "src/landlock/plumbing.py", "src/landlock/porcelain.py", "src/meson.build"]}, {"commit_id": "a4a0b0dfcc8175a006df888bd71b43793a99f5c5", "commit_date": "Wed Feb 22 14:09:16 2023 -0500", "commit_message": "Implement incoming folder isolation.", "files_name": ["bin/warpinator.in", "data/org.x.Warpinator.gschema.xml", "debian/warpinator.debhelper.log", "resources/main-window.ui", "resources/meson.build", "src/config.py.in", "src/launcher.py", "src/meson.build", "src/ops.py", "src/prefs.py", "src/remote.py", "src/server.py", "src/transfers.py", "src/util.py", "src/warpinator.py"]}, {"commit_id": "985794e2f0ad66e79af2e8b2f04ad94bb2afae43", "commit_date": "Wed Feb 22 19:55:09 2023 -0500", "commit_message": "Forbid some locations from being chosen as the save folder.", "files_name": ["src/util.py"]}, {"commit_id": "f7714a2a3a252b47229833b39e6e685e1f5bd362", "commit_date": "Thu Mar 2 23:54:14 2023 -0500", "commit_message": "Check if recents can be written to before attempting it.", "files_name": ["src/util.py"]}, {"commit_id": "8da5441f57d795662ffe30c6cca6f85c6f9235af", "commit_date": "Sat Mar 4 11:57:51 2023 -0500", "commit_message": "Move some util functions into a new file.", "files_name": ["src/meson.build", "src/misc.py", "src/notifications.py", "src/ops.py", "src/prefs.py", "src/remote.py", "src/server.py", "src/transfers.py", "src/util.py", "src/warpinator.py", "testing/testing.py"]}, {"commit_id": "1fb784f6e2942bdc7a7e68225969fd4de52001a1", "commit_date": "Sun Mar 5 11:47:16 2023 -0500", "commit_message": "Add warpinator-send utility.", "files_name": ["bin/meson.build", "bin/warpinator-send.in", "data/meson.build", "data/org.x.Warpinator.xml", "data/warpinator-send-check", "data/warpinator-send.nemo_action.in", "install-scripts/meson_install_bin_script.sh", "makepot", "src/dbus_service.py", "src/meson.build", "src/notifications.py", "src/ops.py", "src/remote.py", "src/warpinator.py"]}, {"commit_id": "c0a2998a21e429d29c02b12870b5da4341c2d074", "commit_date": "Sun Mar 5 14:14:36 2023 -0500", "commit_message": "bubblewrap: Fixes for debian/lmde.", "files_name": ["bin/warpinator.in"]}, {"commit_id": "efc9e5621cb335a54eed6728818e2a7a25b81ed4", "commit_date": "Wed Mar 15 15:24:53 2023 -0400", "commit_message": "transfers.py: Use generic getter for file content type.", "files_name": ["src/transfers.py"]}, {"commit_id": "471d78a6f1b16077645c2b33e4ce5e174f51e2bf", "commit_date": "Wed Mar 22 15:26:32 2023 -0400", "commit_message": "build: Fix dh_python3 byte-compilation.", "files_name": ["debian/py3dist-overrides", "debian/rules"]}, {"commit_id": "036de05c984ab83196b9943a53161426904e1530", "commit_date": "Wed Mar 22 15:43:51 2023 -0400", "commit_message": "Simplify startup scripts.", "files_name": [".gitignore", "bin/meson.build", "bin/warpinator-send.in", "bin/warpinator.in", "data/meson.build", "debian/warpinator.debhelper.log", "install-scripts/meson.build", "install-scripts/meson_install_bin_script.sh", "src/config.py.in", "src/launcher.py", "src/meson.build", "src/server.py", "src/util.py", "src/warpinator-launch.py", "src/warpinator.py"]}, {"commit_id": "f1045ca3b42f2db797380e648fa8598b582e9f6a", "commit_date": "Wed Mar 22 15:47:25 2023 -0400", "commit_message": "Remove some remnants of a previous grpc version.", "files_name": ["src/grpc-py310-x86_64/grpcio-1.41.1.dist-info/LICENSE", "src/grpc-py310-x86_64/grpcio-1.41.1.dist-info/METADATA", "src/grpc-py310-x86_64/grpcio-1.41.1.dist-info/RECORD", "src/grpc-py310-x86_64/grpcio-1.41.1.dist-info/WHEEL", "src/grpc-py310-x86_64/grpcio-1.41.1.dist-info/top_level.txt"]}, {"commit_id": "4cd477d5d6b94b51be0e2a0f4f7b1f0021fd5cb5", "commit_date": "Thu Mar 23 14:22:55 2023 -0400", "commit_message": "free space monitor: Improve readability, comments.", "files_name": ["src/util.py"]}, {"commit_id": "21b23bcae79bc89c1de8dead70d78b613b63d16b", "commit_date": "Thu Mar 23 19:07:16 2023 -0400", "commit_message": "free space: Don't run the monitor when only sending files.", "files_name": ["src/server.py", "src/warpinator.py"]}, {"commit_id": "6cbb645a420401f3f86d74ea19916b1c0104d4ab", "commit_date": "Thu Apr 20 13:49:10 2023 -0400", "commit_message": "Clean up --help information, add a new section to the README to explain landlock, bubblewrap.", "files_name": ["README.md", "src/warpinator-launch.py"]}, {"commit_id": "0087a44e26ba26a6bb97de543d7f29ee84b90704", "commit_date": "Thu Apr 20 13:51:16 2023 -0400", "commit_message": "Add an infobar for a sandbox warning.", "files_name": ["resources/main-window.ui", "src/warpinator.py"]}, {"commit_id": "8fce03e9f1b2375b3182436124ee00ee073dd5e3", "commit_date": "Thu Apr 20 13:55:00 2023 -0400", "commit_message": "Cleanup bubblewrap arguments, sandbox_mode setting, exit if the user specifies a mode that isn't available, explain file manager launch complexities.", "files_name": ["src/config.py.in", "src/misc.py", "src/util.py", "src/warpinator-launch.py", "src/warpinator.py"]}, {"commit_id": "dcd9df9c177899db5c95086343c77d60c18b5478", "commit_date": "Thu Apr 20 15:35:18 2023 -0400", "commit_message": "Simpliy NewThreadExecutor a bit.", "files_name": ["src/util.py"]}, {"commit_id": "3ed6ed04a1a305d2cca22602af9efbb106e09e90", "commit_date": "Mon Apr 24 11:45:31 2023 +0100", "commit_message": "l10n: Update POT", "files_name": ["warpinator.pot"]}, {"commit_id": "f34a0cf5dadbca9f420b4d87fcf5b913e390aa7e", "commit_date": "Mon Apr 24 11:45:39 2023 +0100", "commit_message": "1.6.0", "files_name": ["debian/changelog", "meson.build"]}, {"commit_id": "93bdc74387c7e6195fb28f1e4e262ae1d71c17bd", "commit_date": "Tue Apr 25 06:24:00 2023 -0400", "commit_message": "warpinator-launch.py: Fix bubblewrap launch string.", "files_name": ["src/warpinator-launch.py", "src/warpinator.py"]}, {"commit_id": "84f7e4ada1049ba637d19f0a6b75f1bb20d4816d", "commit_date": "Tue Apr 25 06:33:26 2023 -0400", "commit_message": "warpinator-send: Give a better error if warpinator isn't running.", "files_name": ["bin/warpinator-send.in"]}, {"commit_id": "e2ae3d2cb9d16d782e67ac1a0ef83cd22f4ebe41", "commit_date": "Tue Apr 25 07:28:53 2023 -0400", "commit_message": "Add /dev back to bubblewrap args.", "files_name": ["src/warpinator-launch.py"]}, {"commit_id": "5915ce7914c5c4d92ab3385fef62f51e7cd3a71f", "commit_date": "Tue Apr 25 16:07:39 2023 +0100", "commit_message": "1.6.1", "files_name": ["debian/changelog", "meson.build"]}, {"commit_id": "d43434e8a183bf523fdc067df3c836ac348f1400", "commit_date": "Thu Apr 27 02:14:45 2023 +0800", "commit_message": "Possible remaining_count fixes (#174)", "files_name": ["src/remote.py", "src/transfers.py"]}, {"commit_id": "52f9dda44d9f047e4bac00034de82e6cd8e1f2eb", "commit_date": "Mon May 8 19:38:29 2023 +0200", "commit_message": "Correct a typo in `README.md` (#175)", "files_name": ["README.md"]}, {"commit_id": "ff99e4946695c53ee78a97bb7a9dff36aa8876d3", "commit_date": "Mon May 8 20:23:06 2023 -0400", "commit_message": "github workflow: Add optional ssh session.", "files_name": [".github/workflows/build.yml"]}, {"commit_id": "311046d000d943d2563c39058fab2fa67ca3c3fe", "commit_date": "Mon May 22 15:29:02 2023 +0200", "commit_message": "Add `bash` syntax highlighting to `README.md` (#176)", "files_name": ["README.md"]}, {"commit_id": "b5c0513675520db79b1198cf6bdb89b22512cbca", "commit_date": "Thu Jun 1 12:11:43 2023 +0100", "commit_message": "1.6.2", "files_name": ["debian/changelog", "meson.build"]}, {"commit_id": "d065ce3d10a2c69efa15f2447a0ac5bed7fbefee", "commit_date": "Tue Jun 6 14:02:11 2023 +0100", "commit_message": "l10n: Update POT", "files_name": ["resources/main-window.ui", "warpinator.pot"]}, {"commit_id": "15eaba1db478fbc4bf9820f8014c8527cc71b32f", "commit_date": "Thu Jun 8 12:04:03 2023 +0100", "commit_message": "l10n: Update translations", "files_name": ["po/am.po", "po/ar.po", "po/be.po", "po/bg.po", "po/bn.po", "po/ca.po", "po/cs.po", "po/cy.po", "po/da.po", "po/de.po"]}], "parents": [{"commit_id_before": "a4a0b0dfcc8175a006df888bd71b43793a99f5c5", "url_before": "https://api.github.com/repos/linuxmint/warpinator/commits/a4a0b0dfcc8175a006df888bd71b43793a99f5c5", "html_url_before": "https://github.com/linuxmint/warpinator/commit/a4a0b0dfcc8175a006df888bd71b43793a99f5c5"}], "details": [{"raw_url": "https://github.com/linuxmint/warpinator/raw/9aae768522b7bbb09c836419893802a02221d663/src%2Fops.py", "code": "#!/usr/bin/python3\n\nimport gettext\nimport logging\nfrom pathlib import Path\n\nfrom gi.repository import GObject, GLib, Gio\n\nimport grpc\n\nimport transfers\nimport prefs\nimport util\nimport notifications\nfrom util import OpStatus, OpCommand, TransferDirection, ReceiveError\n\n_ = gettext.gettext\n\nclass CommonOp(GObject.Object):\n    __gsignals__ = {\n        \"status-changed\": (GObject.SignalFlags.RUN_LAST, None, ()),\n        \"initial-setup-complete\": (GObject.SignalFlags.RUN_LAST, None, ()),\n        \"op-command\": (GObject.SignalFlags.RUN_LAST, None, (int,)),\n        \"progress-changed\": (GObject.SignalFlags.RUN_LAST, None, ()),\n        \"active\": (GObject.SignalFlags.RUN_LAST, None, ()),\n        \"focus\": (GObject.SignalFlags.RUN_LAST, None, ())\n    }\n    def __init__(self, direction, sender, uris=None):\n        super(CommonOp, self).__init__()\n        self.uris = uris\n        self.sender = sender\n        self.direction = direction\n        self.status = OpStatus.INIT\n        self.start_time = GLib.get_monotonic_time() # for sorting in the op list\n\n        self.total_size = 0\n        self.total_count = 0\n        self.remaining_count = 0\n\n        self.size_string = \"\"\n        self.description = \"\"\n        self.name_if_single = None\n        self.mime_if_single = \"application/octet-stream\" # unknown\n        self.gicon = Gio.content_type_get_symbolic_icon(self.mime_if_single)\n\n        self.error_msg = \"\"\n\n        self.progress_tracker = None\n\n    def progress_report(self, report):\n        self.current_progress_report = report\n        report.progress_text = _(\"%(time_left)s (%(bytes_per_sec)s/s)\") \\\n                                   % ({\n                                         \"time_left\": util.format_time_span(report.time_left_sec),\n                                         \"bytes_per_sec\": GLib.format_size(report.bytes_per_sec)\n                                     })\n\n        if report.progress == 1.0:\n            self.status = OpStatus.FINISHED\n            self.emit_status_changed()\n            return\n\n        self.emit(\"active\")\n        self.emit(\"progress-changed\")\n\n    def get_progress_text(self):\n        try:\n            return self.current_progress_report.progress_text\n        except AttributeError:\n            return \"\"\n\n    def get_progress(self):\n        try:\n            return self.current_progress_report.progress\n        except AttributeError:\n            return 0\n\n    def set_error(self, e=None):\n        if e is None:\n            self.error_msg = \"\"\n            return\n\n        if isinstance(e, GLib.Error):\n            self.error_msg = e.message\n        elif isinstance(e, grpc.RpcError):\n            self.error_msg = e.details()\n        elif isinstance(e, ReceiveError):\n            self.error_msg = str(e)\n        else:\n            self.error_msg = str(e)\n\n    @util._idle\n    def emit_initial_setup_complete(self):\n        self.emit(\"initial-setup-complete\")\n\n    @util._idle\n    def emit_status_changed(self):\n        self.emit(\"status-changed\")\n\n    def set_status(self, status):\n        pass\n\n    def focus(self):\n        self.emit(\"focus\")\n\nclass SendOp(CommonOp):\n    def __init__(self, sender=None, receiver=None, receiver_name=None, uris=None):\n        super(SendOp, self).__init__(TransferDirection.TO_REMOTE_MACHINE, sender, uris)\n        self.receiver = receiver\n        self.sender_name = GLib.get_real_name()\n        self.receiver_name = receiver_name\n\n        self.resolved_files = []\n        self.first_missing_file = None\n\n        self.file_send_cancellable = None\n\n        self.current_progress_report = None\n\n        # These are the first-level base names (no path, just the filename) that we'll send to the server\n        # to check for pre-existence.  We know that if these files/folders don't exist, none of their children\n        # will.  This is a bit simple, but until we need more, it's fine.\n        self.top_dir_basenames = []\n\n    def set_status(self, status):\n        self.status = status\n\n        if status == OpStatus.FINISHED:\n            notifications.TransferCompleteNotification(self, sender=True)\n        elif status in (OpStatus.FAILED_UNRECOVERABLE, OpStatus.FAILED):\n            notifications.TransferFailedNotification(self, sender=True)\n         # We only care if the other remote cancelled.  If we did it, we don't need a notification.\n        elif status == OpStatus.STOPPED_BY_RECEIVER:\n            notifications.TransferStoppedNotification(self, sender=True)\n\n        self.emit_status_changed()\n\n    def prepare_send_info(self):\n        self.status = OpStatus.CALCULATING\n        self.emit_status_changed()\n\n        error = transfers.gather_file_info(self)\n\n        self.update_ui_info(error)\n\n    def update_ui_info(self, error):\n        if error is None:\n            self.size_string = GLib.format_size(self.total_size)\n            logging.debug(\"Op: calculated %d files, with a size of %s\" % (self.total_count, self.size_string))\n\n            if self.total_count > 1:\n                # Translators: Don't need to translate singular, we show the filename if there's only one\n                self.description = gettext.ngettext(\"%d file-do-not-translate\",\n                                                    \"%d files\", self.total_count) % (self.total_count,)\n                self.gicon = Gio.ThemedIcon.new(\"edit-copy-symbolic\")\n            else:\n                self.description = self.resolved_files[0].basename\n                self.gicon = Gio.content_type_get_symbolic_icon(self.mime_if_single)\n\n            self.set_status(OpStatus.WAITING_PERMISSION)\n        else:\n            if isinstance(error, GLib.Error) and error.code == Gio.IOErrorEnum.NOT_FOUND:\n                self.status = OpStatus.FILE_NOT_FOUND\n                self.description = \"\"\n                self.error_msg = \"\"\n                self.first_missing_file = self.top_dir_basenames[-1]\n                self.gicon = Gio.ThemedIcon.new(\"dialog-error-symbolic\")\n            else:\n                self.status = OpStatus.FAILED_UNRECOVERABLE\n                self.description = \"\"\n                self.set_error(error)\n\n        self.emit_initial_setup_complete()\n        self.emit_status_changed()\n\n    # Widget handlers\n\n    def cancel_transfer_request(self):\n        self.emit(\"op-command\", OpCommand.CANCEL_PERMISSION_BY_SENDER)\n\n    def retry_transfer(self):\n        self.emit(\"op-command\", OpCommand.RETRY_TRANSFER)\n\n    def pause_transfer(self):\n        pass\n\n    def stop_transfer(self):\n        self.emit(\"op-command\", OpCommand.STOP_TRANSFER_BY_SENDER)\n\n    def remove_transfer(self):\n        self.emit(\"op-command\", OpCommand.REMOVE_TRANSFER)\n\n# This represents a send or receive 'job', there would be potentially many of these.\nclass ReceiveOp(CommonOp):\n    def __init__(self, sender):\n        super(ReceiveOp, self).__init__(TransferDirection.FROM_REMOTE_MACHINE, sender)\n        self.sender_name = self.sender\n        self.receiver_name = GLib.get_real_name()\n\n         # If there's insufficient disk space, always ask for permission\n         # If we're overwriting, there's a preference to check whether we need to ask or not.\n        self.have_space = False\n        self.existing = False\n\n        # This will be a <_Rendezvous object of in-flight RPC> if no compression is used, and a\n        # SteamResponseWrapper (interceptors.py) if it is.\n        self.file_iterator = None\n\n        self.current_progress_report = None\n        # These are the first-level base names (no path, just the filename) that we'll send to the server\n        # to check for pre-existence.  We know that if these files/folders don't exist, none of their children\n        # will.  This is a bit simple, but until we need more, it's fine.\n        self.top_dir_basenames = []\n\n    def set_status(self, status):\n        self.status = status\n\n        if status == OpStatus.FINISHED:\n            notifications.TransferCompleteNotification(self, sender=False)\n        elif status == OpStatus.FINISHED_WARNING:\n            notifications.TransferCompleteNotification(self, sender=False, warn=True)\n        elif status in (OpStatus.FAILED_UNRECOVERABLE, OpStatus.FAILED):\n            notifications.TransferFailedNotification(self, sender=False)\n         # We only care if the other remote cancelled.  If we did it, we don't need a notification.\n        elif status == OpStatus.STOPPED_BY_SENDER:\n            notifications.TransferStoppedNotification(self, sender=False)\n\n        self.emit_status_changed()\n\n    def prepare_receive_info(self):\n        self.size_string = GLib.format_size(self.total_size)\n        logging.debug(\"Op: details: %d files, with a size of %s\" % (self.total_count, self.size_string))\n\n        # Check that toplevels are valid, safe. This is done immediately to prevent some sort of runaway\n        # free-space check.\n        for top_dir in self.top_dir_basenames:\n            try:\n                util.test_resolved_path_safety(top_dir)\n            except ReceiveError as e:\n                self.set_error(e)\n                self.status = OpStatus.FAILED_UNRECOVERABLE\n                self.emit_initial_setup_complete()\n                return\n\n        self.have_space = util.free_space_monitor.have_enough_free(self.total_size, self.top_dir_basenames)\n        self.existing = util.files_exist(self.top_dir_basenames)\n        self.update_ui_info()\n\n    def update_ui_info(self):\n        if self.total_count > 1:\n            # Translators: Don't need to translate singular, we show the filename if there's only one\n            self.description = gettext.ngettext(\"%d file\",\n                                                \"%d files\", self.total_count) % (self.total_count,)\n            self.gicon = Gio.ThemedIcon.new(\"edit-copy-symbolic\")\n        else:\n            self.description = self.name_if_single\n            self.gicon = Gio.content_type_get_symbolic_icon(self.mime_if_single)\n\n        self.status = OpStatus.WAITING_PERMISSION\n\n        notifications.NewOpUserNotification(self)\n        self.emit_initial_setup_complete()\n\n    # Widget handlers\n    def accept_transfer(self):\n        self.emit(\"op-command\", OpCommand.START_TRANSFER)\n\n    def decline_transfer_request(self):\n        self.emit(\"op-command\", OpCommand.CANCEL_PERMISSION_BY_RECEIVER)\n\n    def stop_transfer(self):\n        self.emit(\"op-command\", OpCommand.STOP_TRANSFER_BY_RECEIVER)\n\n    def remove_transfer(self):\n        self.emit(\"op-command\", OpCommand.REMOVE_TRANSFER)\n\n", "code_before": "#!/usr/bin/python3\n\nimport gettext\nimport logging\n\nfrom gi.repository import GObject, GLib, Gio\n\nimport grpc\n\nimport transfers\nimport prefs\nimport util\nimport notifications\nfrom util import OpStatus, OpCommand, TransferDirection, ReceiveError\n\n_ = gettext.gettext\n\nclass CommonOp(GObject.Object):\n    __gsignals__ = {\n        \"status-changed\": (GObject.SignalFlags.RUN_LAST, None, ()),\n        \"initial-setup-complete\": (GObject.SignalFlags.RUN_LAST, None, ()),\n        \"op-command\": (GObject.SignalFlags.RUN_LAST, None, (int,)),\n        \"progress-changed\": (GObject.SignalFlags.RUN_LAST, None, ()),\n        \"active\": (GObject.SignalFlags.RUN_LAST, None, ()),\n        \"focus\": (GObject.SignalFlags.RUN_LAST, None, ())\n    }\n    def __init__(self, direction, sender, uris=None):\n        super(CommonOp, self).__init__()\n        self.uris = uris\n        self.sender = sender\n        self.direction = direction\n        self.status = OpStatus.INIT\n        self.start_time = GLib.get_monotonic_time() # for sorting in the op list\n\n        self.total_size = 0\n        self.total_count = 0\n        self.remaining_count = 0\n\n        self.size_string = \"\"\n        self.description = \"\"\n        self.name_if_single = None\n        self.mime_if_single = \"application/octet-stream\" # unknown\n        self.gicon = Gio.content_type_get_symbolic_icon(self.mime_if_single)\n\n        self.error_msg = \"\"\n\n        self.progress_tracker = None\n\n    def progress_report(self, report):\n        self.current_progress_report = report\n        report.progress_text = _(\"%(time_left)s (%(bytes_per_sec)s/s)\") \\\n                                   % ({\n                                         \"time_left\": util.format_time_span(report.time_left_sec),\n                                         \"bytes_per_sec\": GLib.format_size(report.bytes_per_sec)\n                                     })\n\n        if report.progress == 1.0:\n            self.status = OpStatus.FINISHED\n            self.emit_status_changed()\n            return\n\n        self.emit(\"active\")\n        self.emit(\"progress-changed\")\n\n    def get_progress_text(self):\n        try:\n            return self.current_progress_report.progress_text\n        except AttributeError:\n            return \"\"\n\n    def get_progress(self):\n        try:\n            return self.current_progress_report.progress\n        except AttributeError:\n            return 0\n\n    def set_error(self, e=None):\n        if e is None:\n            self.error_msg = \"\"\n            return\n\n        if isinstance(e, GLib.Error):\n            self.error_msg = e.message\n        elif isinstance(e, grpc.RpcError):\n            self.error_msg = e.details()\n        elif isinstance(e, ReceiveError):\n            self.error_msg = str(e)\n        else:\n            self.error_msg = str(e)\n\n    @util._idle\n    def emit_initial_setup_complete(self):\n        self.emit(\"initial-setup-complete\")\n\n    @util._idle\n    def emit_status_changed(self):\n        self.emit(\"status-changed\")\n\n    def set_status(self, status):\n        pass\n\n    def focus(self):\n        self.emit(\"focus\")\n\nclass SendOp(CommonOp):\n    def __init__(self, sender=None, receiver=None, receiver_name=None, uris=None):\n        super(SendOp, self).__init__(TransferDirection.TO_REMOTE_MACHINE, sender, uris)\n        self.receiver = receiver\n        self.sender_name = GLib.get_real_name()\n        self.receiver_name = receiver_name\n\n        self.resolved_files = []\n        self.first_missing_file = None\n\n        self.file_send_cancellable = None\n\n        self.current_progress_report = None\n\n        # These are the first-level base names (no path, just the filename) that we'll send to the server\n        # to check for pre-existence.  We know that if these files/folders don't exist, none of their children\n        # will.  This is a bit simple, but until we need more, it's fine.\n        self.top_dir_basenames = []\n\n    def set_status(self, status):\n        self.status = status\n\n        if status == OpStatus.FINISHED:\n            notifications.TransferCompleteNotification(self, sender=True)\n        elif status in (OpStatus.FAILED_UNRECOVERABLE, OpStatus.FAILED):\n            notifications.TransferFailedNotification(self, sender=True)\n         # We only care if the other remote cancelled.  If we did it, we don't need a notification.\n        elif status == OpStatus.STOPPED_BY_RECEIVER:\n            notifications.TransferStoppedNotification(self, sender=True)\n\n        self.emit_status_changed()\n\n    def prepare_send_info(self):\n        self.status = OpStatus.CALCULATING\n        self.emit_status_changed()\n\n        error = transfers.gather_file_info(self)\n\n        self.update_ui_info(error)\n\n    def update_ui_info(self, error):\n        if error is None:\n            self.size_string = GLib.format_size(self.total_size)\n            logging.debug(\"Op: calculated %d files, with a size of %s\" % (self.total_count, self.size_string))\n\n            if self.total_count > 1:\n                # Translators: Don't need to translate singular, we show the filename if there's only one\n                self.description = gettext.ngettext(\"%d file-do-not-translate\",\n                                                    \"%d files\", self.total_count) % (self.total_count,)\n                self.gicon = Gio.ThemedIcon.new(\"edit-copy-symbolic\")\n            else:\n                self.description = self.resolved_files[0].basename\n                self.gicon = Gio.content_type_get_symbolic_icon(self.mime_if_single)\n\n            self.set_status(OpStatus.WAITING_PERMISSION)\n        else:\n            if isinstance(error, GLib.Error) and error.code == Gio.IOErrorEnum.NOT_FOUND:\n                self.status = OpStatus.FILE_NOT_FOUND\n                self.description = \"\"\n                self.error_msg = \"\"\n                self.first_missing_file = self.top_dir_basenames[-1]\n                self.gicon = Gio.ThemedIcon.new(\"dialog-error-symbolic\")\n            else:\n                self.status = OpStatus.FAILED_UNRECOVERABLE\n                self.description = \"\"\n                self.set_error(error)\n\n        self.emit_initial_setup_complete()\n        self.emit_status_changed()\n\n    # Widget handlers\n\n    def cancel_transfer_request(self):\n        self.emit(\"op-command\", OpCommand.CANCEL_PERMISSION_BY_SENDER)\n\n    def retry_transfer(self):\n        self.emit(\"op-command\", OpCommand.RETRY_TRANSFER)\n\n    def pause_transfer(self):\n        pass\n\n    def stop_transfer(self):\n        self.emit(\"op-command\", OpCommand.STOP_TRANSFER_BY_SENDER)\n\n    def remove_transfer(self):\n        self.emit(\"op-command\", OpCommand.REMOVE_TRANSFER)\n\n# This represents a send or receive 'job', there would be potentially many of these.\nclass ReceiveOp(CommonOp):\n    def __init__(self, sender):\n        super(ReceiveOp, self).__init__(TransferDirection.FROM_REMOTE_MACHINE, sender)\n        self.sender_name = self.sender\n        self.receiver_name = GLib.get_real_name()\n\n         # If there's insufficient disk space, always ask for permission\n         # If we're overwriting, there's a preference to check whether we need to ask or not.\n        self.have_space = False\n        self.existing = False\n\n        # This will be a <_Rendezvous object of in-flight RPC> if no compression is used, and a\n        # SteamResponseWrapper (interceptors.py) if it is.\n        self.file_iterator = None\n\n        self.current_progress_report = None\n        # These are the first-level base names (no path, just the filename) that we'll send to the server\n        # to check for pre-existence.  We know that if these files/folders don't exist, none of their children\n        # will.  This is a bit simple, but until we need more, it's fine.\n        self.top_dir_basenames = []\n\n    def set_status(self, status):\n        self.status = status\n\n        if status == OpStatus.FINISHED:\n            notifications.TransferCompleteNotification(self, sender=False)\n        elif status == OpStatus.FINISHED_WARNING:\n            notifications.TransferCompleteNotification(self, sender=False, warn=True)\n        elif status in (OpStatus.FAILED_UNRECOVERABLE, OpStatus.FAILED):\n            notifications.TransferFailedNotification(self, sender=False)\n         # We only care if the other remote cancelled.  If we did it, we don't need a notification.\n        elif status == OpStatus.STOPPED_BY_SENDER:\n            notifications.TransferStoppedNotification(self, sender=False)\n\n        self.emit_status_changed()\n\n    def prepare_receive_info(self):\n        self.size_string = GLib.format_size(self.total_size)\n        logging.debug(\"Op: details: %d files, with a size of %s\" % (self.total_count, self.size_string))\n\n        self.have_space = util.free_space_monitor.have_enough_free(self.total_size, self.top_dir_basenames)\n        self.existing = util.files_exist(self.top_dir_basenames)\n        self.update_ui_info()\n\n    def update_ui_info(self):\n        if self.total_count > 1:\n            # Translators: Don't need to translate singular, we show the filename if there's only one\n            self.description = gettext.ngettext(\"%d file\",\n                                                \"%d files\", self.total_count) % (self.total_count,)\n            self.gicon = Gio.ThemedIcon.new(\"edit-copy-symbolic\")\n        else:\n            self.description = self.name_if_single\n            self.gicon = Gio.content_type_get_symbolic_icon(self.mime_if_single)\n\n        self.status = OpStatus.WAITING_PERMISSION\n\n        notifications.NewOpUserNotification(self)\n        self.emit_initial_setup_complete()\n\n    # Widget handlers\n    def accept_transfer(self):\n        self.emit(\"op-command\", OpCommand.START_TRANSFER)\n\n    def decline_transfer_request(self):\n        self.emit(\"op-command\", OpCommand.CANCEL_PERMISSION_BY_RECEIVER)\n\n    def stop_transfer(self):\n        self.emit(\"op-command\", OpCommand.STOP_TRANSFER_BY_RECEIVER)\n\n    def remove_transfer(self):\n        self.emit(\"op-command\", OpCommand.REMOVE_TRANSFER)\n\n", "patch": "@@ -2,6 +2,7 @@\n \n import gettext\n import logging\n+from pathlib import Path\n \n from gi.repository import GObject, GLib, Gio\n \n@@ -230,6 +231,17 @@ def prepare_receive_info(self):\n         self.size_string = GLib.format_size(self.total_size)\n         logging.debug(\"Op: details: %d files, with a size of %s\" % (self.total_count, self.size_string))\n \n+        # Check that toplevels are valid, safe. This is done immediately to prevent some sort of runaway\n+        # free-space check.\n+        for top_dir in self.top_dir_basenames:\n+            try:\n+                util.test_resolved_path_safety(top_dir)\n+            except ReceiveError as e:\n+                self.set_error(e)\n+                self.status = OpStatus.FAILED_UNRECOVERABLE\n+                self.emit_initial_setup_complete()\n+                return\n+\n         self.have_space = util.free_space_monitor.have_enough_free(self.total_size, self.top_dir_basenames)\n         self.existing = util.files_exist(self.top_dir_basenames)\n         self.update_ui_info()", "file_path": "files/2023_5/150", "file_language": "py", "file_name": "src/ops.py", "outdated_file_modify": 0, "outdated_file_before": 1, "outdated_file_after": 0, "llm_check": 1, "static_check": 0, "static": {"rats": [false, []], "semgrep": [false, []]}, "target": -1, "function_before": [], "function_after": []}, {"raw_url": "https://github.com/linuxmint/warpinator/raw/9aae768522b7bbb09c836419893802a02221d663/src%2Fremote.py", "code": "#!/usr/bin/python3\n\nimport time\nimport gettext\nimport threading\nimport logging\n\nfrom gi.repository import GObject, GLib\n\nimport grpc\nimport warp_pb2\nimport warp_pb2_grpc\n\nimport interceptors\nimport prefs\nimport util\nimport transfers\nimport auth\nfrom ops import SendOp, ReceiveOp\nfrom util import TransferDirection, OpStatus, OpCommand, RemoteStatus, ReceiveError\n\n_ = gettext.gettext\n\n#typedef\nvoid = warp_pb2.VoidType()\n\nCHANNEL_RETRY_WAIT_TIME = 30\n\nDUPLEX_MAX_FAILURES = 10\nDUPLEX_WAIT_PING_TIME = 1\nCONNECTED_PING_TIME = 20\n\n# client\nclass RemoteMachine(GObject.Object):\n    __gsignals__ = {\n        'machine-info-changed': (GObject.SignalFlags.RUN_LAST, None, ()),\n        'ops-changed': (GObject.SignalFlags.RUN_LAST, None, ()),\n        'new-incoming-op': (GObject.SignalFlags.RUN_LAST, None, (object,)),\n        'new-outgoing-op': (GObject.SignalFlags.RUN_LAST, None, (object,)),\n        'focus-remote': (GObject.SignalFlags.RUN_LAST, None, ()),\n        'remote-status-changed': (GObject.SignalFlags.RUN_LAST, None, ())\n    }\n\n    def __init__(self, ident, hostname, display_hostname, ip_info, port, local_ident, api_version):\n        GObject.Object.__init__(self)\n        self.ip_info = ip_info\n        self.port = port\n        self.ident = ident\n        self.local_ident = local_ident\n        self.api_version = api_version\n        self.hostname = hostname\n        self.display_hostname = display_hostname\n        self.user_name = \"\"\n        self.display_name = \"\"\n        self.favorite = prefs.get_is_favorite(self.ident)\n        self.recent_time = 0 # Keep monotonic time when visited on the user page\n\n        self.avatar_surface = None\n        self.transfer_ops = []\n\n        self.sort_key = self.hostname\n        self.status = RemoteStatus.INIT_CONNECTING\n\n        self.machine_info_changed_source_id = 0\n        self.machine_info_changed_lock = threading.Lock()\n\n        self.status_idle_source_id = 0\n        self.status_lock = threading.Lock()\n\n        self.stub = None\n\n        self.busy = False # Skip keepalive ping when we're busy.\n        self.ping_timer = threading.Event()\n\n        self.channel_keepalive = threading.Event()\n\n        prefs.prefs_settings.connect(\"changed::favorites\", self.update_favorite_status)\n\n        self.has_zc_presence = False # This is currently unused.\n\n    def start_remote_thread(self):\n        # func = lambda: return\n\n        if self.api_version == \"1\":\n            func = self.remote_thread_v1\n        elif self.api_version == \"2\":\n            func = self.remote_thread_v2\n\n        self.remote_thread = threading.Thread(target=func, name=\"remote-main-thread-v%s-%s-%s:%d-%s\"\n                                              % (self.api_version, self.hostname, self.ip_info.ip4_address, self.port, self.ident))\n        # logging.debug(\"remote-thread-%s-%s:%d-%s\"\n                          # % (self.hostname, self.ip_info.ip4_address, self.port, self.ident))\n        self.remote_thread.start()\n\n    def remote_thread_v1(self):\n        self.ping_timer.clear()\n\n        self.emit_machine_info_changed() # Let's make sure the button doesn't have junk in it if we fail to connect.\n\n        logging.debug(\"Remote: Attempting to connect to %s (%s) - api version 1\" % (self.display_hostname, self.ip_info.ip4_address))\n\n        self.set_remote_status(RemoteStatus.INIT_CONNECTING)\n\n        def run_secure_loop():\n            logging.debug(\"Remote: Starting a new connection loop for %s (%s:%d)\"\n                              % (self.display_hostname, self.ip_info.ip4_address, self.port))\n\n            cert = auth.get_singleton().get_cached_cert(self.hostname, self.ip_info)\n            creds = grpc.ssl_channel_credentials(cert)\n\n            with grpc.secure_channel(\"%s:%d\" % (self.ip_info.ip4_address, self.port), creds) as channel:\n                future = grpc.channel_ready_future(channel)\n\n                try:\n                    future.result(timeout=4)\n                    self.stub = warp_pb2_grpc.WarpStub(channel)\n                except grpc.FutureTimeoutError:\n                    self.set_remote_status(RemoteStatus.UNREACHABLE)\n                    future.cancel()\n\n                    if not self.ping_timer.is_set():\n                        logging.debug(\"Remote: Unable to establish secure connection with %s (%s:%d). Trying again in %ds\"\n                                          % (self.display_hostname, self.ip_info.ip4_address, self.port, CHANNEL_RETRY_WAIT_TIME))\n                        self.ping_timer.wait(CHANNEL_RETRY_WAIT_TIME)\n                        return True # run_secure_loop()\n\n                    return False # run_secure_loop()\n\n                duplex_fail_counter = 0\n                one_ping = False # A successful duplex response lets us finish setting things up.\n\n                while not self.ping_timer.is_set():\n\n                    if self.busy:\n                        logging.debug(\"Remote Ping: Skipping keepalive ping to %s (%s:%d) (busy)\"\n                                          % (self.display_hostname, self.ip_info.ip4_address, self.port))\n                        self.busy = False\n                    else:\n                        try:\n                            # t = GLib.get_monotonic_time()\n                            logging.debug(\"Remote Ping: to   %s (%s:%d)\"\n                                          % (self.display_hostname, self.ip_info.ip4_address, self.port))\n                            self.stub.Ping(warp_pb2.LookupName(id=self.local_ident,\n                                                               readable_name=util.get_hostname()),\n                                           timeout=5)\n                            # logging.debug(\"Latency: %s (%s)\"\n                                          # % (util.precise_format_time_span(GLib.get_monotonic_time() - t), self.display_hostname))\n                            if not one_ping:\n                                self.set_remote_status(RemoteStatus.AWAITING_DUPLEX)\n                                if self.check_duplex_connection():\n                                    logging.debug(\"Remote: Connected to %s (%s:%d)\"\n                                                      % (self.display_hostname, self.ip_info.ip4_address, self.port))\n\n                                    self.set_remote_status(RemoteStatus.ONLINE)\n\n                                    self.rpc_call(self.update_remote_machine_info)\n                                    self.rpc_call(self.update_remote_machine_avatar)\n                                    one_ping = True\n                                else:\n                                    duplex_fail_counter += 1\n                                    if duplex_fail_counter > DUPLEX_MAX_FAILURES:\n                                        logging.debug(\"Remote: CheckDuplexConnection to %s (%s:%d) failed too many times\"\n                                                          % (self.display_hostname, self.ip_info.ip4_address, self.port))\n                                        self.ping_timer.wait(CHANNEL_RETRY_WAIT_TIME)\n                                        return True\n                        except grpc.RpcError as e:\n                            logging.debug(\"Remote: Ping failed, shutting down %s (%s:%d)\"\n                                              % (self.display_hostname, self.ip_info.ip4_address, self.port))\n                            break\n\n                    self.ping_timer.wait(CONNECTED_PING_TIME if self.status == RemoteStatus.ONLINE else DUPLEX_WAIT_PING_TIME)\n\n                # This is reached by the RpcError break above.  If the remote is still discoverable, start\n                # the secure loop over.  This could have happened as a result of a quick disco/reconnect,\n                # And we don't notice until it has already come back. In this case, try a new connection.\n                if self.has_zc_presence and not self.ping_timer.is_set():\n                    return True # run_secure_loop()\n\n                # The ping timer has been triggered, this is an orderly shutdown.\n                return False # run_secure_loop()\n\n        try:\n            while run_secure_loop():\n                continue\n        except Exception as e:\n            logging.critical(\"!! Major problem starting connection loop for %s (%s:%d): %s\"\n                                 % (self.display_hostname, self.ip_info.ip4_address, self.port, e))\n\n        self.set_remote_status(RemoteStatus.OFFLINE)\n        self.run_thread_alive = False\n\n    def remote_thread_v2(self):\n        self.channel_keepalive.clear()\n\n        self.emit_machine_info_changed() # Let's make sure the button doesn't have junk in it if we fail to connect.\n\n        logging.debug(\"Remote: Attempting to connect to %s (%s) - api version 2\" % (self.display_hostname, self.ip_info.ip4_address))\n\n        self.set_remote_status(RemoteStatus.INIT_CONNECTING)\n\n        cert = auth.get_singleton().get_cached_cert(self.hostname, self.ip_info)\n        creds = grpc.ssl_channel_credentials(cert)\n\n        def run_secure_loop():\n            opts = (\n                ('grpc.keepalive_time_ms', 10000),\n                ('grpc.keepalive_timeout_ms', 5000),\n                ('grpc.keepalive_permit_without_calls', True),\n                ('grpc.http2.max_pings_without_data', 0),\n                ('grpc.http2.min_time_between_pings_ms', 10000),\n                ('grpc.http2.min_ping_interval_without_data_ms', 5000)\n            )\n\n            with grpc.secure_channel(\"%s:%d\" % (self.ip_info.ip4_address, self.port), creds, options=opts) as channel:\n\n                def channel_state_changed(state):\n                    if state != grpc.ChannelConnectivity.READY:\n                        # The server may have already called shutdown\n                        try:\n                            self.shutdown()\n                        except:\n                            pass\n\n                intercepted_channel = grpc.intercept_channel(channel,\n                                                             interceptors.ChunkDecompressor())\n\n                future = grpc.channel_ready_future(intercepted_channel)\n\n                try:\n                    future.result(timeout=4)\n                    channel.subscribe(channel_state_changed)\n                    self.stub = warp_pb2_grpc.WarpStub(intercepted_channel)\n\n                    self.set_remote_status(RemoteStatus.AWAITING_DUPLEX)\n\n                    duplex = self.wait_for_duplex()\n                    duplex.result(timeout=10)\n\n                    self.set_remote_status(RemoteStatus.ONLINE)\n\n                    self.rpc_call(self.update_remote_machine_info)\n                    self.rpc_call(self.update_remote_machine_avatar)\n\n                    # Online loop\n                    logging.info(\"Connected to %s\" % self.display_hostname)\n                    while not self.channel_keepalive.is_set():\n                        self.channel_keepalive.wait(.5)\n                    ##\n\n                except Exception as e:\n                    self.set_remote_status(RemoteStatus.UNREACHABLE)\n\n                    if isinstance(e, grpc.FutureTimeoutError):\n                        future.cancel()\n                        logging.critical(\"Problem while waiting for channel - api version 2: %s\" % e)\n                    elif isinstance(e, grpc.RpcError):\n                        logging.critical(\"Problem while awaiting duplex response - api version 2: %s - %s\" % (e.code(), e.details()))\n                    else:\n                        logging.critical(\"General error with remote channel connection - api version 2: %s\" % e)\n\n                    self.channel_keepalive.wait(10)\n                finally:\n                    channel.unsubscribe(channel_state_changed)\n\n        while not self.channel_keepalive.is_set():\n            run_secure_loop()\n\n        self.set_remote_status(RemoteStatus.OFFLINE)\n\n    def shutdown(self):\n        if self.api_version == \"1\":\n            self.ping_timer.set()\n        else:\n            self.channel_keepalive.set()\n        # This is called by server just before running start_remote_thread, so the first time\n        # self.remote_thread will be None.\n        try:\n            self.remote_thread.join(10)\n        except AttributeError:\n            pass\n\n        self.remote_thread = None\n\n    def update_favorite_status(self, pspec, data=None):\n        old_favorite = self.favorite\n        self.favorite = prefs.get_is_favorite(self.ident)\n\n        if old_favorite != self.favorite:\n            self.emit_machine_info_changed()\n\n    def stamp_recent_time(self):\n        self.recent_time = GLib.get_monotonic_time()\n        self.emit_machine_info_changed()\n\n    def set_remote_status(self, status):\n        with self.status_lock:\n            if self.status_idle_source_id > 0:\n                GLib.source_remove(self.status_idle_source_id)\n\n            self.status_idle_source_id = GLib.idle_add(self.set_status_cb, status)\n\n    def set_status_cb(self, status):\n        with self.status_lock:\n            self.status_idle_source_id = 0\n\n            if status == self.status:\n                return GLib.SOURCE_REMOVE\n\n            self.status = status\n            self.cancel_ops_if_offline()\n\n            logging.debug(\"Remote: %s is now %s ****\" % (self.hostname, self.status))\n            self.emit(\"remote-status-changed\")\n\n        return GLib.SOURCE_REMOVE\n\n    def emit_machine_info_changed(self):\n        with self.machine_info_changed_lock:\n            if self.machine_info_changed_source_id > 0:\n                GLib.source_remove(self.machine_info_changed_source_id)\n\n            self.machine_info_changed_source_id = GLib.idle_add(self.emit_machine_info_changed_cb)\n\n    def emit_machine_info_changed_cb(self):\n        with self.machine_info_changed_lock:\n            self.machine_info_changed_source_id = 0\n            self.emit(\"machine-info-changed\")\n\n        return GLib.SOURCE_REMOVE\n\n    def rpc_call(self, func, *args, **kargs):\n        try:\n            util.global_rpc_threadpool.submit(func, *args, **kargs)\n        except Exception as e:\n            # exception concurrent.futures.thread.BrokenThreadPool is not available in bionic/python3 < 3.7\n            logging.critical(\"!! RPC threadpool failure while submitting call to %s (%s:%d): %s\"\n                                 % (self.display_hostname, self.ip_info.ip4_address, self.port, e))\n\n    # Not added to thread pool\n    def check_duplex_connection(self):\n        logging.debug(\"Remote: checking duplex with '%s'\" % self.display_hostname)\n\n        ret = self.stub.CheckDuplexConnection(warp_pb2.LookupName(id=self.local_ident,\n                                                                  readable_name=util.get_hostname()))\n\n        return ret.response\n\n    def wait_for_duplex(self):\n        logging.debug(\"Remote: waiting for duplex from '%s'\" % self.display_hostname)\n\n        future = self.stub.WaitingForDuplex.future(warp_pb2.LookupName(id=self.local_ident,\n                                                                       readable_name=util.get_hostname()))\n\n        return future\n\n    # Run in thread pool\n    def update_remote_machine_info(self):\n        logging.debug(\"Remote RPC: calling GetRemoteMachineInfo on '%s'\" % self.display_hostname)\n        def get_info_finished(future):\n            info = future.result()\n            self.display_name = info.display_name\n            self.user_name = info.user_name\n            self.favorite = prefs.get_is_favorite(self.ident)\n\n            valid = GLib.utf8_make_valid(self.display_name, -1)\n            self.sort_key = GLib.utf8_collate_key(valid.lower(), -1)\n\n            self.emit_machine_info_changed()\n            self.set_remote_status(RemoteStatus.ONLINE)\n        \n        future = self.stub.GetRemoteMachineInfo.future(\n            warp_pb2.LookupName(\n                id=self.local_ident,\n                readable_name=util.get_hostname()\n            )\n        )\n        future.add_done_callback(get_info_finished)\n\n    # Run in thread pool\n    def update_remote_machine_avatar(self):\n        logging.debug(\"Remote RPC: calling GetRemoteMachineAvatar on '%s'\" % self.display_hostname)\n        iterator = self.stub.GetRemoteMachineAvatar(\n            warp_pb2.LookupName(\n                id=self.local_ident,\n                readable_name=util.get_hostname()\n            )\n        )\n        loader = None\n        try:\n            for info in iterator:\n                if loader is None:\n                    loader = util.CairoSurfaceLoader()\n                loader.add_bytes(info.avatar_chunk)\n        except grpc.RpcError as e:\n            logging.debug(\"Remote RPC: could not fetch remote avatar, using a generic one. (%s, %s)\" % (e.code(), e.details()))\n\n        self.get_avatar_surface(loader)\n\n    @util._idle\n    def get_avatar_surface(self, loader=None):\n        # This needs to be on the main loop, or else we get an x error\n        if loader:\n            self.avatar_surface = loader.get_surface()\n        else:\n            self.avatar_surface = None\n\n        self.emit_machine_info_changed()\n\n    # Run in thread pool\n    def send_transfer_op_request(self, op):\n        if not self.stub: # short circuit for testing widgets\n            return\n\n        logging.debug(\"Remote RPC: calling TransferOpRequest on '%s'\" % (self.display_hostname))\n\n        transfer_op = warp_pb2.TransferOpRequest(\n            info=warp_pb2.OpInfo(\n                ident=op.sender,\n                timestamp=op.start_time,\n                readable_name=util.get_hostname(),\n                use_compression=prefs.use_compression(),\n            ),\n            sender_name=op.sender_name,\n            receiver=self.ident,\n            size=op.total_size,\n            count=op.total_count,\n            name_if_single=op.description,\n            mime_if_single=op.mime_if_single,\n            top_dir_basenames=op.top_dir_basenames\n        )\n\n        self.stub.ProcessTransferOpRequest(transfer_op)\n\n    # Run in thread pool\n    def cancel_transfer_op_request(self, op, by_sender=False):\n        logging.debug(\"Remote RPC: calling CancelTransferOpRequest on '%s'\" % (self.display_hostname))\n\n        if op.direction == TransferDirection.TO_REMOTE_MACHINE:\n            name = op.sender\n        else:\n            name = self.local_ident\n        self.stub.CancelTransferOpRequest(\n            warp_pb2.OpInfo(\n                timestamp=op.start_time,\n                ident=name,\n                readable_name=util.get_hostname()\n            )\n        )\n        op.set_status(OpStatus.CANCELLED_PERMISSION_BY_SENDER if by_sender else OpStatus.CANCELLED_PERMISSION_BY_RECEIVER)\n\n    # Run in thread pool\n    def start_transfer_op(self, op):\n        logging.debug(\"Remote RPC: calling StartTransfer on '%s'\" % (self.display_hostname))\n\n        start_time = GLib.get_monotonic_time()\n\n        op.progress_tracker = transfers.OpProgressTracker(op)\n        op.current_progress_report = None\n        receiver = transfers.FileReceiver(op)\n        op.set_status(OpStatus.TRANSFERRING)\n\n        # This is ugly because StartTransfer only returns file_iterator. The\n        # interceptor returns the cancellable with it, because file_iterator\n        # is not a future if compression is active, it's just a generator.\n        op.file_iterator = self.stub.StartTransfer(\n            warp_pb2.OpInfo(\n                timestamp=op.start_time,\n                ident=self.local_ident,\n                readable_name=util.get_hostname(),\n                use_compression=op.use_compression and prefs.use_compression()\n            )\n        )\n\n        def report_receive_error(error):\n            op.file_iterator = None\n\n            # Get rid of any toplevel file/folder if the transfer stops prematurely,\n            # so it or its children \n            receiver.clean_current_top_dir_file()\n\n            if error is None:\n                return\n\n            op.set_error(error)\n\n            try:\n                # If we leave an io stream open, it locks the location.  For instance,\n                # if this was a mounted location, we wouldn't be able to terminate until\n                # we closed warp.\n                if receiver.current_stream is not None:\n                    receiver.current_stream.close()\n            except GLib.Error:\n                pass\n\n            logging.critical(\"An error occurred receiving data from %s: %s\" % (op.sender, op.error_msg))\n            op.set_status(OpStatus.FAILED)\n            op.stop_transfer()\n\n        try:\n            receiver.clean_existing_files()\n\n            for data in op.file_iterator:\n                receiver.receive_data(data)\n\n            op.file_iterator = None\n            receiver.receive_finished()\n\n            logging.debug(\"Remote: receipt of %s files (%s) finished in %s\" % \\\n                          (op.total_count, GLib.format_size(op.total_size),\\\n                           util.precise_format_time_span(GLib.get_monotonic_time() - start_time)))\n\n            if op.remaining_count > 0:\n                raise ReceiveError(\"Transfer completed, but the number of files received is less than the original request size (expected %d, received %d)\"\n                                       % (op.total_count, op.total_count - receiver.remaining_count),\n                                   fatal=False)\n            op.set_status(OpStatus.FINISHED)\n        except grpc.RpcError as e:\n            if e.code() == grpc.StatusCode.CANCELLED:\n                report_receive_error(None)\n            else:\n                report_receive_error(e)\n        except ReceiveError as e:\n            if e.fatal:\n                report_receive_error(e)\n            else:\n                logging.critical(str(e))\n                op.set_error(e)\n                op.set_status(OpStatus.FINISHED_WARNING)\n        except Exception as e:\n            report_receive_error(e)\n\n    # Run in thread pool\n    def stop_transfer_op(self, op, by_sender=False, lost_connection=False):\n        logging.debug(\"Remote RPC: Calling StopTransfer on '%s'\" % (self.display_hostname))\n\n        if op.direction == TransferDirection.TO_REMOTE_MACHINE:\n            name = op.sender\n        else:\n            name = self.local_ident\n\n        if by_sender:\n            op.file_send_cancellable.set()\n            # If we stopped due to connection error, we don't want the message to be 'stopped by xx',\n            # but just failed.\n            if not lost_connection:\n                logging.debug(\"Remote: stop transfer initiated by sender\")\n                if op.error_msg == \"\":\n                    op.set_status(OpStatus.STOPPED_BY_SENDER)\n                else:\n                    op.set_status(OpStatus.FAILED)\n        else:\n            if op.file_iterator:\n                op.file_iterator.cancel()\n            if not lost_connection:\n                logging.debug(\"Remote: stop transfer initiated by receiver\")\n                if op.error_msg == \"\":\n                    op.set_status(OpStatus.STOPPED_BY_RECEIVER)\n                else:\n                    op.set_status(OpStatus.FAILED)\n\n        if not lost_connection:\n            # We don't need to send this if it's a connection loss, the other end will handle\n            # its own cleanup.\n            opinfo = warp_pb2.OpInfo(\n                timestamp=op.start_time,\n                ident=name,\n                readable_name=util.get_hostname()\n            )\n            self.stub.StopTransfer(warp_pb2.StopInfo(info=opinfo, error=op.error_msg != \"\"))\n\n    # Op handling (run in thread pool)\n    def send_files(self, uri_list):\n        def _send_files(uri_list):\n            op = SendOp(\n                self.local_ident,\n                self.ident,\n                self.display_name,\n                uri_list\n            )\n            self.add_op(op)\n            op.prepare_send_info()\n\n        util.add_to_recents_if_single_selection(uri_list)\n        self.rpc_call(_send_files, uri_list)\n\n    @util._idle\n    def add_op(self, op):\n        if op not in self.transfer_ops:\n            self.transfer_ops.append(op)\n            op.connect(\"status-changed\", self.emit_ops_changed)\n            op.connect(\"op-command\", self.op_command_issued)\n            op.connect(\"focus\", self.op_focus)\n            if isinstance(op, SendOp):\n                op.connect(\"initial-setup-complete\", self.notify_remote_machine_of_new_op)\n                self.emit(\"new-outgoing-op\", op)\n            if isinstance(op, ReceiveOp):\n                self.emit(\"new-incoming-op\", op)\n\n        def set_busy():\n            self.busy = True\n\n        op.connect(\"active\", lambda op: set_busy())\n\n        self.emit_ops_changed()\n\n        # For now, only bad base filenames cause this (failed util.test_resolved_path_safety())\n        # We let it get this far so the UI has something to show the user.\n        if op.status == OpStatus.FAILED_UNRECOVERABLE:\n            op.decline_transfer_request()\n            return\n\n        self.check_for_autostart(op)\n\n    @util._idle\n    def notify_remote_machine_of_new_op(self, op):\n        if op.status == OpStatus.WAITING_PERMISSION:\n            if op.direction == TransferDirection.TO_REMOTE_MACHINE:\n                self.rpc_call(self.send_transfer_op_request, op)\n\n    @util._idle\n    def check_for_autostart(self, op):\n        if op.status == OpStatus.WAITING_PERMISSION:\n            if isinstance(op, ReceiveOp) and \\\n              op.have_space and \\\n              (not (op.existing and prefs.prevent_overwriting())) and \\\n              (not prefs.require_permission_for_transfer()):\n                op.accept_transfer()\n\n    def remove_op(self, op):\n        self.transfer_ops.remove(op)\n        self.emit_ops_changed()\n\n    @util._idle\n    def emit_ops_changed(self, op=None):\n        self.emit(\"ops-changed\")\n\n    def cancel_ops_if_offline(self):\n        if self.status in (RemoteStatus.OFFLINE, RemoteStatus.UNREACHABLE):\n            for op in self.transfer_ops:\n                if op.status == OpStatus.TRANSFERRING:\n                    op.error_msg = _(\"Connection has been lost\")\n                    self.rpc_call(self.stop_transfer_op, op, isinstance(op, SendOp), lost_connection=True)\n                    op.set_status(OpStatus.FAILED)\n                elif op.status in (OpStatus.WAITING_PERMISSION, OpStatus.CALCULATING, OpStatus.PAUSED):\n                    op.error_msg = _(\"Connection has been lost\")\n                    op.set_status(OpStatus.FAILED_UNRECOVERABLE)\n\n    @util._idle\n    def op_command_issued(self, op, command):\n        # send\n        if command == OpCommand.CANCEL_PERMISSION_BY_SENDER:\n            self.rpc_call(self.cancel_transfer_op_request, op, by_sender=True)\n        # elif command == OpCommand.PAUSE_TRANSFER:\n            # self.rpc_call(self.pause_transfer_op, op)\n        elif command == OpCommand.STOP_TRANSFER_BY_SENDER:\n            self.rpc_call(self.stop_transfer_op, op, by_sender=True)\n        elif command == OpCommand.RETRY_TRANSFER:\n            op.set_status(OpStatus.WAITING_PERMISSION)\n            self.rpc_call(self.send_transfer_op_request, op)\n        elif command == OpCommand.REMOVE_TRANSFER:\n            self.remove_op(op)\n        # receive\n        elif command == OpCommand.START_TRANSFER:\n            self.rpc_call(self.start_transfer_op, op)\n        elif command == OpCommand.CANCEL_PERMISSION_BY_RECEIVER:\n            self.rpc_call(self.cancel_transfer_op_request, op, by_sender=False)\n        elif command == OpCommand.STOP_TRANSFER_BY_RECEIVER:\n            self.rpc_call(self.stop_transfer_op, op, by_sender=False)\n\n    @util._idle\n    def op_focus(self, op):\n        self.emit(\"focus-remote\")\n\n    def lookup_op(self, timestamp):\n        for op in self.transfer_ops:\n            if op.start_time == timestamp:\n                return op\n", "code_before": "#!/usr/bin/python3\n\nimport time\nimport gettext\nimport threading\nimport logging\n\nfrom gi.repository import GObject, GLib\n\nimport grpc\nimport warp_pb2\nimport warp_pb2_grpc\n\nimport interceptors\nimport prefs\nimport util\nimport transfers\nimport auth\nfrom ops import SendOp, ReceiveOp\nfrom util import TransferDirection, OpStatus, OpCommand, RemoteStatus, ReceiveError\n\n_ = gettext.gettext\n\n#typedef\nvoid = warp_pb2.VoidType()\n\nCHANNEL_RETRY_WAIT_TIME = 30\n\nDUPLEX_MAX_FAILURES = 10\nDUPLEX_WAIT_PING_TIME = 1\nCONNECTED_PING_TIME = 20\n\n# client\nclass RemoteMachine(GObject.Object):\n    __gsignals__ = {\n        'machine-info-changed': (GObject.SignalFlags.RUN_LAST, None, ()),\n        'ops-changed': (GObject.SignalFlags.RUN_LAST, None, ()),\n        'new-incoming-op': (GObject.SignalFlags.RUN_LAST, None, (object,)),\n        'new-outgoing-op': (GObject.SignalFlags.RUN_LAST, None, (object,)),\n        'focus-remote': (GObject.SignalFlags.RUN_LAST, None, ()),\n        'remote-status-changed': (GObject.SignalFlags.RUN_LAST, None, ())\n    }\n\n    def __init__(self, ident, hostname, display_hostname, ip_info, port, local_ident, api_version):\n        GObject.Object.__init__(self)\n        self.ip_info = ip_info\n        self.port = port\n        self.ident = ident\n        self.local_ident = local_ident\n        self.api_version = api_version\n        self.hostname = hostname\n        self.display_hostname = display_hostname\n        self.user_name = \"\"\n        self.display_name = \"\"\n        self.favorite = prefs.get_is_favorite(self.ident)\n        self.recent_time = 0 # Keep monotonic time when visited on the user page\n\n        self.avatar_surface = None\n        self.transfer_ops = []\n\n        self.sort_key = self.hostname\n        self.status = RemoteStatus.INIT_CONNECTING\n\n        self.machine_info_changed_source_id = 0\n        self.machine_info_changed_lock = threading.Lock()\n\n        self.status_idle_source_id = 0\n        self.status_lock = threading.Lock()\n\n        self.stub = None\n\n        self.busy = False # Skip keepalive ping when we're busy.\n        self.ping_timer = threading.Event()\n\n        self.channel_keepalive = threading.Event()\n\n        prefs.prefs_settings.connect(\"changed::favorites\", self.update_favorite_status)\n\n        self.has_zc_presence = False # This is currently unused.\n\n    def start_remote_thread(self):\n        # func = lambda: return\n\n        if self.api_version == \"1\":\n            func = self.remote_thread_v1\n        elif self.api_version == \"2\":\n            func = self.remote_thread_v2\n\n        self.remote_thread = threading.Thread(target=func, name=\"remote-main-thread-v%s-%s-%s:%d-%s\"\n                                              % (self.api_version, self.hostname, self.ip_info.ip4_address, self.port, self.ident))\n        # logging.debug(\"remote-thread-%s-%s:%d-%s\"\n                          # % (self.hostname, self.ip_info.ip4_address, self.port, self.ident))\n        self.remote_thread.start()\n\n    def remote_thread_v1(self):\n        self.ping_timer.clear()\n\n        self.emit_machine_info_changed() # Let's make sure the button doesn't have junk in it if we fail to connect.\n\n        logging.debug(\"Remote: Attempting to connect to %s (%s) - api version 1\" % (self.display_hostname, self.ip_info.ip4_address))\n\n        self.set_remote_status(RemoteStatus.INIT_CONNECTING)\n\n        def run_secure_loop():\n            logging.debug(\"Remote: Starting a new connection loop for %s (%s:%d)\"\n                              % (self.display_hostname, self.ip_info.ip4_address, self.port))\n\n            cert = auth.get_singleton().get_cached_cert(self.hostname, self.ip_info)\n            creds = grpc.ssl_channel_credentials(cert)\n\n            with grpc.secure_channel(\"%s:%d\" % (self.ip_info.ip4_address, self.port), creds) as channel:\n                future = grpc.channel_ready_future(channel)\n\n                try:\n                    future.result(timeout=4)\n                    self.stub = warp_pb2_grpc.WarpStub(channel)\n                except grpc.FutureTimeoutError:\n                    self.set_remote_status(RemoteStatus.UNREACHABLE)\n                    future.cancel()\n\n                    if not self.ping_timer.is_set():\n                        logging.debug(\"Remote: Unable to establish secure connection with %s (%s:%d). Trying again in %ds\"\n                                          % (self.display_hostname, self.ip_info.ip4_address, self.port, CHANNEL_RETRY_WAIT_TIME))\n                        self.ping_timer.wait(CHANNEL_RETRY_WAIT_TIME)\n                        return True # run_secure_loop()\n\n                    return False # run_secure_loop()\n\n                duplex_fail_counter = 0\n                one_ping = False # A successful duplex response lets us finish setting things up.\n\n                while not self.ping_timer.is_set():\n\n                    if self.busy:\n                        logging.debug(\"Remote Ping: Skipping keepalive ping to %s (%s:%d) (busy)\"\n                                          % (self.display_hostname, self.ip_info.ip4_address, self.port))\n                        self.busy = False\n                    else:\n                        try:\n                            # t = GLib.get_monotonic_time()\n                            logging.debug(\"Remote Ping: to   %s (%s:%d)\"\n                                          % (self.display_hostname, self.ip_info.ip4_address, self.port))\n                            self.stub.Ping(warp_pb2.LookupName(id=self.local_ident,\n                                                               readable_name=util.get_hostname()),\n                                           timeout=5)\n                            # logging.debug(\"Latency: %s (%s)\"\n                                          # % (util.precise_format_time_span(GLib.get_monotonic_time() - t), self.display_hostname))\n                            if not one_ping:\n                                self.set_remote_status(RemoteStatus.AWAITING_DUPLEX)\n                                if self.check_duplex_connection():\n                                    logging.debug(\"Remote: Connected to %s (%s:%d)\"\n                                                      % (self.display_hostname, self.ip_info.ip4_address, self.port))\n\n                                    self.set_remote_status(RemoteStatus.ONLINE)\n\n                                    self.rpc_call(self.update_remote_machine_info)\n                                    self.rpc_call(self.update_remote_machine_avatar)\n                                    one_ping = True\n                                else:\n                                    duplex_fail_counter += 1\n                                    if duplex_fail_counter > DUPLEX_MAX_FAILURES:\n                                        logging.debug(\"Remote: CheckDuplexConnection to %s (%s:%d) failed too many times\"\n                                                          % (self.display_hostname, self.ip_info.ip4_address, self.port))\n                                        self.ping_timer.wait(CHANNEL_RETRY_WAIT_TIME)\n                                        return True\n                        except grpc.RpcError as e:\n                            logging.debug(\"Remote: Ping failed, shutting down %s (%s:%d)\"\n                                              % (self.display_hostname, self.ip_info.ip4_address, self.port))\n                            break\n\n                    self.ping_timer.wait(CONNECTED_PING_TIME if self.status == RemoteStatus.ONLINE else DUPLEX_WAIT_PING_TIME)\n\n                # This is reached by the RpcError break above.  If the remote is still discoverable, start\n                # the secure loop over.  This could have happened as a result of a quick disco/reconnect,\n                # And we don't notice until it has already come back. In this case, try a new connection.\n                if self.has_zc_presence and not self.ping_timer.is_set():\n                    return True # run_secure_loop()\n\n                # The ping timer has been triggered, this is an orderly shutdown.\n                return False # run_secure_loop()\n\n        try:\n            while run_secure_loop():\n                continue\n        except Exception as e:\n            logging.critical(\"!! Major problem starting connection loop for %s (%s:%d): %s\"\n                                 % (self.display_hostname, self.ip_info.ip4_address, self.port, e))\n\n        self.set_remote_status(RemoteStatus.OFFLINE)\n        self.run_thread_alive = False\n\n    def remote_thread_v2(self):\n        self.channel_keepalive.clear()\n\n        self.emit_machine_info_changed() # Let's make sure the button doesn't have junk in it if we fail to connect.\n\n        logging.debug(\"Remote: Attempting to connect to %s (%s) - api version 2\" % (self.display_hostname, self.ip_info.ip4_address))\n\n        self.set_remote_status(RemoteStatus.INIT_CONNECTING)\n\n        cert = auth.get_singleton().get_cached_cert(self.hostname, self.ip_info)\n        creds = grpc.ssl_channel_credentials(cert)\n\n        def run_secure_loop():\n            opts = (\n                ('grpc.keepalive_time_ms', 10000),\n                ('grpc.keepalive_timeout_ms', 5000),\n                ('grpc.keepalive_permit_without_calls', True),\n                ('grpc.http2.max_pings_without_data', 0),\n                ('grpc.http2.min_time_between_pings_ms', 10000),\n                ('grpc.http2.min_ping_interval_without_data_ms', 5000)\n            )\n\n            with grpc.secure_channel(\"%s:%d\" % (self.ip_info.ip4_address, self.port), creds, options=opts) as channel:\n\n                def channel_state_changed(state):\n                    if state != grpc.ChannelConnectivity.READY:\n                        # The server may have already called shutdown\n                        try:\n                            self.shutdown()\n                        except:\n                            pass\n\n                intercepted_channel = grpc.intercept_channel(channel,\n                                                             interceptors.ChunkDecompressor())\n\n                future = grpc.channel_ready_future(intercepted_channel)\n\n                try:\n                    future.result(timeout=4)\n                    channel.subscribe(channel_state_changed)\n                    self.stub = warp_pb2_grpc.WarpStub(intercepted_channel)\n\n                    self.set_remote_status(RemoteStatus.AWAITING_DUPLEX)\n\n                    duplex = self.wait_for_duplex()\n                    duplex.result(timeout=10)\n\n                    self.set_remote_status(RemoteStatus.ONLINE)\n\n                    self.rpc_call(self.update_remote_machine_info)\n                    self.rpc_call(self.update_remote_machine_avatar)\n\n                    # Online loop\n                    logging.info(\"Connected to %s\" % self.display_hostname)\n                    while not self.channel_keepalive.is_set():\n                        self.channel_keepalive.wait(.5)\n                    ##\n\n                except Exception as e:\n                    self.set_remote_status(RemoteStatus.UNREACHABLE)\n\n                    if isinstance(e, grpc.FutureTimeoutError):\n                        future.cancel()\n                        logging.critical(\"Problem while waiting for channel - api version 2: %s\" % e)\n                    elif isinstance(e, grpc.RpcError):\n                        logging.critical(\"Problem while awaiting duplex response - api version 2: %s - %s\" % (e.code(), e.details()))\n                    else:\n                        logging.critical(\"General error with remote channel connection - api version 2: %s\" % e)\n\n                    self.channel_keepalive.wait(10)\n                finally:\n                    channel.unsubscribe(channel_state_changed)\n\n        while not self.channel_keepalive.is_set():\n            run_secure_loop()\n\n        self.set_remote_status(RemoteStatus.OFFLINE)\n\n    def shutdown(self):\n        if self.api_version == \"1\":\n            self.ping_timer.set()\n        else:\n            self.channel_keepalive.set()\n        # This is called by server just before running start_remote_thread, so the first time\n        # self.remote_thread will be None.\n        try:\n            self.remote_thread.join(10)\n        except AttributeError:\n            pass\n\n        self.remote_thread = None\n\n    def update_favorite_status(self, pspec, data=None):\n        old_favorite = self.favorite\n        self.favorite = prefs.get_is_favorite(self.ident)\n\n        if old_favorite != self.favorite:\n            self.emit_machine_info_changed()\n\n    def stamp_recent_time(self):\n        self.recent_time = GLib.get_monotonic_time()\n        self.emit_machine_info_changed()\n\n    def set_remote_status(self, status):\n        with self.status_lock:\n            if self.status_idle_source_id > 0:\n                GLib.source_remove(self.status_idle_source_id)\n\n            self.status_idle_source_id = GLib.idle_add(self.set_status_cb, status)\n\n    def set_status_cb(self, status):\n        with self.status_lock:\n            self.status_idle_source_id = 0\n\n            if status == self.status:\n                return GLib.SOURCE_REMOVE\n\n            self.status = status\n            self.cancel_ops_if_offline()\n\n            logging.debug(\"Remote: %s is now %s ****\" % (self.hostname, self.status))\n            self.emit(\"remote-status-changed\")\n\n        return GLib.SOURCE_REMOVE\n\n    def emit_machine_info_changed(self):\n        with self.machine_info_changed_lock:\n            if self.machine_info_changed_source_id > 0:\n                GLib.source_remove(self.machine_info_changed_source_id)\n\n            self.machine_info_changed_source_id = GLib.idle_add(self.emit_machine_info_changed_cb)\n\n    def emit_machine_info_changed_cb(self):\n        with self.machine_info_changed_lock:\n            self.machine_info_changed_source_id = 0\n            self.emit(\"machine-info-changed\")\n\n        return GLib.SOURCE_REMOVE\n\n    def rpc_call(self, func, *args, **kargs):\n        try:\n            util.global_rpc_threadpool.submit(func, *args, **kargs)\n        except Exception as e:\n            # exception concurrent.futures.thread.BrokenThreadPool is not available in bionic/python3 < 3.7\n            logging.critical(\"!! RPC threadpool failure while submitting call to %s (%s:%d): %s\"\n                                 % (self.display_hostname, self.ip_info.ip4_address, self.port, e))\n\n    # Not added to thread pool\n    def check_duplex_connection(self):\n        logging.debug(\"Remote: checking duplex with '%s'\" % self.display_hostname)\n\n        ret = self.stub.CheckDuplexConnection(warp_pb2.LookupName(id=self.local_ident,\n                                                                  readable_name=util.get_hostname()))\n\n        return ret.response\n\n    def wait_for_duplex(self):\n        logging.debug(\"Remote: waiting for duplex from '%s'\" % self.display_hostname)\n\n        future = self.stub.WaitingForDuplex.future(warp_pb2.LookupName(id=self.local_ident,\n                                                                       readable_name=util.get_hostname()))\n\n        return future\n\n    # Run in thread pool\n    def update_remote_machine_info(self):\n        logging.debug(\"Remote RPC: calling GetRemoteMachineInfo on '%s'\" % self.display_hostname)\n        def get_info_finished(future):\n            info = future.result()\n            self.display_name = info.display_name\n            self.user_name = info.user_name\n            self.favorite = prefs.get_is_favorite(self.ident)\n\n            valid = GLib.utf8_make_valid(self.display_name, -1)\n            self.sort_key = GLib.utf8_collate_key(valid.lower(), -1)\n\n            self.emit_machine_info_changed()\n            self.set_remote_status(RemoteStatus.ONLINE)\n        \n        future = self.stub.GetRemoteMachineInfo.future(\n            warp_pb2.LookupName(\n                id=self.local_ident,\n                readable_name=util.get_hostname()\n            )\n        )\n        future.add_done_callback(get_info_finished)\n\n    # Run in thread pool\n    def update_remote_machine_avatar(self):\n        logging.debug(\"Remote RPC: calling GetRemoteMachineAvatar on '%s'\" % self.display_hostname)\n        iterator = self.stub.GetRemoteMachineAvatar(\n            warp_pb2.LookupName(\n                id=self.local_ident,\n                readable_name=util.get_hostname()\n            )\n        )\n        loader = None\n        try:\n            for info in iterator:\n                if loader is None:\n                    loader = util.CairoSurfaceLoader()\n                loader.add_bytes(info.avatar_chunk)\n        except grpc.RpcError as e:\n            logging.debug(\"Remote RPC: could not fetch remote avatar, using a generic one. (%s, %s)\" % (e.code(), e.details()))\n\n        self.get_avatar_surface(loader)\n\n    @util._idle\n    def get_avatar_surface(self, loader=None):\n        # This needs to be on the main loop, or else we get an x error\n        if loader:\n            self.avatar_surface = loader.get_surface()\n        else:\n            self.avatar_surface = None\n\n        self.emit_machine_info_changed()\n\n    # Run in thread pool\n    def send_transfer_op_request(self, op):\n        if not self.stub: # short circuit for testing widgets\n            return\n\n        logging.debug(\"Remote RPC: calling TransferOpRequest on '%s'\" % (self.display_hostname))\n\n        transfer_op = warp_pb2.TransferOpRequest(\n            info=warp_pb2.OpInfo(\n                ident=op.sender,\n                timestamp=op.start_time,\n                readable_name=util.get_hostname(),\n                use_compression=prefs.use_compression(),\n            ),\n            sender_name=op.sender_name,\n            receiver=self.ident,\n            size=op.total_size,\n            count=op.total_count,\n            name_if_single=op.description,\n            mime_if_single=op.mime_if_single,\n            top_dir_basenames=op.top_dir_basenames\n        )\n\n        self.stub.ProcessTransferOpRequest(transfer_op)\n\n    # Run in thread pool\n    def cancel_transfer_op_request(self, op, by_sender=False):\n        logging.debug(\"Remote RPC: calling CancelTransferOpRequest on '%s'\" % (self.display_hostname))\n\n        if op.direction == TransferDirection.TO_REMOTE_MACHINE:\n            name = op.sender\n        else:\n            name = self.local_ident\n        self.stub.CancelTransferOpRequest(\n            warp_pb2.OpInfo(\n                timestamp=op.start_time,\n                ident=name,\n                readable_name=util.get_hostname()\n            )\n        )\n        op.set_status(OpStatus.CANCELLED_PERMISSION_BY_SENDER if by_sender else OpStatus.CANCELLED_PERMISSION_BY_RECEIVER)\n\n    # Run in thread pool\n    def start_transfer_op(self, op):\n        logging.debug(\"Remote RPC: calling StartTransfer on '%s'\" % (self.display_hostname))\n\n        start_time = GLib.get_monotonic_time()\n\n        op.progress_tracker = transfers.OpProgressTracker(op)\n        op.current_progress_report = None\n        receiver = transfers.FileReceiver(op)\n        op.set_status(OpStatus.TRANSFERRING)\n\n        # This is ugly because StartTransfer only returns file_iterator. The\n        # interceptor returns the cancellable with it, because file_iterator\n        # is not a future if compression is active, it's just a generator.\n        op.file_iterator = self.stub.StartTransfer(\n            warp_pb2.OpInfo(\n                timestamp=op.start_time,\n                ident=self.local_ident,\n                readable_name=util.get_hostname(),\n                use_compression=op.use_compression and prefs.use_compression()\n            )\n        )\n\n        def report_receive_error(error):\n            op.file_iterator = None\n\n            if error is None:\n                return\n\n            op.set_error(error)\n\n            try:\n                # If we leave an io stream open, it locks the location.  For instance,\n                # if this was a mounted location, we wouldn't be able to terminate until\n                # we closed warp.\n                if receiver.current_stream is not None:\n                    receiver.current_stream.close()\n            except GLib.Error:\n                pass\n\n            logging.critical(\"An error occurred receiving data from %s: %s\" % (op.sender, op.error_msg))\n            op.set_status(OpStatus.FAILED)\n            op.stop_transfer()\n\n        try:\n            for data in op.file_iterator:\n                receiver.receive_data(data)\n\n            op.file_iterator = None\n            receiver.receive_finished()\n\n            logging.debug(\"Remote: receipt of %s files (%s) finished in %s\" % \\\n                          (op.total_count, GLib.format_size(op.total_size),\\\n                           util.precise_format_time_span(GLib.get_monotonic_time() - start_time)))\n\n            if op.remaining_count > 0:\n                raise ReceiveError(\"Transfer completed, but the number of files received is less than the original request size (expected %d, received %d)\"\n                                       % (op.total_count, op.total_count - receiver.remaining_count),\n                                   fatal=False)\n            op.set_status(OpStatus.FINISHED)\n        except grpc.RpcError as e:\n            if e.code() == grpc.StatusCode.CANCELLED:\n                report_receive_error(None)\n            else:\n                report_receive_error(e)\n        except ReceiveError as e:\n            if e.fatal:\n                report_receive_error(e)\n            else:\n                logging.critical(str(e))\n                op.set_error(e)\n                op.set_status(OpStatus.FINISHED_WARNING)\n        except Exception as e:\n            report_receive_error(e)\n\n    # Run in thread pool\n    def stop_transfer_op(self, op, by_sender=False, lost_connection=False):\n        logging.debug(\"Remote RPC: Calling StopTransfer on '%s'\" % (self.display_hostname))\n\n        if op.direction == TransferDirection.TO_REMOTE_MACHINE:\n            name = op.sender\n        else:\n            name = self.local_ident\n\n        if by_sender:\n            op.file_send_cancellable.set()\n            # If we stopped due to connection error, we don't want the message to be 'stopped by xx',\n            # but just failed.\n            if not lost_connection:\n                logging.debug(\"Remote: stop transfer initiated by sender\")\n                if op.error_msg == \"\":\n                    op.set_status(OpStatus.STOPPED_BY_SENDER)\n                else:\n                    op.set_status(OpStatus.FAILED)\n        else:\n            if op.file_iterator:\n                op.file_iterator.cancel()\n            if not lost_connection:\n                logging.debug(\"Remote: stop transfer initiated by receiver\")\n                if op.error_msg == \"\":\n                    op.set_status(OpStatus.STOPPED_BY_RECEIVER)\n                else:\n                    op.set_status(OpStatus.FAILED)\n\n        if not lost_connection:\n            # We don't need to send this if it's a connection loss, the other end will handle\n            # its own cleanup.\n            opinfo = warp_pb2.OpInfo(\n                timestamp=op.start_time,\n                ident=name,\n                readable_name=util.get_hostname()\n            )\n            self.stub.StopTransfer(warp_pb2.StopInfo(info=opinfo, error=op.error_msg != \"\"))\n\n    # Op handling (run in thread pool)\n    def send_files(self, uri_list):\n        def _send_files(uri_list):\n            op = SendOp(\n                self.local_ident,\n                self.ident,\n                self.display_name,\n                uri_list\n            )\n            self.add_op(op)\n            op.prepare_send_info()\n\n        util.add_to_recents_if_single_selection(uri_list)\n        self.rpc_call(_send_files, uri_list)\n\n    @util._idle\n    def add_op(self, op):\n        if op not in self.transfer_ops:\n            self.transfer_ops.append(op)\n            op.connect(\"status-changed\", self.emit_ops_changed)\n            op.connect(\"op-command\", self.op_command_issued)\n            op.connect(\"focus\", self.op_focus)\n            if isinstance(op, SendOp):\n                op.connect(\"initial-setup-complete\", self.notify_remote_machine_of_new_op)\n                self.emit(\"new-outgoing-op\", op)\n            if isinstance(op, ReceiveOp):\n                self.emit(\"new-incoming-op\", op)\n\n        def set_busy():\n            self.busy = True\n\n        op.connect(\"active\", lambda op: set_busy())\n\n        self.emit_ops_changed()\n        self.check_for_autostart(op)\n\n    @util._idle\n    def notify_remote_machine_of_new_op(self, op):\n        if op.status == OpStatus.WAITING_PERMISSION:\n            if op.direction == TransferDirection.TO_REMOTE_MACHINE:\n                self.rpc_call(self.send_transfer_op_request, op)\n\n    @util._idle\n    def check_for_autostart(self, op):\n        if op.status == OpStatus.WAITING_PERMISSION:\n            if isinstance(op, ReceiveOp) and \\\n              op.have_space and \\\n              (not (op.existing and prefs.prevent_overwriting())) and \\\n              (not prefs.require_permission_for_transfer()):\n                op.accept_transfer()\n\n    def remove_op(self, op):\n        self.transfer_ops.remove(op)\n        self.emit_ops_changed()\n\n    @util._idle\n    def emit_ops_changed(self, op=None):\n        self.emit(\"ops-changed\")\n\n    def cancel_ops_if_offline(self):\n        if self.status in (RemoteStatus.OFFLINE, RemoteStatus.UNREACHABLE):\n            for op in self.transfer_ops:\n                if op.status == OpStatus.TRANSFERRING:\n                    op.error_msg = _(\"Connection has been lost\")\n                    self.rpc_call(self.stop_transfer_op, op, isinstance(op, SendOp), lost_connection=True)\n                    op.set_status(OpStatus.FAILED)\n                elif op.status in (OpStatus.WAITING_PERMISSION, OpStatus.CALCULATING, OpStatus.PAUSED):\n                    op.error_msg = _(\"Connection has been lost\")\n                    op.set_status(OpStatus.FAILED_UNRECOVERABLE)\n\n    @util._idle\n    def op_command_issued(self, op, command):\n        # send\n        if command == OpCommand.CANCEL_PERMISSION_BY_SENDER:\n            self.rpc_call(self.cancel_transfer_op_request, op, by_sender=True)\n        # elif command == OpCommand.PAUSE_TRANSFER:\n            # self.rpc_call(self.pause_transfer_op, op)\n        elif command == OpCommand.STOP_TRANSFER_BY_SENDER:\n            self.rpc_call(self.stop_transfer_op, op, by_sender=True)\n        elif command == OpCommand.RETRY_TRANSFER:\n            op.set_status(OpStatus.WAITING_PERMISSION)\n            self.rpc_call(self.send_transfer_op_request, op)\n        elif command == OpCommand.REMOVE_TRANSFER:\n            self.remove_op(op)\n        # receive\n        elif command == OpCommand.START_TRANSFER:\n            self.rpc_call(self.start_transfer_op, op)\n        elif command == OpCommand.CANCEL_PERMISSION_BY_RECEIVER:\n            self.rpc_call(self.cancel_transfer_op_request, op, by_sender=False)\n        elif command == OpCommand.STOP_TRANSFER_BY_RECEIVER:\n            self.rpc_call(self.stop_transfer_op, op, by_sender=False)\n\n    @util._idle\n    def op_focus(self, op):\n        self.emit(\"focus-remote\")\n\n    def lookup_op(self, timestamp):\n        for op in self.transfer_ops:\n            if op.start_time == timestamp:\n                return op\n", "patch": "@@ -474,6 +474,10 @@ def start_transfer_op(self, op):\n         def report_receive_error(error):\n             op.file_iterator = None\n \n+            # Get rid of any toplevel file/folder if the transfer stops prematurely,\n+            # so it or its children \n+            receiver.clean_current_top_dir_file()\n+\n             if error is None:\n                 return\n \n@@ -493,6 +497,8 @@ def report_receive_error(error):\n             op.stop_transfer()\n \n         try:\n+            receiver.clean_existing_files()\n+\n             for data in op.file_iterator:\n                 receiver.receive_data(data)\n \n@@ -596,6 +602,13 @@ def set_busy():\n         op.connect(\"active\", lambda op: set_busy())\n \n         self.emit_ops_changed()\n+\n+        # For now, only bad base filenames cause this (failed util.test_resolved_path_safety())\n+        # We let it get this far so the UI has something to show the user.\n+        if op.status == OpStatus.FAILED_UNRECOVERABLE:\n+            op.decline_transfer_request()\n+            return\n+\n         self.check_for_autostart(op)\n \n     @util._idle", "file_path": "files/2023_5/151", "file_language": "py", "file_name": "src/remote.py", "outdated_file_modify": 0, "outdated_file_before": 1, "outdated_file_after": 0, "llm_check": 0, "static_check": 0, "static": {"rats": [false, []], "semgrep": [false, []]}, "target": 0, "function_before": [{"function": "class RemoteMachine(GObject.Object):\n    __gsignals__ = {\n        'machine-info-changed': (GObject.SignalFlags.RUN_LAST, None, ()),\n        'ops-changed': (GObject.SignalFlags.RUN_LAST, None, ()),\n        'new-incoming-op': (GObject.SignalFlags.RUN_LAST, None, (object,)),\n        'new-outgoing-op': (GObject.SignalFlags.RUN_LAST, None, (object,)),\n        'focus-remote': (GObject.SignalFlags.RUN_LAST, None, ()),\n        'remote-status-changed': (GObject.SignalFlags.RUN_LAST, None, ())\n    }\n\n    def __init__(self, ident, hostname, display_hostname, ip_info, port, local_ident, api_version):\n        GObject.Object.__init__(self)\n        self.ip_info = ip_info\n        self.port = port\n        self.ident = ident\n        self.local_ident = local_ident\n        self.api_version = api_version\n        self.hostname = hostname\n        self.display_hostname = display_hostname\n        self.user_name = \"\"\n        self.display_name = \"\"\n        self.favorite = prefs.get_is_favorite(self.ident)\n        self.recent_time = 0 # Keep monotonic time when visited on the user page\n\n        self.avatar_surface = None\n        self.transfer_ops = []\n\n        self.sort_key = self.hostname\n        self.status = RemoteStatus.INIT_CONNECTING\n\n        self.machine_info_changed_source_id = 0\n        self.machine_info_changed_lock = threading.Lock()\n\n        self.status_idle_source_id = 0\n        self.status_lock = threading.Lock()\n\n        self.stub = None\n\n        self.busy = False # Skip keepalive ping when we're busy.\n        self.ping_timer = threading.Event()\n\n        self.channel_keepalive = threading.Event()\n\n        prefs.prefs_settings.connect(\"changed::favorites\", self.update_favorite_status)\n\n        self.has_zc_presence = False # This is currently unused.\n\n    def start_remote_thread(self):\n        # func = lambda: return\n\n        if self.api_version == \"1\":\n            func = self.remote_thread_v1\n        elif self.api_version == \"2\":\n            func = self.remote_thread_v2\n\n        self.remote_thread = threading.Thread(target=func, name=\"remote-main-thread-v%s-%s-%s:%d-%s\"\n                                              % (self.api_version, self.hostname, self.ip_info.ip4_address, self.port, self.ident))\n        # logging.debug(\"remote-thread-%s-%s:%d-%s\"\n                          # % (self.hostname, self.ip_info.ip4_address, self.port, self.ident))\n        self.remote_thread.start()\n\n    def remote_thread_v1(self):\n        self.ping_timer.clear()\n\n        self.emit_machine_info_changed() # Let's make sure the button doesn't have junk in it if we fail to connect.\n\n        logging.debug(\"Remote: Attempting to connect to %s (%s) - api version 1\" % (self.display_hostname, self.ip_info.ip4_address))\n\n        self.set_remote_status(RemoteStatus.INIT_CONNECTING)\n\n        def run_secure_loop():\n            logging.debug(\"Remote: Starting a new connection loop for %s (%s:%d)\"\n                              % (self.display_hostname, self.ip_info.ip4_address, self.port))\n\n            cert = auth.get_singleton().get_cached_cert(self.hostname, self.ip_info)\n            creds = grpc.ssl_channel_credentials(cert)\n\n            with grpc.secure_channel(\"%s:%d\" % (self.ip_info.ip4_address, self.port), creds) as channel:\n                future = grpc.channel_ready_future(channel)\n\n                try:\n                    future.result(timeout=4)\n                    self.stub = warp_pb2_grpc.WarpStub(channel)\n                except grpc.FutureTimeoutError:\n                    self.set_remote_status(RemoteStatus.UNREACHABLE)\n                    future.cancel()\n\n                    if not self.ping_timer.is_set():\n                        logging.debug(\"Remote: Unable to establish secure connection with %s (%s:%d). Trying again in %ds\"\n                                          % (self.display_hostname, self.ip_info.ip4_address, self.port, CHANNEL_RETRY_WAIT_TIME))\n                        self.ping_timer.wait(CHANNEL_RETRY_WAIT_TIME)\n                        return True # run_secure_loop()\n\n                    return False # run_secure_loop()\n\n                duplex_fail_counter = 0\n                one_ping = False # A successful duplex response lets us finish setting things up.\n\n                while not self.ping_timer.is_set():\n\n                    if self.busy:\n                        logging.debug(\"Remote Ping: Skipping keepalive ping to %s (%s:%d) (busy)\"\n                                          % (self.display_hostname, self.ip_info.ip4_address, self.port))\n                        self.busy = False\n                    else:\n                        try:\n                            # t = GLib.get_monotonic_time()\n                            logging.debug(\"Remote Ping: to   %s (%s:%d)\"\n                                          % (self.display_hostname, self.ip_info.ip4_address, self.port))\n                            self.stub.Ping(warp_pb2.LookupName(id=self.local_ident,\n                                                               readable_name=util.get_hostname()),\n                                           timeout=5)\n                            # logging.debug(\"Latency: %s (%s)\"\n                                          # % (util.precise_format_time_span(GLib.get_monotonic_time() - t), self.display_hostname))\n                            if not one_ping:\n                                self.set_remote_status(RemoteStatus.AWAITING_DUPLEX)\n                                if self.check_duplex_connection():\n                                    logging.debug(\"Remote: Connected to %s (%s:%d)\"\n                                                      % (self.display_hostname, self.ip_info.ip4_address, self.port))\n\n                                    self.set_remote_status(RemoteStatus.ONLINE)\n\n                                    self.rpc_call(self.update_remote_machine_info)\n                                    self.rpc_call(self.update_remote_machine_avatar)\n                                    one_ping = True\n                                else:\n                                    duplex_fail_counter += 1\n                                    if duplex_fail_counter > DUPLEX_MAX_FAILURES:\n                                        logging.debug(\"Remote: CheckDuplexConnection to %s (%s:%d) failed too many times\"\n                                                          % (self.display_hostname, self.ip_info.ip4_address, self.port))\n                                        self.ping_timer.wait(CHANNEL_RETRY_WAIT_TIME)\n                                        return True\n                        except grpc.RpcError as e:\n                            logging.debug(\"Remote: Ping failed, shutting down %s (%s:%d)\"\n                                              % (self.display_hostname, self.ip_info.ip4_address, self.port))\n                            break\n\n                    self.ping_timer.wait(CONNECTED_PING_TIME if self.status == RemoteStatus.ONLINE else DUPLEX_WAIT_PING_TIME)\n\n                # This is reached by the RpcError break above.  If the remote is still discoverable, start\n                # the secure loop over.  This could have happened as a result of a quick disco/reconnect,\n                # And we don't notice until it has already come back. In this case, try a new connection.\n                if self.has_zc_presence and not self.ping_timer.is_set():\n                    return True # run_secure_loop()\n\n                # The ping timer has been triggered, this is an orderly shutdown.\n                return False # run_secure_loop()\n\n        try:\n            while run_secure_loop():\n                continue\n        except Exception as e:\n            logging.critical(\"!! Major problem starting connection loop for %s (%s:%d): %s\"\n                                 % (self.display_hostname, self.ip_info.ip4_address, self.port, e))\n\n        self.set_remote_status(RemoteStatus.OFFLINE)\n        self.run_thread_alive = False\n\n    def remote_thread_v2(self):\n        self.channel_keepalive.clear()\n\n        self.emit_machine_info_changed() # Let's make sure the button doesn't have junk in it if we fail to connect.\n\n        logging.debug(\"Remote: Attempting to connect to %s (%s) - api version 2\" % (self.display_hostname, self.ip_info.ip4_address))\n\n        self.set_remote_status(RemoteStatus.INIT_CONNECTING)\n\n        cert = auth.get_singleton().get_cached_cert(self.hostname, self.ip_info)\n        creds = grpc.ssl_channel_credentials(cert)\n\n        def run_secure_loop():\n            opts = (\n                ('grpc.keepalive_time_ms', 10000),\n                ('grpc.keepalive_timeout_ms', 5000),\n                ('grpc.keepalive_permit_without_calls', True),\n                ('grpc.http2.max_pings_without_data', 0),\n                ('grpc.http2.min_time_between_pings_ms', 10000),\n                ('grpc.http2.min_ping_interval_without_data_ms', 5000)\n            )\n\n            with grpc.secure_channel(\"%s:%d\" % (self.ip_info.ip4_address, self.port), creds, options=opts) as channel:\n\n                def channel_state_changed(state):\n                    if state != grpc.ChannelConnectivity.READY:\n                        # The server may have already called shutdown\n                        try:\n                            self.shutdown()\n                        except:\n                            pass\n\n                intercepted_channel = grpc.intercept_channel(channel,\n                                                             interceptors.ChunkDecompressor())\n\n                future = grpc.channel_ready_future(intercepted_channel)\n\n                try:\n                    future.result(timeout=4)\n                    channel.subscribe(channel_state_changed)\n                    self.stub = warp_pb2_grpc.WarpStub(intercepted_channel)\n\n                    self.set_remote_status(RemoteStatus.AWAITING_DUPLEX)\n\n                    duplex = self.wait_for_duplex()\n                    duplex.result(timeout=10)\n\n                    self.set_remote_status(RemoteStatus.ONLINE)\n\n                    self.rpc_call(self.update_remote_machine_info)\n                    self.rpc_call(self.update_remote_machine_avatar)\n\n                    # Online loop\n                    logging.info(\"Connected to %s\" % self.display_hostname)\n                    while not self.channel_keepalive.is_set():\n                        self.channel_keepalive.wait(.5)\n                    ##\n\n                except Exception as e:\n                    self.set_remote_status(RemoteStatus.UNREACHABLE)\n\n                    if isinstance(e, grpc.FutureTimeoutError):\n                        future.cancel()\n                        logging.critical(\"Problem while waiting for channel - api version 2: %s\" % e)\n                    elif isinstance(e, grpc.RpcError):\n                        logging.critical(\"Problem while awaiting duplex response - api version 2: %s - %s\" % (e.code(), e.details()))\n                    else:\n                        logging.critical(\"General error with remote channel connection - api version 2: %s\" % e)\n\n                    self.channel_keepalive.wait(10)\n                finally:\n                    channel.unsubscribe(channel_state_changed)\n\n        while not self.channel_keepalive.is_set():\n            run_secure_loop()\n\n        self.set_remote_status(RemoteStatus.OFFLINE)\n\n    def shutdown(self):\n        if self.api_version == \"1\":\n            self.ping_timer.set()\n        else:\n            self.channel_keepalive.set()\n        # This is called by server just before running start_remote_thread, so the first time\n        # self.remote_thread will be None.\n        try:\n            self.remote_thread.join(10)\n        except AttributeError:\n            pass\n\n        self.remote_thread = None\n\n    def update_favorite_status(self, pspec, data=None):\n        old_favorite = self.favorite\n        self.favorite = prefs.get_is_favorite(self.ident)\n\n        if old_favorite != self.favorite:\n            self.emit_machine_info_changed()\n\n    def stamp_recent_time(self):\n        self.recent_time = GLib.get_monotonic_time()\n        self.emit_machine_info_changed()\n\n    def set_remote_status(self, status):\n        with self.status_lock:\n            if self.status_idle_source_id > 0:\n                GLib.source_remove(self.status_idle_source_id)\n\n            self.status_idle_source_id = GLib.idle_add(self.set_status_cb, status)\n\n    def set_status_cb(self, status):\n        with self.status_lock:\n            self.status_idle_source_id = 0\n\n            if status == self.status:\n                return GLib.SOURCE_REMOVE\n\n            self.status = status\n            self.cancel_ops_if_offline()\n\n            logging.debug(\"Remote: %s is now %s ****\" % (self.hostname, self.status))\n            self.emit(\"remote-status-changed\")\n\n        return GLib.SOURCE_REMOVE\n\n    def emit_machine_info_changed(self):\n        with self.machine_info_changed_lock:\n            if self.machine_info_changed_source_id > 0:\n                GLib.source_remove(self.machine_info_changed_source_id)\n\n            self.machine_info_changed_source_id = GLib.idle_add(self.emit_machine_info_changed_cb)\n\n    def emit_machine_info_changed_cb(self):\n        with self.machine_info_changed_lock:\n            self.machine_info_changed_source_id = 0\n            self.emit(\"machine-info-changed\")\n\n        return GLib.SOURCE_REMOVE\n\n    def rpc_call(self, func, *args, **kargs):\n        try:\n            util.global_rpc_threadpool.submit(func, *args, **kargs)\n        except Exception as e:\n            # exception concurrent.futures.thread.BrokenThreadPool is not available in bionic/python3 < 3.7\n            logging.critical(\"!! RPC threadpool failure while submitting call to %s (%s:%d): %s\"\n                                 % (self.display_hostname, self.ip_info.ip4_address, self.port, e))\n\n    # Not added to thread pool\n    def check_duplex_connection(self):\n        logging.debug(\"Remote: checking duplex with '%s'\" % self.display_hostname)\n\n        ret = self.stub.CheckDuplexConnection(warp_pb2.LookupName(id=self.local_ident,\n                                                                  readable_name=util.get_hostname()))\n\n        return ret.response\n\n    def wait_for_duplex(self):\n        logging.debug(\"Remote: waiting for duplex from '%s'\" % self.display_hostname)\n\n        future = self.stub.WaitingForDuplex.future(warp_pb2.LookupName(id=self.local_ident,\n                                                                       readable_name=util.get_hostname()))\n\n        return future\n\n    # Run in thread pool\n    def update_remote_machine_info(self):\n        logging.debug(\"Remote RPC: calling GetRemoteMachineInfo on '%s'\" % self.display_hostname)\n        def get_info_finished(future):\n            info = future.result()\n            self.display_name = info.display_name\n            self.user_name = info.user_name\n            self.favorite = prefs.get_is_favorite(self.ident)\n\n            valid = GLib.utf8_make_valid(self.display_name, -1)\n            self.sort_key = GLib.utf8_collate_key(valid.lower(), -1)\n\n            self.emit_machine_info_changed()\n            self.set_remote_status(RemoteStatus.ONLINE)\n        \n        future = self.stub.GetRemoteMachineInfo.future(\n            warp_pb2.LookupName(\n                id=self.local_ident,\n                readable_name=util.get_hostname()\n            )\n        )\n        future.add_done_callback(get_info_finished)\n\n    # Run in thread pool\n    def update_remote_machine_avatar(self):\n        logging.debug(\"Remote RPC: calling GetRemoteMachineAvatar on '%s'\" % self.display_hostname)\n        iterator = self.stub.GetRemoteMachineAvatar(\n            warp_pb2.LookupName(\n                id=self.local_ident,\n                readable_name=util.get_hostname()\n            )\n        )\n        loader = None\n        try:\n            for info in iterator:\n                if loader is None:\n                    loader = util.CairoSurfaceLoader()\n                loader.add_bytes(info.avatar_chunk)\n        except grpc.RpcError as e:\n            logging.debug(\"Remote RPC: could not fetch remote avatar, using a generic one. (%s, %s)\" % (e.code(), e.details()))\n\n        self.get_avatar_surface(loader)\n\n    @util._idle\n    def get_avatar_surface(self, loader=None):\n        # This needs to be on the main loop, or else we get an x error\n        if loader:\n            self.avatar_surface = loader.get_surface()\n        else:\n            self.avatar_surface = None\n\n        self.emit_machine_info_changed()\n\n    # Run in thread pool\n    def send_transfer_op_request(self, op):\n        if not self.stub: # short circuit for testing widgets\n            return\n\n        logging.debug(\"Remote RPC: calling TransferOpRequest on '%s'\" % (self.display_hostname))\n\n        transfer_op = warp_pb2.TransferOpRequest(\n            info=warp_pb2.OpInfo(\n                ident=op.sender,\n                timestamp=op.start_time,\n                readable_name=util.get_hostname(),\n                use_compression=prefs.use_compression(),\n            ),\n            sender_name=op.sender_name,\n            receiver=self.ident,\n            size=op.total_size,\n            count=op.total_count,\n            name_if_single=op.description,\n            mime_if_single=op.mime_if_single,\n            top_dir_basenames=op.top_dir_basenames\n        )\n\n        self.stub.ProcessTransferOpRequest(transfer_op)\n\n    # Run in thread pool\n    def cancel_transfer_op_request(self, op, by_sender=False):\n        logging.debug(\"Remote RPC: calling CancelTransferOpRequest on '%s'\" % (self.display_hostname))\n\n        if op.direction == TransferDirection.TO_REMOTE_MACHINE:\n            name = op.sender\n        else:\n            name = self.local_ident\n        self.stub.CancelTransferOpRequest(\n            warp_pb2.OpInfo(\n                timestamp=op.start_time,\n                ident=name,\n                readable_name=util.get_hostname()\n            )\n        )\n        op.set_status(OpStatus.CANCELLED_PERMISSION_BY_SENDER if by_sender else OpStatus.CANCELLED_PERMISSION_BY_RECEIVER)\n\n    # Run in thread pool\n    def start_transfer_op(self, op):\n        logging.debug(\"Remote RPC: calling StartTransfer on '%s'\" % (self.display_hostname))\n\n        start_time = GLib.get_monotonic_time()\n\n        op.progress_tracker = transfers.OpProgressTracker(op)\n        op.current_progress_report = None\n        receiver = transfers.FileReceiver(op)\n        op.set_status(OpStatus.TRANSFERRING)\n\n        # This is ugly because StartTransfer only returns file_iterator. The\n        # interceptor returns the cancellable with it, because file_iterator\n        # is not a future if compression is active, it's just a generator.\n        op.file_iterator = self.stub.StartTransfer(\n            warp_pb2.OpInfo(\n                timestamp=op.start_time,\n                ident=self.local_ident,\n                readable_name=util.get_hostname(),\n                use_compression=op.use_compression and prefs.use_compression()\n            )\n        )\n\n        def report_receive_error(error):\n            op.file_iterator = None\n\n            if error is None:\n                return\n\n            op.set_error(error)\n\n            try:\n                # If we leave an io stream open, it locks the location.  For instance,\n                # if this was a mounted location, we wouldn't be able to terminate until\n                # we closed warp.\n                if receiver.current_stream is not None:\n                    receiver.current_stream.close()\n            except GLib.Error:\n                pass\n\n            logging.critical(\"An error occurred receiving data from %s: %s\" % (op.sender, op.error_msg))\n            op.set_status(OpStatus.FAILED)\n            op.stop_transfer()\n\n        try:\n            for data in op.file_iterator:\n                receiver.receive_data(data)\n\n            op.file_iterator = None\n            receiver.receive_finished()\n\n            logging.debug(\"Remote: receipt of %s files (%s) finished in %s\" % \\\n                          (op.total_count, GLib.format_size(op.total_size),\\\n                           util.precise_format_time_span(GLib.get_monotonic_time() - start_time)))\n\n            if op.remaining_count > 0:\n                raise ReceiveError(\"Transfer completed, but the number of files received is less than the original request size (expected %d, received %d)\"\n                                       % (op.total_count, op.total_count - receiver.remaining_count),\n                                   fatal=False)\n            op.set_status(OpStatus.FINISHED)\n        except grpc.RpcError as e:\n            if e.code() == grpc.StatusCode.CANCELLED:\n                report_receive_error(None)\n            else:\n                report_receive_error(e)\n        except ReceiveError as e:\n            if e.fatal:\n                report_receive_error(e)\n            else:\n                logging.critical(str(e))\n                op.set_error(e)\n                op.set_status(OpStatus.FINISHED_WARNING)\n        except Exception as e:\n            report_receive_error(e)\n\n    # Run in thread pool\n    def stop_transfer_op(self, op, by_sender=False, lost_connection=False):\n        logging.debug(\"Remote RPC: Calling StopTransfer on '%s'\" % (self.display_hostname))\n\n        if op.direction == TransferDirection.TO_REMOTE_MACHINE:\n            name = op.sender\n        else:\n            name = self.local_ident\n\n        if by_sender:\n            op.file_send_cancellable.set()\n            # If we stopped due to connection error, we don't want the message to be 'stopped by xx',\n            # but just failed.\n            if not lost_connection:\n                logging.debug(\"Remote: stop transfer initiated by sender\")\n                if op.error_msg == \"\":\n                    op.set_status(OpStatus.STOPPED_BY_SENDER)\n                else:\n                    op.set_status(OpStatus.FAILED)\n        else:\n            if op.file_iterator:\n                op.file_iterator.cancel()\n            if not lost_connection:\n                logging.debug(\"Remote: stop transfer initiated by receiver\")\n                if op.error_msg == \"\":\n                    op.set_status(OpStatus.STOPPED_BY_RECEIVER)\n                else:\n                    op.set_status(OpStatus.FAILED)\n\n        if not lost_connection:\n            # We don't need to send this if it's a connection loss, the other end will handle\n            # its own cleanup.\n            opinfo = warp_pb2.OpInfo(\n                timestamp=op.start_time,\n                ident=name,\n                readable_name=util.get_hostname()\n            )\n            self.stub.StopTransfer(warp_pb2.StopInfo(info=opinfo, error=op.error_msg != \"\"))\n\n    # Op handling (run in thread pool)\n    def send_files(self, uri_list):\n        def _send_files(uri_list):\n            op = SendOp(\n                self.local_ident,\n                self.ident,\n                self.display_name,\n                uri_list\n            )\n            self.add_op(op)\n            op.prepare_send_info()\n\n        util.add_to_recents_if_single_selection(uri_list)\n        self.rpc_call(_send_files, uri_list)\n\n    @util._idle\n    def add_op(self, op):\n        if op not in self.transfer_ops:\n            self.transfer_ops.append(op)\n            op.connect(\"status-changed\", self.emit_ops_changed)\n            op.connect(\"op-command\", self.op_command_issued)\n            op.connect(\"focus\", self.op_focus)\n            if isinstance(op, SendOp):\n                op.connect(\"initial-setup-complete\", self.notify_remote_machine_of_new_op)\n                self.emit(\"new-outgoing-op\", op)\n            if isinstance(op, ReceiveOp):\n                self.emit(\"new-incoming-op\", op)\n\n        def set_busy():\n            self.busy = True\n\n        op.connect(\"active\", lambda op: set_busy())\n\n        self.emit_ops_changed()\n        self.check_for_autostart(op)\n\n    @util._idle\n    def notify_remote_machine_of_new_op(self, op):\n        if op.status == OpStatus.WAITING_PERMISSION:\n            if op.direction == TransferDirection.TO_REMOTE_MACHINE:\n                self.rpc_call(self.send_transfer_op_request, op)\n\n    @util._idle\n    def check_for_autostart(self, op):\n        if op.status == OpStatus.WAITING_PERMISSION:\n            if isinstance(op, ReceiveOp) and \\\n              op.have_space and \\\n              (not (op.existing and prefs.prevent_overwriting())) and \\\n              (not prefs.require_permission_for_transfer()):\n                op.accept_transfer()\n\n    def remove_op(self, op):\n        self.transfer_ops.remove(op)\n        self.emit_ops_changed()\n\n    @util._idle\n    def emit_ops_changed(self, op=None):\n        self.emit(\"ops-changed\")\n\n    def cancel_ops_if_offline(self):\n        if self.status in (RemoteStatus.OFFLINE, RemoteStatus.UNREACHABLE):\n            for op in self.transfer_ops:\n                if op.status == OpStatus.TRANSFERRING:\n                    op.error_msg = _(\"Connection has been lost\")\n                    self.rpc_call(self.stop_transfer_op, op, isinstance(op, SendOp), lost_connection=True)\n                    op.set_status(OpStatus.FAILED)\n                elif op.status in (OpStatus.WAITING_PERMISSION, OpStatus.CALCULATING, OpStatus.PAUSED):\n                    op.error_msg = _(\"Connection has been lost\")\n                    op.set_status(OpStatus.FAILED_UNRECOVERABLE)\n\n    @util._idle\n    def op_command_issued(self, op, command):\n        # send\n        if command == OpCommand.CANCEL_PERMISSION_BY_SENDER:\n            self.rpc_call(self.cancel_transfer_op_request, op, by_sender=True)\n        # elif command == OpCommand.PAUSE_TRANSFER:\n            # self.rpc_call(self.pause_transfer_op, op)\n        elif command == OpCommand.STOP_TRANSFER_BY_SENDER:\n            self.rpc_call(self.stop_transfer_op, op, by_sender=True)\n        elif command == OpCommand.RETRY_TRANSFER:\n            op.set_status(OpStatus.WAITING_PERMISSION)\n            self.rpc_call(self.send_transfer_op_request, op)\n        elif command == OpCommand.REMOVE_TRANSFER:\n            self.remove_op(op)\n        # receive\n        elif command == OpCommand.START_TRANSFER:\n            self.rpc_call(self.start_transfer_op, op)\n        elif command == OpCommand.CANCEL_PERMISSION_BY_RECEIVER:\n            self.rpc_call(self.cancel_transfer_op_request, op, by_sender=False)\n        elif command == OpCommand.STOP_TRANSFER_BY_RECEIVER:\n            self.rpc_call(self.stop_transfer_op, op, by_sender=False)\n\n    @util._idle\n    def op_focus(self, op):\n        self.emit(\"focus-remote\")\n\n    def lookup_op(self, timestamp):\n        for op in self.transfer_ops:\n            if op.start_time == timestamp:\n                return op", "target": 0}], "function_after": [{"function": "class RemoteMachine(GObject.Object):\n    __gsignals__ = {\n        'machine-info-changed': (GObject.SignalFlags.RUN_LAST, None, ()),\n        'ops-changed': (GObject.SignalFlags.RUN_LAST, None, ()),\n        'new-incoming-op': (GObject.SignalFlags.RUN_LAST, None, (object,)),\n        'new-outgoing-op': (GObject.SignalFlags.RUN_LAST, None, (object,)),\n        'focus-remote': (GObject.SignalFlags.RUN_LAST, None, ()),\n        'remote-status-changed': (GObject.SignalFlags.RUN_LAST, None, ())\n    }\n\n    def __init__(self, ident, hostname, display_hostname, ip_info, port, local_ident, api_version):\n        GObject.Object.__init__(self)\n        self.ip_info = ip_info\n        self.port = port\n        self.ident = ident\n        self.local_ident = local_ident\n        self.api_version = api_version\n        self.hostname = hostname\n        self.display_hostname = display_hostname\n        self.user_name = \"\"\n        self.display_name = \"\"\n        self.favorite = prefs.get_is_favorite(self.ident)\n        self.recent_time = 0 # Keep monotonic time when visited on the user page\n\n        self.avatar_surface = None\n        self.transfer_ops = []\n\n        self.sort_key = self.hostname\n        self.status = RemoteStatus.INIT_CONNECTING\n\n        self.machine_info_changed_source_id = 0\n        self.machine_info_changed_lock = threading.Lock()\n\n        self.status_idle_source_id = 0\n        self.status_lock = threading.Lock()\n\n        self.stub = None\n\n        self.busy = False # Skip keepalive ping when we're busy.\n        self.ping_timer = threading.Event()\n\n        self.channel_keepalive = threading.Event()\n\n        prefs.prefs_settings.connect(\"changed::favorites\", self.update_favorite_status)\n\n        self.has_zc_presence = False # This is currently unused.\n\n    def start_remote_thread(self):\n        # func = lambda: return\n\n        if self.api_version == \"1\":\n            func = self.remote_thread_v1\n        elif self.api_version == \"2\":\n            func = self.remote_thread_v2\n\n        self.remote_thread = threading.Thread(target=func, name=\"remote-main-thread-v%s-%s-%s:%d-%s\"\n                                              % (self.api_version, self.hostname, self.ip_info.ip4_address, self.port, self.ident))\n        # logging.debug(\"remote-thread-%s-%s:%d-%s\"\n                          # % (self.hostname, self.ip_info.ip4_address, self.port, self.ident))\n        self.remote_thread.start()\n\n    def remote_thread_v1(self):\n        self.ping_timer.clear()\n\n        self.emit_machine_info_changed() # Let's make sure the button doesn't have junk in it if we fail to connect.\n\n        logging.debug(\"Remote: Attempting to connect to %s (%s) - api version 1\" % (self.display_hostname, self.ip_info.ip4_address))\n\n        self.set_remote_status(RemoteStatus.INIT_CONNECTING)\n\n        def run_secure_loop():\n            logging.debug(\"Remote: Starting a new connection loop for %s (%s:%d)\"\n                              % (self.display_hostname, self.ip_info.ip4_address, self.port))\n\n            cert = auth.get_singleton().get_cached_cert(self.hostname, self.ip_info)\n            creds = grpc.ssl_channel_credentials(cert)\n\n            with grpc.secure_channel(\"%s:%d\" % (self.ip_info.ip4_address, self.port), creds) as channel:\n                future = grpc.channel_ready_future(channel)\n\n                try:\n                    future.result(timeout=4)\n                    self.stub = warp_pb2_grpc.WarpStub(channel)\n                except grpc.FutureTimeoutError:\n                    self.set_remote_status(RemoteStatus.UNREACHABLE)\n                    future.cancel()\n\n                    if not self.ping_timer.is_set():\n                        logging.debug(\"Remote: Unable to establish secure connection with %s (%s:%d). Trying again in %ds\"\n                                          % (self.display_hostname, self.ip_info.ip4_address, self.port, CHANNEL_RETRY_WAIT_TIME))\n                        self.ping_timer.wait(CHANNEL_RETRY_WAIT_TIME)\n                        return True # run_secure_loop()\n\n                    return False # run_secure_loop()\n\n                duplex_fail_counter = 0\n                one_ping = False # A successful duplex response lets us finish setting things up.\n\n                while not self.ping_timer.is_set():\n\n                    if self.busy:\n                        logging.debug(\"Remote Ping: Skipping keepalive ping to %s (%s:%d) (busy)\"\n                                          % (self.display_hostname, self.ip_info.ip4_address, self.port))\n                        self.busy = False\n                    else:\n                        try:\n                            # t = GLib.get_monotonic_time()\n                            logging.debug(\"Remote Ping: to   %s (%s:%d)\"\n                                          % (self.display_hostname, self.ip_info.ip4_address, self.port))\n                            self.stub.Ping(warp_pb2.LookupName(id=self.local_ident,\n                                                               readable_name=util.get_hostname()),\n                                           timeout=5)\n                            # logging.debug(\"Latency: %s (%s)\"\n                                          # % (util.precise_format_time_span(GLib.get_monotonic_time() - t), self.display_hostname))\n                            if not one_ping:\n                                self.set_remote_status(RemoteStatus.AWAITING_DUPLEX)\n                                if self.check_duplex_connection():\n                                    logging.debug(\"Remote: Connected to %s (%s:%d)\"\n                                                      % (self.display_hostname, self.ip_info.ip4_address, self.port))\n\n                                    self.set_remote_status(RemoteStatus.ONLINE)\n\n                                    self.rpc_call(self.update_remote_machine_info)\n                                    self.rpc_call(self.update_remote_machine_avatar)\n                                    one_ping = True\n                                else:\n                                    duplex_fail_counter += 1\n                                    if duplex_fail_counter > DUPLEX_MAX_FAILURES:\n                                        logging.debug(\"Remote: CheckDuplexConnection to %s (%s:%d) failed too many times\"\n                                                          % (self.display_hostname, self.ip_info.ip4_address, self.port))\n                                        self.ping_timer.wait(CHANNEL_RETRY_WAIT_TIME)\n                                        return True\n                        except grpc.RpcError as e:\n                            logging.debug(\"Remote: Ping failed, shutting down %s (%s:%d)\"\n                                              % (self.display_hostname, self.ip_info.ip4_address, self.port))\n                            break\n\n                    self.ping_timer.wait(CONNECTED_PING_TIME if self.status == RemoteStatus.ONLINE else DUPLEX_WAIT_PING_TIME)\n\n                # This is reached by the RpcError break above.  If the remote is still discoverable, start\n                # the secure loop over.  This could have happened as a result of a quick disco/reconnect,\n                # And we don't notice until it has already come back. In this case, try a new connection.\n                if self.has_zc_presence and not self.ping_timer.is_set():\n                    return True # run_secure_loop()\n\n                # The ping timer has been triggered, this is an orderly shutdown.\n                return False # run_secure_loop()\n\n        try:\n            while run_secure_loop():\n                continue\n        except Exception as e:\n            logging.critical(\"!! Major problem starting connection loop for %s (%s:%d): %s\"\n                                 % (self.display_hostname, self.ip_info.ip4_address, self.port, e))\n\n        self.set_remote_status(RemoteStatus.OFFLINE)\n        self.run_thread_alive = False\n\n    def remote_thread_v2(self):\n        self.channel_keepalive.clear()\n\n        self.emit_machine_info_changed() # Let's make sure the button doesn't have junk in it if we fail to connect.\n\n        logging.debug(\"Remote: Attempting to connect to %s (%s) - api version 2\" % (self.display_hostname, self.ip_info.ip4_address))\n\n        self.set_remote_status(RemoteStatus.INIT_CONNECTING)\n\n        cert = auth.get_singleton().get_cached_cert(self.hostname, self.ip_info)\n        creds = grpc.ssl_channel_credentials(cert)\n\n        def run_secure_loop():\n            opts = (\n                ('grpc.keepalive_time_ms', 10000),\n                ('grpc.keepalive_timeout_ms', 5000),\n                ('grpc.keepalive_permit_without_calls', True),\n                ('grpc.http2.max_pings_without_data', 0),\n                ('grpc.http2.min_time_between_pings_ms', 10000),\n                ('grpc.http2.min_ping_interval_without_data_ms', 5000)\n            )\n\n            with grpc.secure_channel(\"%s:%d\" % (self.ip_info.ip4_address, self.port), creds, options=opts) as channel:\n\n                def channel_state_changed(state):\n                    if state != grpc.ChannelConnectivity.READY:\n                        # The server may have already called shutdown\n                        try:\n                            self.shutdown()\n                        except:\n                            pass\n\n                intercepted_channel = grpc.intercept_channel(channel,\n                                                             interceptors.ChunkDecompressor())\n\n                future = grpc.channel_ready_future(intercepted_channel)\n\n                try:\n                    future.result(timeout=4)\n                    channel.subscribe(channel_state_changed)\n                    self.stub = warp_pb2_grpc.WarpStub(intercepted_channel)\n\n                    self.set_remote_status(RemoteStatus.AWAITING_DUPLEX)\n\n                    duplex = self.wait_for_duplex()\n                    duplex.result(timeout=10)\n\n                    self.set_remote_status(RemoteStatus.ONLINE)\n\n                    self.rpc_call(self.update_remote_machine_info)\n                    self.rpc_call(self.update_remote_machine_avatar)\n\n                    # Online loop\n                    logging.info(\"Connected to %s\" % self.display_hostname)\n                    while not self.channel_keepalive.is_set():\n                        self.channel_keepalive.wait(.5)\n                    ##\n\n                except Exception as e:\n                    self.set_remote_status(RemoteStatus.UNREACHABLE)\n\n                    if isinstance(e, grpc.FutureTimeoutError):\n                        future.cancel()\n                        logging.critical(\"Problem while waiting for channel - api version 2: %s\" % e)\n                    elif isinstance(e, grpc.RpcError):\n                        logging.critical(\"Problem while awaiting duplex response - api version 2: %s - %s\" % (e.code(), e.details()))\n                    else:\n                        logging.critical(\"General error with remote channel connection - api version 2: %s\" % e)\n\n                    self.channel_keepalive.wait(10)\n                finally:\n                    channel.unsubscribe(channel_state_changed)\n\n        while not self.channel_keepalive.is_set():\n            run_secure_loop()\n\n        self.set_remote_status(RemoteStatus.OFFLINE)\n\n    def shutdown(self):\n        if self.api_version == \"1\":\n            self.ping_timer.set()\n        else:\n            self.channel_keepalive.set()\n        # This is called by server just before running start_remote_thread, so the first time\n        # self.remote_thread will be None.\n        try:\n            self.remote_thread.join(10)\n        except AttributeError:\n            pass\n\n        self.remote_thread = None\n\n    def update_favorite_status(self, pspec, data=None):\n        old_favorite = self.favorite\n        self.favorite = prefs.get_is_favorite(self.ident)\n\n        if old_favorite != self.favorite:\n            self.emit_machine_info_changed()\n\n    def stamp_recent_time(self):\n        self.recent_time = GLib.get_monotonic_time()\n        self.emit_machine_info_changed()\n\n    def set_remote_status(self, status):\n        with self.status_lock:\n            if self.status_idle_source_id > 0:\n                GLib.source_remove(self.status_idle_source_id)\n\n            self.status_idle_source_id = GLib.idle_add(self.set_status_cb, status)\n\n    def set_status_cb(self, status):\n        with self.status_lock:\n            self.status_idle_source_id = 0\n\n            if status == self.status:\n                return GLib.SOURCE_REMOVE\n\n            self.status = status\n            self.cancel_ops_if_offline()\n\n            logging.debug(\"Remote: %s is now %s ****\" % (self.hostname, self.status))\n            self.emit(\"remote-status-changed\")\n\n        return GLib.SOURCE_REMOVE\n\n    def emit_machine_info_changed(self):\n        with self.machine_info_changed_lock:\n            if self.machine_info_changed_source_id > 0:\n                GLib.source_remove(self.machine_info_changed_source_id)\n\n            self.machine_info_changed_source_id = GLib.idle_add(self.emit_machine_info_changed_cb)\n\n    def emit_machine_info_changed_cb(self):\n        with self.machine_info_changed_lock:\n            self.machine_info_changed_source_id = 0\n            self.emit(\"machine-info-changed\")\n\n        return GLib.SOURCE_REMOVE\n\n    def rpc_call(self, func, *args, **kargs):\n        try:\n            util.global_rpc_threadpool.submit(func, *args, **kargs)\n        except Exception as e:\n            # exception concurrent.futures.thread.BrokenThreadPool is not available in bionic/python3 < 3.7\n            logging.critical(\"!! RPC threadpool failure while submitting call to %s (%s:%d): %s\"\n                                 % (self.display_hostname, self.ip_info.ip4_address, self.port, e))\n\n    # Not added to thread pool\n    def check_duplex_connection(self):\n        logging.debug(\"Remote: checking duplex with '%s'\" % self.display_hostname)\n\n        ret = self.stub.CheckDuplexConnection(warp_pb2.LookupName(id=self.local_ident,\n                                                                  readable_name=util.get_hostname()))\n\n        return ret.response\n\n    def wait_for_duplex(self):\n        logging.debug(\"Remote: waiting for duplex from '%s'\" % self.display_hostname)\n\n        future = self.stub.WaitingForDuplex.future(warp_pb2.LookupName(id=self.local_ident,\n                                                                       readable_name=util.get_hostname()))\n\n        return future\n\n    # Run in thread pool\n    def update_remote_machine_info(self):\n        logging.debug(\"Remote RPC: calling GetRemoteMachineInfo on '%s'\" % self.display_hostname)\n        def get_info_finished(future):\n            info = future.result()\n            self.display_name = info.display_name\n            self.user_name = info.user_name\n            self.favorite = prefs.get_is_favorite(self.ident)\n\n            valid = GLib.utf8_make_valid(self.display_name, -1)\n            self.sort_key = GLib.utf8_collate_key(valid.lower(), -1)\n\n            self.emit_machine_info_changed()\n            self.set_remote_status(RemoteStatus.ONLINE)\n        \n        future = self.stub.GetRemoteMachineInfo.future(\n            warp_pb2.LookupName(\n                id=self.local_ident,\n                readable_name=util.get_hostname()\n            )\n        )\n        future.add_done_callback(get_info_finished)\n\n    # Run in thread pool\n    def update_remote_machine_avatar(self):\n        logging.debug(\"Remote RPC: calling GetRemoteMachineAvatar on '%s'\" % self.display_hostname)\n        iterator = self.stub.GetRemoteMachineAvatar(\n            warp_pb2.LookupName(\n                id=self.local_ident,\n                readable_name=util.get_hostname()\n            )\n        )\n        loader = None\n        try:\n            for info in iterator:\n                if loader is None:\n                    loader = util.CairoSurfaceLoader()\n                loader.add_bytes(info.avatar_chunk)\n        except grpc.RpcError as e:\n            logging.debug(\"Remote RPC: could not fetch remote avatar, using a generic one. (%s, %s)\" % (e.code(), e.details()))\n\n        self.get_avatar_surface(loader)\n\n    @util._idle\n    def get_avatar_surface(self, loader=None):\n        # This needs to be on the main loop, or else we get an x error\n        if loader:\n            self.avatar_surface = loader.get_surface()\n        else:\n            self.avatar_surface = None\n\n        self.emit_machine_info_changed()\n\n    # Run in thread pool\n    def send_transfer_op_request(self, op):\n        if not self.stub: # short circuit for testing widgets\n            return\n\n        logging.debug(\"Remote RPC: calling TransferOpRequest on '%s'\" % (self.display_hostname))\n\n        transfer_op = warp_pb2.TransferOpRequest(\n            info=warp_pb2.OpInfo(\n                ident=op.sender,\n                timestamp=op.start_time,\n                readable_name=util.get_hostname(),\n                use_compression=prefs.use_compression(),\n            ),\n            sender_name=op.sender_name,\n            receiver=self.ident,\n            size=op.total_size,\n            count=op.total_count,\n            name_if_single=op.description,\n            mime_if_single=op.mime_if_single,\n            top_dir_basenames=op.top_dir_basenames\n        )\n\n        self.stub.ProcessTransferOpRequest(transfer_op)\n\n    # Run in thread pool\n    def cancel_transfer_op_request(self, op, by_sender=False):\n        logging.debug(\"Remote RPC: calling CancelTransferOpRequest on '%s'\" % (self.display_hostname))\n\n        if op.direction == TransferDirection.TO_REMOTE_MACHINE:\n            name = op.sender\n        else:\n            name = self.local_ident\n        self.stub.CancelTransferOpRequest(\n            warp_pb2.OpInfo(\n                timestamp=op.start_time,\n                ident=name,\n                readable_name=util.get_hostname()\n            )\n        )\n        op.set_status(OpStatus.CANCELLED_PERMISSION_BY_SENDER if by_sender else OpStatus.CANCELLED_PERMISSION_BY_RECEIVER)\n\n    # Run in thread pool\n    def start_transfer_op(self, op):\n        logging.debug(\"Remote RPC: calling StartTransfer on '%s'\" % (self.display_hostname))\n\n        start_time = GLib.get_monotonic_time()\n\n        op.progress_tracker = transfers.OpProgressTracker(op)\n        op.current_progress_report = None\n        receiver = transfers.FileReceiver(op)\n        op.set_status(OpStatus.TRANSFERRING)\n\n        # This is ugly because StartTransfer only returns file_iterator. The\n        # interceptor returns the cancellable with it, because file_iterator\n        # is not a future if compression is active, it's just a generator.\n        op.file_iterator = self.stub.StartTransfer(\n            warp_pb2.OpInfo(\n                timestamp=op.start_time,\n                ident=self.local_ident,\n                readable_name=util.get_hostname(),\n                use_compression=op.use_compression and prefs.use_compression()\n            )\n        )\n\n        def report_receive_error(error):\n            op.file_iterator = None\n\n            # Get rid of any toplevel file/folder if the transfer stops prematurely,\n            # so it or its children \n            receiver.clean_current_top_dir_file()\n\n            if error is None:\n                return\n\n            op.set_error(error)\n\n            try:\n                # If we leave an io stream open, it locks the location.  For instance,\n                # if this was a mounted location, we wouldn't be able to terminate until\n                # we closed warp.\n                if receiver.current_stream is not None:\n                    receiver.current_stream.close()\n            except GLib.Error:\n                pass\n\n            logging.critical(\"An error occurred receiving data from %s: %s\" % (op.sender, op.error_msg))\n            op.set_status(OpStatus.FAILED)\n            op.stop_transfer()\n\n        try:\n            receiver.clean_existing_files()\n\n            for data in op.file_iterator:\n                receiver.receive_data(data)\n\n            op.file_iterator = None\n            receiver.receive_finished()\n\n            logging.debug(\"Remote: receipt of %s files (%s) finished in %s\" % \\\n                          (op.total_count, GLib.format_size(op.total_size),\\\n                           util.precise_format_time_span(GLib.get_monotonic_time() - start_time)))\n\n            if op.remaining_count > 0:\n                raise ReceiveError(\"Transfer completed, but the number of files received is less than the original request size (expected %d, received %d)\"\n                                       % (op.total_count, op.total_count - receiver.remaining_count),\n                                   fatal=False)\n            op.set_status(OpStatus.FINISHED)\n        except grpc.RpcError as e:\n            if e.code() == grpc.StatusCode.CANCELLED:\n                report_receive_error(None)\n            else:\n                report_receive_error(e)\n        except ReceiveError as e:\n            if e.fatal:\n                report_receive_error(e)\n            else:\n                logging.critical(str(e))\n                op.set_error(e)\n                op.set_status(OpStatus.FINISHED_WARNING)\n        except Exception as e:\n            report_receive_error(e)\n\n    # Run in thread pool\n    def stop_transfer_op(self, op, by_sender=False, lost_connection=False):\n        logging.debug(\"Remote RPC: Calling StopTransfer on '%s'\" % (self.display_hostname))\n\n        if op.direction == TransferDirection.TO_REMOTE_MACHINE:\n            name = op.sender\n        else:\n            name = self.local_ident\n\n        if by_sender:\n            op.file_send_cancellable.set()\n            # If we stopped due to connection error, we don't want the message to be 'stopped by xx',\n            # but just failed.\n            if not lost_connection:\n                logging.debug(\"Remote: stop transfer initiated by sender\")\n                if op.error_msg == \"\":\n                    op.set_status(OpStatus.STOPPED_BY_SENDER)\n                else:\n                    op.set_status(OpStatus.FAILED)\n        else:\n            if op.file_iterator:\n                op.file_iterator.cancel()\n            if not lost_connection:\n                logging.debug(\"Remote: stop transfer initiated by receiver\")\n                if op.error_msg == \"\":\n                    op.set_status(OpStatus.STOPPED_BY_RECEIVER)\n                else:\n                    op.set_status(OpStatus.FAILED)\n\n        if not lost_connection:\n            # We don't need to send this if it's a connection loss, the other end will handle\n            # its own cleanup.\n            opinfo = warp_pb2.OpInfo(\n                timestamp=op.start_time,\n                ident=name,\n                readable_name=util.get_hostname()\n            )\n            self.stub.StopTransfer(warp_pb2.StopInfo(info=opinfo, error=op.error_msg != \"\"))\n\n    # Op handling (run in thread pool)\n    def send_files(self, uri_list):\n        def _send_files(uri_list):\n            op = SendOp(\n                self.local_ident,\n                self.ident,\n                self.display_name,\n                uri_list\n            )\n            self.add_op(op)\n            op.prepare_send_info()\n\n        util.add_to_recents_if_single_selection(uri_list)\n        self.rpc_call(_send_files, uri_list)\n\n    @util._idle\n    def add_op(self, op):\n        if op not in self.transfer_ops:\n            self.transfer_ops.append(op)\n            op.connect(\"status-changed\", self.emit_ops_changed)\n            op.connect(\"op-command\", self.op_command_issued)\n            op.connect(\"focus\", self.op_focus)\n            if isinstance(op, SendOp):\n                op.connect(\"initial-setup-complete\", self.notify_remote_machine_of_new_op)\n                self.emit(\"new-outgoing-op\", op)\n            if isinstance(op, ReceiveOp):\n                self.emit(\"new-incoming-op\", op)\n\n        def set_busy():\n            self.busy = True\n\n        op.connect(\"active\", lambda op: set_busy())\n\n        self.emit_ops_changed()\n\n        # For now, only bad base filenames cause this (failed util.test_resolved_path_safety())\n        # We let it get this far so the UI has something to show the user.\n        if op.status == OpStatus.FAILED_UNRECOVERABLE:\n            op.decline_transfer_request()\n            return\n\n        self.check_for_autostart(op)\n\n    @util._idle\n    def notify_remote_machine_of_new_op(self, op):\n        if op.status == OpStatus.WAITING_PERMISSION:\n            if op.direction == TransferDirection.TO_REMOTE_MACHINE:\n                self.rpc_call(self.send_transfer_op_request, op)\n\n    @util._idle\n    def check_for_autostart(self, op):\n        if op.status == OpStatus.WAITING_PERMISSION:\n            if isinstance(op, ReceiveOp) and \\\n              op.have_space and \\\n              (not (op.existing and prefs.prevent_overwriting())) and \\\n              (not prefs.require_permission_for_transfer()):\n                op.accept_transfer()\n\n    def remove_op(self, op):\n        self.transfer_ops.remove(op)\n        self.emit_ops_changed()\n\n    @util._idle\n    def emit_ops_changed(self, op=None):\n        self.emit(\"ops-changed\")\n\n    def cancel_ops_if_offline(self):\n        if self.status in (RemoteStatus.OFFLINE, RemoteStatus.UNREACHABLE):\n            for op in self.transfer_ops:\n                if op.status == OpStatus.TRANSFERRING:\n                    op.error_msg = _(\"Connection has been lost\")\n                    self.rpc_call(self.stop_transfer_op, op, isinstance(op, SendOp), lost_connection=True)\n                    op.set_status(OpStatus.FAILED)\n                elif op.status in (OpStatus.WAITING_PERMISSION, OpStatus.CALCULATING, OpStatus.PAUSED):\n                    op.error_msg = _(\"Connection has been lost\")\n                    op.set_status(OpStatus.FAILED_UNRECOVERABLE)\n\n    @util._idle\n    def op_command_issued(self, op, command):\n        # send\n        if command == OpCommand.CANCEL_PERMISSION_BY_SENDER:\n            self.rpc_call(self.cancel_transfer_op_request, op, by_sender=True)\n        # elif command == OpCommand.PAUSE_TRANSFER:\n            # self.rpc_call(self.pause_transfer_op, op)\n        elif command == OpCommand.STOP_TRANSFER_BY_SENDER:\n            self.rpc_call(self.stop_transfer_op, op, by_sender=True)\n        elif command == OpCommand.RETRY_TRANSFER:\n            op.set_status(OpStatus.WAITING_PERMISSION)\n            self.rpc_call(self.send_transfer_op_request, op)\n        elif command == OpCommand.REMOVE_TRANSFER:\n            self.remove_op(op)\n        # receive\n        elif command == OpCommand.START_TRANSFER:\n            self.rpc_call(self.start_transfer_op, op)\n        elif command == OpCommand.CANCEL_PERMISSION_BY_RECEIVER:\n            self.rpc_call(self.cancel_transfer_op_request, op, by_sender=False)\n        elif command == OpCommand.STOP_TRANSFER_BY_RECEIVER:\n            self.rpc_call(self.stop_transfer_op, op, by_sender=False)\n\n    @util._idle\n    def op_focus(self, op):\n        self.emit(\"focus-remote\")\n\n    def lookup_op(self, timestamp):\n        for op in self.transfer_ops:\n            if op.start_time == timestamp:\n                return op", "target": 0}]}, {"raw_url": "https://github.com/linuxmint/warpinator/raw/9aae768522b7bbb09c836419893802a02221d663/src%2Ftransfers.py", "code": "#!/usr/bin/python3\n\nimport os\nimport logging\nimport stat\nimport shutil\nimport gettext\nfrom pathlib import Path\n\nfrom gi.repository import GLib, Gio, GObject\n\nimport util\nfrom util import FileType, ReceiveError\nimport prefs\nimport warp_pb2\n\n_ = gettext.gettext\n\nFILE_INFOS = \",\".join([\n    \"standard::size\",\n    \"standard::allocated-size\",\n    \"standard::name\",\n    \"standard::type\",\n    \"standard::symlink-target\",\n    \"time::modified\",\n    \"time::modified-usec\",\n    \"unix::mode\"\n])\n\nFILE_INFOS_SINGLE_FILE = \",\".join([\n    \"standard::size\",\n    \"standard::allocated-size\",\n    \"standard::name\",\n    \"standard::type\",\n    \"standard::symlink-target\",\n    \"standard::content-type\",\n    \"time::modified\",\n    \"time::modified-usec\",\n    \"unix::mode\"\n])\n\nMODE_MASK = (stat.S_IRWXU | stat.S_IRWXG | stat.S_IRWXO)\n\nPROGRESS_UPDATE_FREQ = 2 * 1000 * 1000\n\ndef load_file_in_chunks(path):\n    gfile = Gio.File.new_for_path(path)\n\n    try:\n        stream = gfile.read(None)\n    except GLib.Error:\n        return\n\n    while True:\n        bytes = stream.read_bytes(1024 * 1024, None)\n        if bytes.get_size() == 0:\n            break\n\n        response = warp_pb2.RemoteMachineAvatar(avatar_chunk=bytes.get_data())\n        yield response\n\n    stream.close()\n\ndef make_symbolic_link(op, path, target):\n    tmppath = os.path.join(os.path.dirname(path), \"%s-%d-%d.tmp\" % (op.sender, op.start_time, GLib.get_monotonic_time()))\n    tmpfile = Gio.File.new_for_path(tmppath)\n\n    tmpfile.make_symbolic_link(target, None)\n    os.replace(tmpfile.get_path(), path)\n\n# This represents a file to be transferred (this is used by the sender)\nclass File:\n    def __init__(self, uri, basename, rel_path, size, file_type, symlink_target=None, file_mode=0, mtime=0, mtime_usec=0):\n        self.uri = uri\n        self.basename = basename\n        self.relative_path = rel_path\n        self.size = size\n        self.file_type = file_type\n        self.symlink_target = symlink_target\n        self.file_mode = file_mode\n        self.mtime = mtime\n        self.mtime_usec = mtime_usec\n\nclass FileSender(GObject.Object):\n    def __init__(self, op, timestamp, cancellable):\n        super(FileSender, self).__init__()\n        self.op = op\n        self.timestamp = timestamp\n        self.cancellable = cancellable\n        self.block_size = prefs.get_block_size()\n\n        self.error = None\n\n    def read_chunks(self):\n        for file in self.op.resolved_files:\n            if self.cancellable.is_set():\n                return # StopIteration as different behaviors between 3.5 and 3.7, this works as well.\n\n            logging.debug(\"get mtime: %lu.%u -- %s\" % (file.mtime, file.mtime_usec, file.relative_path))\n\n            ftime = warp_pb2.FileTime(mtime=file.mtime,\n                                      mtime_usec = file.mtime_usec)\n            if file.file_type == FileType.DIRECTORY:\n                yield warp_pb2.FileChunk(relative_path=file.relative_path,\n                                         file_type=file.file_type,\n                                         file_mode=file.file_mode,\n                                         time=ftime)\n            elif file.file_type == FileType.SYMBOLIC_LINK:\n                yield warp_pb2.FileChunk(relative_path=file.relative_path,\n                                         file_type=file.file_type,\n                                         symlink_target=file.symlink_target,\n                                         file_mode=file.file_mode,\n                                         time=ftime)\n            else:\n                stream = None\n\n                try:\n                    gfile = Gio.File.new_for_uri(file.uri)\n                    stream = gfile.read(None)\n\n                    file_done = False\n                    first_chunk = True\n\n                    while True:\n                        if file_done:\n                            break\n\n                        if self.cancellable.is_set():\n                            return\n\n                        b = stream.read_bytes(self.block_size, None)\n\n                        last_size_read = b.get_size()\n                        if last_size_read < self.block_size:\n                            file_done = True\n\n                        self.op.progress_tracker.update_progress(last_size_read)\n\n                        if first_chunk:\n                            time = ftime\n                            first_chunk = False\n                        else:\n                            time = None\n\n                        yield warp_pb2.FileChunk(relative_path=file.relative_path,\n                                                 file_type=file.file_type,\n                                                 chunk=b.get_data(),\n                                                 file_mode=file.file_mode,\n                                                 time=time)\n\n                    stream.close()\n                    continue\n                except Exception as e:\n                    try:\n                        # If we leave an io stream open, it locks the location.  For instance,\n                        # if this was a mounted location, we wouldn't be able to terminate until\n                        # we closed warp.\n                        stream.close()\n                    except:\n                        pass\n\n                    self.error = e\n                    return\n\n        self.op.progress_tracker.finished()\n\nclass FileReceiver(GObject.Object):\n    def __init__(self, op):\n        super(FileReceiver, self).__init__()\n        self.save_path = prefs.get_save_path()\n        self.op = op\n        self.preserve_perms = prefs.preserve_permissions() and util.save_folder_is_native_fs()\n        self.preserve_timestamp = prefs.preserve_timestamp() and util.save_folder_is_native_fs()\n\n        self.current_path = None\n        self.current_gfile = None\n        self.current_type = None\n        self.current_stream = None\n        self.current_mode = 0\n        self.current_mtime = 0\n        self.current_mtime_usec = 0\n\n        # We write files top-down.  If we're preserving permissions and we receive\n        # a folder in some hierarchy that is not writable, we won't be able to create\n        # anything inside it.\n        self.folder_permission_change_list = []\n\n    def clean_existing_files(self):\n        logging.debug(\"Removing any existing files matching the pending transfer\")\n        for name in self.op.top_dir_basenames:\n            path = Path(os.path.join(self.save_path, name))\n            self.rm_any(path)\n\n    def clean_current_top_dir_file(self):\n        if self.current_path is not None:\n            current = Path(self.current_path)\n            save = Path(self.save_path)\n\n            try:\n                relative = current.relative_to(save)\n                util.test_resolved_path_safety(relative.as_posix())\n            except (ValueError, ReceiveError) as e:\n                logging.critical(\"Partial file or directory from aborted transfer is invalid: %s\" % str(e))\n                return\n\n            abs_top_dir = save.joinpath(relative.parts[0])\n            logging.debug(\"Removing partial file or directory: %s\" % abs_top_dir)\n\n            self.rm_any(abs_top_dir)\n\n    def rm_any(self, path):\n        try:\n            try:\n                os.remove(path)\n            except IsADirectoryError:\n                shutil.rmtree(path)\n        except FileNotFoundError:\n            pass\n        except Exception as e:\n            logging.warning(\"Problem removing existing files: %s\" % e)\n\n    def receive_data(self, s):\n        path = os.path.join(self.save_path, s.relative_path)\n        if path != self.current_path:\n            self.close_current_file()\n            self.current_path = path\n            self.current_mode = s.file_mode\n            self.current_type = s.file_type\n            self.current_mtime = s.time.mtime\n            self.current_mtime_usec = s.time.mtime_usec\n            if not s.relative_path.startswith(tuple(self.op.top_dir_basenames)):\n                raise ReceiveError(\"File path is not descended from a valid toplevel directory: %s\" % s.relative_path)\n            if self.op.remaining_count == 0:\n                raise ReceiveError(\"File count exceeds original request size\")\n\n        if not self.current_gfile:\n            util.test_resolved_path_safety(s.relative_path)\n            self.current_gfile = Gio.File.new_for_path(path)\n\n        if s.file_type == FileType.DIRECTORY:\n            os.makedirs(path, exist_ok=True)\n        elif s.file_type == FileType.SYMBOLIC_LINK:\n            make_symbolic_link(self.op, path, s.symlink_target)\n        else:\n            if self.current_stream is None:\n                self.current_stream = self.current_gfile.create(Gio.FileCreateFlags.NONE, None)\n\n            if not s.chunk:\n                return\n\n            self.current_stream.write_bytes(GLib.Bytes(s.chunk), None)\n            self.op.progress_tracker.update_progress(len(s.chunk))\n\n    def close_current_file(self):\n        if self.current_gfile is None:\n            # First block received we self.close_current_file() with an empty path.\n            return\n\n        if self.current_stream:\n            self.current_stream.close()\n            self.current_stream = None\n\n        # set_attributes and os.chmod don't support operating on symlinks directly.\n\n        if self.preserve_timestamp and self.current_mtime > 0 and self.current_type != FileType.SYMBOLIC_LINK:\n            logging.debug(\"Restoring mtime: %s --> %lu.%u\" \\\n                % (self.current_path, self.current_mtime, self.current_mtime_usec))\n\n            info = Gio.FileInfo.new()\n            info.set_attribute_uint64(Gio.FILE_ATTRIBUTE_TIME_MODIFIED, self.current_mtime)\n            info.set_attribute_uint32(Gio.FILE_ATTRIBUTE_TIME_MODIFIED_USEC, self.current_mtime_usec)\n            try:\n                self.current_gfile.set_attributes_from_info(info, Gio.FileQueryInfoFlags.NONE, None)\n            except GLib.Error as e:\n                logging.warning(\"Unable to restore original mtime to '%s': %s\" % (self.current_path, e.message))\n\n        # Only restore permissions on normal files here.\n        # Folder permissions are set in reverse order at the end of the op,\n        if self.preserve_perms and self.current_mode > 0 and self.current_type != FileType.SYMBOLIC_LINK:\n            try:\n                if self.current_type == FileType.REGULAR:\n                    logging.debug(\"Restoring permissions: %s --> %s\" % (self.current_path, self.current_mode))\n                    os.chmod(self.current_path, mode=self.current_mode)\n                else:\n                    self.folder_permission_change_list.append((self.current_path, self.current_mode))\n            except Exception as e:\n                logging.warning(\"Unable to restore original permissions to '%s': %s\" % (self.current_path, str(e)))\n\n        self.current_mtime = 0\n        self.current_mtime_usec = 0\n        self.current_type = None\n        self.current_mode = 0\n        self.current_path = None\n        self.current_gfile = None\n        self.op.remaining_count -= 1\n\n    def apply_folder_permissions(self):\n        if self.preserve_perms:\n            while self.folder_permission_change_list:\n                # We added folders from parent->children, this will apply permissions\n                # from child to parent.\n                path, mode = self.folder_permission_change_list.pop()\n                try:\n                    logging.debug(\"Restoring folder permissions: %s --> %s\" % (path, mode))\n                    os.chmod(path, mode)\n                except Exception as e:\n                    logging.warning(\"Unable to restore original permissions to folder '%s': %s\" % (self.current_path, str(e)))\n\n    def receive_finished(self):\n        # We left the last (or only) file open\n        self.close_current_file()\n        self.apply_folder_permissions()\n        self.op.progress_tracker.finished()\n\n\ndef add_file(op, basename, uri, base_uri, info):\n    symlink_target = None\n\n    # Normal files usually take more disk space than their actual size, so we want that\n    # for checking free disk space on the target computer.  However, sparse files can\n    # report a smaller allocated size on disk than their 'actual' size. For now we can\n    # only copy files in their full state, and at the other end they'll no longer be\n    # sparse, so we use the largest of the two sizes for our purposes.\n    alloc_size = info.get_attribute_uint64(Gio.FILE_ATTRIBUTE_STANDARD_ALLOCATED_SIZE)\n    file_size = info.get_size()\n    size = file_size if file_size > alloc_size else alloc_size\n\n    file_type = info.get_file_type()\n\n    if file_type == FileType.SYMBOLIC_LINK:\n        symlink_target = info.get_symlink_target()\n\n    st_mode = info.get_attribute_uint32(\"unix::mode\")\n    file_mode = (st_mode & MODE_MASK) if (st_mode > 0) else 0\n\n    if base_uri:\n        relative_path = util.relpath_from_uri(uri, base_uri)\n    else:\n        relative_path = basename\n\n    mtime = info.get_attribute_uint64(Gio.FILE_ATTRIBUTE_TIME_MODIFIED)\n    mtime_usec = info.get_attribute_uint32(Gio.FILE_ATTRIBUTE_TIME_MODIFIED_USEC)\n\n    file = File(uri, basename, relative_path, size, file_type, symlink_target, file_mode, mtime, mtime_usec)\n\n    op.resolved_files.append(file)\n    op.total_size += size\n    op.total_count += 1\n\ndef gather_file_info(op):\n        top_dir_basenames = []\n        uri_list = op.uris\n\n        error = None\n\n        if len(uri_list) == 1:\n            infos = FILE_INFOS_SINGLE_FILE\n        else:\n            infos = FILE_INFOS\n\n        # Recursive function for processing folders and their contents.\n        def process_folder(folder_uri, top_dir):\n            folder_file = Gio.File.new_for_uri(folder_uri)\n\n            enumerator = folder_file.enumerate_children(infos,\n                                                        Gio.FileQueryInfoFlags.NOFOLLOW_SYMLINKS,\n                                                        None)\n            info = enumerator.next_file(None)\n\n            while info:\n                child = enumerator.get_child(info)\n                child_uri = child.get_uri()\n                child_basename = child.get_basename()\n\n                file_type = info.get_file_type()\n\n                if file_type == FileType.DIRECTORY:\n                    add_file(op, child_basename, child_uri, top_dir, info)\n                    process_folder(child_uri, top_dir)\n                else:\n                    add_file(op, child_basename, child_uri, top_dir, info)\n\n                info = enumerator.next_file(None)\n\n        # Process the initial list.\n        try:\n            for uri in uri_list:\n                file = Gio.File.new_for_uri(uri)\n                top_dir_basenames.append(file.get_basename())\n\n                info = file.query_info(infos, Gio.FileQueryInfoFlags.NOFOLLOW_SYMLINKS, None)\n                basename = file.get_basename()\n                if len(uri_list) == 1:\n                    op.mime_if_single = info.get_content_type()\n\n                if info and info.get_file_type() == FileType.DIRECTORY:\n                    top_dir = file.get_parent().get_uri()\n                    add_file(op, basename, uri, None, info)\n                    process_folder(uri, top_dir)\n                    continue\n                else:\n                    add_file(op, basename, uri, None, info)\n            op.top_dir_basenames = top_dir_basenames\n        except Exception as e:\n            error = e\n\n        return error\n\nclass Progress():\n    def __init__(self, progress, time_left_sec, bytes_per_sec):\n        self.progress = progress\n        self.time_left_sec = time_left_sec\n        self.bytes_per_sec = bytes_per_sec\n        self.progress_text = \"\"\n\nclass OpProgressTracker():\n    def __init__(self, op):\n        self.op = op\n        self.total_size = op.total_size\n        self.total_transferred = 0\n        self.transfer_start_time = GLib.get_monotonic_time()\n        self.last_update_time = self.transfer_start_time\n\n    @util._idle\n    def update_progress(self, size_read):\n        self.total_transferred += size_read\n\n        now = GLib.get_monotonic_time()\n\n        if ((now - self.last_update_time) > PROGRESS_UPDATE_FREQ):\n            self.last_update_time = now\n\n            progress = self.total_transferred / self.total_size\n            elapsed = now - self.transfer_start_time\n\n            bytes_per_micro = self.total_transferred / elapsed\n            bytes_per_sec = int(bytes_per_micro * 1000 * 1000)\n\n            if bytes_per_sec == 0:\n                bytes_per_sec = 1 # no a/0\n\n            time_left_sec = (self.total_size - self.total_transferred) / bytes_per_sec\n\n            logging.debug(\"Progress: %s time left, %s/s\" % (util.format_time_span(time_left_sec), GLib.format_size(bytes_per_sec)))\n\n            progress_report = Progress(progress, time_left_sec, bytes_per_sec)\n            self.op.progress_report(progress_report)\n\n    def finished(self):\n        self.op.progress_report(Progress(1.0, 0, 0))\n", "code_before": "#!/usr/bin/python3\n\nimport os\nimport logging\nimport stat\nimport shutil\nimport gettext\nfrom pathlib import Path\n\nfrom gi.repository import GLib, Gio, GObject\n\nimport util\nfrom util import FileType, ReceiveError\nimport prefs\nimport warp_pb2\n\n_ = gettext.gettext\n\nFILE_INFOS = \",\".join([\n    \"standard::size\",\n    \"standard::allocated-size\",\n    \"standard::name\",\n    \"standard::type\",\n    \"standard::symlink-target\",\n    \"time::modified\",\n    \"time::modified-usec\",\n    \"unix::mode\"\n])\n\nFILE_INFOS_SINGLE_FILE = \",\".join([\n    \"standard::size\",\n    \"standard::allocated-size\",\n    \"standard::name\",\n    \"standard::type\",\n    \"standard::symlink-target\",\n    \"standard::content-type\",\n    \"time::modified\",\n    \"time::modified-usec\",\n    \"unix::mode\"\n])\n\nMODE_MASK = (stat.S_IRWXU | stat.S_IRWXG | stat.S_IRWXO)\n\nPROGRESS_UPDATE_FREQ = 2 * 1000 * 1000\n\ndef load_file_in_chunks(path):\n    gfile = Gio.File.new_for_path(path)\n\n    try:\n        stream = gfile.read(None)\n    except GLib.Error:\n        return\n\n    while True:\n        bytes = stream.read_bytes(1024 * 1024, None)\n        if bytes.get_size() == 0:\n            break\n\n        response = warp_pb2.RemoteMachineAvatar(avatar_chunk=bytes.get_data())\n        yield response\n\n    stream.close()\n\ndef make_symbolic_link(op, path, target):\n    tmppath = os.path.join(os.path.dirname(path), \"%s-%d-%d.tmp\" % (op.sender, op.start_time, GLib.get_monotonic_time()))\n    tmpfile = Gio.File.new_for_path(tmppath)\n\n    tmpfile.make_symbolic_link(target, None)\n    os.replace(tmpfile.get_path(), path)\n\n# This represents a file to be transferred (this is used by the sender)\nclass File:\n    def __init__(self, uri, basename, rel_path, size, file_type, symlink_target=None, file_mode=0, mtime=0, mtime_usec=0):\n        self.uri = uri\n        self.basename = basename\n        self.relative_path = rel_path\n        self.size = size\n        self.file_type = file_type\n        self.symlink_target = symlink_target\n        self.file_mode = file_mode\n        self.mtime = mtime\n        self.mtime_usec = mtime_usec\n\nclass FileSender(GObject.Object):\n    def __init__(self, op, timestamp, cancellable):\n        super(FileSender, self).__init__()\n        self.op = op\n        self.timestamp = timestamp\n        self.cancellable = cancellable\n        self.block_size = prefs.get_block_size()\n\n        self.error = None\n\n    def read_chunks(self):\n        for file in self.op.resolved_files:\n            if self.cancellable.is_set():\n                return # StopIteration as different behaviors between 3.5 and 3.7, this works as well.\n\n            logging.debug(\"get mtime: %lu.%u -- %s\" % (file.mtime, file.mtime_usec, file.relative_path))\n\n            ftime = warp_pb2.FileTime(mtime=file.mtime,\n                                      mtime_usec = file.mtime_usec)\n            if file.file_type == FileType.DIRECTORY:\n                yield warp_pb2.FileChunk(relative_path=file.relative_path,\n                                         file_type=file.file_type,\n                                         file_mode=file.file_mode,\n                                         time=ftime)\n            elif file.file_type == FileType.SYMBOLIC_LINK:\n                yield warp_pb2.FileChunk(relative_path=file.relative_path,\n                                         file_type=file.file_type,\n                                         symlink_target=file.symlink_target,\n                                         file_mode=file.file_mode,\n                                         time=ftime)\n            else:\n                stream = None\n\n                try:\n                    gfile = Gio.File.new_for_uri(file.uri)\n                    stream = gfile.read(None)\n\n                    file_done = False\n                    first_chunk = True\n\n                    while True:\n                        if file_done:\n                            break\n\n                        if self.cancellable.is_set():\n                            return\n\n                        b = stream.read_bytes(self.block_size, None)\n\n                        last_size_read = b.get_size()\n                        if last_size_read < self.block_size:\n                            file_done = True\n\n                        self.op.progress_tracker.update_progress(last_size_read)\n\n                        if first_chunk:\n                            time = ftime\n                            first_chunk = False\n                        else:\n                            time = None\n\n                        yield warp_pb2.FileChunk(relative_path=file.relative_path,\n                                                 file_type=file.file_type,\n                                                 chunk=b.get_data(),\n                                                 file_mode=file.file_mode,\n                                                 time=time)\n\n                    stream.close()\n                    continue\n                except Exception as e:\n                    try:\n                        # If we leave an io stream open, it locks the location.  For instance,\n                        # if this was a mounted location, we wouldn't be able to terminate until\n                        # we closed warp.\n                        stream.close()\n                    except:\n                        pass\n\n                    self.error = e\n                    return\n\n        self.op.progress_tracker.finished()\n\nclass FileReceiver(GObject.Object):\n    def __init__(self, op):\n        super(FileReceiver, self).__init__()\n        self.save_path = prefs.get_save_path()\n        self.save_path_obj = Path(self.save_path).resolve()\n        self.op = op\n        self.preserve_perms = prefs.preserve_permissions() and util.save_folder_is_native_fs()\n        self.preserve_timestamp = prefs.preserve_timestamp() and util.save_folder_is_native_fs()\n\n        self.current_path = None\n        self.current_gfile = None\n        self.current_type = None\n        self.current_stream = None\n        self.current_mode = 0\n        self.current_mtime = 0\n        self.current_mtime_usec = 0\n\n\n        for name in op.top_dir_basenames:\n            try:\n                path = os.path.join(self.save_path, name)\n                if os.path.isdir(path): # file not found is ok\n                    shutil.rmtree(path)\n                else:\n                    os.remove(path)\n            except FileNotFoundError:\n                pass\n            except Exception as e:\n                logging.warning(\"Problem removing existing files.  Transfer may not succeed: %s\" % e)\n\n        # We write files top-down.  If we're preserving permissions and we receive\n        # a folder in some hierarchy that is not writable, we won't be able to create\n        # anything inside it.\n        self.folder_permission_change_list = []\n\n    def receive_data(self, s):\n        save_path = prefs.get_save_path()\n\n        path = os.path.join(save_path, s.relative_path)\n        if path != self.current_path:\n            self.close_current_file()\n            self.current_path = path\n            self.current_mode = s.file_mode\n            self.current_type = s.file_type\n            self.current_mtime = s.time.mtime\n            self.current_mtime_usec = s.time.mtime_usec\n        if self.remaining_files == 0:\n            raise Exception(_(\"File count exceeds original request size\"))\n            if self.op.remaining_count == 0:\n                raise ReceiveError(\"File count exceeds original request size\")\n\n        if not self.current_gfile:\n            # Check for valid path (pathlib.Path resolves both relative and symbolically-linked paths)\n            test_path = Path(path).resolve()\n            try:\n                test_path.relative_to(self.save_path_obj)\n            except ValueError:\n                raise ReceiveError(_(\"Resolved path is not valid: %s -> %s\") % (path, str(test_path)), fatal=True)\n\n            self.current_gfile = Gio.File.new_for_path(path)\n\n        if s.file_type == FileType.DIRECTORY:\n            os.makedirs(path, exist_ok=True)\n        elif s.file_type == FileType.SYMBOLIC_LINK:\n            make_symbolic_link(self.op, path, s.symlink_target)\n        else:\n            if self.current_stream is None:\n                self.current_stream = self.current_gfile.create(Gio.FileCreateFlags.NONE, None)\n\n            if not s.chunk:\n                return\n\n            self.current_stream.write_bytes(GLib.Bytes(s.chunk), None)\n            self.op.progress_tracker.update_progress(len(s.chunk))\n\n    def close_current_file(self):\n        if self.current_gfile is None:\n            # First block received we self.close_current_file() with an empty path.\n            return\n\n        if self.current_stream:\n            self.current_stream.close()\n            self.current_stream = None\n\n        # set_attributes and os.chmod don't support operating on symlinks directly.\n\n        if self.preserve_timestamp and self.current_mtime > 0 and self.current_type != FileType.SYMBOLIC_LINK:\n            logging.debug(\"Restoring mtime: %s --> %lu.%u\" \\\n                % (self.current_path, self.current_mtime, self.current_mtime_usec))\n\n            info = Gio.FileInfo.new()\n            info.set_attribute_uint64(Gio.FILE_ATTRIBUTE_TIME_MODIFIED, self.current_mtime)\n            info.set_attribute_uint32(Gio.FILE_ATTRIBUTE_TIME_MODIFIED_USEC, self.current_mtime_usec)\n            try:\n                self.current_gfile.set_attributes_from_info(info, Gio.FileQueryInfoFlags.NONE, None)\n            except GLib.Error as e:\n                logging.warning(\"Unable to restore original mtime to '%s': %s\" % (self.current_path, e.message))\n\n        # Only restore permissions on normal files here.\n        # Folder permissions are set in reverse order at the end of the op,\n        if self.preserve_perms and self.current_mode > 0 and self.current_type != FileType.SYMBOLIC_LINK:\n            try:\n                if self.current_type == FileType.REGULAR:\n                    logging.debug(\"Restoring permissions: %s --> %s\" % (self.current_path, self.current_mode))\n                    os.chmod(self.current_path, mode=self.current_mode)\n                else:\n                    self.folder_permission_change_list.append((self.current_path, self.current_mode))\n            except Exception as e:\n                logging.warning(\"Unable to restore original permissions to '%s': %s\" % (self.current_path, str(e)))\n\n        self.current_mtime = 0\n        self.current_mtime_usec = 0\n        self.current_type = None\n        self.current_mode = 0\n        self.current_path = None\n        self.current_gfile = None\n        self.op.remaining_count -= 1\n\n    def apply_folder_permissions(self):\n        if self.preserve_perms:\n            while self.folder_permission_change_list:\n                # We added folders from parent->children, this will apply permissions\n                # from child to parent.\n                path, mode = self.folder_permission_change_list.pop()\n                try:\n                    logging.debug(\"Restoring folder permissions: %s --> %s\" % (path, mode))\n                    os.chmod(path, mode)\n                except Exception as e:\n                    logging.warning(\"Unable to restore original permissions to folder '%s': %s\" % (self.current_path, str(e)))\n\n    def receive_finished(self):\n        # We left the last (or only) file open\n        self.close_current_file()\n        self.apply_folder_permissions()\n        self.op.progress_tracker.finished()\n\n\ndef add_file(op, basename, uri, base_uri, info):\n    symlink_target = None\n\n    # Normal files usually take more disk space than their actual size, so we want that\n    # for checking free disk space on the target computer.  However, sparse files can\n    # report a smaller allocated size on disk than their 'actual' size. For now we can\n    # only copy files in their full state, and at the other end they'll no longer be\n    # sparse, so we use the largest of the two sizes for our purposes.\n    alloc_size = info.get_attribute_uint64(Gio.FILE_ATTRIBUTE_STANDARD_ALLOCATED_SIZE)\n    file_size = info.get_size()\n    size = file_size if file_size > alloc_size else alloc_size\n\n    file_type = info.get_file_type()\n\n    if file_type == FileType.SYMBOLIC_LINK:\n        symlink_target = info.get_symlink_target()\n\n    st_mode = info.get_attribute_uint32(\"unix::mode\")\n    file_mode = (st_mode & MODE_MASK) if (st_mode > 0) else 0\n\n    if base_uri:\n        relative_path = util.relpath_from_uri(uri, base_uri)\n    else:\n        relative_path = basename\n\n    mtime = info.get_attribute_uint64(Gio.FILE_ATTRIBUTE_TIME_MODIFIED)\n    mtime_usec = info.get_attribute_uint32(Gio.FILE_ATTRIBUTE_TIME_MODIFIED_USEC)\n\n    file = File(uri, basename, relative_path, size, file_type, symlink_target, file_mode, mtime, mtime_usec)\n\n    op.resolved_files.append(file)\n    op.total_size += size\n    op.total_count += 1\n\ndef gather_file_info(op):\n        top_dir_basenames = []\n        uri_list = op.uris\n\n        error = None\n\n        if len(uri_list) == 1:\n            infos = FILE_INFOS_SINGLE_FILE\n        else:\n            infos = FILE_INFOS\n\n        # Recursive function for processing folders and their contents.\n        def process_folder(folder_uri, top_dir):\n            folder_file = Gio.File.new_for_uri(folder_uri)\n\n            enumerator = folder_file.enumerate_children(infos,\n                                                        Gio.FileQueryInfoFlags.NOFOLLOW_SYMLINKS,\n                                                        None)\n            info = enumerator.next_file(None)\n\n            while info:\n                child = enumerator.get_child(info)\n                child_uri = child.get_uri()\n                child_basename = child.get_basename()\n\n                file_type = info.get_file_type()\n\n                if file_type == FileType.DIRECTORY:\n                    add_file(op, child_basename, child_uri, top_dir, info)\n                    process_folder(child_uri, top_dir)\n                else:\n                    add_file(op, child_basename, child_uri, top_dir, info)\n\n                info = enumerator.next_file(None)\n\n        # Process the initial list.\n        try:\n            for uri in uri_list:\n                file = Gio.File.new_for_uri(uri)\n                top_dir_basenames.append(file.get_basename())\n\n                info = file.query_info(infos, Gio.FileQueryInfoFlags.NOFOLLOW_SYMLINKS, None)\n                basename = file.get_basename()\n                if len(uri_list) == 1:\n                    op.mime_if_single = info.get_content_type()\n\n                if info and info.get_file_type() == FileType.DIRECTORY:\n                    top_dir = file.get_parent().get_uri()\n                    add_file(op, basename, uri, None, info)\n                    process_folder(uri, top_dir)\n                    continue\n                else:\n                    add_file(op, basename, uri, None, info)\n            op.top_dir_basenames = top_dir_basenames\n        except Exception as e:\n            error = e\n\n        return error\n\nclass Progress():\n    def __init__(self, progress, time_left_sec, bytes_per_sec):\n        self.progress = progress\n        self.time_left_sec = time_left_sec\n        self.bytes_per_sec = bytes_per_sec\n        self.progress_text = \"\"\n\nclass OpProgressTracker():\n    def __init__(self, op):\n        self.op = op\n        self.total_size = op.total_size\n        self.total_transferred = 0\n        self.transfer_start_time = GLib.get_monotonic_time()\n        self.last_update_time = self.transfer_start_time\n\n    @util._idle\n    def update_progress(self, size_read):\n        self.total_transferred += size_read\n\n        now = GLib.get_monotonic_time()\n\n        if ((now - self.last_update_time) > PROGRESS_UPDATE_FREQ):\n            self.last_update_time = now\n\n            progress = self.total_transferred / self.total_size\n            elapsed = now - self.transfer_start_time\n\n            bytes_per_micro = self.total_transferred / elapsed\n            bytes_per_sec = int(bytes_per_micro * 1000 * 1000)\n\n            if bytes_per_sec == 0:\n                bytes_per_sec = 1 # no a/0\n\n            time_left_sec = (self.total_size - self.total_transferred) / bytes_per_sec\n\n            logging.debug(\"Progress: %s time left, %s/s\" % (util.format_time_span(time_left_sec), GLib.format_size(bytes_per_sec)))\n\n            progress_report = Progress(progress, time_left_sec, bytes_per_sec)\n            self.op.progress_report(progress_report)\n\n    def finished(self):\n        self.op.progress_report(Progress(1.0, 0, 0))\n", "patch": "@@ -168,7 +168,6 @@ class FileReceiver(GObject.Object):\n     def __init__(self, op):\n         super(FileReceiver, self).__init__()\n         self.save_path = prefs.get_save_path()\n-        self.save_path_obj = Path(self.save_path).resolve()\n         self.op = op\n         self.preserve_perms = prefs.preserve_permissions() and util.save_folder_is_native_fs()\n         self.preserve_timestamp = prefs.preserve_timestamp() and util.save_folder_is_native_fs()\n@@ -181,48 +180,61 @@ def __init__(self, op):\n         self.current_mtime = 0\n         self.current_mtime_usec = 0\n \n-\n-        for name in op.top_dir_basenames:\n-            try:\n-                path = os.path.join(self.save_path, name)\n-                if os.path.isdir(path): # file not found is ok\n-                    shutil.rmtree(path)\n-                else:\n-                    os.remove(path)\n-            except FileNotFoundError:\n-                pass\n-            except Exception as e:\n-                logging.warning(\"Problem removing existing files.  Transfer may not succeed: %s\" % e)\n-\n         # We write files top-down.  If we're preserving permissions and we receive\n         # a folder in some hierarchy that is not writable, we won't be able to create\n         # anything inside it.\n         self.folder_permission_change_list = []\n \n-    def receive_data(self, s):\n-        save_path = prefs.get_save_path()\n+    def clean_existing_files(self):\n+        logging.debug(\"Removing any existing files matching the pending transfer\")\n+        for name in self.op.top_dir_basenames:\n+            path = Path(os.path.join(self.save_path, name))\n+            self.rm_any(path)\n+\n+    def clean_current_top_dir_file(self):\n+        if self.current_path is not None:\n+            current = Path(self.current_path)\n+            save = Path(self.save_path)\n+\n+            try:\n+                relative = current.relative_to(save)\n+                util.test_resolved_path_safety(relative.as_posix())\n+            except (ValueError, ReceiveError) as e:\n+                logging.critical(\"Partial file or directory from aborted transfer is invalid: %s\" % str(e))\n+                return\n \n-        path = os.path.join(save_path, s.relative_path)\n+            abs_top_dir = save.joinpath(relative.parts[0])\n+            logging.debug(\"Removing partial file or directory: %s\" % abs_top_dir)\n+\n+            self.rm_any(abs_top_dir)\n+\n+    def rm_any(self, path):\n+        try:\n+            try:\n+                os.remove(path)\n+            except IsADirectoryError:\n+                shutil.rmtree(path)\n+        except FileNotFoundError:\n+            pass\n+        except Exception as e:\n+            logging.warning(\"Problem removing existing files: %s\" % e)\n+\n+    def receive_data(self, s):\n+        path = os.path.join(self.save_path, s.relative_path)\n         if path != self.current_path:\n             self.close_current_file()\n             self.current_path = path\n             self.current_mode = s.file_mode\n             self.current_type = s.file_type\n             self.current_mtime = s.time.mtime\n             self.current_mtime_usec = s.time.mtime_usec\n-        if self.remaining_files == 0:\n-            raise Exception(_(\"File count exceeds original request size\"))\n+            if not s.relative_path.startswith(tuple(self.op.top_dir_basenames)):\n+                raise ReceiveError(\"File path is not descended from a valid toplevel directory: %s\" % s.relative_path)\n             if self.op.remaining_count == 0:\n                 raise ReceiveError(\"File count exceeds original request size\")\n \n         if not self.current_gfile:\n-            # Check for valid path (pathlib.Path resolves both relative and symbolically-linked paths)\n-            test_path = Path(path).resolve()\n-            try:\n-                test_path.relative_to(self.save_path_obj)\n-            except ValueError:\n-                raise ReceiveError(_(\"Resolved path is not valid: %s -> %s\") % (path, str(test_path)), fatal=True)\n-\n+            util.test_resolved_path_safety(s.relative_path)\n             self.current_gfile = Gio.File.new_for_path(path)\n \n         if s.file_type == FileType.DIRECTORY:", "file_path": "files/2023_5/152", "file_language": "py", "file_name": "src/transfers.py", "outdated_file_modify": 0, "outdated_file_before": 0, "outdated_file_after": 0, "llm_check": 1, "static_check": 0, "static": {"rats": [false, []], "semgrep": [false, []]}, "target": -1, "function_before": [], "function_after": []}, {"raw_url": "https://github.com/linuxmint/warpinator/raw/9aae768522b7bbb09c836419893802a02221d663/src%2Futil.py", "code": "#!/usr/bin/python3\n\nimport threading\nimport gettext\nimport math\nimport logging\nimport os\nfrom pathlib import Path\nimport queue\nimport sys\nimport socket\nimport time\nimport traceback\nfrom concurrent.futures import ThreadPoolExecutor\n\nfrom gi.repository import GLib, Gtk, Gdk, GObject, GdkPixbuf, Gio\n\nimport prefs\nimport config\n\nif config.using_landlock:\n    import landlock\n\n_ = gettext.gettext\n\n# Not sure what the ideal count is, too few and there will be waits if a lot of\n# transfers are happening.  The server runs on its own thread, and has its own thread\n# pool to service incoming rpcs. Each remote uses one thread for its connection loop,\n# and all remotes share this thread pool for outgoing calls. It could be we may need\n# to limit the number of simultaneous ops in the gui.\n#\n# Both server and remote thread pool sizes can be adjusted in dconf.\nglobal_rpc_threadpool = None\n\n# Initializing in thie function avoids a circular import due to prefs.get_thread_count()\ndef initialize_rpc_threadpool():\n    global global_rpc_threadpool\n\n    if config.using_landlock:\n        import landlock\n        global_rpc_threadpool = NewThreadExecutor()\n    else:\n        global_rpc_threadpool = ThreadPoolExecutor(max_workers=prefs.get_remote_pool_max_threads())\n\nclass NewThreadExecutor():\n    def __init__(self):\n        self.max_workers = prefs.get_remote_pool_max_threads()\n        self.transfer_queue = queue.SimpleQueue()\n\n\n        self._threads_lock = threading.Lock()\n        self._threads = {}\n        self._shutdown_lock = threading.Lock()\n        self._shutdown = False\n        self.counter = 0\n        self._factory_thread_keepalive = threading.Event()\n        self._wait_semaphore = threading.Semaphore(self.max_workers)\n\n        self._factory_thread = threading.Thread(target=self.factory_thread_func, name=\"NewThreadExecutor-factory-thread\")\n        self._factory_thread.start()\n\n    def factory_thread_func(self):\n        while True:\n            if self._factory_thread_keepalive.is_set():\n                break\n\n            if self._wait_semaphore.acquire(timeout=0.5):\n                continue\n\n            if not self.transfer_queue.empty():\n                self.spawn_thread()\n\n    def submit(self, func, *args, **kargs):\n        with self._shutdown_lock:\n            if self._shutdown:\n                raise RuntimeError(\"Cannot start new transfer threads, shutting down.\")\n\n            self.transfer_queue.put((func, args, kargs))\n\n    def spawn_thread(self):\n        self.counter += 1\n\n        tname = \"landlocked-thread-%d\" % self.counter\n        t = threading.Thread(target=self._transfer_landlocked_thread_func, name=tname)\n\n        with self._threads_lock:\n            t.start()\n            self._threads[t.ident] = t\n        return True\n\n    def _transfer_landlocked_thread_func(self):\n        try:\n            opinfo = self.transfer_queue.get_nowait()\n\n            if opinfo[0].__name__ == \"start_transfer_op\":\n                rs = landlock.Ruleset()\n                rs.allow(prefs.get_save_path())\n                rs.apply()\n\n            opinfo[0](*opinfo[1], **opinfo[2])\n        except queue.Empty:\n            pass\n\n        with self._threads_lock:\n            del self._threads[threading.get_ident()]\n\n        self._wait_semaphore.release()\n\n    def shutdown(self, wait=True):\n        with self._shutdown_lock:\n            self._shutdown = True\n\n            for t in self._threads:\n                t.join()\n\n            self._factory_thread_keepalive.set()\n            self._factory_thread.join()\n\nfrom enum import IntEnum\nTransferDirection = IntEnum('TransferDirection', 'TO_REMOTE_MACHINE \\\n                                                  FROM_REMOTE_MACHINE')\n\n# Using Gio enums fails for some unknown reason when collecting file info sometimes.\n# Avoid introspection.\nFileType = IntEnum('FileType', (('REGULAR', Gio.FileType.REGULAR),\n                                ('DIRECTORY', Gio.FileType.DIRECTORY),\n                                ('SYMBOLIC_LINK', Gio.FileType.SYMBOLIC_LINK)))\n\n# Online - all ok\n# Offline - no presence at all\n# Init connecting - we've just discovered you\n# Unreachable - we've either tried and failed after initial discovery, or something went wrong during the session\n\nRemoteStatus = IntEnum('RemoteStatus', 'ONLINE \\\n                                        OFFLINE \\\n                                        INIT_CONNECTING \\\n                                        UNREACHABLE \\\n                                        AWAITING_DUPLEX')\n\nOpStatus = IntEnum('OpStatus', 'INIT \\\n                                CALCULATING \\\n                                WAITING_PERMISSION \\\n                                CANCELLED_PERMISSION_BY_SENDER \\\n                                CANCELLED_PERMISSION_BY_RECEIVER \\\n                                TRANSFERRING \\\n                                PAUSED \\\n                                STOPPED_BY_SENDER \\\n                                STOPPED_BY_RECEIVER \\\n                                FAILED \\\n                                FAILED_UNRECOVERABLE \\\n                                FILE_NOT_FOUND \\\n                                FINISHED \\\n                                FINISHED_WARNING')\n\nOpCommand = IntEnum('OpCommand', 'START_TRANSFER \\\n                                  UPDATE_PROGRESS \\\n                                  CANCEL_PERMISSION_BY_SENDER \\\n                                  CANCEL_PERMISSION_BY_RECEIVER \\\n                                  PAUSE_TRANSFER \\\n                                  RETRY_TRANSFER \\\n                                  STOP_TRANSFER_BY_SENDER \\\n                                  STOP_TRANSFER_BY_RECEIVER \\\n                                  REMOVE_TRANSFER')\n\nclass ReceiveError(Exception):\n    def __init__(self, message, fatal=True):\n        self.fatal = fatal\n        logging.debug(\"ReceiveError: (fatal: %d): %s\" % (self.fatal, message))\n        super().__init__(message)\n\nclass InterfaceInfo():\n    def __init__(self, ip4, ip6, iface=None):\n        self.iface = iface\n        # netifaces AF_INET and AF_INET6 dicts\n        self.ip4 = ip4\n        self.ip4_address = self.ip4[\"addr\"]\n\n        try:\n            self.ip6 = ip6\n            self.ip6_address = self.ip6[\"addr\"]\n        except:\n            self.ip6 = None\n            self.ip6_address = None\n\n    def __eq__(self, other):\n        if other is None:\n            return False\n\n        return self.ip4_address == other.ip4_address\n\n    def as_binary_list(self):\n        blist = []\n\n        if self.ip4:\n            try:\n                blist.append(socket.inet_pton(GLib.SYSDEF_AF_INET, self.ip4_address))\n            except:\n                pass\n        if self.ip6:\n            try:\n                blist.append(socket.inet_pton(GLib.SYSDEF_AF_INET6, self.ip6_address))\n            except:\n                pass\n\n        return blist\n\nclass RemoteInterfaceInfo():\n    def __init__(self, blist):\n        ip4 = None\n        ip6 = None\n\n        for item in blist:\n            try:\n                ip4 = socket.inet_ntop(socket.AF_INET, item)\n            except ValueError:\n                ip6 = socket.inet_ntop(socket.AF_INET6, item)\n\n        if ip4:\n            self.ip4_address = ip4\n        if ip6:\n            self.ip6_address = ip6\n\n    def __eq__(self, other):\n        if other is None:\n            return False\n\n        return self.ip4_address == other.ip4_address\n\nlast_location = Gio.File.new_for_path(GLib.get_home_dir())\n# A normal GtkFileChooserDialog only lets you pick folders OR files, not\n# both in the same dialog.  This does.\n\nclass FolderFileChooserDialog(Gtk.Dialog):\n    def __init__(self, window_title, transient_parent, starting_location):\n        super(FolderFileChooserDialog, self).__init__(title=window_title,\n                                                      parent=transient_parent,\n                                                      default_width=750,\n                                                      default_height=500)\n\n        self.add_buttons(_(\"Cancel\"), Gtk.ResponseType.CANCEL,\n                         _(\"Add\"), Gtk.ResponseType.OK)\n\n        self.chooser = Gtk.FileChooserWidget(action=Gtk.FileChooserAction.OPEN, select_multiple=True)\n        self.chooser.set_current_folder_file(starting_location)\n        self.chooser.connect(\"file-activated\", lambda chooser: self.response(Gtk.ResponseType.OK))\n        self.chooser.show_all()\n\n        self.get_content_area().add(self.chooser)\n        self.get_content_area().set_border_width(0)\n        self.get_uris = self.chooser.get_uris\n        self.get_current_folder_file = self.chooser.get_current_folder_file\n        self.connect(\"key-press-event\", self.on_button_press)\n\n    def on_button_press(self, widget, event, data=None):\n        multi = len(self.chooser.get_uris()) != 1\n        if event.keyval in (Gdk.KEY_KP_Enter, Gdk.KEY_Return) and multi:\n            self.response(Gtk.ResponseType.OK)\n            return Gdk.EVENT_STOP\n\n        return Gdk.EVENT_PROPAGATE\n\ndef create_file_and_folder_picker(dialog_parent=None):\n    chooser = FolderFileChooserDialog(_(\"Select file(s) to send\"), dialog_parent, last_location)\n\n    def update_last_location(dialog, response_id, data=None):\n        if response_id != Gtk.ResponseType.OK:\n            return\n\n        global last_location\n        last_location = chooser.get_current_folder_file()\n\n    chooser.connect(\"response\", update_last_location)\n    return chooser\n\n# Used as a decorator to run things in the background\ndef _async(func):\n    def wrapper(*args, **kwargs):\n        thread = threading.Thread(target=func, args=args, kwargs=kwargs)\n        thread.daemon = True\n        thread.start()\n        return thread\n    return wrapper\n\n# Used as a decorator to run things in the main loop, from another thread\ndef _idle(func):\n    def wrapper(*args, **kwargs):\n        GLib.idle_add(func, *args, **kwargs)\n    return wrapper\n\ndef print_stack():\n    traceback.print_stack()\n\ndef open_save_folder(filename=None):\n    bus = Gio.Application.get_default().get_dbus_connection()\n\n    if filename is not None:\n        method = \"ShowItems\"\n        abs_path = os.path.join(prefs.get_save_path(), filename)\n    else:\n        method = \"ShowFolders\"\n        abs_path = prefs.get_save_path()\n\n    file = Gio.File.new_for_path(abs_path)\n    startup_id = str(os.getpid())\n\n    try:\n        bus.call_sync(\"org.freedesktop.FileManager1\",\n                      \"/org/freedesktop/FileManager1\",\n                      \"org.freedesktop.FileManager1\",\n                      method,\n                      GLib.Variant(\"(ass)\",\n                                   ([file.get_uri()], startup_id)),\n                      None,\n                      Gio.DBusCallFlags.NONE,\n                      1000,\n                      None)\n        logging.debug(\"Opening save folder using dbus\")\n        return\n    except GLib.Error as e:\n        logging.debug(\"Could not use dbus interface to launch file manager: %s\" % e.message)\n\n    app = Gio.AppInfo.get_default_for_type(\"inode/directory\", True)\n\n    try:\n        logging.debug(\"Opening save folder using Gio (mimetype)\")\n        Gio.AppInfo.launch_default_for_uri(prefs.get_save_uri(), None)\n    except GLib.Error as e:\n        logging.critical(\"Could not open received files location: %s\" % e.message)\n\ndef verify_save_folder(transient_for=None):\n    return os.access(save_path, os.R_OK | os.W_OK)\n\ndef test_resolved_path_safety(relative_path):\n    # Check for valid path (pathlib.Path resolves both relative and symbolically-linked paths)\n    base = Path(prefs.get_save_path())\n    unresolved = base.joinpath(relative_path)\n\n    try:\n        resolved = unresolved.resolve()\n\n        # Not outside the base folder (raises ValueError)\n        relative = resolved.relative_to(base)\n\n        # Not the base folder (../Warpinator.. )\n        try:\n            if resolved.samefile(base):\n                raise ValueError()\n        except OSError:\n            # resolved doesn't exist, so it can't be the same\n            pass\n    except RuntimeError as e:\n        raise ReceiveError(\"Could not resolve path '%s': %s\" % str(e))\n    except ValueError:\n        raise ReceiveError(\"Resolved path is not valid child of the save folder: %s -> %s\" % (unresolved, str(resolved)), fatal=True)\n\ndef save_folder_is_native_fs():\n    file = Gio.File.new_for_path(prefs.get_save_path())\n    return file.is_native()\n\ndef trash_uri_supported():\n    vfs = Gio.Vfs.get_default()\n    return \"trash\" in vfs.get_supported_uri_schemes()\n\ndef open_trash():\n    Gio.AppInfo.launch_default_for_uri(\"trash:///\", None)\n\ndef disk_usage_available():\n    return GLib.find_program_in_path(\"baobab\")\n\ndef open_disk_usage():\n    if GLib.find_program_in_path(\"baobab\"):\n        GLib.spawn_async([\"baobab\", GLib.get_home_dir()], flags=GLib.SpawnFlags.SEARCH_PATH_FROM_ENVP)\n\nfree_space_monitor = None\nMB_TO_B = 1024 * 1024\n\ndef initialize_free_space_monitor():\n    global free_space_monitor\n    free_space_monitor  = FreeSpaceMonitor()\n\nclass FreeSpaceMonitor(GObject.Object):\n    __gsignals__ = {\n        \"low-space\": (GObject.SignalFlags.RUN_LAST, None, ()),\n        \"folder-changed\": (GObject.SignalFlags.RUN_LAST, None, ())\n    }\n\n    poll_levels = [\n        [ 100 * MB_TO_B,     0.05 ],\n        [ 1000 * MB_TO_B,    0.50 ],\n        [ 10000 * MB_TO_B,   5.00 ],\n        [ 100000 * MB_TO_B, 30.00 ]\n    ]\n\n    def __init__(self):\n        GObject.Object.__init__(self)\n        logging.debug(\"FreeSpaceMonitor new\")\n\n        self._monitor_thread = None\n\n        self._cancellable = Gio.Cancellable()\n        self._gate = threading.Event()\n        self._lock = threading.Lock()\n\n        self.sleep_time = 0\n        self.available_bytes = 0\n        self.min_free = prefs.get_min_free_space()\n        self.save_folder = Gio.File.new_for_path(prefs.get_save_path())\n\n        prefs.prefs_settings.connect(\"changed::receiving-folder\", self._folder_setting_changed)\n        prefs.prefs_settings.connect(\"changed::minimum-free-space\", self._folder_setting_changed)\n\n    def _folder_setting_changed(self, settings, key, data=None):\n        new_folder = Gio.File.new_for_path(prefs.get_save_path())\n        new_min_free = prefs.get_min_free_space()\n\n        if not self.save_folder.equal(new_folder):\n            self.save_folder = new_folder\n            self.emit(\"folder-changed\")\n\n        if self.min_free != new_min_free:\n            self.have_enough_free(0)\n\n    def get_free(self):\n        with self._lock:\n            return self.available_bytes\n\n    def have_enough_free(self, size, top_dir_basenames=[]):\n        self.save_folder = Gio.File.new_for_path(prefs.get_save_path())\n        self.min_free = prefs.get_min_free_space()\n\n        # Existing files haven't been removed yet, so their contents' size needs to be\n        # taken into account.\n        existing_allocation = 0\n\n        for basename in top_dir_basenames:\n            path = os.path.join(prefs.get_save_path(), basename)\n            if not os.path.exists(path):\n                continue\n            folder_file = Gio.File.new_for_path(path)\n\n            def get_contents_size(file):\n                if file.query_file_type(Gio.FileQueryInfoFlags.NOFOLLOW_SYMLINKS, None) != FileType.DIRECTORY:\n                    info = file.query_info(\"standard::allocated-size\",\n                                           Gio.FileQueryInfoFlags.NOFOLLOW_SYMLINKS,\n                                           None)\n                    if info:\n                        return info.get_attribute_uint64(\"standard::allocated-size\")\n                    else:\n                        return 0\n\n                size = 0\n                enumerator = file.enumerate_children(\"standard::allocated-size\",\n                                                     Gio.FileQueryInfoFlags.NOFOLLOW_SYMLINKS,\n                                                     None)\n                info = enumerator.next_file(None)\n                while info:\n                    child = enumerator.get_child(info)\n                    child_uri = child.get_uri()\n                    child_basename = child.get_basename()\n\n                    file_type = info.get_file_type()\n\n                    if file_type == FileType.DIRECTORY:\n                        size += get_contents_size(child)\n                    else:\n                        size += info.get_attribute_uint64(\"standard::allocated-size\")\n\n                    info = enumerator.next_file(None)\n\n                return size\n            existing_allocation += get_contents_size(folder_file)\n\n        if self._gate.is_set():\n            with self._lock:\n                total = self.available_bytes + existing_allocation\n                logging.debug(\"FreeSpaceMonitor - op needs %s, %s available (%s of which is being overwritten)\" % \\\n                    (GLib.format_size(size), GLib.format_size(total), GLib.format_size(existing_allocation)))\n                return size < total\n\n        self._refresh_available(self._cancellable)\n\n        with self._lock:\n            total = self.available_bytes + existing_allocation\n            logging.debug(\"FreeSpaceMonitor - op needs %s, %s available (%s of which is being overwritten)\" % \\\n                (GLib.format_size(size), GLib.format_size(total), GLib.format_size(existing_allocation)))\n            return size < total\n\n    def start(self):\n        self.save_folder = Gio.File.new_for_path(prefs.get_save_path())\n        self.min_free = prefs.get_min_free_space()\n        logging.debug(\"FreeSpaceMonitor start (monitoring %s,  keeping a %s reserve\" % (self.save_folder.get_path(), GLib.format_size(self.min_free * MB_TO_B)))\n\n        if self._monitor_thread is None:\n            self._monitor_thread = threading.Thread(target=self._monitor_thread_func, args=(self._cancellable,), name=\"FreeSpaceMonitor-thread\")\n            self._monitor_thread.start()\n\n        self._gate.set()\n\n    def pause(self):\n        logging.debug(\"FreeSpaceMonitor pause\")\n        self._gate.clear()\n\n    def stop(self):\n        logging.debug(\"FreeSpaceMonitor stop\")\n        self._cancellable.cancel()\n        self._gate.set()\n        if self._monitor_thread is not None:\n            self._monitor_thread.join(5)\n\n    def _sleep(self):\n        duration = 30.0\n\n        for level in self.poll_levels:\n            if self.available_bytes <= level[0]:\n                duration = level[1]\n                break\n        logging.debug(\"FreeSpaceMonitor - sleep duration %.2fs\" % duration)\n        time.sleep(duration)\n\n    def _monitor_thread_func(self, cancellable):\n        while not cancellable.is_cancelled():\n            self._refresh_available(cancellable)\n            self._sleep()\n            self._gate.wait()\n            continue\n\n    def _refresh_available(self, cancellable):\n        available_bytes = 0\n        try:\n            info = self.save_folder.query_filesystem_info(Gio.FILE_ATTRIBUTE_FILESYSTEM_FREE, cancellable)\n            available_bytes = info.get_attribute_uint64(Gio.FILE_ATTRIBUTE_FILESYSTEM_FREE)\n            if available_bytes == 0:\n                raise GLib.Error(code=GLib.FileError.FAILED, message=\"Save directory's filesystem doesn't report useful available space info.\")\n        except GLib.Error as e:\n            logging.critical(\"Could not query available disk space for the save directory, allowing all transfers: %s\" % e.message)\n            available_bytes = 0\n\n        with self._lock:\n            adjusted = available_bytes - (self.min_free * 1024 * 1024)\n            logging.debug(\"FreeSpaceMonitor - %d available (%s)\" % (adjusted, GLib.format_size(adjusted if adjusted >= 0 else 0)))\n            self.available_bytes = adjusted if adjusted > 0 else 0\n            if self.available_bytes == 0:\n                self._notify_low_space()\n\n    def _notify_low_space(self):\n        self.pause()\n        GLib.idle_add(priority=GLib.PRIORITY_HIGH, function=self._notify_idle_cb)\n\n    def _notify_idle_cb(self):\n        logging.critical(\"FreeSpaceMonitor - out of space!\")\n        self.emit(\"low-space\")\n\ndef files_exist(base_names):\n    for name in base_names:\n        path = os.path.join(prefs.get_save_path(), name)\n        logging.debug(\"(server side) Checking if file or folder %s already exists.\" % (path,))\n        file = Gio.File.new_for_path(path)\n        if file.query_exists(None):\n            return True\n\n    return False\n\ndef check_ml(fid):\n    on_ml = threading.current_thread() == threading.main_thread()\n    print(\"%s on mainloop: \" % fid, on_ml)\n\ndef get_hostname():\n    return GLib.get_host_name()\n\ndef get_local_name(hostname=get_hostname()):\n    local_name = \"%s@%s\" % (GLib.get_user_name(), hostname)\n    real_name = GLib.get_real_name()\n    if real_name is not None and real_name != \"\" and real_name != \"Unknown\":\n        # according to glib's doc, it can actually return \"Unknown\"\n        local_name = \"%s - %s\" % (real_name, local_name)\n    return local_name\n\ndef relpath_from_uri(child_uri, base_uri):\n    child_uri = GLib.uri_unescape_string(child_uri)\n    base_uri = GLib.uri_unescape_string(base_uri)\n\n    if child_uri.startswith(base_uri):\n        return child_uri.replace(base_uri + \"/\", \"\")\n    else:\n        return None\n\ndef sort_remote_machines(am, bm):\n    if am.favorite and not bm.favorite:\n        return -1\n    elif bm.favorite and not am.favorite:\n        return +1\n    elif am.recent_time > bm.recent_time:\n        return -1\n    elif bm.recent_time > am.recent_time:\n        return +1\n    elif am.display_name and not bm.display_name:\n        return -1\n    elif bm.display_name and not am.display_name:\n        return +1\n    elif not am.display_name and not bm.display_name:\n        return -1 if am.hostname < bm.hostname else +1\n\n    return -1 if am.display_name < bm.display_name else +1\n\n# adapted from nemo-file-operations.c: format_time()\ndef format_time_span(seconds):\n    if seconds < 0:\n        seconds = 0\n\n    if (seconds < 10):\n        return _(\"A few seconds remaining\")\n\n    if (seconds < 60):\n        return _(\"%d seconds remaining\") % seconds\n\n    if (seconds < 60 * 60):\n        minutes = round(seconds / 60)\n        return gettext.ngettext(\"%d minute\", \"%d minutes\", minutes) % minutes\n\n    hours = math.floor(seconds / (60 * 60))\n\n    if seconds < (60 * 60 * 4):\n        minutes = int((seconds - hours * 60 * 60) / 60)\n\n        h = gettext.ngettext (\"%d hour\", \"%d hours\", hours) % hours\n        m = gettext.ngettext (\"%d minute\", \"%d minutes\", minutes) % minutes\n        res = \"%s, %s\" % (h, m)\n        return res;\n\n    return gettext.ngettext(\"approximately %d hour\", \"approximately %d hours\", hours) % hours\n\n\n# adapted from nemo-file-operations.c: format_time()\ndef precise_format_time_span(micro):\n    sdec, total_seconds = math.modf(micro / 1000 / 1000)\n    seconds = total_seconds % 60\n    mdec, total_minutes = math.modf(total_seconds / 60)\n    minutes = total_minutes % 60\n    hdec, total_hours = math.modf(total_minutes / 60)\n    hours = total_hours % 60\n    return (\"%02d:%02d:%02d.%s\" % (hours, minutes, seconds, str(sdec)[2:5]))\n\ndef get_global_scale_factor():\n    screen = Gdk.Screen.get_default()\n\n    v = GObject.Value(int)\n\n    if screen.get_setting(\"gdk-window-scaling-factor\", v):\n        return v.get_value()\n\n    return 1\n\nclass CairoSurfaceLoader(GObject.Object):\n    __gsignals__ = {\n        'error': (GObject.SignalFlags.RUN_LAST, None, ())\n    }\n\n    def __init__(self, icon_size=Gtk.IconSize.DND):\n        self.loader =GdkPixbuf.PixbufLoader()\n        self.loader.connect(\"size-prepared\", self.on_loader_size_prepared)\n\n        s, w, h = Gtk.IconSize.lookup(icon_size)\n\n        self.surface_size = w\n        self.pixbuf_size = w * get_global_scale_factor()\n\n    def on_loader_size_prepared(self, loader, width, height, data=None):\n        new_width = self.pixbuf_size\n        new_height = self.pixbuf_size\n\n        if width != height:\n            if width > height:\n                aspect_ratio = height / width\n\n                new_width = self.pixbuf_size\n                new_height = new_width * aspect_ratio\n            else:\n                aspect_ratio = width / height\n\n                new_height = self.pixbuf_size\n                new_width = new_height * aspect_ratio\n\n        self.loader.set_size(new_width, new_height)\n\n    def add_bytes(self, _bytes):\n        try:\n            self.loader.write_bytes(GLib.Bytes(_bytes))\n        except GLib.Error:\n            try:\n                self.loader.close()\n            except:\n                pass\n\n            self.emit(\"error\")\n\n    def get_surface(self):\n        try:\n            self.loader.close()\n            pixbuf = self.loader.get_pixbuf()\n\n            if pixbuf:\n                surface = Gdk.cairo_surface_create_from_pixbuf(pixbuf,\n                                                               get_global_scale_factor(),\n                                                               None)\n                return surface\n        except:\n            self.emit(\"error\")\n\nclass AboutDialog():\n    def __init__(self, parent):\n        # Maybe this can be configured during the build? But this works.\n        if config.FLATPAK_BUILD:\n            name = \"Warpinator (Flatpak)\"\n        else:\n            name = \"Warpinator\"\n\n        dialog = Gtk.AboutDialog(parent=parent,\n                                 title=_(\"About\"),\n                                 program_name=name,\n                                 icon_name=\"org.x.Warpinator\",\n                                 logo_icon_name=\"org.x.Warpinator\",\n                                 comments=_(\"Send and Receive Files across the Network\"),\n                                 website=\"https://github.com/linuxmint/warpinator\",\n                                 version=config.VERSION,\n                                 license_type=Gtk.License.GPL_3_0)\n\n        dialog.run()\n        dialog.destroy()\n\n#### Logging\nclass WarpLogFormatter(logging.Formatter):\n    dbg_crit_format = \"%(asctime)-15s::warpinator::%(levelname)s: %(message)s -- %(filename)s (line %(lineno)d)\"\n    info_format = \"%(asctime)-15s::warpinator: %(message)s\"\n\n    def __init__(self):\n        super().__init__()\n\n    def format(self, record):\n        if record.levelno in (logging.DEBUG, logging.ERROR):\n            self._style._fmt = WarpLogFormatter.dbg_crit_format\n\n        elif record.levelno == logging.INFO:\n            self._style._fmt = WarpLogFormatter.info_format\n\n        result = logging.Formatter.format(self, record)\n\n        return result\n\nlog_handler = logging.StreamHandler(sys.stdout)\nlog_handler.setFormatter(WarpLogFormatter())\nlogging.root.addHandler(log_handler)\n\ntry:\n    debug = os.environ[\"WARPINATOR_DEBUG\"]\nexcept:\n    debug = False\n\nif debug:\n    logging.root.setLevel(logging.DEBUG)\nelse:\n    logging.root.setLevel(logging.INFO)\n\n#### /Logging\n\nrecent_manager = Gtk.RecentManager()\n\ndef add_to_recents_if_single_selection(uri_list):\n    if len(uri_list) == 1:\n        try:\n            recent_manager.add_item(uri_list[0])\n        except Exception as e:\n            logging.warning(\"Could not add '%s' single item to recent files: %s\" % e)\n\ndef get_recent_chooser_menu():\n    chooser = Gtk.RecentChooserMenu(show_tips=True,\n                                    sort_type=Gtk.RecentSortType.MRU,\n                                    show_not_found=False)\n\n    return chooser\n", "code_before": "#!/usr/bin/python3\n\nimport threading\nimport gettext\nimport math\nimport logging\nimport os\nfrom pathlib import Path\nimport queue\nimport sys\nimport socket\nimport time\nimport traceback\nfrom concurrent.futures import ThreadPoolExecutor\n\nfrom gi.repository import GLib, Gtk, Gdk, GObject, GdkPixbuf, Gio\n\nimport prefs\nimport config\n\nif config.using_landlock:\n    import landlock\n\n_ = gettext.gettext\n\n# Not sure what the ideal count is, too few and there will be waits if a lot of\n# transfers are happening.  The server runs on its own thread, and has its own thread\n# pool to service incoming rpcs. Each remote uses one thread for its connection loop,\n# and all remotes share this thread pool for outgoing calls. It could be we may need\n# to limit the number of simultaneous ops in the gui.\n#\n# Both server and remote thread pool sizes can be adjusted in dconf.\nglobal_rpc_threadpool = None\n\n# Initializing in thie function avoids a circular import due to prefs.get_thread_count()\ndef initialize_rpc_threadpool():\n    global global_rpc_threadpool\n\n    if config.using_landlock:\n        import landlock\n        global_rpc_threadpool = NewThreadExecutor()\n    else:\n        global_rpc_threadpool = ThreadPoolExecutor(max_workers=prefs.get_remote_pool_max_threads())\n\nclass NewThreadExecutor():\n    def __init__(self):\n        self.max_workers = prefs.get_remote_pool_max_threads()\n        self.transfer_queue = queue.SimpleQueue()\n\n\n        self._threads_lock = threading.Lock()\n        self._threads = {}\n        self._shutdown_lock = threading.Lock()\n        self._shutdown = False\n        self.counter = 0\n        self._factory_thread_keepalive = threading.Event()\n        self._wait_semaphore = threading.Semaphore(self.max_workers)\n\n        self._factory_thread = threading.Thread(target=self.factory_thread_func, name=\"NewThreadExecutor-factory-thread\")\n        self._factory_thread.start()\n\n    def factory_thread_func(self):\n        while True:\n            if self._factory_thread_keepalive.is_set():\n                break\n\n            if self._wait_semaphore.acquire(timeout=0.5):\n                continue\n\n            if not self.transfer_queue.empty():\n                self.spawn_thread()\n\n    def submit(self, func, *args, **kargs):\n        with self._shutdown_lock:\n            if self._shutdown:\n                raise RuntimeError(\"Cannot start new transfer threads, shutting down.\")\n\n            self.transfer_queue.put((func, args, kargs))\n\n    def spawn_thread(self):\n        self.counter += 1\n\n        tname = \"landlocked-thread-%d\" % self.counter\n        t = threading.Thread(target=self._transfer_landlocked_thread_func, name=tname)\n\n        with self._threads_lock:\n            t.start()\n            self._threads[t.ident] = t\n        return True\n\n    def _transfer_landlocked_thread_func(self):\n        try:\n            opinfo = self.transfer_queue.get_nowait()\n\n            if opinfo[0].__name__ == \"start_transfer_op\":\n                rs = landlock.Ruleset()\n                rs.allow(prefs.get_save_path())\n                rs.apply()\n\n            opinfo[0](*opinfo[1], **opinfo[2])\n        except queue.Empty:\n            pass\n\n        with self._threads_lock:\n            del self._threads[threading.get_ident()]\n\n        self._wait_semaphore.release()\n\n    def shutdown(self, wait=True):\n        with self._shutdown_lock:\n            self._shutdown = True\n\n            for t in self._threads:\n                t.join()\n\n            self._factory_thread_keepalive.set()\n            self._factory_thread.join()\n\nfrom enum import IntEnum\nTransferDirection = IntEnum('TransferDirection', 'TO_REMOTE_MACHINE \\\n                                                  FROM_REMOTE_MACHINE')\n\n# Using Gio enums fails for some unknown reason when collecting file info sometimes.\n# Avoid introspection.\nFileType = IntEnum('FileType', (('REGULAR', Gio.FileType.REGULAR),\n                                ('DIRECTORY', Gio.FileType.DIRECTORY),\n                                ('SYMBOLIC_LINK', Gio.FileType.SYMBOLIC_LINK)))\n\n# Online - all ok\n# Offline - no presence at all\n# Init connecting - we've just discovered you\n# Unreachable - we've either tried and failed after initial discovery, or something went wrong during the session\n\nRemoteStatus = IntEnum('RemoteStatus', 'ONLINE \\\n                                        OFFLINE \\\n                                        INIT_CONNECTING \\\n                                        UNREACHABLE \\\n                                        AWAITING_DUPLEX')\n\nOpStatus = IntEnum('OpStatus', 'INIT \\\n                                CALCULATING \\\n                                WAITING_PERMISSION \\\n                                CANCELLED_PERMISSION_BY_SENDER \\\n                                CANCELLED_PERMISSION_BY_RECEIVER \\\n                                TRANSFERRING \\\n                                PAUSED \\\n                                STOPPED_BY_SENDER \\\n                                STOPPED_BY_RECEIVER \\\n                                FAILED \\\n                                FAILED_UNRECOVERABLE \\\n                                FILE_NOT_FOUND \\\n                                FINISHED \\\n                                FINISHED_WARNING')\n\nOpCommand = IntEnum('OpCommand', 'START_TRANSFER \\\n                                  UPDATE_PROGRESS \\\n                                  CANCEL_PERMISSION_BY_SENDER \\\n                                  CANCEL_PERMISSION_BY_RECEIVER \\\n                                  PAUSE_TRANSFER \\\n                                  RETRY_TRANSFER \\\n                                  STOP_TRANSFER_BY_SENDER \\\n                                  STOP_TRANSFER_BY_RECEIVER \\\n                                  REMOVE_TRANSFER')\n\nclass ReceiveError(Exception):\n    def __init__(self, message, fatal=True):\n        self.fatal = fatal\n        logging.debug(\"ReceiveError: (fatal: %d): %s\" % (self.fatal, message))\n        super().__init__(message)\n\nclass InterfaceInfo():\n    def __init__(self, ip4, ip6, iface=None):\n        self.iface = iface\n        # netifaces AF_INET and AF_INET6 dicts\n        self.ip4 = ip4\n        self.ip4_address = self.ip4[\"addr\"]\n\n        try:\n            self.ip6 = ip6\n            self.ip6_address = self.ip6[\"addr\"]\n        except:\n            self.ip6 = None\n            self.ip6_address = None\n\n    def __eq__(self, other):\n        if other is None:\n            return False\n\n        return self.ip4_address == other.ip4_address\n\n    def as_binary_list(self):\n        blist = []\n\n        if self.ip4:\n            try:\n                blist.append(socket.inet_pton(GLib.SYSDEF_AF_INET, self.ip4_address))\n            except:\n                pass\n        if self.ip6:\n            try:\n                blist.append(socket.inet_pton(GLib.SYSDEF_AF_INET6, self.ip6_address))\n            except:\n                pass\n\n        return blist\n\nclass RemoteInterfaceInfo():\n    def __init__(self, blist):\n        ip4 = None\n        ip6 = None\n\n        for item in blist:\n            try:\n                ip4 = socket.inet_ntop(socket.AF_INET, item)\n            except ValueError:\n                ip6 = socket.inet_ntop(socket.AF_INET6, item)\n\n        if ip4:\n            self.ip4_address = ip4\n        if ip6:\n            self.ip6_address = ip6\n\n    def __eq__(self, other):\n        if other is None:\n            return False\n\n        return self.ip4_address == other.ip4_address\n\nlast_location = Gio.File.new_for_path(GLib.get_home_dir())\n# A normal GtkFileChooserDialog only lets you pick folders OR files, not\n# both in the same dialog.  This does.\n\nclass FolderFileChooserDialog(Gtk.Dialog):\n    def __init__(self, window_title, transient_parent, starting_location):\n        super(FolderFileChooserDialog, self).__init__(title=window_title,\n                                                      parent=transient_parent,\n                                                      default_width=750,\n                                                      default_height=500)\n\n        self.add_buttons(_(\"Cancel\"), Gtk.ResponseType.CANCEL,\n                         _(\"Add\"), Gtk.ResponseType.OK)\n\n        self.chooser = Gtk.FileChooserWidget(action=Gtk.FileChooserAction.OPEN, select_multiple=True)\n        self.chooser.set_current_folder_file(starting_location)\n        self.chooser.connect(\"file-activated\", lambda chooser: self.response(Gtk.ResponseType.OK))\n        self.chooser.show_all()\n\n        self.get_content_area().add(self.chooser)\n        self.get_content_area().set_border_width(0)\n        self.get_uris = self.chooser.get_uris\n        self.get_current_folder_file = self.chooser.get_current_folder_file\n        self.connect(\"key-press-event\", self.on_button_press)\n\n    def on_button_press(self, widget, event, data=None):\n        multi = len(self.chooser.get_uris()) != 1\n        if event.keyval in (Gdk.KEY_KP_Enter, Gdk.KEY_Return) and multi:\n            self.response(Gtk.ResponseType.OK)\n            return Gdk.EVENT_STOP\n\n        return Gdk.EVENT_PROPAGATE\n\ndef create_file_and_folder_picker(dialog_parent=None):\n    chooser = FolderFileChooserDialog(_(\"Select file(s) to send\"), dialog_parent, last_location)\n\n    def update_last_location(dialog, response_id, data=None):\n        if response_id != Gtk.ResponseType.OK:\n            return\n\n        global last_location\n        last_location = chooser.get_current_folder_file()\n\n    chooser.connect(\"response\", update_last_location)\n    return chooser\n\n# Used as a decorator to run things in the background\ndef _async(func):\n    def wrapper(*args, **kwargs):\n        thread = threading.Thread(target=func, args=args, kwargs=kwargs)\n        thread.daemon = True\n        thread.start()\n        return thread\n    return wrapper\n\n# Used as a decorator to run things in the main loop, from another thread\ndef _idle(func):\n    def wrapper(*args, **kwargs):\n        GLib.idle_add(func, *args, **kwargs)\n    return wrapper\n\ndef print_stack():\n    traceback.print_stack()\n\ndef open_save_folder(filename=None):\n    bus = Gio.Application.get_default().get_dbus_connection()\n\n    if filename is not None:\n        method = \"ShowItems\"\n        abs_path = os.path.join(prefs.get_save_path(), filename)\n    else:\n        method = \"ShowFolders\"\n        abs_path = prefs.get_save_path()\n\n    file = Gio.File.new_for_path(abs_path)\n    startup_id = str(os.getpid())\n\n    try:\n        bus.call_sync(\"org.freedesktop.FileManager1\",\n                      \"/org/freedesktop/FileManager1\",\n                      \"org.freedesktop.FileManager1\",\n                      method,\n                      GLib.Variant(\"(ass)\",\n                                   ([file.get_uri()], startup_id)),\n                      None,\n                      Gio.DBusCallFlags.NONE,\n                      1000,\n                      None)\n        logging.debug(\"Opening save folder using dbus\")\n        return\n    except GLib.Error as e:\n        logging.debug(\"Could not use dbus interface to launch file manager: %s\" % e.message)\n\n    app = Gio.AppInfo.get_default_for_type(\"inode/directory\", True)\n\n    try:\n        logging.debug(\"Opening save folder using Gio (mimetype)\")\n        Gio.AppInfo.launch_default_for_uri(prefs.get_save_uri(), None)\n    except GLib.Error as e:\n        logging.critical(\"Could not open received files location: %s\" % e.message)\n\ndef verify_save_folder(transient_for=None):\n    return os.access(save_path, os.R_OK | os.W_OK)\n\ndef save_folder_is_native_fs():\n    file = Gio.File.new_for_path(prefs.get_save_path())\n    return file.is_native()\n\ndef trash_uri_supported():\n    vfs = Gio.Vfs.get_default()\n    return \"trash\" in vfs.get_supported_uri_schemes()\n\ndef open_trash():\n    Gio.AppInfo.launch_default_for_uri(\"trash:///\", None)\n\ndef disk_usage_available():\n    return GLib.find_program_in_path(\"baobab\")\n\ndef open_disk_usage():\n    if GLib.find_program_in_path(\"baobab\"):\n        GLib.spawn_async([\"baobab\", GLib.get_home_dir()], flags=GLib.SpawnFlags.SEARCH_PATH_FROM_ENVP)\n\nfree_space_monitor = None\nMB_TO_B = 1024 * 1024\n\ndef initialize_free_space_monitor():\n    global free_space_monitor\n    free_space_monitor  = FreeSpaceMonitor()\n\nclass FreeSpaceMonitor(GObject.Object):\n    __gsignals__ = {\n        \"low-space\": (GObject.SignalFlags.RUN_LAST, None, ()),\n        \"folder-changed\": (GObject.SignalFlags.RUN_LAST, None, ())\n    }\n\n    poll_levels = [\n        [ 100 * MB_TO_B,     0.05 ],\n        [ 1000 * MB_TO_B,    0.50 ],\n        [ 10000 * MB_TO_B,   5.00 ],\n        [ 100000 * MB_TO_B, 30.00 ]\n    ]\n\n    def __init__(self):\n        GObject.Object.__init__(self)\n        logging.debug(\"FreeSpaceMonitor new\")\n\n        self._monitor_thread = None\n\n        self._cancellable = Gio.Cancellable()\n        self._gate = threading.Event()\n        self._lock = threading.Lock()\n\n        self.sleep_time = 0\n        self.available_bytes = 0\n        self.min_free = prefs.get_min_free_space()\n        self.save_folder = Gio.File.new_for_path(prefs.get_save_path())\n\n        prefs.prefs_settings.connect(\"changed::receiving-folder\", self._folder_setting_changed)\n        prefs.prefs_settings.connect(\"changed::minimum-free-space\", self._folder_setting_changed)\n\n    def _folder_setting_changed(self, settings, key, data=None):\n        new_folder = Gio.File.new_for_path(prefs.get_save_path())\n        new_min_free = prefs.get_min_free_space()\n\n        if not self.save_folder.equal(new_folder):\n            self.save_folder = new_folder\n            self.emit(\"folder-changed\")\n\n        if self.min_free != new_min_free:\n            self.have_enough_free(0)\n\n    def get_free(self):\n        with self._lock:\n            return self.available_bytes\n\n    def have_enough_free(self, size, top_dir_basenames=[]):\n        self.save_folder = Gio.File.new_for_path(prefs.get_save_path())\n        self.min_free = prefs.get_min_free_space()\n\n        # Existing files haven't been removed yet, so their contents' size needs to be\n        # taken into account.\n        existing_allocation = 0\n\n        for basename in top_dir_basenames:\n            path = os.path.join(prefs.get_save_path(), basename)\n            if not os.path.exists(path):\n                continue\n            folder_file = Gio.File.new_for_path(path)\n\n            def get_contents_size(file):\n                if file.query_file_type(Gio.FileQueryInfoFlags.NOFOLLOW_SYMLINKS, None) != FileType.DIRECTORY:\n                    info = file.query_info(\"standard::allocated-size\",\n                                           Gio.FileQueryInfoFlags.NOFOLLOW_SYMLINKS,\n                                           None)\n                    if info:\n                        return info.get_attribute_uint64(\"standard::allocated-size\")\n                    else:\n                        return 0\n\n                size = 0\n                enumerator = file.enumerate_children(\"standard::allocated-size\",\n                                                     Gio.FileQueryInfoFlags.NOFOLLOW_SYMLINKS,\n                                                     None)\n                info = enumerator.next_file(None)\n                while info:\n                    child = enumerator.get_child(info)\n                    child_uri = child.get_uri()\n                    child_basename = child.get_basename()\n\n                    file_type = info.get_file_type()\n\n                    if file_type == FileType.DIRECTORY:\n                        size += get_contents_size(child)\n                    else:\n                        size += info.get_attribute_uint64(\"standard::allocated-size\")\n\n                    info = enumerator.next_file(None)\n\n                return size\n            existing_allocation += get_contents_size(folder_file)\n\n        if self._gate.is_set():\n            with self._lock:\n                total = self.available_bytes + existing_allocation\n                logging.debug(\"FreeSpaceMonitor - op needs %s, %s available (%s of which is being overwritten)\" % \\\n                    (GLib.format_size(size), GLib.format_size(total), GLib.format_size(existing_allocation)))\n                return size < total\n\n        self._refresh_available(self._cancellable)\n\n        with self._lock:\n            total = self.available_bytes + existing_allocation\n            logging.debug(\"FreeSpaceMonitor - op needs %s, %s available (%s of which is being overwritten)\" % \\\n                (GLib.format_size(size), GLib.format_size(total), GLib.format_size(existing_allocation)))\n            return size < total\n\n    def start(self):\n        self.save_folder = Gio.File.new_for_path(prefs.get_save_path())\n        self.min_free = prefs.get_min_free_space()\n        logging.debug(\"FreeSpaceMonitor start (monitoring %s,  keeping a %s reserve\" % (self.save_folder.get_path(), GLib.format_size(self.min_free * MB_TO_B)))\n\n        if self._monitor_thread is None:\n            self._monitor_thread = threading.Thread(target=self._monitor_thread_func, args=(self._cancellable,), name=\"FreeSpaceMonitor-thread\")\n            self._monitor_thread.start()\n\n        self._gate.set()\n\n    def pause(self):\n        logging.debug(\"FreeSpaceMonitor pause\")\n        self._gate.clear()\n\n    def stop(self):\n        logging.debug(\"FreeSpaceMonitor stop\")\n        self._cancellable.cancel()\n        self._gate.set()\n        if self._monitor_thread is not None:\n            self._monitor_thread.join(5)\n\n    def _sleep(self):\n        duration = 30.0\n\n        for level in self.poll_levels:\n            if self.available_bytes <= level[0]:\n                duration = level[1]\n                break\n        logging.debug(\"FreeSpaceMonitor - sleep duration %.2fs\" % duration)\n        time.sleep(duration)\n\n    def _monitor_thread_func(self, cancellable):\n        while not cancellable.is_cancelled():\n            self._refresh_available(cancellable)\n            self._sleep()\n            self._gate.wait()\n            continue\n\n    def _refresh_available(self, cancellable):\n        available_bytes = 0\n        try:\n            info = self.save_folder.query_filesystem_info(Gio.FILE_ATTRIBUTE_FILESYSTEM_FREE, cancellable)\n            available_bytes = info.get_attribute_uint64(Gio.FILE_ATTRIBUTE_FILESYSTEM_FREE)\n            if available_bytes == 0:\n                raise GLib.Error(code=GLib.FileError.FAILED, message=\"Save directory's filesystem doesn't report useful available space info.\")\n        except GLib.Error as e:\n            logging.critical(\"Could not query available disk space for the save directory, allowing all transfers: %s\" % e.message)\n            available_bytes = 0\n\n        with self._lock:\n            adjusted = available_bytes - (self.min_free * 1024 * 1024)\n            logging.debug(\"FreeSpaceMonitor - %d available (%s)\" % (adjusted, GLib.format_size(adjusted if adjusted >= 0 else 0)))\n            self.available_bytes = adjusted if adjusted > 0 else 0\n            if self.available_bytes == 0:\n                self._notify_low_space()\n\n    def _notify_low_space(self):\n        self.pause()\n        GLib.idle_add(priority=GLib.PRIORITY_HIGH, function=self._notify_idle_cb)\n\n    def _notify_idle_cb(self):\n        logging.critical(\"FreeSpaceMonitor - out of space!\")\n        self.emit(\"low-space\")\n\ndef files_exist(base_names):\n    for name in base_names:\n        path = os.path.join(prefs.get_save_path(), name)\n        logging.debug(\"(server side) Checking if file or folder %s already exists.\" % (path,))\n        file = Gio.File.new_for_path(path)\n        if file.query_exists(None):\n            return True\n\n    return False\n\ndef check_ml(fid):\n    on_ml = threading.current_thread() == threading.main_thread()\n    print(\"%s on mainloop: \" % fid, on_ml)\n\ndef get_hostname():\n    return GLib.get_host_name()\n\ndef get_local_name(hostname=get_hostname()):\n    local_name = \"%s@%s\" % (GLib.get_user_name(), hostname)\n    real_name = GLib.get_real_name()\n    if real_name is not None and real_name != \"\" and real_name != \"Unknown\":\n        # according to glib's doc, it can actually return \"Unknown\"\n        local_name = \"%s - %s\" % (real_name, local_name)\n    return local_name\n\ndef relpath_from_uri(child_uri, base_uri):\n    child_uri = GLib.uri_unescape_string(child_uri)\n    base_uri = GLib.uri_unescape_string(base_uri)\n\n    if child_uri.startswith(base_uri):\n        return child_uri.replace(base_uri + \"/\", \"\")\n    else:\n        return None\n\ndef sort_remote_machines(am, bm):\n    if am.favorite and not bm.favorite:\n        return -1\n    elif bm.favorite and not am.favorite:\n        return +1\n    elif am.recent_time > bm.recent_time:\n        return -1\n    elif bm.recent_time > am.recent_time:\n        return +1\n    elif am.display_name and not bm.display_name:\n        return -1\n    elif bm.display_name and not am.display_name:\n        return +1\n    elif not am.display_name and not bm.display_name:\n        return -1 if am.hostname < bm.hostname else +1\n\n    return -1 if am.display_name < bm.display_name else +1\n\n# adapted from nemo-file-operations.c: format_time()\ndef format_time_span(seconds):\n    if seconds < 0:\n        seconds = 0\n\n    if (seconds < 10):\n        return _(\"A few seconds remaining\")\n\n    if (seconds < 60):\n        return _(\"%d seconds remaining\") % seconds\n\n    if (seconds < 60 * 60):\n        minutes = round(seconds / 60)\n        return gettext.ngettext(\"%d minute\", \"%d minutes\", minutes) % minutes\n\n    hours = math.floor(seconds / (60 * 60))\n\n    if seconds < (60 * 60 * 4):\n        minutes = int((seconds - hours * 60 * 60) / 60)\n\n        h = gettext.ngettext (\"%d hour\", \"%d hours\", hours) % hours\n        m = gettext.ngettext (\"%d minute\", \"%d minutes\", minutes) % minutes\n        res = \"%s, %s\" % (h, m)\n        return res;\n\n    return gettext.ngettext(\"approximately %d hour\", \"approximately %d hours\", hours) % hours\n\n\n# adapted from nemo-file-operations.c: format_time()\ndef precise_format_time_span(micro):\n    sdec, total_seconds = math.modf(micro / 1000 / 1000)\n    seconds = total_seconds % 60\n    mdec, total_minutes = math.modf(total_seconds / 60)\n    minutes = total_minutes % 60\n    hdec, total_hours = math.modf(total_minutes / 60)\n    hours = total_hours % 60\n    return (\"%02d:%02d:%02d.%s\" % (hours, minutes, seconds, str(sdec)[2:5]))\n\ndef get_global_scale_factor():\n    screen = Gdk.Screen.get_default()\n\n    v = GObject.Value(int)\n\n    if screen.get_setting(\"gdk-window-scaling-factor\", v):\n        return v.get_value()\n\n    return 1\n\nclass CairoSurfaceLoader(GObject.Object):\n    __gsignals__ = {\n        'error': (GObject.SignalFlags.RUN_LAST, None, ())\n    }\n\n    def __init__(self, icon_size=Gtk.IconSize.DND):\n        self.loader =GdkPixbuf.PixbufLoader()\n        self.loader.connect(\"size-prepared\", self.on_loader_size_prepared)\n\n        s, w, h = Gtk.IconSize.lookup(icon_size)\n\n        self.surface_size = w\n        self.pixbuf_size = w * get_global_scale_factor()\n\n    def on_loader_size_prepared(self, loader, width, height, data=None):\n        new_width = self.pixbuf_size\n        new_height = self.pixbuf_size\n\n        if width != height:\n            if width > height:\n                aspect_ratio = height / width\n\n                new_width = self.pixbuf_size\n                new_height = new_width * aspect_ratio\n            else:\n                aspect_ratio = width / height\n\n                new_height = self.pixbuf_size\n                new_width = new_height * aspect_ratio\n\n        self.loader.set_size(new_width, new_height)\n\n    def add_bytes(self, _bytes):\n        try:\n            self.loader.write_bytes(GLib.Bytes(_bytes))\n        except GLib.Error:\n            try:\n                self.loader.close()\n            except:\n                pass\n\n            self.emit(\"error\")\n\n    def get_surface(self):\n        try:\n            self.loader.close()\n            pixbuf = self.loader.get_pixbuf()\n\n            if pixbuf:\n                surface = Gdk.cairo_surface_create_from_pixbuf(pixbuf,\n                                                               get_global_scale_factor(),\n                                                               None)\n                return surface\n        except:\n            self.emit(\"error\")\n\nclass AboutDialog():\n    def __init__(self, parent):\n        # Maybe this can be configured during the build? But this works.\n        if config.FLATPAK_BUILD:\n            name = \"Warpinator (Flatpak)\"\n        else:\n            name = \"Warpinator\"\n\n        dialog = Gtk.AboutDialog(parent=parent,\n                                 title=_(\"About\"),\n                                 program_name=name,\n                                 icon_name=\"org.x.Warpinator\",\n                                 logo_icon_name=\"org.x.Warpinator\",\n                                 comments=_(\"Send and Receive Files across the Network\"),\n                                 website=\"https://github.com/linuxmint/warpinator\",\n                                 version=config.VERSION,\n                                 license_type=Gtk.License.GPL_3_0)\n\n        dialog.run()\n        dialog.destroy()\n\n#### Logging\nclass WarpLogFormatter(logging.Formatter):\n    dbg_crit_format = \"%(asctime)-15s::warpinator::%(levelname)s: %(message)s -- %(filename)s (line %(lineno)d)\"\n    info_format = \"%(asctime)-15s::warpinator: %(message)s\"\n\n    def __init__(self):\n        super().__init__()\n\n    def format(self, record):\n        if record.levelno in (logging.DEBUG, logging.ERROR):\n            self._style._fmt = WarpLogFormatter.dbg_crit_format\n\n        elif record.levelno == logging.INFO:\n            self._style._fmt = WarpLogFormatter.info_format\n\n        result = logging.Formatter.format(self, record)\n\n        return result\n\nlog_handler = logging.StreamHandler(sys.stdout)\nlog_handler.setFormatter(WarpLogFormatter())\nlogging.root.addHandler(log_handler)\n\ntry:\n    debug = os.environ[\"WARPINATOR_DEBUG\"]\nexcept:\n    debug = False\n\nif debug:\n    logging.root.setLevel(logging.DEBUG)\nelse:\n    logging.root.setLevel(logging.INFO)\n\n#### /Logging\n\nrecent_manager = Gtk.RecentManager()\n\ndef add_to_recents_if_single_selection(uri_list):\n    if len(uri_list) == 1:\n        try:\n            recent_manager.add_item(uri_list[0])\n        except Exception as e:\n            logging.warning(\"Could not add '%s' single item to recent files: %s\" % e)\n\ndef get_recent_chooser_menu():\n    chooser = Gtk.RecentChooserMenu(show_tips=True,\n                                    sort_type=Gtk.RecentSortType.MRU,\n                                    show_not_found=False)\n\n    return chooser\n", "patch": "@@ -330,6 +330,29 @@ def open_save_folder(filename=None):\n def verify_save_folder(transient_for=None):\n     return os.access(save_path, os.R_OK | os.W_OK)\n \n+def test_resolved_path_safety(relative_path):\n+    # Check for valid path (pathlib.Path resolves both relative and symbolically-linked paths)\n+    base = Path(prefs.get_save_path())\n+    unresolved = base.joinpath(relative_path)\n+\n+    try:\n+        resolved = unresolved.resolve()\n+\n+        # Not outside the base folder (raises ValueError)\n+        relative = resolved.relative_to(base)\n+\n+        # Not the base folder (../Warpinator.. )\n+        try:\n+            if resolved.samefile(base):\n+                raise ValueError()\n+        except OSError:\n+            # resolved doesn't exist, so it can't be the same\n+            pass\n+    except RuntimeError as e:\n+        raise ReceiveError(\"Could not resolve path '%s': %s\" % str(e))\n+    except ValueError:\n+        raise ReceiveError(\"Resolved path is not valid child of the save folder: %s -> %s\" % (unresolved, str(resolved)), fatal=True)\n+\n def save_folder_is_native_fs():\n     file = Gio.File.new_for_path(prefs.get_save_path())\n     return file.is_native()", "file_path": "files/2023_5/153", "file_language": "py", "file_name": "src/util.py", "outdated_file_modify": 0, "outdated_file_before": 0, "outdated_file_after": 0, "llm_check": 1, "static_check": 0, "static": {"rats": [false, []], "semgrep": [false, []]}, "target": -1, "function_before": [], "function_after": []}], "outdated": 0, "cwe_descripiton": "", "cwe_consequence": "", "cwe_method": "", "cwe_solution": ""}
