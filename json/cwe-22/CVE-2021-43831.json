{"index": 6918, "cve_id": "CVE-2021-43831", "cwe_id": ["CWE-22"], "cve_language": "Python", "cve_description": "Gradio is an open source framework for building interactive machine learning models and demos. In versions prior to 2.5.0 there is a vulnerability that affects anyone who creates and publicly shares Gradio interfaces. File paths are not restricted and users who receive a Gradio link can access any files on the host computer if they know the file names or file paths. This is limited only by the host operating system. Paths are opened in read only mode. The problem has been patched in gradio 2.5.0.", "cvss": "7.7", "publish_date": "December 15, 2021", "AV": "NETWORK", "AC": "NETWORK", "PR": "LOW", "UI": "NONE", "S": "CHANGED", "C": "HIGH", "I": "NONE", "A": "NONE", "commit_id": "41bd3645bdb616e1248b2167ca83636a2653f781", "commit_message": "secure path hotfix", "commit_date": "2021-12-14T21:01:55Z", "project": "gradio-app/gradio", "url": "https://api.github.com/repos/gradio-app/gradio/commits/41bd3645bdb616e1248b2167ca83636a2653f781", "html_url": "https://github.com/gradio-app/gradio/commit/41bd3645bdb616e1248b2167ca83636a2653f781", "windows_before": [{"commit_id": "0b2c4901a63b2e5a7d7b3964d27b8f82d6d330e1", "commit_date": "Tue Dec 14 18:57:16 2021 +0000", "commit_message": "updated PyPi version", "files_name": ["gradio.egg-info/PKG-INFO", "gradio/version.txt", "setup.py"]}, {"commit_id": "fba164d4f4682cef7fe5dd69dc5c3e3ce463904a", "commit_date": "Tue Dec 14 12:32:33 2021 -0600", "commit_message": "Create SECURITY.md", "files_name": ["SECURITY.md"]}, {"commit_id": "30f57eec26b52ebf6ef807b187d75a1376a87b4f", "commit_date": "Tue Dec 14 17:55:54 2021 +0100", "commit_message": "handling reserved ip address to bind to all network interfaces #382", "files_name": ["gradio/networking.py"]}, {"commit_id": "0abfe9c60d35ef38ce7abcfc23b3c097cec84135", "commit_date": "Tue Dec 14 10:13:04 2021 -0600", "commit_message": "networking start server", "files_name": ["gradio/networking.py"]}, {"commit_id": "b0d6e5ebd98ab94f62d9b10eb014e7ba5aa93e1c", "commit_date": "Tue Dec 14 10:12:34 2021 -0600", "commit_message": "Merge branch 'master' into abidlabs/url", "files_name": ["af0100f52f4e4c7ceca39d3a51973f35c92ef441 - Tue Dec 14 10:09:21 2021 -0600 : working on refactoring server_name and server_port", "gradio/interface.py"]}, {"commit_id": "6fcfe8c21d1fd69e1e39824681f57ea88b38530b", "commit_date": "Tue Dec 14 10:08:25 2021 -0600", "commit_message": "reverted back start server port parameter", "files_name": ["gradio/networking.py"]}, {"commit_id": "719d107d87abc472cb601f1374a25fbf25adf061", "commit_date": "Tue Dec 14 10:00:10 2021 -0600", "commit_message": "fixed static file issue", "files_name": ["gradio/networking.py"]}, {"commit_id": "94a5b745dbe8cca1e733f1b02c57c71ad2e3231a", "commit_date": "Tue Dec 14 08:14:57 2021 -0600", "commit_message": "Merge pull request #406 from haby0/patch-1", "files_name": ["f9378ba57ff573c520644831fb4bc3c21204965f - Mon Dec 13 22:31:52 2021 -0800 : Update README.md", "website/README.md"]}, {"commit_id": "4bd50ea548dbdfe04ecfba4b45770b63fd57b70e", "commit_date": "Mon Dec 13 22:31:22 2021 -0800", "commit_message": "Update website readme", "files_name": ["website/README.md"]}, {"commit_id": "8bdc59735f99635c76ea07f5ee4c6b622ab0d238", "commit_date": "Tue Dec 14 14:09:50 2021 +0800", "commit_message": "Fix arbitrary file reading vulnerabilities", "files_name": ["gradio/networking.py"]}, {"commit_id": "b4d982540975f1215ab82c3b99a9b2ca3b6f53c1", "commit_date": "Mon Dec 13 22:02:19 2021 -0800", "commit_message": "Website: WIP (#328)", "files_name": [".dockerignore", ".gitignore", "README.md", "demo/calculator/run.py", "demo/calculator/screenshot.gif", "demo/calculator_live/run.py", "demo/calculator_live/screenshot.gif", "demo/chatbot/run.py", "demo/chatbot/screenshot.gif", "demo/diff_texts/run.py", "demo/diff_texts/screenshot.png", "demo/digit_classifier/requirements.txt", "demo/digit_classifier/run.py", "demo/digit_classifier/screenshot.png", "demo/disease_report/requirements.txt", "demo/disease_report/run.py", "demo/disease_report/screenshot.png", "demo/face_segment.py", "demo/files/timeseries.csv", "demo/files/video.avi", "demo/files/video.mp4", "demo/filter_records/run.py", "demo/filter_records/screenshot.png", "demo/form_graph/requirements.txt", "demo/form_graph/run.py", "demo/fraud_detector/requirements.txt", "demo/fraud_detector/run.py", "demo/fraud_detector/screenshot.png", "demo/gender_sentence_custom_interpretation/run.py", "demo/gender_sentence_custom_interpretation/screenshot.gif", "demo/gender_sentence_default_interpretation/run.py", "demo/gender_sentence_default_interpretation/screenshot.gif", "demo/generate_tone/requirements.txt", "demo/generate_tone/run.py", "demo/generate_tone/screenshot.png", "demo/gpt_j/run.py", "demo/hello_world/run.py", "demo/hello_world/screenshot.gif", "demo/hello_world/screenshot.png", "demo/hello_world_2/run.py", "demo/hello_world_2/screenshot.gif", "demo/hello_world_3/run.py", "demo/hello_world_3/screenshot.gif", "demo/image_classifier.py", "demo/image_classifier/files/imagenet_labels.json", "demo/image_classifier/images/cheetah1.jpg", "demo/image_classifier/images/lion.jpg", "demo/image_classifier/requirements.txt", "demo/image_classifier/run.py", "demo/image_classifier/screenshot.gif", "demo/image_classifier/screenshot.png", "demo/image_classifier_2/files/imagenet_labels.json", "demo/image_classifier_2/requirements.txt", "demo/image_classifier_2/run.py", "demo/image_classifier_interpretation/files/imagenet_labels.json", "demo/image_classifier_interpretation/images/cheetah1.jpg", "demo/image_classifier_interpretation/images/lion.jpg", "demo/image_classifier_interpretation/requirements.txt", "demo/image_classifier_interpretation/run.py", "demo/image_classifier_interpretation/screenshot.gif", "demo/image_classifier_interpretation/screenshot.png", "demo/image_mod/run.py", "demo/image_mod/screenshot.png", "demo/images/1.jpg", "demo/images/2.jpg", "demo/images/cheetah2.jpg", "demo/images/stop_1.jpg", "demo/images/stop_2.jpg", "demo/kitchen_sink/run.py", "demo/longest_word/run.py", "demo/main_note/audio/cantina.wav", "demo/main_note/audio/recording1.wav", "demo/main_note/requirements.txt", "demo/main_note/run.py", "demo/main_note/screenshot.png", "demo/matrix_transpose/requirements.txt", "demo/matrix_transpose/run.py", "demo/matrix_transpose/screenshot.png", "demo/outbreak_forecast/requirements.txt", "demo/outbreak_forecast/run.py", "demo/question_answer.py", "demo/question_answer/files/bert.py", "demo/question_answer/files/utils.py", "demo/question_answer/requirements.txt", "demo/question_answer/run.py", "demo/reverse_audio/audio/cantina.wav", "demo/reverse_audio/audio/recording1.wav", "demo/reverse_audio/run.py", "demo/reverse_audio/screenshot.png", "demo/sales_projections/requirements.txt", "demo/sales_projections/run.py", "demo/sales_projections/screenshot.gif", "demo/sentence_builder/run.py", "demo/sentence_builder/screenshot.png", "demo/sentiment_analysis/requirements.txt", "demo/sentiment_analysis/run.py", "demo/sepia_filter/run.py", "demo/sepia_filter/screenshot.gif", "demo/spectogram/requirements.txt", "demo/spectogram/run.py", "demo/spectogram/screenshot.png", "demo/stock_forecast/requirements.txt", "demo/stock_forecast/run.py", "demo/stock_forecast/screenshot.png", "demo/stop_sign_detection.py", "demo/tax_calculator/run.py", "demo/tax_calculator/screenshot.png", "demo/text_analysis/requirements.txt", "demo/text_analysis/run.py", "demo/text_analysis/screenshot.png", "demo/text_analysis/setup.sh", "demo/titanic_survival/files/titanic.csv", "demo/titanic_survival/requirements.txt", "demo/titanic_survival/run.py", "demo/titanic_survival/screenshot.png", "demo/utils/FCN8s_keras.py", "demo/utils/drive.py", "demo/utils/requirements.txt", "demo/video_flip/run.py", "demo/video_flip/screenshot.png", "demo/webcam/run.py", "demo/webcam/screenshot.png", "demo/zip_to_json/run.py", "demo/zip_to_json/screenshot.png", "demo/zip_two_files/files/titanic.csv", "demo/zip_two_files/run.py", "demo/zip_two_files/screenshot.png", "frontend/.dockerignore", "frontend/package-lock.json", "gradio/.dockerignore", "gradio/inputs.py", "gradio/outputs.py", "guides/getting_started.md", "guides/readme_template.md", "guides/working_with_ml.md", "readme_template.md", "render_readme.py", "test/test_demos.py", "test/test_files/cheetah1.jpg", "test/test_outputs.py", "website/.gitignore", "website/README.md", "website/demos/.gitignore", "website/demos/Dockerfile", "website/demos/map_demos.py", "website/demos/nginx_template.conf", "website/demos/requirements.txt", "website/demos/run_demos.py", "website/docker-compose.yml", "website/homepage/.dockerignore", "website/homepage/.gitignore", "website/homepage/Dockerfile", "website/homepage/README.md", "website/homepage/nginx.conf", "website/homepage/package-lock.json", "website/homepage/package.json", "website/homepage/postcss.config.js", "website/homepage/render_html.py", "website/homepage/replace_style_names.py", "website/homepage/requirements.txt", "website/homepage/src/assets/img/colab-badge.svg", "website/homepage/src/assets/img/gallery.png"]}], "windows_after": [{"commit_id": "a7a453602fa9f38d286f81df87c6b4b5dd9c5dd0", "commit_date": "Tue Dec 14 21:02:26 2021 +0000", "commit_message": "updated PyPi version", "files_name": ["gradio.egg-info/PKG-INFO", "setup.py"]}, {"commit_id": "160a0379890d33f948ae165f406fb7c6fcad1c9b", "commit_date": "Tue Dec 14 17:05:02 2021 -0600", "commit_message": "added test for checking if static files are served safely", "files_name": ["test/test_networking.py"]}, {"commit_id": "ebee87073235b798e81fba6760ed55c15727cf6c", "commit_date": "Tue Dec 14 18:37:17 2021 -0600", "commit_message": "Merge branch 'master' into cansik/reserved-ip", "files_name": ["b12ac1d935150111ae1f967c832b74320d6c5ac4 - Tue Dec 14 18:39:36 2021 -0600 : Merge pull request #408 from cansik/cansik/reserved-ip", "9151bff97dfd91d475c74f7bde48e87eee612276 - Tue Dec 14 18:40:41 2021 -0600 : Merge branch 'master' into abidlabs/url", "7a23e8f74819491828f94ade4e1c4f6785e2ae57 - Tue Dec 14 18:40:57 2021 -0600 : cleaning interface.py", "gradio/interface.py"]}, {"commit_id": "c798b971b227aa70d1953fb59bbd8da4b8a543f0", "commit_date": "Tue Dec 14 19:26:27 2021 -0600", "commit_message": "added docs for Interface class", "files_name": ["gradio/interface.py"]}, {"commit_id": "c39bbad459c8db1feba999bba7d184162452b74a", "commit_date": "Tue Dec 14 20:40:36 2021 -0600", "commit_message": "cleaned up interface.py", "files_name": ["gradio.egg-info/PKG-INFO", "gradio.egg-info/requires.txt", "gradio/interface.py"]}, {"commit_id": "13b3508a00d9de421748a1f1ed0792b7bdc494af", "commit_date": "Tue Dec 14 20:40:51 2021 -0600", "commit_message": "Merge branch 'master' into abidlabs/url", "files_name": ["ff0a0d02733aab53048ffb3a94b62511dc48d41d - Tue Dec 14 20:53:02 2021 -0600 : added readme badges", "README.md", "frontend/package-lock.json", "gradio/templates/frontend/asset-manifest.json", "gradio/templates/frontend/index.html", "guides/readme_template.md"]}, {"commit_id": "19a7935876fa7555b2bd9232b3fb49b6d058c8ff", "commit_date": "Wed Dec 15 02:54:09 2021 +0000", "commit_message": "Bump tmpl from 1.0.4 to 1.0.5 in /frontend", "files_name": ["frontend/package-lock.json"]}, {"commit_id": "18884c21f740aae74e22a150b6a905f879e5c625", "commit_date": "Wed Dec 15 02:54:10 2021 +0000", "commit_message": "Bump jsuites from 4.6.6 to 4.9.28 in /frontend", "files_name": ["frontend/package-lock.json"]}, {"commit_id": "ce9422f883c5597cc2d4479feee2a056315671b0", "commit_date": "Wed Dec 15 02:54:10 2021 +0000", "commit_message": "Bump tar from 6.1.0 to 6.1.11 in /frontend", "files_name": ["frontend/package-lock.json"]}, {"commit_id": "fd99d217c3d85a4527239ea8189d6a428bff133d", "commit_date": "Tue Dec 14 21:06:49 2021 -0600", "commit_message": "cleaning up interface.py", "files_name": ["gradio/interface.py"]}, {"commit_id": "97fc1d1dfd6b0aa0fa4f02a42c04db1968158179", "commit_date": "Thu Dec 16 08:24:24 2021 -0600", "commit_message": "cleaned up interface.py file", "files_name": ["gradio/external.py", "gradio/interface.py", "gradio/utils.py"]}, {"commit_id": "f65375b471418779eca7cf7be1d5c9158a6ff7f5", "commit_date": "Thu Dec 16 16:22:24 2021 +0100", "commit_message": "Added hers to list of female words", "files_name": ["demo/gender_sentence_custom_interpretation/run.py", "demo/gender_sentence_default_interpretation/run.py"]}, {"commit_id": "2a00d384a61365fe13a45b6caf9ba4765c021bc7", "commit_date": "Thu Dec 16 09:24:51 2021 -0600", "commit_message": "Merge pull request #415 from fiordiconio/master", "files_name": ["a422206e1f54d46652ce5028478cc95c51c110b8 - Thu Dec 16 09:33:21 2021 -0600 : Merge pull request #412 from gradio-app/dependabot/npm_and_yarn/frontend/jsuites-4.9.28", "6a9f2d9c72fa2755cf541c2a3ca6569d1cedfa63 - Thu Dec 16 09:33:33 2021 -0600 : Merge pull request #411 from gradio-app/dependabot/npm_and_yarn/frontend/tar-6.1.11", "341d2ce7a9ffb6ede69403332e9069b10ec70874 - Thu Dec 16 09:33:48 2021 -0600 : Merge pull request #410 from gradio-app/dependabot/npm_and_yarn/frontend/tmpl-1.0.5", "159cb88955279744574048f05a71323690869628 - Thu Dec 16 15:35:00 2021 +0000 : Bump dns-packet from 1.3.1 to 1.3.4 in /frontend", "frontend/package-lock.json"]}, {"commit_id": "e5b57cd5ecb932be9bbae0e2d16c08173f284cd0", "commit_date": "Thu Dec 16 09:35:23 2021 -0600", "commit_message": "Merge pull request #416 from gradio-app/dependabot/npm_and_yarn/frontend/dns-packet-1.3.4", "files_name": ["65417861498de0520c6f8ca7d4a2ea5f5255516f - Thu Dec 16 15:36:30 2021 +0000 : Bump url-parse from 1.5.1 to 1.5.3 in /frontend", "frontend/package-lock.json"]}, {"commit_id": "f19ebf8ad25b6be49a423d0487ba8480c84c27ac", "commit_date": "Thu Dec 16 15:36:32 2021 +0000", "commit_message": "Bump path-parse from 1.0.6 to 1.0.7 in /frontend", "files_name": ["frontend/package-lock.json"]}, {"commit_id": "8c7ddea492144c71e775ffb94e058c430953dd6b", "commit_date": "Thu Dec 16 09:37:35 2021 -0600", "commit_message": "Merge pull request #418 from gradio-app/dependabot/npm_and_yarn/frontend/path-parse-1.0.7", "files_name": ["ed1b2a3477634368fd956622f743fc99fe9b9b39 - Thu Dec 16 09:37:44 2021 -0600 : Merge pull request #417 from gradio-app/dependabot/npm_and_yarn/frontend/url-parse-1.5.3", "8dc11093b99dd13954ea42b47e3d49360909e530 - Thu Dec 16 09:43:31 2021 -0600 : significant cleanup and test fixes", "gradio/interface.py", "gradio/mix.py", "gradio/utils.py", "test/test_external.py", "test/test_interfaces.py", "test/test_utils.py"]}, {"commit_id": "8d5f55db18f459fba2f90eb425a61729931a3a7f", "commit_date": "Thu Dec 16 10:07:55 2021 -0600", "commit_message": "Merge pull request #409 from gradio-app/abidlabs/url", "files_name": ["d2f020d0dfc466db0470c4258a6c8907a87c3ade - Thu Dec 16 10:25:09 2021 -0600 : Update CONTRIBUTING.md", "CONTRIBUTING.md"]}, {"commit_id": "0a8e2e2992845e17f8a583ac2e0706dff1dacffa", "commit_date": "Thu Dec 16 10:29:05 2021 -0600", "commit_message": "Update CONTRIBUTING.md", "files_name": ["CONTRIBUTING.md"]}, {"commit_id": "598b28ba3f31039076b068860ce5b87da4121387", "commit_date": "Thu Dec 16 10:29:31 2021 -0600", "commit_message": "Update interface.py", "files_name": ["gradio/interface.py"]}, {"commit_id": "7ae192a3d0a2047c7217bdc20ac008622fef5932", "commit_date": "Thu Dec 16 10:41:16 2021 -0600", "commit_message": "interface cleanup", "files_name": ["gradio/interface.py"]}, {"commit_id": "031be6cca7deda6108dcf0f84a64de136d968b44", "commit_date": "Thu Dec 16 11:09:50 2021 -0600", "commit_message": "Update getting_started.md", "files_name": ["guides/getting_started.md"]}, {"commit_id": "0cf710cc6941b507bece00286afbce039e8bf773", "commit_date": "Thu Dec 16 17:15:23 2021 +0000", "commit_message": "acq announcement", "files_name": ["website/homepage/package-lock.json", "website/homepage/postcss.config.js", "website/homepage/render_html.py", "website/homepage/src/assets/img/acquisition_card.png", "website/homepage/src/assets/img/acquisition_screenshot.png", "website/homepage/src/docs_template.html", "website/homepage/src/guides_template.html", "website/homepage/src/index_template.html", "website/homepage/src/other_templates/acquisition_template.html"]}, {"commit_id": "55ad60585c491637e7214670ccc4bea979be008d", "commit_date": "Thu Dec 16 17:17:04 2021 +0000", "commit_message": "Merge branch 'master' of https://github.com/gradio-app/gradio", "files_name": ["9616892b0c6117d3ee168acbab8fce3ae6565c15 - Thu Dec 16 11:23:14 2021 -0600 : Update issue templates", ".github/ISSUE_TEMPLATE/bug_report.md"]}, {"commit_id": "e725ac90ed216bd7b76ce7954798d5a658cf0342", "commit_date": "Thu Dec 16 11:25:15 2021 -0600", "commit_message": "Update issue templates", "files_name": [".github/ISSUE_TEMPLATE/feature_request.md"]}, {"commit_id": "6be6df1d07f115c204626509a13679ecd0dd5dd2", "commit_date": "Thu Dec 16 11:25:56 2021 -0600", "commit_message": "Update SECURITY.md", "files_name": ["SECURITY.md"]}, {"commit_id": "388e5643a948ba9841d5ce0069038d1d751eb53f", "commit_date": "Thu Dec 16 11:31:48 2021 -0600", "commit_message": "added issue chooser to website", "files_name": ["gradio/interface.py", "website/homepage/src/docs_template.html", "website/homepage/src/guides_template.html", "website/homepage/src/index_template.html"]}, {"commit_id": "db67f751c44952beae787a39dbed8c95b48afe81", "commit_date": "Thu Dec 16 09:52:58 2021 -0800", "commit_message": "acq updates", "files_name": ["website/homepage/src/docs_template.html", "website/homepage/src/guides_template.html", "website/homepage/src/index_template.html", "website/homepage/src/other_templates/joining-huggingface_template.html", "website/upload_notebooks/run.py"]}, {"commit_id": "6e52b580a67c0840ed65dc94b4dc6f016f7184e0", "commit_date": "Thu Dec 16 09:53:17 2021 -0800", "commit_message": "Merge branch 'master' of https://github.com/gradio-app/gradio", "files_name": ["5f23f0f1cf739b319fcfb0a55d517eda93b38d5f - Thu Dec 16 11:56:43 2021 -0600 : Update joining-huggingface_template.html", "website/homepage/src/other_templates/joining-huggingface_template.html"]}, {"commit_id": "52f9460c286c7d43cd12492d300bf8d108fa7b48", "commit_date": "Thu Dec 16 18:01:36 2021 +0000", "commit_message": "updated PyPi version", "files_name": ["gradio.egg-info/PKG-INFO", "gradio.egg-info/requires.txt", "gradio/templates/frontend/asset-manifest.json", "gradio/templates/frontend/index.html", "gradio/version.txt", "setup.py"]}, {"commit_id": "e5c006da3a81ae76ff036db514d70de3001b7ac2", "commit_date": "Thu Dec 16 12:50:04 2021 -0800", "commit_message": "improve Dockerfile for website for quicker restarts", "files_name": ["website/demos/Dockerfile", "website/demos/run_demos.py", "website/homepage/Dockerfile", "website/homepage/src/docs_template.html", "website/homepage/src/guides_template.html", "website/homepage/src/index_template.html", "website/homepage/src/other_templates/joining-huggingface_template.html"]}, {"commit_id": "1925b9d02c769d02122a84bbdabecf032b33f631", "commit_date": "Thu Dec 16 12:52:34 2021 -0800", "commit_message": "Merge branch 'master' of https://github.com/gradio-app/gradio", "files_name": ["875840584afbf5476529676880c8e7b18bf93038 - Thu Dec 16 14:13:59 2021 -0800 : website fixes", "website/demos/run_demos.py", "website/homepage/src/other_templates/joining-huggingface_template.html"]}, {"commit_id": "789b4374dc0d5c1a633cb083b8e11c4b38ffaa25", "commit_date": "Thu Dec 16 15:08:27 2021 -0800", "commit_message": "autoreload website on changes", "files_name": ["website/reload_website.sh", "website/upload_notebooks/upload_notebooks.py"]}, {"commit_id": "56cd9952214a05ad831bee657241cf1519d39aa8", "commit_date": "Thu Dec 16 15:16:41 2021 -0800", "commit_message": "fix reload", "files_name": ["website/reload_website.sh"]}, {"commit_id": "ab04673b358ea37bc16e459a3a0d4bcc9efd0c56", "commit_date": "Thu Dec 16 15:18:48 2021 -0800", "commit_message": "Update README.md", "files_name": ["website/README.md"]}, {"commit_id": "8abd0ec4dfe8703cfcaf836300d499e539461f47", "commit_date": "Thu Dec 16 15:19:05 2021 -0800", "commit_message": "Merge branch 'master' of https://github.com/gradio-app/gradio", "files_name": ["de7bcdaa4482cf73a1f88f5bc8212f8ae8e122b7 - Thu Dec 16 15:26:55 2021 -0800 : Test change", "website/homepage/src/docs_template.html"]}, {"commit_id": "a41aea61a3524876be2e70c29f34a112da791268", "commit_date": "Thu Dec 16 15:30:02 2021 -0800", "commit_message": "Merge branch 'master' of https://github.com/gradio-app/gradio", "files_name": ["3ef1088d7adfc7ecf6aac4a3968c1cdbb64867b0 - Thu Dec 16 16:28:34 2021 -0800 : Test change", "website/homepage/src/docs_template.html"]}, {"commit_id": "35e8499a846517a6a8f2d9e98f26adc60592219a", "commit_date": "Thu Dec 16 16:43:09 2021 -0800", "commit_message": "Update docs_template.html", "files_name": ["website/homepage/src/docs_template.html"]}, {"commit_id": "4ed65722935f7d7b52601cbc4ca67af5769ad8fc", "commit_date": "Thu Dec 16 16:55:31 2021 -0800", "commit_message": "Update docs_template.html", "files_name": ["website/homepage/src/docs_template.html"]}, {"commit_id": "d4f9142d788e9189bd581aa73db08a54ac17750a", "commit_date": "Thu Dec 16 17:05:52 2021 -0800", "commit_message": "Update docs_template.html", "files_name": ["website/homepage/src/docs_template.html"]}, {"commit_id": "1e6c71f591e3d135c552dd911ae95b86ba1ae892", "commit_date": "Thu Dec 16 17:17:49 2021 -0800", "commit_message": "Update docs_template.html", "files_name": ["website/homepage/src/docs_template.html"]}, {"commit_id": "f26fa6a0717443e1bdc76d3258ed89798574c24d", "commit_date": "Thu Dec 16 19:41:14 2021 -0800", "commit_message": "fix website reloader", "files_name": ["website/reload_website.sh"]}, {"commit_id": "b10decc63568e06795b8a051f7cbe113b76d669f", "commit_date": "Fri Dec 17 03:54:02 2021 +0000", "commit_message": "fix acquisition page", "files_name": ["website/homepage/src/other_templates/joining-huggingface_template.html"]}, {"commit_id": "8d23f067a22bd9099a4f96ec510bd40d624546f4", "commit_date": "Fri Dec 17 10:52:19 2021 +0000", "commit_message": "theme-preview", "files_name": ["demo/kitchen_sink/files/cantina.wav", "demo/kitchen_sink/files/cheetah1.jpg", "demo/kitchen_sink/files/titanic.csv", "demo/kitchen_sink/run.py", "website/demos/map_demos.py", "website/homepage/src/other_templates/theme-preview_template.html"]}, {"commit_id": "9d54d13d54bea63786d54ef67d1696402ad4eb11", "commit_date": "Fri Dec 17 10:43:11 2021 -0600", "commit_message": "allows you to fix port; deprecates server_port, server_name parameters in Interface()", "files_name": ["gradio/interface.py", "gradio/networking.py"]}], "parents": [{"commit_id_before": "0b2c4901a63b2e5a7d7b3964d27b8f82d6d330e1", "url_before": "https://api.github.com/repos/gradio-app/gradio/commits/0b2c4901a63b2e5a7d7b3964d27b8f82d6d330e1", "html_url_before": "https://github.com/gradio-app/gradio/commit/0b2c4901a63b2e5a7d7b3964d27b8f82d6d330e1"}], "details": [{"raw_url": "https://github.com/gradio-app/gradio/raw/41bd3645bdb616e1248b2167ca83636a2653f781/gradio%2Fnetworking.py", "code": "\"\"\"\nDefines helper methods useful for setting up ports, launching servers, and handling `ngrok`\n\"\"\"\n\nimport os\nimport socket\nimport threading\nfrom flask import Flask, request, session, jsonify, abort, send_file, render_template, redirect\nfrom flask_cachebuster import CacheBuster\nfrom flask_login import LoginManager, login_user, current_user, login_required\nfrom flask_cors import CORS\nimport threading\nimport pkg_resources\nimport datetime\nimport time\nimport json\nimport urllib.request\nfrom shutil import copyfile\nimport requests\nimport sys\nimport csv\nimport logging\nfrom gradio.tunneling import create_tunnel\nfrom gradio import encryptor\nfrom gradio import queue\nfrom functools import wraps\nimport io\nimport inspect\nimport traceback\nfrom werkzeug.security import safe_join\n\nINITIAL_PORT_VALUE = int(os.getenv(\n    'GRADIO_SERVER_PORT', \"7860\"))  # The http server will try to open on port 7860. If not available, 7861, 7862, etc.\nTRY_NUM_PORTS = int(os.getenv(\n    'GRADIO_NUM_PORTS', \"100\"))  # Number of ports to try before giving up and throwing an exception.\nLOCALHOST_NAME = os.getenv(\n    'GRADIO_SERVER_NAME', \"127.0.0.1\")\nGRADIO_API_SERVER = \"https://api.gradio.app/v1/tunnel-request\"\nGRADIO_FEATURE_ANALYTICS_URL = \"https://api.gradio.app/gradio-feature-analytics/\"\n\nSTATIC_TEMPLATE_LIB = pkg_resources.resource_filename(\"gradio\", \"templates/\")\nSTATIC_PATH_LIB = pkg_resources.resource_filename(\"gradio\", \"templates/frontend/static\")\nVERSION_FILE = pkg_resources.resource_filename(\"gradio\", \"version.txt\")\nwith open(VERSION_FILE) as version_file:\n    GRADIO_STATIC_ROOT = \"https://gradio.s3-us-west-2.amazonaws.com/\" + \\\n        version_file.read().strip() + \"/static/\"\n\napp = Flask(__name__,\n            template_folder=STATIC_TEMPLATE_LIB,\n            static_folder=\"\",\n            static_url_path=\"/none/\")\napp.url_map.strict_slashes = False\n\nCORS(app)\ncache_buster = CacheBuster(\n    config={'extensions': ['.js', '.css'], 'hash_size': 5})\ncache_buster.init_app(app)\napp.secret_key = os.getenv(\"GRADIO_KEY\", \"secret\")\nlogin_manager = LoginManager()\nlogin_manager.login_view = 'login'\nlogin_manager.init_app(app)\n\n# Hide Flask default message\ncli = sys.modules['flask.cli']\ncli.show_server_banner = lambda *x: None\n\n\nclass User:\n    def __init__(self, id):\n        self.is_authenticated = True\n        self.is_active = True\n        self.is_anonymous = False\n        self.id = id\n\n    def get_id(self):\n        return self.id\n\n\n@login_manager.user_loader\ndef load_user(_id):\n    return User(_id)\n\n\ndef login_check(func):\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n        if app.auth:\n            @login_required\n            def func2(*args, **kwargs):\n                return func(*args, **kwargs)\n\n            return func2(*args, **kwargs)\n        else:\n            return func(*args, **kwargs)\n    return wrapper\n\n\ndef get_local_ip_address():\n    try:\n        ip_address = requests.get('https://api.ipify.org', timeout=3).text\n    except (requests.ConnectionError, requests.exceptions.ReadTimeout):\n        ip_address = \"No internet connection\"\n    return ip_address\n\n\nIP_ADDRESS = get_local_ip_address()\n\n\ndef get_first_available_port(initial, final):\n    \"\"\"\n    Gets the first open port in a specified range of port numbers\n    :param initial: the initial value in the range of port numbers\n    :param final: final (exclusive) value in the range of port numbers, should be greater than `initial`\n    :return:\n    \"\"\"\n    for port in range(initial, final):\n        try:\n            s = socket.socket()  # create a socket object\n            s.bind((LOCALHOST_NAME, port))  # Bind to the port\n            s.close()\n            return port\n        except OSError:\n            pass\n    raise OSError(\n        \"All ports from {} to {} are in use. Please close a port.\".format(\n            initial, final\n        )\n    )\n\n\n@app.route(\"/\", methods=[\"GET\"])\n@login_check\ndef main():\n    session[\"state\"] = None\n    return render_template(\"frontend/index.html\", config=app.interface.config)\n\n\n@app.route(\"/static/<path:path>\", methods=[\"GET\"])\ndef static_resource(path):\n    if app.interface.share:\n        return redirect(GRADIO_STATIC_ROOT + path)\n    else:\n        return send_file(safe_join(STATIC_PATH_LIB, path))\n\n\n# TODO(@aliabid94): this throws a 500 error if app.auth is None (should probalbly just redirect to '/')\n@app.route('/login', methods=[\"GET\", \"POST\"])\ndef login():\n    if request.method == \"GET\":\n        config = get_config()\n        return render_template(\"frontend/index.html\", config=config)\n    elif request.method == \"POST\":\n        username = request.form.get(\"username\")\n        password = request.form.get(\"password\")\n        if ((not callable(app.auth) and username in app.auth and app.auth[username] == password)\n                or (callable(app.auth) and app.auth.__call__(username, password))):\n            login_user(User(username))\n            return redirect(\"/\")\n        else:\n            return abort(401)\n\n\n@app.route(\"/config/\", methods=[\"GET\"])\ndef get_config():\n    if app.interface.auth is None or current_user.is_authenticated:\n        return jsonify(app.interface.config)\n    else:\n        return {\"auth_required\": True, \"auth_message\": app.interface.auth_message}\n\n\n@app.route(\"/enable_sharing/<path:path>\", methods=[\"GET\"])\n@login_check\ndef enable_sharing(path):\n    if path == \"None\":\n        path = None\n    app.interface.config[\"share_url\"] = path\n    return jsonify(success=True)\n\n\n@app.route(\"/shutdown\", methods=['GET'])\ndef shutdown():\n    shutdown_func = request.environ.get('werkzeug.server.shutdown')\n    if shutdown_func is None:\n        raise RuntimeError('Not running werkzeug')\n    shutdown_func()\n    return \"Shutting down...\"\n\n\n@app.route(\"/api/predict/\", methods=[\"POST\"])\n@login_check\ndef predict():\n    raw_input = request.json[\"data\"]\n    # Capture any errors made and pipe to front end\n    if app.interface.show_error:\n        try:\n            prediction, durations = app.interface.process(raw_input)\n        except BaseException as error:\n            traceback.print_exc()\n            return jsonify({\"error\": str(error)}), 500\n    else:\n        prediction, durations = app.interface.process(raw_input)\n    avg_durations = []\n    for i, duration in enumerate(durations):\n        app.interface.predict_durations[i][0] += duration\n        app.interface.predict_durations[i][1] += 1\n        avg_durations.append(app.interface.predict_durations[i][0] \n            / app.interface.predict_durations[i][1])\n    app.interface.config[\"avg_durations\"] = avg_durations\n    output = {\"data\": prediction, \"durations\": durations, \"avg_durations\": avg_durations}\n    if app.interface.allow_flagging == \"auto\":\n        try:\n            flag_index = flag_data(raw_input, prediction, \n                flag_option=(None if app.interface.flagging_options is None else \"\"), \n                username=current_user.id if current_user.is_authenticated else None)\n            output[\"flag_index\"] = flag_index\n        except Exception as e:\n            print(str(e))\n            pass\n    return jsonify(output)\n\n\ndef get_types(cls_set, component):\n    docset = []\n    types = []\n    if component == \"input\":\n        for cls in cls_set:\n            doc = inspect.getdoc(cls.preprocess)\n            doc_lines = doc.split(\"\\n\")\n            docset.append(doc_lines[1].split(\":\")[-1])\n            types.append(doc_lines[1].split(\")\")[0].split(\"(\")[-1])\n    else:\n        for cls in cls_set:\n            doc = inspect.getdoc(cls.postprocess)\n            doc_lines = doc.split(\"\\n\")\n            docset.append(doc_lines[-1].split(\":\")[-1])\n            types.append(doc_lines[-1].split(\")\")[0].split(\"(\")[-1])\n    return docset, types\n\n\n@app.route(\"/api/\", methods=[\"GET\"])\ndef api_docs():\n    inputs = [type(inp) for inp in app.interface.input_components]\n    outputs = [type(out) for out in app.interface.output_components]\n    input_types_doc, input_types = get_types(inputs, \"input\")\n    output_types_doc, output_types = get_types(outputs, \"output\")\n    input_names = [type(inp).__name__ for inp in app.interface.input_components]\n    output_names = [type(out).__name__ for out in app.interface.output_components]\n    sample_inputs = [inp.generate_sample() for inp in app.interface.input_components]\n    docs = {\n        \"inputs\": input_names,\n        \"outputs\": output_names,\n        \"len_inputs\": len(inputs),\n        \"len_outputs\": len(outputs),\n        \"inputs_lower\": [name.lower() for name in input_names],\n        \"outputs_lower\": [name.lower() for name in output_names],\n        \"input_types\": input_types,\n        \"output_types\": output_types,\n        \"input_types_doc\": input_types_doc,\n        \"output_types_doc\": output_types_doc,\n        \"sample_inputs\": sample_inputs\n    }\n    return render_template(\"api_docs.html\", **docs)\n\n\ndef log_feature_analytics(feature):\n    if app.interface.analytics_enabled:\n        try:\n            requests.post(GRADIO_FEATURE_ANALYTICS_URL,\n                          data={\n                              'ip_address': IP_ADDRESS,\n                              'feature': feature}, timeout=3)\n        except (requests.ConnectionError, requests.exceptions.ReadTimeout):\n            pass  # do not push analytics if no network\n\n\ndef flag_data(input_data, output_data, flag_option=None, flag_index=None, username=None, flag_path=None):\n    if flag_path is None:\n        flag_path = os.path.join(app.cwd, app.interface.flagging_dir)\n    log_fp = \"{}/log.csv\".format(flag_path)\n    encryption_key = app.interface.encryption_key if app.interface.encrypt else None\n    is_new = not os.path.exists(log_fp)\n\n    if flag_index is None:\n        csv_data = []\n        for i, interface in enumerate(app.interface.input_components):\n            csv_data.append(interface.save_flagged(\n                flag_path, app.interface.config[\"input_components\"][i][\"label\"], input_data[i], encryption_key))\n        for i, interface in enumerate(app.interface.output_components):\n            csv_data.append(interface.save_flagged(\n                flag_path, app.interface.config[\"output_components\"][i][\"label\"], output_data[i], encryption_key) if output_data[i] is not None else \"\")\n        if flag_option is not None:\n            csv_data.append(flag_option)\n        if username is not None:\n            csv_data.append(username)\n        csv_data.append(str(datetime.datetime.now()))\n        if is_new:\n            headers = [interface[\"label\"]\n                    for interface in app.interface.config[\"input_components\"]]\n            headers += [interface[\"label\"]\n                        for interface in app.interface.config[\"output_components\"]]\n            if app.interface.flagging_options is not None:\n                headers.append(\"flag\")\n            if username is not None:\n                headers.append(\"username\")\n            headers.append(\"timestamp\")\n\n    def replace_flag_at_index(file_content):\n        file_content = io.StringIO(file_content)\n        content = list(csv.reader(file_content))\n        header = content[0]\n        flag_col_index = header.index(\"flag\")\n        content[flag_index][flag_col_index] = flag_option\n        output = io.StringIO()\n        writer = csv.writer(output)\n        writer.writerows(content)\n        return output.getvalue()\n\n    if app.interface.encrypt:\n        output = io.StringIO()\n        if not is_new:\n            with open(log_fp, \"rb\") as csvfile:\n                encrypted_csv = csvfile.read()\n                decrypted_csv = encryptor.decrypt(\n                    app.interface.encryption_key, encrypted_csv)\n                file_content = decrypted_csv.decode()\n                if flag_index is not None:\n                    file_content = replace_flag_at_index(file_content)\n                output.write(file_content)\n        writer = csv.writer(output)\n        if flag_index is None:\n            if is_new:\n                writer.writerow(headers)\n            writer.writerow(csv_data)\n        with open(log_fp, \"wb\") as csvfile:\n            csvfile.write(encryptor.encrypt(\n                app.interface.encryption_key, output.getvalue().encode()))\n    else:\n        if flag_index is None:\n            with open(log_fp, \"a\", newline=\"\") as csvfile:\n                writer = csv.writer(csvfile)\n                if is_new:\n                    writer.writerow(headers)\n                writer.writerow(csv_data)\n        else:\n            with open(log_fp) as csvfile:\n                file_content = csvfile.read()\n                file_content = replace_flag_at_index(file_content)\n            with open(log_fp, \"w\", newline=\"\") as csvfile:  # newline parameter needed for Windows\n                csvfile.write(file_content)\n    with open(log_fp, \"r\") as csvfile:\n        line_count = len([None for row in csv.reader(csvfile)]) - 1\n    return line_count\n\n@app.route(\"/api/flag/\", methods=[\"POST\"])\n@login_check\ndef flag():\n    log_feature_analytics('flag')\n    data = request.json['data']\n    flag_data(data['input_data'], data['output_data'], data.get(\"flag_option\"), data.get(\"flag_index\"), \n        current_user.id if current_user.is_authenticated else None)\n    return jsonify(success=True)\n\n\n@app.route(\"/api/interpret/\", methods=[\"POST\"])\n@login_check\ndef interpret():\n    log_feature_analytics('interpret')\n    raw_input = request.json[\"data\"]\n    interpretation_scores, alternative_outputs = app.interface.interpret(\n        raw_input)\n    return jsonify({\n        \"interpretation_scores\": interpretation_scores,\n        \"alternative_outputs\": alternative_outputs\n    })\n\n\n@app.route(\"/file/<path:path>\", methods=[\"GET\"])\n@login_check\ndef file(path):\n    if app.interface.encrypt and isinstance(app.interface.examples, str) and path.startswith(app.interface.examples):\n        with open(safe_join(app.cwd, path), \"rb\") as encrypted_file:\n            encrypted_data = encrypted_file.read()\n        file_data = encryptor.decrypt(\n            app.interface.encryption_key, encrypted_data)\n        return send_file(io.BytesIO(file_data), attachment_filename=os.path.basename(path))\n    else:\n        return send_file(safe_join(app.cwd, path))\n\n\n@app.route(\"/api/queue/push/\", methods=[\"POST\"])\n@login_check\ndef queue_push():\n    data = request.json[\"data\"]\n    action = request.json[\"action\"]\n    job_hash, queue_position = queue.push({\"data\": data}, action)\n    return {\"hash\": job_hash, \"queue_position\": queue_position}\n\n\n@app.route(\"/api/queue/status/\", methods=[\"POST\"])\n@login_check\ndef queue_status():\n    hash = request.json['hash']\n    status, data = queue.get_status(hash)\n    return {\"status\": status, \"data\": data}\n\n\ndef queue_thread(path_to_local_server, test_mode=False):\n    while True:\n        try:\n            next_job = queue.pop()\n            if next_job is not None:\n                _, hash, input_data, task_type = next_job\n                queue.start_job(hash)\n                response = requests.post(\n                    path_to_local_server + \"/api/\" + task_type + \"/\", json=input_data)\n                if response.status_code == 200:\n                    queue.pass_job(hash, response.json())\n                else:\n                    queue.fail_job(hash, response.text)\n            else:\n                time.sleep(1)\n        except Exception as e:\n            time.sleep(1)\n            pass\n        if test_mode:\n            break\n\n\ndef start_server(interface, server_name, server_port=None, auth=None, ssl=None):\n    if server_port is None:\n        server_port = INITIAL_PORT_VALUE\n    port = get_first_available_port(\n        server_port, server_port + TRY_NUM_PORTS\n    )\n    path_to_local_server = \"http://{}:{}/\".format(server_name, port)\n    if auth is not None:\n        if not callable(auth):\n            app.auth = {account[0]: account[1] for account in auth}\n        else:\n            app.auth = auth\n    else:\n        app.auth = None\n    app.interface = interface\n    app.cwd = os.getcwd()\n    log = logging.getLogger('werkzeug')\n    log.setLevel(logging.ERROR)\n    if app.interface.enable_queue:\n        if auth is not None or app.interface.encrypt:\n            raise ValueError(\"Cannot queue with encryption or authentication enabled.\")\n        queue.init()\n        app.queue_thread = threading.Thread(target=queue_thread, args=(path_to_local_server,))\n        app.queue_thread.start()\n    if interface.save_to is not None:\n        interface.save_to[\"port\"] = port\n    app_kwargs = {\"port\": port, \"host\": server_name}\n    if ssl:\n        app_kwargs[\"ssl_context\"] = ssl\n    thread = threading.Thread(target=app.run,\n                              kwargs=app_kwargs,\n                              daemon=True)\n    thread.start()\n\n    return port, path_to_local_server, app, thread\n\ndef get_state():\n    return session.get(\"state\")\n\ndef set_state(value):\n    session[\"state\"] = value\n\ndef close_server(process):\n    process.terminate()\n    process.join()\n\n\ndef url_request(url):\n    try:\n        req = urllib.request.Request(\n            url=url, headers={\"content-type\": \"application/json\"}\n        )\n        res = urllib.request.urlopen(req, timeout=10)\n        return res\n    except Exception as e:\n        raise RuntimeError(str(e))\n\n\ndef setup_tunnel(local_server_port, endpoint):\n    response = url_request(\n        endpoint + '/v1/tunnel-request' if endpoint is not None else GRADIO_API_SERVER)\n    if response and response.code == 200:\n        try:\n            payload = json.loads(response.read().decode(\"utf-8\"))[0]\n            return create_tunnel(payload, LOCALHOST_NAME, local_server_port)\n\n        except Exception as e:\n            raise RuntimeError(str(e))\n\n\ndef url_ok(url):\n    try:\n        for _ in range(5):\n            time.sleep(.500)\n            r = requests.head(url, timeout=3)\n            if r.status_code in (200, 401, 302):  # 401 or 302 if auth is set\n                return True\n    except (ConnectionError, requests.exceptions.ConnectionError):\n        return False\n", "code_before": "\"\"\"\nDefines helper methods useful for setting up ports, launching servers, and handling `ngrok`\n\"\"\"\n\nimport os\nimport socket\nimport threading\nfrom flask import Flask, request, session, jsonify, abort, send_file, render_template, redirect\nfrom flask_cachebuster import CacheBuster\nfrom flask_login import LoginManager, login_user, current_user, login_required\nfrom flask_cors import CORS\nimport threading\nimport pkg_resources\nimport datetime\nimport time\nimport json\nimport urllib.request\nfrom shutil import copyfile\nimport requests\nimport sys\nimport csv\nimport logging\nfrom gradio.tunneling import create_tunnel\nfrom gradio import encryptor\nfrom gradio import queue\nfrom functools import wraps\nimport io\nimport inspect\nimport traceback\nfrom werkzeug.security import safe_join\n\nINITIAL_PORT_VALUE = int(os.getenv(\n    'GRADIO_SERVER_PORT', \"7860\"))  # The http server will try to open on port 7860. If not available, 7861, 7862, etc.\nTRY_NUM_PORTS = int(os.getenv(\n    'GRADIO_NUM_PORTS', \"100\"))  # Number of ports to try before giving up and throwing an exception.\nLOCALHOST_NAME = os.getenv(\n    'GRADIO_SERVER_NAME', \"127.0.0.1\")\nGRADIO_API_SERVER = \"https://api.gradio.app/v1/tunnel-request\"\nGRADIO_FEATURE_ANALYTICS_URL = \"https://api.gradio.app/gradio-feature-analytics/\"\n\nSTATIC_TEMPLATE_LIB = pkg_resources.resource_filename(\"gradio\", \"templates/\")\nSTATIC_PATH_LIB = pkg_resources.resource_filename(\"gradio\", \"templates/frontend/static\")\nVERSION_FILE = pkg_resources.resource_filename(\"gradio\", \"version.txt\")\nwith open(VERSION_FILE) as version_file:\n    GRADIO_STATIC_ROOT = \"https://gradio.s3-us-west-2.amazonaws.com/\" + \\\n        version_file.read().strip() + \"/static/\"\n\napp = Flask(__name__,\n            template_folder=STATIC_TEMPLATE_LIB,\n            static_folder=\"\",\n            static_url_path=\"/none/\")\napp.url_map.strict_slashes = False\n\nCORS(app)\ncache_buster = CacheBuster(\n    config={'extensions': ['.js', '.css'], 'hash_size': 5})\ncache_buster.init_app(app)\napp.secret_key = os.getenv(\"GRADIO_KEY\", \"secret\")\nlogin_manager = LoginManager()\nlogin_manager.login_view = 'login'\nlogin_manager.init_app(app)\n\n# Hide Flask default message\ncli = sys.modules['flask.cli']\ncli.show_server_banner = lambda *x: None\n\n\nclass User:\n    def __init__(self, id):\n        self.is_authenticated = True\n        self.is_active = True\n        self.is_anonymous = False\n        self.id = id\n\n    def get_id(self):\n        return self.id\n\n\n@login_manager.user_loader\ndef load_user(_id):\n    return User(_id)\n\n\ndef login_check(func):\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n        if app.auth:\n            @login_required\n            def func2(*args, **kwargs):\n                return func(*args, **kwargs)\n\n            return func2(*args, **kwargs)\n        else:\n            return func(*args, **kwargs)\n    return wrapper\n\n\ndef get_local_ip_address():\n    try:\n        ip_address = requests.get('https://api.ipify.org', timeout=3).text\n    except (requests.ConnectionError, requests.exceptions.ReadTimeout):\n        ip_address = \"No internet connection\"\n    return ip_address\n\n\nIP_ADDRESS = get_local_ip_address()\n\n\ndef get_first_available_port(initial, final):\n    \"\"\"\n    Gets the first open port in a specified range of port numbers\n    :param initial: the initial value in the range of port numbers\n    :param final: final (exclusive) value in the range of port numbers, should be greater than `initial`\n    :return:\n    \"\"\"\n    for port in range(initial, final):\n        try:\n            s = socket.socket()  # create a socket object\n            s.bind((LOCALHOST_NAME, port))  # Bind to the port\n            s.close()\n            return port\n        except OSError:\n            pass\n    raise OSError(\n        \"All ports from {} to {} are in use. Please close a port.\".format(\n            initial, final\n        )\n    )\n\n\n@app.route(\"/\", methods=[\"GET\"])\n@login_check\ndef main():\n    session[\"state\"] = None\n    return render_template(\"frontend/index.html\", config=app.interface.config)\n\n\n@app.route(\"/static/<path:path>\", methods=[\"GET\"])\ndef static_resource(path):\n    if app.interface.share:\n        return redirect(GRADIO_STATIC_ROOT + path)\n    else:\n        return send_file(safe_join(STATIC_PATH_LIB, path))\n\n\n# TODO(@aliabid94): this throws a 500 error if app.auth is None (should probalbly just redirect to '/')\n@app.route('/login', methods=[\"GET\", \"POST\"])\ndef login():\n    if request.method == \"GET\":\n        config = get_config()\n        return render_template(\"frontend/index.html\", config=config)\n    elif request.method == \"POST\":\n        username = request.form.get(\"username\")\n        password = request.form.get(\"password\")\n        if ((not callable(app.auth) and username in app.auth and app.auth[username] == password)\n                or (callable(app.auth) and app.auth.__call__(username, password))):\n            login_user(User(username))\n            return redirect(\"/\")\n        else:\n            return abort(401)\n\n\n@app.route(\"/config/\", methods=[\"GET\"])\ndef get_config():\n    if app.interface.auth is None or current_user.is_authenticated:\n        return jsonify(app.interface.config)\n    else:\n        return {\"auth_required\": True, \"auth_message\": app.interface.auth_message}\n\n\n@app.route(\"/enable_sharing/<path:path>\", methods=[\"GET\"])\n@login_check\ndef enable_sharing(path):\n    if path == \"None\":\n        path = None\n    app.interface.config[\"share_url\"] = path\n    return jsonify(success=True)\n\n\n@app.route(\"/shutdown\", methods=['GET'])\ndef shutdown():\n    shutdown_func = request.environ.get('werkzeug.server.shutdown')\n    if shutdown_func is None:\n        raise RuntimeError('Not running werkzeug')\n    shutdown_func()\n    return \"Shutting down...\"\n\n\n@app.route(\"/api/predict/\", methods=[\"POST\"])\n@login_check\ndef predict():\n    raw_input = request.json[\"data\"]\n    # Capture any errors made and pipe to front end\n    if app.interface.show_error:\n        try:\n            prediction, durations = app.interface.process(raw_input)\n        except BaseException as error:\n            traceback.print_exc()\n            return jsonify({\"error\": str(error)}), 500\n    else:\n        prediction, durations = app.interface.process(raw_input)\n    avg_durations = []\n    for i, duration in enumerate(durations):\n        app.interface.predict_durations[i][0] += duration\n        app.interface.predict_durations[i][1] += 1\n        avg_durations.append(app.interface.predict_durations[i][0] \n            / app.interface.predict_durations[i][1])\n    app.interface.config[\"avg_durations\"] = avg_durations\n    output = {\"data\": prediction, \"durations\": durations, \"avg_durations\": avg_durations}\n    if app.interface.allow_flagging == \"auto\":\n        try:\n            flag_index = flag_data(raw_input, prediction, \n                flag_option=(None if app.interface.flagging_options is None else \"\"), \n                username=current_user.id if current_user.is_authenticated else None)\n            output[\"flag_index\"] = flag_index\n        except Exception as e:\n            print(str(e))\n            pass\n    return jsonify(output)\n\n\ndef get_types(cls_set, component):\n    docset = []\n    types = []\n    if component == \"input\":\n        for cls in cls_set:\n            doc = inspect.getdoc(cls.preprocess)\n            doc_lines = doc.split(\"\\n\")\n            docset.append(doc_lines[1].split(\":\")[-1])\n            types.append(doc_lines[1].split(\")\")[0].split(\"(\")[-1])\n    else:\n        for cls in cls_set:\n            doc = inspect.getdoc(cls.postprocess)\n            doc_lines = doc.split(\"\\n\")\n            docset.append(doc_lines[-1].split(\":\")[-1])\n            types.append(doc_lines[-1].split(\")\")[0].split(\"(\")[-1])\n    return docset, types\n\n\n@app.route(\"/api/\", methods=[\"GET\"])\ndef api_docs():\n    inputs = [type(inp) for inp in app.interface.input_components]\n    outputs = [type(out) for out in app.interface.output_components]\n    input_types_doc, input_types = get_types(inputs, \"input\")\n    output_types_doc, output_types = get_types(outputs, \"output\")\n    input_names = [type(inp).__name__ for inp in app.interface.input_components]\n    output_names = [type(out).__name__ for out in app.interface.output_components]\n    sample_inputs = [inp.generate_sample() for inp in app.interface.input_components]\n    docs = {\n        \"inputs\": input_names,\n        \"outputs\": output_names,\n        \"len_inputs\": len(inputs),\n        \"len_outputs\": len(outputs),\n        \"inputs_lower\": [name.lower() for name in input_names],\n        \"outputs_lower\": [name.lower() for name in output_names],\n        \"input_types\": input_types,\n        \"output_types\": output_types,\n        \"input_types_doc\": input_types_doc,\n        \"output_types_doc\": output_types_doc,\n        \"sample_inputs\": sample_inputs\n    }\n    return render_template(\"api_docs.html\", **docs)\n\n\ndef log_feature_analytics(feature):\n    if app.interface.analytics_enabled:\n        try:\n            requests.post(GRADIO_FEATURE_ANALYTICS_URL,\n                          data={\n                              'ip_address': IP_ADDRESS,\n                              'feature': feature}, timeout=3)\n        except (requests.ConnectionError, requests.exceptions.ReadTimeout):\n            pass  # do not push analytics if no network\n\n\ndef flag_data(input_data, output_data, flag_option=None, flag_index=None, username=None, flag_path=None):\n    if flag_path is None:\n        flag_path = os.path.join(app.cwd, app.interface.flagging_dir)\n    log_fp = \"{}/log.csv\".format(flag_path)\n    encryption_key = app.interface.encryption_key if app.interface.encrypt else None\n    is_new = not os.path.exists(log_fp)\n\n    if flag_index is None:\n        csv_data = []\n        for i, interface in enumerate(app.interface.input_components):\n            csv_data.append(interface.save_flagged(\n                flag_path, app.interface.config[\"input_components\"][i][\"label\"], input_data[i], encryption_key))\n        for i, interface in enumerate(app.interface.output_components):\n            csv_data.append(interface.save_flagged(\n                flag_path, app.interface.config[\"output_components\"][i][\"label\"], output_data[i], encryption_key) if output_data[i] is not None else \"\")\n        if flag_option is not None:\n            csv_data.append(flag_option)\n        if username is not None:\n            csv_data.append(username)\n        csv_data.append(str(datetime.datetime.now()))\n        if is_new:\n            headers = [interface[\"label\"]\n                    for interface in app.interface.config[\"input_components\"]]\n            headers += [interface[\"label\"]\n                        for interface in app.interface.config[\"output_components\"]]\n            if app.interface.flagging_options is not None:\n                headers.append(\"flag\")\n            if username is not None:\n                headers.append(\"username\")\n            headers.append(\"timestamp\")\n\n    def replace_flag_at_index(file_content):\n        file_content = io.StringIO(file_content)\n        content = list(csv.reader(file_content))\n        header = content[0]\n        flag_col_index = header.index(\"flag\")\n        content[flag_index][flag_col_index] = flag_option\n        output = io.StringIO()\n        writer = csv.writer(output)\n        writer.writerows(content)\n        return output.getvalue()\n\n    if app.interface.encrypt:\n        output = io.StringIO()\n        if not is_new:\n            with open(log_fp, \"rb\") as csvfile:\n                encrypted_csv = csvfile.read()\n                decrypted_csv = encryptor.decrypt(\n                    app.interface.encryption_key, encrypted_csv)\n                file_content = decrypted_csv.decode()\n                if flag_index is not None:\n                    file_content = replace_flag_at_index(file_content)\n                output.write(file_content)\n        writer = csv.writer(output)\n        if flag_index is None:\n            if is_new:\n                writer.writerow(headers)\n            writer.writerow(csv_data)\n        with open(log_fp, \"wb\") as csvfile:\n            csvfile.write(encryptor.encrypt(\n                app.interface.encryption_key, output.getvalue().encode()))\n    else:\n        if flag_index is None:\n            with open(log_fp, \"a\", newline=\"\") as csvfile:\n                writer = csv.writer(csvfile)\n                if is_new:\n                    writer.writerow(headers)\n                writer.writerow(csv_data)\n        else:\n            with open(log_fp) as csvfile:\n                file_content = csvfile.read()\n                file_content = replace_flag_at_index(file_content)\n            with open(log_fp, \"w\", newline=\"\") as csvfile:  # newline parameter needed for Windows\n                csvfile.write(file_content)\n    with open(log_fp, \"r\") as csvfile:\n        line_count = len([None for row in csv.reader(csvfile)]) - 1\n    return line_count\n\n@app.route(\"/api/flag/\", methods=[\"POST\"])\n@login_check\ndef flag():\n    log_feature_analytics('flag')\n    data = request.json['data']\n    flag_data(data['input_data'], data['output_data'], data.get(\"flag_option\"), data.get(\"flag_index\"), \n        current_user.id if current_user.is_authenticated else None)\n    return jsonify(success=True)\n\n\n@app.route(\"/api/interpret/\", methods=[\"POST\"])\n@login_check\ndef interpret():\n    log_feature_analytics('interpret')\n    raw_input = request.json[\"data\"]\n    interpretation_scores, alternative_outputs = app.interface.interpret(\n        raw_input)\n    return jsonify({\n        \"interpretation_scores\": interpretation_scores,\n        \"alternative_outputs\": alternative_outputs\n    })\n\n\n@app.route(\"/file/<path:path>\", methods=[\"GET\"])\n@login_check\ndef file(path):\n    path = secure_filename(path)\n    if app.interface.encrypt and isinstance(app.interface.examples, str) and path.startswith(app.interface.examples):\n        with open(os.path.join(app.cwd, path), \"rb\") as encrypted_file:\n            encrypted_data = encrypted_file.read()\n        file_data = encryptor.decrypt(\n            app.interface.encryption_key, encrypted_data)\n        return send_file(io.BytesIO(file_data), attachment_filename=os.path.basename(path))\n    else:\n        return send_file(os.path.join(app.cwd, path))\n\n\n@app.route(\"/api/queue/push/\", methods=[\"POST\"])\n@login_check\ndef queue_push():\n    data = request.json[\"data\"]\n    action = request.json[\"action\"]\n    job_hash, queue_position = queue.push({\"data\": data}, action)\n    return {\"hash\": job_hash, \"queue_position\": queue_position}\n\n\n@app.route(\"/api/queue/status/\", methods=[\"POST\"])\n@login_check\ndef queue_status():\n    hash = request.json['hash']\n    status, data = queue.get_status(hash)\n    return {\"status\": status, \"data\": data}\n\n\ndef queue_thread(path_to_local_server, test_mode=False):\n    while True:\n        try:\n            next_job = queue.pop()\n            if next_job is not None:\n                _, hash, input_data, task_type = next_job\n                queue.start_job(hash)\n                response = requests.post(\n                    path_to_local_server + \"/api/\" + task_type + \"/\", json=input_data)\n                if response.status_code == 200:\n                    queue.pass_job(hash, response.json())\n                else:\n                    queue.fail_job(hash, response.text)\n            else:\n                time.sleep(1)\n        except Exception as e:\n            time.sleep(1)\n            pass\n        if test_mode:\n            break\n\n\ndef start_server(interface, server_name, server_port=None, auth=None, ssl=None):\n    if server_port is None:\n        server_port = INITIAL_PORT_VALUE\n    port = get_first_available_port(\n        server_port, server_port + TRY_NUM_PORTS\n    )\n    path_to_local_server = \"http://{}:{}/\".format(server_name, port)\n    if auth is not None:\n        if not callable(auth):\n            app.auth = {account[0]: account[1] for account in auth}\n        else:\n            app.auth = auth\n    else:\n        app.auth = None\n    app.interface = interface\n    app.cwd = os.getcwd()\n    log = logging.getLogger('werkzeug')\n    log.setLevel(logging.ERROR)\n    if app.interface.enable_queue:\n        if auth is not None or app.interface.encrypt:\n            raise ValueError(\"Cannot queue with encryption or authentication enabled.\")\n        queue.init()\n        app.queue_thread = threading.Thread(target=queue_thread, args=(path_to_local_server,))\n        app.queue_thread.start()\n    if interface.save_to is not None:\n        interface.save_to[\"port\"] = port\n    app_kwargs = {\"port\": port, \"host\": server_name}\n    if ssl:\n        app_kwargs[\"ssl_context\"] = ssl\n    thread = threading.Thread(target=app.run,\n                              kwargs=app_kwargs,\n                              daemon=True)\n    thread.start()\n\n    return port, path_to_local_server, app, thread\n\ndef get_state():\n    return session.get(\"state\")\n\ndef set_state(value):\n    session[\"state\"] = value\n\ndef close_server(process):\n    process.terminate()\n    process.join()\n\n\ndef url_request(url):\n    try:\n        req = urllib.request.Request(\n            url=url, headers={\"content-type\": \"application/json\"}\n        )\n        res = urllib.request.urlopen(req, timeout=10)\n        return res\n    except Exception as e:\n        raise RuntimeError(str(e))\n\n\ndef setup_tunnel(local_server_port, endpoint):\n    response = url_request(\n        endpoint + '/v1/tunnel-request' if endpoint is not None else GRADIO_API_SERVER)\n    if response and response.code == 200:\n        try:\n            payload = json.loads(response.read().decode(\"utf-8\"))[0]\n            return create_tunnel(payload, LOCALHOST_NAME, local_server_port)\n\n        except Exception as e:\n            raise RuntimeError(str(e))\n\n\ndef url_ok(url):\n    try:\n        for _ in range(5):\n            time.sleep(.500)\n            r = requests.head(url, timeout=3)\n            if r.status_code in (200, 401, 302):  # 401 or 302 if auth is set\n                return True\n    except (ConnectionError, requests.exceptions.ConnectionError):\n        return False\n", "patch": "@@ -377,15 +377,14 @@ def interpret():\n @app.route(\"/file/<path:path>\", methods=[\"GET\"])\n @login_check\n def file(path):\n-    path = secure_filename(path)\n     if app.interface.encrypt and isinstance(app.interface.examples, str) and path.startswith(app.interface.examples):\n-        with open(os.path.join(app.cwd, path), \"rb\") as encrypted_file:\n+        with open(safe_join(app.cwd, path), \"rb\") as encrypted_file:\n             encrypted_data = encrypted_file.read()\n         file_data = encryptor.decrypt(\n             app.interface.encryption_key, encrypted_data)\n         return send_file(io.BytesIO(file_data), attachment_filename=os.path.basename(path))\n     else:\n-        return send_file(os.path.join(app.cwd, path))\n+        return send_file(safe_join(app.cwd, path))\n \n \n @app.route(\"/api/queue/push/\", methods=[\"POST\"])", "file_path": "files/2021_12/340", "file_language": "py", "file_name": "gradio/networking.py", "outdated_file_modify": 0, "outdated_file_before": 0, "outdated_file_after": 0, "llm_check": 0, "static_check": 1, "static": {"rats": [false, []], "semgrep": [true, ["       python.flask.security.injection.path-traversal-open.path-traversal-open                      \n          Found request data in a call to 'open'. Ensure the request data is validated or sanitized,\n          otherwise it could result in path traversal attacks.                                      \n          Details: https://sg.run/PJRW                                                              \n\n          382\u2506 with open(os.path.join(app.cwd, path), \"rb\") as encrypted_file:"]]}, "target": -1, "function_before": [], "function_after": []}], "outdated": 0, "cwe_descripiton": "", "cwe_consequence": "", "cwe_method": "", "cwe_solution": ""}
