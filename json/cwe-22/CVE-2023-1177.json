{"index": 10891, "cve_id": "CVE-2023-1177", "cwe_id": ["CWE-22", "CWE-29"], "cve_language": "Python", "cve_description": "Path Traversal: '\\..\\filename' in GitHub repository mlflow/mlflow prior to 2.2.1.", "cvss": "9.8", "publish_date": "March 24, 2023", "AV": "NETWORK", "AC": "NETWORK", "PR": "NONE", "UI": "NONE", "S": "UNCHANGED", "C": "HIGH", "I": "HIGH", "A": "HIGH", "commit_id": "7162a50c654792c21f3e4a160eb1a0e6a34f6e6e", "commit_message": "Apply suggestions from code review\n\nCo-authored-by: Ben Wilson <39283302+BenWilson2@users.noreply.github.com>\nSigned-off-by: Harutaka Kawamura <hkawamura0130@gmail.com>", "commit_date": "2023-02-25T02:30:47Z", "project": "mlflow/mlflow", "url": "https://api.github.com/repos/mlflow/mlflow/commits/7162a50c654792c21f3e4a160eb1a0e6a34f6e6e", "html_url": "https://github.com/mlflow/mlflow/commit/7162a50c654792c21f3e4a160eb1a0e6a34f6e6e", "windows_before": [{"commit_id": "36c787aa96f14caca40b521e293a5bd2d088685f", "commit_date": "Fri Feb 24 23:23:35 2023 +0800", "commit_message": "Implement `searchModelVersions()` API in Java client (#7880)", "files_name": ["mlflow/java/client/src/main/java/org/mlflow/tracking/MlflowClient.java", "mlflow/java/client/src/main/java/org/mlflow/tracking/MlflowProtobufMapper.java", "mlflow/java/client/src/main/java/org/mlflow/tracking/ModelVersionsPage.java", "mlflow/java/client/src/test/java/org/mlflow/tracking/ModelRegistryMlflowClientTest.java"]}, {"commit_id": "cf4e533679c7d5829fe7ead3259673939a99d264", "commit_date": "Thu Feb 23 17:16:04 2023 -0800", "commit_message": "MLflow UI updates, including new chart view (#7864)", "files_name": [".github/workflows/js.yml", "mlflow/server/js/.storybook/main.js", "mlflow/server/js/craco.config.js", "mlflow/server/js/package.json", "mlflow/server/js/src/assets.d.ts", "mlflow/server/js/src/common/components/ErrorView.js", "mlflow/server/js/src/common/components/ExperimentRunsTableEmptyOverlay.js", "mlflow/server/js/src/common/components/ExperimentRunsTableEmptyOverlay.test.js", "mlflow/server/js/src/common/components/RequestStateWrapper.js", "mlflow/server/js/src/common/components/SearchTree.js", "mlflow/server/js/src/common/constants.js", "mlflow/server/js/src/common/static/chart-bar.svg", "mlflow/server/js/src/common/static/chart-contour.svg", "mlflow/server/js/src/common/static/chart-line.svg", "mlflow/server/js/src/common/static/chart-parallel.svg", "mlflow/server/js/src/common/static/chart-scatter.svg", "mlflow/server/js/src/common/static/parallel-chart-placeholder.svg", "mlflow/server/js/src/common/utils/DatabricksTestUtils.d.ts", "mlflow/server/js/src/common/utils/FeatureUtils.ts", "mlflow/server/js/src/common/utils/Utils.js", "mlflow/server/js/src/common/utils/withRouterNext.tsx", "mlflow/server/js/src/experiment-tracking/actions.js", "mlflow/server/js/src/experiment-tracking/actions.test.js", "mlflow/server/js/src/experiment-tracking/components/App.js", "mlflow/server/js/src/experiment-tracking/components/ArtifactPage.js", "mlflow/server/js/src/experiment-tracking/components/ArtifactView.test.js", "mlflow/server/js/src/experiment-tracking/components/CompareRunView.js", "mlflow/server/js/src/experiment-tracking/components/ExperimentListView.js", "mlflow/server/js/src/experiment-tracking/components/HomePage.css", "mlflow/server/js/src/experiment-tracking/components/HomeView.js", "mlflow/server/js/src/experiment-tracking/components/MetricPage.js", "mlflow/server/js/src/experiment-tracking/components/MetricsPlotControls.js", "mlflow/server/js/src/experiment-tracking/components/MetricsPlotPanel.js", "mlflow/server/js/src/experiment-tracking/components/MetricsPlotPanel.test.js", "mlflow/server/js/src/experiment-tracking/components/artifact-view-components/LazyShowArtifactMapView.js", "mlflow/server/js/src/experiment-tracking/components/artifact-view-components/LazyShowArtifactPdfView.js", "mlflow/server/js/src/experiment-tracking/components/artifact-view-components/ShowArtifactPage.js", "mlflow/server/js/src/experiment-tracking/components/artifact-view-components/ShowArtifactPage.test.js", "mlflow/server/js/src/experiment-tracking/components/experiment-page/ExperimentPage.tsx", "mlflow/server/js/src/experiment-tracking/components/experiment-page/ExperimentView.tsx", "mlflow/server/js/src/experiment-tracking/components/experiment-page/components/ExperimentViewOnboarding.test.tsx", "mlflow/server/js/src/experiment-tracking/components/experiment-page/components/ExperimentViewOnboarding.tsx", "mlflow/server/js/src/experiment-tracking/components/experiment-page/components/header/ExperimentViewHeader.tsx", "mlflow/server/js/src/experiment-tracking/components/experiment-page/components/runs/ExperimentViewLoadMore.tsx", "mlflow/server/js/src/experiment-tracking/components/experiment-page/components/runs/ExperimentViewRefreshButton.tsx", "mlflow/server/js/src/experiment-tracking/components/experiment-page/components/runs/ExperimentViewRuns.test.tsx", "mlflow/server/js/src/experiment-tracking/components/experiment-page/components/runs/ExperimentViewRuns.tsx", "mlflow/server/js/src/experiment-tracking/components/experiment-page/components/runs/ExperimentViewRunsColumnSelector.tsx", "mlflow/server/js/src/experiment-tracking/components/experiment-page/components/runs/ExperimentViewRunsControls.stories.tsx", "mlflow/server/js/src/experiment-tracking/components/experiment-page/components/runs/ExperimentViewRunsControls.tsx", "mlflow/server/js/src/experiment-tracking/components/experiment-page/components/runs/ExperimentViewRunsControlsActions.stories.tsx", "mlflow/server/js/src/experiment-tracking/components/experiment-page/components/runs/ExperimentViewRunsControlsActions.test.tsx", "mlflow/server/js/src/experiment-tracking/components/experiment-page/components/runs/ExperimentViewRunsControlsActions.tsx", "mlflow/server/js/src/experiment-tracking/components/experiment-page/components/runs/ExperimentViewRunsControlsFilters.stories.tsx", "mlflow/server/js/src/experiment-tracking/components/experiment-page/components/runs/ExperimentViewRunsControlsFilters.test.tsx", "mlflow/server/js/src/experiment-tracking/components/experiment-page/components/runs/ExperimentViewRunsControlsFilters.tsx", "mlflow/server/js/src/experiment-tracking/components/experiment-page/components/runs/ExperimentViewRunsEmptyTable.test.tsx", "mlflow/server/js/src/experiment-tracking/components/experiment-page/components/runs/ExperimentViewRunsEmptyTable.tsx", "mlflow/server/js/src/experiment-tracking/components/experiment-page/components/runs/ExperimentViewRunsModeSwitch.tsx", "mlflow/server/js/src/experiment-tracking/components/experiment-page/components/runs/ExperimentViewRunsSortSelector.tsx", "mlflow/server/js/src/experiment-tracking/components/experiment-page/components/runs/ExperimentViewRunsTable.test.tsx", "mlflow/server/js/src/experiment-tracking/components/experiment-page/components/runs/ExperimentViewRunsTable.tsx", "mlflow/server/js/src/experiment-tracking/components/experiment-page/components/runs/ExperimentViewRunsTableAddColumnCTA.tsx", "mlflow/server/js/src/experiment-tracking/components/experiment-page/components/runs/ExperimentViewRunsTableStatusBar.tsx", "mlflow/server/js/src/experiment-tracking/components/experiment-page/components/runs/RunsSearchAutoComplete.test.tsx", "mlflow/server/js/src/experiment-tracking/components/experiment-page/components/runs/RunsSearchAutoComplete.tsx", "mlflow/server/js/src/experiment-tracking/components/experiment-page/components/runs/RunsSearchAutoComplete.utils.tsx", "mlflow/server/js/src/experiment-tracking/components/experiment-page/components/runs/RunsSearchTooltipContent.tsx", "mlflow/server/js/src/experiment-tracking/components/experiment-page/components/runs/cells/DateCellRenderer.tsx", "mlflow/server/js/src/experiment-tracking/components/experiment-page/components/runs/cells/LoadMoreRowRenderer.tsx", "mlflow/server/js/src/experiment-tracking/components/experiment-page/components/runs/cells/PinRowCellRenderer.tsx", "mlflow/server/js/src/experiment-tracking/components/experiment-page/components/runs/cells/RowActionsCellRenderer.tsx", "mlflow/server/js/src/experiment-tracking/components/experiment-page/components/runs/cells/RowActionsHeaderCellRenderer.tsx", "mlflow/server/js/src/experiment-tracking/components/experiment-page/components/runs/cells/RunNameCellRenderer.tsx", "mlflow/server/js/src/experiment-tracking/components/experiment-page/contexts/GetExperimentRunsContext.tsx", "mlflow/server/js/src/experiment-tracking/components/experiment-page/contexts/GetExperimentsContext.tsx", "mlflow/server/js/src/experiment-tracking/components/experiment-page/fixtures/experiment-runs.fixtures.ts", "mlflow/server/js/src/experiment-tracking/components/experiment-page/hooks/useExperimentPageFeedbackUrl.ts", "mlflow/server/js/src/experiment-tracking/components/experiment-page/models/SearchExperimentRunsFacetsState.ts", "mlflow/server/js/src/experiment-tracking/components/experiment-page/utils/experimentPage.column-utils.ts", "mlflow/server/js/src/experiment-tracking/components/experiment-page/utils/experimentPage.common-utils.ts", "mlflow/server/js/src/experiment-tracking/components/experiment-page/utils/experimentPage.row-types.ts", "mlflow/server/js/src/experiment-tracking/components/experiment-page/utils/experimentPage.row-utils.test.ts", "mlflow/server/js/src/experiment-tracking/components/experiment-page/utils/experimentPage.row-utils.ts", "mlflow/server/js/src/experiment-tracking/components/experiment-page/utils/persistSearchFacets.serializers.test.ts", "mlflow/server/js/src/experiment-tracking/components/experiment-page/utils/persistSearchFacets.serializers.ts", "mlflow/server/js/src/experiment-tracking/components/runs-compare/ConfigureChartModal.tsx", "mlflow/server/js/src/experiment-tracking/components/runs-compare/RunsCompare.tsx", "mlflow/server/js/src/experiment-tracking/components/runs-compare/RunsCompareAddChartMenu.tsx", "mlflow/server/js/src/experiment-tracking/components/runs-compare/RunsCompareCharts.test.tsx", "mlflow/server/js/src/experiment-tracking/components/runs-compare/RunsCompareCharts.tsx", "mlflow/server/js/src/experiment-tracking/components/runs-compare/RunsCompareConfigureModal.tsx", "mlflow/server/js/src/experiment-tracking/components/runs-compare/RunsCompareTooltipBody.tsx", "mlflow/server/js/src/experiment-tracking/components/runs-compare/cards/ChartCard.common.tsx", "mlflow/server/js/src/experiment-tracking/components/runs-compare/cards/RunsCompareBarChartCard.tsx", "mlflow/server/js/src/experiment-tracking/components/runs-compare/cards/RunsCompareContourChartCard.tsx", "mlflow/server/js/src/experiment-tracking/components/runs-compare/cards/RunsCompareLineChartCard.tsx", "mlflow/server/js/src/experiment-tracking/components/runs-compare/cards/RunsCompareParallelChartCard.tsx", "mlflow/server/js/src/experiment-tracking/components/runs-compare/cards/RunsCompareScatterChartCard.tsx", "mlflow/server/js/src/experiment-tracking/components/runs-compare/charts/CompareRunsCharts.common.ts", "mlflow/server/js/src/experiment-tracking/components/runs-compare/charts/CompareRunsContourPlot.tsx", "mlflow/server/js/src/experiment-tracking/components/runs-compare/charts/CompareRunsMetricsBarPlot.tsx", "mlflow/server/js/src/experiment-tracking/components/runs-compare/charts/CompareRunsMetricsLinePlot.stories.tsx", "mlflow/server/js/src/experiment-tracking/components/runs-compare/charts/CompareRunsMetricsLinePlot.tsx", "mlflow/server/js/src/experiment-tracking/components/runs-compare/charts/CompareRunsScatterPlot.tsx", "mlflow/server/js/src/experiment-tracking/components/runs-compare/charts/LazyParallelCoordinatesPlot.tsx", "mlflow/server/js/src/experiment-tracking/components/runs-compare/charts/ParallelCoordinatesPlot.css", "mlflow/server/js/src/experiment-tracking/components/runs-compare/charts/ParallelCoordinatesPlot.stories.tsx", "mlflow/server/js/src/experiment-tracking/components/runs-compare/charts/ParallelCoordinatesPlot.tsx", "mlflow/server/js/src/experiment-tracking/components/runs-compare/config/RunsCompareConfigure.common.tsx", "mlflow/server/js/src/experiment-tracking/components/runs-compare/config/RunsCompareConfigureBarChart.preview.tsx", "mlflow/server/js/src/experiment-tracking/components/runs-compare/config/RunsCompareConfigureBarChart.tsx", "mlflow/server/js/src/experiment-tracking/components/runs-compare/config/RunsCompareConfigureContourChart.preview.tsx", "mlflow/server/js/src/experiment-tracking/components/runs-compare/config/RunsCompareConfigureContourChart.tsx", "mlflow/server/js/src/experiment-tracking/components/runs-compare/config/RunsCompareConfigureLineChart.preview.tsx", "mlflow/server/js/src/experiment-tracking/components/runs-compare/config/RunsCompareConfigureLineChart.tsx", "mlflow/server/js/src/experiment-tracking/components/runs-compare/config/RunsCompareConfigureParallelChart.preview.tsx", "mlflow/server/js/src/experiment-tracking/components/runs-compare/config/RunsCompareConfigureParallelChart.tsx", "mlflow/server/js/src/experiment-tracking/components/runs-compare/config/RunsCompareConfigureScatterChart.preview.tsx", "mlflow/server/js/src/experiment-tracking/components/runs-compare/config/RunsCompareConfigureScatterChart.tsx", "mlflow/server/js/src/experiment-tracking/components/runs-compare/hooks/useCompareRunsTooltip.stories.tsx", "mlflow/server/js/src/experiment-tracking/components/runs-compare/hooks/useCompareRunsTooltip.test.tsx", "mlflow/server/js/src/experiment-tracking/components/runs-compare/hooks/useCompareRunsTooltip.tsx", "mlflow/server/js/src/experiment-tracking/components/runs-compare/hooks/useCompareRunsTraceHighlight.ts", "mlflow/server/js/src/experiment-tracking/components/runs-compare/hooks/useFetchCompareRunsMetricHistory.test.tsx", "mlflow/server/js/src/experiment-tracking/components/runs-compare/hooks/useFetchCompareRunsMetricHistory.ts", "mlflow/server/js/src/experiment-tracking/components/runs-compare/hooks/useMultipleChartsMetricHistory.test.tsx", "mlflow/server/js/src/experiment-tracking/components/runs-compare/hooks/useMultipleChartsMetricHistory.ts", "mlflow/server/js/src/experiment-tracking/components/runs-compare/hooks/useMutableHoverCallback.tsx", "mlflow/server/js/src/experiment-tracking/components/runs-compare/parcoord-es.d.ts", "mlflow/server/js/src/experiment-tracking/components/runs-compare/runs-compare.types.ts", "mlflow/server/js/src/experiment-tracking/constants.js", "mlflow/server/js/src/experiment-tracking/reducers/MetricReducer.js", "mlflow/server/js/src/experiment-tracking/reducers/MetricReducer.test.js", "mlflow/server/js/src/experiment-tracking/routes.js", "mlflow/server/js/src/experiment-tracking/types.ts", "mlflow/server/js/src/i18n/I18nUtils.js", "mlflow/server/js/src/i18n/default/en.json", "mlflow/server/js/src/index.css", "mlflow/server/js/src/model-registry/components/ModelListView.js", "mlflow/server/js/src/model-registry/components/ModelPage.js", "mlflow/server/js/src/model-registry/components/ModelPage.test.js", "mlflow/server/js/src/model-registry/components/ModelVersionPage.js", "mlflow/server/js/src/model-registry/components/ModelVersionPage.test.js", "mlflow/server/js/src/model-registry/components/ModelView.js", "mlflow/server/js/src/model-registry/utils.js", "mlflow/server/js/yarn.lock"]}, {"commit_id": "cabff94045c0557634f0818ec203566ce69343be", "commit_date": "Fri Feb 24 09:48:23 2023 +0900", "commit_message": "Make `validate_path_is_safe` more strict (#7886)", "files_name": ["mlflow/server/handlers.py", "tests/tracking/test_rest_tracking.py"]}, {"commit_id": "4c223ca4222c3e4206444ecc516999dceac4f8e5", "commit_date": "Thu Feb 23 11:24:56 2023 -0800", "commit_message": "Introduce artifact repo for models in UC (#7861)", "files_name": ["mlflow/protos/databricks_uc_registry_messages.proto", "mlflow/protos/databricks_uc_registry_messages_pb2.py", "mlflow/store/_unity_catalog/registry/rest_store.py", "mlflow/store/_unity_catalog/registry/utils.py", "mlflow/store/artifact/unity_catalog_models_artifact_repo.py", "mlflow/tracking/registry.py", "mlflow/utils/uri.py", "tests/store/artifact/test_unity_catalog_models_artifact_repo.py", "tests/utils/test_uri.py"]}, {"commit_id": "cea396bccee9a91b58620c006dba1975f421f243", "commit_date": "Wed Feb 22 17:57:20 2023 -0800", "commit_message": "fix pytorch gpu inference (#7885)", "files_name": ["mlflow/pytorch/__init__.py"]}, {"commit_id": "20c83f57f20d328df1f88a880b8fc6ac1bae8923", "commit_date": "Thu Feb 23 08:40:18 2023 +0900", "commit_message": "Fix typo (#7882)", "files_name": ["mlflow/server/handlers.py"]}, {"commit_id": "d17c7d3211bb9028e6e2ce11fec3638e578aab96", "commit_date": "Wed Feb 22 18:36:10 2023 -0500", "commit_message": "Migrate model registry `test_registered_model` to pytest (#7877)", "files_name": ["tests/entities/model_registry/test_registered_model.py"]}, {"commit_id": "6ee7895ad84f953666fcdffe2f561ec4e179cd28", "commit_date": "Wed Feb 22 08:47:20 2023 -0800", "commit_message": "Add internal-only ADLS artifact repo (#7858)", "files_name": ["mlflow/store/artifact/azure_data_lake_artifact_repo.py", "requirements/test-requirements.txt", "tests/store/artifact/test_azure_data_lake_artifact_repo.py"]}, {"commit_id": "b9c2193700bbb8a9151b9a9e8e0e00506215e606", "commit_date": "Wed Feb 22 19:42:57 2023 +0900", "commit_message": "Fix test_spark_udf_autofills_no_arguments (#7883)", "files_name": ["tests/pyfunc/test_spark.py"]}, {"commit_id": "7a0590a57e1fffd4db3ed80fda7b2e01ef22b14a", "commit_date": "Wed Feb 22 12:59:36 2023 +0900", "commit_message": "Fix flaky tests in tests/tracking/test_model_registry.py (#7875)", "files_name": ["tests/tracking/test_model_registry.py"]}, {"commit_id": "c3370bff294e6e2760b197ed88373340a2aa34cf", "commit_date": "Tue Feb 21 19:52:57 2023 -0800", "commit_message": "Enhance GCS artifact repo to support passing custom client (#7862)", "files_name": ["mlflow/store/artifact/gcs_artifact_repo.py", "tests/store/artifact/test_gcs_artifact_repo.py"]}, {"commit_id": "9d5024b5dbbc559fd45293729794acbfec3f7967", "commit_date": "Wed Feb 22 12:39:19 2023 +0900", "commit_message": "Use strategy in > 1.9.3 (#7874)", "files_name": ["tests/pytorch/test_pytorch_autolog.py"]}, {"commit_id": "8bf26f0a46a9fad91dbdb587fa0b556c13c7620a", "commit_date": "Wed Feb 22 09:48:26 2023 +0900", "commit_message": "Fix flaky `test_recipe_batch_dag_clean_step_works` (#7871)", "files_name": ["tests/recipes/regression/v1/test_regression_pipeline_batch_scoring.py"]}], "windows_after": [{"commit_id": "63ef72aa4334a6473ce7f889573c92fcae0b3c0d", "commit_date": "Sat Feb 25 14:22:33 2023 +0900", "commit_message": "Prevent registered model name from containing path separator (#7892)", "files_name": ["mlflow/store/model_registry/file_store.py", "mlflow/utils/file_utils.py", "tests/store/model_registry/test_file_store.py"]}, {"commit_id": "b425222d4dd508d88b1156274ce736e44c27cb67", "commit_date": "Mon Feb 27 10:48:29 2023 +0900", "commit_message": "Apply `validate_path_is_safe` to `path` and `artifact_path` for `/mlflow-artifacts/` endpoints (#7891)", "files_name": ["mlflow/server/handlers.py"]}, {"commit_id": "82e3666f21dfde5d8d73a41ab275fcb3fdd37906", "commit_date": "Mon Feb 27 07:57:54 2023 +0530", "commit_message": "Fix: `TypeError: describe() got an unexpected keyword argument 'datetime_is_numeric'` in pandas 2.0.0rc0  (#7898)", "files_name": ["mlflow/recipes/cards/pandas_renderer.py"]}, {"commit_id": "a9765617eead4f90ad905d30b7d0e910e439005c", "commit_date": "Sun Feb 26 21:29:25 2023 -0500", "commit_message": "Migrate `test_model_version.py` & `test_sqlalchemy_store.py` to pytest (#7895)", "files_name": ["tests/entities/model_registry/test_model_version.py", "tests/store/model_registry/test_sqlalchemy_store.py"]}, {"commit_id": "8cf6202eb70ceeb687ce90e604cf0ef509813ed7", "commit_date": "Mon Feb 27 00:26:35 2023 -0800", "commit_message": "Improve error message if user tries to set tracking URI to UC (#7896)", "files_name": ["mlflow/tracking/_tracking_service/utils.py", "tests/tracking/_tracking_service/test_utils.py"]}, {"commit_id": "b39d44e93303ac7fbd594348cf4ef8be8878d92c", "commit_date": "Tue Feb 28 03:37:24 2023 +0300", "commit_message": "Clean cache python (#7866)", "files_name": ["Dockerfile"]}, {"commit_id": "e2e381695e6e58e8d25e0e3938e0dfd33ddb25f6", "commit_date": "Tue Feb 28 12:13:19 2023 +0900", "commit_message": "Update requirements YAML files (#7903)", "files_name": ["requirements/core-requirements.txt", "requirements/core-requirements.yaml", "requirements/skinny-requirements.txt", "requirements/skinny-requirements.yaml"]}, {"commit_id": "b288e8bf3d7375a8e2b4720ffaf389c650480d35", "commit_date": "Tue Feb 28 12:14:01 2023 +0900", "commit_message": "Run python3 dev/update_pypi_package_index.py (#7904)", "files_name": ["mlflow/pypi_package_index.json"]}, {"commit_id": "208bb43ba8944b9273152a667c65cfbd75ecc55d", "commit_date": "Tue Feb 28 13:17:32 2023 +0900", "commit_message": "Replaces `np.dtype(\"datetime64\")` and `np.datetime64` with `np.dtype(\"datetime64[ns]\")` for pandas 2.0 (#7899)", "files_name": ["mlflow/models/utils.py", "mlflow/types/schema.py", "tests/pyfunc/test_model_export_with_loader_module_and_data_path.py"]}, {"commit_id": "65b64102cc0006f3a0c42b00668b793cd8dbe5fe", "commit_date": "Tue Feb 28 19:51:50 2023 +0900", "commit_message": "Disallow local source for model version (#7908)", "files_name": ["mlflow/java/client/src/test/java/org/mlflow/tracking/ModelRegistryMlflowClientTest.java", "mlflow/server/handlers.py", "mlflow/utils/uri.py", "tests/server/test_handlers.py", "tests/tracking/test_model_registry.py", "tests/tracking/test_rest_tracking.py", "tests/utils/test_uri.py"]}, {"commit_id": "ff36b8be2e449e5e0e76df3d19461595ef77e4fa", "commit_date": "Wed Mar 1 07:18:45 2023 +0900", "commit_message": "Run `python3 dev/update_ml_package_versions.py` (#7905)", "files_name": ["mlflow/ml-package-versions.yml", "mlflow/ml_package_versions.py"]}, {"commit_id": "68e11fbc39a7e1c0d42ab6a38a6243dbc71e031f", "commit_date": "Tue Feb 28 15:48:40 2023 -0800", "commit_message": "Bump pandas (#7910)", "files_name": ["requirements/core-requirements.txt", "requirements/core-requirements.yaml"]}, {"commit_id": "c9b25363d7510611ae353d5b711f29cb80b506da", "commit_date": "Wed Mar 1 12:56:23 2023 +0900", "commit_message": "Ignore delta checkpoint files in spark autologging (#7902)", "files_name": ["mlflow/java/spark/src/main/scala/org/mlflow/spark/autologging/MlflowAutologEventPublisher.scala"]}, {"commit_id": "e7163e84fb91653bbc9f5a9f979f503e362b20e2", "commit_date": "Tue Feb 28 23:43:05 2023 -0600", "commit_message": "Experiment list virtual (#7804)", "files_name": ["mlflow/server/js/package.json", "mlflow/server/js/src/experiment-tracking/components/ExperimentListView.js", "mlflow/server/js/src/experiment-tracking/components/ExperimentListView.test.js", "mlflow/server/js/yarn.lock"]}, {"commit_id": "d364f9ff821c5e5e4d18a7fa8a83ee570e59af30", "commit_date": "Wed Mar 1 14:51:20 2023 +0900", "commit_message": "Run `python3 dev/update_changelog.py --prev-branch branch-2.1 --curr-branch branch-2.2 --release-version 2.2.0` (#7907)", "files_name": ["CHANGELOG.md"]}, {"commit_id": "d4754e6218d42d753514c847d710e41234a87247", "commit_date": "Wed Mar 1 15:30:50 2023 +0900", "commit_message": "Merge `compile_ml_package_versions.py` and `update_ml_package_versions.py` (#7913)", "files_name": [".pre-commit-config.yaml", "dev/compile_ml_package_versions.py", "dev/update_ml_package_versions.py", "mlflow/ml_package_versions.py"]}, {"commit_id": "7f6f4c1c37057e6c9d18e77802b88c1a5cc2446d", "commit_date": "Wed Mar 1 17:11:24 2023 +0900", "commit_message": "Handle empty PR description in advice.js (#7914)", "files_name": [".github/workflows/advice.js"]}, {"commit_id": "887104c92e4821bdb6845de252fb9ca03e853b59", "commit_date": "Wed Mar 1 18:16:19 2023 +0900", "commit_message": "Fix flaky test_search_experiments_filter_by_time_attribute (#7916)", "files_name": ["tests/store/tracking/test_file_store.py", "tests/store/tracking/test_sqlalchemy_store.py"]}, {"commit_id": "3b1819aec26a6ab24362b4ca18edd9c403ee9ed8", "commit_date": "Wed Mar 1 08:07:25 2023 -0800", "commit_message": "Add support for writing UC model version files at creation time (#7844)", "files_name": ["mlflow/protos/databricks_uc_registry_messages.proto", "mlflow/protos/databricks_uc_registry_messages_pb2.py", "mlflow/store/_unity_catalog/registry/rest_store.py", "mlflow/store/artifact/unity_catalog_models_artifact_repo.py", "tests/store/_unity_catalog/model_registry/test_unity_catalog_rest_store.py", "tests/store/artifact/test_unity_catalog_models_artifact_repo.py"]}, {"commit_id": "1f310fa0545a859237b7c4339c4c6fb16b609ef4", "commit_date": "Thu Mar 2 01:19:17 2023 +0900", "commit_message": "Fix `tests/dev/test_update_ml_package_versions.py` (#7918)", "files_name": ["dev/update_ml_package_versions.py", "tests/dev/test_update_ml_package_versions.py"]}, {"commit_id": "545b10e4b5392d4703ec9259df0979aa81fe33eb", "commit_date": "Wed Mar 1 16:19:56 2023 -0800", "commit_message": "Improve error handling when wheel download fails (#7920)", "files_name": ["mlflow/models/wheeled_model.py"]}, {"commit_id": "c18744336e0b78dc82175551a6f26eafe2fc9bc4", "commit_date": "Wed Mar 1 17:17:12 2023 -0800", "commit_message": "MLflow UI changes (#7923)", "files_name": [".github/workflows/js.yml", "mlflow/server/js/.eslintrc.js", "mlflow/server/js/package.json", "mlflow/server/js/src/common/components/PageContainer.js", "mlflow/server/js/src/common/components/SimplePagination.js", "mlflow/server/js/src/common/components/tables/EditableFormTable.js", "mlflow/server/js/src/common/utils/FeatureUtils.ts", "mlflow/server/js/src/experiment-tracking/components/HtmlTableView.js", "mlflow/server/js/src/experiment-tracking/components/HtmlTableView.test.js", "mlflow/server/js/src/experiment-tracking/components/RunView.js", "mlflow/server/js/src/experiment-tracking/components/artifact-view-components/ShowArtifactTableView.js", "mlflow/server/js/src/experiment-tracking/components/experiment-page/components/header/ExperimentViewHeader.tsx", "mlflow/server/js/src/experiment-tracking/components/experiment-page/components/runs/ExperimentViewRunsControlsActions.tsx", "mlflow/server/js/src/experiment-tracking/components/experiment-page/components/runs/ExperimentViewRunsSortSelector.tsx", "mlflow/server/js/src/experiment-tracking/components/experiment-page/components/runs/ExperimentViewRunsTable.tsx", "mlflow/server/js/src/experiment-tracking/components/experiment-page/components/runs/RunsSearchAutoComplete.tsx", "mlflow/server/js/src/experiment-tracking/components/experiment-page/components/runs/RunsSearchAutoComplete.utils.tsx", "mlflow/server/js/src/experiment-tracking/types.ts", "mlflow/server/js/src/i18n/default/en.json", "mlflow/server/js/src/model-registry/components/ModelListView.js", "mlflow/server/js/src/model-registry/components/ModelListView.test.js", "mlflow/server/js/src/model-registry/components/ModelVersionPage.test.js", "mlflow/server/js/src/model-registry/components/ModelVersionTable.css", "mlflow/server/js/src/model-registry/components/model-list/ModelListFilters.test.tsx", "mlflow/server/js/src/model-registry/components/model-list/ModelListFilters.tsx", "mlflow/server/js/src/model-registry/components/model-list/ModelListTable.test.tsx", "mlflow/server/js/src/model-registry/components/model-list/ModelListTable.tsx", "mlflow/server/js/src/model-registry/components/model-list/ModelTableCellRenderers.tsx", "mlflow/server/js/src/shared/building_blocks/PageHeader.jsx", "mlflow/server/js/yarn.lock"]}, {"commit_id": "dde55afe0795c8d21b4749b7be238746a1c575a3", "commit_date": "Wed Mar 1 19:11:29 2023 -0800", "commit_message": "[#7921] Modify pytorch predict to use the GPU if it's available (#7922)", "files_name": ["docs/source/models.rst", "mlflow/environment_variables.py", "mlflow/pytorch/__init__.py"]}, {"commit_id": "182f04c472a0e2c7dac7da26dc2be44352c4b25d", "commit_date": "Thu Mar 2 12:42:50 2023 +0900", "commit_message": "Use a shorter timeout for `_await_server_up_or_die` (#7917)", "files_name": ["tests/test_cli.py", "tests/tracking/integration_test_utils.py"]}, {"commit_id": "977f794103977018d156b48833095e037208c718", "commit_date": "Wed Mar 1 21:37:40 2023 -0800", "commit_message": "changelog updates (#7924)", "files_name": ["CHANGELOG.md"]}, {"commit_id": "f2abcf5d78c1c40746da8b8df9b8155c1f4b9aef", "commit_date": "Thu Mar 2 06:00:44 2023 -0600", "commit_message": "[Server][Feature] add plugin to allow custom configs for mlflow.server (#7757)", "files_name": ["docs/source/plugins.rst", "mlflow/server/__init__.py", "tests/resources/mlflow-test-plugin/mlflow_test_plugin/app.py", "tests/resources/mlflow-test-plugin/setup.py", "tests/server/test_init.py"]}, {"commit_id": "af5ab1e2d78ffc713e8a048e5be47df10a13e7c3", "commit_date": "Thu Mar 2 22:27:07 2023 +0900", "commit_message": "Follow-up for #7757 (#7929)", "files_name": ["docs/source/plugins.rst", "tests/resources/mlflow-test-plugin/mlflow_test_plugin/app.py"]}, {"commit_id": "28cfde3cddb9317d82a3c48de91e95f2870984a5", "commit_date": "Thu Mar 2 22:42:37 2023 +0900", "commit_message": "Update bug report title to encourage issue reporters to use `UI bug report` for UI issues (#7930)", "files_name": [".github/ISSUE_TEMPLATE/bug_report_template.yaml"]}, {"commit_id": "d661091450f789b91586e913313ade49947b7947", "commit_date": "Fri Mar 3 01:26:07 2023 +0900", "commit_message": "Use sqlalchemy.text (#7931)", "files_name": ["tests/db/check_migration.py"]}, {"commit_id": "4588230fca19ade195eae5dfb784cf7d4abbd450", "commit_date": "Thu Mar 2 12:29:54 2023 -0800", "commit_message": "Use default max results of 10000 for model registry search_model_versions() API (#7935)", "files_name": ["mlflow/store/model_registry/__init__.py"]}, {"commit_id": "b4988bd8fe832a2b9e5e2cea04adcfdc5a8cec5b", "commit_date": "Thu Mar 2 13:04:12 2023 -0800", "commit_message": "Fix (#7940)", "files_name": ["CHANGELOG.md"]}, {"commit_id": "45e35659d5169585452ebf8a7b7e708d1b6fd4b1", "commit_date": "Fri Mar 3 15:23:36 2023 -0500", "commit_message": "Add simple dev utility debugging script for version compatibility checks (#7934)", "files_name": ["dev/update_requirements.py", "tests/server/test_handlers.py"]}, {"commit_id": "d74aee3a67a4068932cdb3b21fdcfe4c05454788", "commit_date": "Sat Mar 4 09:23:26 2023 -0800", "commit_message": "Get workspace ID from source tracking server when creating UC model versions (#7901)", "files_name": ["mlflow/protos/databricks_uc_registry_messages.proto", "mlflow/protos/databricks_uc_registry_messages_pb2.py", "mlflow/store/_unity_catalog/registry/rest_store.py", "tests/store/_unity_catalog/model_registry/test_unity_catalog_rest_store.py", "tests/store/artifact/test_unity_catalog_models_artifact_repo.py"]}, {"commit_id": "e37fbbc5f93db3923533e1ce640b82ac6719f248", "commit_date": "Sun Mar 5 23:30:58 2023 -0800", "commit_message": "Require signature for model versions in UC (#7909)", "files_name": ["mlflow/store/_unity_catalog/registry/rest_store.py", "tests/store/_unity_catalog/model_registry/test_unity_catalog_rest_store.py"]}, {"commit_id": "f8330fbaeddd3eb023394cf651f79594706b9e85", "commit_date": "Mon Mar 6 17:47:14 2023 +0900", "commit_message": "Temporarily avoid alembic 1.10.0 (#7968)", "files_name": ["dev/run-python-skinny-tests.sh", "requirements/core-requirements.txt", "requirements/core-requirements.yaml"]}, {"commit_id": "1c4251ff1bb5168be4adf9db558db7332adc8c8b", "commit_date": "Mon Mar 6 19:22:49 2023 +0900", "commit_message": "Validate name in FileStore.get_registered_model (#7965)", "files_name": ["instance/mlflow-auth.db", "mlflow/store/model_registry/file_store.py", "tests/store/model_registry/test_file_store.py"]}, {"commit_id": "e4a09de7144a55cb819d7cd7e9eaec64f6dbecc8", "commit_date": "Mon Mar 6 13:48:35 2023 +0300", "commit_message": "Updating the description of the version in the documentation (#7928)", "files_name": ["README.rst"]}, {"commit_id": "ce2279aa43e31bb4ce8d541d3906f909851fba9b", "commit_date": "Mon Mar 6 18:05:15 2023 -0800", "commit_message": "[Recipes][Bugfix] Correctly fixing the toPandas issue for datetime datatype to correctly render profiling (#7925)", "files_name": ["mlflow/recipes/steps/ingest/datasets.py", "tests/recipes/test_ingest_step.py"]}, {"commit_id": "d7fbe7a363476d44cbd81b3e0264b7093142fbab", "commit_date": "Tue Mar 7 18:07:28 2023 +0900", "commit_message": "Skip test_log_figure_plotly_image on windows (#7981)", "files_name": ["tests/tracking/test_log_figure.py"]}, {"commit_id": "b55a660afd36156d2a6d5b8fdf3ca8c7049c3b52", "commit_date": "Tue Mar 7 22:24:11 2023 +0900", "commit_message": "Address TODO for alembic (#7987)", "files_name": ["dev/run-python-skinny-tests.sh", "requirements/core-requirements.yaml"]}, {"commit_id": "0fd10e0a5ce7d065cf9ac1ff5b455a6ec6168411", "commit_date": "Tue Mar 7 23:51:12 2023 -0500", "commit_message": "Fix tensorflow cross version tests for typing-extensions transitive dependency (#7994)", "files_name": []}], "parents": [{"commit_id_before": "fedf876a90bdcb8d4e06b42abfc31a8df0055143", "url_before": "https://api.github.com/repos/mlflow/mlflow/commits/fedf876a90bdcb8d4e06b42abfc31a8df0055143", "html_url_before": "https://github.com/mlflow/mlflow/commit/fedf876a90bdcb8d4e06b42abfc31a8df0055143"}], "details": [{"raw_url": "https://github.com/mlflow/mlflow/raw/7162a50c654792c21f3e4a160eb1a0e6a34f6e6e/mlflow%2Fserver%2Fhandlers.py", "code": "# Define all the service endpoint handlers here.\nimport json\nimport os\nimport re\nimport tempfile\nimport posixpath\nimport urllib\nfrom mimetypes import guess_type\nimport pathlib\n\nimport logging\nfrom functools import wraps\n\nfrom flask import Response, request, current_app, send_file\nfrom google.protobuf import descriptor\nfrom google.protobuf.json_format import ParseError\n\nfrom mlflow.entities import Metric, Param, RunTag, ViewType, ExperimentTag, FileInfo\nfrom mlflow.entities.model_registry import RegisteredModelTag, ModelVersionTag\nfrom mlflow.exceptions import MlflowException\nfrom mlflow.models import Model\nfrom mlflow.models.model import MLMODEL_FILE_NAME\nfrom mlflow.projects._project_spec import MLPROJECT_FILE_NAME\nfrom mlflow.protos import databricks_pb2\nfrom mlflow.protos.service_pb2 import (\n    CreateExperiment,\n    MlflowService,\n    GetExperiment,\n    GetRun,\n    SearchRuns,\n    ListArtifacts,\n    GetMetricHistory,\n    CreateRun,\n    UpdateRun,\n    LogMetric,\n    LogParam,\n    SetTag,\n    SearchExperiments,\n    DeleteExperiment,\n    RestoreExperiment,\n    RestoreRun,\n    DeleteRun,\n    UpdateExperiment,\n    LogBatch,\n    DeleteTag,\n    SetExperimentTag,\n    GetExperimentByName,\n    LogModel,\n)\nfrom mlflow.protos.model_registry_pb2 import (\n    ModelRegistryService,\n    CreateRegisteredModel,\n    UpdateRegisteredModel,\n    DeleteRegisteredModel,\n    GetRegisteredModel,\n    GetLatestVersions,\n    CreateModelVersion,\n    UpdateModelVersion,\n    DeleteModelVersion,\n    GetModelVersion,\n    GetModelVersionDownloadUri,\n    SearchModelVersions,\n    RenameRegisteredModel,\n    TransitionModelVersionStage,\n    SearchRegisteredModels,\n    SetRegisteredModelTag,\n    DeleteRegisteredModelTag,\n    SetModelVersionTag,\n    DeleteModelVersionTag,\n)\nfrom mlflow.protos.mlflow_artifacts_pb2 import (\n    MlflowArtifactsService,\n    DownloadArtifact,\n    UploadArtifact,\n    ListArtifacts as ListArtifactsMlflowArtifacts,\n    DeleteArtifact,\n)\nfrom mlflow.protos.databricks_pb2 import RESOURCE_DOES_NOT_EXIST, INVALID_PARAMETER_VALUE\nfrom mlflow.store.artifact.artifact_repository_registry import get_artifact_repository\nfrom mlflow.store.db.db_types import DATABASE_ENGINES\nfrom mlflow.tracking._model_registry.registry import ModelRegistryStoreRegistry\nfrom mlflow.tracking._tracking_service.registry import TrackingStoreRegistry\nfrom mlflow.utils.proto_json_utils import message_to_json, parse_dict\nfrom mlflow.utils.validation import _validate_batch_log_api_req\nfrom mlflow.utils.string_utils import is_string_type\nfrom mlflow.tracking.registry import UnsupportedModelRegistryStoreURIException\n\n_logger = logging.getLogger(__name__)\n_tracking_store = None\n_model_registry_store = None\n_artifact_repo = None\nSTATIC_PREFIX_ENV_VAR = \"_MLFLOW_STATIC_PREFIX\"\n\n\nclass TrackingStoreRegistryWrapper(TrackingStoreRegistry):\n    def __init__(self):\n        super().__init__()\n        self.register(\"\", self._get_file_store)\n        self.register(\"file\", self._get_file_store)\n        for scheme in DATABASE_ENGINES:\n            self.register(scheme, self._get_sqlalchemy_store)\n        self.register_entrypoints()\n\n    @classmethod\n    def _get_file_store(cls, store_uri, artifact_uri):\n        from mlflow.store.tracking.file_store import FileStore\n\n        return FileStore(store_uri, artifact_uri)\n\n    @classmethod\n    def _get_sqlalchemy_store(cls, store_uri, artifact_uri):\n        from mlflow.store.tracking.sqlalchemy_store import SqlAlchemyStore\n\n        return SqlAlchemyStore(store_uri, artifact_uri)\n\n\nclass ModelRegistryStoreRegistryWrapper(ModelRegistryStoreRegistry):\n    def __init__(self):\n        super().__init__()\n        self.register(\"\", self._get_file_store)\n        self.register(\"file\", self._get_file_store)\n        for scheme in DATABASE_ENGINES:\n            self.register(scheme, self._get_sqlalchemy_store)\n        self.register_entrypoints()\n\n    @classmethod\n    def _get_file_store(cls, store_uri):\n        from mlflow.store.model_registry.file_store import FileStore\n\n        return FileStore(store_uri)\n\n    @classmethod\n    def _get_sqlalchemy_store(cls, store_uri):\n        from mlflow.store.model_registry.sqlalchemy_store import SqlAlchemyStore\n\n        return SqlAlchemyStore(store_uri)\n\n\n_tracking_store_registry = TrackingStoreRegistryWrapper()\n_model_registry_store_registry = ModelRegistryStoreRegistryWrapper()\n\n\ndef _get_artifact_repo_mlflow_artifacts():\n    \"\"\"\n    Get an artifact repository specified by ``--artifacts-destination`` option for ``mlflow server``\n    command.\n    \"\"\"\n    from mlflow.server import ARTIFACTS_DESTINATION_ENV_VAR\n\n    global _artifact_repo\n    if _artifact_repo is None:\n        _artifact_repo = get_artifact_repository(os.environ[ARTIFACTS_DESTINATION_ENV_VAR])\n    return _artifact_repo\n\n\ndef _is_serving_proxied_artifacts():\n    \"\"\"\n    :return: ``True`` if the MLflow server is serving proxied artifacts (i.e. acting as a proxy for\n             artifact upload / download / list operations), as would be enabled by specifying the\n             ``--serve-artifacts`` configuration option. ``False`` otherwise.\n    \"\"\"\n    from mlflow.server import SERVE_ARTIFACTS_ENV_VAR\n\n    return os.environ.get(SERVE_ARTIFACTS_ENV_VAR, \"false\") == \"true\"\n\n\ndef _is_servable_proxied_run_artifact_root(run_artifact_root):\n    \"\"\"\n    Determines whether or not the following are true:\n\n    - The specified Run artifact root is a proxied artifact root (i.e. an artifact root with scheme\n      ``http``, ``https``, or ``mlflow-artifacts``).\n\n    - The MLflow server is capable of resolving and accessing the underlying storage location\n      corresponding to the proxied artifact root, allowing it to fulfill artifact list and\n      download requests by using this storage location directly.\n\n    :param run_artifact_root: The Run artifact root location (URI).\n    :return: ``True`` if the specified Run artifact root refers to proxied artifacts that can be\n             served by this MLflow server (i.e. the server has access to the destination and\n             can respond to list and download requests for the artifact). ``False`` otherwise.\n    \"\"\"\n    parsed_run_artifact_root = urllib.parse.urlparse(run_artifact_root)\n    # NB: If the run artifact root is a proxied artifact root (has scheme `http`, `https`, or\n    # `mlflow-artifacts`) *and* the MLflow server is configured to serve artifacts, the MLflow\n    # server always assumes that it has access to the underlying storage location for the proxied\n    # artifacts. This may not always be accurate. For example:\n    #\n    # An organization may initially use the MLflow server to serve Tracking API requests and proxy\n    # access to artifacts stored in Location A (via `mlflow server --serve-artifacts`). Then, for\n    # scalability and / or security purposes, the organization may decide to store artifacts in a\n    # new location B and set up a separate server (e.g. `mlflow server --artifacts-only`) to proxy\n    # access to artifacts stored in Location B.\n    #\n    # In this scenario, requests for artifacts stored in Location B that are sent to the original\n    # MLflow server will fail if the original MLflow server does not have access to Location B\n    # because it will assume that it can serve all proxied artifacts regardless of the underlying\n    # location. Such failures can be remediated by granting the original MLflow server access to\n    # Location B.\n    return (\n        parsed_run_artifact_root.scheme in [\"http\", \"https\", \"mlflow-artifacts\"]\n        and _is_serving_proxied_artifacts()\n    )\n\n\ndef _get_proxied_run_artifact_destination_path(proxied_artifact_root, relative_path=None):\n    \"\"\"\n    Resolves the specified proxied artifact location within a Run to a concrete storage location.\n\n    :param proxied_artifact_root: The Run artifact root location (URI) with scheme ``http``,\n                                  ``https``, or `mlflow-artifacts` that can be resolved by the\n                                  MLflow server to a concrete storage location.\n    :param relative_path: The relative path of the destination within the specified\n                          ``proxied_artifact_root``. If ``None``, the destination is assumed to be\n                          the resolved ``proxied_artifact_root``.\n    :return: The storage location of the specified artifact.\n    \"\"\"\n    parsed_proxied_artifact_root = urllib.parse.urlparse(proxied_artifact_root)\n    assert parsed_proxied_artifact_root.scheme in [\"http\", \"https\", \"mlflow-artifacts\"]\n\n    if parsed_proxied_artifact_root.scheme == \"mlflow-artifacts\":\n        # If the proxied artifact root is an `mlflow-artifacts` URI, the run artifact root path is\n        # simply the path component of the URI, since the fully-qualified format of an\n        # `mlflow-artifacts` URI is `mlflow-artifacts://<netloc>/path/to/artifact`\n        proxied_run_artifact_root_path = parsed_proxied_artifact_root.path.lstrip(\"/\")\n    else:\n        # In this case, the proxied artifact root is an HTTP(S) URL referring to an mlflow-artifacts\n        # API route that can be used to download the artifact. These routes are always anchored at\n        # `/api/2.0/mlflow-artifacts/artifacts`. Accordingly, we split the path on this route anchor\n        # and interpret the rest of the path (everything after the route anchor) as the run artifact\n        # root path\n        mlflow_artifacts_http_route_anchor = \"/api/2.0/mlflow-artifacts/artifacts/\"\n        assert mlflow_artifacts_http_route_anchor in parsed_proxied_artifact_root.path\n\n        proxied_run_artifact_root_path = parsed_proxied_artifact_root.path.split(\n            mlflow_artifacts_http_route_anchor\n        )[1].lstrip(\"/\")\n\n    return (\n        posixpath.join(proxied_run_artifact_root_path, relative_path)\n        if relative_path is not None\n        else proxied_run_artifact_root_path\n    )\n\n\ndef _get_tracking_store(backend_store_uri=None, default_artifact_root=None):\n    from mlflow.server import BACKEND_STORE_URI_ENV_VAR, ARTIFACT_ROOT_ENV_VAR\n\n    global _tracking_store\n    if _tracking_store is None:\n        store_uri = backend_store_uri or os.environ.get(BACKEND_STORE_URI_ENV_VAR, None)\n        artifact_root = default_artifact_root or os.environ.get(ARTIFACT_ROOT_ENV_VAR, None)\n        _tracking_store = _tracking_store_registry.get_store(store_uri, artifact_root)\n    return _tracking_store\n\n\ndef _get_model_registry_store(registry_store_uri=None):\n    from mlflow.server import REGISTRY_STORE_URI_ENV_VAR, BACKEND_STORE_URI_ENV_VAR\n\n    global _model_registry_store\n    if _model_registry_store is None:\n        store_uri = (\n            registry_store_uri\n            or os.environ.get(REGISTRY_STORE_URI_ENV_VAR, None)\n            or os.environ.get(BACKEND_STORE_URI_ENV_VAR, None)\n        )\n        _model_registry_store = _model_registry_store_registry.get_store(store_uri)\n    return _model_registry_store\n\n\ndef initialize_backend_stores(\n    backend_store_uri=None, registry_store_uri=None, default_artifact_root=None\n):\n    _get_tracking_store(backend_store_uri, default_artifact_root)\n    try:\n        _get_model_registry_store(registry_store_uri)\n    except UnsupportedModelRegistryStoreURIException:\n        pass\n\n\ndef _assert_string(x):\n    assert isinstance(x, str)\n\n\ndef _assert_intlike(x):\n    try:\n        x = int(x)\n    except ValueError:\n        pass\n\n    assert isinstance(x, int)\n\n\ndef _assert_bool(x):\n    assert isinstance(x, bool)\n\n\ndef _assert_floatlike(x):\n    try:\n        x = float(x)\n    except ValueError:\n        pass\n\n    assert isinstance(x, float)\n\n\ndef _assert_array(x):\n    assert isinstance(x, list)\n\n\ndef _assert_required(x):\n    assert x is not None\n    # When parsing JSON payloads via proto, absent string fields\n    # are expressed as empty strings\n    assert x != \"\"\n\n\ndef _assert_less_than_or_equal(x, max_value):\n    assert x <= max_value\n\n\ndef _assert_item_type_string(x):\n    assert all(isinstance(item, str) for item in x)\n\n\n_TYPE_VALIDATORS = {\n    _assert_intlike,\n    _assert_string,\n    _assert_bool,\n    _assert_floatlike,\n    _assert_array,\n    _assert_item_type_string,\n}\n\n\ndef _validate_param_against_schema(schema, param, value, proto_parsing_succeeded=False):\n    \"\"\"\n    Attempts to validate a single parameter against a specified schema.\n    Examples of the elements of the schema are type assertions and checks for required parameters.\n    Returns None on validation success. Otherwise, raises an MLFlowException if an assertion fails.\n    This method is intended to be called for side effects.\n\n            Parameters:\n    :param schema: A list of functions to validate the parameter against.\n    :param param: The string name of the parameter being validated.\n    :param value: The corresponding value of the `param` being validated.\n    :param proto_parsing_succeeded: A boolean value indicating whether proto parsing succeeded.\n                                    If the proto was successfully parsed, we assume all of the types\n                                    of the parameters in the request body were correctly specified,\n                                    and thus we skip validating types. If proto parsing failed,\n                                    then we validate types in addition to the rest of the schema.\n                                    For details, see https://github.com/mlflow/mlflow/pull/\n                                    5458#issuecomment-1080880870.\n    \"\"\"\n\n    for f in schema:\n        if f in _TYPE_VALIDATORS and proto_parsing_succeeded:\n            continue\n\n        try:\n            f(value)\n        except AssertionError:\n            if f == _assert_required:\n                message = f\"Missing value for required parameter '{param}'.\"\n            else:\n                message = (\n                    f\"Invalid value {value} for parameter '{param}' supplied.\"\n                    f\" Hint: Value was of type '{type(value).__name__}'.\"\n                )\n            raise MlflowException(\n                message=(\n                    message + \" See the API docs for more information about request parameters.\"\n                ),\n                error_code=INVALID_PARAMETER_VALUE,\n            )\n\n    return None\n\n\ndef _get_request_json(flask_request=request):\n    return flask_request.get_json(force=True, silent=True)\n\n\ndef _get_request_message(request_message, flask_request=request, schema=None):\n    from querystring_parser import parser\n\n    if flask_request.method == \"GET\" and len(flask_request.query_string) > 0:\n        # This is a hack to make arrays of length 1 work with the parser.\n        # for example experiment_ids%5B%5D=0 should be parsed to {experiment_ids: [0]}\n        # but it gets parsed to {experiment_ids: 0}\n        # but it doesn't. However, experiment_ids%5B0%5D=0 will get parsed to the right\n        # result.\n        query_string = re.sub(\"%5B%5D\", \"%5B0%5D\", flask_request.query_string.decode(\"utf-8\"))\n        request_dict = parser.parse(query_string, normalized=True)\n        # Convert atomic values of repeated fields to lists before calling protobuf deserialization.\n        # Context: We parse the parameter string into a dictionary outside of protobuf since\n        # protobuf does not know how to read the query parameters directly. The query parser above\n        # has no type information and hence any parameter that occurs exactly once is parsed as an\n        # atomic value. Since protobuf requires that the values of repeated fields are lists,\n        # deserialization will fail unless we do the fix below.\n        for field in request_message.DESCRIPTOR.fields:\n            if (\n                field.label == descriptor.FieldDescriptor.LABEL_REPEATED\n                and field.name in request_dict\n            ):\n                if not isinstance(request_dict[field.name], list):\n                    request_dict[field.name] = [request_dict[field.name]]\n        parse_dict(request_dict, request_message)\n        return request_message\n\n    request_json = _get_request_json(flask_request)\n\n    # Older clients may post their JSON double-encoded as strings, so the get_json\n    # above actually converts it to a string. Therefore, we check this condition\n    # (which we can tell for sure because any proper request should be a dictionary),\n    # and decode it a second time.\n    if is_string_type(request_json):\n        request_json = json.loads(request_json)\n\n    # If request doesn't have json body then assume it's empty.\n    if request_json is None:\n        request_json = {}\n\n    proto_parsing_succeeded = True\n    try:\n        parse_dict(request_json, request_message)\n    except ParseError:\n        proto_parsing_succeeded = False\n\n    schema = schema or {}\n    for schema_key, schema_validation_fns in schema.items():\n        if schema_key in request_json or _assert_required in schema_validation_fns:\n            value = request_json.get(schema_key)\n            if schema_key == \"run_id\" and value is None and \"run_uuid\" in request_json:\n                value = request_json.get(\"run_uuid\")\n            _validate_param_against_schema(\n                schema=schema_validation_fns,\n                param=schema_key,\n                value=value,\n                proto_parsing_succeeded=proto_parsing_succeeded,\n            )\n\n    return request_message\n\n\ndef _response_with_file_attachment_headers(file_path, response):\n    mime_type = _guess_mime_type(file_path)\n    filename = pathlib.Path(file_path).name\n    response.mimetype = mime_type\n    content_disposition_header_name = \"Content-Disposition\"\n    if content_disposition_header_name not in response.headers:\n        response.headers[content_disposition_header_name] = f\"attachment; filename={filename}\"\n    response.headers[\"X-Content-Type-Options\"] = \"nosniff\"\n    response.headers[\"Content-Type\"] = mime_type\n    return response\n\n\ndef _send_artifact(artifact_repository, path):\n    file_path = os.path.abspath(artifact_repository.download_artifacts(path))\n    # Always send artifacts as attachments to prevent the browser from displaying them on our web\n    # server's domain, which might enable XSS.\n    mime_type = _guess_mime_type(file_path)\n    file_sender_response = send_file(file_path, mimetype=mime_type, as_attachment=True)\n    return _response_with_file_attachment_headers(file_path, file_sender_response)\n\n\ndef catch_mlflow_exception(func):\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n        try:\n            return func(*args, **kwargs)\n        except MlflowException as e:\n            response = Response(mimetype=\"application/json\")\n            response.set_data(e.serialize_as_json())\n            response.status_code = e.get_http_status_code()\n            return response\n\n    return wrapper\n\n\n_TEXT_EXTENSIONS = [\n    \"txt\",\n    \"log\",\n    \"err\",\n    \"cfg\",\n    \"conf\",\n    \"cnf\",\n    \"cf\",\n    \"ini\",\n    \"properties\",\n    \"prop\",\n    \"hocon\",\n    \"toml\",\n    \"yaml\",\n    \"yml\",\n    \"xml\",\n    \"json\",\n    \"js\",\n    \"py\",\n    \"py3\",\n    \"csv\",\n    \"tsv\",\n    \"md\",\n    \"rst\",\n    MLMODEL_FILE_NAME,\n    MLPROJECT_FILE_NAME,\n]\n\n\ndef _guess_mime_type(file_path):\n    filename = pathlib.Path(file_path).name\n    extension = os.path.splitext(filename)[-1].replace(\".\", \"\")\n    # for MLmodel/mlproject with no extensions\n    if extension == \"\":\n        extension = filename\n    if extension in _TEXT_EXTENSIONS:\n        return \"text/plain\"\n    mime_type, _ = guess_type(filename)\n    if not mime_type:\n        # As a fallback, if mime type is not detected, treat it as a binary file\n        return \"application/octet-stream\"\n    return mime_type\n\n\ndef _disable_unless_serve_artifacts(func):\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n        if not _is_serving_proxied_artifacts():\n            return Response(\n                (\n                    f\"Endpoint: {request.url_rule} disabled due to the mlflow server running \"\n                    \"with `--no-serve-artifacts`. To enable artifacts server functionality, \"\n                    \"run `mlflow server` with `--serve-artifacts`\"\n                ),\n                503,\n            )\n        return func(*args, **kwargs)\n\n    return wrapper\n\n\ndef _disable_if_artifacts_only(func):\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n        from mlflow.server import ARTIFACTS_ONLY_ENV_VAR\n\n        if os.environ.get(ARTIFACTS_ONLY_ENV_VAR):\n            return Response(\n                (\n                    f\"Endpoint: {request.url_rule} disabled due to the mlflow server running \"\n                    \"in `--artifacts-only` mode. To enable tracking server functionality, run \"\n                    \"`mlflow server` without `--artifacts-only`\"\n                ),\n                503,\n            )\n        return func(*args, **kwargs)\n\n    return wrapper\n\n\n_OS_ALT_SEPS = [sep for sep in [os.sep, os.path.altsep] if sep is not None and sep != \"/\"]\n\n\ndef validate_path_is_safe(path):\n    \"\"\"\n    Validates that the specified path is safe to join with a trusted prefix. This is a security\n    measure to prevent path traversal attacks.\n    \"\"\"\n    if (\n        any((s in path) for s in _OS_ALT_SEPS)\n        or \"..\" in path.split(posixpath.sep)\n        or posixpath.isabs(path)\n    ):\n        raise MlflowException(f\"Invalid path: {path}\", error_code=INVALID_PARAMETER_VALUE)\n\n\n@catch_mlflow_exception\ndef get_artifact_handler():\n    from querystring_parser import parser\n\n    query_string = request.query_string.decode(\"utf-8\")\n    request_dict = parser.parse(query_string, normalized=True)\n    run_id = request_dict.get(\"run_id\") or request_dict.get(\"run_uuid\")\n    path = request_dict[\"path\"]\n    validate_path_is_safe(path)\n    run = _get_tracking_store().get_run(run_id)\n\n    if _is_servable_proxied_run_artifact_root(run.info.artifact_uri):\n        artifact_repo = _get_artifact_repo_mlflow_artifacts()\n        artifact_path = _get_proxied_run_artifact_destination_path(\n            proxied_artifact_root=run.info.artifact_uri,\n            relative_path=path,\n        )\n    else:\n        artifact_repo = _get_artifact_repo(run)\n        artifact_path = path\n\n    return _send_artifact(artifact_repo, artifact_path)\n\n\ndef _not_implemented():\n    response = Response()\n    response.status_code = 404\n    return response\n\n\n# Tracking Server APIs\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _create_experiment():\n    request_message = _get_request_message(\n        CreateExperiment(),\n        schema={\n            \"name\": [_assert_required, _assert_string],\n            \"artifact_location\": [_assert_string],\n            \"tags\": [_assert_array],\n        },\n    )\n\n    tags = [ExperimentTag(tag.key, tag.value) for tag in request_message.tags]\n    experiment_id = _get_tracking_store().create_experiment(\n        request_message.name, request_message.artifact_location, tags\n    )\n    response_message = CreateExperiment.Response()\n    response_message.experiment_id = experiment_id\n    response = Response(mimetype=\"application/json\")\n    response.set_data(message_to_json(response_message))\n    return response\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _get_experiment():\n    request_message = _get_request_message(\n        GetExperiment(), schema={\"experiment_id\": [_assert_required, _assert_string]}\n    )\n    response_message = GetExperiment.Response()\n    experiment = _get_tracking_store().get_experiment(request_message.experiment_id).to_proto()\n    response_message.experiment.MergeFrom(experiment)\n    response = Response(mimetype=\"application/json\")\n    response.set_data(message_to_json(response_message))\n    return response\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _get_experiment_by_name():\n    request_message = _get_request_message(\n        GetExperimentByName(), schema={\"experiment_name\": [_assert_required, _assert_string]}\n    )\n    response_message = GetExperimentByName.Response()\n    store_exp = _get_tracking_store().get_experiment_by_name(request_message.experiment_name)\n    if store_exp is None:\n        raise MlflowException(\n            \"Could not find experiment with name '%s'\" % request_message.experiment_name,\n            error_code=RESOURCE_DOES_NOT_EXIST,\n        )\n    experiment = store_exp.to_proto()\n    response_message.experiment.MergeFrom(experiment)\n    response = Response(mimetype=\"application/json\")\n    response.set_data(message_to_json(response_message))\n    return response\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _delete_experiment():\n    request_message = _get_request_message(\n        DeleteExperiment(), schema={\"experiment_id\": [_assert_required, _assert_string]}\n    )\n    _get_tracking_store().delete_experiment(request_message.experiment_id)\n    response_message = DeleteExperiment.Response()\n    response = Response(mimetype=\"application/json\")\n    response.set_data(message_to_json(response_message))\n    return response\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _restore_experiment():\n    request_message = _get_request_message(\n        RestoreExperiment(), schema={\"experiment_id\": [_assert_required, _assert_string]}\n    )\n    _get_tracking_store().restore_experiment(request_message.experiment_id)\n    response_message = RestoreExperiment.Response()\n    response = Response(mimetype=\"application/json\")\n    response.set_data(message_to_json(response_message))\n    return response\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _update_experiment():\n    request_message = _get_request_message(\n        UpdateExperiment(),\n        schema={\n            \"experiment_id\": [_assert_required, _assert_string],\n            \"new_name\": [_assert_string, _assert_required],\n        },\n    )\n    if request_message.new_name:\n        _get_tracking_store().rename_experiment(\n            request_message.experiment_id, request_message.new_name\n        )\n    response_message = UpdateExperiment.Response()\n    response = Response(mimetype=\"application/json\")\n    response.set_data(message_to_json(response_message))\n    return response\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _create_run():\n    request_message = _get_request_message(\n        CreateRun(),\n        schema={\n            \"experiment_id\": [_assert_string],\n            \"start_time\": [_assert_intlike],\n            \"run_name\": [_assert_string],\n        },\n    )\n\n    tags = [RunTag(tag.key, tag.value) for tag in request_message.tags]\n    run = _get_tracking_store().create_run(\n        experiment_id=request_message.experiment_id,\n        user_id=request_message.user_id,\n        start_time=request_message.start_time,\n        tags=tags,\n        run_name=request_message.run_name,\n    )\n\n    response_message = CreateRun.Response()\n    response_message.run.MergeFrom(run.to_proto())\n    response = Response(mimetype=\"application/json\")\n    response.set_data(message_to_json(response_message))\n    return response\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _update_run():\n    request_message = _get_request_message(\n        UpdateRun(),\n        schema={\n            \"run_id\": [_assert_required, _assert_string],\n            \"end_time\": [_assert_intlike],\n            \"status\": [_assert_string],\n            \"run_name\": [_assert_string],\n        },\n    )\n    run_id = request_message.run_id or request_message.run_uuid\n    updated_info = _get_tracking_store().update_run_info(\n        run_id, request_message.status, request_message.end_time, request_message.run_name\n    )\n    response_message = UpdateRun.Response(run_info=updated_info.to_proto())\n    response = Response(mimetype=\"application/json\")\n    response.set_data(message_to_json(response_message))\n    return response\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _delete_run():\n    request_message = _get_request_message(\n        DeleteRun(), schema={\"run_id\": [_assert_required, _assert_string]}\n    )\n    _get_tracking_store().delete_run(request_message.run_id)\n    response_message = DeleteRun.Response()\n    response = Response(mimetype=\"application/json\")\n    response.set_data(message_to_json(response_message))\n    return response\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _restore_run():\n    request_message = _get_request_message(\n        RestoreRun(), schema={\"run_id\": [_assert_required, _assert_string]}\n    )\n    _get_tracking_store().restore_run(request_message.run_id)\n    response_message = RestoreRun.Response()\n    response = Response(mimetype=\"application/json\")\n    response.set_data(message_to_json(response_message))\n    return response\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _log_metric():\n    request_message = _get_request_message(\n        LogMetric(),\n        schema={\n            \"run_id\": [_assert_required, _assert_string],\n            \"key\": [_assert_required, _assert_string],\n            \"value\": [_assert_required, _assert_floatlike],\n            \"timestamp\": [_assert_intlike, _assert_required],\n            \"step\": [_assert_intlike],\n        },\n    )\n    metric = Metric(\n        request_message.key, request_message.value, request_message.timestamp, request_message.step\n    )\n    run_id = request_message.run_id or request_message.run_uuid\n    _get_tracking_store().log_metric(run_id, metric)\n    response_message = LogMetric.Response()\n    response = Response(mimetype=\"application/json\")\n    response.set_data(message_to_json(response_message))\n    return response\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _log_param():\n    request_message = _get_request_message(\n        LogParam(),\n        schema={\n            \"run_id\": [_assert_required, _assert_string],\n            \"key\": [_assert_required, _assert_string],\n            \"value\": [_assert_string],\n        },\n    )\n    param = Param(request_message.key, request_message.value)\n    run_id = request_message.run_id or request_message.run_uuid\n    _get_tracking_store().log_param(run_id, param)\n    response_message = LogParam.Response()\n    response = Response(mimetype=\"application/json\")\n    response.set_data(message_to_json(response_message))\n    return response\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _set_experiment_tag():\n    request_message = _get_request_message(\n        SetExperimentTag(),\n        schema={\n            \"experiment_id\": [_assert_required, _assert_string],\n            \"key\": [_assert_required, _assert_string],\n            \"value\": [_assert_string],\n        },\n    )\n    tag = ExperimentTag(request_message.key, request_message.value)\n    _get_tracking_store().set_experiment_tag(request_message.experiment_id, tag)\n    response_message = SetExperimentTag.Response()\n    response = Response(mimetype=\"application/json\")\n    response.set_data(message_to_json(response_message))\n    return response\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _set_tag():\n    request_message = _get_request_message(\n        SetTag(),\n        schema={\n            \"run_id\": [_assert_required, _assert_string],\n            \"key\": [_assert_required, _assert_string],\n            \"value\": [_assert_string],\n        },\n    )\n    tag = RunTag(request_message.key, request_message.value)\n    run_id = request_message.run_id or request_message.run_uuid\n    _get_tracking_store().set_tag(run_id, tag)\n    response_message = SetTag.Response()\n    response = Response(mimetype=\"application/json\")\n    response.set_data(message_to_json(response_message))\n    return response\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _delete_tag():\n    request_message = _get_request_message(\n        DeleteTag(),\n        schema={\n            \"run_id\": [_assert_required, _assert_string],\n            \"key\": [_assert_required, _assert_string],\n        },\n    )\n    _get_tracking_store().delete_tag(request_message.run_id, request_message.key)\n    response_message = DeleteTag.Response()\n    response = Response(mimetype=\"application/json\")\n    response.set_data(message_to_json(response_message))\n    return response\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _get_run():\n    request_message = _get_request_message(\n        GetRun(), schema={\"run_id\": [_assert_required, _assert_string]}\n    )\n    response_message = GetRun.Response()\n    run_id = request_message.run_id or request_message.run_uuid\n    response_message.run.MergeFrom(_get_tracking_store().get_run(run_id).to_proto())\n    response = Response(mimetype=\"application/json\")\n    response.set_data(message_to_json(response_message))\n    return response\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _search_runs():\n    request_message = _get_request_message(\n        SearchRuns(),\n        schema={\n            \"experiment_ids\": [_assert_array],\n            \"filter\": [_assert_string],\n            \"max_results\": [_assert_intlike, lambda x: _assert_less_than_or_equal(x, 50000)],\n            \"order_by\": [_assert_array, _assert_item_type_string],\n        },\n    )\n    response_message = SearchRuns.Response()\n    run_view_type = ViewType.ACTIVE_ONLY\n    if request_message.HasField(\"run_view_type\"):\n        run_view_type = ViewType.from_proto(request_message.run_view_type)\n    filter_string = request_message.filter\n    max_results = request_message.max_results\n    experiment_ids = request_message.experiment_ids\n    order_by = request_message.order_by\n    page_token = request_message.page_token\n    run_entities = _get_tracking_store().search_runs(\n        experiment_ids, filter_string, run_view_type, max_results, order_by, page_token\n    )\n    response_message.runs.extend([r.to_proto() for r in run_entities])\n    if run_entities.token:\n        response_message.next_page_token = run_entities.token\n    response = Response(mimetype=\"application/json\")\n    response.set_data(message_to_json(response_message))\n    return response\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _list_artifacts():\n    request_message = _get_request_message(\n        ListArtifacts(),\n        schema={\n            \"run_id\": [_assert_string, _assert_required],\n            \"path\": [_assert_string],\n            \"page_token\": [_assert_string],\n        },\n    )\n    response_message = ListArtifacts.Response()\n    if request_message.HasField(\"path\"):\n        path = request_message.path\n        validate_path_is_safe(path)\n    else:\n        path = None\n    run_id = request_message.run_id or request_message.run_uuid\n    run = _get_tracking_store().get_run(run_id)\n\n    if _is_servable_proxied_run_artifact_root(run.info.artifact_uri):\n        artifact_entities = _list_artifacts_for_proxied_run_artifact_root(\n            proxied_artifact_root=run.info.artifact_uri,\n            relative_path=path,\n        )\n    else:\n        artifact_entities = _get_artifact_repo(run).list_artifacts(path)\n\n    response_message.files.extend([a.to_proto() for a in artifact_entities])\n    response_message.root_uri = run.info.artifact_uri\n    response = Response(mimetype=\"application/json\")\n    response.set_data(message_to_json(response_message))\n    return response\n\n\n@catch_mlflow_exception\ndef _list_artifacts_for_proxied_run_artifact_root(proxied_artifact_root, relative_path=None):\n    \"\"\"\n    Lists artifacts from the specified ``relative_path`` within the specified proxied Run artifact\n    root (i.e. a Run artifact root with scheme ``http``, ``https``, or ``mlflow-artifacts``).\n\n    :param proxied_artifact_root: The Run artifact root location (URI) with scheme ``http``,\n                                  ``https``, or ``mlflow-artifacts`` that can be resolved by the\n                                  MLflow server to a concrete storage location.\n    :param relative_path: The relative path within the specified ``proxied_artifact_root`` under\n                          which to list artifact contents. If ``None``, artifacts are listed from\n                          the ``proxied_artifact_root`` directory.\n    \"\"\"\n    parsed_proxied_artifact_root = urllib.parse.urlparse(proxied_artifact_root)\n    assert parsed_proxied_artifact_root.scheme in [\"http\", \"https\", \"mlflow-artifacts\"]\n\n    artifact_destination_repo = _get_artifact_repo_mlflow_artifacts()\n    artifact_destination_path = _get_proxied_run_artifact_destination_path(\n        proxied_artifact_root=proxied_artifact_root,\n        relative_path=relative_path,\n    )\n\n    artifact_entities = []\n    for file_info in artifact_destination_repo.list_artifacts(artifact_destination_path):\n        basename = posixpath.basename(file_info.path)\n        run_relative_artifact_path = (\n            posixpath.join(relative_path, basename) if relative_path else basename\n        )\n        artifact_entities.append(\n            FileInfo(run_relative_artifact_path, file_info.is_dir, file_info.file_size)\n        )\n\n    return artifact_entities\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _get_metric_history():\n    request_message = _get_request_message(\n        GetMetricHistory(),\n        schema={\n            \"run_id\": [_assert_string, _assert_required],\n            \"metric_key\": [_assert_string, _assert_required],\n        },\n    )\n    response_message = GetMetricHistory.Response()\n    run_id = request_message.run_id or request_message.run_uuid\n    metric_entities = _get_tracking_store().get_metric_history(run_id, request_message.metric_key)\n    response_message.metrics.extend([m.to_proto() for m in metric_entities])\n    response = Response(mimetype=\"application/json\")\n    response.set_data(message_to_json(response_message))\n    return response\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef get_metric_history_bulk_handler():\n    MAX_HISTORY_RESULTS = 25000\n    MAX_RUN_IDS_PER_REQUEST = 20\n    run_ids = request.args.to_dict(flat=False).get(\"run_id\", [])\n    if not run_ids:\n        raise MlflowException(\n            message=\"GetMetricHistoryBulk request must specify at least one run_id.\",\n            error_code=INVALID_PARAMETER_VALUE,\n        )\n    if len(run_ids) > MAX_RUN_IDS_PER_REQUEST:\n        raise MlflowException(\n            message=(\n                f\"GetMetricHistoryBulk request cannot specify more than {MAX_RUN_IDS_PER_REQUEST}\"\n                f\" run_ids. Received {len(run_ids)} run_ids.\"\n            ),\n            error_code=INVALID_PARAMETER_VALUE,\n        )\n\n    metric_key = request.args.get(\"metric_key\")\n    if metric_key is None:\n        raise MlflowException(\n            message=\"GetMetricHistoryBulk request must specify a metric_key.\",\n            error_code=INVALID_PARAMETER_VALUE,\n        )\n\n    max_results = int(request.args.get(\"max_results\", MAX_HISTORY_RESULTS))\n    max_results = min(max_results, MAX_HISTORY_RESULTS)\n\n    store = _get_tracking_store()\n\n    def _default_history_bulk_impl():\n        metrics_with_run_ids = []\n        for run_id in sorted(run_ids):\n            metrics_for_run = sorted(\n                store.get_metric_history(\n                    run_id=run_id,\n                    metric_key=metric_key,\n                    max_results=max_results,\n                ),\n                key=lambda metric: (metric.timestamp, metric.step, metric.value),\n            )\n            metrics_with_run_ids.extend(\n                [\n                    {\n                        \"key\": metric.key,\n                        \"value\": metric.value,\n                        \"timestamp\": metric.timestamp,\n                        \"step\": metric.step,\n                        \"run_id\": run_id,\n                    }\n                    for metric in metrics_for_run\n                ]\n            )\n        return metrics_with_run_ids\n\n    if hasattr(store, \"get_metric_history_bulk\"):\n        metrics_with_run_ids = [\n            metric.to_dict()\n            for metric in store.get_metric_history_bulk(\n                run_ids=run_ids,\n                metric_key=metric_key,\n                max_results=max_results,\n            )\n        ]\n    else:\n        metrics_with_run_ids = _default_history_bulk_impl()\n\n    return {\n        \"metrics\": metrics_with_run_ids[:max_results],\n    }\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _search_experiments():\n    request_message = _get_request_message(\n        SearchExperiments(),\n        schema={\n            \"view_type\": [_assert_intlike],\n            \"max_results\": [_assert_intlike],\n            \"order_by\": [_assert_array],\n            \"filter\": [_assert_string],\n            \"page_token\": [_assert_string],\n        },\n    )\n    experiment_entities = _get_tracking_store().search_experiments(\n        view_type=request_message.view_type,\n        max_results=request_message.max_results,\n        order_by=request_message.order_by,\n        filter_string=request_message.filter,\n        page_token=request_message.page_token,\n    )\n    response_message = SearchExperiments.Response()\n    response_message.experiments.extend([e.to_proto() for e in experiment_entities])\n    if experiment_entities.token:\n        response_message.next_page_token = experiment_entities.token\n    response = Response(mimetype=\"application/json\")\n    response.set_data(message_to_json(response_message))\n    return response\n\n\n@catch_mlflow_exception\ndef _get_artifact_repo(run):\n    return get_artifact_repository(run.info.artifact_uri)\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _log_batch():\n    def _assert_metrics_fields_present(metrics):\n        for m in metrics:\n            _assert_required(m[\"key\"])\n            _assert_required(m[\"value\"])\n            _assert_required(m[\"timestamp\"])\n            _assert_required(m[\"step\"])\n\n    def _assert_params_tags_fields_present(params_or_tags):\n        for param_or_tag in params_or_tags:\n            _assert_required(param_or_tag[\"key\"])\n\n    _validate_batch_log_api_req(_get_request_json())\n    request_message = _get_request_message(\n        LogBatch(),\n        schema={\n            \"run_id\": [_assert_string, _assert_required],\n            \"metrics\": [_assert_array, _assert_metrics_fields_present],\n            \"params\": [_assert_array, _assert_params_tags_fields_present],\n            \"tags\": [_assert_array, _assert_params_tags_fields_present],\n        },\n    )\n    metrics = [Metric.from_proto(proto_metric) for proto_metric in request_message.metrics]\n    params = [Param.from_proto(proto_param) for proto_param in request_message.params]\n    tags = [RunTag.from_proto(proto_tag) for proto_tag in request_message.tags]\n    _get_tracking_store().log_batch(\n        run_id=request_message.run_id, metrics=metrics, params=params, tags=tags\n    )\n    response_message = LogBatch.Response()\n    response = Response(mimetype=\"application/json\")\n    response.set_data(message_to_json(response_message))\n    return response\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _log_model():\n    request_message = _get_request_message(\n        LogModel(),\n        schema={\n            \"run_id\": [_assert_string, _assert_required],\n            \"model_json\": [_assert_string, _assert_required],\n        },\n    )\n    try:\n        model = json.loads(request_message.model_json)\n    except Exception:\n        raise MlflowException(\n            \"Malformed model info. \\n {} \\n is not a valid JSON.\".format(\n                request_message.model_json\n            ),\n            error_code=INVALID_PARAMETER_VALUE,\n        )\n\n    missing_fields = {\"artifact_path\", \"flavors\", \"utc_time_created\", \"run_id\"} - set(model.keys())\n\n    if missing_fields:\n        raise MlflowException(\n            f\"Model json is missing mandatory fields: {missing_fields}\",\n            error_code=INVALID_PARAMETER_VALUE,\n        )\n    _get_tracking_store().record_logged_model(\n        run_id=request_message.run_id, mlflow_model=Model.from_dict(model)\n    )\n    response_message = LogModel.Response()\n    response = Response(mimetype=\"application/json\")\n    response.set_data(message_to_json(response_message))\n    return response\n\n\ndef _wrap_response(response_message):\n    response = Response(mimetype=\"application/json\")\n    response.set_data(message_to_json(response_message))\n    return response\n\n\n# Model Registry APIs\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _create_registered_model():\n    request_message = _get_request_message(\n        CreateRegisteredModel(),\n        schema={\n            \"name\": [_assert_string, _assert_required],\n            \"tags\": [_assert_array],\n            \"description\": [_assert_string],\n        },\n    )\n    registered_model = _get_model_registry_store().create_registered_model(\n        name=request_message.name,\n        tags=request_message.tags,\n        description=request_message.description,\n    )\n    response_message = CreateRegisteredModel.Response(registered_model=registered_model.to_proto())\n    return _wrap_response(response_message)\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _get_registered_model():\n    request_message = _get_request_message(\n        GetRegisteredModel(), schema={\"name\": [_assert_string, _assert_required]}\n    )\n    registered_model = _get_model_registry_store().get_registered_model(name=request_message.name)\n    response_message = GetRegisteredModel.Response(registered_model=registered_model.to_proto())\n    return _wrap_response(response_message)\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _update_registered_model():\n    request_message = _get_request_message(\n        UpdateRegisteredModel(),\n        schema={\"name\": [_assert_string, _assert_required], \"description\": [_assert_string]},\n    )\n    name = request_message.name\n    new_description = request_message.description\n    registered_model = _get_model_registry_store().update_registered_model(\n        name=name, description=new_description\n    )\n    response_message = UpdateRegisteredModel.Response(registered_model=registered_model.to_proto())\n    return _wrap_response(response_message)\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _rename_registered_model():\n    request_message = _get_request_message(\n        RenameRegisteredModel(),\n        schema={\n            \"name\": [_assert_string, _assert_required],\n            \"new_name\": [_assert_string, _assert_required],\n        },\n    )\n    name = request_message.name\n    new_name = request_message.new_name\n    registered_model = _get_model_registry_store().rename_registered_model(\n        name=name, new_name=new_name\n    )\n    response_message = RenameRegisteredModel.Response(registered_model=registered_model.to_proto())\n    return _wrap_response(response_message)\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _delete_registered_model():\n    request_message = _get_request_message(\n        DeleteRegisteredModel(), schema={\"name\": [_assert_string, _assert_required]}\n    )\n    _get_model_registry_store().delete_registered_model(name=request_message.name)\n    return _wrap_response(DeleteRegisteredModel.Response())\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _search_registered_models():\n    request_message = _get_request_message(\n        SearchRegisteredModels(),\n        schema={\n            \"filter\": [_assert_string],\n            \"max_results\": [_assert_intlike, lambda x: _assert_less_than_or_equal(x, 1000)],\n            \"order_by\": [_assert_array, _assert_item_type_string],\n            \"page_token\": [_assert_string],\n        },\n    )\n    store = _get_model_registry_store()\n    registered_models = store.search_registered_models(\n        filter_string=request_message.filter,\n        max_results=request_message.max_results,\n        order_by=request_message.order_by,\n        page_token=request_message.page_token,\n    )\n    response_message = SearchRegisteredModels.Response()\n    response_message.registered_models.extend([e.to_proto() for e in registered_models])\n    if registered_models.token:\n        response_message.next_page_token = registered_models.token\n    return _wrap_response(response_message)\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _get_latest_versions():\n    request_message = _get_request_message(\n        GetLatestVersions(),\n        schema={\n            \"name\": [_assert_string, _assert_required],\n            \"stages\": [_assert_array, _assert_item_type_string],\n        },\n    )\n    latest_versions = _get_model_registry_store().get_latest_versions(\n        name=request_message.name, stages=request_message.stages\n    )\n    response_message = GetLatestVersions.Response()\n    response_message.model_versions.extend([e.to_proto() for e in latest_versions])\n    return _wrap_response(response_message)\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _set_registered_model_tag():\n    request_message = _get_request_message(\n        SetRegisteredModelTag(),\n        schema={\n            \"name\": [_assert_string, _assert_required],\n            \"key\": [_assert_string, _assert_required],\n            \"value\": [_assert_string],\n        },\n    )\n    tag = RegisteredModelTag(key=request_message.key, value=request_message.value)\n    _get_model_registry_store().set_registered_model_tag(name=request_message.name, tag=tag)\n    return _wrap_response(SetRegisteredModelTag.Response())\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _delete_registered_model_tag():\n    request_message = _get_request_message(\n        DeleteRegisteredModelTag(),\n        schema={\n            \"name\": [_assert_string, _assert_required],\n            \"key\": [_assert_string, _assert_required],\n        },\n    )\n    _get_model_registry_store().delete_registered_model_tag(\n        name=request_message.name, key=request_message.key\n    )\n    return _wrap_response(DeleteRegisteredModelTag.Response())\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _create_model_version():\n    request_message = _get_request_message(\n        CreateModelVersion(),\n        schema={\n            \"name\": [_assert_string, _assert_required],\n            \"source\": [_assert_string, _assert_required],\n            \"run_id\": [_assert_string],\n            \"tags\": [_assert_array],\n            \"run_link\": [_assert_string],\n            \"description\": [_assert_string],\n        },\n    )\n    model_version = _get_model_registry_store().create_model_version(\n        name=request_message.name,\n        source=request_message.source,\n        run_id=request_message.run_id,\n        run_link=request_message.run_link,\n        tags=request_message.tags,\n        description=request_message.description,\n    )\n    response_message = CreateModelVersion.Response(model_version=model_version.to_proto())\n    return _wrap_response(response_message)\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef get_model_version_artifact_handler():\n    from querystring_parser import parser\n\n    query_string = request.query_string.decode(\"utf-8\")\n    request_dict = parser.parse(query_string, normalized=True)\n    name = request_dict.get(\"name\")\n    version = request_dict.get(\"version\")\n    path = request_dict[\"path\"]\n    validate_path_is_safe(path)\n    artifact_uri = _get_model_registry_store().get_model_version_download_uri(name, version)\n    if _is_servable_proxied_run_artifact_root(artifact_uri):\n        artifact_repo = _get_artifact_repo_mlflow_artifacts()\n        artifact_path = _get_proxied_run_artifact_destination_path(\n            proxied_artifact_root=artifact_uri,\n            relative_path=path,\n        )\n    else:\n        artifact_repo = get_artifact_repository(artifact_uri)\n        artifact_path = path\n\n    return _send_artifact(artifact_repo, artifact_path)\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _get_model_version():\n    request_message = _get_request_message(\n        GetModelVersion(),\n        schema={\n            \"name\": [_assert_string, _assert_required],\n            \"version\": [_assert_string, _assert_required],\n        },\n    )\n    model_version = _get_model_registry_store().get_model_version(\n        name=request_message.name, version=request_message.version\n    )\n    response_proto = model_version.to_proto()\n    response_message = GetModelVersion.Response(model_version=response_proto)\n    return _wrap_response(response_message)\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _update_model_version():\n    request_message = _get_request_message(\n        UpdateModelVersion(),\n        schema={\n            \"name\": [_assert_string, _assert_required],\n            \"version\": [_assert_string, _assert_required],\n            \"description\": [_assert_string],\n        },\n    )\n    new_description = None\n    if request_message.HasField(\"description\"):\n        new_description = request_message.description\n    model_version = _get_model_registry_store().update_model_version(\n        name=request_message.name, version=request_message.version, description=new_description\n    )\n    return _wrap_response(UpdateModelVersion.Response(model_version=model_version.to_proto()))\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _transition_stage():\n    request_message = _get_request_message(\n        TransitionModelVersionStage(),\n        schema={\n            \"name\": [_assert_string, _assert_required],\n            \"version\": [_assert_string, _assert_required],\n            \"stage\": [_assert_string, _assert_required],\n            \"archive_existing_versions\": [_assert_bool],\n        },\n    )\n    model_version = _get_model_registry_store().transition_model_version_stage(\n        name=request_message.name,\n        version=request_message.version,\n        stage=request_message.stage,\n        archive_existing_versions=request_message.archive_existing_versions,\n    )\n    return _wrap_response(\n        TransitionModelVersionStage.Response(model_version=model_version.to_proto())\n    )\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _delete_model_version():\n    request_message = _get_request_message(\n        DeleteModelVersion(),\n        schema={\n            \"name\": [_assert_string, _assert_required],\n            \"version\": [_assert_string, _assert_required],\n        },\n    )\n    _get_model_registry_store().delete_model_version(\n        name=request_message.name, version=request_message.version\n    )\n    return _wrap_response(DeleteModelVersion.Response())\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _get_model_version_download_uri():\n    request_message = _get_request_message(GetModelVersionDownloadUri())\n    download_uri = _get_model_registry_store().get_model_version_download_uri(\n        name=request_message.name, version=request_message.version\n    )\n    response_message = GetModelVersionDownloadUri.Response(artifact_uri=download_uri)\n    return _wrap_response(response_message)\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _search_model_versions():\n    request_message = _get_request_message(\n        SearchModelVersions(),\n        schema={\n            \"filter\": [_assert_string],\n            \"max_results\": [_assert_intlike, lambda x: _assert_less_than_or_equal(x, 200_000)],\n            \"order_by\": [_assert_array, _assert_item_type_string],\n            \"page_token\": [_assert_string],\n        },\n    )\n    store = _get_model_registry_store()\n    model_versions = store.search_model_versions(\n        filter_string=request_message.filter,\n        max_results=request_message.max_results,\n        order_by=request_message.order_by,\n        page_token=request_message.page_token,\n    )\n    response_message = SearchModelVersions.Response()\n    response_message.model_versions.extend([e.to_proto() for e in model_versions])\n    if model_versions.token:\n        response_message.next_page_token = model_versions.token\n    return _wrap_response(response_message)\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _set_model_version_tag():\n    request_message = _get_request_message(\n        SetModelVersionTag(),\n        schema={\n            \"name\": [_assert_string, _assert_required],\n            \"version\": [_assert_string, _assert_required],\n            \"key\": [_assert_string, _assert_required],\n            \"value\": [_assert_string],\n        },\n    )\n    tag = ModelVersionTag(key=request_message.key, value=request_message.value)\n    _get_model_registry_store().set_model_version_tag(\n        name=request_message.name, version=request_message.version, tag=tag\n    )\n    return _wrap_response(SetModelVersionTag.Response())\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _delete_model_version_tag():\n    request_message = _get_request_message(\n        DeleteModelVersionTag(),\n        schema={\n            \"name\": [_assert_string, _assert_required],\n            \"version\": [_assert_string, _assert_required],\n            \"key\": [_assert_string, _assert_required],\n        },\n    )\n    _get_model_registry_store().delete_model_version_tag(\n        name=request_message.name, version=request_message.version, key=request_message.key\n    )\n    return _wrap_response(DeleteModelVersionTag.Response())\n\n\n# MLflow Artifacts APIs\n\n\n@catch_mlflow_exception\n@_disable_unless_serve_artifacts\ndef _download_artifact(artifact_path):\n    \"\"\"\n    A request handler for `GET /mlflow-artifacts/artifacts/<artifact_path>` to download an artifact\n    from `artifact_path` (a relative path from the root artifact directory).\n    \"\"\"\n    validate_path_is_safe(artifact_path)\n    tmp_dir = tempfile.TemporaryDirectory()\n    artifact_repo = _get_artifact_repo_mlflow_artifacts()\n    dst = artifact_repo.download_artifacts(artifact_path, tmp_dir.name)\n\n    # Ref: https://stackoverflow.com/a/24613980/6943581\n    file_handle = open(dst, \"rb\")\n\n    def stream_and_remove_file():\n        yield from file_handle\n        file_handle.close()\n        tmp_dir.cleanup()\n\n    file_sender_response = current_app.response_class(stream_and_remove_file())\n\n    return _response_with_file_attachment_headers(artifact_path, file_sender_response)\n\n\n@catch_mlflow_exception\n@_disable_unless_serve_artifacts\ndef _upload_artifact(artifact_path):\n    \"\"\"\n    A request handler for `PUT /mlflow-artifacts/artifacts/<artifact_path>` to upload an artifact\n    to `artifact_path` (a relative path from the root artifact directory).\n    \"\"\"\n    validate_path_is_safe(artifact_path)\n    head, tail = posixpath.split(artifact_path)\n    with tempfile.TemporaryDirectory() as tmp_dir:\n        tmp_path = os.path.join(tmp_dir, tail)\n        with open(tmp_path, \"wb\") as f:\n            chunk_size = 1024 * 1024  # 1 MB\n            while True:\n                chunk = request.stream.read(chunk_size)\n                if len(chunk) == 0:\n                    break\n                f.write(chunk)\n\n        artifact_repo = _get_artifact_repo_mlflow_artifacts()\n        artifact_repo.log_artifact(tmp_path, artifact_path=head or None)\n\n    return _wrap_response(UploadArtifact.Response())\n\n\n@catch_mlflow_exception\n@_disable_unless_serve_artifacts\ndef _list_artifacts_mlflow_artifacts():\n    \"\"\"\n    A request handler for `GET /mlflow-artifacts/artifacts?path=<value>` to list artifacts in `path`\n    (a relative path from the root artifact directory).\n    \"\"\"\n    request_message = _get_request_message(ListArtifactsMlflowArtifacts())\n    if request_message.HasField(\"path\"):\n        validate_path_is_safe(request_message.path)\n        path = request_message.path\n    else:\n        path = None\n    artifact_repo = _get_artifact_repo_mlflow_artifacts()\n    files = []\n    for file_info in artifact_repo.list_artifacts(path):\n        basename = posixpath.basename(file_info.path)\n        new_file_info = FileInfo(basename, file_info.is_dir, file_info.file_size)\n        files.append(new_file_info.to_proto())\n    response_message = ListArtifacts.Response()\n    response_message.files.extend(files)\n    response = Response(mimetype=\"application/json\")\n    response.set_data(message_to_json(response_message))\n    return response\n\n\n@catch_mlflow_exception\n@_disable_unless_serve_artifacts\ndef _delete_artifact_mlflow_artifacts(artifact_path):\n    \"\"\"\n    A request handler for `DELETE /mlflow-artifacts/artifacts?path=<value>` to delete artifacts in\n    `path` (a relative path from the root artifact directory).\n    \"\"\"\n    validate_path_is_safe(artifact_path)\n    _get_request_message(DeleteArtifact())\n    artifact_repo = _get_artifact_repo_mlflow_artifacts()\n    artifact_repo.delete_artifacts(artifact_path)\n    response_message = DeleteArtifact.Response()\n    response = Response(mimetype=\"application/json\")\n    response.set_data(message_to_json(response_message))\n    return response\n\n\ndef _add_static_prefix(route):\n    prefix = os.environ.get(STATIC_PREFIX_ENV_VAR)\n    if prefix:\n        return prefix + route\n    return route\n\n\ndef _get_paths(base_path):\n    \"\"\"\n    A service endpoints base path is typically something like /mlflow/experiment.\n    We should register paths like /api/2.0/mlflow/experiment and\n    /ajax-api/2.0/mlflow/experiment in the Flask router.\n    \"\"\"\n    return [f\"/api/2.0{base_path}\", _add_static_prefix(f\"/ajax-api/2.0{base_path}\")]\n\n\ndef get_handler(request_class):\n    \"\"\"\n    :param request_class: The type of protobuf message\n    :return:\n    \"\"\"\n    return HANDLERS.get(request_class, _not_implemented)\n\n\ndef get_endpoints():\n    \"\"\"\n    :return: List of tuples (path, handler, methods)\n    \"\"\"\n\n    def get_service_endpoints(service):\n        ret = []\n        for service_method in service.DESCRIPTOR.methods:\n            endpoints = service_method.GetOptions().Extensions[databricks_pb2.rpc].endpoints\n            for endpoint in endpoints:\n                for http_path in _get_paths(endpoint.path):\n                    handler = get_handler(service().GetRequestClass(service_method))\n                    ret.append((http_path, handler, [endpoint.method]))\n        return ret\n\n    return (\n        get_service_endpoints(MlflowService)\n        + get_service_endpoints(ModelRegistryService)\n        + get_service_endpoints(MlflowArtifactsService)\n    )\n\n\nHANDLERS = {\n    # Tracking Server APIs\n    CreateExperiment: _create_experiment,\n    GetExperiment: _get_experiment,\n    GetExperimentByName: _get_experiment_by_name,\n    DeleteExperiment: _delete_experiment,\n    RestoreExperiment: _restore_experiment,\n    UpdateExperiment: _update_experiment,\n    CreateRun: _create_run,\n    UpdateRun: _update_run,\n    DeleteRun: _delete_run,\n    RestoreRun: _restore_run,\n    LogParam: _log_param,\n    LogMetric: _log_metric,\n    SetExperimentTag: _set_experiment_tag,\n    SetTag: _set_tag,\n    DeleteTag: _delete_tag,\n    LogBatch: _log_batch,\n    LogModel: _log_model,\n    GetRun: _get_run,\n    SearchRuns: _search_runs,\n    ListArtifacts: _list_artifacts,\n    GetMetricHistory: _get_metric_history,\n    SearchExperiments: _search_experiments,\n    # Model Registry APIs\n    CreateRegisteredModel: _create_registered_model,\n    GetRegisteredModel: _get_registered_model,\n    DeleteRegisteredModel: _delete_registered_model,\n    UpdateRegisteredModel: _update_registered_model,\n    RenameRegisteredModel: _rename_registered_model,\n    SearchRegisteredModels: _search_registered_models,\n    GetLatestVersions: _get_latest_versions,\n    CreateModelVersion: _create_model_version,\n    GetModelVersion: _get_model_version,\n    DeleteModelVersion: _delete_model_version,\n    UpdateModelVersion: _update_model_version,\n    TransitionModelVersionStage: _transition_stage,\n    GetModelVersionDownloadUri: _get_model_version_download_uri,\n    SearchModelVersions: _search_model_versions,\n    SetRegisteredModelTag: _set_registered_model_tag,\n    DeleteRegisteredModelTag: _delete_registered_model_tag,\n    SetModelVersionTag: _set_model_version_tag,\n    DeleteModelVersionTag: _delete_model_version_tag,\n    # MLflow Artifacts APIs\n    DownloadArtifact: _download_artifact,\n    UploadArtifact: _upload_artifact,\n    ListArtifactsMlflowArtifacts: _list_artifacts_mlflow_artifacts,\n    DeleteArtifact: _delete_artifact_mlflow_artifacts,\n}\n", "code_before": "# Define all the service endpoint handlers here.\nimport json\nimport os\nimport re\nimport tempfile\nimport posixpath\nimport urllib\nfrom mimetypes import guess_type\nimport pathlib\n\nimport logging\nfrom functools import wraps\n\nfrom flask import Response, request, current_app, send_file\nfrom google.protobuf import descriptor\nfrom google.protobuf.json_format import ParseError\n\nfrom mlflow.entities import Metric, Param, RunTag, ViewType, ExperimentTag, FileInfo\nfrom mlflow.entities.model_registry import RegisteredModelTag, ModelVersionTag\nfrom mlflow.exceptions import MlflowException\nfrom mlflow.models import Model\nfrom mlflow.models.model import MLMODEL_FILE_NAME\nfrom mlflow.projects._project_spec import MLPROJECT_FILE_NAME\nfrom mlflow.protos import databricks_pb2\nfrom mlflow.protos.service_pb2 import (\n    CreateExperiment,\n    MlflowService,\n    GetExperiment,\n    GetRun,\n    SearchRuns,\n    ListArtifacts,\n    GetMetricHistory,\n    CreateRun,\n    UpdateRun,\n    LogMetric,\n    LogParam,\n    SetTag,\n    SearchExperiments,\n    DeleteExperiment,\n    RestoreExperiment,\n    RestoreRun,\n    DeleteRun,\n    UpdateExperiment,\n    LogBatch,\n    DeleteTag,\n    SetExperimentTag,\n    GetExperimentByName,\n    LogModel,\n)\nfrom mlflow.protos.model_registry_pb2 import (\n    ModelRegistryService,\n    CreateRegisteredModel,\n    UpdateRegisteredModel,\n    DeleteRegisteredModel,\n    GetRegisteredModel,\n    GetLatestVersions,\n    CreateModelVersion,\n    UpdateModelVersion,\n    DeleteModelVersion,\n    GetModelVersion,\n    GetModelVersionDownloadUri,\n    SearchModelVersions,\n    RenameRegisteredModel,\n    TransitionModelVersionStage,\n    SearchRegisteredModels,\n    SetRegisteredModelTag,\n    DeleteRegisteredModelTag,\n    SetModelVersionTag,\n    DeleteModelVersionTag,\n)\nfrom mlflow.protos.mlflow_artifacts_pb2 import (\n    MlflowArtifactsService,\n    DownloadArtifact,\n    UploadArtifact,\n    ListArtifacts as ListArtifactsMlflowArtifacts,\n    DeleteArtifact,\n)\nfrom mlflow.protos.databricks_pb2 import RESOURCE_DOES_NOT_EXIST, INVALID_PARAMETER_VALUE\nfrom mlflow.store.artifact.artifact_repository_registry import get_artifact_repository\nfrom mlflow.store.db.db_types import DATABASE_ENGINES\nfrom mlflow.tracking._model_registry.registry import ModelRegistryStoreRegistry\nfrom mlflow.tracking._tracking_service.registry import TrackingStoreRegistry\nfrom mlflow.utils.proto_json_utils import message_to_json, parse_dict\nfrom mlflow.utils.validation import _validate_batch_log_api_req\nfrom mlflow.utils.string_utils import is_string_type\nfrom mlflow.tracking.registry import UnsupportedModelRegistryStoreURIException\n\n_logger = logging.getLogger(__name__)\n_tracking_store = None\n_model_registry_store = None\n_artifact_repo = None\nSTATIC_PREFIX_ENV_VAR = \"_MLFLOW_STATIC_PREFIX\"\n\n\nclass TrackingStoreRegistryWrapper(TrackingStoreRegistry):\n    def __init__(self):\n        super().__init__()\n        self.register(\"\", self._get_file_store)\n        self.register(\"file\", self._get_file_store)\n        for scheme in DATABASE_ENGINES:\n            self.register(scheme, self._get_sqlalchemy_store)\n        self.register_entrypoints()\n\n    @classmethod\n    def _get_file_store(cls, store_uri, artifact_uri):\n        from mlflow.store.tracking.file_store import FileStore\n\n        return FileStore(store_uri, artifact_uri)\n\n    @classmethod\n    def _get_sqlalchemy_store(cls, store_uri, artifact_uri):\n        from mlflow.store.tracking.sqlalchemy_store import SqlAlchemyStore\n\n        return SqlAlchemyStore(store_uri, artifact_uri)\n\n\nclass ModelRegistryStoreRegistryWrapper(ModelRegistryStoreRegistry):\n    def __init__(self):\n        super().__init__()\n        self.register(\"\", self._get_file_store)\n        self.register(\"file\", self._get_file_store)\n        for scheme in DATABASE_ENGINES:\n            self.register(scheme, self._get_sqlalchemy_store)\n        self.register_entrypoints()\n\n    @classmethod\n    def _get_file_store(cls, store_uri):\n        from mlflow.store.model_registry.file_store import FileStore\n\n        return FileStore(store_uri)\n\n    @classmethod\n    def _get_sqlalchemy_store(cls, store_uri):\n        from mlflow.store.model_registry.sqlalchemy_store import SqlAlchemyStore\n\n        return SqlAlchemyStore(store_uri)\n\n\n_tracking_store_registry = TrackingStoreRegistryWrapper()\n_model_registry_store_registry = ModelRegistryStoreRegistryWrapper()\n\n\ndef _get_artifact_repo_mlflow_artifacts():\n    \"\"\"\n    Get an artifact repository specified by ``--artifacts-destination`` option for ``mlflow server``\n    command.\n    \"\"\"\n    from mlflow.server import ARTIFACTS_DESTINATION_ENV_VAR\n\n    global _artifact_repo\n    if _artifact_repo is None:\n        _artifact_repo = get_artifact_repository(os.environ[ARTIFACTS_DESTINATION_ENV_VAR])\n    return _artifact_repo\n\n\ndef _is_serving_proxied_artifacts():\n    \"\"\"\n    :return: ``True`` if the MLflow server is serving proxied artifacts (i.e. acting as a proxy for\n             artifact upload / download / list operations), as would be enabled by specifying the\n             ``--serve-artifacts`` configuration option. ``False`` otherwise.\n    \"\"\"\n    from mlflow.server import SERVE_ARTIFACTS_ENV_VAR\n\n    return os.environ.get(SERVE_ARTIFACTS_ENV_VAR, \"false\") == \"true\"\n\n\ndef _is_servable_proxied_run_artifact_root(run_artifact_root):\n    \"\"\"\n    Determines whether or not the following are true:\n\n    - The specified Run artifact root is a proxied artifact root (i.e. an artifact root with scheme\n      ``http``, ``https``, or ``mlflow-artifacts``).\n\n    - The MLflow server is capable of resolving and accessing the underlying storage location\n      corresponding to the proxied artifact root, allowing it to fulfill artifact list and\n      download requests by using this storage location directly.\n\n    :param run_artifact_root: The Run artifact root location (URI).\n    :return: ``True`` if the specified Run artifact root refers to proxied artifacts that can be\n             served by this MLflow server (i.e. the server has access to the destination and\n             can respond to list and download requests for the artifact). ``False`` otherwise.\n    \"\"\"\n    parsed_run_artifact_root = urllib.parse.urlparse(run_artifact_root)\n    # NB: If the run artifact root is a proxied artifact root (has scheme `http`, `https`, or\n    # `mlflow-artifacts`) *and* the MLflow server is configured to serve artifacts, the MLflow\n    # server always assumes that it has access to the underlying storage location for the proxied\n    # artifacts. This may not always be accurate. For example:\n    #\n    # An organization may initially use the MLflow server to serve Tracking API requests and proxy\n    # access to artifacts stored in Location A (via `mlflow server --serve-artifacts`). Then, for\n    # scalability and / or security purposes, the organization may decide to store artifacts in a\n    # new location B and set up a separate server (e.g. `mlflow server --artifacts-only`) to proxy\n    # access to artifacts stored in Location B.\n    #\n    # In this scenario, requests for artifacts stored in Location B that are sent to the original\n    # MLflow server will fail if the original MLflow server does not have access to Location B\n    # because it will assume that it can serve all proxied artifacts regardless of the underlying\n    # location. Such failures can be remediated by granting the original MLflow server access to\n    # Location B.\n    return (\n        parsed_run_artifact_root.scheme in [\"http\", \"https\", \"mlflow-artifacts\"]\n        and _is_serving_proxied_artifacts()\n    )\n\n\ndef _get_proxied_run_artifact_destination_path(proxied_artifact_root, relative_path=None):\n    \"\"\"\n    Resolves the specified proxied artifact location within a Run to a concrete storage location.\n\n    :param proxied_artifact_root: The Run artifact root location (URI) with scheme ``http``,\n                                  ``https``, or `mlflow-artifacts` that can be resolved by the\n                                  MLflow server to a concrete storage location.\n    :param relative_path: The relative path of the destination within the specified\n                          ``proxied_artifact_root``. If ``None``, the destination is assumed to be\n                          the resolved ``proxied_artifact_root``.\n    :return: The storage location of the specified artifact.\n    \"\"\"\n    parsed_proxied_artifact_root = urllib.parse.urlparse(proxied_artifact_root)\n    assert parsed_proxied_artifact_root.scheme in [\"http\", \"https\", \"mlflow-artifacts\"]\n\n    if parsed_proxied_artifact_root.scheme == \"mlflow-artifacts\":\n        # If the proxied artifact root is an `mlflow-artifacts` URI, the run artifact root path is\n        # simply the path component of the URI, since the fully-qualified format of an\n        # `mlflow-artifacts` URI is `mlflow-artifacts://<netloc>/path/to/artifact`\n        proxied_run_artifact_root_path = parsed_proxied_artifact_root.path.lstrip(\"/\")\n    else:\n        # In this case, the proxied artifact root is an HTTP(S) URL referring to an mlflow-artifacts\n        # API route that can be used to download the artifact. These routes are always anchored at\n        # `/api/2.0/mlflow-artifacts/artifacts`. Accordingly, we split the path on this route anchor\n        # and interpret the rest of the path (everything after the route anchor) as the run artifact\n        # root path\n        mlflow_artifacts_http_route_anchor = \"/api/2.0/mlflow-artifacts/artifacts/\"\n        assert mlflow_artifacts_http_route_anchor in parsed_proxied_artifact_root.path\n\n        proxied_run_artifact_root_path = parsed_proxied_artifact_root.path.split(\n            mlflow_artifacts_http_route_anchor\n        )[1].lstrip(\"/\")\n\n    return (\n        posixpath.join(proxied_run_artifact_root_path, relative_path)\n        if relative_path is not None\n        else proxied_run_artifact_root_path\n    )\n\n\ndef _get_tracking_store(backend_store_uri=None, default_artifact_root=None):\n    from mlflow.server import BACKEND_STORE_URI_ENV_VAR, ARTIFACT_ROOT_ENV_VAR\n\n    global _tracking_store\n    if _tracking_store is None:\n        store_uri = backend_store_uri or os.environ.get(BACKEND_STORE_URI_ENV_VAR, None)\n        artifact_root = default_artifact_root or os.environ.get(ARTIFACT_ROOT_ENV_VAR, None)\n        _tracking_store = _tracking_store_registry.get_store(store_uri, artifact_root)\n    return _tracking_store\n\n\ndef _get_model_registry_store(registry_store_uri=None):\n    from mlflow.server import REGISTRY_STORE_URI_ENV_VAR, BACKEND_STORE_URI_ENV_VAR\n\n    global _model_registry_store\n    if _model_registry_store is None:\n        store_uri = (\n            registry_store_uri\n            or os.environ.get(REGISTRY_STORE_URI_ENV_VAR, None)\n            or os.environ.get(BACKEND_STORE_URI_ENV_VAR, None)\n        )\n        _model_registry_store = _model_registry_store_registry.get_store(store_uri)\n    return _model_registry_store\n\n\ndef initialize_backend_stores(\n    backend_store_uri=None, registry_store_uri=None, default_artifact_root=None\n):\n    _get_tracking_store(backend_store_uri, default_artifact_root)\n    try:\n        _get_model_registry_store(registry_store_uri)\n    except UnsupportedModelRegistryStoreURIException:\n        pass\n\n\ndef _assert_string(x):\n    assert isinstance(x, str)\n\n\ndef _assert_intlike(x):\n    try:\n        x = int(x)\n    except ValueError:\n        pass\n\n    assert isinstance(x, int)\n\n\ndef _assert_bool(x):\n    assert isinstance(x, bool)\n\n\ndef _assert_floatlike(x):\n    try:\n        x = float(x)\n    except ValueError:\n        pass\n\n    assert isinstance(x, float)\n\n\ndef _assert_array(x):\n    assert isinstance(x, list)\n\n\ndef _assert_required(x):\n    assert x is not None\n    # When parsing JSON payloads via proto, absent string fields\n    # are expressed as empty strings\n    assert x != \"\"\n\n\ndef _assert_less_than_or_equal(x, max_value):\n    assert x <= max_value\n\n\ndef _assert_item_type_string(x):\n    assert all(isinstance(item, str) for item in x)\n\n\n_TYPE_VALIDATORS = {\n    _assert_intlike,\n    _assert_string,\n    _assert_bool,\n    _assert_floatlike,\n    _assert_array,\n    _assert_item_type_string,\n}\n\n\ndef _validate_param_against_schema(schema, param, value, proto_parsing_succeeded=False):\n    \"\"\"\n    Attempts to validate a single parameter against a specified schema.\n    Examples of the elements of the schema are type assertions and checks for required parameters.\n    Returns None on validation success. Otherwise, raises an MLFlowException if an assertion fails.\n    This method is intended to be called for side effects.\n\n            Parameters:\n    :param schema: A list of functions to validate the parameter against.\n    :param param: The string name of the parameter being validated.\n    :param value: The corresponding value of the `param` being validated.\n    :param proto_parsing_succeeded: A boolean value indicating whether proto parsing succeeded.\n                                    If the proto was successfully parsed, we assume all of the types\n                                    of the parameters in the request body were correctly specified,\n                                    and thus we skip validating types. If proto parsing failed,\n                                    then we validate types in addition to the rest of the schema.\n                                    For details, see https://github.com/mlflow/mlflow/pull/\n                                    5458#issuecomment-1080880870.\n    \"\"\"\n\n    for f in schema:\n        if f in _TYPE_VALIDATORS and proto_parsing_succeeded:\n            continue\n\n        try:\n            f(value)\n        except AssertionError:\n            if f == _assert_required:\n                message = f\"Missing value for required parameter '{param}'.\"\n            else:\n                message = (\n                    f\"Invalid value {value} for parameter '{param}' supplied.\"\n                    f\" Hint: Value was of type '{type(value).__name__}'.\"\n                )\n            raise MlflowException(\n                message=(\n                    message + \" See the API docs for more information about request parameters.\"\n                ),\n                error_code=INVALID_PARAMETER_VALUE,\n            )\n\n    return None\n\n\ndef _get_request_json(flask_request=request):\n    return flask_request.get_json(force=True, silent=True)\n\n\ndef _get_request_message(request_message, flask_request=request, schema=None):\n    from querystring_parser import parser\n\n    if flask_request.method == \"GET\" and len(flask_request.query_string) > 0:\n        # This is a hack to make arrays of length 1 work with the parser.\n        # for example experiment_ids%5B%5D=0 should be parsed to {experiment_ids: [0]}\n        # but it gets parsed to {experiment_ids: 0}\n        # but it doesn't. However, experiment_ids%5B0%5D=0 will get parsed to the right\n        # result.\n        query_string = re.sub(\"%5B%5D\", \"%5B0%5D\", flask_request.query_string.decode(\"utf-8\"))\n        request_dict = parser.parse(query_string, normalized=True)\n        # Convert atomic values of repeated fields to lists before calling protobuf deserialization.\n        # Context: We parse the parameter string into a dictionary outside of protobuf since\n        # protobuf does not know how to read the query parameters directly. The query parser above\n        # has no type information and hence any parameter that occurs exactly once is parsed as an\n        # atomic value. Since protobuf requires that the values of repeated fields are lists,\n        # deserialization will fail unless we do the fix below.\n        for field in request_message.DESCRIPTOR.fields:\n            if (\n                field.label == descriptor.FieldDescriptor.LABEL_REPEATED\n                and field.name in request_dict\n            ):\n                if not isinstance(request_dict[field.name], list):\n                    request_dict[field.name] = [request_dict[field.name]]\n        parse_dict(request_dict, request_message)\n        return request_message\n\n    request_json = _get_request_json(flask_request)\n\n    # Older clients may post their JSON double-encoded as strings, so the get_json\n    # above actually converts it to a string. Therefore, we check this condition\n    # (which we can tell for sure because any proper request should be a dictionary),\n    # and decode it a second time.\n    if is_string_type(request_json):\n        request_json = json.loads(request_json)\n\n    # If request doesn't have json body then assume it's empty.\n    if request_json is None:\n        request_json = {}\n\n    proto_parsing_succeeded = True\n    try:\n        parse_dict(request_json, request_message)\n    except ParseError:\n        proto_parsing_succeeded = False\n\n    schema = schema or {}\n    for schema_key, schema_validation_fns in schema.items():\n        if schema_key in request_json or _assert_required in schema_validation_fns:\n            value = request_json.get(schema_key)\n            if schema_key == \"run_id\" and value is None and \"run_uuid\" in request_json:\n                value = request_json.get(\"run_uuid\")\n            _validate_param_against_schema(\n                schema=schema_validation_fns,\n                param=schema_key,\n                value=value,\n                proto_parsing_succeeded=proto_parsing_succeeded,\n            )\n\n    return request_message\n\n\ndef _response_with_file_attachment_headers(file_path, response):\n    mime_type = _guess_mime_type(file_path)\n    filename = pathlib.Path(file_path).name\n    response.mimetype = mime_type\n    content_disposition_header_name = \"Content-Disposition\"\n    if content_disposition_header_name not in response.headers:\n        response.headers[content_disposition_header_name] = f\"attachment; filename={filename}\"\n    response.headers[\"X-Content-Type-Options\"] = \"nosniff\"\n    response.headers[\"Content-Type\"] = mime_type\n    return response\n\n\ndef _send_artifact(artifact_repository, path):\n    file_path = os.path.abspath(artifact_repository.download_artifacts(path))\n    # Always send artifacts as attachments to prevent the browser from displaying them on our web\n    # server's domain, which might enable XSS.\n    mime_type = _guess_mime_type(file_path)\n    file_sender_response = send_file(file_path, mimetype=mime_type, as_attachment=True)\n    return _response_with_file_attachment_headers(file_path, file_sender_response)\n\n\ndef catch_mlflow_exception(func):\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n        try:\n            return func(*args, **kwargs)\n        except MlflowException as e:\n            response = Response(mimetype=\"application/json\")\n            response.set_data(e.serialize_as_json())\n            response.status_code = e.get_http_status_code()\n            return response\n\n    return wrapper\n\n\n_TEXT_EXTENSIONS = [\n    \"txt\",\n    \"log\",\n    \"err\",\n    \"cfg\",\n    \"conf\",\n    \"cnf\",\n    \"cf\",\n    \"ini\",\n    \"properties\",\n    \"prop\",\n    \"hocon\",\n    \"toml\",\n    \"yaml\",\n    \"yml\",\n    \"xml\",\n    \"json\",\n    \"js\",\n    \"py\",\n    \"py3\",\n    \"csv\",\n    \"tsv\",\n    \"md\",\n    \"rst\",\n    MLMODEL_FILE_NAME,\n    MLPROJECT_FILE_NAME,\n]\n\n\ndef _guess_mime_type(file_path):\n    filename = pathlib.Path(file_path).name\n    extension = os.path.splitext(filename)[-1].replace(\".\", \"\")\n    # for MLmodel/mlproject with no extensions\n    if extension == \"\":\n        extension = filename\n    if extension in _TEXT_EXTENSIONS:\n        return \"text/plain\"\n    mime_type, _ = guess_type(filename)\n    if not mime_type:\n        # As a fallback, if mime type is not detected, treat it as a binary file\n        return \"application/octet-stream\"\n    return mime_type\n\n\ndef _disable_unless_serve_artifacts(func):\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n        if not _is_serving_proxied_artifacts():\n            return Response(\n                (\n                    f\"Endpoint: {request.url_rule} disabled due to the mlflow server running \"\n                    \"with `--no-serve-artifacts`. To enable artifacts server functionality, \"\n                    \"run `mlflow server` with `--serve-artifacts`\"\n                ),\n                503,\n            )\n        return func(*args, **kwargs)\n\n    return wrapper\n\n\ndef _disable_if_artifacts_only(func):\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n        from mlflow.server import ARTIFACTS_ONLY_ENV_VAR\n\n        if os.environ.get(ARTIFACTS_ONLY_ENV_VAR):\n            return Response(\n                (\n                    f\"Endpoint: {request.url_rule} disabled due to the mlflow server running \"\n                    \"in `--artifacts-only` mode. To enable tracking server functionality, run \"\n                    \"`mlflow server` without `--artifacts-only`\"\n                ),\n                503,\n            )\n        return func(*args, **kwargs)\n\n    return wrapper\n\n\n_OS_ALT_SEPS = [sep for sep in [os.sep, os.path.altsep] if sep is not None and sep != \"/\"]\n\n\ndef validate_path_is_safe(path):\n    \"\"\"\n    Validates that the specified path is safe to join with a trusted prefix. This is a security\n    measure to prevent path traversal attacks.\n    \"\"\"\n    if (\n        any((s in path) for s in _OS_ALT_SEPS)\n        or \"..\" in path.split(posixpath.sep)\n        or posixpath.isabs(path)\n    ):\n        raise MlflowException(f\"Invalid path: {path}\", error_code=INVALID_PARAMETER_VALUE)\n\n\n@catch_mlflow_exception\ndef get_artifact_handler():\n    from querystring_parser import parser\n\n    query_string = request.query_string.decode(\"utf-8\")\n    request_dict = parser.parse(query_string, normalized=True)\n    run_id = request_dict.get(\"run_id\") or request_dict.get(\"run_uuid\")\n    path = request_dict[\"path\"]\n    validate_path_is_safe(path)\n    run = _get_tracking_store().get_run(run_id)\n\n    if _is_servable_proxied_run_artifact_root(run.info.artifact_uri):\n        artifact_repo = _get_artifact_repo_mlflow_artifacts()\n        artifact_path = _get_proxied_run_artifact_destination_path(\n            proxied_artifact_root=run.info.artifact_uri,\n            relative_path=path,\n        )\n    else:\n        artifact_repo = _get_artifact_repo(run)\n        artifact_path = path\n\n    return _send_artifact(artifact_repo, artifact_path)\n\n\ndef _not_implemented():\n    response = Response()\n    response.status_code = 404\n    return response\n\n\n# Tracking Server APIs\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _create_experiment():\n    request_message = _get_request_message(\n        CreateExperiment(),\n        schema={\n            \"name\": [_assert_required, _assert_string],\n            \"artifact_location\": [_assert_string],\n            \"tags\": [_assert_array],\n        },\n    )\n\n    tags = [ExperimentTag(tag.key, tag.value) for tag in request_message.tags]\n    experiment_id = _get_tracking_store().create_experiment(\n        request_message.name, request_message.artifact_location, tags\n    )\n    response_message = CreateExperiment.Response()\n    response_message.experiment_id = experiment_id\n    response = Response(mimetype=\"application/json\")\n    response.set_data(message_to_json(response_message))\n    return response\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _get_experiment():\n    request_message = _get_request_message(\n        GetExperiment(), schema={\"experiment_id\": [_assert_required, _assert_string]}\n    )\n    response_message = GetExperiment.Response()\n    experiment = _get_tracking_store().get_experiment(request_message.experiment_id).to_proto()\n    response_message.experiment.MergeFrom(experiment)\n    response = Response(mimetype=\"application/json\")\n    response.set_data(message_to_json(response_message))\n    return response\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _get_experiment_by_name():\n    request_message = _get_request_message(\n        GetExperimentByName(), schema={\"experiment_name\": [_assert_required, _assert_string]}\n    )\n    response_message = GetExperimentByName.Response()\n    store_exp = _get_tracking_store().get_experiment_by_name(request_message.experiment_name)\n    if store_exp is None:\n        raise MlflowException(\n            \"Could not find experiment with name '%s'\" % request_message.experiment_name,\n            error_code=RESOURCE_DOES_NOT_EXIST,\n        )\n    experiment = store_exp.to_proto()\n    response_message.experiment.MergeFrom(experiment)\n    response = Response(mimetype=\"application/json\")\n    response.set_data(message_to_json(response_message))\n    return response\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _delete_experiment():\n    request_message = _get_request_message(\n        DeleteExperiment(), schema={\"experiment_id\": [_assert_required, _assert_string]}\n    )\n    _get_tracking_store().delete_experiment(request_message.experiment_id)\n    response_message = DeleteExperiment.Response()\n    response = Response(mimetype=\"application/json\")\n    response.set_data(message_to_json(response_message))\n    return response\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _restore_experiment():\n    request_message = _get_request_message(\n        RestoreExperiment(), schema={\"experiment_id\": [_assert_required, _assert_string]}\n    )\n    _get_tracking_store().restore_experiment(request_message.experiment_id)\n    response_message = RestoreExperiment.Response()\n    response = Response(mimetype=\"application/json\")\n    response.set_data(message_to_json(response_message))\n    return response\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _update_experiment():\n    request_message = _get_request_message(\n        UpdateExperiment(),\n        schema={\n            \"experiment_id\": [_assert_required, _assert_string],\n            \"new_name\": [_assert_string, _assert_required],\n        },\n    )\n    if request_message.new_name:\n        _get_tracking_store().rename_experiment(\n            request_message.experiment_id, request_message.new_name\n        )\n    response_message = UpdateExperiment.Response()\n    response = Response(mimetype=\"application/json\")\n    response.set_data(message_to_json(response_message))\n    return response\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _create_run():\n    request_message = _get_request_message(\n        CreateRun(),\n        schema={\n            \"experiment_id\": [_assert_string],\n            \"start_time\": [_assert_intlike],\n            \"run_name\": [_assert_string],\n        },\n    )\n\n    tags = [RunTag(tag.key, tag.value) for tag in request_message.tags]\n    run = _get_tracking_store().create_run(\n        experiment_id=request_message.experiment_id,\n        user_id=request_message.user_id,\n        start_time=request_message.start_time,\n        tags=tags,\n        run_name=request_message.run_name,\n    )\n\n    response_message = CreateRun.Response()\n    response_message.run.MergeFrom(run.to_proto())\n    response = Response(mimetype=\"application/json\")\n    response.set_data(message_to_json(response_message))\n    return response\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _update_run():\n    request_message = _get_request_message(\n        UpdateRun(),\n        schema={\n            \"run_id\": [_assert_required, _assert_string],\n            \"end_time\": [_assert_intlike],\n            \"status\": [_assert_string],\n            \"run_name\": [_assert_string],\n        },\n    )\n    run_id = request_message.run_id or request_message.run_uuid\n    updated_info = _get_tracking_store().update_run_info(\n        run_id, request_message.status, request_message.end_time, request_message.run_name\n    )\n    response_message = UpdateRun.Response(run_info=updated_info.to_proto())\n    response = Response(mimetype=\"application/json\")\n    response.set_data(message_to_json(response_message))\n    return response\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _delete_run():\n    request_message = _get_request_message(\n        DeleteRun(), schema={\"run_id\": [_assert_required, _assert_string]}\n    )\n    _get_tracking_store().delete_run(request_message.run_id)\n    response_message = DeleteRun.Response()\n    response = Response(mimetype=\"application/json\")\n    response.set_data(message_to_json(response_message))\n    return response\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _restore_run():\n    request_message = _get_request_message(\n        RestoreRun(), schema={\"run_id\": [_assert_required, _assert_string]}\n    )\n    _get_tracking_store().restore_run(request_message.run_id)\n    response_message = RestoreRun.Response()\n    response = Response(mimetype=\"application/json\")\n    response.set_data(message_to_json(response_message))\n    return response\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _log_metric():\n    request_message = _get_request_message(\n        LogMetric(),\n        schema={\n            \"run_id\": [_assert_required, _assert_string],\n            \"key\": [_assert_required, _assert_string],\n            \"value\": [_assert_required, _assert_floatlike],\n            \"timestamp\": [_assert_intlike, _assert_required],\n            \"step\": [_assert_intlike],\n        },\n    )\n    metric = Metric(\n        request_message.key, request_message.value, request_message.timestamp, request_message.step\n    )\n    run_id = request_message.run_id or request_message.run_uuid\n    _get_tracking_store().log_metric(run_id, metric)\n    response_message = LogMetric.Response()\n    response = Response(mimetype=\"application/json\")\n    response.set_data(message_to_json(response_message))\n    return response\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _log_param():\n    request_message = _get_request_message(\n        LogParam(),\n        schema={\n            \"run_id\": [_assert_required, _assert_string],\n            \"key\": [_assert_required, _assert_string],\n            \"value\": [_assert_string],\n        },\n    )\n    param = Param(request_message.key, request_message.value)\n    run_id = request_message.run_id or request_message.run_uuid\n    _get_tracking_store().log_param(run_id, param)\n    response_message = LogParam.Response()\n    response = Response(mimetype=\"application/json\")\n    response.set_data(message_to_json(response_message))\n    return response\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _set_experiment_tag():\n    request_message = _get_request_message(\n        SetExperimentTag(),\n        schema={\n            \"experiment_id\": [_assert_required, _assert_string],\n            \"key\": [_assert_required, _assert_string],\n            \"value\": [_assert_string],\n        },\n    )\n    tag = ExperimentTag(request_message.key, request_message.value)\n    _get_tracking_store().set_experiment_tag(request_message.experiment_id, tag)\n    response_message = SetExperimentTag.Response()\n    response = Response(mimetype=\"application/json\")\n    response.set_data(message_to_json(response_message))\n    return response\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _set_tag():\n    request_message = _get_request_message(\n        SetTag(),\n        schema={\n            \"run_id\": [_assert_required, _assert_string],\n            \"key\": [_assert_required, _assert_string],\n            \"value\": [_assert_string],\n        },\n    )\n    tag = RunTag(request_message.key, request_message.value)\n    run_id = request_message.run_id or request_message.run_uuid\n    _get_tracking_store().set_tag(run_id, tag)\n    response_message = SetTag.Response()\n    response = Response(mimetype=\"application/json\")\n    response.set_data(message_to_json(response_message))\n    return response\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _delete_tag():\n    request_message = _get_request_message(\n        DeleteTag(),\n        schema={\n            \"run_id\": [_assert_required, _assert_string],\n            \"key\": [_assert_required, _assert_string],\n        },\n    )\n    _get_tracking_store().delete_tag(request_message.run_id, request_message.key)\n    response_message = DeleteTag.Response()\n    response = Response(mimetype=\"application/json\")\n    response.set_data(message_to_json(response_message))\n    return response\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _get_run():\n    request_message = _get_request_message(\n        GetRun(), schema={\"run_id\": [_assert_required, _assert_string]}\n    )\n    response_message = GetRun.Response()\n    run_id = request_message.run_id or request_message.run_uuid\n    response_message.run.MergeFrom(_get_tracking_store().get_run(run_id).to_proto())\n    response = Response(mimetype=\"application/json\")\n    response.set_data(message_to_json(response_message))\n    return response\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _search_runs():\n    request_message = _get_request_message(\n        SearchRuns(),\n        schema={\n            \"experiment_ids\": [_assert_array],\n            \"filter\": [_assert_string],\n            \"max_results\": [_assert_intlike, lambda x: _assert_less_than_or_equal(x, 50000)],\n            \"order_by\": [_assert_array, _assert_item_type_string],\n        },\n    )\n    response_message = SearchRuns.Response()\n    run_view_type = ViewType.ACTIVE_ONLY\n    if request_message.HasField(\"run_view_type\"):\n        run_view_type = ViewType.from_proto(request_message.run_view_type)\n    filter_string = request_message.filter\n    max_results = request_message.max_results\n    experiment_ids = request_message.experiment_ids\n    order_by = request_message.order_by\n    page_token = request_message.page_token\n    run_entities = _get_tracking_store().search_runs(\n        experiment_ids, filter_string, run_view_type, max_results, order_by, page_token\n    )\n    response_message.runs.extend([r.to_proto() for r in run_entities])\n    if run_entities.token:\n        response_message.next_page_token = run_entities.token\n    response = Response(mimetype=\"application/json\")\n    response.set_data(message_to_json(response_message))\n    return response\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _list_artifacts():\n    request_message = _get_request_message(\n        ListArtifacts(),\n        schema={\n            \"run_id\": [_assert_string, _assert_required],\n            \"path\": [_assert_string],\n            \"page_token\": [_assert_string],\n        },\n    )\n    response_message = ListArtifacts.Response()\n    if request_message.HasField(\"path\"):\n        path = request_message.path\n        validate_path_is_safe(path)\n    else:\n        path = None\n    run_id = request_message.run_id or request_message.run_uuid\n    run = _get_tracking_store().get_run(run_id)\n\n    if _is_servable_proxied_run_artifact_root(run.info.artifact_uri):\n        artifact_entities = _list_artifacts_for_proxied_run_artifact_root(\n            proxied_artifact_root=run.info.artifact_uri,\n            relative_path=path,\n        )\n    else:\n        artifact_entities = _get_artifact_repo(run).list_artifacts(path)\n\n    response_message.files.extend([a.to_proto() for a in artifact_entities])\n    response_message.root_uri = run.info.artifact_uri\n    response = Response(mimetype=\"application/json\")\n    response.set_data(message_to_json(response_message))\n    return response\n\n\n@catch_mlflow_exception\ndef _list_artifacts_for_proxied_run_artifact_root(proxied_artifact_root, relative_path=None):\n    \"\"\"\n    Lists artifacts from the specified ``relative_path`` within the specified proxied Run artifact\n    root (i.e. a Run artifact root with scheme ``http``, ``https``, or ``mlflow-artifacts``).\n\n    :param proxied_artifact_root: The Run artifact root location (URI) with scheme ``http``,\n                                  ``https``, or ``mlflow-artifacts`` that can be resolved by the\n                                  MLflow server to a concrete storage location.\n    :param relative_path: The relative path within the specified ``proxied_artifact_root`` under\n                          which to list artifact contents. If ``None``, artifacts are listed from\n                          the ``proxied_artifact_root`` directory.\n    \"\"\"\n    parsed_proxied_artifact_root = urllib.parse.urlparse(proxied_artifact_root)\n    assert parsed_proxied_artifact_root.scheme in [\"http\", \"https\", \"mlflow-artifacts\"]\n\n    artifact_destination_repo = _get_artifact_repo_mlflow_artifacts()\n    artifact_destination_path = _get_proxied_run_artifact_destination_path(\n        proxied_artifact_root=proxied_artifact_root,\n        relative_path=relative_path,\n    )\n\n    artifact_entities = []\n    for file_info in artifact_destination_repo.list_artifacts(artifact_destination_path):\n        basename = posixpath.basename(file_info.path)\n        run_relative_artifact_path = (\n            posixpath.join(relative_path, basename) if relative_path else basename\n        )\n        artifact_entities.append(\n            FileInfo(run_relative_artifact_path, file_info.is_dir, file_info.file_size)\n        )\n\n    return artifact_entities\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _get_metric_history():\n    request_message = _get_request_message(\n        GetMetricHistory(),\n        schema={\n            \"run_id\": [_assert_string, _assert_required],\n            \"metric_key\": [_assert_string, _assert_required],\n        },\n    )\n    response_message = GetMetricHistory.Response()\n    run_id = request_message.run_id or request_message.run_uuid\n    metric_entities = _get_tracking_store().get_metric_history(run_id, request_message.metric_key)\n    response_message.metrics.extend([m.to_proto() for m in metric_entities])\n    response = Response(mimetype=\"application/json\")\n    response.set_data(message_to_json(response_message))\n    return response\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef get_metric_history_bulk_handler():\n    MAX_HISTORY_RESULTS = 25000\n    MAX_RUN_IDS_PER_REQUEST = 20\n    run_ids = request.args.to_dict(flat=False).get(\"run_id\", [])\n    if not run_ids:\n        raise MlflowException(\n            message=\"GetMetricHistoryBulk request must specify at least one run_id.\",\n            error_code=INVALID_PARAMETER_VALUE,\n        )\n    if len(run_ids) > MAX_RUN_IDS_PER_REQUEST:\n        raise MlflowException(\n            message=(\n                f\"GetMetricHistoryBulk request cannot specify more than {MAX_RUN_IDS_PER_REQUEST}\"\n                f\" run_ids. Received {len(run_ids)} run_ids.\"\n            ),\n            error_code=INVALID_PARAMETER_VALUE,\n        )\n\n    metric_key = request.args.get(\"metric_key\")\n    if metric_key is None:\n        raise MlflowException(\n            message=\"GetMetricHistoryBulk request must specify a metric_key.\",\n            error_code=INVALID_PARAMETER_VALUE,\n        )\n\n    max_results = int(request.args.get(\"max_results\", MAX_HISTORY_RESULTS))\n    max_results = min(max_results, MAX_HISTORY_RESULTS)\n\n    store = _get_tracking_store()\n\n    def _default_history_bulk_impl():\n        metrics_with_run_ids = []\n        for run_id in sorted(run_ids):\n            metrics_for_run = sorted(\n                store.get_metric_history(\n                    run_id=run_id,\n                    metric_key=metric_key,\n                    max_results=max_results,\n                ),\n                key=lambda metric: (metric.timestamp, metric.step, metric.value),\n            )\n            metrics_with_run_ids.extend(\n                [\n                    {\n                        \"key\": metric.key,\n                        \"value\": metric.value,\n                        \"timestamp\": metric.timestamp,\n                        \"step\": metric.step,\n                        \"run_id\": run_id,\n                    }\n                    for metric in metrics_for_run\n                ]\n            )\n        return metrics_with_run_ids\n\n    if hasattr(store, \"get_metric_history_bulk\"):\n        metrics_with_run_ids = [\n            metric.to_dict()\n            for metric in store.get_metric_history_bulk(\n                run_ids=run_ids,\n                metric_key=metric_key,\n                max_results=max_results,\n            )\n        ]\n    else:\n        metrics_with_run_ids = _default_history_bulk_impl()\n\n    return {\n        \"metrics\": metrics_with_run_ids[:max_results],\n    }\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _search_experiments():\n    request_message = _get_request_message(\n        SearchExperiments(),\n        schema={\n            \"view_type\": [_assert_intlike],\n            \"max_results\": [_assert_intlike],\n            \"order_by\": [_assert_array],\n            \"filter\": [_assert_string],\n            \"page_token\": [_assert_string],\n        },\n    )\n    experiment_entities = _get_tracking_store().search_experiments(\n        view_type=request_message.view_type,\n        max_results=request_message.max_results,\n        order_by=request_message.order_by,\n        filter_string=request_message.filter,\n        page_token=request_message.page_token,\n    )\n    response_message = SearchExperiments.Response()\n    response_message.experiments.extend([e.to_proto() for e in experiment_entities])\n    if experiment_entities.token:\n        response_message.next_page_token = experiment_entities.token\n    response = Response(mimetype=\"application/json\")\n    response.set_data(message_to_json(response_message))\n    return response\n\n\n@catch_mlflow_exception\ndef _get_artifact_repo(run):\n    return get_artifact_repository(run.info.artifact_uri)\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _log_batch():\n    def _assert_metrics_fields_present(metrics):\n        for m in metrics:\n            _assert_required(m[\"key\"])\n            _assert_required(m[\"value\"])\n            _assert_required(m[\"timestamp\"])\n            _assert_required(m[\"step\"])\n\n    def _assert_params_tags_fields_present(params_or_tags):\n        for param_or_tag in params_or_tags:\n            _assert_required(param_or_tag[\"key\"])\n\n    _validate_batch_log_api_req(_get_request_json())\n    request_message = _get_request_message(\n        LogBatch(),\n        schema={\n            \"run_id\": [_assert_string, _assert_required],\n            \"metrics\": [_assert_array, _assert_metrics_fields_present],\n            \"params\": [_assert_array, _assert_params_tags_fields_present],\n            \"tags\": [_assert_array, _assert_params_tags_fields_present],\n        },\n    )\n    metrics = [Metric.from_proto(proto_metric) for proto_metric in request_message.metrics]\n    params = [Param.from_proto(proto_param) for proto_param in request_message.params]\n    tags = [RunTag.from_proto(proto_tag) for proto_tag in request_message.tags]\n    _get_tracking_store().log_batch(\n        run_id=request_message.run_id, metrics=metrics, params=params, tags=tags\n    )\n    response_message = LogBatch.Response()\n    response = Response(mimetype=\"application/json\")\n    response.set_data(message_to_json(response_message))\n    return response\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _log_model():\n    request_message = _get_request_message(\n        LogModel(),\n        schema={\n            \"run_id\": [_assert_string, _assert_required],\n            \"model_json\": [_assert_string, _assert_required],\n        },\n    )\n    try:\n        model = json.loads(request_message.model_json)\n    except Exception:\n        raise MlflowException(\n            \"Malformed model info. \\n {} \\n is not a valid JSON.\".format(\n                request_message.model_json\n            ),\n            error_code=INVALID_PARAMETER_VALUE,\n        )\n\n    missing_fields = {\"artifact_path\", \"flavors\", \"utc_time_created\", \"run_id\"} - set(model.keys())\n\n    if missing_fields:\n        raise MlflowException(\n            f\"Model json is missing mandatory fields: {missing_fields}\",\n            error_code=INVALID_PARAMETER_VALUE,\n        )\n    _get_tracking_store().record_logged_model(\n        run_id=request_message.run_id, mlflow_model=Model.from_dict(model)\n    )\n    response_message = LogModel.Response()\n    response = Response(mimetype=\"application/json\")\n    response.set_data(message_to_json(response_message))\n    return response\n\n\ndef _wrap_response(response_message):\n    response = Response(mimetype=\"application/json\")\n    response.set_data(message_to_json(response_message))\n    return response\n\n\n# Model Registry APIs\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _create_registered_model():\n    request_message = _get_request_message(\n        CreateRegisteredModel(),\n        schema={\n            \"name\": [_assert_string, _assert_required],\n            \"tags\": [_assert_array],\n            \"description\": [_assert_string],\n        },\n    )\n    registered_model = _get_model_registry_store().create_registered_model(\n        name=request_message.name,\n        tags=request_message.tags,\n        description=request_message.description,\n    )\n    response_message = CreateRegisteredModel.Response(registered_model=registered_model.to_proto())\n    return _wrap_response(response_message)\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _get_registered_model():\n    request_message = _get_request_message(\n        GetRegisteredModel(), schema={\"name\": [_assert_string, _assert_required]}\n    )\n    registered_model = _get_model_registry_store().get_registered_model(name=request_message.name)\n    response_message = GetRegisteredModel.Response(registered_model=registered_model.to_proto())\n    return _wrap_response(response_message)\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _update_registered_model():\n    request_message = _get_request_message(\n        UpdateRegisteredModel(),\n        schema={\"name\": [_assert_string, _assert_required], \"description\": [_assert_string]},\n    )\n    name = request_message.name\n    new_description = request_message.description\n    registered_model = _get_model_registry_store().update_registered_model(\n        name=name, description=new_description\n    )\n    response_message = UpdateRegisteredModel.Response(registered_model=registered_model.to_proto())\n    return _wrap_response(response_message)\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _rename_registered_model():\n    request_message = _get_request_message(\n        RenameRegisteredModel(),\n        schema={\n            \"name\": [_assert_string, _assert_required],\n            \"new_name\": [_assert_string, _assert_required],\n        },\n    )\n    name = request_message.name\n    new_name = request_message.new_name\n    registered_model = _get_model_registry_store().rename_registered_model(\n        name=name, new_name=new_name\n    )\n    response_message = RenameRegisteredModel.Response(registered_model=registered_model.to_proto())\n    return _wrap_response(response_message)\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _delete_registered_model():\n    request_message = _get_request_message(\n        DeleteRegisteredModel(), schema={\"name\": [_assert_string, _assert_required]}\n    )\n    _get_model_registry_store().delete_registered_model(name=request_message.name)\n    return _wrap_response(DeleteRegisteredModel.Response())\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _search_registered_models():\n    request_message = _get_request_message(\n        SearchRegisteredModels(),\n        schema={\n            \"filter\": [_assert_string],\n            \"max_results\": [_assert_intlike, lambda x: _assert_less_than_or_equal(x, 1000)],\n            \"order_by\": [_assert_array, _assert_item_type_string],\n            \"page_token\": [_assert_string],\n        },\n    )\n    store = _get_model_registry_store()\n    registered_models = store.search_registered_models(\n        filter_string=request_message.filter,\n        max_results=request_message.max_results,\n        order_by=request_message.order_by,\n        page_token=request_message.page_token,\n    )\n    response_message = SearchRegisteredModels.Response()\n    response_message.registered_models.extend([e.to_proto() for e in registered_models])\n    if registered_models.token:\n        response_message.next_page_token = registered_models.token\n    return _wrap_response(response_message)\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _get_latest_versions():\n    request_message = _get_request_message(\n        GetLatestVersions(),\n        schema={\n            \"name\": [_assert_string, _assert_required],\n            \"stages\": [_assert_array, _assert_item_type_string],\n        },\n    )\n    latest_versions = _get_model_registry_store().get_latest_versions(\n        name=request_message.name, stages=request_message.stages\n    )\n    response_message = GetLatestVersions.Response()\n    response_message.model_versions.extend([e.to_proto() for e in latest_versions])\n    return _wrap_response(response_message)\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _set_registered_model_tag():\n    request_message = _get_request_message(\n        SetRegisteredModelTag(),\n        schema={\n            \"name\": [_assert_string, _assert_required],\n            \"key\": [_assert_string, _assert_required],\n            \"value\": [_assert_string],\n        },\n    )\n    tag = RegisteredModelTag(key=request_message.key, value=request_message.value)\n    _get_model_registry_store().set_registered_model_tag(name=request_message.name, tag=tag)\n    return _wrap_response(SetRegisteredModelTag.Response())\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _delete_registered_model_tag():\n    request_message = _get_request_message(\n        DeleteRegisteredModelTag(),\n        schema={\n            \"name\": [_assert_string, _assert_required],\n            \"key\": [_assert_string, _assert_required],\n        },\n    )\n    _get_model_registry_store().delete_registered_model_tag(\n        name=request_message.name, key=request_message.key\n    )\n    return _wrap_response(DeleteRegisteredModelTag.Response())\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _create_model_version():\n    request_message = _get_request_message(\n        CreateModelVersion(),\n        schema={\n            \"name\": [_assert_string, _assert_required],\n            \"source\": [_assert_string, _assert_required],\n            \"run_id\": [_assert_string],\n            \"tags\": [_assert_array],\n            \"run_link\": [_assert_string],\n            \"description\": [_assert_string],\n        },\n    )\n    model_version = _get_model_registry_store().create_model_version(\n        name=request_message.name,\n        source=request_message.source,\n        run_id=request_message.run_id,\n        run_link=request_message.run_link,\n        tags=request_message.tags,\n        description=request_message.description,\n    )\n    response_message = CreateModelVersion.Response(model_version=model_version.to_proto())\n    return _wrap_response(response_message)\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef get_model_version_artifact_handler():\n    from querystring_parser import parser\n\n    query_string = request.query_string.decode(\"utf-8\")\n    request_dict = parser.parse(query_string, normalized=True)\n    name = request_dict.get(\"name\")\n    version = request_dict.get(\"version\")\n    path = request_dict[\"path\"]\n    validate_path_is_safe(path)\n    artifact_uri = _get_model_registry_store().get_model_version_download_uri(name, version)\n    if _is_servable_proxied_run_artifact_root(artifact_uri):\n        artifact_repo = _get_artifact_repo_mlflow_artifacts()\n        artifact_path = _get_proxied_run_artifact_destination_path(\n            proxied_artifact_root=artifact_uri,\n            relative_path=path,\n        )\n    else:\n        artifact_repo = get_artifact_repository(artifact_uri)\n        artifact_path = path\n\n    return _send_artifact(artifact_repo, artifact_path)\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _get_model_version():\n    request_message = _get_request_message(\n        GetModelVersion(),\n        schema={\n            \"name\": [_assert_string, _assert_required],\n            \"version\": [_assert_string, _assert_required],\n        },\n    )\n    model_version = _get_model_registry_store().get_model_version(\n        name=request_message.name, version=request_message.version\n    )\n    response_proto = model_version.to_proto()\n    response_message = GetModelVersion.Response(model_version=response_proto)\n    return _wrap_response(response_message)\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _update_model_version():\n    request_message = _get_request_message(\n        UpdateModelVersion(),\n        schema={\n            \"name\": [_assert_string, _assert_required],\n            \"version\": [_assert_string, _assert_required],\n            \"description\": [_assert_string],\n        },\n    )\n    new_description = None\n    if request_message.HasField(\"description\"):\n        new_description = request_message.description\n    model_version = _get_model_registry_store().update_model_version(\n        name=request_message.name, version=request_message.version, description=new_description\n    )\n    return _wrap_response(UpdateModelVersion.Response(model_version=model_version.to_proto()))\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _transition_stage():\n    request_message = _get_request_message(\n        TransitionModelVersionStage(),\n        schema={\n            \"name\": [_assert_string, _assert_required],\n            \"version\": [_assert_string, _assert_required],\n            \"stage\": [_assert_string, _assert_required],\n            \"archive_existing_versions\": [_assert_bool],\n        },\n    )\n    model_version = _get_model_registry_store().transition_model_version_stage(\n        name=request_message.name,\n        version=request_message.version,\n        stage=request_message.stage,\n        archive_existing_versions=request_message.archive_existing_versions,\n    )\n    return _wrap_response(\n        TransitionModelVersionStage.Response(model_version=model_version.to_proto())\n    )\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _delete_model_version():\n    request_message = _get_request_message(\n        DeleteModelVersion(),\n        schema={\n            \"name\": [_assert_string, _assert_required],\n            \"version\": [_assert_string, _assert_required],\n        },\n    )\n    _get_model_registry_store().delete_model_version(\n        name=request_message.name, version=request_message.version\n    )\n    return _wrap_response(DeleteModelVersion.Response())\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _get_model_version_download_uri():\n    request_message = _get_request_message(GetModelVersionDownloadUri())\n    download_uri = _get_model_registry_store().get_model_version_download_uri(\n        name=request_message.name, version=request_message.version\n    )\n    response_message = GetModelVersionDownloadUri.Response(artifact_uri=download_uri)\n    return _wrap_response(response_message)\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _search_model_versions():\n    request_message = _get_request_message(\n        SearchModelVersions(),\n        schema={\n            \"filter\": [_assert_string],\n            \"max_results\": [_assert_intlike, lambda x: _assert_less_than_or_equal(x, 200_000)],\n            \"order_by\": [_assert_array, _assert_item_type_string],\n            \"page_token\": [_assert_string],\n        },\n    )\n    store = _get_model_registry_store()\n    model_versions = store.search_model_versions(\n        filter_string=request_message.filter,\n        max_results=request_message.max_results,\n        order_by=request_message.order_by,\n        page_token=request_message.page_token,\n    )\n    response_message = SearchModelVersions.Response()\n    response_message.model_versions.extend([e.to_proto() for e in model_versions])\n    if model_versions.token:\n        response_message.next_page_token = model_versions.token\n    return _wrap_response(response_message)\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _set_model_version_tag():\n    request_message = _get_request_message(\n        SetModelVersionTag(),\n        schema={\n            \"name\": [_assert_string, _assert_required],\n            \"version\": [_assert_string, _assert_required],\n            \"key\": [_assert_string, _assert_required],\n            \"value\": [_assert_string],\n        },\n    )\n    tag = ModelVersionTag(key=request_message.key, value=request_message.value)\n    _get_model_registry_store().set_model_version_tag(\n        name=request_message.name, version=request_message.version, tag=tag\n    )\n    return _wrap_response(SetModelVersionTag.Response())\n\n\n@catch_mlflow_exception\n@_disable_if_artifacts_only\ndef _delete_model_version_tag():\n    request_message = _get_request_message(\n        DeleteModelVersionTag(),\n        schema={\n            \"name\": [_assert_string, _assert_required],\n            \"version\": [_assert_string, _assert_required],\n            \"key\": [_assert_string, _assert_required],\n        },\n    )\n    _get_model_registry_store().delete_model_version_tag(\n        name=request_message.name, version=request_message.version, key=request_message.key\n    )\n    return _wrap_response(DeleteModelVersionTag.Response())\n\n\n# MLflow Artifacts APIs\n\n\n@catch_mlflow_exception\n@_disable_unless_serve_artifacts\ndef _download_artifact(artifact_path):\n    \"\"\"\n    A request handler for `GET /mlflow-artifacts/artifacts/<artifact_path>` to download an artifact\n    from `artifact_path` (a relative path from the root artifact directory).\n    \"\"\"\n    validate_path_is_safe(validate_path_is_safe)\n    tmp_dir = tempfile.TemporaryDirectory()\n    artifact_repo = _get_artifact_repo_mlflow_artifacts()\n    dst = artifact_repo.download_artifacts(artifact_path, tmp_dir.name)\n\n    # Ref: https://stackoverflow.com/a/24613980/6943581\n    file_handle = open(dst, \"rb\")\n\n    def stream_and_remove_file():\n        yield from file_handle\n        file_handle.close()\n        tmp_dir.cleanup()\n\n    file_sender_response = current_app.response_class(stream_and_remove_file())\n\n    return _response_with_file_attachment_headers(artifact_path, file_sender_response)\n\n\n@catch_mlflow_exception\n@_disable_unless_serve_artifacts\ndef _upload_artifact(artifact_path):\n    \"\"\"\n    A request handler for `PUT /mlflow-artifacts/artifacts/<artifact_path>` to upload an artifact\n    to `artifact_path` (a relative path from the root artifact directory).\n    \"\"\"\n    validate_path_is_safe(validate_path_is_safe)\n    head, tail = posixpath.split(artifact_path)\n    with tempfile.TemporaryDirectory() as tmp_dir:\n        tmp_path = os.path.join(tmp_dir, tail)\n        with open(tmp_path, \"wb\") as f:\n            chunk_size = 1024 * 1024  # 1 MB\n            while True:\n                chunk = request.stream.read(chunk_size)\n                if len(chunk) == 0:\n                    break\n                f.write(chunk)\n\n        artifact_repo = _get_artifact_repo_mlflow_artifacts()\n        artifact_repo.log_artifact(tmp_path, artifact_path=head or None)\n\n    return _wrap_response(UploadArtifact.Response())\n\n\n@catch_mlflow_exception\n@_disable_unless_serve_artifacts\ndef _list_artifacts_mlflow_artifacts():\n    \"\"\"\n    A request handler for `GET /mlflow-artifacts/artifacts?path=<value>` to list artifacts in `path`\n    (a relative path from the root artifact directory).\n    \"\"\"\n    request_message = _get_request_message(ListArtifactsMlflowArtifacts())\n    if request_message.HasField(\"path\"):\n        validate_path_is_safe(request_message.path)\n        path = request_message.path\n    else:\n        path = None\n    artifact_repo = _get_artifact_repo_mlflow_artifacts()\n    files = []\n    for file_info in artifact_repo.list_artifacts(path):\n        basename = posixpath.basename(file_info.path)\n        new_file_info = FileInfo(basename, file_info.is_dir, file_info.file_size)\n        files.append(new_file_info.to_proto())\n    response_message = ListArtifacts.Response()\n    response_message.files.extend(files)\n    response = Response(mimetype=\"application/json\")\n    response.set_data(message_to_json(response_message))\n    return response\n\n\n@catch_mlflow_exception\n@_disable_unless_serve_artifacts\ndef _delete_artifact_mlflow_artifacts(artifact_path):\n    \"\"\"\n    A request handler for `DELETE /mlflow-artifacts/artifacts?path=<value>` to delete artifacts in\n    `path` (a relative path from the root artifact directory).\n    \"\"\"\n    validate_path_is_safe(artifact_path)\n    _get_request_message(DeleteArtifact())\n    artifact_repo = _get_artifact_repo_mlflow_artifacts()\n    artifact_repo.delete_artifacts(artifact_path)\n    response_message = DeleteArtifact.Response()\n    response = Response(mimetype=\"application/json\")\n    response.set_data(message_to_json(response_message))\n    return response\n\n\ndef _add_static_prefix(route):\n    prefix = os.environ.get(STATIC_PREFIX_ENV_VAR)\n    if prefix:\n        return prefix + route\n    return route\n\n\ndef _get_paths(base_path):\n    \"\"\"\n    A service endpoints base path is typically something like /mlflow/experiment.\n    We should register paths like /api/2.0/mlflow/experiment and\n    /ajax-api/2.0/mlflow/experiment in the Flask router.\n    \"\"\"\n    return [f\"/api/2.0{base_path}\", _add_static_prefix(f\"/ajax-api/2.0{base_path}\")]\n\n\ndef get_handler(request_class):\n    \"\"\"\n    :param request_class: The type of protobuf message\n    :return:\n    \"\"\"\n    return HANDLERS.get(request_class, _not_implemented)\n\n\ndef get_endpoints():\n    \"\"\"\n    :return: List of tuples (path, handler, methods)\n    \"\"\"\n\n    def get_service_endpoints(service):\n        ret = []\n        for service_method in service.DESCRIPTOR.methods:\n            endpoints = service_method.GetOptions().Extensions[databricks_pb2.rpc].endpoints\n            for endpoint in endpoints:\n                for http_path in _get_paths(endpoint.path):\n                    handler = get_handler(service().GetRequestClass(service_method))\n                    ret.append((http_path, handler, [endpoint.method]))\n        return ret\n\n    return (\n        get_service_endpoints(MlflowService)\n        + get_service_endpoints(ModelRegistryService)\n        + get_service_endpoints(MlflowArtifactsService)\n    )\n\n\nHANDLERS = {\n    # Tracking Server APIs\n    CreateExperiment: _create_experiment,\n    GetExperiment: _get_experiment,\n    GetExperimentByName: _get_experiment_by_name,\n    DeleteExperiment: _delete_experiment,\n    RestoreExperiment: _restore_experiment,\n    UpdateExperiment: _update_experiment,\n    CreateRun: _create_run,\n    UpdateRun: _update_run,\n    DeleteRun: _delete_run,\n    RestoreRun: _restore_run,\n    LogParam: _log_param,\n    LogMetric: _log_metric,\n    SetExperimentTag: _set_experiment_tag,\n    SetTag: _set_tag,\n    DeleteTag: _delete_tag,\n    LogBatch: _log_batch,\n    LogModel: _log_model,\n    GetRun: _get_run,\n    SearchRuns: _search_runs,\n    ListArtifacts: _list_artifacts,\n    GetMetricHistory: _get_metric_history,\n    SearchExperiments: _search_experiments,\n    # Model Registry APIs\n    CreateRegisteredModel: _create_registered_model,\n    GetRegisteredModel: _get_registered_model,\n    DeleteRegisteredModel: _delete_registered_model,\n    UpdateRegisteredModel: _update_registered_model,\n    RenameRegisteredModel: _rename_registered_model,\n    SearchRegisteredModels: _search_registered_models,\n    GetLatestVersions: _get_latest_versions,\n    CreateModelVersion: _create_model_version,\n    GetModelVersion: _get_model_version,\n    DeleteModelVersion: _delete_model_version,\n    UpdateModelVersion: _update_model_version,\n    TransitionModelVersionStage: _transition_stage,\n    GetModelVersionDownloadUri: _get_model_version_download_uri,\n    SearchModelVersions: _search_model_versions,\n    SetRegisteredModelTag: _set_registered_model_tag,\n    DeleteRegisteredModelTag: _delete_registered_model_tag,\n    SetModelVersionTag: _set_model_version_tag,\n    DeleteModelVersionTag: _delete_model_version_tag,\n    # MLflow Artifacts APIs\n    DownloadArtifact: _download_artifact,\n    UploadArtifact: _upload_artifact,\n    ListArtifactsMlflowArtifacts: _list_artifacts_mlflow_artifacts,\n    DeleteArtifact: _delete_artifact_mlflow_artifacts,\n}\n", "patch": "@@ -1573,7 +1573,7 @@ def _download_artifact(artifact_path):\n     A request handler for `GET /mlflow-artifacts/artifacts/<artifact_path>` to download an artifact\n     from `artifact_path` (a relative path from the root artifact directory).\n     \"\"\"\n-    validate_path_is_safe(validate_path_is_safe)\n+    validate_path_is_safe(artifact_path)\n     tmp_dir = tempfile.TemporaryDirectory()\n     artifact_repo = _get_artifact_repo_mlflow_artifacts()\n     dst = artifact_repo.download_artifacts(artifact_path, tmp_dir.name)\n@@ -1598,7 +1598,7 @@ def _upload_artifact(artifact_path):\n     A request handler for `PUT /mlflow-artifacts/artifacts/<artifact_path>` to upload an artifact\n     to `artifact_path` (a relative path from the root artifact directory).\n     \"\"\"\n-    validate_path_is_safe(validate_path_is_safe)\n+    validate_path_is_safe(artifact_path)\n     head, tail = posixpath.split(artifact_path)\n     with tempfile.TemporaryDirectory() as tmp_dir:\n         tmp_path = os.path.join(tmp_dir, tail)", "file_path": "files/2023_3/400", "file_language": "py", "file_name": "mlflow/server/handlers.py", "outdated_file_modify": 1, "outdated_file_before": 0, "outdated_file_after": 0, "llm_check": 1, "static_check": 0, "static": {"rats": [false, []], "semgrep": [false, []]}, "target": -1, "function_before": [], "function_after": []}], "outdated": 0, "cwe_descripiton": "", "cwe_consequence": "", "cwe_method": "", "cwe_solution": ""}
