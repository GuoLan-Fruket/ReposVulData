{"index": 8141, "cve_id": "CVE-2022-1813", "cwe_id": ["CWE-78"], "cve_language": "Python", "cve_description": "OS Command Injection in GitHub repository yogeshojha/rengine prior to 1.2.0.", "cvss": "9.8", "publish_date": "May 22, 2022", "AV": "NETWORK", "AC": "NETWORK", "PR": "NONE", "UI": "NONE", "S": "UNCHANGED", "C": "HIGH", "I": "HIGH", "A": "HIGH", "commit_id": "8277cec0f008a0451371a92e7e0bf082ab3f0c34", "commit_message": "Fix command injection issue on detect cms", "commit_date": "2022-05-22T15:41:29Z", "project": "yogeshojha/rengine", "url": "https://api.github.com/repos/yogeshojha/rengine/commits/8277cec0f008a0451371a92e7e0bf082ab3f0c34", "html_url": "https://github.com/yogeshojha/rengine/commit/8277cec0f008a0451371a92e7e0bf082ab3f0c34", "windows_before": [{"commit_id": "72a5fb2eb766c7b0334a3420af7576a60c95b182", "commit_date": "Sun May 22 19:44:19 2022 +0530", "commit_message": "Updated Security.md", "files_name": [".github/SECURITY.md"]}, {"commit_id": "669a93e69b8a705a203eff76d8899ace1f9da3ae", "commit_date": "Sun May 22 19:26:24 2022 +0530", "commit_message": "Fixed XSS on Hackerone Markdown Report", "files_name": [".github/SECURITY.md", "web/scanEngine/templates/scanEngine/settings/hackerone.html"]}, {"commit_id": "f5bad1dc168706b76e18cd934b5303fdbb154b85", "commit_date": "Sun May 22 19:14:33 2022 +0530", "commit_message": "Added DOM purify", "files_name": ["web/templates/base/base.html"]}, {"commit_id": "aca1a0b9171a9c72c224910ecdeb562f6508ed68", "commit_date": "Sun May 15 01:48:10 2022 +0530", "commit_message": "Merge pull request #631 from shirishupadhyay/release/1.2.0", "files_name": ["213bcee4b6e2243240cbcaba2338e3fa8ab551ed - Sun May 15 01:45:24 2022 +0530 : Updated Security", ".github/SECURITY.md"]}, {"commit_id": "22fc9617b053a935305b802151fa0a4e3d3ee444", "commit_date": "Sun May 15 01:42:31 2022 +0530", "commit_message": "Fix xss in import target", "files_name": ["web/targetApp/templates/target/add.html"]}, {"commit_id": "a4d1df476fb358c2f9c86ff82ba44b0875589cd3", "commit_date": "Sun May 15 01:29:23 2022 +0530", "commit_message": "remove dummy value", "files_name": ["web/static/custom/toolbox.js"]}, {"commit_id": "3be3479ce9f7de2789200ee437920c242bce01e7", "commit_date": "Sun May 15 01:20:34 2022 +0530", "commit_message": "Fix error message", "files_name": ["web/api/views.py"]}, {"commit_id": "2b67be8f661105860d11866298d16227f346d489", "commit_date": "Sun May 15 01:19:39 2022 +0530", "commit_message": "space to tabs", "files_name": ["web/reNgine/tasks.py"]}, {"commit_id": "c17c0fe806bc3dbfcc287d9b9751aff2a3d14f39", "commit_date": "Sun May 15 01:19:32 2022 +0530", "commit_message": "Added function to validate HTTP URL", "files_name": ["web/static/custom/custom.js"]}, {"commit_id": "3d5f1724dd12cf9861443742e7d7c02ff8c75a6f", "commit_date": "Sun May 15 01:19:09 2022 +0530", "commit_message": "Added WAF Detector Toolbox", "files_name": ["web/api/urls.py", "web/api/views.py", "web/static/custom/toolbox.js", "web/static/img/firewall.png", "web/templates/base/_items/top_bar.html"]}, {"commit_id": "41f6dbefe070146d853bfb08827656221b5c97e2", "commit_date": "Tue May 3 22:43:07 2022 +0530", "commit_message": "Added Waf detection badges", "files_name": ["web/startScan/templates/startScan/subdomains.html", "web/targetApp/templates/target/summary.html"]}, {"commit_id": "5df710d17231ee80906d628d19b269fa8a168092", "commit_date": "Sun May 1 01:45:29 2022 +0530", "commit_message": "Added waf badges", "files_name": ["web/api/serializers.py", "web/startScan/templates/startScan/detail_scan.html"]}, {"commit_id": "d00afae43bedce026e32a06c7cdcdbc4a41d392d", "commit_date": "Sun May 1 01:13:19 2022 +0530", "commit_message": "fix stop scan without scan activity", "files_name": ["web/api/views.py"]}, {"commit_id": "ed34f4277bdaedcf9d6f9897bbd1a5ba2b1c25c1", "commit_date": "Sun May 1 01:05:54 2022 +0530", "commit_message": "Added waf migrations", "files_name": ["web/startScan/migrations/0023_auto_20220430_1933.py"]}, {"commit_id": "398b35c3ad22daefd273ce5f6cf7a266591c8c4b", "commit_date": "Sun May 1 01:02:57 2022 +0530", "commit_message": "Added wafw00f", "files_name": ["web/reNgine/tasks.py", "web/requirements.txt", "web/startScan/admin.py", "web/startScan/models.py"]}, {"commit_id": "c346ba82c3c61c86de6a1c5cfff77aeb32a4d4fc", "commit_date": "Fri Dec 31 14:16:35 2021 +0100", "commit_message": "fix hardcoded db host to respect environment settings", "files_name": ["web/beat-entrypoint.sh", "web/celery-entrypoint.sh", "web/entrypoint.sh"]}, {"commit_id": "8b57976c8d62f8db322e96c62014c8c6e469b23e", "commit_date": "Mon Apr 25 15:40:29 2022 +0530", "commit_message": "Merge pull request #617 from yogeshojha/release/1.1", "files_name": ["eba3800bb455284e618c01c7481421b692644edb - Mon Apr 25 15:29:12 2022 +0530 : update readme", "README.md"]}, {"commit_id": "5a8c0b8cbb23841adf7bcf23bd0f33a7d411a1c5", "commit_date": "Mon Apr 25 15:21:34 2022 +0530", "commit_message": "Merge branch 'release/1.1' of github.com:yogeshojha/rengine into release/1.1", "files_name": ["099113449e8f38e1bb3815d13d158c72093e71b2 - Mon Apr 25 15:21:22 2022 +0530 : fix artwork", "install.sh", "scripts/uninstall.sh", "web/art/1.1.txt", "web/manage.py"]}, {"commit_id": "0397b3f356123228d1b2c14b8f26986a2d2f77f0", "commit_date": "Mon Apr 25 15:17:59 2022 +0530", "commit_message": "Merge pull request #618 from nerrorsec/patch-1", "files_name": ["8f8cc0dd19729024321e3a9dd94ece7f981ab890 - Mon Apr 25 15:00:36 2022 +0530 : Merge pull request #619 from nerrorsec/patch-2", "0b45743f9ab17ef5d988688f820e95fd2b5a9ab6 - Mon Apr 25 11:39:38 2022 +0545 : Update custom.js", "web/static/custom/custom.js"]}, {"commit_id": "71c919f4eb131ec8d581f399a58662cbf3a9b4a6", "commit_date": "Mon Apr 25 11:20:44 2022 +0545", "commit_message": "Fixes stored xss via Scan Engine Name", "files_name": ["web/static/custom/right_sidebar.js"]}, {"commit_id": "49a9e865b9d609313394ee2da9f7544d4e2db130", "commit_date": "Mon Apr 25 01:24:45 2022 +0530", "commit_message": "Updated changelog", "files_name": ["CHANGELOG.md"]}, {"commit_id": "08801138f148a4115176812da00fe7c1b583ab21", "commit_date": "Mon Apr 25 01:21:29 2022 +0530", "commit_message": "update readme", "files_name": ["README.md"]}, {"commit_id": "04eb95e28c6cea020eb8d36e53da3a9167ee4d48", "commit_date": "Mon Apr 25 01:16:03 2022 +0530", "commit_message": "Fix all screenshots on readme", "files_name": [".github/screenshots/1.gif", ".github/screenshots/2.gif", ".github/screenshots/dark.gif", ".github/screenshots/filtering.gif", ".github/screenshots/hackerone.gif", ".github/screenshots/hackerone1.gif", ".github/screenshots/notif.gif", ".github/screenshots/organization.gif", ".github/screenshots/rengine_1.jpeg", ".github/screenshots/scan_results.gif", ".github/screenshots/screenshot.gif", ".github/screenshots/todo.gif", ".github/screenshots/tool.gif", ".github/screenshots/visualization.gif", "README.md"]}, {"commit_id": "807ab143d38386d986a2b34dd42d36fbd27080c1", "commit_date": "Sun Apr 24 23:16:21 2022 +0530", "commit_message": "Merge branch 'release/1.1' of github.com:yogeshojha/rengine into release/1.1", "files_name": ["b077b79c36b29ffd7762316a39f9e01746f4a01d - Sun Apr 24 23:12:37 2022 +0530 : update readme", "README.md"]}, {"commit_id": "4ca664c9f5fccdb1c0d4d78f57e40a08561f37e9", "commit_date": "Sun Apr 24 22:54:40 2022 +0530", "commit_message": "udpate readme for 1.1", "files_name": ["README.md", "web/entrypoint.sh"]}, {"commit_id": "41d52e4d2e4010ff48f31ef3fe452150d491ff3c", "commit_date": "Sun Apr 24 22:28:44 2022 +0530", "commit_message": "fixed default scan engine fixture", "files_name": ["web/fixtures/default_scan_engines.yaml"]}, {"commit_id": "273cf1b5563b79a97e4d8f06153a055294a9012c", "commit_date": "Sun Apr 24 21:53:38 2022 +0530", "commit_message": "fix tisks", "files_name": ["README.md", "web/reNgine/tasks.py"]}, {"commit_id": "c579c6a66391221cd7b2250404a8bffe81275b17", "commit_date": "Sun Apr 24 20:31:48 2022 +0530", "commit_message": "fixed default yaml config", "files_name": ["default_yaml_config.yaml", "web/scanEngine/templates/scanEngine/_items/form_engine.html", "web/scanEngine/templates/scanEngine/add_engine.html"]}, {"commit_id": "39bff8a7aaaa4058d005056aef62f8cc723f2f51", "commit_date": "Sun Apr 24 20:24:01 2022 +0530", "commit_message": "added default_yaml config", "files_name": ["default_yaml_config.yaml"]}, {"commit_id": "814d74c5eebfcb5281727f32fc95bcc5eccfd61f", "commit_date": "Sun Apr 24 20:17:39 2022 +0530", "commit_message": "fix custom header", "files_name": ["web/reNgine/tasks.py", "web/scanEngine/templates/scanEngine/settings/_items/external_tool_form.html"]}, {"commit_id": "1d0f28604c03fe69f8012a0823b09a616b889578", "commit_date": "Sun Apr 24 18:26:30 2022 +0530", "commit_message": "fix http crawler", "files_name": ["web/reNgine/tasks.py"]}, {"commit_id": "6490a2d50f3eb5f7e57803668530fa0f5fa70465", "commit_date": "Sun Apr 24 01:53:05 2022 +0530", "commit_message": "Added env var for concurrency", "files_name": [".env", "docker-compose.dev.yml", "docker-compose.yml"]}, {"commit_id": "27e1c8d0ea5046a377128693af5831aaa8d74759", "commit_date": "Sun Apr 24 01:44:19 2022 +0530", "commit_message": "ready to release, fixed celery autoscale :rocket:", "files_name": ["docker-compose.yml"]}, {"commit_id": "58cb43a01b6d325faad0c5ef9b55dc3686aca47c", "commit_date": "Sun Apr 24 01:41:49 2022 +0530", "commit_message": "Added Custom header option #532", "files_name": ["web/reNgine/definitions.py", "web/reNgine/tasks.py"]}, {"commit_id": "ece8aa4908dd6446ce311ad43608d6d495f1b9d3", "commit_date": "Sun Apr 24 01:27:56 2022 +0530", "commit_message": "fix links in metro", "files_name": ["web/api/views.py", "web/templates/report/template.html"]}, {"commit_id": "519e6ff41ab3e025bf52507cd1725c43417047b5", "commit_date": "Sun Apr 24 01:25:31 2022 +0530", "commit_message": "fix report", "files_name": ["web/templates/report/template.html"]}, {"commit_id": "5c84827dd0b470891363eb2a9a91c194abe705d9", "commit_date": "Sun Apr 24 01:21:38 2022 +0530", "commit_message": "fix severity issue in report", "files_name": ["web/scanEngine/forms.py", "web/scanEngine/templates/scanEngine/settings/report.html", "web/startScan/models.py", "web/startScan/views.py", "web/templates/report/template.html"]}, {"commit_id": "6e4fb239e48cca98e665cec2c0680df82a3bdc72", "commit_date": "Sun Apr 24 00:41:39 2022 +0530", "commit_message": "Added theHarvester fixture", "files_name": ["web/api/views.py", "web/fixtures/external_tools.yaml"]}, {"commit_id": "ba4c1f25eb6f9a549f7c845698fb9b4df94beedc", "commit_date": "Sun Apr 24 00:10:54 2022 +0530", "commit_message": "Added search history clickable", "files_name": ["web/templates/base/base.html"]}, {"commit_id": "f1629b7e3c430afcd91ec7a9d8b1ed310fccab2f", "commit_date": "Sun Apr 24 00:09:33 2022 +0530", "commit_message": "Added Search History", "files_name": ["web/api/serializers.py", "web/api/urls.py", "web/api/views.py", "web/dashboard/templates/dashboard/search.html", "web/static/custom/custom.js", "web/templates/base/_items/top_bar.html", "web/templates/base/base.html"]}, {"commit_id": "36bfaa036534b98eaf941181c18a5623c66bad2c", "commit_date": "Sat Apr 23 23:41:17 2022 +0530", "commit_message": "Add search history", "files_name": ["web/api/views.py", "web/dashboard/admin.py", "web/dashboard/migrations/0001_initial.py", "web/dashboard/migrations/0002_rename_name_searchhistory_query.py", "web/dashboard/migrations/__init__.py", "web/dashboard/models.py", "web/dashboard/templates/dashboard/search.html"]}, {"commit_id": "b86c0e45e027048a4e7b40afd74f100d3f0d0c80", "commit_date": "Sat Apr 23 23:21:03 2022 +0530", "commit_message": "Added vulnerability and endpoints on search", "files_name": ["web/api/views.py", "web/dashboard/templates/dashboard/search.html", "web/static/custom/custom.js"]}, {"commit_id": "5c8e2b22ceef4e8cc95a2e07d44b6c35ec3c7b03", "commit_date": "Sat Apr 23 23:00:50 2022 +0530", "commit_message": "added subdomain clickable", "files_name": ["web/api/views.py", "web/dashboard/templates/dashboard/search.html", "web/startScan/templates/startScan/subdomains.html"]}, {"commit_id": "fd8967d60e7e3c5b6b16523c595b0857bea73e0b", "commit_date": "Sat Apr 23 22:42:41 2022 +0530", "commit_message": "Added subdomain in search section", "files_name": ["web/api/views.py", "web/dashboard/templates/dashboard/search.html"]}], "windows_after": [{"commit_id": "2c694f6ecb95be2e47c53dfdccc6b47a263eb508", "commit_date": "Mon May 23 09:54:45 2022 +0530", "commit_message": "Fix command injection on subdomain gathering", "files_name": [".github/SECURITY.md", "web/reNgine/tasks.py"]}, {"commit_id": "8fed51a443503c0d2df659d859f806b54f2e6c09", "commit_date": "Mon May 23 11:51:16 2022 +0530", "commit_message": "Fix command injection on proxy", "files_name": [".github/SECURITY.md", "web/reNgine/tasks.py"]}, {"commit_id": "7356242b31dc07ed99a604ea4441d7b1fe0d23ed", "commit_date": "Mon May 23 11:58:42 2022 +0530", "commit_message": "fix instances of command injection", "files_name": ["web/reNgine/tasks.py"]}, {"commit_id": "9f07020ef4d6084db7716e280a7da1201c9d06f5", "commit_date": "Mon May 23 12:02:59 2022 +0530", "commit_message": "update security.md", "files_name": [".github/SECURITY.md"]}, {"commit_id": "e2c0c29d22aa5242670c07c565f4eb67cf615836", "commit_date": "Wed May 25 10:27:47 2022 +0530", "commit_message": "fix proxy issue in nuclei", "files_name": ["web/reNgine/tasks.py"]}, {"commit_id": "a70bb61ac94c0e0743516aaec917f58648417ad9", "commit_date": "Wed May 25 10:41:53 2022 +0530", "commit_message": "fix hakrawler", "files_name": ["web/reNgine/tasks.py"]}, {"commit_id": "9a9596bf04d47f3381c79a8f3fc176c8dfef3e18", "commit_date": "Thu May 26 20:36:29 2022 +0530", "commit_message": "Fix for #630 where character name was too long", "files_name": ["web/scanEngine/migrations/0002_auto_20220526_1457.py", "web/scanEngine/models.py", "web/startScan/migrations/0024_auto_20220526_1454.py", "web/startScan/migrations/0025_auto_20220526_1500.py", "web/startScan/migrations/0026_auto_20220526_1506.py", "web/startScan/models.py"]}, {"commit_id": "cced87d071a771e1719d31ec8f8b1af0feeaa622", "commit_date": "Thu May 26 20:48:48 2022 +0530", "commit_message": "Update Readme", "files_name": ["README.md"]}, {"commit_id": "42f8d66d3e1a7ba3c87f04bc59f2e57496c41411", "commit_date": "Fri May 27 11:30:49 2022 +0530", "commit_message": "fix ip and port collision", "files_name": ["web/reNgine/tasks.py", "web/templates/base/_items/subdomain_tab_content.html"]}, {"commit_id": "7e799d772660b4a8e523a84068a404bc6d347438", "commit_date": "Fri May 27 11:33:14 2022 +0530", "commit_message": "Exclude cdn port scanning for naabu", "files_name": ["web/reNgine/tasks.py"]}, {"commit_id": "381f7bd71a99db1a87d0ca209bc5d859c8aae8f9", "commit_date": "Fri May 27 12:21:27 2022 +0530", "commit_message": "Changelog Updated", "files_name": ["CHANGELOG.md", "docker-compose.yml", "web/templates/base/_items/top_bar.html"]}, {"commit_id": "61d11afa005992b4cde3630b3b6588748dd7fc63", "commit_date": "Sat May 28 22:22:38 2022 +0530", "commit_message": "Fix version", "files_name": ["docker-compose.dev.yml", "web/templates/base/base.html"]}, {"commit_id": "14e058f0ba3ca82bd2b7fff8c444a0f23deb91a6", "commit_date": "Sun May 29 22:34:11 2022 +0530", "commit_message": "use latest version of docker-compose and install curl", "files_name": ["install.sh"]}, {"commit_id": "a2486efc4bd96bb31b8954b3a4005dd98e540245", "commit_date": "Sun May 29 22:51:40 2022 +0530", "commit_message": "Added changelog message", "files_name": ["web/api/views.py", "web/templates/base/base.html"]}, {"commit_id": "a2228ace1f2b224cc5ef626b237c48d11911e129", "commit_date": "Sun May 29 22:58:41 2022 +0530", "commit_message": "fix rengine art", "files_name": ["web/art/1.0.txt", "web/art/1.1.txt", "web/art/reNgine.txt", "web/manage.py"]}, {"commit_id": "ccec28e89a994d256b79025537880f9138354737", "commit_date": "Sun May 29 23:08:42 2022 +0530", "commit_message": "Update Readme", "files_name": ["README.md"]}, {"commit_id": "2850f45e085db9f82ec372ae0379b0fee59506fe", "commit_date": "Sun May 29 23:09:20 2022 +0530", "commit_message": "Update changelog", "files_name": ["CHANGELOG.md"]}, {"commit_id": "b621dfe5e42389f602b7663bd1bdbfd7b25c1f5d", "commit_date": "Mon May 30 00:19:34 2022 +0530", "commit_message": "Updated Readme", "files_name": ["README.md"]}, {"commit_id": "a0f7fbca8c72eb27e54edd4cc62405f7fde92707", "commit_date": "Mon May 30 00:25:53 2022 +0530", "commit_message": "Update Readme", "files_name": ["README.md"]}, {"commit_id": "2a5e1b94c3f831d1cf80f2ec32e052e4f77e8546", "commit_date": "Mon May 30 00:31:08 2022 +0530", "commit_message": "fix naabu", "files_name": ["web/reNgine/tasks.py"]}, {"commit_id": "188b300fb9e14d6f63169af546a7b598b22f0535", "commit_date": "Mon May 30 00:38:15 2022 +0530", "commit_message": "fix migration issue", "files_name": ["web/beat-entrypoint.sh"]}, {"commit_id": "821ae47d8a99ac99692306c979ca1fbdd780da31", "commit_date": "Mon May 30 01:40:06 2022 +0530", "commit_message": "Merge pull request #638 from yogeshojha/release/1.2.0", "files_name": ["900275718049c8cf0bbb4b1e1fe153bd97feb982 - Mon Jun 13 08:31:12 2022 -0600 : Change wording on Organization update page", "web/targetApp/templates/organization/update.html"]}, {"commit_id": "8b8f6f826645a96bc577b7d7eba2793af99f3177", "commit_date": "Tue Jun 14 22:58:39 2022 +0530", "commit_message": "Added New Whois Model", "files_name": ["web/Dockerfile", "web/reNgine/common_func.py", "web/requirements.txt", "web/targetApp/admin.py", "web/targetApp/migrations/0011_domaininfo_date_expiration.py", "web/targetApp/models.py"]}, {"commit_id": "bacaaa291f8f460e930cec58ef92ebff43ea6c99", "commit_date": "Tue Jun 14 23:08:26 2022 +0530", "commit_message": "Updated whois model", "files_name": ["web/targetApp/migrations/0012_auto_20220614_1738.py", "web/targetApp/models.py"]}, {"commit_id": "ee394bddef09a28518548528851efa4f7174c135", "commit_date": "Wed Jun 15 10:05:17 2022 +0530", "commit_message": "Updaed Whois Model", "files_name": ["web/reNgine/common_func.py", "web/requirements.txt", "web/targetApp/migrations/0013_auto_20220615_0428.py", "web/targetApp/models.py"]}, {"commit_id": "0f47c9a23c30c818136dc8fbbd5b91f48a2ac70c", "commit_date": "Wed Jun 15 10:50:08 2022 +0530", "commit_message": "Fixed whois response", "files_name": ["web/reNgine/common_func.py", "web/targetApp/migrations/0014_auto_20220615_0510.py", "web/targetApp/models.py"]}, {"commit_id": "da1faf385153cf65f8a512022928a3f68fc7b146", "commit_date": "Thu Jun 16 21:47:06 2022 +0530", "commit_message": "added registrant and tech to db", "files_name": ["web/reNgine/common_func.py", "web/targetApp/admin.py", "web/targetApp/migrations/0015_auto_20220615_0524.py", "web/targetApp/migrations/0016_alter_domaininfo_registrar.py", "web/targetApp/migrations/0017_domaininfo_ip_address.py", "web/targetApp/models.py"]}, {"commit_id": "38646238bf32e1d9b200ee719747380072e55833", "commit_date": "Thu Jun 16 21:58:06 2022 +0530", "commit_message": "Added nameservers", "files_name": ["web/reNgine/common_func.py", "web/targetApp/migrations/0018_domaininfo_name_servers.py", "web/targetApp/models.py"]}, {"commit_id": "8dbaa1849bce58aef3dc405354a50c292fa5610e", "commit_date": "Sat Jun 18 15:41:03 2022 +0530", "commit_message": "Fix whois status :rocket:", "files_name": ["web/reNgine/common_func.py", "web/reNgine/common_serializers.py", "web/targetApp/migrations/0019_auto_20220616_1637.py", "web/targetApp/migrations/0020_auto_20220617_0552.py", "web/targetApp/migrations/0021_domaininfo_ip_address.py", "web/targetApp/migrations/0022_auto_20220617_0554.py", "web/targetApp/migrations/0023_auto_20220617_0554.py", "web/targetApp/models.py"]}, {"commit_id": "81453a57d6869a2763abb843bcf7178f0f7331ad", "commit_date": "Sat Jun 18 15:47:49 2022 +0530", "commit_message": "fix whois domain registrar", "files_name": ["web/reNgine/common_func.py"]}, {"commit_id": "a9175c012ee1131623c5fcc6832bc879c972bf32", "commit_date": "Sat Jun 18 20:22:20 2022 +0530", "commit_message": "Updated whois ui", "files_name": ["web/startScan/templates/startScan/detail_scan.html", "web/static/custom/custom.js", "web/targetApp/templates/target/summary.html"]}, {"commit_id": "8ce420b94b60c9985c175ff44d60ecdd333bf83d", "commit_date": "Sat Jul 2 11:39:11 2022 +0530", "commit_message": "fix whois ui", "files_name": ["web/reNgine/common_func.py", "web/reNgine/settings.py", "web/requirements.txt", "web/startScan/templates/startScan/detail_scan.html"]}, {"commit_id": "f0d199f91532aecc73ed221dac184977c88bc9a0", "commit_date": "Sat Jul 2 12:46:56 2022 +0530", "commit_message": "Added domain id for whois", "files_name": ["web/reNgine/common_func.py", "web/startScan/templates/startScan/detail_scan.html"]}, {"commit_id": "f5c089961edb22ef820db0ce8399cbbb1f0cb0be", "commit_date": "Sat Jul 2 13:05:34 2022 +0530", "commit_message": "fix target summary whois", "files_name": ["web/startScan/templates/startScan/detail_scan.html", "web/targetApp/templates/target/summary.html"]}, {"commit_id": "fcde00cff362b7cb1b80d9e7284f396983cf003c", "commit_date": "Fri Jul 8 23:05:12 2022 +0530", "commit_message": "Added whois email", "files_name": ["web/startScan/templates/startScan/detail_scan.html", "web/static/custom/custom.js", "web/targetApp/templates/target/summary.html"]}, {"commit_id": "944a1ec91547d5cf7e5421f203cf5773124581ac", "commit_date": "Fri Jul 8 23:51:45 2022 +0530", "commit_message": "added whois for toolbox", "files_name": ["web/static/custom/custom.js"]}, {"commit_id": "348d93e7e47661a935fcbcfa6c455bc73e180bca", "commit_date": "Sat Jul 9 01:21:16 2022 +0530", "commit_message": "fix httpx", "files_name": ["web/Dockerfile", "web/celery-entrypoint.sh"]}, {"commit_id": "f07d3eef621a8cbe1c0a55bb0d4fe6247b69edc1", "commit_date": "Sat Jul 9 11:03:23 2022 +0530", "commit_message": "httpx direct go path", "files_name": ["web/reNgine/tasks.py"]}, {"commit_id": "d0a7c40ac7189266680a5373b0d7372106c822cd", "commit_date": "Sat Jul 9 11:41:18 2022 +0530", "commit_message": "Added jvector map", "files_name": ["web/startScan/templates/startScan/detail_scan.html", "web/static/plugins/j-map/jquery-jvectormap-1.2.2.css", "web/static/plugins/j-map/jquery-jvectormap-1.2.2.min.js", "web/static/plugins/j-map/maps/jquery-jvectormap-world-mill-en.js"]}, {"commit_id": "ba87e73c931f203702ec6f3bfbe6fb5a1cf4e91e", "commit_date": "Sat Jul 9 11:41:25 2022 +0530", "commit_message": "Add geo iso model", "files_name": ["web/startScan/migrations/0027_auto_20220709_0610.py", "web/startScan/models.py"]}, {"commit_id": "14f973ead74614e2a7f19ffe6f0837ea450ed7b6", "commit_date": "Sun Jul 10 16:12:45 2022 +0530", "commit_message": "Added assets by country map", "files_name": ["web/Dockerfile", "web/reNgine/tasks.py", "web/src/spyse-python", "web/startScan/admin.py", "web/startScan/models.py", "web/startScan/templates/startScan/detail_scan.html", "web/startScan/views.py"]}, {"commit_id": "8faf10e1f0b4fe81212966b701f675c329d7c4e8", "commit_date": "Sun Jul 10 16:37:57 2022 +0530", "commit_message": "Fixed flags", "files_name": ["web/reNgine/settings.py", "web/requirements.txt", "web/startScan/templates/startScan/detail_scan.html"]}, {"commit_id": "ceb318f57676265515b0156f381c081971a992e1", "commit_date": "Sun Jul 10 19:00:01 2022 +0530", "commit_message": "fix geoip full_country name", "files_name": ["web/Dockerfile", "web/reNgine/tasks.py", "web/startScan/migrations/0028_auto_20220710_1140.py", "web/startScan/models.py", "web/startScan/templates/startScan/detail_scan.html"]}, {"commit_id": "0bb77ec38da2daec716ef792a57e897e7a2147b8", "commit_date": "Sun Jul 10 19:26:36 2022 +0530", "commit_message": "Updated vector map", "files_name": []}], "parents": [{"commit_id_before": "72a5fb2eb766c7b0334a3420af7576a60c95b182", "url_before": "https://api.github.com/repos/yogeshojha/rengine/commits/72a5fb2eb766c7b0334a3420af7576a60c95b182", "html_url_before": "https://github.com/yogeshojha/rengine/commit/72a5fb2eb766c7b0334a3420af7576a60c95b182"}], "details": [{"raw_url": "https://github.com/yogeshojha/rengine/raw/8277cec0f008a0451371a92e7e0bf082ab3f0c34/web%2FreNgine%2Fcommon_func.py", "code": "import os\nimport re\nimport json\nimport random\nimport requests\nimport tldextract\nimport logging\nimport shutil\nimport subprocess\n\nfrom threading import Thread\n\nfrom urllib.parse import urlparse\n\nfrom bs4 import BeautifulSoup\nfrom lxml import html\n\nfrom discord_webhook import DiscordWebhook\nfrom django.db.models import Q\nfrom functools import reduce\nfrom scanEngine.models import *\nfrom startScan.models import *\nfrom targetApp.models import *\nfrom reNgine.definitions import *\nfrom rest_framework import serializers\n\n\n# Serializers for NS\nclass NSRecordSerializer(serializers.ModelSerializer):\n    class Meta:\n        model = NSRecord\n        fields = '__all__'\n\n\nclass NameServerHistorySerializer(serializers.ModelSerializer):\n    class Meta:\n        model = NameServerHistory\n        fields = '__all__'\n\n\nclass AssociatedDomainSerializer(serializers.ModelSerializer):\n    class Meta:\n        model = AssociatedDomain\n        fields = '__all__'\n\n\ndef get_lookup_keywords():\n    default_lookup_keywords = [\n        key.strip() for key in InterestingLookupModel.objects.get(\n            id=1).keywords.split(',')]\n    custom_lookup_keywords = []\n    if InterestingLookupModel.objects.filter(custom_type=True):\n        custom_lookup_keywords = [\n            key.strip() for key in InterestingLookupModel.objects.filter(\n                custom_type=True).order_by('-id')[0].keywords.split(',')]\n    lookup_keywords = default_lookup_keywords + custom_lookup_keywords\n    # remove empty strings from list, if any\n    lookup_keywords = list(filter(None, lookup_keywords))\n\n    return lookup_keywords\n\n\ndef get_interesting_subdomains(scan_history=None, target=None):\n    lookup_keywords = get_lookup_keywords()\n\n    subdomain_lookup_query = Q()\n    page_title_lookup_query = Q()\n\n    for key in lookup_keywords:\n        if InterestingLookupModel.objects.filter(custom_type=True).exists():\n            if InterestingLookupModel.objects.filter(\n                    custom_type=True).order_by('-id')[0].url_lookup:\n                subdomain_lookup_query |= Q(name__icontains=key)\n            if InterestingLookupModel.objects.filter(\n                    custom_type=True).order_by('-id')[0].title_lookup:\n                page_title_lookup_query |= Q(\n                    page_title__iregex=\"\\\\y{}\\\\y\".format(key))\n        else:\n            subdomain_lookup_query |= Q(name__icontains=key)\n            page_title_lookup_query |= Q(\n                page_title__iregex=\"\\\\y{}\\\\y\".format(key))\n\n    if InterestingLookupModel.objects.filter(\n            custom_type=True) and InterestingLookupModel.objects.filter(\n            custom_type=True).order_by('-id')[0].condition_200_http_lookup:\n        subdomain_lookup_query &= Q(http_status__exact=200)\n        page_title_lookup_query &= Q(http_status__exact=200)\n\n    subdomain_lookup = Subdomain.objects.none()\n    title_lookup = Subdomain.objects.none()\n\n    if target:\n        subdomains = Subdomain.objects.filter(target_domain__id=target).distinct('name')\n        if subdomain_lookup_query:\n            subdomain_lookup = subdomains.filter(subdomain_lookup_query)\n        if page_title_lookup_query:\n            title_lookup = subdomains.filter(page_title_lookup_query)\n    elif scan_history:\n        subdomains = Subdomain.objects.filter(scan_history__id=scan_history)\n        if subdomain_lookup_query:\n            subdomain_lookup = subdomains.filter(subdomain_lookup_query)\n        if page_title_lookup_query:\n            title_lookup = subdomains.filter(page_title_lookup_query)\n    else:\n        if subdomain_lookup_query:\n            subdomain_lookup = Subdomain.objects.filter(subdomain_lookup_query)\n        if page_title_lookup_query:\n            title_lookup = Subdomain.objects.filter(page_title_lookup_query)\n    lookup = subdomain_lookup | title_lookup\n    return lookup\n\n\ndef get_interesting_endpoint(scan_history=None, target=None):\n    lookup_keywords = get_lookup_keywords()\n\n    url_lookup_query = Q()\n    page_title_lookup_query = Q()\n\n    for key in lookup_keywords:\n        if InterestingLookupModel.objects.filter(custom_type=True).exists():\n            if InterestingLookupModel.objects.filter(custom_type=True).order_by('-id')[0].url_lookup:\n                url_lookup_query |= Q(http_url__icontains=key)\n            if InterestingLookupModel.objects.filter(custom_type=True).order_by('-id')[0].title_lookup:\n                page_title_lookup_query |= Q(page_title__iregex=\"\\\\y{}\\\\y\".format(key))\n\n        else:\n            url_lookup_query |= Q(http_url__icontains=key)\n            page_title_lookup_query |= Q(page_title__iregex=\"\\\\y{}\\\\y\".format(key))\n\n    if InterestingLookupModel.objects.filter(custom_type=True) and InterestingLookupModel.objects.filter(custom_type=True).order_by('-id')[0].condition_200_http_lookup:\n        url_lookup_query &= Q(http_status__exact=200)\n        page_title_lookup_query &= Q(http_status__exact=200)\n\n    url_lookup = EndPoint.objects.none()\n    title_lookup = EndPoint.objects.none()\n\n    if target:\n        urls = EndPoint.objects.filter(target_domain__id=target).distinct('http_url')\n        if url_lookup_query:\n            url_lookup = urls.filter(url_lookup_query)\n        if page_title_lookup_query:\n            title_lookup = urls.filter(page_title_lookup_query)\n    elif scan_history:\n        urls = EndPoint.objects.filter(scan_history__id=scan_history)\n        if url_lookup_query:\n            url_lookup = urls.filter(url_lookup_query)\n        if page_title_lookup_query:\n            title_lookup = urls.filter(page_title_lookup_query)\n\n    else:\n        if url_lookup_query:\n            url_lookup = EndPoint.objects.filter(url_lookup_query)\n        if page_title_lookup_query:\n            title_lookup = EndPoint.objects.filter(page_title_lookup_query)\n\n    return url_lookup | title_lookup\n\ndef check_keyword_exists(keyword_list, subdomain):\n    return any(sub in subdomain for sub in keyword_list)\n\ndef get_subdomain_from_url(url):\n    extract_url = tldextract.extract(url)\n    subdomain = '.'.join(extract_url[:4])\n    if subdomain[0] == '.':\n        subdomain = subdomain[1:]\n    return subdomain\n\ndef get_domain_from_subdomain(subdomain):\n    ext = tldextract.extract(subdomain)\n    return '.'.join(ext[1:3])\n\ndef send_telegram_message(message):\n    notification = Notification.objects.all()\n    if notification and notification[0].send_to_telegram \\\n    and notification[0].telegram_bot_token \\\n    and notification[0].telegram_bot_chat_id:\n        telegram_bot_token = notification[0].telegram_bot_token\n        telegram_bot_chat_id = notification[0].telegram_bot_chat_id\n        send_text = 'https://api.telegram.org/bot' + telegram_bot_token \\\n            + '/sendMessage?chat_id=' + telegram_bot_chat_id \\\n            + '&parse_mode=Markdown&text=' + message\n        thread = Thread(target=requests.get, args = (send_text, ))\n        thread.start()\n\ndef send_slack_message(message):\n    headers = {'content-type': 'application/json'}\n    message = {'text': message}\n    notification = Notification.objects.all()\n    if notification and notification[0].send_to_slack \\\n    and notification[0].slack_hook_url:\n        hook_url = notification[0].slack_hook_url\n        thread = Thread(\n            target=requests.post,\n            kwargs = {\n                'url': hook_url,\n                'data': json.dumps(message),\n                'headers': headers,\n            })\n        thread.start()\n\ndef send_discord_message(message):\n    notification = Notification.objects.all()\n    if notification and notification[0].send_to_discord \\\n    and notification[0].discord_hook_url:\n        webhook = DiscordWebhook(\n            url=notification[0].discord_hook_url,\n            content=message,\n            rate_limit_retry=True\n            )\n        thread = Thread(target=webhook.execute)\n        thread.start()\n\ndef send_files_to_discord(file_path):\n    notification = Notification.objects.all()\n    if notification and notification[0].send_to_discord \\\n    and notification[0].discord_hook_url:\n        webhook = DiscordWebhook(\n            url=notification[0].discord_hook_url,\n            rate_limit_retry=True,\n            username=\"Scan Results - File\"\n        )\n        with open(file_path, \"rb\") as f:\n            head, tail = os.path.split(file_path)\n            webhook.add_file(file=f.read(), filename=tail)\n        thread = Thread(target=webhook.execute)\n        thread.start()\n\ndef send_notification(message):\n    send_slack_message(message)\n    send_discord_message(message)\n    send_telegram_message(message)\n\ndef get_random_proxy():\n    if Proxy.objects.all().exists():\n        proxy = Proxy.objects.all()[0]\n        if proxy.use_proxy:\n            proxy_name = random.choice(proxy.proxies.splitlines())\n            print('Using proxy: ' + proxy_name)\n            return proxy_name\n    return False\n\ndef send_hackerone_report(vulnerability_id):\n    headers = {\n        'Content-Type': 'application/json',\n        'Accept': 'application/json'\n    }\n    # get hackerone creds\n    vulnerability = Vulnerability.objects.get(id=vulnerability_id)\n    # can only send vulnerability report if team_handle exists\n    if len(vulnerability.target_domain.h1_team_handle) !=0:\n        if Hackerone.objects.all().exists():\n            hackerone = Hackerone.objects.all()[0]\n            if vulnerability.severity == 0:\n                severity_value = 'none'\n            elif vulnerability.severity == 1:\n                severity_value = 'low'\n            elif vulnerability.severity == 2:\n                severity_value = 'medium'\n            elif vulnerability.severity == 3:\n                severity_value = 'high'\n            elif vulnerability.severity == 4:\n                severity_value = 'critical'\n            report_template = hackerone.report_template\n            # Replace syntax of report template with actual content\n            if '{vulnerability_name}' in report_template:\n                report_template = report_template.replace('{vulnerability_name}', vulnerability.name)\n            if '{vulnerable_url}' in report_template:\n                report_template = report_template.replace('{vulnerable_url}', vulnerability.http_url)\n            if '{vulnerability_severity}' in report_template:\n                report_template = report_template.replace('{vulnerability_severity}', severity_value)\n            if '{vulnerability_description}' in report_template:\n                report_template = report_template.replace('{vulnerability_description}', vulnerability.description if vulnerability.description else '')\n            if '{vulnerability_extracted_results}' in report_template:\n                report_template = report_template.replace('{vulnerability_extracted_results}', vulnerability.extracted_results if vulnerability.extracted_results else '')\n            if '{vulnerability_reference}' in report_template:\n                report_template = report_template.replace('{vulnerability_reference}', vulnerability.reference if vulnerability.reference else '')\n\n            data = {\n              \"data\": {\n                \"type\": \"report\",\n                \"attributes\": {\n                  \"team_handle\": vulnerability.target_domain.h1_team_handle,\n                  \"title\": '{} found in {}'.format(vulnerability.name, vulnerability.http_url),\n                  \"vulnerability_information\": report_template,\n                  \"severity_rating\": severity_value,\n                  \"impact\": \"More information about the impact and vulnerability can be found here: \\n\" + vulnerability.reference if vulnerability.reference else \"NA\",\n                }\n              }\n            }\n\n            r = requests.post(\n              'https://api.hackerone.com/v1/hackers/reports',\n              auth=(hackerone.username, hackerone.api_key),\n              json = data,\n              headers = headers\n            )\n\n            response = r.json()\n\n            # print(response)\n\n            status_code = r.status_code\n            print(status_code)\n\n            if status_code == 201:\n                vulnerability.hackerone_report_id = response['data'][\"id\"]\n                vulnerability.open_status = False\n                vulnerability.save()\n\n            return status_code\n\n    else:\n        print('No target ')\n        status_code = 111\n\n        return status_code\n\ndef get_whois(ip_domain, save_db=False, fetch_from_db=True):\n    # this function will fetch whois details for domains\n    # if save_db = True, then the whois will be saved in db\n    # if fetch_from_db = True then whois will be fetched from db, no lookup on\n    #     bigdomain data will be done\n    if ip_domain and not fetch_from_db:\n        response = requests.get('https://domainbigdata.com/{}'.format(ip_domain))\n        tree = html.fromstring(response.content)\n        try:\n            #RegistrantInfo Model\n            name = tree.xpath('//*[@id=\"trRegistrantName\"]/td[2]/a/text()')\n            organization = tree.xpath('//*[@id=\"MainMaster_trRegistrantOrganization\"]/td[2]/a/text()')\n            email = tree.xpath('//*[@id=\"trRegistrantEmail\"]/td[2]/a/text()')\n            address = tree.xpath('//*[@id=\"trRegistrantAddress\"]/td[2]/text()')\n            city = tree.xpath('//*[@id=\"trRegistrantCity\"]/td[2]/text()')\n            state = tree.xpath('//*[@id=\"trRegistrantState\"]/td[2]/text()')\n            country = tree.xpath('//*[@id=\"trRegistrantCountry\"]/td[2]/text()')\n            country_iso = tree.xpath('//*[@id=\"imgFlagRegistrant\"]/@alt')\n            tel = tree.xpath('//*[@id=\"trRegistrantTel\"]/td[2]/text()')\n            fax = tree.xpath('//*[@id=\"trRegistrantFax\"]/td[2]/text()')\n\n            #finding domain association using organization\n            organization_association_href = tree.xpath('//*[@id=\"MainMaster_trRegistrantOrganization\"]/td[2]/a/@href')\n            #finding domain association using email\n            email_association_href = tree.xpath('//*[@id=\"trRegistrantEmail\"]/td[2]/a/@href')\n\n            # related tlds\n            related_tlds = tree.xpath('//*[@id=\"divListOtherTLD\"]/descendant::*/text()')\n\n            # whois model\n            whois = tree.xpath('//*[@id=\"whois\"]/div/div[3]/text()')\n            whois = \"\\n\".join(whois).strip()\n\n            # DomainInfo Model\n            date_created = tree.xpath('//*[@id=\"trDateCreation\"]/td[2]/text()')\n            domain_age = tree.xpath('//*[@id=\"trWebAge\"]/td[2]/text()')\n            ip_address = tree.xpath('//*[@id=\"trIP\"]/td[2]/a/text()')\n            geolocation = tree.xpath('//*[@id=\"imgFlag\"]/following-sibling::text()')\n            geolocation_iso = tree.xpath('//*[@id=\"imgFlag\"]/@alt')\n\n            is_private_path = tree.xpath(\"//*[contains(@class, 'websiteglobalstats')]/tr[10]/td[2]/span/text()\")\n            is_private = False\n            if len(is_private_path) > 0:\n                is_private = True\n\n\n            date_created = date_created[0].strip() if date_created else None\n            domain_age = domain_age[0].strip() if domain_age else None\n            ip_address = ip_address[0].strip() if ip_address else None\n            geolocation = geolocation[0].strip() if geolocation else None\n            geolocation_iso = geolocation_iso[0].strip() if geolocation_iso else None\n            name = name[0].strip() if name else None\n            organization = organization[0].strip() if organization else None\n            email = email[0].strip() if email else None\n            address = address[0].strip() if address else None\n            city = city[0].strip() if city else None\n            state = state[0].strip() if state else None\n            country = country[0].strip() if country else None\n            country_iso = country_iso[0].strip() if country_iso else None\n            tel = tel[0].strip() if tel else None\n            fax = fax[0].strip() if fax else None\n\n            # association\n            organization_association_href = organization_association_href[0].strip() if organization_association_href else None\n            email_association_href = email_association_href[0].strip() if email_association_href else None\n\n            # other tlds\n            related_tlds = [ tld for tld in related_tlds if \"\\r\\n\" not in tld ]\n\n            dns_history_xpath = tree.xpath(\"//*[@id='MainMaster_divNSHistory']/table/tbody/tr\")\n            dns_history = []\n            for table_row in dns_history_xpath:\n                row = table_row.xpath('td/text()')\n                dns_history.append(\n                    {\n                        'date': row[0],\n                        'action': row[1],\n                        'nameserver': row[2],\n                    }\n                )\n\n            associated_domains = []\n            if organization_association_href and organization not in IGNORE_WHOIS_RELATED_KEYWORD:\n                # get all associated domains using organization\n                response_org = requests.get('https://domainbigdata.com{}'.format(organization_association_href))\n                tree_org = html.fromstring(response_org.content)\n                associated_domains_tree = tree_org.xpath('//*[@id=\"aDomain\"]/text()')\n                for domain in associated_domains_tree:\n                    associated_domains.append(domain)\n\n            if email_association_href and email not in IGNORE_WHOIS_RELATED_KEYWORD:\n                print(email_association_href)\n                response_email = requests.get('https://domainbigdata.com{}'.format(email_association_href))\n                tree_email = html.fromstring(response_email.content)\n                associated_domains_tree = tree_email.xpath('//*[@id=\"aDomain\"]/text()')\n                for domain in associated_domains_tree:\n                    associated_domains.append(domain)\n\n            # unique associated_domains\n            unique_associated_domains = []\n            [unique_associated_domains.append(domain) for domain in associated_domains if domain not in unique_associated_domains]\n\n            # save in db\n            if save_db and Domain.objects.filter(name=ip_domain).exists():\n                # look for domain and save in db\n                domain = Domain.objects.get(name=ip_domain)\n\n\n                # check if registrant exists\n                if RegistrantInfo.objects.filter(email=email).filter(name=name).exists():\n                    registrant = RegistrantInfo.objects.get(email=email, name=name)\n                else:\n                    registrant = RegistrantInfo()\n                    registrant.name = name\n                    registrant.organization = organization\n                    registrant.email = email\n                    registrant.address = address\n                    registrant.city = city\n                    registrant.state = state\n                    registrant.country = country\n                    registrant.country_iso = country_iso\n                    registrant.phone_number = tel\n                    registrant.fax = fax\n                    registrant.organization_association_href = organization_association_href\n                    registrant.email_association_href = email_association_href\n                    registrant.save()\n\n                if WhoisDetail.objects.filter(details=whois).exists():\n                    whois_model = WhoisDetail.objects.get(details=whois)\n                else:\n                    whois_model = WhoisDetail()\n                    whois_model.details = whois if whois else None\n                    whois_model.registrant = registrant\n                    whois_model.save()\n\n                domain_info = DomainInfo()\n                domain_info.date_created = date_created\n                domain_info.domain_age = domain_age\n                domain_info.ip_address = ip_address\n                domain_info.geolocation = geolocation\n                domain_info.geolocation_iso = geolocation_iso\n                domain_info.whois = whois_model\n                domain_info.save()\n\n                for table_row in dns_history_xpath:\n                    row = table_row.xpath('td/text()')\n                    ns_history = NameServerHistory()\n                    ns_history.date = row[0]\n                    ns_history.action = row[1]\n                    ns_history.server = row[2]\n                    ns_history.save()\n\n                    domain_info.nameserver_history.add(ns_history);\n\n                domain.domain_info = domain_info\n                domain.save()\n\n\n                # save associated domains\n                for domain in unique_associated_domains:\n                    if AssociatedDomain.objects.filter(name=domain).exists():\n                        ass_domain = AssociatedDomain.objects.get(name=domain)\n                    else:\n                        ass_domain = AssociatedDomain()\n                        ass_domain.name = domain\n                        ass_domain.save()\n                    domain_info.associated_domains.add(ass_domain)\n\n                # save related TLDs\n                for tld in related_tlds:\n                    if RelatedTLD.objects.filter(name=tld).exists():\n                        rel_tld = RelatedTLD.objects.get(name=tld)\n                    else:\n                        rel_tld = RelatedTLD()\n                        rel_tld.name = tld\n                        rel_tld.save()\n                    domain_info.related_tlds.add(rel_tld)\n\n            ns_records = []\n            for i in range(4):\n                ns_records_xpath = tree.xpath(\"//*[@id='divDNSRecords']/table[{}]/tbody/tr\".format(i))\n                for table_row in ns_records_xpath:\n                    row = table_row.xpath('td/text()')\n                    if row[0] == 'A':\n                        # for getting address, use child lookup\n                        address = table_row.xpath('td/a/text()')\n                        address = address[0] if address else None\n\n                        ns_records.append(\n                            {\n                                'type': row[0],\n                                'hostname': row[1],\n                                'address': address,\n                                'ttl': row[2],\n                                'class': row[3],\n                            }\n                        )\n\n                        if save_db and Domain.objects.filter(name=ip_domain).exists():\n                            ns = NSRecord()\n                            ns.type = row[0]\n                            ns.hostname = row[1]\n                            ns.address = address\n                            ns.ttl = row[2]\n                            ns.ns_class = row[3]\n                            ns.save()\n                            domain_info.nameserver_record.add(ns)\n\n                    elif row[0] == 'AAAA':\n                        # for getting address, use child lookup\n                        ns_records.append(\n                            {\n                                'type': row[0],\n                                'hostname': row[1],\n                                'address': row[2],\n                                'ttl': row[3],\n                                'class': row[4],\n                            }\n                        )\n\n                        if save_db and Domain.objects.filter(name=ip_domain).exists():\n                            ns = NSRecord()\n                            ns.type = row[0]\n                            ns.hostname = row[1]\n                            ns.address = row[2]\n                            ns.ttl = row[3]\n                            ns.ns_class = row[4]\n                            ns.save()\n                            domain_info.nameserver_record.add(ns)\n\n                    elif row[0] == 'MX':\n                        ns_records.append(\n                            {\n                                'type': row[0],\n                                'hostname': row[1],\n                                'address': row[2],\n                                'preference': row[3],\n                                'ttl': row[4],\n                                'class': row[5],\n                            }\n                        )\n\n                        if save_db and Domain.objects.filter(name=ip_domain).exists():\n                            ns = NSRecord()\n                            ns.type = row[0]\n                            ns.hostname = row[1]\n                            ns.address = address\n                            ns.preference = row[3]\n                            ns.ttl = row[4]\n                            ns.ns_class = row[5]\n                            ns.save()\n                            domain_info.nameserver_record.add(ns)\n\n\n            final_organization_association_url = 'https://domainbigdata.com' + organization_association_href if organization_association_href else None\n            final_email_association_url = 'https://domainbigdata.com' + email_association_href if email_association_href else None\n\n\n            return {\n                'status': True,\n                'ip_domain': ip_domain,\n                'domain': {\n                    'date_created': date_created,\n                    'domain_age': domain_age,\n                    'ip_address': ip_address,\n                    'geolocation': geolocation,\n                    'geolocation_iso': geolocation_iso,\n                },\n                'nameserver': {\n                    'history': dns_history,\n                    'records': ns_records\n                },\n                'registrant': {\n                    'name': name,\n                    'organization': organization,\n                    'email': email,\n                    'address': address,\n                    'city': city,\n                    'state': state,\n                    'country': country,\n                    'country_iso': country_iso,\n                    'tel': tel,\n                    'fax': fax,\n                    'organization_association_url': final_organization_association_url,\n                    'email_association_url': final_email_association_url,\n                },\n                'related_domains': unique_associated_domains,\n                'related_tlds': related_tlds,\n                'whois': whois if whois else None\n            }\n        except Exception as e:\n            logging.exception(e)\n            return {\n                'status': False,\n                'ip_domain': ip_domain,\n                'result': 'Domain not found'\n            }\n    elif ip_domain and fetch_from_db:\n        if Domain.objects.filter(name=ip_domain).exists():\n            domain = Domain.objects.get(name=ip_domain)\n            unique_associated_domains = []\n\n            if domain.domain_info and domain.domain_info.associated_domains:\n                unique_associated_domains = [d.name for d in domain.domain_info.associated_domains.all()]\n\n\n            unique_related_tlds = []\n            if domain.domain_info and domain.domain_info.related_tlds:\n                unique_related_tlds = [d.name for d in domain.domain_info.related_tlds.all()]\n\n            if domain.domain_info:\n                return {\n                    'status': True,\n                    'ip_domain': ip_domain,\n                    'domain': {\n                        'date_created': domain.domain_info.date_created,\n                        'domain_age': domain.domain_info.domain_age,\n                        'ip_address': domain.domain_info.ip_address,\n                        'geolocation': domain.domain_info.geolocation,\n                        'geolocation_iso': domain.domain_info.geolocation_iso,\n                    },\n                    'nameserver': {\n                        'history': NameServerHistorySerializer(domain.domain_info.nameserver_history.all(), many=True).data,\n                        'records': NSRecordSerializer(domain.domain_info.nameserver_record.all(), many=True).data\n                    },\n                    'registrant': {\n                        'name': domain.domain_info.whois.registrant.name,\n                        'organization': domain.domain_info.whois.registrant.organization,\n                        'email': domain.domain_info.whois.registrant.email,\n                        'address': domain.domain_info.whois.registrant.address,\n                        'city': domain.domain_info.whois.registrant.city,\n                        'state': domain.domain_info.whois.registrant.state,\n                        'country': domain.domain_info.whois.registrant.country,\n                        'country_iso': domain.domain_info.whois.registrant.country_iso,\n                        'tel': domain.domain_info.whois.registrant.phone_number,\n                        'fax': domain.domain_info.whois.registrant.fax,\n                    },\n                    'related_domains': unique_associated_domains,\n                    'related_tlds': unique_related_tlds,\n                    'whois': domain.domain_info.whois.details\n                }\n            return {\n                'status': False,\n                'message': 'WHOIS does not exist.'\n            }\n        return {\n            'status': False,\n            'message': 'Domain ' + ip_domain + ' does not exist as target and could not fetch WHOIS from database.'\n        }\n\n\ndef get_cms_details(url):\n    # this function will fetch cms details using cms_detector\n    response = {}\n    cms_detector_command = 'python3 /usr/src/github/CMSeeK/cmseek.py --random-agent --batch --follow-redirect'\n    subprocess_splitted_command = cms_detector_command.split()\n    subprocess_splitted_command.append('-u')\n    subprocess_splitted_command.append(url)\n    process = subprocess.Popen(subprocess_splitted_command)\n    process.wait()\n\n    response['status'] = False\n    response['message'] = 'Could not detect CMS!'\n\n    parsed_url = urlparse(url)\n\n    domain_name = parsed_url.hostname\n    port = parsed_url.port\n\n    find_dir = domain_name\n\n    if port:\n        find_dir += '_{}'.format(port)\n\n\n    print(url)\n    print(find_dir)\n\n    # subdomain may also have port number, and is stored in dir as _port\n\n    cms_dir_path =  '/usr/src/github/CMSeeK/Result/{}'.format(find_dir)\n    cms_json_path =  cms_dir_path + '/cms.json'\n\n    if os.path.isfile(cms_json_path):\n        cms_file_content = json.loads(open(cms_json_path, 'r').read())\n        if not cms_file_content.get('cms_id'):\n            return response\n        response = {}\n        response = cms_file_content\n        response['status'] = True\n        # remove cms dir path\n        try:\n            shutil.rmtree(cms_dir_path)\n        except Exception as e:\n            print(e)\n\n    return response\n", "code_before": "import os\nimport re\nimport json\nimport random\nimport requests\nimport tldextract\nimport logging\nimport shutil\n\nfrom threading import Thread\n\nfrom urllib.parse import urlparse\n\nfrom bs4 import BeautifulSoup\nfrom lxml import html\n\nfrom discord_webhook import DiscordWebhook\nfrom django.db.models import Q\nfrom functools import reduce\nfrom scanEngine.models import *\nfrom startScan.models import *\nfrom targetApp.models import *\nfrom reNgine.definitions import *\nfrom rest_framework import serializers\n\n\n# Serializers for NS\nclass NSRecordSerializer(serializers.ModelSerializer):\n    class Meta:\n        model = NSRecord\n        fields = '__all__'\n\n\nclass NameServerHistorySerializer(serializers.ModelSerializer):\n    class Meta:\n        model = NameServerHistory\n        fields = '__all__'\n\n\nclass AssociatedDomainSerializer(serializers.ModelSerializer):\n    class Meta:\n        model = AssociatedDomain\n        fields = '__all__'\n\n\ndef get_lookup_keywords():\n    default_lookup_keywords = [\n        key.strip() for key in InterestingLookupModel.objects.get(\n            id=1).keywords.split(',')]\n    custom_lookup_keywords = []\n    if InterestingLookupModel.objects.filter(custom_type=True):\n        custom_lookup_keywords = [\n            key.strip() for key in InterestingLookupModel.objects.filter(\n                custom_type=True).order_by('-id')[0].keywords.split(',')]\n    lookup_keywords = default_lookup_keywords + custom_lookup_keywords\n    # remove empty strings from list, if any\n    lookup_keywords = list(filter(None, lookup_keywords))\n\n    return lookup_keywords\n\n\ndef get_interesting_subdomains(scan_history=None, target=None):\n    lookup_keywords = get_lookup_keywords()\n\n    subdomain_lookup_query = Q()\n    page_title_lookup_query = Q()\n\n    for key in lookup_keywords:\n        if InterestingLookupModel.objects.filter(custom_type=True).exists():\n            if InterestingLookupModel.objects.filter(\n                    custom_type=True).order_by('-id')[0].url_lookup:\n                subdomain_lookup_query |= Q(name__icontains=key)\n            if InterestingLookupModel.objects.filter(\n                    custom_type=True).order_by('-id')[0].title_lookup:\n                page_title_lookup_query |= Q(\n                    page_title__iregex=\"\\\\y{}\\\\y\".format(key))\n        else:\n            subdomain_lookup_query |= Q(name__icontains=key)\n            page_title_lookup_query |= Q(\n                page_title__iregex=\"\\\\y{}\\\\y\".format(key))\n\n    if InterestingLookupModel.objects.filter(\n            custom_type=True) and InterestingLookupModel.objects.filter(\n            custom_type=True).order_by('-id')[0].condition_200_http_lookup:\n        subdomain_lookup_query &= Q(http_status__exact=200)\n        page_title_lookup_query &= Q(http_status__exact=200)\n\n    subdomain_lookup = Subdomain.objects.none()\n    title_lookup = Subdomain.objects.none()\n\n    if target:\n        subdomains = Subdomain.objects.filter(target_domain__id=target).distinct('name')\n        if subdomain_lookup_query:\n            subdomain_lookup = subdomains.filter(subdomain_lookup_query)\n        if page_title_lookup_query:\n            title_lookup = subdomains.filter(page_title_lookup_query)\n    elif scan_history:\n        subdomains = Subdomain.objects.filter(scan_history__id=scan_history)\n        if subdomain_lookup_query:\n            subdomain_lookup = subdomains.filter(subdomain_lookup_query)\n        if page_title_lookup_query:\n            title_lookup = subdomains.filter(page_title_lookup_query)\n    else:\n        if subdomain_lookup_query:\n            subdomain_lookup = Subdomain.objects.filter(subdomain_lookup_query)\n        if page_title_lookup_query:\n            title_lookup = Subdomain.objects.filter(page_title_lookup_query)\n    lookup = subdomain_lookup | title_lookup\n    return lookup\n\n\ndef get_interesting_endpoint(scan_history=None, target=None):\n    lookup_keywords = get_lookup_keywords()\n\n    url_lookup_query = Q()\n    page_title_lookup_query = Q()\n\n    for key in lookup_keywords:\n        if InterestingLookupModel.objects.filter(custom_type=True).exists():\n            if InterestingLookupModel.objects.filter(custom_type=True).order_by('-id')[0].url_lookup:\n                url_lookup_query |= Q(http_url__icontains=key)\n            if InterestingLookupModel.objects.filter(custom_type=True).order_by('-id')[0].title_lookup:\n                page_title_lookup_query |= Q(page_title__iregex=\"\\\\y{}\\\\y\".format(key))\n\n        else:\n            url_lookup_query |= Q(http_url__icontains=key)\n            page_title_lookup_query |= Q(page_title__iregex=\"\\\\y{}\\\\y\".format(key))\n\n    if InterestingLookupModel.objects.filter(custom_type=True) and InterestingLookupModel.objects.filter(custom_type=True).order_by('-id')[0].condition_200_http_lookup:\n        url_lookup_query &= Q(http_status__exact=200)\n        page_title_lookup_query &= Q(http_status__exact=200)\n\n    url_lookup = EndPoint.objects.none()\n    title_lookup = EndPoint.objects.none()\n\n    if target:\n        urls = EndPoint.objects.filter(target_domain__id=target).distinct('http_url')\n        if url_lookup_query:\n            url_lookup = urls.filter(url_lookup_query)\n        if page_title_lookup_query:\n            title_lookup = urls.filter(page_title_lookup_query)\n    elif scan_history:\n        urls = EndPoint.objects.filter(scan_history__id=scan_history)\n        if url_lookup_query:\n            url_lookup = urls.filter(url_lookup_query)\n        if page_title_lookup_query:\n            title_lookup = urls.filter(page_title_lookup_query)\n\n    else:\n        if url_lookup_query:\n            url_lookup = EndPoint.objects.filter(url_lookup_query)\n        if page_title_lookup_query:\n            title_lookup = EndPoint.objects.filter(page_title_lookup_query)\n\n    return url_lookup | title_lookup\n\ndef check_keyword_exists(keyword_list, subdomain):\n    return any(sub in subdomain for sub in keyword_list)\n\ndef get_subdomain_from_url(url):\n    extract_url = tldextract.extract(url)\n    subdomain = '.'.join(extract_url[:4])\n    if subdomain[0] == '.':\n        subdomain = subdomain[1:]\n    return subdomain\n\ndef get_domain_from_subdomain(subdomain):\n    ext = tldextract.extract(subdomain)\n    return '.'.join(ext[1:3])\n\ndef send_telegram_message(message):\n    notification = Notification.objects.all()\n    if notification and notification[0].send_to_telegram \\\n    and notification[0].telegram_bot_token \\\n    and notification[0].telegram_bot_chat_id:\n        telegram_bot_token = notification[0].telegram_bot_token\n        telegram_bot_chat_id = notification[0].telegram_bot_chat_id\n        send_text = 'https://api.telegram.org/bot' + telegram_bot_token \\\n            + '/sendMessage?chat_id=' + telegram_bot_chat_id \\\n            + '&parse_mode=Markdown&text=' + message\n        thread = Thread(target=requests.get, args = (send_text, ))\n        thread.start()\n\ndef send_slack_message(message):\n    headers = {'content-type': 'application/json'}\n    message = {'text': message}\n    notification = Notification.objects.all()\n    if notification and notification[0].send_to_slack \\\n    and notification[0].slack_hook_url:\n        hook_url = notification[0].slack_hook_url\n        thread = Thread(\n            target=requests.post,\n            kwargs = {\n                'url': hook_url,\n                'data': json.dumps(message),\n                'headers': headers,\n            })\n        thread.start()\n\ndef send_discord_message(message):\n    notification = Notification.objects.all()\n    if notification and notification[0].send_to_discord \\\n    and notification[0].discord_hook_url:\n        webhook = DiscordWebhook(\n            url=notification[0].discord_hook_url,\n            content=message,\n            rate_limit_retry=True\n            )\n        thread = Thread(target=webhook.execute)\n        thread.start()\n\ndef send_files_to_discord(file_path):\n    notification = Notification.objects.all()\n    if notification and notification[0].send_to_discord \\\n    and notification[0].discord_hook_url:\n        webhook = DiscordWebhook(\n            url=notification[0].discord_hook_url,\n            rate_limit_retry=True,\n            username=\"Scan Results - File\"\n        )\n        with open(file_path, \"rb\") as f:\n            head, tail = os.path.split(file_path)\n            webhook.add_file(file=f.read(), filename=tail)\n        thread = Thread(target=webhook.execute)\n        thread.start()\n\ndef send_notification(message):\n    send_slack_message(message)\n    send_discord_message(message)\n    send_telegram_message(message)\n\ndef get_random_proxy():\n    if Proxy.objects.all().exists():\n        proxy = Proxy.objects.all()[0]\n        if proxy.use_proxy:\n            proxy_name = random.choice(proxy.proxies.splitlines())\n            print('Using proxy: ' + proxy_name)\n            return proxy_name\n    return False\n\ndef send_hackerone_report(vulnerability_id):\n    headers = {\n        'Content-Type': 'application/json',\n        'Accept': 'application/json'\n    }\n    # get hackerone creds\n    vulnerability = Vulnerability.objects.get(id=vulnerability_id)\n    # can only send vulnerability report if team_handle exists\n    if len(vulnerability.target_domain.h1_team_handle) !=0:\n        if Hackerone.objects.all().exists():\n            hackerone = Hackerone.objects.all()[0]\n            if vulnerability.severity == 0:\n                severity_value = 'none'\n            elif vulnerability.severity == 1:\n                severity_value = 'low'\n            elif vulnerability.severity == 2:\n                severity_value = 'medium'\n            elif vulnerability.severity == 3:\n                severity_value = 'high'\n            elif vulnerability.severity == 4:\n                severity_value = 'critical'\n            report_template = hackerone.report_template\n            # Replace syntax of report template with actual content\n            if '{vulnerability_name}' in report_template:\n                report_template = report_template.replace('{vulnerability_name}', vulnerability.name)\n            if '{vulnerable_url}' in report_template:\n                report_template = report_template.replace('{vulnerable_url}', vulnerability.http_url)\n            if '{vulnerability_severity}' in report_template:\n                report_template = report_template.replace('{vulnerability_severity}', severity_value)\n            if '{vulnerability_description}' in report_template:\n                report_template = report_template.replace('{vulnerability_description}', vulnerability.description if vulnerability.description else '')\n            if '{vulnerability_extracted_results}' in report_template:\n                report_template = report_template.replace('{vulnerability_extracted_results}', vulnerability.extracted_results if vulnerability.extracted_results else '')\n            if '{vulnerability_reference}' in report_template:\n                report_template = report_template.replace('{vulnerability_reference}', vulnerability.reference if vulnerability.reference else '')\n\n            data = {\n              \"data\": {\n                \"type\": \"report\",\n                \"attributes\": {\n                  \"team_handle\": vulnerability.target_domain.h1_team_handle,\n                  \"title\": '{} found in {}'.format(vulnerability.name, vulnerability.http_url),\n                  \"vulnerability_information\": report_template,\n                  \"severity_rating\": severity_value,\n                  \"impact\": \"More information about the impact and vulnerability can be found here: \\n\" + vulnerability.reference if vulnerability.reference else \"NA\",\n                }\n              }\n            }\n\n            r = requests.post(\n              'https://api.hackerone.com/v1/hackers/reports',\n              auth=(hackerone.username, hackerone.api_key),\n              json = data,\n              headers = headers\n            )\n\n            response = r.json()\n\n            # print(response)\n\n            status_code = r.status_code\n            print(status_code)\n\n            if status_code == 201:\n                vulnerability.hackerone_report_id = response['data'][\"id\"]\n                vulnerability.open_status = False\n                vulnerability.save()\n\n            return status_code\n\n    else:\n        print('No target ')\n        status_code = 111\n\n        return status_code\n\ndef get_whois(ip_domain, save_db=False, fetch_from_db=True):\n    # this function will fetch whois details for domains\n    # if save_db = True, then the whois will be saved in db\n    # if fetch_from_db = True then whois will be fetched from db, no lookup on\n    #     bigdomain data will be done\n    if ip_domain and not fetch_from_db:\n        response = requests.get('https://domainbigdata.com/{}'.format(ip_domain))\n        tree = html.fromstring(response.content)\n        try:\n            #RegistrantInfo Model\n            name = tree.xpath('//*[@id=\"trRegistrantName\"]/td[2]/a/text()')\n            organization = tree.xpath('//*[@id=\"MainMaster_trRegistrantOrganization\"]/td[2]/a/text()')\n            email = tree.xpath('//*[@id=\"trRegistrantEmail\"]/td[2]/a/text()')\n            address = tree.xpath('//*[@id=\"trRegistrantAddress\"]/td[2]/text()')\n            city = tree.xpath('//*[@id=\"trRegistrantCity\"]/td[2]/text()')\n            state = tree.xpath('//*[@id=\"trRegistrantState\"]/td[2]/text()')\n            country = tree.xpath('//*[@id=\"trRegistrantCountry\"]/td[2]/text()')\n            country_iso = tree.xpath('//*[@id=\"imgFlagRegistrant\"]/@alt')\n            tel = tree.xpath('//*[@id=\"trRegistrantTel\"]/td[2]/text()')\n            fax = tree.xpath('//*[@id=\"trRegistrantFax\"]/td[2]/text()')\n\n            #finding domain association using organization\n            organization_association_href = tree.xpath('//*[@id=\"MainMaster_trRegistrantOrganization\"]/td[2]/a/@href')\n            #finding domain association using email\n            email_association_href = tree.xpath('//*[@id=\"trRegistrantEmail\"]/td[2]/a/@href')\n\n            # related tlds\n            related_tlds = tree.xpath('//*[@id=\"divListOtherTLD\"]/descendant::*/text()')\n\n            # whois model\n            whois = tree.xpath('//*[@id=\"whois\"]/div/div[3]/text()')\n            whois = \"\\n\".join(whois).strip()\n\n            # DomainInfo Model\n            date_created = tree.xpath('//*[@id=\"trDateCreation\"]/td[2]/text()')\n            domain_age = tree.xpath('//*[@id=\"trWebAge\"]/td[2]/text()')\n            ip_address = tree.xpath('//*[@id=\"trIP\"]/td[2]/a/text()')\n            geolocation = tree.xpath('//*[@id=\"imgFlag\"]/following-sibling::text()')\n            geolocation_iso = tree.xpath('//*[@id=\"imgFlag\"]/@alt')\n\n            is_private_path = tree.xpath(\"//*[contains(@class, 'websiteglobalstats')]/tr[10]/td[2]/span/text()\")\n            is_private = False\n            if len(is_private_path) > 0:\n                is_private = True\n\n\n            date_created = date_created[0].strip() if date_created else None\n            domain_age = domain_age[0].strip() if domain_age else None\n            ip_address = ip_address[0].strip() if ip_address else None\n            geolocation = geolocation[0].strip() if geolocation else None\n            geolocation_iso = geolocation_iso[0].strip() if geolocation_iso else None\n            name = name[0].strip() if name else None\n            organization = organization[0].strip() if organization else None\n            email = email[0].strip() if email else None\n            address = address[0].strip() if address else None\n            city = city[0].strip() if city else None\n            state = state[0].strip() if state else None\n            country = country[0].strip() if country else None\n            country_iso = country_iso[0].strip() if country_iso else None\n            tel = tel[0].strip() if tel else None\n            fax = fax[0].strip() if fax else None\n\n            # association\n            organization_association_href = organization_association_href[0].strip() if organization_association_href else None\n            email_association_href = email_association_href[0].strip() if email_association_href else None\n\n            # other tlds\n            related_tlds = [ tld for tld in related_tlds if \"\\r\\n\" not in tld ]\n\n            dns_history_xpath = tree.xpath(\"//*[@id='MainMaster_divNSHistory']/table/tbody/tr\")\n            dns_history = []\n            for table_row in dns_history_xpath:\n                row = table_row.xpath('td/text()')\n                dns_history.append(\n                    {\n                        'date': row[0],\n                        'action': row[1],\n                        'nameserver': row[2],\n                    }\n                )\n\n            associated_domains = []\n            if organization_association_href and organization not in IGNORE_WHOIS_RELATED_KEYWORD:\n                # get all associated domains using organization\n                response_org = requests.get('https://domainbigdata.com{}'.format(organization_association_href))\n                tree_org = html.fromstring(response_org.content)\n                associated_domains_tree = tree_org.xpath('//*[@id=\"aDomain\"]/text()')\n                for domain in associated_domains_tree:\n                    associated_domains.append(domain)\n\n            if email_association_href and email not in IGNORE_WHOIS_RELATED_KEYWORD:\n                print(email_association_href)\n                response_email = requests.get('https://domainbigdata.com{}'.format(email_association_href))\n                tree_email = html.fromstring(response_email.content)\n                associated_domains_tree = tree_email.xpath('//*[@id=\"aDomain\"]/text()')\n                for domain in associated_domains_tree:\n                    associated_domains.append(domain)\n\n            # unique associated_domains\n            unique_associated_domains = []\n            [unique_associated_domains.append(domain) for domain in associated_domains if domain not in unique_associated_domains]\n\n            # save in db\n            if save_db and Domain.objects.filter(name=ip_domain).exists():\n                # look for domain and save in db\n                domain = Domain.objects.get(name=ip_domain)\n\n\n                # check if registrant exists\n                if RegistrantInfo.objects.filter(email=email).filter(name=name).exists():\n                    registrant = RegistrantInfo.objects.get(email=email, name=name)\n                else:\n                    registrant = RegistrantInfo()\n                    registrant.name = name\n                    registrant.organization = organization\n                    registrant.email = email\n                    registrant.address = address\n                    registrant.city = city\n                    registrant.state = state\n                    registrant.country = country\n                    registrant.country_iso = country_iso\n                    registrant.phone_number = tel\n                    registrant.fax = fax\n                    registrant.organization_association_href = organization_association_href\n                    registrant.email_association_href = email_association_href\n                    registrant.save()\n\n                if WhoisDetail.objects.filter(details=whois).exists():\n                    whois_model = WhoisDetail.objects.get(details=whois)\n                else:\n                    whois_model = WhoisDetail()\n                    whois_model.details = whois if whois else None\n                    whois_model.registrant = registrant\n                    whois_model.save()\n\n                domain_info = DomainInfo()\n                domain_info.date_created = date_created\n                domain_info.domain_age = domain_age\n                domain_info.ip_address = ip_address\n                domain_info.geolocation = geolocation\n                domain_info.geolocation_iso = geolocation_iso\n                domain_info.whois = whois_model\n                domain_info.save()\n\n                for table_row in dns_history_xpath:\n                    row = table_row.xpath('td/text()')\n                    ns_history = NameServerHistory()\n                    ns_history.date = row[0]\n                    ns_history.action = row[1]\n                    ns_history.server = row[2]\n                    ns_history.save()\n\n                    domain_info.nameserver_history.add(ns_history);\n\n                domain.domain_info = domain_info\n                domain.save()\n\n\n                # save associated domains\n                for domain in unique_associated_domains:\n                    if AssociatedDomain.objects.filter(name=domain).exists():\n                        ass_domain = AssociatedDomain.objects.get(name=domain)\n                    else:\n                        ass_domain = AssociatedDomain()\n                        ass_domain.name = domain\n                        ass_domain.save()\n                    domain_info.associated_domains.add(ass_domain)\n\n                # save related TLDs\n                for tld in related_tlds:\n                    if RelatedTLD.objects.filter(name=tld).exists():\n                        rel_tld = RelatedTLD.objects.get(name=tld)\n                    else:\n                        rel_tld = RelatedTLD()\n                        rel_tld.name = tld\n                        rel_tld.save()\n                    domain_info.related_tlds.add(rel_tld)\n\n            ns_records = []\n            for i in range(4):\n                ns_records_xpath = tree.xpath(\"//*[@id='divDNSRecords']/table[{}]/tbody/tr\".format(i))\n                for table_row in ns_records_xpath:\n                    row = table_row.xpath('td/text()')\n                    if row[0] == 'A':\n                        # for getting address, use child lookup\n                        address = table_row.xpath('td/a/text()')\n                        address = address[0] if address else None\n\n                        ns_records.append(\n                            {\n                                'type': row[0],\n                                'hostname': row[1],\n                                'address': address,\n                                'ttl': row[2],\n                                'class': row[3],\n                            }\n                        )\n\n                        if save_db and Domain.objects.filter(name=ip_domain).exists():\n                            ns = NSRecord()\n                            ns.type = row[0]\n                            ns.hostname = row[1]\n                            ns.address = address\n                            ns.ttl = row[2]\n                            ns.ns_class = row[3]\n                            ns.save()\n                            domain_info.nameserver_record.add(ns)\n\n                    elif row[0] == 'AAAA':\n                        # for getting address, use child lookup\n                        ns_records.append(\n                            {\n                                'type': row[0],\n                                'hostname': row[1],\n                                'address': row[2],\n                                'ttl': row[3],\n                                'class': row[4],\n                            }\n                        )\n\n                        if save_db and Domain.objects.filter(name=ip_domain).exists():\n                            ns = NSRecord()\n                            ns.type = row[0]\n                            ns.hostname = row[1]\n                            ns.address = row[2]\n                            ns.ttl = row[3]\n                            ns.ns_class = row[4]\n                            ns.save()\n                            domain_info.nameserver_record.add(ns)\n\n                    elif row[0] == 'MX':\n                        ns_records.append(\n                            {\n                                'type': row[0],\n                                'hostname': row[1],\n                                'address': row[2],\n                                'preference': row[3],\n                                'ttl': row[4],\n                                'class': row[5],\n                            }\n                        )\n\n                        if save_db and Domain.objects.filter(name=ip_domain).exists():\n                            ns = NSRecord()\n                            ns.type = row[0]\n                            ns.hostname = row[1]\n                            ns.address = address\n                            ns.preference = row[3]\n                            ns.ttl = row[4]\n                            ns.ns_class = row[5]\n                            ns.save()\n                            domain_info.nameserver_record.add(ns)\n\n\n            final_organization_association_url = 'https://domainbigdata.com' + organization_association_href if organization_association_href else None\n            final_email_association_url = 'https://domainbigdata.com' + email_association_href if email_association_href else None\n\n\n            return {\n                'status': True,\n                'ip_domain': ip_domain,\n                'domain': {\n                    'date_created': date_created,\n                    'domain_age': domain_age,\n                    'ip_address': ip_address,\n                    'geolocation': geolocation,\n                    'geolocation_iso': geolocation_iso,\n                },\n                'nameserver': {\n                    'history': dns_history,\n                    'records': ns_records\n                },\n                'registrant': {\n                    'name': name,\n                    'organization': organization,\n                    'email': email,\n                    'address': address,\n                    'city': city,\n                    'state': state,\n                    'country': country,\n                    'country_iso': country_iso,\n                    'tel': tel,\n                    'fax': fax,\n                    'organization_association_url': final_organization_association_url,\n                    'email_association_url': final_email_association_url,\n                },\n                'related_domains': unique_associated_domains,\n                'related_tlds': related_tlds,\n                'whois': whois if whois else None\n            }\n        except Exception as e:\n            logging.exception(e)\n            return {\n                'status': False,\n                'ip_domain': ip_domain,\n                'result': 'Domain not found'\n            }\n    elif ip_domain and fetch_from_db:\n        if Domain.objects.filter(name=ip_domain).exists():\n            domain = Domain.objects.get(name=ip_domain)\n            unique_associated_domains = []\n\n            if domain.domain_info and domain.domain_info.associated_domains:\n                unique_associated_domains = [d.name for d in domain.domain_info.associated_domains.all()]\n\n\n            unique_related_tlds = []\n            if domain.domain_info and domain.domain_info.related_tlds:\n                unique_related_tlds = [d.name for d in domain.domain_info.related_tlds.all()]\n\n            if domain.domain_info:\n                return {\n                    'status': True,\n                    'ip_domain': ip_domain,\n                    'domain': {\n                        'date_created': domain.domain_info.date_created,\n                        'domain_age': domain.domain_info.domain_age,\n                        'ip_address': domain.domain_info.ip_address,\n                        'geolocation': domain.domain_info.geolocation,\n                        'geolocation_iso': domain.domain_info.geolocation_iso,\n                    },\n                    'nameserver': {\n                        'history': NameServerHistorySerializer(domain.domain_info.nameserver_history.all(), many=True).data,\n                        'records': NSRecordSerializer(domain.domain_info.nameserver_record.all(), many=True).data\n                    },\n                    'registrant': {\n                        'name': domain.domain_info.whois.registrant.name,\n                        'organization': domain.domain_info.whois.registrant.organization,\n                        'email': domain.domain_info.whois.registrant.email,\n                        'address': domain.domain_info.whois.registrant.address,\n                        'city': domain.domain_info.whois.registrant.city,\n                        'state': domain.domain_info.whois.registrant.state,\n                        'country': domain.domain_info.whois.registrant.country,\n                        'country_iso': domain.domain_info.whois.registrant.country_iso,\n                        'tel': domain.domain_info.whois.registrant.phone_number,\n                        'fax': domain.domain_info.whois.registrant.fax,\n                    },\n                    'related_domains': unique_associated_domains,\n                    'related_tlds': unique_related_tlds,\n                    'whois': domain.domain_info.whois.details\n                }\n            return {\n                'status': False,\n                'message': 'WHOIS does not exist.'\n            }\n        return {\n            'status': False,\n            'message': 'Domain ' + ip_domain + ' does not exist as target and could not fetch WHOIS from database.'\n        }\n\n\ndef get_cms_details(url):\n    # this function will fetch cms details using cms_detector\n    response = {}\n    cms_detector_command = 'python3 /usr/src/github/CMSeeK/cmseek.py -u {} --random-agent --batch --follow-redirect'.format(url)\n    os.system(cms_detector_command)\n\n    response['status'] = False\n    response['message'] = 'Could not detect CMS!'\n\n    parsed_url = urlparse(url)\n\n    domain_name = parsed_url.hostname\n    port = parsed_url.port\n\n    find_dir = domain_name\n\n    if port:\n        find_dir += '_{}'.format(port)\n\n\n    print(url)\n    print(find_dir)\n\n    # subdomain may also have port number, and is stored in dir as _port\n\n    cms_dir_path =  '/usr/src/github/CMSeeK/Result/{}'.format(find_dir)\n    cms_json_path =  cms_dir_path + '/cms.json'\n\n    if os.path.isfile(cms_json_path):\n        cms_file_content = json.loads(open(cms_json_path, 'r').read())\n        if not cms_file_content.get('cms_id'):\n            return response\n        response = {}\n        response = cms_file_content\n        response['status'] = True\n        # remove cms dir path\n        try:\n            shutil.rmtree(cms_dir_path)\n        except Exception as e:\n            print(e)\n\n    return response\n", "patch": "@@ -6,6 +6,7 @@\n import tldextract\n import logging\n import shutil\n+import subprocess\n \n from threading import Thread\n \n@@ -668,8 +669,12 @@ def get_whois(ip_domain, save_db=False, fetch_from_db=True):\n def get_cms_details(url):\n     # this function will fetch cms details using cms_detector\n     response = {}\n-    cms_detector_command = 'python3 /usr/src/github/CMSeeK/cmseek.py -u {} --random-agent --batch --follow-redirect'.format(url)\n-    os.system(cms_detector_command)\n+    cms_detector_command = 'python3 /usr/src/github/CMSeeK/cmseek.py --random-agent --batch --follow-redirect'\n+    subprocess_splitted_command = cms_detector_command.split()\n+    subprocess_splitted_command.append('-u')\n+    subprocess_splitted_command.append(url)\n+    process = subprocess.Popen(subprocess_splitted_command)\n+    process.wait()\n \n     response['status'] = False\n     response['message'] = 'Could not detect CMS!'", "file_path": "files/2022_5/215", "file_language": "py", "file_name": "web/reNgine/common_func.py", "outdated_file_modify": 0, "outdated_file_before": 0, "outdated_file_after": 0, "llm_check": 1, "static_check": 1, "static": {"rats": [true, ["/data/rdhu/other/Static/tmp/2022_5_215.py:672: High: system\n    os.system(cms_detector_command)\nArgument 1 to this function call should be checked to ensure that it does not\ncome from an untrusted source without first verifying that it contains nothing\ndangerous.\n"]], "semgrep": [false, []]}, "target": 1, "function_before": [{"function": "class NSRecordSerializer(serializers.ModelSerializer):\n    class Meta:\n        model = NSRecord\n        fields = '__all__'", "target": 0}, {"function": "class NameServerHistorySerializer(serializers.ModelSerializer):\n    class Meta:\n        model = NameServerHistory\n        fields = '__all__'", "target": 0}, {"function": "class AssociatedDomainSerializer(serializers.ModelSerializer):\n    class Meta:\n        model = AssociatedDomain\n        fields = '__all__'", "target": 0}, {"function": "def get_lookup_keywords():\n    default_lookup_keywords = [\n        key.strip() for key in InterestingLookupModel.objects.get(\n            id=1).keywords.split(',')]\n    custom_lookup_keywords = []\n    if InterestingLookupModel.objects.filter(custom_type=True):\n        custom_lookup_keywords = [\n            key.strip() for key in InterestingLookupModel.objects.filter(\n                custom_type=True).order_by('-id')[0].keywords.split(',')]\n    lookup_keywords = default_lookup_keywords + custom_lookup_keywords\n    # remove empty strings from list, if any\n    lookup_keywords = list(filter(None, lookup_keywords))\n\n    return lookup_keywords", "target": 0}, {"function": "def get_interesting_subdomains(scan_history=None, target=None):\n    lookup_keywords = get_lookup_keywords()\n\n    subdomain_lookup_query = Q()\n    page_title_lookup_query = Q()\n\n    for key in lookup_keywords:\n        if InterestingLookupModel.objects.filter(custom_type=True).exists():\n            if InterestingLookupModel.objects.filter(\n                    custom_type=True).order_by('-id')[0].url_lookup:\n                subdomain_lookup_query |= Q(name__icontains=key)\n            if InterestingLookupModel.objects.filter(\n                    custom_type=True).order_by('-id')[0].title_lookup:\n                page_title_lookup_query |= Q(\n                    page_title__iregex=\"\\\\y{}\\\\y\".format(key))\n        else:\n            subdomain_lookup_query |= Q(name__icontains=key)\n            page_title_lookup_query |= Q(\n                page_title__iregex=\"\\\\y{}\\\\y\".format(key))\n\n    if InterestingLookupModel.objects.filter(\n            custom_type=True) and InterestingLookupModel.objects.filter(\n            custom_type=True).order_by('-id')[0].condition_200_http_lookup:\n        subdomain_lookup_query &= Q(http_status__exact=200)\n        page_title_lookup_query &= Q(http_status__exact=200)\n\n    subdomain_lookup = Subdomain.objects.none()\n    title_lookup = Subdomain.objects.none()\n\n    if target:\n        subdomains = Subdomain.objects.filter(target_domain__id=target).distinct('name')\n        if subdomain_lookup_query:\n            subdomain_lookup = subdomains.filter(subdomain_lookup_query)\n        if page_title_lookup_query:\n            title_lookup = subdomains.filter(page_title_lookup_query)\n    elif scan_history:\n        subdomains = Subdomain.objects.filter(scan_history__id=scan_history)\n        if subdomain_lookup_query:\n            subdomain_lookup = subdomains.filter(subdomain_lookup_query)\n        if page_title_lookup_query:\n            title_lookup = subdomains.filter(page_title_lookup_query)\n    else:\n        if subdomain_lookup_query:\n            subdomain_lookup = Subdomain.objects.filter(subdomain_lookup_query)\n        if page_title_lookup_query:\n            title_lookup = Subdomain.objects.filter(page_title_lookup_query)\n    lookup = subdomain_lookup | title_lookup\n    return lookup", "target": 0}, {"function": "def get_interesting_endpoint(scan_history=None, target=None):\n    lookup_keywords = get_lookup_keywords()\n\n    url_lookup_query = Q()\n    page_title_lookup_query = Q()\n\n    for key in lookup_keywords:\n        if InterestingLookupModel.objects.filter(custom_type=True).exists():\n            if InterestingLookupModel.objects.filter(custom_type=True).order_by('-id')[0].url_lookup:\n                url_lookup_query |= Q(http_url__icontains=key)\n            if InterestingLookupModel.objects.filter(custom_type=True).order_by('-id')[0].title_lookup:\n                page_title_lookup_query |= Q(page_title__iregex=\"\\\\y{}\\\\y\".format(key))\n\n        else:\n            url_lookup_query |= Q(http_url__icontains=key)\n            page_title_lookup_query |= Q(page_title__iregex=\"\\\\y{}\\\\y\".format(key))\n\n    if InterestingLookupModel.objects.filter(custom_type=True) and InterestingLookupModel.objects.filter(custom_type=True).order_by('-id')[0].condition_200_http_lookup:\n        url_lookup_query &= Q(http_status__exact=200)\n        page_title_lookup_query &= Q(http_status__exact=200)\n\n    url_lookup = EndPoint.objects.none()\n    title_lookup = EndPoint.objects.none()\n\n    if target:\n        urls = EndPoint.objects.filter(target_domain__id=target).distinct('http_url')\n        if url_lookup_query:\n            url_lookup = urls.filter(url_lookup_query)\n        if page_title_lookup_query:\n            title_lookup = urls.filter(page_title_lookup_query)\n    elif scan_history:\n        urls = EndPoint.objects.filter(scan_history__id=scan_history)\n        if url_lookup_query:\n            url_lookup = urls.filter(url_lookup_query)\n        if page_title_lookup_query:\n            title_lookup = urls.filter(page_title_lookup_query)\n\n    else:\n        if url_lookup_query:\n            url_lookup = EndPoint.objects.filter(url_lookup_query)\n        if page_title_lookup_query:\n            title_lookup = EndPoint.objects.filter(page_title_lookup_query)\n\n    return url_lookup | title_lookup", "target": 0}, {"function": "def check_keyword_exists(keyword_list, subdomain):\n    return any(sub in subdomain for sub in keyword_list)", "target": 0}, {"function": "def get_subdomain_from_url(url):\n    extract_url = tldextract.extract(url)\n    subdomain = '.'.join(extract_url[:4])\n    if subdomain[0] == '.':\n        subdomain = subdomain[1:]\n    return subdomain", "target": 0}, {"function": "def get_domain_from_subdomain(subdomain):\n    ext = tldextract.extract(subdomain)\n    return '.'.join(ext[1:3])", "target": 0}, {"function": "def send_telegram_message(message):\n    notification = Notification.objects.all()\n    if notification and notification[0].send_to_telegram \\\n    and notification[0].telegram_bot_token \\\n    and notification[0].telegram_bot_chat_id:\n        telegram_bot_token = notification[0].telegram_bot_token\n        telegram_bot_chat_id = notification[0].telegram_bot_chat_id\n        send_text = 'https://api.telegram.org/bot' + telegram_bot_token \\\n            + '/sendMessage?chat_id=' + telegram_bot_chat_id \\\n            + '&parse_mode=Markdown&text=' + message\n        thread = Thread(target=requests.get, args = (send_text, ))\n        thread.start()", "target": 0}, {"function": "def send_slack_message(message):\n    headers = {'content-type': 'application/json'}\n    message = {'text': message}\n    notification = Notification.objects.all()\n    if notification and notification[0].send_to_slack \\\n    and notification[0].slack_hook_url:\n        hook_url = notification[0].slack_hook_url\n        thread = Thread(\n            target=requests.post,\n            kwargs = {\n                'url': hook_url,\n                'data': json.dumps(message),\n                'headers': headers,\n            })\n        thread.start()", "target": 0}, {"function": "def send_discord_message(message):\n    notification = Notification.objects.all()\n    if notification and notification[0].send_to_discord \\\n    and notification[0].discord_hook_url:\n        webhook = DiscordWebhook(\n            url=notification[0].discord_hook_url,\n            content=message,\n            rate_limit_retry=True\n            )\n        thread = Thread(target=webhook.execute)\n        thread.start()", "target": 0}, {"function": "def send_files_to_discord(file_path):\n    notification = Notification.objects.all()\n    if notification and notification[0].send_to_discord \\\n    and notification[0].discord_hook_url:\n        webhook = DiscordWebhook(\n            url=notification[0].discord_hook_url,\n            rate_limit_retry=True,\n            username=\"Scan Results - File\"\n        )\n        with open(file_path, \"rb\") as f:\n            head, tail = os.path.split(file_path)\n            webhook.add_file(file=f.read(), filename=tail)\n        thread = Thread(target=webhook.execute)\n        thread.start()", "target": 0}, {"function": "def send_notification(message):\n    send_slack_message(message)\n    send_discord_message(message)\n    send_telegram_message(message)", "target": 0}, {"function": "def get_random_proxy():\n    if Proxy.objects.all().exists():\n        proxy = Proxy.objects.all()[0]\n        if proxy.use_proxy:\n            proxy_name = random.choice(proxy.proxies.splitlines())\n            print('Using proxy: ' + proxy_name)\n            return proxy_name\n    return False", "target": 0}, {"function": "def send_hackerone_report(vulnerability_id):\n    headers = {\n        'Content-Type': 'application/json',\n        'Accept': 'application/json'\n    }\n    # get hackerone creds\n    vulnerability = Vulnerability.objects.get(id=vulnerability_id)\n    # can only send vulnerability report if team_handle exists\n    if len(vulnerability.target_domain.h1_team_handle) !=0:\n        if Hackerone.objects.all().exists():\n            hackerone = Hackerone.objects.all()[0]\n            if vulnerability.severity == 0:\n                severity_value = 'none'\n            elif vulnerability.severity == 1:\n                severity_value = 'low'\n            elif vulnerability.severity == 2:\n                severity_value = 'medium'\n            elif vulnerability.severity == 3:\n                severity_value = 'high'\n            elif vulnerability.severity == 4:\n                severity_value = 'critical'\n            report_template = hackerone.report_template\n            # Replace syntax of report template with actual content\n            if '{vulnerability_name}' in report_template:\n                report_template = report_template.replace('{vulnerability_name}', vulnerability.name)\n            if '{vulnerable_url}' in report_template:\n                report_template = report_template.replace('{vulnerable_url}', vulnerability.http_url)\n            if '{vulnerability_severity}' in report_template:\n                report_template = report_template.replace('{vulnerability_severity}', severity_value)\n            if '{vulnerability_description}' in report_template:\n                report_template = report_template.replace('{vulnerability_description}', vulnerability.description if vulnerability.description else '')\n            if '{vulnerability_extracted_results}' in report_template:\n                report_template = report_template.replace('{vulnerability_extracted_results}', vulnerability.extracted_results if vulnerability.extracted_results else '')\n            if '{vulnerability_reference}' in report_template:\n                report_template = report_template.replace('{vulnerability_reference}', vulnerability.reference if vulnerability.reference else '')\n\n            data = {\n              \"data\": {\n                \"type\": \"report\",\n                \"attributes\": {\n                  \"team_handle\": vulnerability.target_domain.h1_team_handle,\n                  \"title\": '{} found in {}'.format(vulnerability.name, vulnerability.http_url),\n                  \"vulnerability_information\": report_template,\n                  \"severity_rating\": severity_value,\n                  \"impact\": \"More information about the impact and vulnerability can be found here: \\n\" + vulnerability.reference if vulnerability.reference else \"NA\",\n                }\n              }\n            }\n\n            r = requests.post(\n              'https://api.hackerone.com/v1/hackers/reports',\n              auth=(hackerone.username, hackerone.api_key),\n              json = data,\n              headers = headers\n            )\n\n            response = r.json()\n\n            # print(response)\n\n            status_code = r.status_code\n            print(status_code)\n\n            if status_code == 201:\n                vulnerability.hackerone_report_id = response['data'][\"id\"]\n                vulnerability.open_status = False\n                vulnerability.save()\n\n            return status_code\n\n    else:\n        print('No target ')\n        status_code = 111\n\n        return status_code", "target": 0}, {"function": "def get_whois(ip_domain, save_db=False, fetch_from_db=True):\n    # this function will fetch whois details for domains\n    # if save_db = True, then the whois will be saved in db\n    # if fetch_from_db = True then whois will be fetched from db, no lookup on\n    #     bigdomain data will be done\n    if ip_domain and not fetch_from_db:\n        response = requests.get('https://domainbigdata.com/{}'.format(ip_domain))\n        tree = html.fromstring(response.content)\n        try:\n            #RegistrantInfo Model\n            name = tree.xpath('//*[@id=\"trRegistrantName\"]/td[2]/a/text()')\n            organization = tree.xpath('//*[@id=\"MainMaster_trRegistrantOrganization\"]/td[2]/a/text()')\n            email = tree.xpath('//*[@id=\"trRegistrantEmail\"]/td[2]/a/text()')\n            address = tree.xpath('//*[@id=\"trRegistrantAddress\"]/td[2]/text()')\n            city = tree.xpath('//*[@id=\"trRegistrantCity\"]/td[2]/text()')\n            state = tree.xpath('//*[@id=\"trRegistrantState\"]/td[2]/text()')\n            country = tree.xpath('//*[@id=\"trRegistrantCountry\"]/td[2]/text()')\n            country_iso = tree.xpath('//*[@id=\"imgFlagRegistrant\"]/@alt')\n            tel = tree.xpath('//*[@id=\"trRegistrantTel\"]/td[2]/text()')\n            fax = tree.xpath('//*[@id=\"trRegistrantFax\"]/td[2]/text()')\n\n            #finding domain association using organization\n            organization_association_href = tree.xpath('//*[@id=\"MainMaster_trRegistrantOrganization\"]/td[2]/a/@href')\n            #finding domain association using email\n            email_association_href = tree.xpath('//*[@id=\"trRegistrantEmail\"]/td[2]/a/@href')\n\n            # related tlds\n            related_tlds = tree.xpath('//*[@id=\"divListOtherTLD\"]/descendant::*/text()')\n\n            # whois model\n            whois = tree.xpath('//*[@id=\"whois\"]/div/div[3]/text()')\n            whois = \"\\n\".join(whois).strip()\n\n            # DomainInfo Model\n            date_created = tree.xpath('//*[@id=\"trDateCreation\"]/td[2]/text()')\n            domain_age = tree.xpath('//*[@id=\"trWebAge\"]/td[2]/text()')\n            ip_address = tree.xpath('//*[@id=\"trIP\"]/td[2]/a/text()')\n            geolocation = tree.xpath('//*[@id=\"imgFlag\"]/following-sibling::text()')\n            geolocation_iso = tree.xpath('//*[@id=\"imgFlag\"]/@alt')\n\n            is_private_path = tree.xpath(\"//*[contains(@class, 'websiteglobalstats')]/tr[10]/td[2]/span/text()\")\n            is_private = False\n            if len(is_private_path) > 0:\n                is_private = True\n\n\n            date_created = date_created[0].strip() if date_created else None\n            domain_age = domain_age[0].strip() if domain_age else None\n            ip_address = ip_address[0].strip() if ip_address else None\n            geolocation = geolocation[0].strip() if geolocation else None\n            geolocation_iso = geolocation_iso[0].strip() if geolocation_iso else None\n            name = name[0].strip() if name else None\n            organization = organization[0].strip() if organization else None\n            email = email[0].strip() if email else None\n            address = address[0].strip() if address else None\n            city = city[0].strip() if city else None\n            state = state[0].strip() if state else None\n            country = country[0].strip() if country else None\n            country_iso = country_iso[0].strip() if country_iso else None\n            tel = tel[0].strip() if tel else None\n            fax = fax[0].strip() if fax else None\n\n            # association\n            organization_association_href = organization_association_href[0].strip() if organization_association_href else None\n            email_association_href = email_association_href[0].strip() if email_association_href else None\n\n            # other tlds\n            related_tlds = [ tld for tld in related_tlds if \"\\r\\n\" not in tld ]\n\n            dns_history_xpath = tree.xpath(\"//*[@id='MainMaster_divNSHistory']/table/tbody/tr\")\n            dns_history = []\n            for table_row in dns_history_xpath:\n                row = table_row.xpath('td/text()')\n                dns_history.append(\n                    {\n                        'date': row[0],\n                        'action': row[1],\n                        'nameserver': row[2],\n                    }\n                )\n\n            associated_domains = []\n            if organization_association_href and organization not in IGNORE_WHOIS_RELATED_KEYWORD:\n                # get all associated domains using organization\n                response_org = requests.get('https://domainbigdata.com{}'.format(organization_association_href))\n                tree_org = html.fromstring(response_org.content)\n                associated_domains_tree = tree_org.xpath('//*[@id=\"aDomain\"]/text()')\n                for domain in associated_domains_tree:\n                    associated_domains.append(domain)\n\n            if email_association_href and email not in IGNORE_WHOIS_RELATED_KEYWORD:\n                print(email_association_href)\n                response_email = requests.get('https://domainbigdata.com{}'.format(email_association_href))\n                tree_email = html.fromstring(response_email.content)\n                associated_domains_tree = tree_email.xpath('//*[@id=\"aDomain\"]/text()')\n                for domain in associated_domains_tree:\n                    associated_domains.append(domain)\n\n            # unique associated_domains\n            unique_associated_domains = []\n            [unique_associated_domains.append(domain) for domain in associated_domains if domain not in unique_associated_domains]\n\n            # save in db\n            if save_db and Domain.objects.filter(name=ip_domain).exists():\n                # look for domain and save in db\n                domain = Domain.objects.get(name=ip_domain)\n\n\n                # check if registrant exists\n                if RegistrantInfo.objects.filter(email=email).filter(name=name).exists():\n                    registrant = RegistrantInfo.objects.get(email=email, name=name)\n                else:\n                    registrant = RegistrantInfo()\n                    registrant.name = name\n                    registrant.organization = organization\n                    registrant.email = email\n                    registrant.address = address\n                    registrant.city = city\n                    registrant.state = state\n                    registrant.country = country\n                    registrant.country_iso = country_iso\n                    registrant.phone_number = tel\n                    registrant.fax = fax\n                    registrant.organization_association_href = organization_association_href\n                    registrant.email_association_href = email_association_href\n                    registrant.save()\n\n                if WhoisDetail.objects.filter(details=whois).exists():\n                    whois_model = WhoisDetail.objects.get(details=whois)\n                else:\n                    whois_model = WhoisDetail()\n                    whois_model.details = whois if whois else None\n                    whois_model.registrant = registrant\n                    whois_model.save()\n\n                domain_info = DomainInfo()\n                domain_info.date_created = date_created\n                domain_info.domain_age = domain_age\n                domain_info.ip_address = ip_address\n                domain_info.geolocation = geolocation\n                domain_info.geolocation_iso = geolocation_iso\n                domain_info.whois = whois_model\n                domain_info.save()\n\n                for table_row in dns_history_xpath:\n                    row = table_row.xpath('td/text()')\n                    ns_history = NameServerHistory()\n                    ns_history.date = row[0]\n                    ns_history.action = row[1]\n                    ns_history.server = row[2]\n                    ns_history.save()\n\n                    domain_info.nameserver_history.add(ns_history);\n\n                domain.domain_info = domain_info\n                domain.save()\n\n\n                # save associated domains\n                for domain in unique_associated_domains:\n                    if AssociatedDomain.objects.filter(name=domain).exists():\n                        ass_domain = AssociatedDomain.objects.get(name=domain)\n                    else:\n                        ass_domain = AssociatedDomain()\n                        ass_domain.name = domain\n                        ass_domain.save()\n                    domain_info.associated_domains.add(ass_domain)\n\n                # save related TLDs\n                for tld in related_tlds:\n                    if RelatedTLD.objects.filter(name=tld).exists():\n                        rel_tld = RelatedTLD.objects.get(name=tld)\n                    else:\n                        rel_tld = RelatedTLD()\n                        rel_tld.name = tld\n                        rel_tld.save()\n                    domain_info.related_tlds.add(rel_tld)\n\n            ns_records = []\n            for i in range(4):\n                ns_records_xpath = tree.xpath(\"//*[@id='divDNSRecords']/table[{}]/tbody/tr\".format(i))\n                for table_row in ns_records_xpath:\n                    row = table_row.xpath('td/text()')\n                    if row[0] == 'A':\n                        # for getting address, use child lookup\n                        address = table_row.xpath('td/a/text()')\n                        address = address[0] if address else None\n\n                        ns_records.append(\n                            {\n                                'type': row[0],\n                                'hostname': row[1],\n                                'address': address,\n                                'ttl': row[2],\n                                'class': row[3],\n                            }\n                        )\n\n                        if save_db and Domain.objects.filter(name=ip_domain).exists():\n                            ns = NSRecord()\n                            ns.type = row[0]\n                            ns.hostname = row[1]\n                            ns.address = address\n                            ns.ttl = row[2]\n                            ns.ns_class = row[3]\n                            ns.save()\n                            domain_info.nameserver_record.add(ns)\n\n                    elif row[0] == 'AAAA':\n                        # for getting address, use child lookup\n                        ns_records.append(\n                            {\n                                'type': row[0],\n                                'hostname': row[1],\n                                'address': row[2],\n                                'ttl': row[3],\n                                'class': row[4],\n                            }\n                        )\n\n                        if save_db and Domain.objects.filter(name=ip_domain).exists():\n                            ns = NSRecord()\n                            ns.type = row[0]\n                            ns.hostname = row[1]\n                            ns.address = row[2]\n                            ns.ttl = row[3]\n                            ns.ns_class = row[4]\n                            ns.save()\n                            domain_info.nameserver_record.add(ns)\n\n                    elif row[0] == 'MX':\n                        ns_records.append(\n                            {\n                                'type': row[0],\n                                'hostname': row[1],\n                                'address': row[2],\n                                'preference': row[3],\n                                'ttl': row[4],\n                                'class': row[5],\n                            }\n                        )\n\n                        if save_db and Domain.objects.filter(name=ip_domain).exists():\n                            ns = NSRecord()\n                            ns.type = row[0]\n                            ns.hostname = row[1]\n                            ns.address = address\n                            ns.preference = row[3]\n                            ns.ttl = row[4]\n                            ns.ns_class = row[5]\n                            ns.save()\n                            domain_info.nameserver_record.add(ns)\n\n\n            final_organization_association_url = 'https://domainbigdata.com' + organization_association_href if organization_association_href else None\n            final_email_association_url = 'https://domainbigdata.com' + email_association_href if email_association_href else None\n\n\n            return {\n                'status': True,\n                'ip_domain': ip_domain,\n                'domain': {\n                    'date_created': date_created,\n                    'domain_age': domain_age,\n                    'ip_address': ip_address,\n                    'geolocation': geolocation,\n                    'geolocation_iso': geolocation_iso,\n                },\n                'nameserver': {\n                    'history': dns_history,\n                    'records': ns_records\n                },\n                'registrant': {\n                    'name': name,\n                    'organization': organization,\n                    'email': email,\n                    'address': address,\n                    'city': city,\n                    'state': state,\n                    'country': country,\n                    'country_iso': country_iso,\n                    'tel': tel,\n                    'fax': fax,\n                    'organization_association_url': final_organization_association_url,\n                    'email_association_url': final_email_association_url,\n                },\n                'related_domains': unique_associated_domains,\n                'related_tlds': related_tlds,\n                'whois': whois if whois else None\n            }\n        except Exception as e:\n            logging.exception(e)\n            return {\n                'status': False,\n                'ip_domain': ip_domain,\n                'result': 'Domain not found'\n            }\n    elif ip_domain and fetch_from_db:\n        if Domain.objects.filter(name=ip_domain).exists():\n            domain = Domain.objects.get(name=ip_domain)\n            unique_associated_domains = []\n\n            if domain.domain_info and domain.domain_info.associated_domains:\n                unique_associated_domains = [d.name for d in domain.domain_info.associated_domains.all()]\n\n\n            unique_related_tlds = []\n            if domain.domain_info and domain.domain_info.related_tlds:\n                unique_related_tlds = [d.name for d in domain.domain_info.related_tlds.all()]\n\n            if domain.domain_info:\n                return {\n                    'status': True,\n                    'ip_domain': ip_domain,\n                    'domain': {\n                        'date_created': domain.domain_info.date_created,\n                        'domain_age': domain.domain_info.domain_age,\n                        'ip_address': domain.domain_info.ip_address,\n                        'geolocation': domain.domain_info.geolocation,\n                        'geolocation_iso': domain.domain_info.geolocation_iso,\n                    },\n                    'nameserver': {\n                        'history': NameServerHistorySerializer(domain.domain_info.nameserver_history.all(), many=True).data,\n                        'records': NSRecordSerializer(domain.domain_info.nameserver_record.all(), many=True).data\n                    },\n                    'registrant': {\n                        'name': domain.domain_info.whois.registrant.name,\n                        'organization': domain.domain_info.whois.registrant.organization,\n                        'email': domain.domain_info.whois.registrant.email,\n                        'address': domain.domain_info.whois.registrant.address,\n                        'city': domain.domain_info.whois.registrant.city,\n                        'state': domain.domain_info.whois.registrant.state,\n                        'country': domain.domain_info.whois.registrant.country,\n                        'country_iso': domain.domain_info.whois.registrant.country_iso,\n                        'tel': domain.domain_info.whois.registrant.phone_number,\n                        'fax': domain.domain_info.whois.registrant.fax,\n                    },\n                    'related_domains': unique_associated_domains,\n                    'related_tlds': unique_related_tlds,\n                    'whois': domain.domain_info.whois.details\n                }\n            return {\n                'status': False,\n                'message': 'WHOIS does not exist.'\n            }\n        return {\n            'status': False,\n            'message': 'Domain ' + ip_domain + ' does not exist as target and could not fetch WHOIS from database.'\n        }", "target": 0}, {"function": "def get_cms_details(url):\n    # this function will fetch cms details using cms_detector\n    response = {}\n    cms_detector_command = 'python3 /usr/src/github/CMSeeK/cmseek.py -u {} --random-agent --batch --follow-redirect'.format(url)\n    os.system(cms_detector_command)\n\n    response['status'] = False\n    response['message'] = 'Could not detect CMS!'\n\n    parsed_url = urlparse(url)\n\n    domain_name = parsed_url.hostname\n    port = parsed_url.port\n\n    find_dir = domain_name\n\n    if port:\n        find_dir += '_{}'.format(port)\n\n\n    print(url)\n    print(find_dir)\n\n    # subdomain may also have port number, and is stored in dir as _port\n\n    cms_dir_path =  '/usr/src/github/CMSeeK/Result/{}'.format(find_dir)\n    cms_json_path =  cms_dir_path + '/cms.json'\n\n    if os.path.isfile(cms_json_path):\n        cms_file_content = json.loads(open(cms_json_path, 'r').read())\n        if not cms_file_content.get('cms_id'):\n            return response\n        response = {}\n        response = cms_file_content\n        response['status'] = True\n        # remove cms dir path\n        try:\n            shutil.rmtree(cms_dir_path)\n        except Exception as e:\n            print(e)\n\n    return response", "target": 1, "line": "@@  -668,8 +669,12  @@ def get_whois(ip_domain, save_db=False, fetch_from_db=True):\n def get_cms_details(url):\n     # this function will fetch cms details using cms_detector\n     response = {}\n-    cms_detector_command = 'python3 /usr/src/github/CMSeeK/cmseek.py -u {} --random-agent --batch --follow-redirect'.format(url)\n-    os.system(cms_detector_command)\n+    cms_detector_command = 'python3 /usr/src/github/CMSeeK/cmseek.py --random-agent --batch --follow-redirect'\n+    subprocess_splitted_command = cms_detector_command.split()\n+    subprocess_splitted_command.append('-u')\n+    subprocess_splitted_command.append(url)\n+    process = subprocess.Popen(subprocess_splitted_command)\n+    process.wait()\n \n     response['status'] = False\n     response['message'] = 'Could not detect CMS!'"}], "function_after": [{"function": "class NSRecordSerializer(serializers.ModelSerializer):\n    class Meta:\n        model = NSRecord\n        fields = '__all__'", "target": 0}, {"function": "class NameServerHistorySerializer(serializers.ModelSerializer):\n    class Meta:\n        model = NameServerHistory\n        fields = '__all__'", "target": 0}, {"function": "class AssociatedDomainSerializer(serializers.ModelSerializer):\n    class Meta:\n        model = AssociatedDomain\n        fields = '__all__'", "target": 0}, {"function": "def get_lookup_keywords():\n    default_lookup_keywords = [\n        key.strip() for key in InterestingLookupModel.objects.get(\n            id=1).keywords.split(',')]\n    custom_lookup_keywords = []\n    if InterestingLookupModel.objects.filter(custom_type=True):\n        custom_lookup_keywords = [\n            key.strip() for key in InterestingLookupModel.objects.filter(\n                custom_type=True).order_by('-id')[0].keywords.split(',')]\n    lookup_keywords = default_lookup_keywords + custom_lookup_keywords\n    # remove empty strings from list, if any\n    lookup_keywords = list(filter(None, lookup_keywords))\n\n    return lookup_keywords", "target": 0}, {"function": "def get_interesting_subdomains(scan_history=None, target=None):\n    lookup_keywords = get_lookup_keywords()\n\n    subdomain_lookup_query = Q()\n    page_title_lookup_query = Q()\n\n    for key in lookup_keywords:\n        if InterestingLookupModel.objects.filter(custom_type=True).exists():\n            if InterestingLookupModel.objects.filter(\n                    custom_type=True).order_by('-id')[0].url_lookup:\n                subdomain_lookup_query |= Q(name__icontains=key)\n            if InterestingLookupModel.objects.filter(\n                    custom_type=True).order_by('-id')[0].title_lookup:\n                page_title_lookup_query |= Q(\n                    page_title__iregex=\"\\\\y{}\\\\y\".format(key))\n        else:\n            subdomain_lookup_query |= Q(name__icontains=key)\n            page_title_lookup_query |= Q(\n                page_title__iregex=\"\\\\y{}\\\\y\".format(key))\n\n    if InterestingLookupModel.objects.filter(\n            custom_type=True) and InterestingLookupModel.objects.filter(\n            custom_type=True).order_by('-id')[0].condition_200_http_lookup:\n        subdomain_lookup_query &= Q(http_status__exact=200)\n        page_title_lookup_query &= Q(http_status__exact=200)\n\n    subdomain_lookup = Subdomain.objects.none()\n    title_lookup = Subdomain.objects.none()\n\n    if target:\n        subdomains = Subdomain.objects.filter(target_domain__id=target).distinct('name')\n        if subdomain_lookup_query:\n            subdomain_lookup = subdomains.filter(subdomain_lookup_query)\n        if page_title_lookup_query:\n            title_lookup = subdomains.filter(page_title_lookup_query)\n    elif scan_history:\n        subdomains = Subdomain.objects.filter(scan_history__id=scan_history)\n        if subdomain_lookup_query:\n            subdomain_lookup = subdomains.filter(subdomain_lookup_query)\n        if page_title_lookup_query:\n            title_lookup = subdomains.filter(page_title_lookup_query)\n    else:\n        if subdomain_lookup_query:\n            subdomain_lookup = Subdomain.objects.filter(subdomain_lookup_query)\n        if page_title_lookup_query:\n            title_lookup = Subdomain.objects.filter(page_title_lookup_query)\n    lookup = subdomain_lookup | title_lookup\n    return lookup", "target": 0}, {"function": "def get_interesting_endpoint(scan_history=None, target=None):\n    lookup_keywords = get_lookup_keywords()\n\n    url_lookup_query = Q()\n    page_title_lookup_query = Q()\n\n    for key in lookup_keywords:\n        if InterestingLookupModel.objects.filter(custom_type=True).exists():\n            if InterestingLookupModel.objects.filter(custom_type=True).order_by('-id')[0].url_lookup:\n                url_lookup_query |= Q(http_url__icontains=key)\n            if InterestingLookupModel.objects.filter(custom_type=True).order_by('-id')[0].title_lookup:\n                page_title_lookup_query |= Q(page_title__iregex=\"\\\\y{}\\\\y\".format(key))\n\n        else:\n            url_lookup_query |= Q(http_url__icontains=key)\n            page_title_lookup_query |= Q(page_title__iregex=\"\\\\y{}\\\\y\".format(key))\n\n    if InterestingLookupModel.objects.filter(custom_type=True) and InterestingLookupModel.objects.filter(custom_type=True).order_by('-id')[0].condition_200_http_lookup:\n        url_lookup_query &= Q(http_status__exact=200)\n        page_title_lookup_query &= Q(http_status__exact=200)\n\n    url_lookup = EndPoint.objects.none()\n    title_lookup = EndPoint.objects.none()\n\n    if target:\n        urls = EndPoint.objects.filter(target_domain__id=target).distinct('http_url')\n        if url_lookup_query:\n            url_lookup = urls.filter(url_lookup_query)\n        if page_title_lookup_query:\n            title_lookup = urls.filter(page_title_lookup_query)\n    elif scan_history:\n        urls = EndPoint.objects.filter(scan_history__id=scan_history)\n        if url_lookup_query:\n            url_lookup = urls.filter(url_lookup_query)\n        if page_title_lookup_query:\n            title_lookup = urls.filter(page_title_lookup_query)\n\n    else:\n        if url_lookup_query:\n            url_lookup = EndPoint.objects.filter(url_lookup_query)\n        if page_title_lookup_query:\n            title_lookup = EndPoint.objects.filter(page_title_lookup_query)\n\n    return url_lookup | title_lookup", "target": 0}, {"function": "def check_keyword_exists(keyword_list, subdomain):\n    return any(sub in subdomain for sub in keyword_list)", "target": 0}, {"function": "def get_subdomain_from_url(url):\n    extract_url = tldextract.extract(url)\n    subdomain = '.'.join(extract_url[:4])\n    if subdomain[0] == '.':\n        subdomain = subdomain[1:]\n    return subdomain", "target": 0}, {"function": "def get_domain_from_subdomain(subdomain):\n    ext = tldextract.extract(subdomain)\n    return '.'.join(ext[1:3])", "target": 0}, {"function": "def send_telegram_message(message):\n    notification = Notification.objects.all()\n    if notification and notification[0].send_to_telegram \\\n    and notification[0].telegram_bot_token \\\n    and notification[0].telegram_bot_chat_id:\n        telegram_bot_token = notification[0].telegram_bot_token\n        telegram_bot_chat_id = notification[0].telegram_bot_chat_id\n        send_text = 'https://api.telegram.org/bot' + telegram_bot_token \\\n            + '/sendMessage?chat_id=' + telegram_bot_chat_id \\\n            + '&parse_mode=Markdown&text=' + message\n        thread = Thread(target=requests.get, args = (send_text, ))\n        thread.start()", "target": 0}, {"function": "def send_slack_message(message):\n    headers = {'content-type': 'application/json'}\n    message = {'text': message}\n    notification = Notification.objects.all()\n    if notification and notification[0].send_to_slack \\\n    and notification[0].slack_hook_url:\n        hook_url = notification[0].slack_hook_url\n        thread = Thread(\n            target=requests.post,\n            kwargs = {\n                'url': hook_url,\n                'data': json.dumps(message),\n                'headers': headers,\n            })\n        thread.start()", "target": 0}, {"function": "def send_discord_message(message):\n    notification = Notification.objects.all()\n    if notification and notification[0].send_to_discord \\\n    and notification[0].discord_hook_url:\n        webhook = DiscordWebhook(\n            url=notification[0].discord_hook_url,\n            content=message,\n            rate_limit_retry=True\n            )\n        thread = Thread(target=webhook.execute)\n        thread.start()", "target": 0}, {"function": "def send_files_to_discord(file_path):\n    notification = Notification.objects.all()\n    if notification and notification[0].send_to_discord \\\n    and notification[0].discord_hook_url:\n        webhook = DiscordWebhook(\n            url=notification[0].discord_hook_url,\n            rate_limit_retry=True,\n            username=\"Scan Results - File\"\n        )\n        with open(file_path, \"rb\") as f:\n            head, tail = os.path.split(file_path)\n            webhook.add_file(file=f.read(), filename=tail)\n        thread = Thread(target=webhook.execute)\n        thread.start()", "target": 0}, {"function": "def send_notification(message):\n    send_slack_message(message)\n    send_discord_message(message)\n    send_telegram_message(message)", "target": 0}, {"function": "def get_random_proxy():\n    if Proxy.objects.all().exists():\n        proxy = Proxy.objects.all()[0]\n        if proxy.use_proxy:\n            proxy_name = random.choice(proxy.proxies.splitlines())\n            print('Using proxy: ' + proxy_name)\n            return proxy_name\n    return False", "target": 0}, {"function": "def send_hackerone_report(vulnerability_id):\n    headers = {\n        'Content-Type': 'application/json',\n        'Accept': 'application/json'\n    }\n    # get hackerone creds\n    vulnerability = Vulnerability.objects.get(id=vulnerability_id)\n    # can only send vulnerability report if team_handle exists\n    if len(vulnerability.target_domain.h1_team_handle) !=0:\n        if Hackerone.objects.all().exists():\n            hackerone = Hackerone.objects.all()[0]\n            if vulnerability.severity == 0:\n                severity_value = 'none'\n            elif vulnerability.severity == 1:\n                severity_value = 'low'\n            elif vulnerability.severity == 2:\n                severity_value = 'medium'\n            elif vulnerability.severity == 3:\n                severity_value = 'high'\n            elif vulnerability.severity == 4:\n                severity_value = 'critical'\n            report_template = hackerone.report_template\n            # Replace syntax of report template with actual content\n            if '{vulnerability_name}' in report_template:\n                report_template = report_template.replace('{vulnerability_name}', vulnerability.name)\n            if '{vulnerable_url}' in report_template:\n                report_template = report_template.replace('{vulnerable_url}', vulnerability.http_url)\n            if '{vulnerability_severity}' in report_template:\n                report_template = report_template.replace('{vulnerability_severity}', severity_value)\n            if '{vulnerability_description}' in report_template:\n                report_template = report_template.replace('{vulnerability_description}', vulnerability.description if vulnerability.description else '')\n            if '{vulnerability_extracted_results}' in report_template:\n                report_template = report_template.replace('{vulnerability_extracted_results}', vulnerability.extracted_results if vulnerability.extracted_results else '')\n            if '{vulnerability_reference}' in report_template:\n                report_template = report_template.replace('{vulnerability_reference}', vulnerability.reference if vulnerability.reference else '')\n\n            data = {\n              \"data\": {\n                \"type\": \"report\",\n                \"attributes\": {\n                  \"team_handle\": vulnerability.target_domain.h1_team_handle,\n                  \"title\": '{} found in {}'.format(vulnerability.name, vulnerability.http_url),\n                  \"vulnerability_information\": report_template,\n                  \"severity_rating\": severity_value,\n                  \"impact\": \"More information about the impact and vulnerability can be found here: \\n\" + vulnerability.reference if vulnerability.reference else \"NA\",\n                }\n              }\n            }\n\n            r = requests.post(\n              'https://api.hackerone.com/v1/hackers/reports',\n              auth=(hackerone.username, hackerone.api_key),\n              json = data,\n              headers = headers\n            )\n\n            response = r.json()\n\n            # print(response)\n\n            status_code = r.status_code\n            print(status_code)\n\n            if status_code == 201:\n                vulnerability.hackerone_report_id = response['data'][\"id\"]\n                vulnerability.open_status = False\n                vulnerability.save()\n\n            return status_code\n\n    else:\n        print('No target ')\n        status_code = 111\n\n        return status_code", "target": 0}, {"function": "def get_whois(ip_domain, save_db=False, fetch_from_db=True):\n    # this function will fetch whois details for domains\n    # if save_db = True, then the whois will be saved in db\n    # if fetch_from_db = True then whois will be fetched from db, no lookup on\n    #     bigdomain data will be done\n    if ip_domain and not fetch_from_db:\n        response = requests.get('https://domainbigdata.com/{}'.format(ip_domain))\n        tree = html.fromstring(response.content)\n        try:\n            #RegistrantInfo Model\n            name = tree.xpath('//*[@id=\"trRegistrantName\"]/td[2]/a/text()')\n            organization = tree.xpath('//*[@id=\"MainMaster_trRegistrantOrganization\"]/td[2]/a/text()')\n            email = tree.xpath('//*[@id=\"trRegistrantEmail\"]/td[2]/a/text()')\n            address = tree.xpath('//*[@id=\"trRegistrantAddress\"]/td[2]/text()')\n            city = tree.xpath('//*[@id=\"trRegistrantCity\"]/td[2]/text()')\n            state = tree.xpath('//*[@id=\"trRegistrantState\"]/td[2]/text()')\n            country = tree.xpath('//*[@id=\"trRegistrantCountry\"]/td[2]/text()')\n            country_iso = tree.xpath('//*[@id=\"imgFlagRegistrant\"]/@alt')\n            tel = tree.xpath('//*[@id=\"trRegistrantTel\"]/td[2]/text()')\n            fax = tree.xpath('//*[@id=\"trRegistrantFax\"]/td[2]/text()')\n\n            #finding domain association using organization\n            organization_association_href = tree.xpath('//*[@id=\"MainMaster_trRegistrantOrganization\"]/td[2]/a/@href')\n            #finding domain association using email\n            email_association_href = tree.xpath('//*[@id=\"trRegistrantEmail\"]/td[2]/a/@href')\n\n            # related tlds\n            related_tlds = tree.xpath('//*[@id=\"divListOtherTLD\"]/descendant::*/text()')\n\n            # whois model\n            whois = tree.xpath('//*[@id=\"whois\"]/div/div[3]/text()')\n            whois = \"\\n\".join(whois).strip()\n\n            # DomainInfo Model\n            date_created = tree.xpath('//*[@id=\"trDateCreation\"]/td[2]/text()')\n            domain_age = tree.xpath('//*[@id=\"trWebAge\"]/td[2]/text()')\n            ip_address = tree.xpath('//*[@id=\"trIP\"]/td[2]/a/text()')\n            geolocation = tree.xpath('//*[@id=\"imgFlag\"]/following-sibling::text()')\n            geolocation_iso = tree.xpath('//*[@id=\"imgFlag\"]/@alt')\n\n            is_private_path = tree.xpath(\"//*[contains(@class, 'websiteglobalstats')]/tr[10]/td[2]/span/text()\")\n            is_private = False\n            if len(is_private_path) > 0:\n                is_private = True\n\n\n            date_created = date_created[0].strip() if date_created else None\n            domain_age = domain_age[0].strip() if domain_age else None\n            ip_address = ip_address[0].strip() if ip_address else None\n            geolocation = geolocation[0].strip() if geolocation else None\n            geolocation_iso = geolocation_iso[0].strip() if geolocation_iso else None\n            name = name[0].strip() if name else None\n            organization = organization[0].strip() if organization else None\n            email = email[0].strip() if email else None\n            address = address[0].strip() if address else None\n            city = city[0].strip() if city else None\n            state = state[0].strip() if state else None\n            country = country[0].strip() if country else None\n            country_iso = country_iso[0].strip() if country_iso else None\n            tel = tel[0].strip() if tel else None\n            fax = fax[0].strip() if fax else None\n\n            # association\n            organization_association_href = organization_association_href[0].strip() if organization_association_href else None\n            email_association_href = email_association_href[0].strip() if email_association_href else None\n\n            # other tlds\n            related_tlds = [ tld for tld in related_tlds if \"\\r\\n\" not in tld ]\n\n            dns_history_xpath = tree.xpath(\"//*[@id='MainMaster_divNSHistory']/table/tbody/tr\")\n            dns_history = []\n            for table_row in dns_history_xpath:\n                row = table_row.xpath('td/text()')\n                dns_history.append(\n                    {\n                        'date': row[0],\n                        'action': row[1],\n                        'nameserver': row[2],\n                    }\n                )\n\n            associated_domains = []\n            if organization_association_href and organization not in IGNORE_WHOIS_RELATED_KEYWORD:\n                # get all associated domains using organization\n                response_org = requests.get('https://domainbigdata.com{}'.format(organization_association_href))\n                tree_org = html.fromstring(response_org.content)\n                associated_domains_tree = tree_org.xpath('//*[@id=\"aDomain\"]/text()')\n                for domain in associated_domains_tree:\n                    associated_domains.append(domain)\n\n            if email_association_href and email not in IGNORE_WHOIS_RELATED_KEYWORD:\n                print(email_association_href)\n                response_email = requests.get('https://domainbigdata.com{}'.format(email_association_href))\n                tree_email = html.fromstring(response_email.content)\n                associated_domains_tree = tree_email.xpath('//*[@id=\"aDomain\"]/text()')\n                for domain in associated_domains_tree:\n                    associated_domains.append(domain)\n\n            # unique associated_domains\n            unique_associated_domains = []\n            [unique_associated_domains.append(domain) for domain in associated_domains if domain not in unique_associated_domains]\n\n            # save in db\n            if save_db and Domain.objects.filter(name=ip_domain).exists():\n                # look for domain and save in db\n                domain = Domain.objects.get(name=ip_domain)\n\n\n                # check if registrant exists\n                if RegistrantInfo.objects.filter(email=email).filter(name=name).exists():\n                    registrant = RegistrantInfo.objects.get(email=email, name=name)\n                else:\n                    registrant = RegistrantInfo()\n                    registrant.name = name\n                    registrant.organization = organization\n                    registrant.email = email\n                    registrant.address = address\n                    registrant.city = city\n                    registrant.state = state\n                    registrant.country = country\n                    registrant.country_iso = country_iso\n                    registrant.phone_number = tel\n                    registrant.fax = fax\n                    registrant.organization_association_href = organization_association_href\n                    registrant.email_association_href = email_association_href\n                    registrant.save()\n\n                if WhoisDetail.objects.filter(details=whois).exists():\n                    whois_model = WhoisDetail.objects.get(details=whois)\n                else:\n                    whois_model = WhoisDetail()\n                    whois_model.details = whois if whois else None\n                    whois_model.registrant = registrant\n                    whois_model.save()\n\n                domain_info = DomainInfo()\n                domain_info.date_created = date_created\n                domain_info.domain_age = domain_age\n                domain_info.ip_address = ip_address\n                domain_info.geolocation = geolocation\n                domain_info.geolocation_iso = geolocation_iso\n                domain_info.whois = whois_model\n                domain_info.save()\n\n                for table_row in dns_history_xpath:\n                    row = table_row.xpath('td/text()')\n                    ns_history = NameServerHistory()\n                    ns_history.date = row[0]\n                    ns_history.action = row[1]\n                    ns_history.server = row[2]\n                    ns_history.save()\n\n                    domain_info.nameserver_history.add(ns_history);\n\n                domain.domain_info = domain_info\n                domain.save()\n\n\n                # save associated domains\n                for domain in unique_associated_domains:\n                    if AssociatedDomain.objects.filter(name=domain).exists():\n                        ass_domain = AssociatedDomain.objects.get(name=domain)\n                    else:\n                        ass_domain = AssociatedDomain()\n                        ass_domain.name = domain\n                        ass_domain.save()\n                    domain_info.associated_domains.add(ass_domain)\n\n                # save related TLDs\n                for tld in related_tlds:\n                    if RelatedTLD.objects.filter(name=tld).exists():\n                        rel_tld = RelatedTLD.objects.get(name=tld)\n                    else:\n                        rel_tld = RelatedTLD()\n                        rel_tld.name = tld\n                        rel_tld.save()\n                    domain_info.related_tlds.add(rel_tld)\n\n            ns_records = []\n            for i in range(4):\n                ns_records_xpath = tree.xpath(\"//*[@id='divDNSRecords']/table[{}]/tbody/tr\".format(i))\n                for table_row in ns_records_xpath:\n                    row = table_row.xpath('td/text()')\n                    if row[0] == 'A':\n                        # for getting address, use child lookup\n                        address = table_row.xpath('td/a/text()')\n                        address = address[0] if address else None\n\n                        ns_records.append(\n                            {\n                                'type': row[0],\n                                'hostname': row[1],\n                                'address': address,\n                                'ttl': row[2],\n                                'class': row[3],\n                            }\n                        )\n\n                        if save_db and Domain.objects.filter(name=ip_domain).exists():\n                            ns = NSRecord()\n                            ns.type = row[0]\n                            ns.hostname = row[1]\n                            ns.address = address\n                            ns.ttl = row[2]\n                            ns.ns_class = row[3]\n                            ns.save()\n                            domain_info.nameserver_record.add(ns)\n\n                    elif row[0] == 'AAAA':\n                        # for getting address, use child lookup\n                        ns_records.append(\n                            {\n                                'type': row[0],\n                                'hostname': row[1],\n                                'address': row[2],\n                                'ttl': row[3],\n                                'class': row[4],\n                            }\n                        )\n\n                        if save_db and Domain.objects.filter(name=ip_domain).exists():\n                            ns = NSRecord()\n                            ns.type = row[0]\n                            ns.hostname = row[1]\n                            ns.address = row[2]\n                            ns.ttl = row[3]\n                            ns.ns_class = row[4]\n                            ns.save()\n                            domain_info.nameserver_record.add(ns)\n\n                    elif row[0] == 'MX':\n                        ns_records.append(\n                            {\n                                'type': row[0],\n                                'hostname': row[1],\n                                'address': row[2],\n                                'preference': row[3],\n                                'ttl': row[4],\n                                'class': row[5],\n                            }\n                        )\n\n                        if save_db and Domain.objects.filter(name=ip_domain).exists():\n                            ns = NSRecord()\n                            ns.type = row[0]\n                            ns.hostname = row[1]\n                            ns.address = address\n                            ns.preference = row[3]\n                            ns.ttl = row[4]\n                            ns.ns_class = row[5]\n                            ns.save()\n                            domain_info.nameserver_record.add(ns)\n\n\n            final_organization_association_url = 'https://domainbigdata.com' + organization_association_href if organization_association_href else None\n            final_email_association_url = 'https://domainbigdata.com' + email_association_href if email_association_href else None\n\n\n            return {\n                'status': True,\n                'ip_domain': ip_domain,\n                'domain': {\n                    'date_created': date_created,\n                    'domain_age': domain_age,\n                    'ip_address': ip_address,\n                    'geolocation': geolocation,\n                    'geolocation_iso': geolocation_iso,\n                },\n                'nameserver': {\n                    'history': dns_history,\n                    'records': ns_records\n                },\n                'registrant': {\n                    'name': name,\n                    'organization': organization,\n                    'email': email,\n                    'address': address,\n                    'city': city,\n                    'state': state,\n                    'country': country,\n                    'country_iso': country_iso,\n                    'tel': tel,\n                    'fax': fax,\n                    'organization_association_url': final_organization_association_url,\n                    'email_association_url': final_email_association_url,\n                },\n                'related_domains': unique_associated_domains,\n                'related_tlds': related_tlds,\n                'whois': whois if whois else None\n            }\n        except Exception as e:\n            logging.exception(e)\n            return {\n                'status': False,\n                'ip_domain': ip_domain,\n                'result': 'Domain not found'\n            }\n    elif ip_domain and fetch_from_db:\n        if Domain.objects.filter(name=ip_domain).exists():\n            domain = Domain.objects.get(name=ip_domain)\n            unique_associated_domains = []\n\n            if domain.domain_info and domain.domain_info.associated_domains:\n                unique_associated_domains = [d.name for d in domain.domain_info.associated_domains.all()]\n\n\n            unique_related_tlds = []\n            if domain.domain_info and domain.domain_info.related_tlds:\n                unique_related_tlds = [d.name for d in domain.domain_info.related_tlds.all()]\n\n            if domain.domain_info:\n                return {\n                    'status': True,\n                    'ip_domain': ip_domain,\n                    'domain': {\n                        'date_created': domain.domain_info.date_created,\n                        'domain_age': domain.domain_info.domain_age,\n                        'ip_address': domain.domain_info.ip_address,\n                        'geolocation': domain.domain_info.geolocation,\n                        'geolocation_iso': domain.domain_info.geolocation_iso,\n                    },\n                    'nameserver': {\n                        'history': NameServerHistorySerializer(domain.domain_info.nameserver_history.all(), many=True).data,\n                        'records': NSRecordSerializer(domain.domain_info.nameserver_record.all(), many=True).data\n                    },\n                    'registrant': {\n                        'name': domain.domain_info.whois.registrant.name,\n                        'organization': domain.domain_info.whois.registrant.organization,\n                        'email': domain.domain_info.whois.registrant.email,\n                        'address': domain.domain_info.whois.registrant.address,\n                        'city': domain.domain_info.whois.registrant.city,\n                        'state': domain.domain_info.whois.registrant.state,\n                        'country': domain.domain_info.whois.registrant.country,\n                        'country_iso': domain.domain_info.whois.registrant.country_iso,\n                        'tel': domain.domain_info.whois.registrant.phone_number,\n                        'fax': domain.domain_info.whois.registrant.fax,\n                    },\n                    'related_domains': unique_associated_domains,\n                    'related_tlds': unique_related_tlds,\n                    'whois': domain.domain_info.whois.details\n                }\n            return {\n                'status': False,\n                'message': 'WHOIS does not exist.'\n            }\n        return {\n            'status': False,\n            'message': 'Domain ' + ip_domain + ' does not exist as target and could not fetch WHOIS from database.'\n        }", "target": 0}, {"function": "def get_cms_details(url):\n    # this function will fetch cms details using cms_detector\n    response = {}\n    cms_detector_command = 'python3 /usr/src/github/CMSeeK/cmseek.py --random-agent --batch --follow-redirect'\n    subprocess_splitted_command = cms_detector_command.split()\n    subprocess_splitted_command.append('-u')\n    subprocess_splitted_command.append(url)\n    process = subprocess.Popen(subprocess_splitted_command)\n    process.wait()\n\n    response['status'] = False\n    response['message'] = 'Could not detect CMS!'\n\n    parsed_url = urlparse(url)\n\n    domain_name = parsed_url.hostname\n    port = parsed_url.port\n\n    find_dir = domain_name\n\n    if port:\n        find_dir += '_{}'.format(port)\n\n\n    print(url)\n    print(find_dir)\n\n    # subdomain may also have port number, and is stored in dir as _port\n\n    cms_dir_path =  '/usr/src/github/CMSeeK/Result/{}'.format(find_dir)\n    cms_json_path =  cms_dir_path + '/cms.json'\n\n    if os.path.isfile(cms_json_path):\n        cms_file_content = json.loads(open(cms_json_path, 'r').read())\n        if not cms_file_content.get('cms_id'):\n            return response\n        response = {}\n        response = cms_file_content\n        response['status'] = True\n        # remove cms dir path\n        try:\n            shutil.rmtree(cms_dir_path)\n        except Exception as e:\n            print(e)\n\n    return response", "target": 0}]}], "outdated": 0, "cwe_descripiton": "", "cwe_consequence": "", "cwe_method": "", "cwe_solution": ""}
