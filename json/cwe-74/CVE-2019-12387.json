{"index": 3596, "cve_id": "CVE-2019-12387", "cwe_id": ["CWE-74", "CWE-20"], "cve_language": "Python", "cve_description": "In Twisted before 19.2.1, twisted.web did not validate or sanitize URIs or HTTP methods, allowing an attacker to inject invalid characters such as CRLF.", "cvss": "6.1", "publish_date": "June 10, 2019", "AV": "NETWORK", "AC": "NETWORK", "PR": "NONE", "UI": "REQUIRED", "S": "CHANGED", "C": "LOW", "I": "LOW", "A": "NONE", "commit_id": "6c61fc4503ae39ab8ecee52d10f10ee2c371d7e2", "commit_message": "Prevent CRLF injections described in CVE-2019-12387\n\nAuthor: markrwilliams\r\n\r\nReviewers: glyph\r\n\r\nFixes: ticket:9647\r\n\r\nTwisted's HTTP client APIs were vulnerable to maliciously constructed\r\nHTTP methods, hosts, and/or paths, URI components such as paths and\r\nquery parameters.  These vulnerabilities were beyond the header name\r\nand value injection vulnerabilities addressed in:\r\n\r\nhttps://twistedmatrix.com/trac/ticket/9420\r\nhttps://github.com/twisted/twisted/pull/999/\r\n\r\nThe following client APIs will raise a ValueError if given a method,\r\nhost, or URI that includes newlines or other disallowed characters:\r\n\r\n- twisted.web.client.Agent.request\r\n- twisted.web.client.ProxyAgent.request\r\n- twisted.web.client.Request.__init__\r\n- twisted.web.client.Request.writeTo\r\n\r\nProxyAgent is patched separately from Agent because unlike other\r\nagents (e.g. CookieAgent) it is not implemented as an Agent wrapper.\r\n\r\nRequest.__init__ checks its method and URI so that errors occur closer\r\nto their originating input.  Request.method and Request.uri are both\r\npublic APIs, however, so Request.writeTo (via Request._writeHeaders)\r\nalso checks the validity of both before writing anything to the wire.\r\n\r\nAdditionally, the following deprecated client APIs have also been\r\npatched:\r\n\r\n- twisted.web.client.HTTPPageGetter.__init__\r\n- twisted.web.client.HTTPPageDownloader.__init__\r\n- twisted.web.client.HTTPClientFactory.__init__\r\n- twisted.web.client.HTTPClientFactory.setURL\r\n- twisted.web.client.HTTPDownloader.__init__\r\n- twisted.web.client.HTTPDownloader.setURL\r\n- twisted.web.client.getPage\r\n- twisted.web.client.downloadPage\r\n\r\nThese have been patched prior to their removal so that they won't be\r\nvulnerable in the last Twisted release that includes them.  They\r\nrepresent a best effort, because testing every combination of these\r\npublic APIs would require more code than deprecated APIs warrant.\r\n\r\nIn all cases URI components, including hostnames, are restricted to\r\nthe characters allowed in path components.  This mirrors the CPython\r\npatch (for bpo-30458) that addresses equivalent vulnerabilities:\r\n\r\nhttps://github.com/python/cpython/commit/bb8071a4cae5ab3fe321481dd3d73662ffb26052\r\n\r\nHTTP methods, however, are checked against the set of characters\r\ndescribed in RFC-7230.", "commit_date": "2019-06-05T07:03:37Z", "project": "twisted/twisted", "url": "https://api.github.com/repos/twisted/twisted/commits/6c61fc4503ae39ab8ecee52d10f10ee2c371d7e2", "html_url": "https://github.com/twisted/twisted/commit/6c61fc4503ae39ab8ecee52d10f10ee2c371d7e2", "windows_before": [{"commit_id": "268318f426046f6eb96e2738c4de2654d2afb6ff", "commit_date": "Mon Jun 3 22:39:58 2019 -0700", "commit_message": "Wrap long lines", "files_name": ["src/twisted/web/test/test_http.py"]}, {"commit_id": "4f5a1274dec83059bb7f6bdc2a344e00ddf85f9d", "commit_date": "Mon Jun 3 22:10:41 2019 -0700", "commit_message": "Update newsfragment", "files_name": ["src/twisted/web/newsfragments/9646.bugfix"]}, {"commit_id": "d2f6dd9b3766509f40c980aac67ca8475da67c6f", "commit_date": "Mon Jun 3 22:03:22 2019 -0700", "commit_message": "Refactor to reduce duplication", "files_name": ["src/twisted/web/test/test_http.py"]}, {"commit_id": "1e2d27966b618bb49860e3708d32fdcb80842da5", "commit_date": "Mon Jun 3 17:13:16 2019 -0700", "commit_message": "Reject invalid header lines", "files_name": ["src/twisted/web/http.py"]}, {"commit_id": "7d907209aa3380cee2ec1cb1e038baef74fef9ae", "commit_date": "Mon Jun 3 16:59:10 2019 -0700", "commit_message": "Also test for an empty header name", "files_name": ["src/twisted/web/test/test_http.py"]}, {"commit_id": "374aecfcb30aa85bd04b0662c06c8396dbeeeeac", "commit_date": "Mon Jun 3 16:47:27 2019 -0700", "commit_message": "Add newsfile", "files_name": ["src/twisted/web/newsfragments/9646.bugfix"]}, {"commit_id": "d4f777f540505645998124b58404f07d12a9a984", "commit_date": "Mon Jun 3 16:32:27 2019 -0700", "commit_message": "Test to reproduce", "files_name": ["src/twisted/web/test/test_http.py"]}, {"commit_id": "081fc0e87fcf83bbf57a128bdd5cd1f888427a61", "commit_date": "Mon Jun 3 16:05:48 2019 -0700", "commit_message": "Fix lint failure", "files_name": ["src/twisted/web/test/test_http.py"]}, {"commit_id": "bac557f994463b72a20406e30101c6760eb3e489", "commit_date": "Mon Jun 3 16:03:08 2019 -0700", "commit_message": "Add missing assertion", "files_name": ["src/twisted/web/test/test_http.py"]}, {"commit_id": "8dee233b36ad98d47a90a5248f41f1df1fe1c24b", "commit_date": "Mon Jun 3 15:55:32 2019 -0700", "commit_message": "Add newsfragment", "files_name": ["src/twisted/web/newsfragments/9644.bugfix"]}, {"commit_id": "22efa61cf531219a34be87fb6e4a708456437e5a", "commit_date": "Mon Jun 3 15:48:57 2019 -0700", "commit_message": "Fix t.w.http.HTTPChannel header type confusion", "files_name": ["src/twisted/web/http.py"]}, {"commit_id": "3d98666dbd4766f7773bee5c97f35972fdd0383a", "commit_date": "Mon Jun 3 15:26:05 2019 -0700", "commit_message": "Add t.w.http.HTTPChannel line folding test", "files_name": ["src/twisted/web/test/test_http.py"]}, {"commit_id": "baa427cff97b14456ba60f1c00c644c9cd2db2ab", "commit_date": "Mon Jun 3 14:18:25 2019 -0700", "commit_message": "Test newclient header folding", "files_name": ["src/twisted/web/test/test_newclient.py"]}, {"commit_id": "d0bcf0ba9573a010d199bb3e0b1f5f22a3c72bb0", "commit_date": "Tue Jun 4 22:35:25 2019 -0600", "commit_message": "Merge pull request #1153 from twisted/9648-pypi-readme", "files_name": ["131c2e1b8a02bc4ff107aa306a21910fbc39604a - Tue Jun 4 14:52:49 2019 -0700 : Fix lint failure", "src/twisted/python/test/test_setup.py"]}, {"commit_id": "0f02a46b6db012804d9409aed5d220d68905f0ba", "commit_date": "Tue Jun 4 14:51:15 2019 -0700", "commit_message": "Add newsfragment", "files_name": ["src/twisted/newsfragments/9648.feature"]}, {"commit_id": "4e919ebd8655ddea962d8241f4c131e0c0fe0fa5", "commit_date": "Tue Jun 4 14:38:38 2019 -0700", "commit_message": "Generate long_description from README.rst", "files_name": ["src/twisted/python/_setup.py", "src/twisted/python/test/test_setup.py", "tox.ini"]}, {"commit_id": "106374f6f6d09c136d7a5509b68cd0d04b6f5e38", "commit_date": "Mon Jun 3 23:24:24 2019 -0700", "commit_message": "Remove obsolete codecov badge", "files_name": ["README.rst"]}, {"commit_id": "688325e95a0032e0f8d015993a54cfd3fcc16546", "commit_date": "Mon Jun 3 23:23:40 2019 -0700", "commit_message": "Remove obsolete appveyor badge", "files_name": ["README.rst"]}, {"commit_id": "9d247119b5d4fd21a9edd06e9fcfc035a1da4235", "commit_date": "Mon Jun 3 23:17:51 2019 -0700", "commit_message": "Add project_urls", "files_name": ["src/twisted/python/_setup.py"]}, {"commit_id": "d29ec93adcb7079ecff9f27eade642861c4b9df2", "commit_date": "Mon Jun 3 23:11:59 2019 -0700", "commit_message": "Use HTTPS links in setup.py", "files_name": ["src/twisted/python/_setup.py"]}, {"commit_id": "160238b48a722e20ec1c95d4030e7f4c6227d003", "commit_date": "Mon Jun 3 23:08:54 2019 -0700", "commit_message": "Use HTTPS links in the readme", "files_name": ["README.rst"]}, {"commit_id": "95eec1a0bf275b9a1af7554783dfdb5c334b8e64", "commit_date": "Mon Jun 3 14:37:19 2019 -0600", "commit_message": "Merge branch 'trunk' into trunk", "files_name": ["4ec55088d755aa45afc6d58791ba7caea6d57fd6 - Thu May 30 10:41:47 2019 +0100 : Fix circular import in twisted.trial.reporter", "src/twisted/newsfragments/8267.bugfix", "src/twisted/trial/reporter.py"]}, {"commit_id": "41985d3f4f9ef94690ee11329f3935200ff097cc", "commit_date": "Tue May 28 21:53:16 2019 -0700", "commit_message": "Merge pull request #1146 from twisted/9643-agent-method-bytes", "files_name": ["10f6d03ec90a844d496214450604ac89b50739b5 - Tue May 28 19:50:46 2019 -0700 : ProxyAgent too", "src/twisted/newsfragments/9643.bugfix", "src/twisted/web/client.py", "src/twisted/web/test/test_agent.py"]}, {"commit_id": "a649757186c12d2b4f4a8e215b4d36ba26bd331f", "commit_date": "Tue May 28 16:53:22 2019 +0200", "commit_message": "Better docstring for BasicAuthenticatorTests", "files_name": ["src/twisted/words/test/test_jabberclient.py"]}, {"commit_id": "1f3c9dcd1e666131e3630a5b10b7dc920ce092a8", "commit_date": "Tue May 28 10:16:06 2019 +0200", "commit_message": "Merge branch 'trunk' into trunk", "files_name": ["fa1bc1b9cef2ffe27de0b7202a0075304c13d104 - Mon May 27 14:58:12 2019 -0700 : Merge branch 'trunk' into 9561-xmpp-tls-verify-cert", "672a6338dea08a17cbe18af3d47bdb14fcd0d84b - Mon May 27 15:33:20 2019 +0200 : Fix indents", "src/twisted/words/test/test_jabberclient.py", "src/twisted/words/test/test_jabberxmlstream.py"]}, {"commit_id": "751ac6f754146e5b61ab65d2995be2a9534bd41d", "commit_date": "Mon May 27 14:48:26 2019 +0200", "commit_message": "Skip TLS tests if OpenSSL is not available", "files_name": ["src/twisted/words/test/test_jabberclient.py", "src/twisted/words/test/test_jabberxmlstream.py"]}, {"commit_id": "0a93949f91ea22cfc5453c326e36e927c8da1015", "commit_date": "Mon May 27 13:53:31 2019 +0200", "commit_message": "Fix skipping renamed test when SSL is not available", "files_name": ["src/twisted/words/test/test_jabberxmlstream.py"]}, {"commit_id": "a1f43907c60cb3f92699067c43fdf166cbac2cea", "commit_date": "Mon May 27 11:00:39 2019 +0200", "commit_message": "Add news fragments", "files_name": ["src/twisted/words/newsfragments/9561.bugfix", "src/twisted/words/newsfragments/9561.feature"]}, {"commit_id": "48220a4faa143bb2fa1253bac11aff4c43d256ac", "commit_date": "Sun May 26 20:59:06 2019 -0700", "commit_message": "Unlengthen line", "files_name": ["src/twisted/web/test/test_agent.py"]}, {"commit_id": "725cba630ed76171c17e55381b4f53a34240684a", "commit_date": "Sun May 26 20:48:36 2019 -0700", "commit_message": "Newsfile", "files_name": ["src/twisted/newsfragments/9643.bugfix"]}, {"commit_id": "2b66a306fbb4af8032e89e34848d16f5cfe79776", "commit_date": "Sun May 26 20:45:59 2019 -0700", "commit_message": "Raise TypeError for non-bytes Agent.request method", "files_name": ["src/twisted/web/client.py", "src/twisted/web/test/test_agent.py"]}, {"commit_id": "13aa60c760a59a5bde61fd3c3ee4f029fdb3567d", "commit_date": "Sun May 19 17:30:11 2019 -0500", "commit_message": "cleanup", "files_name": ["src/twisted/trial/runner.py", "src/twisted/trial/test/test_loader.py"]}, {"commit_id": "4e4f8cf8bb9c510eda7387615915a2d6b576451d", "commit_date": "Sun May 19 16:37:00 2019 -0500", "commit_message": "Merge branch '9628-trial3-importerror' of ssh://github.com/twisted/twisted into 9628-trial3-importerror", "files_name": ["f8cce08e9ea4faf329475f6876d3f58130cde264 - Sun May 19 16:34:07 2019 -0500 : test fix", "src/twisted/trial/test/test_loader.py"]}, {"commit_id": "9f1e92e7eb045d8e5196e4e99ff43de0bd30161b", "commit_date": "Sun May 19 16:02:44 2019 -0500", "commit_message": "Merge branch 'trunk' into 9628-trial3-importerror", "files_name": ["5a5b399f527de32d8bcb2efa677cf394bebbc711 - Sun May 19 15:51:44 2019 -0500 : fix & tests", "src/twisted/newsfragments/9628.bugfix", "src/twisted/trial/runner.py", "src/twisted/trial/test/packages.py", "src/twisted/trial/test/test_loader.py"]}, {"commit_id": "dea4e9cfaee8a81fc8c5515d908eb5696f6473a8", "commit_date": "Sun May 19 11:53:20 2019 -0700", "commit_message": "Merge pull request #1142 from twisted/9476-merge-1141", "files_name": ["85490f2e69b1c0fc4f6d9dfe4488b59c14366f40 - Sun May 19 11:16:34 2019 -0700 : Rewrap docstrings", "src/twisted/test/test_application.py"]}, {"commit_id": "b8c9c5a0fa2d8d606ecc6e91785162635aa9ef25", "commit_date": "Sun May 19 16:39:18 2019 +0200", "commit_message": "Merge branch 'trunk' into 9476-fix-backoffPolicy-OverflowError", "files_name": ["2fe120af893bbfc68505a5c05b3377795bd4f70f - Sat May 18 00:00:18 2019 +0200 : fixes #9476 (backoffPolicy OverflowError on attempts higher 1750)", "src/twisted/application/internet.py", "src/twisted/newsfragments/9476.bugfix", "src/twisted/test/test_application.py"]}, {"commit_id": "c1e5dd3ddeb926ab5bd60e950ea56dee1eb5660f", "commit_date": "Sun May 19 01:44:20 2019 -0500", "commit_message": "Merge 9640-eclipseo-regenerate-raiser: Regenerate raiser.c", "files_name": ["8f467ead92157e01250d785bddc3d04d6a72d99c - Sun May 19 01:21:36 2019 -0500 : Update and rename 9640.bugfix to 9640.misc", "src/twisted/newsfragments/9640.bugfix", "src/twisted/newsfragments/9640.misc"]}, {"commit_id": "d9d201c8514709d93f26bc53a42c4198670a566f", "commit_date": "Fri May 17 17:29:32 2019 -0700", "commit_message": "Merge branch 'trunk' into 9640-eclipseo-regenerate-raiser", "files_name": ["c8d59d663964821af685c869627ac132d28ba0c5 - Fri May 17 09:47:01 2019 -0400 : Merge pull request #1106 from jswitzer/trunk", "4d7733cd0d63939c548a744f3d68a7cb5a95c2f8 - Thu May 16 11:24:15 2019 -0400 : Update newsfragment and fix None comparison", "src/twisted/newsfragments/9410.bugfix", "src/twisted/web/http.py"]}, {"commit_id": "8da113ade56c9d7c1eb440ce80efaadfc077bfca", "commit_date": "Tue May 14 17:13:52 2019 +0200", "commit_message": "Newsfragment", "files_name": ["src/twisted/newsfragments/9640.bugfix"]}, {"commit_id": "ad0ed4966e03ab05b4f61995c5e7c9143b0deb93", "commit_date": "Tue May 14 15:57:30 2019 +0200", "commit_message": "Regenerate raiser.c with Cython 3.0a0", "files_name": ["src/twisted/test/raiser.c"]}, {"commit_id": "582465d571bb20c361f8fcc3c2a25521fd4700fd", "commit_date": "Mon May 13 16:55:36 2019 -0400", "commit_message": "Merge branch 'trunk' into trunk", "files_name": ["2c42361c8fa866ea1ef02dd7233e821cab876f57 - Sun May 12 14:27:46 2019 -0700 : Merge pull request #1138 from twisted/9639-orddict-remov", "dd3f50a7cf11c0bebd39302a8992996d75846675 - Sun May 12 14:10:53 2019 -0500 : bump", "src/twisted/newsfragments/9639.removal"]}, {"commit_id": "10b402fcfa795d6a26739377c834618fdecae012", "commit_date": "Sun May 12 03:31:09 2019 -0500", "commit_message": "remove test", "files_name": ["src/twisted/test/test_compat.py"]}, {"commit_id": "a985e557d0c6257d734fb7b0375f2ec16a70fbc7", "commit_date": "Sun May 12 03:22:42 2019 -0500", "commit_message": "remove", "files_name": ["src/twisted/newsfragments/9639.removal", "src/twisted/python/compat.py"]}, {"commit_id": "5ed194c0514a04500b3190b0ecbad0cce8b9b82d", "commit_date": "Thu May 9 12:12:32 2019 -0400", "commit_message": "Adjust tests to TLSInitiatingInitializer being required by default", "files_name": ["src/twisted/words/test/test_jabberxmlstream.py"]}, {"commit_id": "cadf08f3481b689929ad471a17ce29683dc0635d", "commit_date": "Thu May 9 12:05:21 2019 -0400", "commit_message": "Provide a way to use custom certificate options for XMPP clients", "files_name": ["src/twisted/words/protocols/jabber/client.py", "src/twisted/words/protocols/jabber/xmlstream.py", "src/twisted/words/test/test_jabberclient.py"]}, {"commit_id": "fa18e8e65cf486ea9adc8e9a9a6df7e168098ce8", "commit_date": "Thu May 9 11:11:14 2019 -0400", "commit_message": "Clean up connecting authenticators", "files_name": ["src/twisted/words/protocols/jabber/client.py", "src/twisted/words/protocols/jabber/xmlstream.py", "src/twisted/words/test/test_jabberclient.py", "src/twisted/words/test/test_jabberxmlstream.py"]}, {"commit_id": "1a6c1775e4ad99e3b488086af06ad3e7473793d3", "commit_date": "Thu May 9 13:42:35 2019 +0200", "commit_message": "Merge branch 'trunk' into trunk", "files_name": ["d6235bdb43c4d5d603db9f415aa0321fe3ab544c - Wed May 8 16:57:48 2019 -0400 : Merge branch 'trunk' into 9622-cache-acceptableciphers", "5cfbc765c30fde310ca0140eb895ee2a0cbb724e - Wed May 8 16:16:08 2019 -0400 : Merge pull request #1136 from Hnasar/9637-addcomponent-return-value", "d1991363f291a80fb946ac934b2f36df41af1506 - Wed May 8 13:57:36 2019 -0400 : Merge branch 'trunk' into 9637-addcomponent-return-value", "4759e27af0ffa2e61538d5e0a66c3e57e20d3f5b - Wed May 8 13:19:17 2019 -0400 : Add docstrings for new contextFactory attribute", "src/twisted/words/protocols/jabber/xmlstream.py"]}, {"commit_id": "4d25b9767d75d46450baa775ab847c9fd452afc6", "commit_date": "Wed May 8 02:59:41 2019 -0400", "commit_message": "Merge branch 'trunk' into 9622-cache-acceptableciphers", "files_name": ["41c1592c55dcd9c78778c4c5b233f132982daba6 - Tue May 7 21:30:53 2019 -0700 : Merge branch 'trunk' into trunk", "046a9b3017d58b66b6f62239e734922f4edbc862 - Tue May 7 23:46:39 2019 -0400 : Merge 9636-morotti-selectpatch: Remove hack to detect broken pipe behavior on linux < 2.6.11", "3c7c1432d1b6422afd2b576be060ad3616d0f190 - Tue May 7 21:15:22 2019 -0400 : Merge branch 'trunk' into 9636-morotti-selectpatch", "aef6cf31d8933bba065de4497273ad016970f6a3 - Tue May 7 21:15:13 2019 -0400 : Fix lint", "src/twisted/internet/process.py"]}, {"commit_id": "8d75ba5bcbafdc9fd35d8400c526db2f5f14c62e", "commit_date": "Tue May 7 21:12:05 2019 -0400", "commit_message": "Merge 9454-msvs: Support Azure Pipelines", "files_name": ["89954dfb18e613be583c74e22a3dd55d66e7d975 - Tue May 7 18:23:49 2019 -0400 : Allow for custom contextFactory to TLS initializer", "src/twisted/words/protocols/jabber/xmlstream.py"]}], "windows_after": [{"commit_id": "f8db37bc30d6570b97f7c1ca6f5cb4eef63135b2", "commit_date": "Thu Jun 6 17:04:15 2019 -0700", "commit_message": "Merge branch 'trunk' into 9646-http-header-wsp-colon", "files_name": ["f035a94d920dc5ce2b81106631ed3dc0426fb8d0 - Sat Jun 8 12:30:59 2019 -0700 : Merge branch 'trunk' into 9006-coro-result-assertions", "90370911339fe1e8802064531fa566f54ac4951f - Sat Jun 8 13:20:33 2019 -0700 : Move news fragment to where it goes now", "src/twisted/newsfragments/9006.feature"]}, {"commit_id": "d54f66fa06c252d99b97beebdb7a1a3cf4c429bd", "commit_date": "Sat Jun 8 13:20:58 2019 -0700", "commit_message": "import some things so TiwstedChecker doesn't complain", "files_name": ["src/twisted/trial/test/_assertiontests.py.3only"]}, {"commit_id": "fe6b661d92ba080b879b7611d108306f5e14e4c0", "commit_date": "Sun Jun 9 20:29:58 2019 +1000", "commit_message": "Merge branch 'trunk' into 9628-trial3-importerror", "files_name": ["92fa828465c7de1b9c534de8ae021facf7552485 - Sun Jun 9 20:46:18 2019 +1000 : Merge branch 'trunk' into 9622-cache-acceptableciphers", "7ae2b10573e97324b11abd0190e52d66206e2606 - Wed Jun 12 13:08:50 2019 -0700 : Merge branch 'trunk' into 9644-multiline-headers", "fd73587f3d7c89211c8d3624f1c69c34add38024 - Wed Jun 12 21:26:15 2019 -0700 : Merge pull request #1150 from twisted/9644-multiline-headers", "ba8357c50ed71af4a3170fd70093e0105a0ab757 - Wed Jun 12 21:26:33 2019 -0700 : Merge branch 'trunk' into 9646-http-header-wsp-colon", "f255c5f1f885fcb16c0da52666d478c660398526 - Thu Jun 13 11:35:11 2019 -0400 : news fragment", "src/twisted/web/newsfragments/9655.feature"]}, {"commit_id": "69277b8191dc89445611be87dfbe4f3f64a50b66", "commit_date": "Thu Jun 13 11:35:39 2019 -0400", "commit_message": "Factor this assertion helper out into something reusable", "files_name": ["src/twisted/web/test/_util.py", "src/twisted/web/test/test_http.py"]}, {"commit_id": "e877fc04ac69c1eaf18e6761efa8a8d8473fca51", "commit_date": "Thu Jun 13 11:36:41 2019 -0400", "commit_message": "Teach server.Request.gotLength to call getContentFile", "files_name": ["src/twisted/web/server.py", "src/twisted/web/test/test_web.py"]}, {"commit_id": "a70450212c7c8dac37bef7e44dae2f8e263be406", "commit_date": "Thu Jun 13 11:36:53 2019 -0400", "commit_message": "Minor refactoring for cleanliness", "files_name": ["src/twisted/web/http.py"]}, {"commit_id": "0c6805d237f847cf6c8fd9cf0457d68562502b76", "commit_date": "Thu Jun 13 11:37:03 2019 -0400", "commit_message": "import cleanups", "files_name": ["src/twisted/web/test/test_http.py"]}, {"commit_id": "658e326c4b05d789a48c88f9d6624e68f541f638", "commit_date": "Thu Jun 13 14:43:51 2019 -0400", "commit_message": "classic class upcall", "files_name": ["src/twisted/web/server.py"]}, {"commit_id": "2fc69c437ab1ec230cf33477ca31e0e7be5d8fa4", "commit_date": "Thu Jun 13 15:38:32 2019 -0400", "commit_message": "an attempt to satisfy the linter", "files_name": ["src/twisted/web/http.py", "src/twisted/web/test/_util.py", "src/twisted/web/test/test_http.py", "src/twisted/web/test/test_web.py"]}, {"commit_id": "f6c533e52d2d06a268f1b9890d8a88c9a793178f", "commit_date": "Thu Jun 13 15:50:04 2019 -0400", "commit_message": "guessed wrong on that one", "files_name": ["src/twisted/web/test/test_http.py"]}, {"commit_id": "b88b6dd82bedef040687eb16f2f11120dec44c47", "commit_date": "Fri Jun 14 19:22:51 2019 +1000", "commit_message": "Merge remote-tracking branch 'origin/trunk' into 9622-cache-acceptableciphers", "files_name": ["08d3ff842ffb719deb092efa0312fd908acecc11 - Fri Jun 14 19:24:52 2019 +1000 : update docstrings", "src/twisted/internet/_sslverify.py", "src/twisted/internet/interfaces.py", "src/twisted/test/test_sslverify.py"]}, {"commit_id": "4bceaac10570db717ee34a7cf63a5220881ab728", "commit_date": "Sun Jun 16 07:02:09 2019 +1000", "commit_message": "Merge 9656-theyre-ugly-anyway: Disable traceback printing by default in Site and update twisted.web.tap to have an enable flag instead of a disable flag (#1156)", "files_name": ["src/twisted/newsfragments/9656.bugfix", "src/twisted/newsfragments/9656.feature", "src/twisted/newsfragments/9656.removal", "src/twisted/web/server.py", "src/twisted/web/tap.py", "src/twisted/web/test/test_tap.py", "src/twisted/web/test/test_web.py"]}, {"commit_id": "0114d8018e8278b4b7b35ca161c8e1bde36950d2", "commit_date": "Sun Jun 16 09:34:46 2019 +1000", "commit_message": "Make the transport properly carry over the timeout", "files_name": ["src/twisted/newsfragments/9653.bugfix", "src/twisted/protocols/policies.py", "src/twisted/web/http.py", "src/twisted/web/test/test_http.py"]}, {"commit_id": "1f6950b1016527f32f78930f321c2204cdefcf20", "commit_date": "Sun Jun 16 09:52:49 2019 +1000", "commit_message": "fix the test", "files_name": ["src/twisted/protocols/policies.py", "src/twisted/web/test/test_http.py"]}, {"commit_id": "289d596206920d7d56b4e54dcdea96bbd4b100b1", "commit_date": "Sun Jun 16 18:32:37 2019 +1000", "commit_message": "fixes", "files_name": ["src/twisted/web/test/test_http.py"]}, {"commit_id": "ea2d28f7035cdbc56063a0672acef426086875ff", "commit_date": "Sun Jun 16 18:41:49 2019 +0200", "commit_message": "Rename contextFactory to configurationForTLS, make private vars", "files_name": ["src/twisted/words/newsfragments/9561.feature", "src/twisted/words/protocols/jabber/client.py", "src/twisted/words/protocols/jabber/xmlstream.py", "src/twisted/words/test/test_jabberclient.py", "src/twisted/words/test/test_jabberxmlstream.py"]}, {"commit_id": "05556b6ca14a49e4c7f3b5e8ede83137b869926e", "commit_date": "Sun Jun 16 19:02:52 2019 +0200", "commit_message": "Move check for configurationTLS being None to __init__", "files_name": ["src/twisted/words/protocols/jabber/xmlstream.py"]}, {"commit_id": "7caf8ac8795492e346e8f52633ff6d343a07edde", "commit_date": "Sun Jun 16 19:11:35 2019 +0200", "commit_message": "Document configurationForTLS being None directly", "files_name": ["src/twisted/words/protocols/jabber/client.py", "src/twisted/words/protocols/jabber/xmlstream.py"]}, {"commit_id": "a66878c15abe99fdb3c72d7ec533ee0ef54e7f95", "commit_date": "Sun Jun 16 19:14:04 2019 +0200", "commit_message": "Mention CVE-2019-12855 in news fragment", "files_name": ["src/twisted/words/newsfragments/9561.bugfix"]}, {"commit_id": "abbf0fd52c13b1fb5e1429189a3fcc48565870a5", "commit_date": "Sun Jun 16 19:50:33 2019 +0200", "commit_message": "Revert \"Move check for configurationTLS being None to __init__\"", "files_name": ["src/twisted/words/protocols/jabber/xmlstream.py"]}, {"commit_id": "d99ce020e065218288c8319e8211bdbaa7f8f6bf", "commit_date": "Wed Jul 3 11:53:19 2019 +0200", "commit_message": "Merge branch 'trunk' into 9561-xmpp-tls-verify-cert", "files_name": ["cf8ed69824502cb39b3a077ec596fe01c03b93da - Thu Jul 4 14:57:44 2019 +0200 : Merge pull request #1147 from twisted/9561-xmpp-tls-verify-cert", "1bd0583de3f70ff778e404ef9ca68c0b8f80e5b4 - Fri Jul 5 23:50:02 2019 +0200 : replaced distutils by setuptools", "docs/core/howto/tap.rst"]}, {"commit_id": "58c37fde4afb48c11320a1194fbfa1772b9075f2", "commit_date": "Fri Jul 5 23:51:41 2019 +0200", "commit_message": "Merge branch 'trunk' into 9243-westfeld-add-deployment-docs-pip", "files_name": ["7d94ec0b7812c98cca63fdbe58e857ab976d1785 - Fri Jul 12 21:43:02 2019 -0700 : Merge branch 'trunk' into 9646-http-header-wsp-colon", "0935c925e37519c2039a3adea5260b5d6d5b608b - Fri Jul 12 21:44:00 2019 -0700 : Merge branch 'trunk' into 9655-twisted-web-tempfile-parameter", "0a6f84c421e6d670b163b964cd2939a6b51ff2cb - Fri Jul 12 21:46:13 2019 -0700 : Merge branch 'trunk' into 8267-circular-reporter", "b6955269d886279e9e1cd74cd230ab0835ba2847 - Sun Jul 21 01:10:48 2019 +1000 : Merge 9674-raiser-c: Regenerate twisted/test/raiser.c for Python 3.8.0b2", "src/twisted/newsfragments/9674.misc", "src/twisted/test/raiser.c"]}, {"commit_id": "c0ce0d77be9152a8a3645c5bddb6e2f9cc56d98f", "commit_date": "Sat Jul 20 11:52:28 2019 -0400", "commit_message": "Merge jeremycline:9668-jeremycline-stdlog-findCaller-38-compat: Add the stackLevel kwarg to STDLibLogObserver._findCaller", "files_name": ["src/twisted/logger/_stdlib.py", "src/twisted/newsfragments/9668.bugfix"]}, {"commit_id": "4cade8bb1e5ce45a86962fe2548470a413c8ce7a", "commit_date": "Sat Jul 20 12:06:10 2019 -0500", "commit_message": "Merge eevelweezel:move-proto_helpers-6435: Move t.test.proto_helpers to t.internet.testing", "files_name": ["src/twisted/internet/test/_awaittests.py.3only", "src/twisted/internet/test/_yieldfromtests.py.3only", "src/twisted/internet/test/test_endpoints.py", "src/twisted/internet/test/test_testing.py", "src/twisted/internet/testing.py", "src/twisted/newsfragments/6435.removal", "src/twisted/test/__init__.py", "src/twisted/test/proto_helpers.py"]}, {"commit_id": "892e9828ddcbbb970e859bf07c7c24f8662893db", "commit_date": "Sun Jul 21 03:10:06 2019 +1000", "commit_message": "Merge branch 'trunk' into 9646-http-header-wsp-colon", "files_name": ["5b203b267f9869f2bd6e3ed17dcdaafa1fa227d3 - Sat Jul 20 10:32:32 2019 -0700 : Merge ryban:8258-ryban-hmac-sha2-512-fix: Fix SSH not generating correct keys when using hmac-sha2-512 with SHA1 based KEX algorithms", "src/twisted/conch/ssh/transport.py", "src/twisted/conch/test/test_transport.py", "src/twisted/newsfragments/8258.bugfix"]}, {"commit_id": "511d0d98d7cc706f7be3b218cdceb149b42b9a3d", "commit_date": "Sun Jul 21 03:34:45 2019 +1000", "commit_message": "Merge branch 'trunk' into 9646-http-header-wsp-colon", "files_name": ["82379a65015e97853bc38566e7ba0c148d3e6dd4 - Sun Jul 21 05:03:44 2019 +1000 : Merge branch 'trunk' into 9655-twisted-web-tempfile-parameter", "e0b696f17260fc17cd5a9b3e7bc3ad1bc0ffdd54 - Sun Jul 21 05:21:29 2019 +1000 : Merge branch 'trunk' into 9628-trial3-importerror", "ab6156fa761832b6711b2484665cabd07906f491 - Sat Jul 20 13:43:42 2019 -0700 : Merge pull request #1143 from twisted/9628-trial3-importerror", "de4e26d43ac5571d405ea742f68bad0a1ebc6a1b - Sat Jul 20 22:57:55 2019 -0700 : Merge branch 'trunk' into 9646-http-header-wsp-colon", "6e8cb44fb0c1637be099bdd5c19059ddbe034c03 - Mon Jul 22 00:21:55 2019 +1000 : incremental to 19.7.0", "src/twisted/_version.py", "src/twisted/test/__init__.py", "src/twisted/web/test/test_tap.py"]}, {"commit_id": "17084eab78b12a59b42e3a3c460faf0fdb080f10", "commit_date": "Mon Jul 22 00:23:39 2019 +1000", "commit_message": "towncrier for 19.7.0rc1", "files_name": ["NEWS.rst", "src/twisted/conch/newsfragments/2782.bugfix", "src/twisted/conch/newsfragments/9610.misc", "src/twisted/names/newsfragments/9620.bugfix", "src/twisted/newsfragments/6032.bugfix", "src/twisted/newsfragments/6435.removal", "src/twisted/newsfragments/8258.bugfix", "src/twisted/newsfragments/9217.misc", "src/twisted/newsfragments/9410.bugfix", "src/twisted/newsfragments/9445.misc", "src/twisted/newsfragments/9446.bugfix", "src/twisted/newsfragments/9454.misc", "src/twisted/newsfragments/9476.bugfix", "src/twisted/newsfragments/9577.feature", "src/twisted/newsfragments/9592.feature", "src/twisted/newsfragments/9602.removal", "src/twisted/newsfragments/9603.removal", "src/twisted/newsfragments/9604.removal", "src/twisted/newsfragments/9605.misc", "src/twisted/newsfragments/9607.feature", "src/twisted/newsfragments/9613.removal", "src/twisted/newsfragments/9614.misc", "src/twisted/newsfragments/9615.misc", "src/twisted/newsfragments/9617.feature", "src/twisted/newsfragments/9619.misc", "src/twisted/newsfragments/9625.misc", "src/twisted/newsfragments/9628.bugfix", "src/twisted/newsfragments/9632.feature", "src/twisted/newsfragments/9633.misc", "src/twisted/newsfragments/9636.bugfix", "src/twisted/newsfragments/9637.doc", "src/twisted/newsfragments/9639.removal", "src/twisted/newsfragments/9640.misc", "src/twisted/newsfragments/9643.bugfix", "src/twisted/newsfragments/9648.feature", "src/twisted/newsfragments/9656.bugfix", "src/twisted/newsfragments/9656.feature", "src/twisted/newsfragments/9656.removal", "src/twisted/newsfragments/9668.bugfix", "src/twisted/newsfragments/9674.misc", "src/twisted/web/newsfragments/5533.doc", "src/twisted/web/newsfragments/9091.doc", "src/twisted/web/newsfragments/9135.removal", "src/twisted/web/newsfragments/9458.doc", "src/twisted/web/newsfragments/9593.doc", "src/twisted/web/newsfragments/9597.misc", "src/twisted/web/newsfragments/9644.bugfix", "src/twisted/web/newsfragments/9647.bugfix", "src/twisted/words/newsfragments/9561.bugfix", "src/twisted/words/newsfragments/9561.feature"]}, {"commit_id": "6e3c05cf008d89a6313a2b1a1be54bcaabf80ba1", "commit_date": "Sun Jul 21 13:17:18 2019 -0700", "commit_message": "Merge branch 'trunk' into 8267-circular-reporter", "files_name": ["fc70c0cf811ff5f437e5d946ecc87cc14a3266bf - Sun Jul 21 18:47:15 2019 -0700 : Merge branch 'trunk' into 9655-twisted-web-tempfile-parameter", "a4c171b461533f04fa7c041746e9a708604254e5 - Sun Jul 21 19:05:39 2019 -0700 : Merge pull request #1148 from cjwatson/8267-circular-reporter", "f165299c508aee4b5c44562ea801d8183b51974a - Mon Jul 22 11:36:13 2019 -0700 : Merge branch 'trunk' into 9006-coro-result-assertions", "c2fbd43161582895a50fde670e47acda299231ed - Mon Jul 22 11:54:59 2019 -0700 : Merge pull request #691 from twisted/9006-coro-result-assertions", "e79b08e11cdfa91649a410a649332e641b648965 - Mon Jul 22 15:55:03 2019 -0400 : Merge pull request #1155 from twisted/9655-twisted-web-tempfile-parameter", "e1733139f2b391c67f8f52cd0443698b4d665de3 - Tue Jul 23 07:55:12 2019 -0400 : Removed a dead conditional"]}], "parents": [{"commit_id_before": "d0bcf0ba9573a010d199bb3e0b1f5f22a3c72bb0", "url_before": "https://api.github.com/repos/twisted/twisted/commits/d0bcf0ba9573a010d199bb3e0b1f5f22a3c72bb0", "html_url_before": "https://github.com/twisted/twisted/commit/d0bcf0ba9573a010d199bb3e0b1f5f22a3c72bb0"}], "details": [{"raw_url": "https://github.com/twisted/twisted/raw/6c61fc4503ae39ab8ecee52d10f10ee2c371d7e2/src%2Ftwisted%2Fweb%2F_newclient.py", "code": "# -*- test-case-name: twisted.web.test.test_newclient -*-\n# Copyright (c) Twisted Matrix Laboratories.\n# See LICENSE for details.\n\n\"\"\"\nAn U{HTTP 1.1<http://www.w3.org/Protocols/rfc2616/rfc2616.html>} client.\n\nThe way to use the functionality provided by this module is to:\n\n  - Connect a L{HTTP11ClientProtocol} to an HTTP server\n  - Create a L{Request} with the appropriate data\n  - Pass the request to L{HTTP11ClientProtocol.request}\n  - The returned Deferred will fire with a L{Response} object\n  - Create a L{IProtocol} provider which can handle the response body\n  - Connect it to the response with L{Response.deliverBody}\n  - When the protocol's C{connectionLost} method is called, the response is\n    complete.  See L{Response.deliverBody} for details.\n\nVarious other classes in this module support this usage:\n\n  - HTTPParser is the basic HTTP parser.  It can handle the parts of HTTP which\n    are symmetric between requests and responses.\n\n  - HTTPClientParser extends HTTPParser to handle response-specific parts of\n    HTTP.  One instance is created for each request to parse the corresponding\n    response.\n\"\"\"\n\nfrom __future__ import division, absolute_import\n__metaclass__ = type\n\nimport re\n\nfrom zope.interface import implementer\n\nfrom twisted.python.compat import networkString\nfrom twisted.python.components import proxyForInterface\nfrom twisted.python.reflect import fullyQualifiedName\nfrom twisted.python.failure import Failure\nfrom twisted.internet.interfaces import IConsumer, IPushProducer\nfrom twisted.internet.error import ConnectionDone\nfrom twisted.internet.defer import Deferred, succeed, fail, maybeDeferred\nfrom twisted.internet.defer import CancelledError\nfrom twisted.internet.protocol import Protocol\nfrom twisted.protocols.basic import LineReceiver\nfrom twisted.web.iweb import UNKNOWN_LENGTH, IResponse, IClientRequest\nfrom twisted.web.http_headers import Headers\nfrom twisted.web.http import NO_CONTENT, NOT_MODIFIED\nfrom twisted.web.http import _DataLoss, PotentialDataLoss\nfrom twisted.web.http import _IdentityTransferDecoder, _ChunkedTransferDecoder\nfrom twisted.logger import Logger\n\n# States HTTPParser can be in\nSTATUS = u'STATUS'\nHEADER = u'HEADER'\nBODY = u'BODY'\nDONE = u'DONE'\n_moduleLog = Logger()\n\n\nclass BadHeaders(Exception):\n    \"\"\"\n    Headers passed to L{Request} were in some way invalid.\n    \"\"\"\n\n\n\nclass ExcessWrite(Exception):\n    \"\"\"\n    The body L{IBodyProducer} for a request tried to write data after\n    indicating it had finished writing data.\n    \"\"\"\n\n\nclass ParseError(Exception):\n    \"\"\"\n    Some received data could not be parsed.\n\n    @ivar data: The string which could not be parsed.\n    \"\"\"\n    def __init__(self, reason, data):\n        Exception.__init__(self, reason, data)\n        self.data = data\n\n\n\nclass BadResponseVersion(ParseError):\n    \"\"\"\n    The version string in a status line was unparsable.\n    \"\"\"\n\n\n\nclass _WrapperException(Exception):\n    \"\"\"\n    L{_WrapperException} is the base exception type for exceptions which\n    include one or more other exceptions as the low-level causes.\n\n    @ivar reasons: A L{list} of one or more L{Failure} instances encountered\n        during an HTTP request.  See subclass documentation for more details.\n    \"\"\"\n    def __init__(self, reasons):\n        Exception.__init__(self, reasons)\n        self.reasons = reasons\n\n\n\nclass RequestGenerationFailed(_WrapperException):\n    \"\"\"\n    There was an error while creating the bytes which make up a request.\n\n    @ivar reasons: A C{list} of one or more L{Failure} instances giving the\n        reasons the request generation was considered to have failed.\n    \"\"\"\n\n\n\nclass RequestTransmissionFailed(_WrapperException):\n    \"\"\"\n    There was an error while sending the bytes which make up a request.\n\n    @ivar reasons: A C{list} of one or more L{Failure} instances giving the\n        reasons the request transmission was considered to have failed.\n    \"\"\"\n\n\n\nclass ConnectionAborted(Exception):\n    \"\"\"\n    The connection was explicitly aborted by application code.\n    \"\"\"\n\n\n\nclass WrongBodyLength(Exception):\n    \"\"\"\n    An L{IBodyProducer} declared the number of bytes it was going to\n    produce (via its C{length} attribute) and then produced a different number\n    of bytes.\n    \"\"\"\n\n\n\nclass ResponseDone(Exception):\n    \"\"\"\n    L{ResponseDone} may be passed to L{IProtocol.connectionLost} on the\n    protocol passed to L{Response.deliverBody} and indicates that the entire\n    response has been delivered.\n    \"\"\"\n\n\n\nclass ResponseFailed(_WrapperException):\n    \"\"\"\n    L{ResponseFailed} indicates that all of the response to a request was not\n    received for some reason.\n\n    @ivar reasons: A C{list} of one or more L{Failure} instances giving the\n        reasons the response was considered to have failed.\n\n    @ivar response: If specified, the L{Response} received from the server (and\n        in particular the status code and the headers).\n    \"\"\"\n\n    def __init__(self, reasons, response=None):\n        _WrapperException.__init__(self, reasons)\n        self.response = response\n\n\n\nclass ResponseNeverReceived(ResponseFailed):\n    \"\"\"\n    A L{ResponseFailed} that knows no response bytes at all have been received.\n    \"\"\"\n\n\n\nclass RequestNotSent(Exception):\n    \"\"\"\n    L{RequestNotSent} indicates that an attempt was made to issue a request but\n    for reasons unrelated to the details of the request itself, the request\n    could not be sent.  For example, this may indicate that an attempt was made\n    to send a request using a protocol which is no longer connected to a\n    server.\n    \"\"\"\n\n\n\ndef _callAppFunction(function):\n    \"\"\"\n    Call C{function}.  If it raises an exception, log it with a minimal\n    description of the source.\n\n    @return: L{None}\n    \"\"\"\n    try:\n        function()\n    except:\n        _moduleLog.failure(\n            u\"Unexpected exception from {name}\",\n            name=fullyQualifiedName(function)\n        )\n\n\n\nclass HTTPParser(LineReceiver):\n    \"\"\"\n    L{HTTPParser} handles the parsing side of HTTP processing. With a suitable\n    subclass, it can parse either the client side or the server side of the\n    connection.\n\n    @ivar headers: All of the non-connection control message headers yet\n        received.\n\n    @ivar state: State indicator for the response parsing state machine.  One\n        of C{STATUS}, C{HEADER}, C{BODY}, C{DONE}.\n\n    @ivar _partialHeader: L{None} or a C{list} of the lines of a multiline\n        header while that header is being received.\n    \"\"\"\n\n    # NOTE: According to HTTP spec, we're supposed to eat the\n    # 'Proxy-Authenticate' and 'Proxy-Authorization' headers also, but that\n    # doesn't sound like a good idea to me, because it makes it impossible to\n    # have a non-authenticating transparent proxy in front of an authenticating\n    # proxy. An authenticating proxy can eat them itself. -jknight\n    #\n    # Further, quoting\n    # http://homepages.tesco.net/J.deBoynePollard/FGA/web-proxy-connection-header.html\n    # regarding the 'Proxy-Connection' header:\n    #\n    #    The Proxy-Connection: header is a mistake in how some web browsers\n    #    use HTTP. Its name is the result of a false analogy. It is not a\n    #    standard part of the protocol. There is a different standard\n    #    protocol mechanism for doing what it does. And its existence\n    #    imposes a requirement upon HTTP servers such that no proxy HTTP\n    #    server can be standards-conforming in practice.\n    #\n    # -exarkun\n\n    # Some servers (like http://news.ycombinator.com/) return status lines and\n    # HTTP headers delimited by \\n instead of \\r\\n.\n    delimiter = b'\\n'\n\n    CONNECTION_CONTROL_HEADERS = set([\n            b'content-length', b'connection', b'keep-alive', b'te',\n            b'trailers', b'transfer-encoding', b'upgrade',\n            b'proxy-connection'])\n\n    def connectionMade(self):\n        self.headers = Headers()\n        self.connHeaders = Headers()\n        self.state = STATUS\n        self._partialHeader = None\n\n\n    def switchToBodyMode(self, decoder):\n        \"\"\"\n        Switch to body parsing mode - interpret any more bytes delivered as\n        part of the message body and deliver them to the given decoder.\n        \"\"\"\n        if self.state == BODY:\n            raise RuntimeError(u\"already in body mode\")\n\n        self.bodyDecoder = decoder\n        self.state = BODY\n        self.setRawMode()\n\n\n    def lineReceived(self, line):\n        \"\"\"\n        Handle one line from a response.\n        \"\"\"\n        # Handle the normal CR LF case.\n        if line[-1:] == b'\\r':\n            line = line[:-1]\n\n        if self.state == STATUS:\n            self.statusReceived(line)\n            self.state = HEADER\n        elif self.state == HEADER:\n            if not line or line[0] not in b' \\t':\n                if self._partialHeader is not None:\n                    header = b''.join(self._partialHeader)\n                    name, value = header.split(b':', 1)\n                    value = value.strip()\n                    self.headerReceived(name, value)\n                if not line:\n                    # Empty line means the header section is over.\n                    self.allHeadersReceived()\n                else:\n                    # Line not beginning with LWS is another header.\n                    self._partialHeader = [line]\n            else:\n                # A line beginning with LWS is a continuation of a header\n                # begun on a previous line.\n                self._partialHeader.append(line)\n\n\n    def rawDataReceived(self, data):\n        \"\"\"\n        Pass data from the message body to the body decoder object.\n        \"\"\"\n        self.bodyDecoder.dataReceived(data)\n\n\n    def isConnectionControlHeader(self, name):\n        \"\"\"\n        Return C{True} if the given lower-cased name is the name of a\n        connection control header (rather than an entity header).\n\n        According to RFC 2616, section 14.10, the tokens in the Connection\n        header are probably relevant here.  However, I am not sure what the\n        practical consequences of either implementing or ignoring that are.\n        So I leave it unimplemented for the time being.\n        \"\"\"\n        return name in self.CONNECTION_CONTROL_HEADERS\n\n\n    def statusReceived(self, status):\n        \"\"\"\n        Callback invoked whenever the first line of a new message is received.\n        Override this.\n\n        @param status: The first line of an HTTP request or response message\n            without trailing I{CR LF}.\n        @type status: C{bytes}\n        \"\"\"\n\n\n    def headerReceived(self, name, value):\n        \"\"\"\n        Store the given header in C{self.headers}.\n        \"\"\"\n        name = name.lower()\n        if self.isConnectionControlHeader(name):\n            headers = self.connHeaders\n        else:\n            headers = self.headers\n        headers.addRawHeader(name, value)\n\n\n    def allHeadersReceived(self):\n        \"\"\"\n        Callback invoked after the last header is passed to C{headerReceived}.\n        Override this to change to the C{BODY} or C{DONE} state.\n        \"\"\"\n        self.switchToBodyMode(None)\n\n\n\nclass HTTPClientParser(HTTPParser):\n    \"\"\"\n    An HTTP parser which only handles HTTP responses.\n\n    @ivar request: The request with which the expected response is associated.\n    @type request: L{Request}\n\n    @ivar NO_BODY_CODES: A C{set} of response codes which B{MUST NOT} have a\n        body.\n\n    @ivar finisher: A callable to invoke when this response is fully parsed.\n\n    @ivar _responseDeferred: A L{Deferred} which will be called back with the\n        response when all headers in the response have been received.\n        Thereafter, L{None}.\n\n    @ivar _everReceivedData: C{True} if any bytes have been received.\n    \"\"\"\n    NO_BODY_CODES = set([NO_CONTENT, NOT_MODIFIED])\n\n    _transferDecoders = {\n        b'chunked': _ChunkedTransferDecoder,\n        }\n\n    bodyDecoder = None\n    _log = Logger()\n\n    def __init__(self, request, finisher):\n        self.request = request\n        self.finisher = finisher\n        self._responseDeferred = Deferred()\n        self._everReceivedData = False\n\n\n    def dataReceived(self, data):\n        \"\"\"\n        Override so that we know if any response has been received.\n        \"\"\"\n        self._everReceivedData = True\n        HTTPParser.dataReceived(self, data)\n\n\n    def parseVersion(self, strversion):\n        \"\"\"\n        Parse version strings of the form Protocol '/' Major '.' Minor. E.g.\n        b'HTTP/1.1'.  Returns (protocol, major, minor).  Will raise ValueError\n        on bad syntax.\n        \"\"\"\n        try:\n            proto, strnumber = strversion.split(b'/')\n            major, minor = strnumber.split(b'.')\n            major, minor = int(major), int(minor)\n        except ValueError as e:\n            raise BadResponseVersion(str(e), strversion)\n        if major < 0 or minor < 0:\n            raise BadResponseVersion(u\"version may not be negative\",\n                strversion)\n        return (proto, major, minor)\n\n\n    def statusReceived(self, status):\n        \"\"\"\n        Parse the status line into its components and create a response object\n        to keep track of this response's state.\n        \"\"\"\n        parts = status.split(b' ', 2)\n        if len(parts) == 2:\n            # Some broken servers omit the required `phrase` portion of\n            # `status-line`.  One such server identified as\n            # \"cloudflare-nginx\".  Others fail to identify themselves\n            # entirely.  Fill in an empty phrase for such cases.\n            version, codeBytes = parts\n            phrase = b\"\"\n        elif len(parts) == 3:\n            version, codeBytes, phrase = parts\n        else:\n            raise ParseError(u\"wrong number of parts\", status)\n\n        try:\n            statusCode = int(codeBytes)\n        except ValueError:\n            raise ParseError(u\"non-integer status code\", status)\n\n        self.response = Response._construct(\n            self.parseVersion(version),\n            statusCode,\n            phrase,\n            self.headers,\n            self.transport,\n            self.request,\n        )\n\n\n    def _finished(self, rest):\n        \"\"\"\n        Called to indicate that an entire response has been received.  No more\n        bytes will be interpreted by this L{HTTPClientParser}.  Extra bytes are\n        passed up and the state of this L{HTTPClientParser} is set to I{DONE}.\n\n        @param rest: A C{bytes} giving any extra bytes delivered to this\n            L{HTTPClientParser} which are not part of the response being\n            parsed.\n        \"\"\"\n        self.state = DONE\n        self.finisher(rest)\n\n\n    def isConnectionControlHeader(self, name):\n        \"\"\"\n        Content-Length in the response to a HEAD request is an entity header,\n        not a connection control header.\n        \"\"\"\n        if self.request.method == b'HEAD' and name == b'content-length':\n            return False\n        return HTTPParser.isConnectionControlHeader(self, name)\n\n\n    def allHeadersReceived(self):\n        \"\"\"\n        Figure out how long the response body is going to be by examining\n        headers and stuff.\n        \"\"\"\n        if 100 <= self.response.code < 200:\n            # RFC 7231 Section 6.2 says that if we receive a 1XX status code\n            # and aren't expecting it, we MAY ignore it. That's what we're\n            # going to do. We reset the parser here, but we leave\n            # _everReceivedData in its True state because we have, in fact,\n            # received data.\n            self._log.info(\n                \"Ignoring unexpected {code} response\",\n                code=self.response.code\n            )\n            self.connectionMade()\n            del self.response\n            return\n\n        if (self.response.code in self.NO_BODY_CODES\n            or self.request.method == b'HEAD'):\n            self.response.length = 0\n            # The order of the next two lines might be of interest when adding\n            # support for pipelining.\n            self._finished(self.clearLineBuffer())\n            self.response._bodyDataFinished()\n        else:\n            transferEncodingHeaders = self.connHeaders.getRawHeaders(\n                b'transfer-encoding')\n            if transferEncodingHeaders:\n\n                # This could be a KeyError.  However, that would mean we do not\n                # know how to decode the response body, so failing the request\n                # is as good a behavior as any.  Perhaps someday we will want\n                # to normalize/document/test this specifically, but failing\n                # seems fine to me for now.\n                transferDecoder = self._transferDecoders[transferEncodingHeaders[0].lower()]\n\n                # If anyone ever invents a transfer encoding other than\n                # chunked (yea right), and that transfer encoding can predict\n                # the length of the response body, it might be sensible to\n                # allow the transfer decoder to set the response object's\n                # length attribute.\n            else:\n                contentLengthHeaders = self.connHeaders.getRawHeaders(\n                    b'content-length')\n                if contentLengthHeaders is None:\n                    contentLength = None\n                elif len(contentLengthHeaders) == 1:\n                    contentLength = int(contentLengthHeaders[0])\n                    self.response.length = contentLength\n                else:\n                    # \"HTTP Message Splitting\" or \"HTTP Response Smuggling\"\n                    # potentially happening.  Or it's just a buggy server.\n                    raise ValueError(u\"Too many Content-Length headers; \"\n                                     u\"response is invalid\")\n\n                if contentLength == 0:\n                    self._finished(self.clearLineBuffer())\n                    transferDecoder = None\n                else:\n                    transferDecoder = lambda x, y: _IdentityTransferDecoder(\n                        contentLength, x, y)\n\n            if transferDecoder is None:\n                self.response._bodyDataFinished()\n            else:\n                # Make sure as little data as possible from the response body\n                # gets delivered to the response object until the response\n                # object actually indicates it is ready to handle bytes\n                # (probably because an application gave it a way to interpret\n                # them).\n                self.transport.pauseProducing()\n                self.switchToBodyMode(transferDecoder(\n                        self.response._bodyDataReceived,\n                        self._finished))\n\n        # This must be last.  If it were first, then application code might\n        # change some state (for example, registering a protocol to receive the\n        # response body).  Then the pauseProducing above would be wrong since\n        # the response is ready for bytes and nothing else would ever resume\n        # the transport.\n        self._responseDeferred.callback(self.response)\n        del self._responseDeferred\n\n\n    def connectionLost(self, reason):\n        if self.bodyDecoder is not None:\n            try:\n                try:\n                    self.bodyDecoder.noMoreData()\n                except PotentialDataLoss:\n                    self.response._bodyDataFinished(Failure())\n                except _DataLoss:\n                    self.response._bodyDataFinished(\n                        Failure(ResponseFailed([reason, Failure()],\n                                               self.response)))\n                else:\n                    self.response._bodyDataFinished()\n            except:\n                # Handle exceptions from both the except suites and the else\n                # suite.  Those functions really shouldn't raise exceptions,\n                # but maybe there's some buggy application code somewhere\n                # making things difficult.\n                self._log.failure('')\n        elif self.state != DONE:\n            if self._everReceivedData:\n                exceptionClass = ResponseFailed\n            else:\n                exceptionClass = ResponseNeverReceived\n            self._responseDeferred.errback(Failure(exceptionClass([reason])))\n            del self._responseDeferred\n\n\n\n_VALID_METHOD = re.compile(\n    br\"\\A[%s]+\\Z\" % (\n        bytes().join(\n            (\n                b\"!\", b\"#\", b\"$\", b\"%\", b\"&\", b\"'\", b\"*\",\n                b\"+\", b\"-\", b\".\", b\"^\", b\"_\", b\"`\", b\"|\", b\"~\",\n                b\"\\x30-\\x39\",\n                b\"\\x41-\\x5a\",\n                b\"\\x61-\\x7A\",\n            ),\n        ),\n    ),\n)\n\n\n\ndef _ensureValidMethod(method):\n    \"\"\"\n    An HTTP method is an HTTP token, which consists of any visible\n    ASCII character that is not a delimiter (i.e. one of\n    C{\"(),/:;<=>?@[\\\\]{}}.)\n\n    @param method: the method to check\n    @type method: L{bytes}\n\n    @return: the method if it is valid\n    @rtype: L{bytes}\n\n    @raise ValueError: if the method is not valid\n\n    @see: U{https://tools.ietf.org/html/rfc7230#section-3.1.1},\n        U{https://tools.ietf.org/html/rfc7230#section-3.2.6},\n        U{https://tools.ietf.org/html/rfc5234#appendix-B.1}\n    \"\"\"\n    if _VALID_METHOD.match(method):\n        return method\n    raise ValueError(\"Invalid method {!r}\".format(method))\n\n\n\n_VALID_URI = re.compile(br'\\A[\\x21-\\x7e]+\\Z')\n\n\n\ndef _ensureValidURI(uri):\n    \"\"\"\n    A valid URI cannot contain control characters (i.e., characters\n    between 0-32, inclusive and 127) or non-ASCII characters (i.e.,\n    characters with values between 128-255, inclusive).\n\n    @param uri: the URI to check\n    @type uri: L{bytes}\n\n    @return: the URI if it is valid\n    @rtype: L{bytes}\n\n    @raise ValueError: if the URI is not valid\n\n    @see: U{https://tools.ietf.org/html/rfc3986#section-3.3},\n        U{https://tools.ietf.org/html/rfc3986#appendix-A},\n        U{https://tools.ietf.org/html/rfc5234#appendix-B.1}\n    \"\"\"\n    if _VALID_URI.match(uri):\n        return uri\n    raise ValueError(\"Invalid URI {!r}\".format(uri))\n\n\n\n@implementer(IClientRequest)\nclass Request:\n    \"\"\"\n    A L{Request} instance describes an HTTP request to be sent to an HTTP\n    server.\n\n    @ivar method: See L{__init__}.\n    @ivar uri: See L{__init__}.\n    @ivar headers: See L{__init__}.\n    @ivar bodyProducer: See L{__init__}.\n    @ivar persistent: See L{__init__}.\n\n    @ivar _parsedURI: Parsed I{URI} for the request, or L{None}.\n    @type _parsedURI: L{twisted.web.client.URI} or L{None}\n    \"\"\"\n    _log = Logger()\n\n    def __init__(self, method, uri, headers, bodyProducer, persistent=False):\n        \"\"\"\n        @param method: The HTTP method for this request, ex: b'GET', b'HEAD',\n            b'POST', etc.\n        @type method: L{bytes}\n\n        @param uri: The relative URI of the resource to request.  For example,\n            C{b'/foo/bar?baz=quux'}.\n        @type uri: L{bytes}\n\n        @param headers: Headers to be sent to the server.  It is important to\n            note that this object does not create any implicit headers.  So it\n            is up to the HTTP Client to add required headers such as 'Host'.\n        @type headers: L{twisted.web.http_headers.Headers}\n\n        @param bodyProducer: L{None} or an L{IBodyProducer} provider which\n            produces the content body to send to the remote HTTP server.\n\n        @param persistent: Set to C{True} when you use HTTP persistent\n            connection, defaults to C{False}.\n        @type persistent: L{bool}\n        \"\"\"\n        self.method = _ensureValidMethod(method)\n        self.uri = _ensureValidURI(uri)\n        self.headers = headers\n        self.bodyProducer = bodyProducer\n        self.persistent = persistent\n        self._parsedURI = None\n\n\n    @classmethod\n    def _construct(cls, method, uri, headers, bodyProducer, persistent=False,\n                   parsedURI=None):\n        \"\"\"\n        Private constructor.\n\n        @param method: See L{__init__}.\n        @param uri: See L{__init__}.\n        @param headers: See L{__init__}.\n        @param bodyProducer: See L{__init__}.\n        @param persistent: See L{__init__}.\n        @param parsedURI: See L{Request._parsedURI}.\n\n        @return: L{Request} instance.\n        \"\"\"\n        request = cls(method, uri, headers, bodyProducer, persistent)\n        request._parsedURI = parsedURI\n        return request\n\n\n    @property\n    def absoluteURI(self):\n        \"\"\"\n        The absolute URI of the request as C{bytes}, or L{None} if the\n        absolute URI cannot be determined.\n        \"\"\"\n        return getattr(self._parsedURI, 'toBytes', lambda: None)()\n\n\n    def _writeHeaders(self, transport, TEorCL):\n        hosts = self.headers.getRawHeaders(b'host', ())\n        if len(hosts) != 1:\n            raise BadHeaders(u\"Exactly one Host header required\")\n\n        # In the future, having the protocol version be a parameter to this\n        # method would probably be good.  It would be nice if this method\n        # weren't limited to issuing HTTP/1.1 requests.\n        requestLines = []\n        requestLines.append(\n            b' '.join(\n                [\n                    _ensureValidMethod(self.method),\n                    _ensureValidURI(self.uri),\n                    b'HTTP/1.1\\r\\n',\n                ]\n            ),\n        )\n        if not self.persistent:\n            requestLines.append(b'Connection: close\\r\\n')\n        if TEorCL is not None:\n            requestLines.append(TEorCL)\n        for name, values in self.headers.getAllRawHeaders():\n            requestLines.extend([name + b': ' + v + b'\\r\\n' for v in values])\n        requestLines.append(b'\\r\\n')\n        transport.writeSequence(requestLines)\n\n\n    def _writeToBodyProducerChunked(self, transport):\n        \"\"\"\n        Write this request to the given transport using chunked\n        transfer-encoding to frame the body.\n\n        @param transport: See L{writeTo}.\n        @return: See L{writeTo}.\n        \"\"\"\n        self._writeHeaders(transport, b'Transfer-Encoding: chunked\\r\\n')\n        encoder = ChunkedEncoder(transport)\n        encoder.registerProducer(self.bodyProducer, True)\n        d = self.bodyProducer.startProducing(encoder)\n\n        def cbProduced(ignored):\n            encoder.unregisterProducer()\n        def ebProduced(err):\n            encoder._allowNoMoreWrites()\n            # Don't call the encoder's unregisterProducer because it will write\n            # a zero-length chunk.  This would indicate to the server that the\n            # request body is complete.  There was an error, though, so we\n            # don't want to do that.\n            transport.unregisterProducer()\n            return err\n        d.addCallbacks(cbProduced, ebProduced)\n        return d\n\n\n    def _writeToBodyProducerContentLength(self, transport):\n        \"\"\"\n        Write this request to the given transport using content-length to frame\n        the body.\n\n        @param transport: See L{writeTo}.\n        @return: See L{writeTo}.\n        \"\"\"\n        self._writeHeaders(\n            transport,\n            networkString(\n                'Content-Length: %d\\r\\n' % (self.bodyProducer.length,)))\n\n        # This Deferred is used to signal an error in the data written to the\n        # encoder below.  It can only errback and it will only do so before too\n        # many bytes have been written to the encoder and before the producer\n        # Deferred fires.\n        finishedConsuming = Deferred()\n\n        # This makes sure the producer writes the correct number of bytes for\n        # the request body.\n        encoder = LengthEnforcingConsumer(\n            self.bodyProducer, transport, finishedConsuming)\n\n        transport.registerProducer(self.bodyProducer, True)\n\n        finishedProducing = self.bodyProducer.startProducing(encoder)\n\n        def combine(consuming, producing):\n            # This Deferred is returned and will be fired when the first of\n            # consuming or producing fires. If it's cancelled, forward that\n            # cancellation to the producer.\n            def cancelConsuming(ign):\n                finishedProducing.cancel()\n            ultimate = Deferred(cancelConsuming)\n\n            # Keep track of what has happened so far.  This initially\n            # contains None, then an integer uniquely identifying what\n            # sequence of events happened.  See the callbacks and errbacks\n            # defined below for the meaning of each value.\n            state = [None]\n\n            def ebConsuming(err):\n                if state == [None]:\n                    # The consuming Deferred failed first.  This means the\n                    # overall writeTo Deferred is going to errback now.  The\n                    # producing Deferred should not fire later (because the\n                    # consumer should have called stopProducing on the\n                    # producer), but if it does, a callback will be ignored\n                    # and an errback will be logged.\n                    state[0] = 1\n                    ultimate.errback(err)\n                else:\n                    # The consuming Deferred errbacked after the producing\n                    # Deferred fired.  This really shouldn't ever happen.\n                    # If it does, I goofed.  Log the error anyway, just so\n                    # there's a chance someone might notice and complain.\n                    self._log.failure(\n                        u\"Buggy state machine in {request}/[{state}]: \"\n                        u\"ebConsuming called\",\n                        failure=err,\n                        request=repr(self),\n                        state=state[0]\n                    )\n\n            def cbProducing(result):\n                if state == [None]:\n                    # The producing Deferred succeeded first.  Nothing will\n                    # ever happen to the consuming Deferred.  Tell the\n                    # encoder we're done so it can check what the producer\n                    # wrote and make sure it was right.\n                    state[0] = 2\n                    try:\n                        encoder._noMoreWritesExpected()\n                    except:\n                        # Fail the overall writeTo Deferred - something the\n                        # producer did was wrong.\n                        ultimate.errback()\n                    else:\n                        # Success - succeed the overall writeTo Deferred.\n                        ultimate.callback(None)\n                # Otherwise, the consuming Deferred already errbacked.  The\n                # producing Deferred wasn't supposed to fire, but it did\n                # anyway.  It's buggy, but there's not really anything to be\n                # done about it.  Just ignore this result.\n\n            def ebProducing(err):\n                if state == [None]:\n                    # The producing Deferred failed first.  This means the\n                    # overall writeTo Deferred is going to errback now.\n                    # Tell the encoder that we're done so it knows to reject\n                    # further writes from the producer (which should not\n                    # happen, but the producer may be buggy).\n                    state[0] = 3\n                    encoder._allowNoMoreWrites()\n                    ultimate.errback(err)\n                else:\n                    # The producing Deferred failed after the consuming\n                    # Deferred failed.  It shouldn't have, so it's buggy.\n                    # Log the exception in case anyone who can fix the code\n                    # is watching.\n                    self._log.failure(u\"Producer is buggy\", failure=err)\n\n            consuming.addErrback(ebConsuming)\n            producing.addCallbacks(cbProducing, ebProducing)\n\n            return ultimate\n\n        d = combine(finishedConsuming, finishedProducing)\n        def f(passthrough):\n            # Regardless of what happens with the overall Deferred, once it\n            # fires, the producer registered way up above the definition of\n            # combine should be unregistered.\n            transport.unregisterProducer()\n            return passthrough\n        d.addBoth(f)\n        return d\n\n\n    def _writeToEmptyBodyContentLength(self, transport):\n        \"\"\"\n        Write this request to the given transport using content-length to frame\n        the (empty) body.\n\n        @param transport: See L{writeTo}.\n        @return: See L{writeTo}.\n        \"\"\"\n        self._writeHeaders(transport, b\"Content-Length: 0\\r\\n\")\n        return succeed(None)\n\n\n    def writeTo(self, transport):\n        \"\"\"\n        Format this L{Request} as an HTTP/1.1 request and write it to the given\n        transport.  If bodyProducer is not None, it will be associated with an\n        L{IConsumer}.\n\n        @param transport: The transport to which to write.\n        @type transport: L{twisted.internet.interfaces.ITransport} provider\n\n        @return: A L{Deferred} which fires with L{None} when the request has\n            been completely written to the transport or with a L{Failure} if\n            there is any problem generating the request bytes.\n        \"\"\"\n        if self.bodyProducer is None:\n            # If the method semantics anticipate a body, include a\n            # Content-Length even if it is 0.\n            # https://tools.ietf.org/html/rfc7230#section-3.3.2\n            if self.method in (b\"PUT\", b\"POST\"):\n                self._writeToEmptyBodyContentLength(transport)\n            else:\n                self._writeHeaders(transport, None)\n        elif self.bodyProducer.length is UNKNOWN_LENGTH:\n            return self._writeToBodyProducerChunked(transport)\n        else:\n            return self._writeToBodyProducerContentLength(transport)\n\n\n    def stopWriting(self):\n        \"\"\"\n        Stop writing this request to the transport.  This can only be called\n        after C{writeTo} and before the L{Deferred} returned by C{writeTo}\n        fires.  It should cancel any asynchronous task started by C{writeTo}.\n        The L{Deferred} returned by C{writeTo} need not be fired if this method\n        is called.\n        \"\"\"\n        # If bodyProducer is None, then the Deferred returned by writeTo has\n        # fired already and this method cannot be called.\n        _callAppFunction(self.bodyProducer.stopProducing)\n\n\n\nclass LengthEnforcingConsumer:\n    \"\"\"\n    An L{IConsumer} proxy which enforces an exact length requirement on the\n    total data written to it.\n\n    @ivar _length: The number of bytes remaining to be written.\n\n    @ivar _producer: The L{IBodyProducer} which is writing to this\n        consumer.\n\n    @ivar _consumer: The consumer to which at most C{_length} bytes will be\n        forwarded.\n\n    @ivar _finished: A L{Deferred} which will be fired with a L{Failure} if too\n        many bytes are written to this consumer.\n    \"\"\"\n    def __init__(self, producer, consumer, finished):\n        self._length = producer.length\n        self._producer = producer\n        self._consumer = consumer\n        self._finished = finished\n\n\n    def _allowNoMoreWrites(self):\n        \"\"\"\n        Indicate that no additional writes are allowed.  Attempts to write\n        after calling this method will be met with an exception.\n        \"\"\"\n        self._finished = None\n\n\n    def write(self, bytes):\n        \"\"\"\n        Write C{bytes} to the underlying consumer unless\n        C{_noMoreWritesExpected} has been called or there are/have been too\n        many bytes.\n        \"\"\"\n        if self._finished is None:\n            # No writes are supposed to happen any more.  Try to convince the\n            # calling code to stop calling this method by calling its\n            # stopProducing method and then throwing an exception at it.  This\n            # exception isn't documented as part of the API because you're\n            # never supposed to expect it: only buggy code will ever receive\n            # it.\n            self._producer.stopProducing()\n            raise ExcessWrite()\n\n        if len(bytes) <= self._length:\n            self._length -= len(bytes)\n            self._consumer.write(bytes)\n        else:\n            # No synchronous exception is raised in *this* error path because\n            # we still have _finished which we can use to report the error to a\n            # better place than the direct caller of this method (some\n            # arbitrary application code).\n            _callAppFunction(self._producer.stopProducing)\n            self._finished.errback(WrongBodyLength(u\"too many bytes written\"))\n            self._allowNoMoreWrites()\n\n\n    def _noMoreWritesExpected(self):\n        \"\"\"\n        Called to indicate no more bytes will be written to this consumer.\n        Check to see that the correct number have been written.\n\n        @raise WrongBodyLength: If not enough bytes have been written.\n        \"\"\"\n        if self._finished is not None:\n            self._allowNoMoreWrites()\n            if self._length:\n                raise WrongBodyLength(u\"too few bytes written\")\n\n\n\ndef makeStatefulDispatcher(name, template):\n    \"\"\"\n    Given a I{dispatch} name and a function, return a function which can be\n    used as a method and which, when called, will call another method defined\n    on the instance and return the result.  The other method which is called is\n    determined by the value of the C{_state} attribute of the instance.\n\n    @param name: A string which is used to construct the name of the subsidiary\n        method to invoke.  The subsidiary method is named like C{'_%s_%s' %\n        (name, _state)}.\n\n    @param template: A function object which is used to give the returned\n        function a docstring.\n\n    @return: The dispatcher function.\n    \"\"\"\n    def dispatcher(self, *args, **kwargs):\n        func = getattr(self, '_' + name + '_' + self._state, None)\n        if func is None:\n            raise RuntimeError(\n                u\"%r has no %s method in state %s\" % (self, name, self._state))\n        return func(*args, **kwargs)\n    dispatcher.__doc__ = template.__doc__\n    return dispatcher\n\n\n\n# This proxy class is used only in the private constructor of the Response\n# class below, in order to prevent users relying on any property of the\n# concrete request object: they can only use what is provided by\n# IClientRequest.\n_ClientRequestProxy = proxyForInterface(IClientRequest)\n\n\n\n@implementer(IResponse)\nclass Response:\n    \"\"\"\n    A L{Response} instance describes an HTTP response received from an HTTP\n    server.\n\n    L{Response} should not be subclassed or instantiated.\n\n    @ivar _transport: See L{__init__}.\n\n    @ivar _bodyProtocol: The L{IProtocol} provider to which the body is\n        delivered.  L{None} before one has been registered with\n        C{deliverBody}.\n\n    @ivar _bodyBuffer: A C{list} of the strings passed to C{bodyDataReceived}\n        before C{deliverBody} is called.  L{None} afterwards.\n\n    @ivar _state: Indicates what state this L{Response} instance is in,\n        particularly with respect to delivering bytes from the response body\n        to an application-supplied protocol object.  This may be one of\n        C{'INITIAL'}, C{'CONNECTED'}, C{'DEFERRED_CLOSE'}, or C{'FINISHED'},\n        with the following meanings:\n\n          - INITIAL: This is the state L{Response} objects start in.  No\n            protocol has yet been provided and the underlying transport may\n            still have bytes to deliver to it.\n\n          - DEFERRED_CLOSE: If the underlying transport indicates all bytes\n            have been delivered but no application-provided protocol is yet\n            available, the L{Response} moves to this state.  Data is\n            buffered and waiting for a protocol to be delivered to.\n\n          - CONNECTED: If a protocol is provided when the state is INITIAL,\n            the L{Response} moves to this state.  Any buffered data is\n            delivered and any data which arrives from the transport\n            subsequently is given directly to the protocol.\n\n          - FINISHED: If a protocol is provided in the DEFERRED_CLOSE state,\n            the L{Response} moves to this state after delivering all\n            buffered data to the protocol.  Otherwise, if the L{Response} is\n            in the CONNECTED state, if the transport indicates there is no\n            more data, the L{Response} moves to this state.  Nothing else\n            can happen once the L{Response} is in this state.\n    @type _state: C{str}\n    \"\"\"\n\n    length = UNKNOWN_LENGTH\n\n    _bodyProtocol = None\n    _bodyFinished = False\n\n    def __init__(self, version, code, phrase, headers, _transport):\n        \"\"\"\n        @param version: HTTP version components protocol, major, minor. E.g.\n            C{(b'HTTP', 1, 1)} to mean C{b'HTTP/1.1'}.\n\n        @param code: HTTP status code.\n        @type code: L{int}\n\n        @param phrase: HTTP reason phrase, intended to give a short description\n            of the HTTP status code.\n\n        @param headers: HTTP response headers.\n        @type headers: L{twisted.web.http_headers.Headers}\n\n        @param _transport: The transport which is delivering this response.\n        \"\"\"\n        self.version = version\n        self.code = code\n        self.phrase = phrase\n        self.headers = headers\n        self._transport = _transport\n        self._bodyBuffer = []\n        self._state = 'INITIAL'\n        self.request = None\n        self.previousResponse = None\n\n\n    @classmethod\n    def _construct(cls, version, code, phrase, headers, _transport, request):\n        \"\"\"\n        Private constructor.\n\n        @param version: See L{__init__}.\n        @param code: See L{__init__}.\n        @param phrase: See L{__init__}.\n        @param headers: See L{__init__}.\n        @param _transport: See L{__init__}.\n        @param request: See L{IResponse.request}.\n\n        @return: L{Response} instance.\n        \"\"\"\n        response = Response(version, code, phrase, headers, _transport)\n        response.request = _ClientRequestProxy(request)\n        return response\n\n\n    def setPreviousResponse(self, previousResponse):\n        self.previousResponse = previousResponse\n\n\n    def deliverBody(self, protocol):\n        \"\"\"\n        Dispatch the given L{IProtocol} depending of the current state of the\n        response.\n        \"\"\"\n    deliverBody = makeStatefulDispatcher('deliverBody', deliverBody)\n\n\n    def _deliverBody_INITIAL(self, protocol):\n        \"\"\"\n        Deliver any buffered data to C{protocol} and prepare to deliver any\n        future data to it.  Move to the C{'CONNECTED'} state.\n        \"\"\"\n        protocol.makeConnection(self._transport)\n        self._bodyProtocol = protocol\n        for data in self._bodyBuffer:\n            self._bodyProtocol.dataReceived(data)\n        self._bodyBuffer = None\n\n        self._state = 'CONNECTED'\n\n        # Now that there's a protocol to consume the body, resume the\n        # transport.  It was previously paused by HTTPClientParser to avoid\n        # reading too much data before it could be handled. We need to do this\n        # after we transition our state as it may recursively lead to more data\n        # being delivered, or even the body completing.\n        self._transport.resumeProducing()\n\n\n    def _deliverBody_CONNECTED(self, protocol):\n        \"\"\"\n        It is invalid to attempt to deliver data to a protocol when it is\n        already being delivered to another protocol.\n        \"\"\"\n        raise RuntimeError(\n            u\"Response already has protocol %r, cannot deliverBody \"\n            u\"again\" % (self._bodyProtocol,))\n\n\n    def _deliverBody_DEFERRED_CLOSE(self, protocol):\n        \"\"\"\n        Deliver any buffered data to C{protocol} and then disconnect the\n        protocol.  Move to the C{'FINISHED'} state.\n        \"\"\"\n        # Unlike _deliverBody_INITIAL, there is no need to resume the\n        # transport here because all of the response data has been received\n        # already.  Some higher level code may want to resume the transport if\n        # that code expects further data to be received over it.\n\n        protocol.makeConnection(self._transport)\n\n        for data in self._bodyBuffer:\n            protocol.dataReceived(data)\n        self._bodyBuffer = None\n        protocol.connectionLost(self._reason)\n        self._state = 'FINISHED'\n\n\n    def _deliverBody_FINISHED(self, protocol):\n        \"\"\"\n        It is invalid to attempt to deliver data to a protocol after the\n        response body has been delivered to another protocol.\n        \"\"\"\n        raise RuntimeError(\n            u\"Response already finished, cannot deliverBody now.\")\n\n\n    def _bodyDataReceived(self, data):\n        \"\"\"\n        Called by HTTPClientParser with chunks of data from the response body.\n        They will be buffered or delivered to the protocol passed to\n        deliverBody.\n        \"\"\"\n    _bodyDataReceived = makeStatefulDispatcher('bodyDataReceived',\n                                               _bodyDataReceived)\n\n\n    def _bodyDataReceived_INITIAL(self, data):\n        \"\"\"\n        Buffer any data received for later delivery to a protocol passed to\n        C{deliverBody}.\n\n        Little or no data should be buffered by this method, since the\n        transport has been paused and will not be resumed until a protocol\n        is supplied.\n        \"\"\"\n        self._bodyBuffer.append(data)\n\n\n    def _bodyDataReceived_CONNECTED(self, data):\n        \"\"\"\n        Deliver any data received to the protocol to which this L{Response}\n        is connected.\n        \"\"\"\n        self._bodyProtocol.dataReceived(data)\n\n\n    def _bodyDataReceived_DEFERRED_CLOSE(self, data):\n        \"\"\"\n        It is invalid for data to be delivered after it has been indicated\n        that the response body has been completely delivered.\n        \"\"\"\n        raise RuntimeError(u\"Cannot receive body data after _bodyDataFinished\")\n\n\n    def _bodyDataReceived_FINISHED(self, data):\n        \"\"\"\n        It is invalid for data to be delivered after the response body has\n        been delivered to a protocol.\n        \"\"\"\n        raise RuntimeError(u\"Cannot receive body data after \"\n                           u\"protocol disconnected\")\n\n\n    def _bodyDataFinished(self, reason=None):\n        \"\"\"\n        Called by HTTPClientParser when no more body data is available.  If the\n        optional reason is supplied, this indicates a problem or potential\n        problem receiving all of the response body.\n        \"\"\"\n    _bodyDataFinished = makeStatefulDispatcher('bodyDataFinished',\n                                               _bodyDataFinished)\n\n\n    def _bodyDataFinished_INITIAL(self, reason=None):\n        \"\"\"\n        Move to the C{'DEFERRED_CLOSE'} state to wait for a protocol to\n        which to deliver the response body.\n        \"\"\"\n        self._state = 'DEFERRED_CLOSE'\n        if reason is None:\n            reason = Failure(ResponseDone(u\"Response body fully received\"))\n        self._reason = reason\n\n\n    def _bodyDataFinished_CONNECTED(self, reason=None):\n        \"\"\"\n        Disconnect the protocol and move to the C{'FINISHED'} state.\n        \"\"\"\n        if reason is None:\n            reason = Failure(ResponseDone(u\"Response body fully received\"))\n        self._bodyProtocol.connectionLost(reason)\n        self._bodyProtocol = None\n        self._state = 'FINISHED'\n\n\n    def _bodyDataFinished_DEFERRED_CLOSE(self):\n        \"\"\"\n        It is invalid to attempt to notify the L{Response} of the end of the\n        response body data more than once.\n        \"\"\"\n        raise RuntimeError(u\"Cannot finish body data more than once\")\n\n\n    def _bodyDataFinished_FINISHED(self):\n        \"\"\"\n        It is invalid to attempt to notify the L{Response} of the end of the\n        response body data more than once.\n        \"\"\"\n        raise RuntimeError(u\"Cannot finish body data after \"\n                           u\"protocol disconnected\")\n\n\n\n@implementer(IConsumer)\nclass ChunkedEncoder:\n    \"\"\"\n    Helper object which exposes L{IConsumer} on top of L{HTTP11ClientProtocol}\n    for streaming request bodies to the server.\n    \"\"\"\n\n    def __init__(self, transport):\n        self.transport = transport\n\n\n    def _allowNoMoreWrites(self):\n        \"\"\"\n        Indicate that no additional writes are allowed.  Attempts to write\n        after calling this method will be met with an exception.\n        \"\"\"\n        self.transport = None\n\n\n    def registerProducer(self, producer, streaming):\n        \"\"\"\n        Register the given producer with C{self.transport}.\n        \"\"\"\n        self.transport.registerProducer(producer, streaming)\n\n\n    def write(self, data):\n        \"\"\"\n        Write the given request body bytes to the transport using chunked\n        encoding.\n\n        @type data: C{bytes}\n        \"\"\"\n        if self.transport is None:\n            raise ExcessWrite()\n        self.transport.writeSequence((networkString(\"%x\\r\\n\" % len(data)),\n            data, b\"\\r\\n\"))\n\n\n    def unregisterProducer(self):\n        \"\"\"\n        Indicate that the request body is complete and finish the request.\n        \"\"\"\n        self.write(b'')\n        self.transport.unregisterProducer()\n        self._allowNoMoreWrites()\n\n\n\n@implementer(IPushProducer)\nclass TransportProxyProducer:\n    \"\"\"\n    An L{twisted.internet.interfaces.IPushProducer} implementation which\n    wraps another such thing and proxies calls to it until it is told to stop.\n\n    @ivar _producer: The wrapped L{twisted.internet.interfaces.IPushProducer}\n    provider or L{None} after this proxy has been stopped.\n    \"\"\"\n\n    # LineReceiver uses this undocumented attribute of transports to decide\n    # when to stop calling lineReceived or rawDataReceived (if it finds it to\n    # be true, it doesn't bother to deliver any more data).  Set disconnecting\n    # to False here and never change it to true so that all data is always\n    # delivered to us and so that LineReceiver doesn't fail with an\n    # AttributeError.\n    disconnecting = False\n\n    def __init__(self, producer):\n        self._producer = producer\n\n\n    def stopProxying(self):\n        \"\"\"\n        Stop forwarding calls of L{twisted.internet.interfaces.IPushProducer}\n        methods to the underlying L{twisted.internet.interfaces.IPushProducer}\n        provider.\n        \"\"\"\n        self._producer = None\n\n\n    def stopProducing(self):\n        \"\"\"\n        Proxy the stoppage to the underlying producer, unless this proxy has\n        been stopped.\n        \"\"\"\n        if self._producer is not None:\n            self._producer.stopProducing()\n\n\n    def resumeProducing(self):\n        \"\"\"\n        Proxy the resumption to the underlying producer, unless this proxy has\n        been stopped.\n        \"\"\"\n        if self._producer is not None:\n            self._producer.resumeProducing()\n\n\n    def pauseProducing(self):\n        \"\"\"\n        Proxy the pause to the underlying producer, unless this proxy has been\n        stopped.\n        \"\"\"\n        if self._producer is not None:\n            self._producer.pauseProducing()\n\n\n    def loseConnection(self):\n        \"\"\"\n        Proxy the request to lose the connection to the underlying producer,\n        unless this proxy has been stopped.\n        \"\"\"\n        if self._producer is not None:\n            self._producer.loseConnection()\n\n\n\nclass HTTP11ClientProtocol(Protocol):\n    \"\"\"\n    L{HTTP11ClientProtocol} is an implementation of the HTTP 1.1 client\n    protocol.  It supports as few features as possible.\n\n    @ivar _parser: After a request is issued, the L{HTTPClientParser} to\n        which received data making up the response to that request is\n        delivered.\n\n    @ivar _finishedRequest: After a request is issued, the L{Deferred} which\n        will fire when a L{Response} object corresponding to that request is\n        available.  This allows L{HTTP11ClientProtocol} to fail the request\n        if there is a connection or parsing problem.\n\n    @ivar _currentRequest: After a request is issued, the L{Request}\n        instance used to make that request.  This allows\n        L{HTTP11ClientProtocol} to stop request generation if necessary (for\n        example, if the connection is lost).\n\n    @ivar _transportProxy: After a request is issued, the\n        L{TransportProxyProducer} to which C{_parser} is connected.  This\n        allows C{_parser} to pause and resume the transport in a way which\n        L{HTTP11ClientProtocol} can exert some control over.\n\n    @ivar _responseDeferred: After a request is issued, the L{Deferred} from\n        C{_parser} which will fire with a L{Response} when one has been\n        received.  This is eventually chained with C{_finishedRequest}, but\n        only in certain cases to avoid double firing that Deferred.\n\n    @ivar _state: Indicates what state this L{HTTP11ClientProtocol} instance\n        is in with respect to transmission of a request and reception of a\n        response.  This may be one of the following strings:\n\n          - QUIESCENT: This is the state L{HTTP11ClientProtocol} instances\n            start in.  Nothing is happening: no request is being sent and no\n            response is being received or expected.\n\n          - TRANSMITTING: When a request is made (via L{request}), the\n            instance moves to this state.  L{Request.writeTo} has been used\n            to start to send a request but it has not yet finished.\n\n          - TRANSMITTING_AFTER_RECEIVING_RESPONSE: The server has returned a\n            complete response but the request has not yet been fully sent\n            yet.  The instance will remain in this state until the request\n            is fully sent.\n\n          - GENERATION_FAILED: There was an error while the request.  The\n            request was not fully sent to the network.\n\n          - WAITING: The request was fully sent to the network.  The\n            instance is now waiting for the response to be fully received.\n\n          - ABORTING: Application code has requested that the HTTP connection\n            be aborted.\n\n          - CONNECTION_LOST: The connection has been lost.\n    @type _state: C{str}\n\n    @ivar _abortDeferreds: A list of C{Deferred} instances that will fire when\n        the connection is lost.\n    \"\"\"\n    _state = 'QUIESCENT'\n    _parser = None\n    _finishedRequest = None\n    _currentRequest = None\n    _transportProxy = None\n    _responseDeferred = None\n    _log = Logger()\n\n\n    def __init__(self, quiescentCallback=lambda c: None):\n        self._quiescentCallback = quiescentCallback\n        self._abortDeferreds = []\n\n\n    @property\n    def state(self):\n        return self._state\n\n\n    def request(self, request):\n        \"\"\"\n        Issue C{request} over C{self.transport} and return a L{Deferred} which\n        will fire with a L{Response} instance or an error.\n\n        @param request: The object defining the parameters of the request to\n           issue.\n        @type request: L{Request}\n\n        @rtype: L{Deferred}\n        @return: The deferred may errback with L{RequestGenerationFailed} if\n            the request was not fully written to the transport due to a local\n            error.  It may errback with L{RequestTransmissionFailed} if it was\n            not fully written to the transport due to a network error.  It may\n            errback with L{ResponseFailed} if the request was sent (not\n            necessarily received) but some or all of the response was lost.  It\n            may errback with L{RequestNotSent} if it is not possible to send\n            any more requests using this L{HTTP11ClientProtocol}.\n        \"\"\"\n        if self._state != 'QUIESCENT':\n            return fail(RequestNotSent())\n\n        self._state = 'TRANSMITTING'\n        _requestDeferred = maybeDeferred(request.writeTo, self.transport)\n\n        def cancelRequest(ign):\n            # Explicitly cancel the request's deferred if it's still trying to\n            # write when this request is cancelled.\n            if self._state in (\n                    'TRANSMITTING', 'TRANSMITTING_AFTER_RECEIVING_RESPONSE'):\n                _requestDeferred.cancel()\n            else:\n                self.transport.abortConnection()\n                self._disconnectParser(Failure(CancelledError()))\n        self._finishedRequest = Deferred(cancelRequest)\n\n        # Keep track of the Request object in case we need to call stopWriting\n        # on it.\n        self._currentRequest = request\n\n        self._transportProxy = TransportProxyProducer(self.transport)\n        self._parser = HTTPClientParser(request, self._finishResponse)\n        self._parser.makeConnection(self._transportProxy)\n        self._responseDeferred = self._parser._responseDeferred\n\n        def cbRequestWritten(ignored):\n            if self._state == 'TRANSMITTING':\n                self._state = 'WAITING'\n                self._responseDeferred.chainDeferred(self._finishedRequest)\n\n        def ebRequestWriting(err):\n            if self._state == 'TRANSMITTING':\n                self._state = 'GENERATION_FAILED'\n                self.transport.abortConnection()\n                self._finishedRequest.errback(\n                    Failure(RequestGenerationFailed([err])))\n            else:\n                self._log.failure(\n                    u'Error writing request, but not in valid state '\n                    u'to finalize request: {state}',\n                    failure=err,\n                    state=self._state\n                )\n\n        _requestDeferred.addCallbacks(cbRequestWritten, ebRequestWriting)\n\n        return self._finishedRequest\n\n\n    def _finishResponse(self, rest):\n        \"\"\"\n        Called by an L{HTTPClientParser} to indicate that it has parsed a\n        complete response.\n\n        @param rest: A C{bytes} giving any trailing bytes which were given to\n            the L{HTTPClientParser} which were not part of the response it\n            was parsing.\n        \"\"\"\n    _finishResponse = makeStatefulDispatcher('finishResponse', _finishResponse)\n\n\n    def _finishResponse_WAITING(self, rest):\n        # Currently the rest parameter is ignored. Don't forget to use it if\n        # we ever add support for pipelining. And maybe check what trailers\n        # mean.\n        if self._state == 'WAITING':\n            self._state = 'QUIESCENT'\n        else:\n            # The server sent the entire response before we could send the\n            # whole request.  That sucks.  Oh well.  Fire the request()\n            # Deferred with the response.  But first, make sure that if the\n            # request does ever finish being written that it won't try to fire\n            # that Deferred.\n            self._state = 'TRANSMITTING_AFTER_RECEIVING_RESPONSE'\n            self._responseDeferred.chainDeferred(self._finishedRequest)\n\n        # This will happen if we're being called due to connection being lost;\n        # if so, no need to disconnect parser again, or to call\n        # _quiescentCallback.\n        if self._parser is None:\n            return\n\n        reason = ConnectionDone(u\"synthetic!\")\n        connHeaders = self._parser.connHeaders.getRawHeaders(b'connection', ())\n        if ((b'close' in connHeaders) or self._state != \"QUIESCENT\" or\n            not self._currentRequest.persistent):\n            self._giveUp(Failure(reason))\n        else:\n            # Just in case we had paused the transport, resume it before\n            # considering it quiescent again.\n            self.transport.resumeProducing()\n\n            # We call the quiescent callback first, to ensure connection gets\n            # added back to connection pool before we finish the request.\n            try:\n                self._quiescentCallback(self)\n            except:\n                # If callback throws exception, just log it and disconnect;\n                # keeping persistent connections around is an optimisation:\n                self._log.failure('')\n                self.transport.loseConnection()\n            self._disconnectParser(reason)\n\n\n    _finishResponse_TRANSMITTING = _finishResponse_WAITING\n\n\n    def _disconnectParser(self, reason):\n        \"\"\"\n        If there is still a parser, call its C{connectionLost} method with the\n        given reason.  If there is not, do nothing.\n\n        @type reason: L{Failure}\n        \"\"\"\n        if self._parser is not None:\n            parser = self._parser\n            self._parser = None\n            self._currentRequest = None\n            self._finishedRequest = None\n            self._responseDeferred = None\n\n            # The parser is no longer allowed to do anything to the real\n            # transport.  Stop proxying from the parser's transport to the real\n            # transport before telling the parser it's done so that it can't do\n            # anything.\n            self._transportProxy.stopProxying()\n            self._transportProxy = None\n            parser.connectionLost(reason)\n\n\n    def _giveUp(self, reason):\n        \"\"\"\n        Lose the underlying connection and disconnect the parser with the given\n        L{Failure}.\n\n        Use this method instead of calling the transport's loseConnection\n        method directly otherwise random things will break.\n        \"\"\"\n        self.transport.loseConnection()\n        self._disconnectParser(reason)\n\n\n    def dataReceived(self, bytes):\n        \"\"\"\n        Handle some stuff from some place.\n        \"\"\"\n        try:\n            self._parser.dataReceived(bytes)\n        except:\n            self._giveUp(Failure())\n\n\n    def connectionLost(self, reason):\n        \"\"\"\n        The underlying transport went away.  If appropriate, notify the parser\n        object.\n        \"\"\"\n    connectionLost = makeStatefulDispatcher('connectionLost', connectionLost)\n\n\n    def _connectionLost_QUIESCENT(self, reason):\n        \"\"\"\n        Nothing is currently happening.  Move to the C{'CONNECTION_LOST'}\n        state but otherwise do nothing.\n        \"\"\"\n        self._state = 'CONNECTION_LOST'\n\n\n    def _connectionLost_GENERATION_FAILED(self, reason):\n        \"\"\"\n        The connection was in an inconsistent state.  Move to the\n        C{'CONNECTION_LOST'} state but otherwise do nothing.\n        \"\"\"\n        self._state = 'CONNECTION_LOST'\n\n\n    def _connectionLost_TRANSMITTING(self, reason):\n        \"\"\"\n        Fail the L{Deferred} for the current request, notify the request\n        object that it does not need to continue transmitting itself, and\n        move to the C{'CONNECTION_LOST'} state.\n        \"\"\"\n        self._state = 'CONNECTION_LOST'\n        self._finishedRequest.errback(\n            Failure(RequestTransmissionFailed([reason])))\n        del self._finishedRequest\n\n        # Tell the request that it should stop bothering now.\n        self._currentRequest.stopWriting()\n\n\n    def _connectionLost_TRANSMITTING_AFTER_RECEIVING_RESPONSE(self, reason):\n        \"\"\"\n        Move to the C{'CONNECTION_LOST'} state.\n        \"\"\"\n        self._state = 'CONNECTION_LOST'\n\n\n    def _connectionLost_WAITING(self, reason):\n        \"\"\"\n        Disconnect the response parser so that it can propagate the event as\n        necessary (for example, to call an application protocol's\n        C{connectionLost} method, or to fail a request L{Deferred}) and move\n        to the C{'CONNECTION_LOST'} state.\n        \"\"\"\n        self._disconnectParser(reason)\n        self._state = 'CONNECTION_LOST'\n\n\n    def _connectionLost_ABORTING(self, reason):\n        \"\"\"\n        Disconnect the response parser with a L{ConnectionAborted} failure, and\n        move to the C{'CONNECTION_LOST'} state.\n        \"\"\"\n        self._disconnectParser(Failure(ConnectionAborted()))\n        self._state = 'CONNECTION_LOST'\n        for d in self._abortDeferreds:\n            d.callback(None)\n        self._abortDeferreds = []\n\n\n    def abort(self):\n        \"\"\"\n        Close the connection and cause all outstanding L{request} L{Deferred}s\n        to fire with an error.\n        \"\"\"\n        if self._state == \"CONNECTION_LOST\":\n            return succeed(None)\n        self.transport.loseConnection()\n        self._state = 'ABORTING'\n        d = Deferred()\n        self._abortDeferreds.append(d)\n        return d\n", "code_before": "# -*- test-case-name: twisted.web.test.test_newclient -*-\n# Copyright (c) Twisted Matrix Laboratories.\n# See LICENSE for details.\n\n\"\"\"\nAn U{HTTP 1.1<http://www.w3.org/Protocols/rfc2616/rfc2616.html>} client.\n\nThe way to use the functionality provided by this module is to:\n\n  - Connect a L{HTTP11ClientProtocol} to an HTTP server\n  - Create a L{Request} with the appropriate data\n  - Pass the request to L{HTTP11ClientProtocol.request}\n  - The returned Deferred will fire with a L{Response} object\n  - Create a L{IProtocol} provider which can handle the response body\n  - Connect it to the response with L{Response.deliverBody}\n  - When the protocol's C{connectionLost} method is called, the response is\n    complete.  See L{Response.deliverBody} for details.\n\nVarious other classes in this module support this usage:\n\n  - HTTPParser is the basic HTTP parser.  It can handle the parts of HTTP which\n    are symmetric between requests and responses.\n\n  - HTTPClientParser extends HTTPParser to handle response-specific parts of\n    HTTP.  One instance is created for each request to parse the corresponding\n    response.\n\"\"\"\n\nfrom __future__ import division, absolute_import\n__metaclass__ = type\n\nfrom zope.interface import implementer\n\nfrom twisted.python.compat import networkString\nfrom twisted.python.components import proxyForInterface\nfrom twisted.python.reflect import fullyQualifiedName\nfrom twisted.python.failure import Failure\nfrom twisted.internet.interfaces import IConsumer, IPushProducer\nfrom twisted.internet.error import ConnectionDone\nfrom twisted.internet.defer import Deferred, succeed, fail, maybeDeferred\nfrom twisted.internet.defer import CancelledError\nfrom twisted.internet.protocol import Protocol\nfrom twisted.protocols.basic import LineReceiver\nfrom twisted.web.iweb import UNKNOWN_LENGTH, IResponse, IClientRequest\nfrom twisted.web.http_headers import Headers\nfrom twisted.web.http import NO_CONTENT, NOT_MODIFIED\nfrom twisted.web.http import _DataLoss, PotentialDataLoss\nfrom twisted.web.http import _IdentityTransferDecoder, _ChunkedTransferDecoder\nfrom twisted.logger import Logger\n\n# States HTTPParser can be in\nSTATUS = u'STATUS'\nHEADER = u'HEADER'\nBODY = u'BODY'\nDONE = u'DONE'\n_moduleLog = Logger()\n\n\nclass BadHeaders(Exception):\n    \"\"\"\n    Headers passed to L{Request} were in some way invalid.\n    \"\"\"\n\n\n\nclass ExcessWrite(Exception):\n    \"\"\"\n    The body L{IBodyProducer} for a request tried to write data after\n    indicating it had finished writing data.\n    \"\"\"\n\n\nclass ParseError(Exception):\n    \"\"\"\n    Some received data could not be parsed.\n\n    @ivar data: The string which could not be parsed.\n    \"\"\"\n    def __init__(self, reason, data):\n        Exception.__init__(self, reason, data)\n        self.data = data\n\n\n\nclass BadResponseVersion(ParseError):\n    \"\"\"\n    The version string in a status line was unparsable.\n    \"\"\"\n\n\n\nclass _WrapperException(Exception):\n    \"\"\"\n    L{_WrapperException} is the base exception type for exceptions which\n    include one or more other exceptions as the low-level causes.\n\n    @ivar reasons: A L{list} of one or more L{Failure} instances encountered\n        during an HTTP request.  See subclass documentation for more details.\n    \"\"\"\n    def __init__(self, reasons):\n        Exception.__init__(self, reasons)\n        self.reasons = reasons\n\n\n\nclass RequestGenerationFailed(_WrapperException):\n    \"\"\"\n    There was an error while creating the bytes which make up a request.\n\n    @ivar reasons: A C{list} of one or more L{Failure} instances giving the\n        reasons the request generation was considered to have failed.\n    \"\"\"\n\n\n\nclass RequestTransmissionFailed(_WrapperException):\n    \"\"\"\n    There was an error while sending the bytes which make up a request.\n\n    @ivar reasons: A C{list} of one or more L{Failure} instances giving the\n        reasons the request transmission was considered to have failed.\n    \"\"\"\n\n\n\nclass ConnectionAborted(Exception):\n    \"\"\"\n    The connection was explicitly aborted by application code.\n    \"\"\"\n\n\n\nclass WrongBodyLength(Exception):\n    \"\"\"\n    An L{IBodyProducer} declared the number of bytes it was going to\n    produce (via its C{length} attribute) and then produced a different number\n    of bytes.\n    \"\"\"\n\n\n\nclass ResponseDone(Exception):\n    \"\"\"\n    L{ResponseDone} may be passed to L{IProtocol.connectionLost} on the\n    protocol passed to L{Response.deliverBody} and indicates that the entire\n    response has been delivered.\n    \"\"\"\n\n\n\nclass ResponseFailed(_WrapperException):\n    \"\"\"\n    L{ResponseFailed} indicates that all of the response to a request was not\n    received for some reason.\n\n    @ivar reasons: A C{list} of one or more L{Failure} instances giving the\n        reasons the response was considered to have failed.\n\n    @ivar response: If specified, the L{Response} received from the server (and\n        in particular the status code and the headers).\n    \"\"\"\n\n    def __init__(self, reasons, response=None):\n        _WrapperException.__init__(self, reasons)\n        self.response = response\n\n\n\nclass ResponseNeverReceived(ResponseFailed):\n    \"\"\"\n    A L{ResponseFailed} that knows no response bytes at all have been received.\n    \"\"\"\n\n\n\nclass RequestNotSent(Exception):\n    \"\"\"\n    L{RequestNotSent} indicates that an attempt was made to issue a request but\n    for reasons unrelated to the details of the request itself, the request\n    could not be sent.  For example, this may indicate that an attempt was made\n    to send a request using a protocol which is no longer connected to a\n    server.\n    \"\"\"\n\n\n\ndef _callAppFunction(function):\n    \"\"\"\n    Call C{function}.  If it raises an exception, log it with a minimal\n    description of the source.\n\n    @return: L{None}\n    \"\"\"\n    try:\n        function()\n    except:\n        _moduleLog.failure(\n            u\"Unexpected exception from {name}\",\n            name=fullyQualifiedName(function)\n        )\n\n\n\nclass HTTPParser(LineReceiver):\n    \"\"\"\n    L{HTTPParser} handles the parsing side of HTTP processing. With a suitable\n    subclass, it can parse either the client side or the server side of the\n    connection.\n\n    @ivar headers: All of the non-connection control message headers yet\n        received.\n\n    @ivar state: State indicator for the response parsing state machine.  One\n        of C{STATUS}, C{HEADER}, C{BODY}, C{DONE}.\n\n    @ivar _partialHeader: L{None} or a C{list} of the lines of a multiline\n        header while that header is being received.\n    \"\"\"\n\n    # NOTE: According to HTTP spec, we're supposed to eat the\n    # 'Proxy-Authenticate' and 'Proxy-Authorization' headers also, but that\n    # doesn't sound like a good idea to me, because it makes it impossible to\n    # have a non-authenticating transparent proxy in front of an authenticating\n    # proxy. An authenticating proxy can eat them itself. -jknight\n    #\n    # Further, quoting\n    # http://homepages.tesco.net/J.deBoynePollard/FGA/web-proxy-connection-header.html\n    # regarding the 'Proxy-Connection' header:\n    #\n    #    The Proxy-Connection: header is a mistake in how some web browsers\n    #    use HTTP. Its name is the result of a false analogy. It is not a\n    #    standard part of the protocol. There is a different standard\n    #    protocol mechanism for doing what it does. And its existence\n    #    imposes a requirement upon HTTP servers such that no proxy HTTP\n    #    server can be standards-conforming in practice.\n    #\n    # -exarkun\n\n    # Some servers (like http://news.ycombinator.com/) return status lines and\n    # HTTP headers delimited by \\n instead of \\r\\n.\n    delimiter = b'\\n'\n\n    CONNECTION_CONTROL_HEADERS = set([\n            b'content-length', b'connection', b'keep-alive', b'te',\n            b'trailers', b'transfer-encoding', b'upgrade',\n            b'proxy-connection'])\n\n    def connectionMade(self):\n        self.headers = Headers()\n        self.connHeaders = Headers()\n        self.state = STATUS\n        self._partialHeader = None\n\n\n    def switchToBodyMode(self, decoder):\n        \"\"\"\n        Switch to body parsing mode - interpret any more bytes delivered as\n        part of the message body and deliver them to the given decoder.\n        \"\"\"\n        if self.state == BODY:\n            raise RuntimeError(u\"already in body mode\")\n\n        self.bodyDecoder = decoder\n        self.state = BODY\n        self.setRawMode()\n\n\n    def lineReceived(self, line):\n        \"\"\"\n        Handle one line from a response.\n        \"\"\"\n        # Handle the normal CR LF case.\n        if line[-1:] == b'\\r':\n            line = line[:-1]\n\n        if self.state == STATUS:\n            self.statusReceived(line)\n            self.state = HEADER\n        elif self.state == HEADER:\n            if not line or line[0] not in b' \\t':\n                if self._partialHeader is not None:\n                    header = b''.join(self._partialHeader)\n                    name, value = header.split(b':', 1)\n                    value = value.strip()\n                    self.headerReceived(name, value)\n                if not line:\n                    # Empty line means the header section is over.\n                    self.allHeadersReceived()\n                else:\n                    # Line not beginning with LWS is another header.\n                    self._partialHeader = [line]\n            else:\n                # A line beginning with LWS is a continuation of a header\n                # begun on a previous line.\n                self._partialHeader.append(line)\n\n\n    def rawDataReceived(self, data):\n        \"\"\"\n        Pass data from the message body to the body decoder object.\n        \"\"\"\n        self.bodyDecoder.dataReceived(data)\n\n\n    def isConnectionControlHeader(self, name):\n        \"\"\"\n        Return C{True} if the given lower-cased name is the name of a\n        connection control header (rather than an entity header).\n\n        According to RFC 2616, section 14.10, the tokens in the Connection\n        header are probably relevant here.  However, I am not sure what the\n        practical consequences of either implementing or ignoring that are.\n        So I leave it unimplemented for the time being.\n        \"\"\"\n        return name in self.CONNECTION_CONTROL_HEADERS\n\n\n    def statusReceived(self, status):\n        \"\"\"\n        Callback invoked whenever the first line of a new message is received.\n        Override this.\n\n        @param status: The first line of an HTTP request or response message\n            without trailing I{CR LF}.\n        @type status: C{bytes}\n        \"\"\"\n\n\n    def headerReceived(self, name, value):\n        \"\"\"\n        Store the given header in C{self.headers}.\n        \"\"\"\n        name = name.lower()\n        if self.isConnectionControlHeader(name):\n            headers = self.connHeaders\n        else:\n            headers = self.headers\n        headers.addRawHeader(name, value)\n\n\n    def allHeadersReceived(self):\n        \"\"\"\n        Callback invoked after the last header is passed to C{headerReceived}.\n        Override this to change to the C{BODY} or C{DONE} state.\n        \"\"\"\n        self.switchToBodyMode(None)\n\n\n\nclass HTTPClientParser(HTTPParser):\n    \"\"\"\n    An HTTP parser which only handles HTTP responses.\n\n    @ivar request: The request with which the expected response is associated.\n    @type request: L{Request}\n\n    @ivar NO_BODY_CODES: A C{set} of response codes which B{MUST NOT} have a\n        body.\n\n    @ivar finisher: A callable to invoke when this response is fully parsed.\n\n    @ivar _responseDeferred: A L{Deferred} which will be called back with the\n        response when all headers in the response have been received.\n        Thereafter, L{None}.\n\n    @ivar _everReceivedData: C{True} if any bytes have been received.\n    \"\"\"\n    NO_BODY_CODES = set([NO_CONTENT, NOT_MODIFIED])\n\n    _transferDecoders = {\n        b'chunked': _ChunkedTransferDecoder,\n        }\n\n    bodyDecoder = None\n    _log = Logger()\n\n    def __init__(self, request, finisher):\n        self.request = request\n        self.finisher = finisher\n        self._responseDeferred = Deferred()\n        self._everReceivedData = False\n\n\n    def dataReceived(self, data):\n        \"\"\"\n        Override so that we know if any response has been received.\n        \"\"\"\n        self._everReceivedData = True\n        HTTPParser.dataReceived(self, data)\n\n\n    def parseVersion(self, strversion):\n        \"\"\"\n        Parse version strings of the form Protocol '/' Major '.' Minor. E.g.\n        b'HTTP/1.1'.  Returns (protocol, major, minor).  Will raise ValueError\n        on bad syntax.\n        \"\"\"\n        try:\n            proto, strnumber = strversion.split(b'/')\n            major, minor = strnumber.split(b'.')\n            major, minor = int(major), int(minor)\n        except ValueError as e:\n            raise BadResponseVersion(str(e), strversion)\n        if major < 0 or minor < 0:\n            raise BadResponseVersion(u\"version may not be negative\",\n                strversion)\n        return (proto, major, minor)\n\n\n    def statusReceived(self, status):\n        \"\"\"\n        Parse the status line into its components and create a response object\n        to keep track of this response's state.\n        \"\"\"\n        parts = status.split(b' ', 2)\n        if len(parts) == 2:\n            # Some broken servers omit the required `phrase` portion of\n            # `status-line`.  One such server identified as\n            # \"cloudflare-nginx\".  Others fail to identify themselves\n            # entirely.  Fill in an empty phrase for such cases.\n            version, codeBytes = parts\n            phrase = b\"\"\n        elif len(parts) == 3:\n            version, codeBytes, phrase = parts\n        else:\n            raise ParseError(u\"wrong number of parts\", status)\n\n        try:\n            statusCode = int(codeBytes)\n        except ValueError:\n            raise ParseError(u\"non-integer status code\", status)\n\n        self.response = Response._construct(\n            self.parseVersion(version),\n            statusCode,\n            phrase,\n            self.headers,\n            self.transport,\n            self.request,\n        )\n\n\n    def _finished(self, rest):\n        \"\"\"\n        Called to indicate that an entire response has been received.  No more\n        bytes will be interpreted by this L{HTTPClientParser}.  Extra bytes are\n        passed up and the state of this L{HTTPClientParser} is set to I{DONE}.\n\n        @param rest: A C{bytes} giving any extra bytes delivered to this\n            L{HTTPClientParser} which are not part of the response being\n            parsed.\n        \"\"\"\n        self.state = DONE\n        self.finisher(rest)\n\n\n    def isConnectionControlHeader(self, name):\n        \"\"\"\n        Content-Length in the response to a HEAD request is an entity header,\n        not a connection control header.\n        \"\"\"\n        if self.request.method == b'HEAD' and name == b'content-length':\n            return False\n        return HTTPParser.isConnectionControlHeader(self, name)\n\n\n    def allHeadersReceived(self):\n        \"\"\"\n        Figure out how long the response body is going to be by examining\n        headers and stuff.\n        \"\"\"\n        if 100 <= self.response.code < 200:\n            # RFC 7231 Section 6.2 says that if we receive a 1XX status code\n            # and aren't expecting it, we MAY ignore it. That's what we're\n            # going to do. We reset the parser here, but we leave\n            # _everReceivedData in its True state because we have, in fact,\n            # received data.\n            self._log.info(\n                \"Ignoring unexpected {code} response\",\n                code=self.response.code\n            )\n            self.connectionMade()\n            del self.response\n            return\n\n        if (self.response.code in self.NO_BODY_CODES\n            or self.request.method == b'HEAD'):\n            self.response.length = 0\n            # The order of the next two lines might be of interest when adding\n            # support for pipelining.\n            self._finished(self.clearLineBuffer())\n            self.response._bodyDataFinished()\n        else:\n            transferEncodingHeaders = self.connHeaders.getRawHeaders(\n                b'transfer-encoding')\n            if transferEncodingHeaders:\n\n                # This could be a KeyError.  However, that would mean we do not\n                # know how to decode the response body, so failing the request\n                # is as good a behavior as any.  Perhaps someday we will want\n                # to normalize/document/test this specifically, but failing\n                # seems fine to me for now.\n                transferDecoder = self._transferDecoders[transferEncodingHeaders[0].lower()]\n\n                # If anyone ever invents a transfer encoding other than\n                # chunked (yea right), and that transfer encoding can predict\n                # the length of the response body, it might be sensible to\n                # allow the transfer decoder to set the response object's\n                # length attribute.\n            else:\n                contentLengthHeaders = self.connHeaders.getRawHeaders(\n                    b'content-length')\n                if contentLengthHeaders is None:\n                    contentLength = None\n                elif len(contentLengthHeaders) == 1:\n                    contentLength = int(contentLengthHeaders[0])\n                    self.response.length = contentLength\n                else:\n                    # \"HTTP Message Splitting\" or \"HTTP Response Smuggling\"\n                    # potentially happening.  Or it's just a buggy server.\n                    raise ValueError(u\"Too many Content-Length headers; \"\n                                     u\"response is invalid\")\n\n                if contentLength == 0:\n                    self._finished(self.clearLineBuffer())\n                    transferDecoder = None\n                else:\n                    transferDecoder = lambda x, y: _IdentityTransferDecoder(\n                        contentLength, x, y)\n\n            if transferDecoder is None:\n                self.response._bodyDataFinished()\n            else:\n                # Make sure as little data as possible from the response body\n                # gets delivered to the response object until the response\n                # object actually indicates it is ready to handle bytes\n                # (probably because an application gave it a way to interpret\n                # them).\n                self.transport.pauseProducing()\n                self.switchToBodyMode(transferDecoder(\n                        self.response._bodyDataReceived,\n                        self._finished))\n\n        # This must be last.  If it were first, then application code might\n        # change some state (for example, registering a protocol to receive the\n        # response body).  Then the pauseProducing above would be wrong since\n        # the response is ready for bytes and nothing else would ever resume\n        # the transport.\n        self._responseDeferred.callback(self.response)\n        del self._responseDeferred\n\n\n    def connectionLost(self, reason):\n        if self.bodyDecoder is not None:\n            try:\n                try:\n                    self.bodyDecoder.noMoreData()\n                except PotentialDataLoss:\n                    self.response._bodyDataFinished(Failure())\n                except _DataLoss:\n                    self.response._bodyDataFinished(\n                        Failure(ResponseFailed([reason, Failure()],\n                                               self.response)))\n                else:\n                    self.response._bodyDataFinished()\n            except:\n                # Handle exceptions from both the except suites and the else\n                # suite.  Those functions really shouldn't raise exceptions,\n                # but maybe there's some buggy application code somewhere\n                # making things difficult.\n                self._log.failure('')\n        elif self.state != DONE:\n            if self._everReceivedData:\n                exceptionClass = ResponseFailed\n            else:\n                exceptionClass = ResponseNeverReceived\n            self._responseDeferred.errback(Failure(exceptionClass([reason])))\n            del self._responseDeferred\n\n\n\n@implementer(IClientRequest)\nclass Request:\n    \"\"\"\n    A L{Request} instance describes an HTTP request to be sent to an HTTP\n    server.\n\n    @ivar method: See L{__init__}.\n    @ivar uri: See L{__init__}.\n    @ivar headers: See L{__init__}.\n    @ivar bodyProducer: See L{__init__}.\n    @ivar persistent: See L{__init__}.\n\n    @ivar _parsedURI: Parsed I{URI} for the request, or L{None}.\n    @type _parsedURI: L{twisted.web.client.URI} or L{None}\n    \"\"\"\n    _log = Logger()\n\n    def __init__(self, method, uri, headers, bodyProducer, persistent=False):\n        \"\"\"\n        @param method: The HTTP method for this request, ex: b'GET', b'HEAD',\n            b'POST', etc.\n        @type method: L{bytes}\n\n        @param uri: The relative URI of the resource to request.  For example,\n            C{b'/foo/bar?baz=quux'}.\n        @type uri: L{bytes}\n\n        @param headers: Headers to be sent to the server.  It is important to\n            note that this object does not create any implicit headers.  So it\n            is up to the HTTP Client to add required headers such as 'Host'.\n        @type headers: L{twisted.web.http_headers.Headers}\n\n        @param bodyProducer: L{None} or an L{IBodyProducer} provider which\n            produces the content body to send to the remote HTTP server.\n\n        @param persistent: Set to C{True} when you use HTTP persistent\n            connection, defaults to C{False}.\n        @type persistent: L{bool}\n        \"\"\"\n        self.method = method\n        self.uri = uri\n        self.headers = headers\n        self.bodyProducer = bodyProducer\n        self.persistent = persistent\n        self._parsedURI = None\n\n\n    @classmethod\n    def _construct(cls, method, uri, headers, bodyProducer, persistent=False,\n                   parsedURI=None):\n        \"\"\"\n        Private constructor.\n\n        @param method: See L{__init__}.\n        @param uri: See L{__init__}.\n        @param headers: See L{__init__}.\n        @param bodyProducer: See L{__init__}.\n        @param persistent: See L{__init__}.\n        @param parsedURI: See L{Request._parsedURI}.\n\n        @return: L{Request} instance.\n        \"\"\"\n        request = cls(method, uri, headers, bodyProducer, persistent)\n        request._parsedURI = parsedURI\n        return request\n\n\n    @property\n    def absoluteURI(self):\n        \"\"\"\n        The absolute URI of the request as C{bytes}, or L{None} if the\n        absolute URI cannot be determined.\n        \"\"\"\n        return getattr(self._parsedURI, 'toBytes', lambda: None)()\n\n\n    def _writeHeaders(self, transport, TEorCL):\n        hosts = self.headers.getRawHeaders(b'host', ())\n        if len(hosts) != 1:\n            raise BadHeaders(u\"Exactly one Host header required\")\n\n        # In the future, having the protocol version be a parameter to this\n        # method would probably be good.  It would be nice if this method\n        # weren't limited to issuing HTTP/1.1 requests.\n        requestLines = []\n        requestLines.append(b' '.join([self.method, self.uri,\n            b'HTTP/1.1\\r\\n']))\n        if not self.persistent:\n            requestLines.append(b'Connection: close\\r\\n')\n        if TEorCL is not None:\n            requestLines.append(TEorCL)\n        for name, values in self.headers.getAllRawHeaders():\n            requestLines.extend([name + b': ' + v + b'\\r\\n' for v in values])\n        requestLines.append(b'\\r\\n')\n        transport.writeSequence(requestLines)\n\n\n    def _writeToBodyProducerChunked(self, transport):\n        \"\"\"\n        Write this request to the given transport using chunked\n        transfer-encoding to frame the body.\n\n        @param transport: See L{writeTo}.\n        @return: See L{writeTo}.\n        \"\"\"\n        self._writeHeaders(transport, b'Transfer-Encoding: chunked\\r\\n')\n        encoder = ChunkedEncoder(transport)\n        encoder.registerProducer(self.bodyProducer, True)\n        d = self.bodyProducer.startProducing(encoder)\n\n        def cbProduced(ignored):\n            encoder.unregisterProducer()\n        def ebProduced(err):\n            encoder._allowNoMoreWrites()\n            # Don't call the encoder's unregisterProducer because it will write\n            # a zero-length chunk.  This would indicate to the server that the\n            # request body is complete.  There was an error, though, so we\n            # don't want to do that.\n            transport.unregisterProducer()\n            return err\n        d.addCallbacks(cbProduced, ebProduced)\n        return d\n\n\n    def _writeToBodyProducerContentLength(self, transport):\n        \"\"\"\n        Write this request to the given transport using content-length to frame\n        the body.\n\n        @param transport: See L{writeTo}.\n        @return: See L{writeTo}.\n        \"\"\"\n        self._writeHeaders(\n            transport,\n            networkString(\n                'Content-Length: %d\\r\\n' % (self.bodyProducer.length,)))\n\n        # This Deferred is used to signal an error in the data written to the\n        # encoder below.  It can only errback and it will only do so before too\n        # many bytes have been written to the encoder and before the producer\n        # Deferred fires.\n        finishedConsuming = Deferred()\n\n        # This makes sure the producer writes the correct number of bytes for\n        # the request body.\n        encoder = LengthEnforcingConsumer(\n            self.bodyProducer, transport, finishedConsuming)\n\n        transport.registerProducer(self.bodyProducer, True)\n\n        finishedProducing = self.bodyProducer.startProducing(encoder)\n\n        def combine(consuming, producing):\n            # This Deferred is returned and will be fired when the first of\n            # consuming or producing fires. If it's cancelled, forward that\n            # cancellation to the producer.\n            def cancelConsuming(ign):\n                finishedProducing.cancel()\n            ultimate = Deferred(cancelConsuming)\n\n            # Keep track of what has happened so far.  This initially\n            # contains None, then an integer uniquely identifying what\n            # sequence of events happened.  See the callbacks and errbacks\n            # defined below for the meaning of each value.\n            state = [None]\n\n            def ebConsuming(err):\n                if state == [None]:\n                    # The consuming Deferred failed first.  This means the\n                    # overall writeTo Deferred is going to errback now.  The\n                    # producing Deferred should not fire later (because the\n                    # consumer should have called stopProducing on the\n                    # producer), but if it does, a callback will be ignored\n                    # and an errback will be logged.\n                    state[0] = 1\n                    ultimate.errback(err)\n                else:\n                    # The consuming Deferred errbacked after the producing\n                    # Deferred fired.  This really shouldn't ever happen.\n                    # If it does, I goofed.  Log the error anyway, just so\n                    # there's a chance someone might notice and complain.\n                    self._log.failure(\n                        u\"Buggy state machine in {request}/[{state}]: \"\n                        u\"ebConsuming called\",\n                        failure=err,\n                        request=repr(self),\n                        state=state[0]\n                    )\n\n            def cbProducing(result):\n                if state == [None]:\n                    # The producing Deferred succeeded first.  Nothing will\n                    # ever happen to the consuming Deferred.  Tell the\n                    # encoder we're done so it can check what the producer\n                    # wrote and make sure it was right.\n                    state[0] = 2\n                    try:\n                        encoder._noMoreWritesExpected()\n                    except:\n                        # Fail the overall writeTo Deferred - something the\n                        # producer did was wrong.\n                        ultimate.errback()\n                    else:\n                        # Success - succeed the overall writeTo Deferred.\n                        ultimate.callback(None)\n                # Otherwise, the consuming Deferred already errbacked.  The\n                # producing Deferred wasn't supposed to fire, but it did\n                # anyway.  It's buggy, but there's not really anything to be\n                # done about it.  Just ignore this result.\n\n            def ebProducing(err):\n                if state == [None]:\n                    # The producing Deferred failed first.  This means the\n                    # overall writeTo Deferred is going to errback now.\n                    # Tell the encoder that we're done so it knows to reject\n                    # further writes from the producer (which should not\n                    # happen, but the producer may be buggy).\n                    state[0] = 3\n                    encoder._allowNoMoreWrites()\n                    ultimate.errback(err)\n                else:\n                    # The producing Deferred failed after the consuming\n                    # Deferred failed.  It shouldn't have, so it's buggy.\n                    # Log the exception in case anyone who can fix the code\n                    # is watching.\n                    self._log.failure(u\"Producer is buggy\", failure=err)\n\n            consuming.addErrback(ebConsuming)\n            producing.addCallbacks(cbProducing, ebProducing)\n\n            return ultimate\n\n        d = combine(finishedConsuming, finishedProducing)\n        def f(passthrough):\n            # Regardless of what happens with the overall Deferred, once it\n            # fires, the producer registered way up above the definition of\n            # combine should be unregistered.\n            transport.unregisterProducer()\n            return passthrough\n        d.addBoth(f)\n        return d\n\n\n    def _writeToEmptyBodyContentLength(self, transport):\n        \"\"\"\n        Write this request to the given transport using content-length to frame\n        the (empty) body.\n\n        @param transport: See L{writeTo}.\n        @return: See L{writeTo}.\n        \"\"\"\n        self._writeHeaders(transport, b\"Content-Length: 0\\r\\n\")\n        return succeed(None)\n\n\n    def writeTo(self, transport):\n        \"\"\"\n        Format this L{Request} as an HTTP/1.1 request and write it to the given\n        transport.  If bodyProducer is not None, it will be associated with an\n        L{IConsumer}.\n\n        @param transport: The transport to which to write.\n        @type transport: L{twisted.internet.interfaces.ITransport} provider\n\n        @return: A L{Deferred} which fires with L{None} when the request has\n            been completely written to the transport or with a L{Failure} if\n            there is any problem generating the request bytes.\n        \"\"\"\n        if self.bodyProducer is None:\n            # If the method semantics anticipate a body, include a\n            # Content-Length even if it is 0.\n            # https://tools.ietf.org/html/rfc7230#section-3.3.2\n            if self.method in (b\"PUT\", b\"POST\"):\n                self._writeToEmptyBodyContentLength(transport)\n            else:\n                self._writeHeaders(transport, None)\n        elif self.bodyProducer.length is UNKNOWN_LENGTH:\n            return self._writeToBodyProducerChunked(transport)\n        else:\n            return self._writeToBodyProducerContentLength(transport)\n\n\n    def stopWriting(self):\n        \"\"\"\n        Stop writing this request to the transport.  This can only be called\n        after C{writeTo} and before the L{Deferred} returned by C{writeTo}\n        fires.  It should cancel any asynchronous task started by C{writeTo}.\n        The L{Deferred} returned by C{writeTo} need not be fired if this method\n        is called.\n        \"\"\"\n        # If bodyProducer is None, then the Deferred returned by writeTo has\n        # fired already and this method cannot be called.\n        _callAppFunction(self.bodyProducer.stopProducing)\n\n\n\nclass LengthEnforcingConsumer:\n    \"\"\"\n    An L{IConsumer} proxy which enforces an exact length requirement on the\n    total data written to it.\n\n    @ivar _length: The number of bytes remaining to be written.\n\n    @ivar _producer: The L{IBodyProducer} which is writing to this\n        consumer.\n\n    @ivar _consumer: The consumer to which at most C{_length} bytes will be\n        forwarded.\n\n    @ivar _finished: A L{Deferred} which will be fired with a L{Failure} if too\n        many bytes are written to this consumer.\n    \"\"\"\n    def __init__(self, producer, consumer, finished):\n        self._length = producer.length\n        self._producer = producer\n        self._consumer = consumer\n        self._finished = finished\n\n\n    def _allowNoMoreWrites(self):\n        \"\"\"\n        Indicate that no additional writes are allowed.  Attempts to write\n        after calling this method will be met with an exception.\n        \"\"\"\n        self._finished = None\n\n\n    def write(self, bytes):\n        \"\"\"\n        Write C{bytes} to the underlying consumer unless\n        C{_noMoreWritesExpected} has been called or there are/have been too\n        many bytes.\n        \"\"\"\n        if self._finished is None:\n            # No writes are supposed to happen any more.  Try to convince the\n            # calling code to stop calling this method by calling its\n            # stopProducing method and then throwing an exception at it.  This\n            # exception isn't documented as part of the API because you're\n            # never supposed to expect it: only buggy code will ever receive\n            # it.\n            self._producer.stopProducing()\n            raise ExcessWrite()\n\n        if len(bytes) <= self._length:\n            self._length -= len(bytes)\n            self._consumer.write(bytes)\n        else:\n            # No synchronous exception is raised in *this* error path because\n            # we still have _finished which we can use to report the error to a\n            # better place than the direct caller of this method (some\n            # arbitrary application code).\n            _callAppFunction(self._producer.stopProducing)\n            self._finished.errback(WrongBodyLength(u\"too many bytes written\"))\n            self._allowNoMoreWrites()\n\n\n    def _noMoreWritesExpected(self):\n        \"\"\"\n        Called to indicate no more bytes will be written to this consumer.\n        Check to see that the correct number have been written.\n\n        @raise WrongBodyLength: If not enough bytes have been written.\n        \"\"\"\n        if self._finished is not None:\n            self._allowNoMoreWrites()\n            if self._length:\n                raise WrongBodyLength(u\"too few bytes written\")\n\n\n\ndef makeStatefulDispatcher(name, template):\n    \"\"\"\n    Given a I{dispatch} name and a function, return a function which can be\n    used as a method and which, when called, will call another method defined\n    on the instance and return the result.  The other method which is called is\n    determined by the value of the C{_state} attribute of the instance.\n\n    @param name: A string which is used to construct the name of the subsidiary\n        method to invoke.  The subsidiary method is named like C{'_%s_%s' %\n        (name, _state)}.\n\n    @param template: A function object which is used to give the returned\n        function a docstring.\n\n    @return: The dispatcher function.\n    \"\"\"\n    def dispatcher(self, *args, **kwargs):\n        func = getattr(self, '_' + name + '_' + self._state, None)\n        if func is None:\n            raise RuntimeError(\n                u\"%r has no %s method in state %s\" % (self, name, self._state))\n        return func(*args, **kwargs)\n    dispatcher.__doc__ = template.__doc__\n    return dispatcher\n\n\n\n# This proxy class is used only in the private constructor of the Response\n# class below, in order to prevent users relying on any property of the\n# concrete request object: they can only use what is provided by\n# IClientRequest.\n_ClientRequestProxy = proxyForInterface(IClientRequest)\n\n\n\n@implementer(IResponse)\nclass Response:\n    \"\"\"\n    A L{Response} instance describes an HTTP response received from an HTTP\n    server.\n\n    L{Response} should not be subclassed or instantiated.\n\n    @ivar _transport: See L{__init__}.\n\n    @ivar _bodyProtocol: The L{IProtocol} provider to which the body is\n        delivered.  L{None} before one has been registered with\n        C{deliverBody}.\n\n    @ivar _bodyBuffer: A C{list} of the strings passed to C{bodyDataReceived}\n        before C{deliverBody} is called.  L{None} afterwards.\n\n    @ivar _state: Indicates what state this L{Response} instance is in,\n        particularly with respect to delivering bytes from the response body\n        to an application-supplied protocol object.  This may be one of\n        C{'INITIAL'}, C{'CONNECTED'}, C{'DEFERRED_CLOSE'}, or C{'FINISHED'},\n        with the following meanings:\n\n          - INITIAL: This is the state L{Response} objects start in.  No\n            protocol has yet been provided and the underlying transport may\n            still have bytes to deliver to it.\n\n          - DEFERRED_CLOSE: If the underlying transport indicates all bytes\n            have been delivered but no application-provided protocol is yet\n            available, the L{Response} moves to this state.  Data is\n            buffered and waiting for a protocol to be delivered to.\n\n          - CONNECTED: If a protocol is provided when the state is INITIAL,\n            the L{Response} moves to this state.  Any buffered data is\n            delivered and any data which arrives from the transport\n            subsequently is given directly to the protocol.\n\n          - FINISHED: If a protocol is provided in the DEFERRED_CLOSE state,\n            the L{Response} moves to this state after delivering all\n            buffered data to the protocol.  Otherwise, if the L{Response} is\n            in the CONNECTED state, if the transport indicates there is no\n            more data, the L{Response} moves to this state.  Nothing else\n            can happen once the L{Response} is in this state.\n    @type _state: C{str}\n    \"\"\"\n\n    length = UNKNOWN_LENGTH\n\n    _bodyProtocol = None\n    _bodyFinished = False\n\n    def __init__(self, version, code, phrase, headers, _transport):\n        \"\"\"\n        @param version: HTTP version components protocol, major, minor. E.g.\n            C{(b'HTTP', 1, 1)} to mean C{b'HTTP/1.1'}.\n\n        @param code: HTTP status code.\n        @type code: L{int}\n\n        @param phrase: HTTP reason phrase, intended to give a short description\n            of the HTTP status code.\n\n        @param headers: HTTP response headers.\n        @type headers: L{twisted.web.http_headers.Headers}\n\n        @param _transport: The transport which is delivering this response.\n        \"\"\"\n        self.version = version\n        self.code = code\n        self.phrase = phrase\n        self.headers = headers\n        self._transport = _transport\n        self._bodyBuffer = []\n        self._state = 'INITIAL'\n        self.request = None\n        self.previousResponse = None\n\n\n    @classmethod\n    def _construct(cls, version, code, phrase, headers, _transport, request):\n        \"\"\"\n        Private constructor.\n\n        @param version: See L{__init__}.\n        @param code: See L{__init__}.\n        @param phrase: See L{__init__}.\n        @param headers: See L{__init__}.\n        @param _transport: See L{__init__}.\n        @param request: See L{IResponse.request}.\n\n        @return: L{Response} instance.\n        \"\"\"\n        response = Response(version, code, phrase, headers, _transport)\n        response.request = _ClientRequestProxy(request)\n        return response\n\n\n    def setPreviousResponse(self, previousResponse):\n        self.previousResponse = previousResponse\n\n\n    def deliverBody(self, protocol):\n        \"\"\"\n        Dispatch the given L{IProtocol} depending of the current state of the\n        response.\n        \"\"\"\n    deliverBody = makeStatefulDispatcher('deliverBody', deliverBody)\n\n\n    def _deliverBody_INITIAL(self, protocol):\n        \"\"\"\n        Deliver any buffered data to C{protocol} and prepare to deliver any\n        future data to it.  Move to the C{'CONNECTED'} state.\n        \"\"\"\n        protocol.makeConnection(self._transport)\n        self._bodyProtocol = protocol\n        for data in self._bodyBuffer:\n            self._bodyProtocol.dataReceived(data)\n        self._bodyBuffer = None\n\n        self._state = 'CONNECTED'\n\n        # Now that there's a protocol to consume the body, resume the\n        # transport.  It was previously paused by HTTPClientParser to avoid\n        # reading too much data before it could be handled. We need to do this\n        # after we transition our state as it may recursively lead to more data\n        # being delivered, or even the body completing.\n        self._transport.resumeProducing()\n\n\n    def _deliverBody_CONNECTED(self, protocol):\n        \"\"\"\n        It is invalid to attempt to deliver data to a protocol when it is\n        already being delivered to another protocol.\n        \"\"\"\n        raise RuntimeError(\n            u\"Response already has protocol %r, cannot deliverBody \"\n            u\"again\" % (self._bodyProtocol,))\n\n\n    def _deliverBody_DEFERRED_CLOSE(self, protocol):\n        \"\"\"\n        Deliver any buffered data to C{protocol} and then disconnect the\n        protocol.  Move to the C{'FINISHED'} state.\n        \"\"\"\n        # Unlike _deliverBody_INITIAL, there is no need to resume the\n        # transport here because all of the response data has been received\n        # already.  Some higher level code may want to resume the transport if\n        # that code expects further data to be received over it.\n\n        protocol.makeConnection(self._transport)\n\n        for data in self._bodyBuffer:\n            protocol.dataReceived(data)\n        self._bodyBuffer = None\n        protocol.connectionLost(self._reason)\n        self._state = 'FINISHED'\n\n\n    def _deliverBody_FINISHED(self, protocol):\n        \"\"\"\n        It is invalid to attempt to deliver data to a protocol after the\n        response body has been delivered to another protocol.\n        \"\"\"\n        raise RuntimeError(\n            u\"Response already finished, cannot deliverBody now.\")\n\n\n    def _bodyDataReceived(self, data):\n        \"\"\"\n        Called by HTTPClientParser with chunks of data from the response body.\n        They will be buffered or delivered to the protocol passed to\n        deliverBody.\n        \"\"\"\n    _bodyDataReceived = makeStatefulDispatcher('bodyDataReceived',\n                                               _bodyDataReceived)\n\n\n    def _bodyDataReceived_INITIAL(self, data):\n        \"\"\"\n        Buffer any data received for later delivery to a protocol passed to\n        C{deliverBody}.\n\n        Little or no data should be buffered by this method, since the\n        transport has been paused and will not be resumed until a protocol\n        is supplied.\n        \"\"\"\n        self._bodyBuffer.append(data)\n\n\n    def _bodyDataReceived_CONNECTED(self, data):\n        \"\"\"\n        Deliver any data received to the protocol to which this L{Response}\n        is connected.\n        \"\"\"\n        self._bodyProtocol.dataReceived(data)\n\n\n    def _bodyDataReceived_DEFERRED_CLOSE(self, data):\n        \"\"\"\n        It is invalid for data to be delivered after it has been indicated\n        that the response body has been completely delivered.\n        \"\"\"\n        raise RuntimeError(u\"Cannot receive body data after _bodyDataFinished\")\n\n\n    def _bodyDataReceived_FINISHED(self, data):\n        \"\"\"\n        It is invalid for data to be delivered after the response body has\n        been delivered to a protocol.\n        \"\"\"\n        raise RuntimeError(u\"Cannot receive body data after \"\n                           u\"protocol disconnected\")\n\n\n    def _bodyDataFinished(self, reason=None):\n        \"\"\"\n        Called by HTTPClientParser when no more body data is available.  If the\n        optional reason is supplied, this indicates a problem or potential\n        problem receiving all of the response body.\n        \"\"\"\n    _bodyDataFinished = makeStatefulDispatcher('bodyDataFinished',\n                                               _bodyDataFinished)\n\n\n    def _bodyDataFinished_INITIAL(self, reason=None):\n        \"\"\"\n        Move to the C{'DEFERRED_CLOSE'} state to wait for a protocol to\n        which to deliver the response body.\n        \"\"\"\n        self._state = 'DEFERRED_CLOSE'\n        if reason is None:\n            reason = Failure(ResponseDone(u\"Response body fully received\"))\n        self._reason = reason\n\n\n    def _bodyDataFinished_CONNECTED(self, reason=None):\n        \"\"\"\n        Disconnect the protocol and move to the C{'FINISHED'} state.\n        \"\"\"\n        if reason is None:\n            reason = Failure(ResponseDone(u\"Response body fully received\"))\n        self._bodyProtocol.connectionLost(reason)\n        self._bodyProtocol = None\n        self._state = 'FINISHED'\n\n\n    def _bodyDataFinished_DEFERRED_CLOSE(self):\n        \"\"\"\n        It is invalid to attempt to notify the L{Response} of the end of the\n        response body data more than once.\n        \"\"\"\n        raise RuntimeError(u\"Cannot finish body data more than once\")\n\n\n    def _bodyDataFinished_FINISHED(self):\n        \"\"\"\n        It is invalid to attempt to notify the L{Response} of the end of the\n        response body data more than once.\n        \"\"\"\n        raise RuntimeError(u\"Cannot finish body data after \"\n                           u\"protocol disconnected\")\n\n\n\n@implementer(IConsumer)\nclass ChunkedEncoder:\n    \"\"\"\n    Helper object which exposes L{IConsumer} on top of L{HTTP11ClientProtocol}\n    for streaming request bodies to the server.\n    \"\"\"\n\n    def __init__(self, transport):\n        self.transport = transport\n\n\n    def _allowNoMoreWrites(self):\n        \"\"\"\n        Indicate that no additional writes are allowed.  Attempts to write\n        after calling this method will be met with an exception.\n        \"\"\"\n        self.transport = None\n\n\n    def registerProducer(self, producer, streaming):\n        \"\"\"\n        Register the given producer with C{self.transport}.\n        \"\"\"\n        self.transport.registerProducer(producer, streaming)\n\n\n    def write(self, data):\n        \"\"\"\n        Write the given request body bytes to the transport using chunked\n        encoding.\n\n        @type data: C{bytes}\n        \"\"\"\n        if self.transport is None:\n            raise ExcessWrite()\n        self.transport.writeSequence((networkString(\"%x\\r\\n\" % len(data)),\n            data, b\"\\r\\n\"))\n\n\n    def unregisterProducer(self):\n        \"\"\"\n        Indicate that the request body is complete and finish the request.\n        \"\"\"\n        self.write(b'')\n        self.transport.unregisterProducer()\n        self._allowNoMoreWrites()\n\n\n\n@implementer(IPushProducer)\nclass TransportProxyProducer:\n    \"\"\"\n    An L{twisted.internet.interfaces.IPushProducer} implementation which\n    wraps another such thing and proxies calls to it until it is told to stop.\n\n    @ivar _producer: The wrapped L{twisted.internet.interfaces.IPushProducer}\n    provider or L{None} after this proxy has been stopped.\n    \"\"\"\n\n    # LineReceiver uses this undocumented attribute of transports to decide\n    # when to stop calling lineReceived or rawDataReceived (if it finds it to\n    # be true, it doesn't bother to deliver any more data).  Set disconnecting\n    # to False here and never change it to true so that all data is always\n    # delivered to us and so that LineReceiver doesn't fail with an\n    # AttributeError.\n    disconnecting = False\n\n    def __init__(self, producer):\n        self._producer = producer\n\n\n    def stopProxying(self):\n        \"\"\"\n        Stop forwarding calls of L{twisted.internet.interfaces.IPushProducer}\n        methods to the underlying L{twisted.internet.interfaces.IPushProducer}\n        provider.\n        \"\"\"\n        self._producer = None\n\n\n    def stopProducing(self):\n        \"\"\"\n        Proxy the stoppage to the underlying producer, unless this proxy has\n        been stopped.\n        \"\"\"\n        if self._producer is not None:\n            self._producer.stopProducing()\n\n\n    def resumeProducing(self):\n        \"\"\"\n        Proxy the resumption to the underlying producer, unless this proxy has\n        been stopped.\n        \"\"\"\n        if self._producer is not None:\n            self._producer.resumeProducing()\n\n\n    def pauseProducing(self):\n        \"\"\"\n        Proxy the pause to the underlying producer, unless this proxy has been\n        stopped.\n        \"\"\"\n        if self._producer is not None:\n            self._producer.pauseProducing()\n\n\n    def loseConnection(self):\n        \"\"\"\n        Proxy the request to lose the connection to the underlying producer,\n        unless this proxy has been stopped.\n        \"\"\"\n        if self._producer is not None:\n            self._producer.loseConnection()\n\n\n\nclass HTTP11ClientProtocol(Protocol):\n    \"\"\"\n    L{HTTP11ClientProtocol} is an implementation of the HTTP 1.1 client\n    protocol.  It supports as few features as possible.\n\n    @ivar _parser: After a request is issued, the L{HTTPClientParser} to\n        which received data making up the response to that request is\n        delivered.\n\n    @ivar _finishedRequest: After a request is issued, the L{Deferred} which\n        will fire when a L{Response} object corresponding to that request is\n        available.  This allows L{HTTP11ClientProtocol} to fail the request\n        if there is a connection or parsing problem.\n\n    @ivar _currentRequest: After a request is issued, the L{Request}\n        instance used to make that request.  This allows\n        L{HTTP11ClientProtocol} to stop request generation if necessary (for\n        example, if the connection is lost).\n\n    @ivar _transportProxy: After a request is issued, the\n        L{TransportProxyProducer} to which C{_parser} is connected.  This\n        allows C{_parser} to pause and resume the transport in a way which\n        L{HTTP11ClientProtocol} can exert some control over.\n\n    @ivar _responseDeferred: After a request is issued, the L{Deferred} from\n        C{_parser} which will fire with a L{Response} when one has been\n        received.  This is eventually chained with C{_finishedRequest}, but\n        only in certain cases to avoid double firing that Deferred.\n\n    @ivar _state: Indicates what state this L{HTTP11ClientProtocol} instance\n        is in with respect to transmission of a request and reception of a\n        response.  This may be one of the following strings:\n\n          - QUIESCENT: This is the state L{HTTP11ClientProtocol} instances\n            start in.  Nothing is happening: no request is being sent and no\n            response is being received or expected.\n\n          - TRANSMITTING: When a request is made (via L{request}), the\n            instance moves to this state.  L{Request.writeTo} has been used\n            to start to send a request but it has not yet finished.\n\n          - TRANSMITTING_AFTER_RECEIVING_RESPONSE: The server has returned a\n            complete response but the request has not yet been fully sent\n            yet.  The instance will remain in this state until the request\n            is fully sent.\n\n          - GENERATION_FAILED: There was an error while the request.  The\n            request was not fully sent to the network.\n\n          - WAITING: The request was fully sent to the network.  The\n            instance is now waiting for the response to be fully received.\n\n          - ABORTING: Application code has requested that the HTTP connection\n            be aborted.\n\n          - CONNECTION_LOST: The connection has been lost.\n    @type _state: C{str}\n\n    @ivar _abortDeferreds: A list of C{Deferred} instances that will fire when\n        the connection is lost.\n    \"\"\"\n    _state = 'QUIESCENT'\n    _parser = None\n    _finishedRequest = None\n    _currentRequest = None\n    _transportProxy = None\n    _responseDeferred = None\n    _log = Logger()\n\n\n    def __init__(self, quiescentCallback=lambda c: None):\n        self._quiescentCallback = quiescentCallback\n        self._abortDeferreds = []\n\n\n    @property\n    def state(self):\n        return self._state\n\n\n    def request(self, request):\n        \"\"\"\n        Issue C{request} over C{self.transport} and return a L{Deferred} which\n        will fire with a L{Response} instance or an error.\n\n        @param request: The object defining the parameters of the request to\n           issue.\n        @type request: L{Request}\n\n        @rtype: L{Deferred}\n        @return: The deferred may errback with L{RequestGenerationFailed} if\n            the request was not fully written to the transport due to a local\n            error.  It may errback with L{RequestTransmissionFailed} if it was\n            not fully written to the transport due to a network error.  It may\n            errback with L{ResponseFailed} if the request was sent (not\n            necessarily received) but some or all of the response was lost.  It\n            may errback with L{RequestNotSent} if it is not possible to send\n            any more requests using this L{HTTP11ClientProtocol}.\n        \"\"\"\n        if self._state != 'QUIESCENT':\n            return fail(RequestNotSent())\n\n        self._state = 'TRANSMITTING'\n        _requestDeferred = maybeDeferred(request.writeTo, self.transport)\n\n        def cancelRequest(ign):\n            # Explicitly cancel the request's deferred if it's still trying to\n            # write when this request is cancelled.\n            if self._state in (\n                    'TRANSMITTING', 'TRANSMITTING_AFTER_RECEIVING_RESPONSE'):\n                _requestDeferred.cancel()\n            else:\n                self.transport.abortConnection()\n                self._disconnectParser(Failure(CancelledError()))\n        self._finishedRequest = Deferred(cancelRequest)\n\n        # Keep track of the Request object in case we need to call stopWriting\n        # on it.\n        self._currentRequest = request\n\n        self._transportProxy = TransportProxyProducer(self.transport)\n        self._parser = HTTPClientParser(request, self._finishResponse)\n        self._parser.makeConnection(self._transportProxy)\n        self._responseDeferred = self._parser._responseDeferred\n\n        def cbRequestWritten(ignored):\n            if self._state == 'TRANSMITTING':\n                self._state = 'WAITING'\n                self._responseDeferred.chainDeferred(self._finishedRequest)\n\n        def ebRequestWriting(err):\n            if self._state == 'TRANSMITTING':\n                self._state = 'GENERATION_FAILED'\n                self.transport.abortConnection()\n                self._finishedRequest.errback(\n                    Failure(RequestGenerationFailed([err])))\n            else:\n                self._log.failure(\n                    u'Error writing request, but not in valid state '\n                    u'to finalize request: {state}',\n                    failure=err,\n                    state=self._state\n                )\n\n        _requestDeferred.addCallbacks(cbRequestWritten, ebRequestWriting)\n\n        return self._finishedRequest\n\n\n    def _finishResponse(self, rest):\n        \"\"\"\n        Called by an L{HTTPClientParser} to indicate that it has parsed a\n        complete response.\n\n        @param rest: A C{bytes} giving any trailing bytes which were given to\n            the L{HTTPClientParser} which were not part of the response it\n            was parsing.\n        \"\"\"\n    _finishResponse = makeStatefulDispatcher('finishResponse', _finishResponse)\n\n\n    def _finishResponse_WAITING(self, rest):\n        # Currently the rest parameter is ignored. Don't forget to use it if\n        # we ever add support for pipelining. And maybe check what trailers\n        # mean.\n        if self._state == 'WAITING':\n            self._state = 'QUIESCENT'\n        else:\n            # The server sent the entire response before we could send the\n            # whole request.  That sucks.  Oh well.  Fire the request()\n            # Deferred with the response.  But first, make sure that if the\n            # request does ever finish being written that it won't try to fire\n            # that Deferred.\n            self._state = 'TRANSMITTING_AFTER_RECEIVING_RESPONSE'\n            self._responseDeferred.chainDeferred(self._finishedRequest)\n\n        # This will happen if we're being called due to connection being lost;\n        # if so, no need to disconnect parser again, or to call\n        # _quiescentCallback.\n        if self._parser is None:\n            return\n\n        reason = ConnectionDone(u\"synthetic!\")\n        connHeaders = self._parser.connHeaders.getRawHeaders(b'connection', ())\n        if ((b'close' in connHeaders) or self._state != \"QUIESCENT\" or\n            not self._currentRequest.persistent):\n            self._giveUp(Failure(reason))\n        else:\n            # Just in case we had paused the transport, resume it before\n            # considering it quiescent again.\n            self.transport.resumeProducing()\n\n            # We call the quiescent callback first, to ensure connection gets\n            # added back to connection pool before we finish the request.\n            try:\n                self._quiescentCallback(self)\n            except:\n                # If callback throws exception, just log it and disconnect;\n                # keeping persistent connections around is an optimisation:\n                self._log.failure('')\n                self.transport.loseConnection()\n            self._disconnectParser(reason)\n\n\n    _finishResponse_TRANSMITTING = _finishResponse_WAITING\n\n\n    def _disconnectParser(self, reason):\n        \"\"\"\n        If there is still a parser, call its C{connectionLost} method with the\n        given reason.  If there is not, do nothing.\n\n        @type reason: L{Failure}\n        \"\"\"\n        if self._parser is not None:\n            parser = self._parser\n            self._parser = None\n            self._currentRequest = None\n            self._finishedRequest = None\n            self._responseDeferred = None\n\n            # The parser is no longer allowed to do anything to the real\n            # transport.  Stop proxying from the parser's transport to the real\n            # transport before telling the parser it's done so that it can't do\n            # anything.\n            self._transportProxy.stopProxying()\n            self._transportProxy = None\n            parser.connectionLost(reason)\n\n\n    def _giveUp(self, reason):\n        \"\"\"\n        Lose the underlying connection and disconnect the parser with the given\n        L{Failure}.\n\n        Use this method instead of calling the transport's loseConnection\n        method directly otherwise random things will break.\n        \"\"\"\n        self.transport.loseConnection()\n        self._disconnectParser(reason)\n\n\n    def dataReceived(self, bytes):\n        \"\"\"\n        Handle some stuff from some place.\n        \"\"\"\n        try:\n            self._parser.dataReceived(bytes)\n        except:\n            self._giveUp(Failure())\n\n\n    def connectionLost(self, reason):\n        \"\"\"\n        The underlying transport went away.  If appropriate, notify the parser\n        object.\n        \"\"\"\n    connectionLost = makeStatefulDispatcher('connectionLost', connectionLost)\n\n\n    def _connectionLost_QUIESCENT(self, reason):\n        \"\"\"\n        Nothing is currently happening.  Move to the C{'CONNECTION_LOST'}\n        state but otherwise do nothing.\n        \"\"\"\n        self._state = 'CONNECTION_LOST'\n\n\n    def _connectionLost_GENERATION_FAILED(self, reason):\n        \"\"\"\n        The connection was in an inconsistent state.  Move to the\n        C{'CONNECTION_LOST'} state but otherwise do nothing.\n        \"\"\"\n        self._state = 'CONNECTION_LOST'\n\n\n    def _connectionLost_TRANSMITTING(self, reason):\n        \"\"\"\n        Fail the L{Deferred} for the current request, notify the request\n        object that it does not need to continue transmitting itself, and\n        move to the C{'CONNECTION_LOST'} state.\n        \"\"\"\n        self._state = 'CONNECTION_LOST'\n        self._finishedRequest.errback(\n            Failure(RequestTransmissionFailed([reason])))\n        del self._finishedRequest\n\n        # Tell the request that it should stop bothering now.\n        self._currentRequest.stopWriting()\n\n\n    def _connectionLost_TRANSMITTING_AFTER_RECEIVING_RESPONSE(self, reason):\n        \"\"\"\n        Move to the C{'CONNECTION_LOST'} state.\n        \"\"\"\n        self._state = 'CONNECTION_LOST'\n\n\n    def _connectionLost_WAITING(self, reason):\n        \"\"\"\n        Disconnect the response parser so that it can propagate the event as\n        necessary (for example, to call an application protocol's\n        C{connectionLost} method, or to fail a request L{Deferred}) and move\n        to the C{'CONNECTION_LOST'} state.\n        \"\"\"\n        self._disconnectParser(reason)\n        self._state = 'CONNECTION_LOST'\n\n\n    def _connectionLost_ABORTING(self, reason):\n        \"\"\"\n        Disconnect the response parser with a L{ConnectionAborted} failure, and\n        move to the C{'CONNECTION_LOST'} state.\n        \"\"\"\n        self._disconnectParser(Failure(ConnectionAborted()))\n        self._state = 'CONNECTION_LOST'\n        for d in self._abortDeferreds:\n            d.callback(None)\n        self._abortDeferreds = []\n\n\n    def abort(self):\n        \"\"\"\n        Close the connection and cause all outstanding L{request} L{Deferred}s\n        to fire with an error.\n        \"\"\"\n        if self._state == \"CONNECTION_LOST\":\n            return succeed(None)\n        self.transport.loseConnection()\n        self._state = 'ABORTING'\n        d = Deferred()\n        self._abortDeferreds.append(d)\n        return d\n", "patch": "@@ -29,6 +29,8 @@\n from __future__ import division, absolute_import\n __metaclass__ = type\n \n+import re\n+\n from zope.interface import implementer\n \n from twisted.python.compat import networkString\n@@ -579,6 +581,74 @@ def connectionLost(self, reason):\n \n \n \n+_VALID_METHOD = re.compile(\n+    br\"\\A[%s]+\\Z\" % (\n+        bytes().join(\n+            (\n+                b\"!\", b\"#\", b\"$\", b\"%\", b\"&\", b\"'\", b\"*\",\n+                b\"+\", b\"-\", b\".\", b\"^\", b\"_\", b\"`\", b\"|\", b\"~\",\n+                b\"\\x30-\\x39\",\n+                b\"\\x41-\\x5a\",\n+                b\"\\x61-\\x7A\",\n+            ),\n+        ),\n+    ),\n+)\n+\n+\n+\n+def _ensureValidMethod(method):\n+    \"\"\"\n+    An HTTP method is an HTTP token, which consists of any visible\n+    ASCII character that is not a delimiter (i.e. one of\n+    C{\"(),/:;<=>?@[\\\\]{}}.)\n+\n+    @param method: the method to check\n+    @type method: L{bytes}\n+\n+    @return: the method if it is valid\n+    @rtype: L{bytes}\n+\n+    @raise ValueError: if the method is not valid\n+\n+    @see: U{https://tools.ietf.org/html/rfc7230#section-3.1.1},\n+        U{https://tools.ietf.org/html/rfc7230#section-3.2.6},\n+        U{https://tools.ietf.org/html/rfc5234#appendix-B.1}\n+    \"\"\"\n+    if _VALID_METHOD.match(method):\n+        return method\n+    raise ValueError(\"Invalid method {!r}\".format(method))\n+\n+\n+\n+_VALID_URI = re.compile(br'\\A[\\x21-\\x7e]+\\Z')\n+\n+\n+\n+def _ensureValidURI(uri):\n+    \"\"\"\n+    A valid URI cannot contain control characters (i.e., characters\n+    between 0-32, inclusive and 127) or non-ASCII characters (i.e.,\n+    characters with values between 128-255, inclusive).\n+\n+    @param uri: the URI to check\n+    @type uri: L{bytes}\n+\n+    @return: the URI if it is valid\n+    @rtype: L{bytes}\n+\n+    @raise ValueError: if the URI is not valid\n+\n+    @see: U{https://tools.ietf.org/html/rfc3986#section-3.3},\n+        U{https://tools.ietf.org/html/rfc3986#appendix-A},\n+        U{https://tools.ietf.org/html/rfc5234#appendix-B.1}\n+    \"\"\"\n+    if _VALID_URI.match(uri):\n+        return uri\n+    raise ValueError(\"Invalid URI {!r}\".format(uri))\n+\n+\n+\n @implementer(IClientRequest)\n class Request:\n     \"\"\"\n@@ -618,8 +688,8 @@ def __init__(self, method, uri, headers, bodyProducer, persistent=False):\n             connection, defaults to C{False}.\n         @type persistent: L{bool}\n         \"\"\"\n-        self.method = method\n-        self.uri = uri\n+        self.method = _ensureValidMethod(method)\n+        self.uri = _ensureValidURI(uri)\n         self.headers = headers\n         self.bodyProducer = bodyProducer\n         self.persistent = persistent\n@@ -664,8 +734,15 @@ def _writeHeaders(self, transport, TEorCL):\n         # method would probably be good.  It would be nice if this method\n         # weren't limited to issuing HTTP/1.1 requests.\n         requestLines = []\n-        requestLines.append(b' '.join([self.method, self.uri,\n-            b'HTTP/1.1\\r\\n']))\n+        requestLines.append(\n+            b' '.join(\n+                [\n+                    _ensureValidMethod(self.method),\n+                    _ensureValidURI(self.uri),\n+                    b'HTTP/1.1\\r\\n',\n+                ]\n+            ),\n+        )\n         if not self.persistent:\n             requestLines.append(b'Connection: close\\r\\n')\n         if TEorCL is not None:", "file_path": "files/2019_6\\157", "file_language": "py", "file_name": "src/twisted/web/_newclient.py", "outdated_file_modify": 0, "outdated_file_before": 0, "outdated_file_after": 0, "llm_check": 1, "static_check": 0, "static": {"rats": [false, []], "semgrep": [false, []]}, "target": -1, "function_before": [], "function_after": []}, {"raw_url": "https://github.com/twisted/twisted/raw/6c61fc4503ae39ab8ecee52d10f10ee2c371d7e2/src%2Ftwisted%2Fweb%2Fclient.py", "code": "# -*- test-case-name: twisted.web.test.test_webclient,twisted.web.test.test_agent -*-\n# Copyright (c) Twisted Matrix Laboratories.\n# See LICENSE for details.\n\n\"\"\"\nHTTP client.\n\"\"\"\n\nfrom __future__ import division, absolute_import\n\nimport os\nimport collections\nimport warnings\n\ntry:\n    from urlparse import urlunparse, urljoin, urldefrag\nexcept ImportError:\n    from urllib.parse import urljoin, urldefrag\n    from urllib.parse import urlunparse as _urlunparse\n\n    def urlunparse(parts):\n        result = _urlunparse(tuple([p.decode(\"charmap\") for p in parts]))\n        return result.encode(\"charmap\")\n\nimport zlib\nfrom functools import wraps\n\nfrom zope.interface import implementer\n\nfrom twisted.python.compat import _PY3, networkString\nfrom twisted.python.compat import nativeString, intToBytes, unicode, itervalues\nfrom twisted.python.deprecate import deprecatedModuleAttribute, deprecated\nfrom twisted.python.failure import Failure\nfrom incremental import Version\n\nfrom twisted.web.iweb import IPolicyForHTTPS, IAgentEndpointFactory\nfrom twisted.python.deprecate import getDeprecationWarningString\nfrom twisted.web import http\nfrom twisted.internet import defer, protocol, task, reactor\nfrom twisted.internet.abstract import isIPv6Address\nfrom twisted.internet.interfaces import IProtocol, IOpenSSLContextFactory\nfrom twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS\nfrom twisted.python.util import InsensitiveDict\nfrom twisted.python.components import proxyForInterface\nfrom twisted.web import error\nfrom twisted.web.iweb import UNKNOWN_LENGTH, IAgent, IBodyProducer, IResponse\nfrom twisted.web.http_headers import Headers\nfrom twisted.logger import Logger\n\nfrom twisted.web._newclient import _ensureValidURI, _ensureValidMethod\n\n\n\nclass PartialDownloadError(error.Error):\n    \"\"\"\n    Page was only partially downloaded, we got disconnected in middle.\n\n    @ivar response: All of the response body which was downloaded.\n    \"\"\"\n\n\nclass HTTPPageGetter(http.HTTPClient):\n    \"\"\"\n    Gets a resource via HTTP, then quits.\n\n    Typically used with L{HTTPClientFactory}.  Note that this class does not, by\n    itself, do anything with the response.  If you want to download a resource\n    into a file, use L{HTTPPageDownloader} instead.\n\n    @ivar _completelyDone: A boolean indicating whether any further requests are\n        necessary after this one completes in order to provide a result to\n        C{self.factory.deferred}.  If it is C{False}, then a redirect is going\n        to be followed.  Otherwise, this protocol's connection is the last one\n        before firing the result Deferred.  This is used to make sure the result\n        Deferred is only fired after the connection is cleaned up.\n    \"\"\"\n\n    quietLoss = 0\n    followRedirect = True\n    failed = 0\n\n    _completelyDone = True\n\n    _specialHeaders = set(\n        (b'host', b'user-agent', b'cookie', b'content-length'),\n    )\n\n    def connectionMade(self):\n        method = _ensureValidMethod(getattr(self.factory, 'method', b'GET'))\n        self.sendCommand(method, _ensureValidURI(self.factory.path))\n        if self.factory.scheme == b'http' and self.factory.port != 80:\n            host = self.factory.host + b':' + intToBytes(self.factory.port)\n        elif self.factory.scheme == b'https' and self.factory.port != 443:\n            host = self.factory.host + b':' + intToBytes(self.factory.port)\n        else:\n            host = self.factory.host\n        self.sendHeader(b'Host', self.factory.headers.get(b\"host\", host))\n        self.sendHeader(b'User-Agent', self.factory.agent)\n        data = getattr(self.factory, 'postdata', None)\n        if data is not None:\n            self.sendHeader(b\"Content-Length\", intToBytes(len(data)))\n\n        cookieData = []\n        for (key, value) in self.factory.headers.items():\n            if key.lower() not in self._specialHeaders:\n                # we calculated it on our own\n                self.sendHeader(key, value)\n            if key.lower() == b'cookie':\n                cookieData.append(value)\n        for cookie, cookval in self.factory.cookies.items():\n            cookieData.append(cookie + b'=' + cookval)\n        if cookieData:\n            self.sendHeader(b'Cookie', b'; '.join(cookieData))\n        self.endHeaders()\n        self.headers = {}\n\n        if data is not None:\n            self.transport.write(data)\n\n    def handleHeader(self, key, value):\n        \"\"\"\n        Called every time a header is received. Stores the header information\n        as key-value pairs in the C{headers} attribute.\n\n        @type key: C{str}\n        @param key: An HTTP header field name.\n\n        @type value: C{str}\n        @param value: An HTTP header field value.\n        \"\"\"\n        key = key.lower()\n        l = self.headers.setdefault(key, [])\n        l.append(value)\n\n    def handleStatus(self, version, status, message):\n        \"\"\"\n        Handle the HTTP status line.\n\n        @param version: The HTTP version.\n        @type version: L{bytes}\n        @param status: The HTTP status code, an integer represented as a\n            bytestring.\n        @type status: L{bytes}\n        @param message: The HTTP status message.\n        @type message: L{bytes}\n        \"\"\"\n        self.version, self.status, self.message = version, status, message\n        self.factory.gotStatus(version, status, message)\n\n    def handleEndHeaders(self):\n        self.factory.gotHeaders(self.headers)\n        m = getattr(self, 'handleStatus_' + nativeString(self.status),\n                    self.handleStatusDefault)\n        m()\n\n    def handleStatus_200(self):\n        pass\n\n    handleStatus_201 = lambda self: self.handleStatus_200()\n    handleStatus_202 = lambda self: self.handleStatus_200()\n\n    def handleStatusDefault(self):\n        self.failed = 1\n\n    def handleStatus_301(self):\n        l = self.headers.get(b'location')\n        if not l:\n            self.handleStatusDefault()\n            return\n        url = l[0]\n        if self.followRedirect:\n            self.factory._redirectCount += 1\n            if self.factory._redirectCount >= self.factory.redirectLimit:\n                err = error.InfiniteRedirection(\n                    self.status,\n                    b'Infinite redirection detected',\n                    location=url)\n                self.factory.noPage(Failure(err))\n                self.quietLoss = True\n                self.transport.loseConnection()\n                return\n\n            self._completelyDone = False\n            self.factory.setURL(url)\n\n            if self.factory.scheme == b'https':\n                from twisted.internet import ssl\n                contextFactory = ssl.ClientContextFactory()\n                reactor.connectSSL(nativeString(self.factory.host),\n                                   self.factory.port,\n                                   self.factory, contextFactory)\n            else:\n                reactor.connectTCP(nativeString(self.factory.host),\n                                   self.factory.port,\n                                   self.factory)\n        else:\n            self.handleStatusDefault()\n            self.factory.noPage(\n                Failure(\n                    error.PageRedirect(\n                        self.status, self.message, location = url)))\n        self.quietLoss = True\n        self.transport.loseConnection()\n\n    def handleStatus_302(self):\n        if self.afterFoundGet:\n            self.handleStatus_303()\n        else:\n            self.handleStatus_301()\n\n\n    def handleStatus_303(self):\n        self.factory.method = b'GET'\n        self.handleStatus_301()\n\n\n    def connectionLost(self, reason):\n        \"\"\"\n        When the connection used to issue the HTTP request is closed, notify the\n        factory if we have not already, so it can produce a result.\n        \"\"\"\n        if not self.quietLoss:\n            http.HTTPClient.connectionLost(self, reason)\n            self.factory.noPage(reason)\n        if self._completelyDone:\n            # Only if we think we're completely done do we tell the factory that\n            # we're \"disconnected\".  This way when we're following redirects,\n            # only the last protocol used will fire the _disconnectedDeferred.\n            self.factory._disconnectedDeferred.callback(None)\n\n\n    def handleResponse(self, response):\n        if self.quietLoss:\n            return\n        if self.failed:\n            self.factory.noPage(\n                Failure(\n                    error.Error(\n                        self.status, self.message, response)))\n        if self.factory.method == b'HEAD':\n            # Callback with empty string, since there is never a response\n            # body for HEAD requests.\n            self.factory.page(b'')\n        elif self.length != None and self.length != 0:\n            self.factory.noPage(Failure(\n                PartialDownloadError(self.status, self.message, response)))\n        else:\n            self.factory.page(response)\n        # server might be stupid and not close connection. admittedly\n        # the fact we do only one request per connection is also\n        # stupid...\n        self.transport.loseConnection()\n\n    def timeout(self):\n        self.quietLoss = True\n        self.transport.abortConnection()\n        self.factory.noPage(defer.TimeoutError(\"Getting %s took longer than %s seconds.\" % (self.factory.url, self.factory.timeout)))\n\n\nclass HTTPPageDownloader(HTTPPageGetter):\n\n    transmittingPage = 0\n\n    def handleStatus_200(self, partialContent=0):\n        HTTPPageGetter.handleStatus_200(self)\n        self.transmittingPage = 1\n        self.factory.pageStart(partialContent)\n\n    def handleStatus_206(self):\n        self.handleStatus_200(partialContent=1)\n\n    def handleResponsePart(self, data):\n        if self.transmittingPage:\n            self.factory.pagePart(data)\n\n    def handleResponseEnd(self):\n        if self.length:\n            self.transmittingPage = 0\n            self.factory.noPage(\n                Failure(\n                    PartialDownloadError(self.status)))\n        if self.transmittingPage:\n            self.factory.pageEnd()\n            self.transmittingPage = 0\n        if self.failed:\n            self.factory.noPage(\n                Failure(\n                    error.Error(\n                        self.status, self.message, None)))\n            self.transport.loseConnection()\n\n\nclass HTTPClientFactory(protocol.ClientFactory):\n    \"\"\"Download a given URL.\n\n    @type deferred: Deferred\n    @ivar deferred: A Deferred that will fire when the content has\n          been retrieved. Once this is fired, the ivars `status', `version',\n          and `message' will be set.\n\n    @type status: bytes\n    @ivar status: The status of the response.\n\n    @type version: bytes\n    @ivar version: The version of the response.\n\n    @type message: bytes\n    @ivar message: The text message returned with the status.\n\n    @type response_headers: dict\n    @ivar response_headers: The headers that were specified in the\n          response from the server.\n\n    @type method: bytes\n    @ivar method: The HTTP method to use in the request.  This should be one of\n        OPTIONS, GET, HEAD, POST, PUT, DELETE, TRACE, or CONNECT (case\n        matters).  Other values may be specified if the server being contacted\n        supports them.\n\n    @type redirectLimit: int\n    @ivar redirectLimit: The maximum number of HTTP redirects that can occur\n          before it is assumed that the redirection is endless.\n\n    @type afterFoundGet: C{bool}\n    @ivar afterFoundGet: Deviate from the HTTP 1.1 RFC by handling redirects\n        the same way as most web browsers; if the request method is POST and a\n        302 status is encountered, the redirect is followed with a GET method\n\n    @type _redirectCount: int\n    @ivar _redirectCount: The current number of HTTP redirects encountered.\n\n    @ivar _disconnectedDeferred: A L{Deferred} which only fires after the last\n        connection associated with the request (redirects may cause multiple\n        connections to be required) has closed.  The result Deferred will only\n        fire after this Deferred, so that callers can be assured that there are\n        no more event sources in the reactor once they get the result.\n    \"\"\"\n\n    protocol = HTTPPageGetter\n\n    url = None\n    scheme = None\n    host = b''\n    port = None\n    path = None\n\n    def __init__(self, url, method=b'GET', postdata=None, headers=None,\n                 agent=b\"Twisted PageGetter\", timeout=0, cookies=None,\n                 followRedirect=True, redirectLimit=20,\n                 afterFoundGet=False):\n        self.followRedirect = followRedirect\n        self.redirectLimit = redirectLimit\n        self._redirectCount = 0\n        self.timeout = timeout\n        self.agent = agent\n        self.afterFoundGet = afterFoundGet\n        if cookies is None:\n            cookies = {}\n        self.cookies = cookies\n        if headers is not None:\n            self.headers = InsensitiveDict(headers)\n        else:\n            self.headers = InsensitiveDict()\n        if postdata is not None:\n            self.headers.setdefault(b'Content-Length',\n                                    intToBytes(len(postdata)))\n            # just in case a broken http/1.1 decides to keep connection alive\n            self.headers.setdefault(b\"connection\", b\"close\")\n        self.postdata = postdata\n        self.method = _ensureValidMethod(method)\n\n        self.setURL(url)\n\n        self.waiting = 1\n        self._disconnectedDeferred = defer.Deferred()\n        self.deferred = defer.Deferred()\n        # Make sure the first callback on the result Deferred pauses the\n        # callback chain until the request connection is closed.\n        self.deferred.addBoth(self._waitForDisconnect)\n        self.response_headers = None\n\n\n    def _waitForDisconnect(self, passthrough):\n        \"\"\"\n        Chain onto the _disconnectedDeferred, preserving C{passthrough}, so that\n        the result is only available after the associated connection has been\n        closed.\n        \"\"\"\n        self._disconnectedDeferred.addCallback(lambda ignored: passthrough)\n        return self._disconnectedDeferred\n\n\n    def __repr__(self):\n        return \"<%s: %s>\" % (self.__class__.__name__, self.url)\n\n    def setURL(self, url):\n        _ensureValidURI(url.strip())\n        self.url = url\n        uri = URI.fromBytes(url)\n        if uri.scheme and uri.host:\n            self.scheme = uri.scheme\n            self.host = uri.host\n            self.port = uri.port\n        self.path = uri.originForm\n\n    def buildProtocol(self, addr):\n        p = protocol.ClientFactory.buildProtocol(self, addr)\n        p.followRedirect = self.followRedirect\n        p.afterFoundGet = self.afterFoundGet\n        if self.timeout:\n            timeoutCall = reactor.callLater(self.timeout, p.timeout)\n            self.deferred.addBoth(self._cancelTimeout, timeoutCall)\n        return p\n\n    def _cancelTimeout(self, result, timeoutCall):\n        if timeoutCall.active():\n            timeoutCall.cancel()\n        return result\n\n    def gotHeaders(self, headers):\n        \"\"\"\n        Parse the response HTTP headers.\n\n        @param headers: The response HTTP headers.\n        @type headers: L{dict}\n        \"\"\"\n        self.response_headers = headers\n        if b'set-cookie' in headers:\n            for cookie in headers[b'set-cookie']:\n                if b'=' in cookie:\n                    cookparts = cookie.split(b';')\n                    cook = cookparts[0]\n                    cook.lstrip()\n                    k, v = cook.split(b'=', 1)\n                    self.cookies[k.lstrip()] = v.lstrip()\n\n    def gotStatus(self, version, status, message):\n        \"\"\"\n        Set the status of the request on us.\n\n        @param version: The HTTP version.\n        @type version: L{bytes}\n        @param status: The HTTP status code, an integer represented as a\n            bytestring.\n        @type status: L{bytes}\n        @param message: The HTTP status message.\n        @type message: L{bytes}\n        \"\"\"\n        self.version, self.status, self.message = version, status, message\n\n    def page(self, page):\n        if self.waiting:\n            self.waiting = 0\n            self.deferred.callback(page)\n\n    def noPage(self, reason):\n        if self.waiting:\n            self.waiting = 0\n            self.deferred.errback(reason)\n\n    def clientConnectionFailed(self, _, reason):\n        \"\"\"\n        When a connection attempt fails, the request cannot be issued.  If no\n        result has yet been provided to the result Deferred, provide the\n        connection failure reason as an error result.\n        \"\"\"\n        if self.waiting:\n            self.waiting = 0\n            # If the connection attempt failed, there is nothing more to\n            # disconnect, so just fire that Deferred now.\n            self._disconnectedDeferred.callback(None)\n            self.deferred.errback(reason)\n\n\n\nclass HTTPDownloader(HTTPClientFactory):\n    \"\"\"\n    Download to a file.\n    \"\"\"\n    protocol = HTTPPageDownloader\n    value = None\n    _log = Logger()\n\n    def __init__(self, url, fileOrName,\n                 method=b'GET', postdata=None, headers=None,\n                 agent=b\"Twisted client\", supportPartial=False,\n                 timeout=0, cookies=None, followRedirect=True,\n                 redirectLimit=20, afterFoundGet=False):\n        self.requestedPartial = 0\n        if isinstance(fileOrName, (str, unicode)):\n            self.fileName = fileOrName\n            self.file = None\n            if supportPartial and os.path.exists(self.fileName):\n                fileLength = os.path.getsize(self.fileName)\n                if fileLength:\n                    self.requestedPartial = fileLength\n                    if headers == None:\n                        headers = {}\n                    headers[b\"range\"] = b\"bytes=\" + intToBytes(fileLength) + b\"-\"\n        else:\n            self.file = fileOrName\n        HTTPClientFactory.__init__(\n            self, url, method=method, postdata=postdata, headers=headers,\n            agent=agent, timeout=timeout, cookies=cookies,\n            followRedirect=followRedirect, redirectLimit=redirectLimit,\n            afterFoundGet=afterFoundGet)\n\n\n    def gotHeaders(self, headers):\n        HTTPClientFactory.gotHeaders(self, headers)\n        if self.requestedPartial:\n            contentRange = headers.get(b\"content-range\", None)\n            if not contentRange:\n                # server doesn't support partial requests, oh well\n                self.requestedPartial = 0\n                return\n            start, end, realLength = http.parseContentRange(contentRange[0])\n            if start != self.requestedPartial:\n                # server is acting weirdly\n                self.requestedPartial = 0\n\n\n    def openFile(self, partialContent):\n        if partialContent:\n            file = open(self.fileName, 'rb+')\n            file.seek(0, 2)\n        else:\n            file = open(self.fileName, 'wb')\n        return file\n\n    def pageStart(self, partialContent):\n        \"\"\"Called on page download start.\n\n        @param partialContent: tells us if the download is partial download we requested.\n        \"\"\"\n        if partialContent and not self.requestedPartial:\n            raise ValueError(\"we shouldn't get partial content response if we didn't want it!\")\n        if self.waiting:\n            try:\n                if not self.file:\n                    self.file = self.openFile(partialContent)\n            except IOError:\n                #raise\n                self.deferred.errback(Failure())\n\n    def pagePart(self, data):\n        if not self.file:\n            return\n        try:\n            self.file.write(data)\n        except IOError:\n            #raise\n            self.file = None\n            self.deferred.errback(Failure())\n\n\n    def noPage(self, reason):\n        \"\"\"\n        Close the storage file and errback the waiting L{Deferred} with the\n        given reason.\n        \"\"\"\n        if self.waiting:\n            self.waiting = 0\n            if self.file:\n                try:\n                    self.file.close()\n                except:\n                    self._log.failure(\"Error closing HTTPDownloader file\")\n            self.deferred.errback(reason)\n\n\n    def pageEnd(self):\n        self.waiting = 0\n        if not self.file:\n            return\n        try:\n            self.file.close()\n        except IOError:\n            self.deferred.errback(Failure())\n            return\n        self.deferred.callback(self.value)\n\n\n\nclass URI(object):\n    \"\"\"\n    A URI object.\n\n    @see: U{https://tools.ietf.org/html/draft-ietf-httpbis-p1-messaging-21}\n    \"\"\"\n    def __init__(self, scheme, netloc, host, port, path, params, query,\n                 fragment):\n        \"\"\"\n        @type scheme: L{bytes}\n        @param scheme: URI scheme specifier.\n\n        @type netloc: L{bytes}\n        @param netloc: Network location component.\n\n        @type host: L{bytes}\n        @param host: Host name. For IPv6 address literals the brackets are\n            stripped.\n\n        @type port: L{int}\n        @param port: Port number.\n\n        @type path: L{bytes}\n        @param path: Hierarchical path.\n\n        @type params: L{bytes}\n        @param params: Parameters for last path segment.\n\n        @type query: L{bytes}\n        @param query: Query string.\n\n        @type fragment: L{bytes}\n        @param fragment: Fragment identifier.\n        \"\"\"\n        self.scheme = scheme\n        self.netloc = netloc\n        self.host = host.strip(b'[]')\n        self.port = port\n        self.path = path\n        self.params = params\n        self.query = query\n        self.fragment = fragment\n\n\n    @classmethod\n    def fromBytes(cls, uri, defaultPort=None):\n        \"\"\"\n        Parse the given URI into a L{URI}.\n\n        @type uri: C{bytes}\n        @param uri: URI to parse.\n\n        @type defaultPort: C{int} or L{None}\n        @param defaultPort: An alternate value to use as the port if the URI\n            does not include one.\n\n        @rtype: L{URI}\n        @return: Parsed URI instance.\n        \"\"\"\n        uri = uri.strip()\n        scheme, netloc, path, params, query, fragment = http.urlparse(uri)\n\n        if defaultPort is None:\n            if scheme == b'https':\n                defaultPort = 443\n            else:\n                defaultPort = 80\n\n        if b':' in netloc:\n            host, port = netloc.rsplit(b':', 1)\n            try:\n                port = int(port)\n            except ValueError:\n                host, port = netloc, defaultPort\n        else:\n            host, port = netloc, defaultPort\n        return cls(scheme, netloc, host, port, path, params, query, fragment)\n\n\n    def toBytes(self):\n        \"\"\"\n        Assemble the individual parts of the I{URI} into a fully formed I{URI}.\n\n        @rtype: C{bytes}\n        @return: A fully formed I{URI}.\n        \"\"\"\n        return urlunparse(\n            (self.scheme, self.netloc, self.path, self.params, self.query,\n             self.fragment))\n\n\n    @property\n    def originForm(self):\n        \"\"\"\n        The absolute I{URI} path including I{URI} parameters, query string and\n        fragment identifier.\n\n        @see: U{https://tools.ietf.org/html/draft-ietf-httpbis-p1-messaging-21#section-5.3}\n\n        @return: The absolute path in original form.\n        @rtype: L{bytes}\n        \"\"\"\n        # The HTTP bis draft says the origin form should not include the\n        # fragment.\n        path = urlunparse(\n            (b'', b'', self.path, self.params, self.query, b''))\n        if path == b'':\n            path = b'/'\n        return path\n\n\n\ndef _urljoin(base, url):\n    \"\"\"\n    Construct a full (\"absolute\") URL by combining a \"base URL\" with another\n    URL. Informally, this uses components of the base URL, in particular the\n    addressing scheme, the network location and (part of) the path, to provide\n    missing components in the relative URL.\n\n    Additionally, the fragment identifier is preserved according to the HTTP\n    1.1 bis draft.\n\n    @type base: C{bytes}\n    @param base: Base URL.\n\n    @type url: C{bytes}\n    @param url: URL to combine with C{base}.\n\n    @return: An absolute URL resulting from the combination of C{base} and\n        C{url}.\n\n    @see: L{urlparse.urljoin}\n\n    @see: U{https://tools.ietf.org/html/draft-ietf-httpbis-p2-semantics-22#section-7.1.2}\n    \"\"\"\n    base, baseFrag = urldefrag(base)\n    url, urlFrag = urldefrag(urljoin(base, url))\n    return urljoin(url, b'#' + (urlFrag or baseFrag))\n\n\n\ndef _makeGetterFactory(url, factoryFactory, contextFactory=None,\n                       *args, **kwargs):\n    \"\"\"\n    Create and connect an HTTP page getting factory.\n\n    Any additional positional or keyword arguments are used when calling\n    C{factoryFactory}.\n\n    @param factoryFactory: Factory factory that is called with C{url}, C{args}\n        and C{kwargs} to produce the getter\n\n    @param contextFactory: Context factory to use when creating a secure\n        connection, defaulting to L{None}\n\n    @return: The factory created by C{factoryFactory}\n    \"\"\"\n    uri = URI.fromBytes(_ensureValidURI(url.strip()))\n    factory = factoryFactory(url, *args, **kwargs)\n    if uri.scheme == b'https':\n        from twisted.internet import ssl\n        if contextFactory is None:\n            contextFactory = ssl.ClientContextFactory()\n        reactor.connectSSL(\n            nativeString(uri.host), uri.port, factory, contextFactory)\n    else:\n        reactor.connectTCP(nativeString(uri.host), uri.port, factory)\n    return factory\n\n\n_GETPAGE_REPLACEMENT_TEXT = \"https://pypi.org/project/treq/ or twisted.web.client.Agent\"\n\ndef _deprecateGetPageClasses():\n    \"\"\"\n    Mark the protocols and factories associated with L{getPage} and\n    L{downloadPage} as deprecated.\n    \"\"\"\n    for klass in [\n        HTTPPageGetter, HTTPPageDownloader,\n        HTTPClientFactory, HTTPDownloader\n    ]:\n        deprecatedModuleAttribute(\n            Version(\"Twisted\", 16, 7, 0),\n            getDeprecationWarningString(\n                klass,\n                Version(\"Twisted\", 16, 7, 0),\n                replacement=_GETPAGE_REPLACEMENT_TEXT)\n            .split(\"; \")[1],\n            klass.__module__,\n            klass.__name__)\n\n_deprecateGetPageClasses()\n\n\n\n@deprecated(Version(\"Twisted\", 16, 7, 0),\n            _GETPAGE_REPLACEMENT_TEXT)\ndef getPage(url, contextFactory=None, *args, **kwargs):\n    \"\"\"\n    Download a web page as a string.\n\n    Download a page. Return a deferred, which will callback with a\n    page (as a string) or errback with a description of the error.\n\n    See L{HTTPClientFactory} to see what extra arguments can be passed.\n    \"\"\"\n    return _makeGetterFactory(\n        url,\n        HTTPClientFactory,\n        contextFactory=contextFactory,\n        *args, **kwargs).deferred\n\n\n\n@deprecated(Version(\"Twisted\", 16, 7, 0),\n            _GETPAGE_REPLACEMENT_TEXT)\ndef downloadPage(url, file, contextFactory=None, *args, **kwargs):\n    \"\"\"\n    Download a web page to a file.\n\n    @param file: path to file on filesystem, or file-like object.\n\n    See HTTPDownloader to see what extra args can be passed.\n    \"\"\"\n    factoryFactory = lambda url, *a, **kw: HTTPDownloader(url, file, *a, **kw)\n    return _makeGetterFactory(\n        url,\n        factoryFactory,\n        contextFactory=contextFactory,\n        *args, **kwargs).deferred\n\n\n# The code which follows is based on the new HTTP client implementation.  It\n# should be significantly better than anything above, though it is not yet\n# feature equivalent.\n\nfrom twisted.web.error import SchemeNotSupported\nfrom twisted.web._newclient import (\n    HTTP11ClientProtocol,\n    PotentialDataLoss,\n    Request,\n    RequestGenerationFailed,\n    RequestNotSent,\n    RequestTransmissionFailed,\n    Response,\n    ResponseDone,\n    ResponseFailed,\n    ResponseNeverReceived,\n    _WrapperException,\n    )\n\n\n\ntry:\n    from OpenSSL import SSL\nexcept ImportError:\n    SSL = None\nelse:\n    from twisted.internet.ssl import (CertificateOptions,\n                                      platformTrust,\n                                      optionsForClientTLS)\n\n\ndef _requireSSL(decoratee):\n    \"\"\"\n    The decorated method requires pyOpenSSL to be present, or it raises\n    L{NotImplementedError}.\n\n    @param decoratee: A function which requires pyOpenSSL.\n    @type decoratee: L{callable}\n\n    @return: A function which raises L{NotImplementedError} if pyOpenSSL is not\n        installed; otherwise, if it is installed, simply return C{decoratee}.\n    @rtype: L{callable}\n    \"\"\"\n    if SSL is None:\n        @wraps(decoratee)\n        def raiseNotImplemented(*a, **kw):\n            \"\"\"\n            pyOpenSSL is not available.\n\n            @param a: The positional arguments for C{decoratee}.\n\n            @param kw: The keyword arguments for C{decoratee}.\n\n            @raise NotImplementedError: Always.\n            \"\"\"\n            raise NotImplementedError(\"SSL support unavailable\")\n        return raiseNotImplemented\n    return decoratee\n\n\n\nclass WebClientContextFactory(object):\n    \"\"\"\n    This class is deprecated.  Please simply use L{Agent} as-is, or if you want\n    to customize something, use L{BrowserLikePolicyForHTTPS}.\n\n    A L{WebClientContextFactory} is an HTTPS policy which totally ignores the\n    hostname and port.  It performs basic certificate verification, however the\n    lack of validation of service identity (e.g.  hostname validation) means it\n    is still vulnerable to man-in-the-middle attacks.  Don't use it any more.\n    \"\"\"\n\n    def _getCertificateOptions(self, hostname, port):\n        \"\"\"\n        Return a L{CertificateOptions}.\n\n        @param hostname: ignored\n\n        @param port: ignored\n\n        @return: A new CertificateOptions instance.\n        @rtype: L{CertificateOptions}\n        \"\"\"\n        return CertificateOptions(\n            method=SSL.SSLv23_METHOD,\n            trustRoot=platformTrust()\n        )\n\n\n    @_requireSSL\n    def getContext(self, hostname, port):\n        \"\"\"\n        Return an L{OpenSSL.SSL.Context}.\n\n        @param hostname: ignored\n        @param port: ignored\n\n        @return: A new SSL context.\n        @rtype: L{OpenSSL.SSL.Context}\n        \"\"\"\n        return self._getCertificateOptions(hostname, port).getContext()\n\n\n\n@implementer(IPolicyForHTTPS)\nclass BrowserLikePolicyForHTTPS(object):\n    \"\"\"\n    SSL connection creator for web clients.\n    \"\"\"\n    def __init__(self, trustRoot=None):\n        self._trustRoot = trustRoot\n\n\n    @_requireSSL\n    def creatorForNetloc(self, hostname, port):\n        \"\"\"\n        Create a L{client connection creator\n        <twisted.internet.interfaces.IOpenSSLClientConnectionCreator>} for a\n        given network location.\n\n        @param tls: The TLS protocol to create a connection for.\n        @type tls: L{twisted.protocols.tls.TLSMemoryBIOProtocol}\n\n        @param hostname: The hostname part of the URI.\n        @type hostname: L{bytes}\n\n        @param port: The port part of the URI.\n        @type port: L{int}\n\n        @return: a connection creator with appropriate verification\n            restrictions set\n        @rtype: L{client connection creator\n            <twisted.internet.interfaces.IOpenSSLClientConnectionCreator>}\n        \"\"\"\n        return optionsForClientTLS(hostname.decode(\"ascii\"),\n                                   trustRoot=self._trustRoot)\n\n\n\ndeprecatedModuleAttribute(Version(\"Twisted\", 14, 0, 0),\n                          getDeprecationWarningString(\n                              WebClientContextFactory,\n                              Version(\"Twisted\", 14, 0, 0),\n                              replacement=BrowserLikePolicyForHTTPS)\n                          .split(\"; \")[1],\n                          WebClientContextFactory.__module__,\n                          WebClientContextFactory.__name__)\n\n\n\n@implementer(IPolicyForHTTPS)\nclass HostnameCachingHTTPSPolicy(object):\n    \"\"\"\n    IPolicyForHTTPS that wraps a L{IPolicyForHTTPS} and caches the created\n    L{IOpenSSLClientConnectionCreator}.\n\n    This policy will cache up to C{cacheSize}\n    L{client connection creators <twisted.internet.interfaces.\n    IOpenSSLClientConnectionCreator>} for reuse in subsequent requests to\n    the same hostname.\n\n    @ivar _policyForHTTPS: See C{policyforHTTPS} parameter of L{__init__}.\n\n    @ivar _cache: A cache associating hostnames to their\n        L{client connection creators <twisted.internet.interfaces.\n        IOpenSSLClientConnectionCreator>}.\n    @type _cache: L{collections.OrderedDict}\n\n    @ivar _cacheSize: See C{cacheSize} parameter of L{__init__}.\n\n    @since: Twisted 19.2.0\n    \"\"\"\n\n    def __init__(self, policyforHTTPS, cacheSize=20):\n        \"\"\"\n        @param policyforHTTPS: The IPolicyForHTTPS to wrap.\n        @type policyforHTTPS: L{IPolicyForHTTPS}\n\n        @param cacheSize: The maximum size of the hostname cache.\n        @type cacheSize: L{int}\n        \"\"\"\n        self._policyForHTTPS = policyforHTTPS\n        self._cache = collections.OrderedDict()\n        self._cacheSize = cacheSize\n\n\n    def creatorForNetloc(self, hostname, port):\n        \"\"\"\n        Create a L{client connection creator\n        <twisted.internet.interfaces.IOpenSSLClientConnectionCreator>} for a\n        given network location and cache it for future use.\n\n        @param hostname: The hostname part of the URI.\n        @type hostname: L{bytes}\n\n        @param port: The port part of the URI.\n        @type port: L{int}\n\n        @return: a connection creator with appropriate verification\n            restrictions set\n        @rtype: L{client connection creator\n            <twisted.internet.interfaces.IOpenSSLClientConnectionCreator>}\n        \"\"\"\n        host = hostname.decode(\"ascii\")\n        try:\n            creator = self._cache.pop(host)\n        except KeyError:\n            creator = self._policyForHTTPS.creatorForNetloc(hostname, port)\n\n        self._cache[host] = creator\n        if len(self._cache) > self._cacheSize:\n            self._cache.popitem(last=False)\n\n        return creator\n\n\n\n@implementer(IOpenSSLContextFactory)\nclass _ContextFactoryWithContext(object):\n    \"\"\"\n    A L{_ContextFactoryWithContext} is like a\n    L{twisted.internet.ssl.ContextFactory} with a pre-created context.\n\n    @ivar _context: A Context.\n    @type _context: L{OpenSSL.SSL.Context}\n    \"\"\"\n\n    def __init__(self, context):\n        \"\"\"\n        Initialize a L{_ContextFactoryWithContext} with a context.\n\n        @param context: An SSL context.\n        @type context: L{OpenSSL.SSL.Context}\n        \"\"\"\n        self._context = context\n\n\n    def getContext(self):\n        \"\"\"\n        Return the context created by\n        L{_DeprecatedToCurrentPolicyForHTTPS._webContextFactory}.\n\n        @return: A context.\n        @rtype context: L{OpenSSL.SSL.Context}\n        \"\"\"\n        return self._context\n\n\n\n@implementer(IPolicyForHTTPS)\nclass _DeprecatedToCurrentPolicyForHTTPS(object):\n    \"\"\"\n    Adapt a web context factory to a normal context factory.\n\n    @ivar _webContextFactory: An object providing a getContext method with\n        C{hostname} and C{port} arguments.\n    @type _webContextFactory: L{WebClientContextFactory} (or object with a\n        similar C{getContext} method).\n    \"\"\"\n    def __init__(self, webContextFactory):\n        \"\"\"\n        Wrap a web context factory in an L{IPolicyForHTTPS}.\n\n        @param webContextFactory: An object providing a getContext method with\n            C{hostname} and C{port} arguments.\n        @type webContextFactory: L{WebClientContextFactory} (or object with a\n            similar C{getContext} method).\n        \"\"\"\n        self._webContextFactory = webContextFactory\n\n\n    def creatorForNetloc(self, hostname, port):\n        \"\"\"\n        Called the wrapped web context factory's C{getContext} method with a\n        hostname and port number and return the resulting context object.\n\n        @param hostname: The hostname part of the URI.\n        @type hostname: L{bytes}\n\n        @param port: The port part of the URI.\n        @type port: L{int}\n\n        @return: A context factory.\n        @rtype: L{IOpenSSLContextFactory}\n        \"\"\"\n        context = self._webContextFactory.getContext(hostname, port)\n        return _ContextFactoryWithContext(context)\n\n\n\n@implementer(IBodyProducer)\nclass FileBodyProducer(object):\n    \"\"\"\n    L{FileBodyProducer} produces bytes from an input file object incrementally\n    and writes them to a consumer.\n\n    Since file-like objects cannot be read from in an event-driven manner,\n    L{FileBodyProducer} uses a L{Cooperator} instance to schedule reads from\n    the file.  This process is also paused and resumed based on notifications\n    from the L{IConsumer} provider being written to.\n\n    The file is closed after it has been read, or if the producer is stopped\n    early.\n\n    @ivar _inputFile: Any file-like object, bytes read from which will be\n        written to a consumer.\n\n    @ivar _cooperate: A method like L{Cooperator.cooperate} which is used to\n        schedule all reads.\n\n    @ivar _readSize: The number of bytes to read from C{_inputFile} at a time.\n    \"\"\"\n\n    def __init__(self, inputFile, cooperator=task, readSize=2 ** 16):\n        self._inputFile = inputFile\n        self._cooperate = cooperator.cooperate\n        self._readSize = readSize\n        self.length = self._determineLength(inputFile)\n\n\n    def _determineLength(self, fObj):\n        \"\"\"\n        Determine how many bytes can be read out of C{fObj} (assuming it is not\n        modified from this point on).  If the determination cannot be made,\n        return C{UNKNOWN_LENGTH}.\n        \"\"\"\n        try:\n            seek = fObj.seek\n            tell = fObj.tell\n        except AttributeError:\n            return UNKNOWN_LENGTH\n        originalPosition = tell()\n        seek(0, os.SEEK_END)\n        end = tell()\n        seek(originalPosition, os.SEEK_SET)\n        return end - originalPosition\n\n\n    def stopProducing(self):\n        \"\"\"\n        Permanently stop writing bytes from the file to the consumer by\n        stopping the underlying L{CooperativeTask}.\n        \"\"\"\n        self._inputFile.close()\n        self._task.stop()\n\n\n    def startProducing(self, consumer):\n        \"\"\"\n        Start a cooperative task which will read bytes from the input file and\n        write them to C{consumer}.  Return a L{Deferred} which fires after all\n        bytes have been written.\n\n        @param consumer: Any L{IConsumer} provider\n        \"\"\"\n        self._task = self._cooperate(self._writeloop(consumer))\n        d = self._task.whenDone()\n        def maybeStopped(reason):\n            # IBodyProducer.startProducing's Deferred isn't support to fire if\n            # stopProducing is called.\n            reason.trap(task.TaskStopped)\n            return defer.Deferred()\n        d.addCallbacks(lambda ignored: None, maybeStopped)\n        return d\n\n\n    def _writeloop(self, consumer):\n        \"\"\"\n        Return an iterator which reads one chunk of bytes from the input file\n        and writes them to the consumer for each time it is iterated.\n        \"\"\"\n        while True:\n            bytes = self._inputFile.read(self._readSize)\n            if not bytes:\n                self._inputFile.close()\n                break\n            consumer.write(bytes)\n            yield None\n\n\n    def pauseProducing(self):\n        \"\"\"\n        Temporarily suspend copying bytes from the input file to the consumer\n        by pausing the L{CooperativeTask} which drives that activity.\n        \"\"\"\n        self._task.pause()\n\n\n    def resumeProducing(self):\n        \"\"\"\n        Undo the effects of a previous C{pauseProducing} and resume copying\n        bytes to the consumer by resuming the L{CooperativeTask} which drives\n        the write activity.\n        \"\"\"\n        self._task.resume()\n\n\n\nclass _HTTP11ClientFactory(protocol.Factory):\n    \"\"\"\n    A factory for L{HTTP11ClientProtocol}, used by L{HTTPConnectionPool}.\n\n    @ivar _quiescentCallback: The quiescent callback to be passed to protocol\n        instances, used to return them to the connection pool.\n\n    @ivar _metadata: Metadata about the low-level connection details,\n        used to make the repr more useful.\n\n    @since: 11.1\n    \"\"\"\n    def __init__(self, quiescentCallback, metadata):\n        self._quiescentCallback = quiescentCallback\n        self._metadata = metadata\n\n\n    def __repr__(self):\n        return '_HTTP11ClientFactory({}, {})'.format(\n            self._quiescentCallback,\n            self._metadata)\n\n    def buildProtocol(self, addr):\n        return HTTP11ClientProtocol(self._quiescentCallback)\n\n\n\nclass _RetryingHTTP11ClientProtocol(object):\n    \"\"\"\n    A wrapper for L{HTTP11ClientProtocol} that automatically retries requests.\n\n    @ivar _clientProtocol: The underlying L{HTTP11ClientProtocol}.\n\n    @ivar _newConnection: A callable that creates a new connection for a\n        retry.\n    \"\"\"\n\n    def __init__(self, clientProtocol, newConnection):\n        self._clientProtocol = clientProtocol\n        self._newConnection = newConnection\n\n\n    def _shouldRetry(self, method, exception, bodyProducer):\n        \"\"\"\n        Indicate whether request should be retried.\n\n        Only returns C{True} if method is idempotent, no response was\n        received, the reason for the failed request was not due to\n        user-requested cancellation, and no body was sent. The latter\n        requirement may be relaxed in the future, and PUT added to approved\n        method list.\n\n        @param method: The method of the request.\n        @type method: L{bytes}\n        \"\"\"\n        if method not in (b\"GET\", b\"HEAD\", b\"OPTIONS\", b\"DELETE\", b\"TRACE\"):\n            return False\n        if not isinstance(exception, (RequestNotSent,\n                                      RequestTransmissionFailed,\n                                      ResponseNeverReceived)):\n            return False\n        if isinstance(exception, _WrapperException):\n            for aFailure in exception.reasons:\n                if aFailure.check(defer.CancelledError):\n                    return False\n        if bodyProducer is not None:\n            return False\n        return True\n\n\n    def request(self, request):\n        \"\"\"\n        Do a request, and retry once (with a new connection) if it fails in\n        a retryable manner.\n\n        @param request: A L{Request} instance that will be requested using the\n            wrapped protocol.\n        \"\"\"\n        d = self._clientProtocol.request(request)\n\n        def failed(reason):\n            if self._shouldRetry(request.method, reason.value,\n                                 request.bodyProducer):\n                return self._newConnection().addCallback(\n                    lambda connection: connection.request(request))\n            else:\n                return reason\n        d.addErrback(failed)\n        return d\n\n\n\nclass HTTPConnectionPool(object):\n    \"\"\"\n    A pool of persistent HTTP connections.\n\n    Features:\n     - Cached connections will eventually time out.\n     - Limits on maximum number of persistent connections.\n\n    Connections are stored using keys, which should be chosen such that any\n    connections stored under a given key can be used interchangeably.\n\n    Failed requests done using previously cached connections will be retried\n    once if they use an idempotent method (e.g. GET), in case the HTTP server\n    timed them out.\n\n    @ivar persistent: Boolean indicating whether connections should be\n        persistent. Connections are persistent by default.\n\n    @ivar maxPersistentPerHost: The maximum number of cached persistent\n        connections for a C{host:port} destination.\n    @type maxPersistentPerHost: C{int}\n\n    @ivar cachedConnectionTimeout: Number of seconds a cached persistent\n        connection will stay open before disconnecting.\n\n    @ivar retryAutomatically: C{boolean} indicating whether idempotent\n        requests should be retried once if no response was received.\n\n    @ivar _factory: The factory used to connect to the proxy.\n\n    @ivar _connections: Map (scheme, host, port) to lists of\n        L{HTTP11ClientProtocol} instances.\n\n    @ivar _timeouts: Map L{HTTP11ClientProtocol} instances to a\n        C{IDelayedCall} instance of their timeout.\n\n    @since: 12.1\n    \"\"\"\n\n    _factory = _HTTP11ClientFactory\n    maxPersistentPerHost = 2\n    cachedConnectionTimeout = 240\n    retryAutomatically = True\n    _log = Logger()\n\n    def __init__(self, reactor, persistent=True):\n        self._reactor = reactor\n        self.persistent = persistent\n        self._connections = {}\n        self._timeouts = {}\n\n\n    def getConnection(self, key, endpoint):\n        \"\"\"\n        Supply a connection, newly created or retrieved from the pool, to be\n        used for one HTTP request.\n\n        The connection will remain out of the pool (not available to be\n        returned from future calls to this method) until one HTTP request has\n        been completed over it.\n\n        Afterwards, if the connection is still open, it will automatically be\n        added to the pool.\n\n        @param key: A unique key identifying connections that can be used\n            interchangeably.\n\n        @param endpoint: An endpoint that can be used to open a new connection\n            if no cached connection is available.\n\n        @return: A C{Deferred} that will fire with a L{HTTP11ClientProtocol}\n           (or a wrapper) that can be used to send a single HTTP request.\n        \"\"\"\n        # Try to get cached version:\n        connections = self._connections.get(key)\n        while connections:\n            connection = connections.pop(0)\n            # Cancel timeout:\n            self._timeouts[connection].cancel()\n            del self._timeouts[connection]\n            if connection.state == \"QUIESCENT\":\n                if self.retryAutomatically:\n                    newConnection = lambda: self._newConnection(key, endpoint)\n                    connection = _RetryingHTTP11ClientProtocol(\n                        connection, newConnection)\n                return defer.succeed(connection)\n\n        return self._newConnection(key, endpoint)\n\n\n    def _newConnection(self, key, endpoint):\n        \"\"\"\n        Create a new connection.\n\n        This implements the new connection code path for L{getConnection}.\n        \"\"\"\n        def quiescentCallback(protocol):\n            self._putConnection(key, protocol)\n        factory = self._factory(quiescentCallback, repr(endpoint))\n        return endpoint.connect(factory)\n\n\n    def _removeConnection(self, key, connection):\n        \"\"\"\n        Remove a connection from the cache and disconnect it.\n        \"\"\"\n        connection.transport.loseConnection()\n        self._connections[key].remove(connection)\n        del self._timeouts[connection]\n\n\n    def _putConnection(self, key, connection):\n        \"\"\"\n        Return a persistent connection to the pool. This will be called by\n        L{HTTP11ClientProtocol} when the connection becomes quiescent.\n        \"\"\"\n        if connection.state != \"QUIESCENT\":\n            # Log with traceback for debugging purposes:\n            try:\n                raise RuntimeError(\n                    \"BUG: Non-quiescent protocol added to connection pool.\")\n            except:\n                self._log.failure(\n                    \"BUG: Non-quiescent protocol added to connection pool.\")\n            return\n        connections = self._connections.setdefault(key, [])\n        if len(connections) == self.maxPersistentPerHost:\n            dropped = connections.pop(0)\n            dropped.transport.loseConnection()\n            self._timeouts[dropped].cancel()\n            del self._timeouts[dropped]\n        connections.append(connection)\n        cid = self._reactor.callLater(self.cachedConnectionTimeout,\n                                      self._removeConnection,\n                                      key, connection)\n        self._timeouts[connection] = cid\n\n\n    def closeCachedConnections(self):\n        \"\"\"\n        Close all persistent connections and remove them from the pool.\n\n        @return: L{defer.Deferred} that fires when all connections have been\n            closed.\n        \"\"\"\n        results = []\n        for protocols in itervalues(self._connections):\n            for p in protocols:\n                results.append(p.abort())\n        self._connections = {}\n        for dc in itervalues(self._timeouts):\n            dc.cancel()\n        self._timeouts = {}\n        return defer.gatherResults(results).addCallback(lambda ign: None)\n\n\n\nclass _AgentBase(object):\n    \"\"\"\n    Base class offering common facilities for L{Agent}-type classes.\n\n    @ivar _reactor: The C{IReactorTime} implementation which will be used by\n        the pool, and perhaps by subclasses as well.\n\n    @ivar _pool: The L{HTTPConnectionPool} used to manage HTTP connections.\n    \"\"\"\n\n    def __init__(self, reactor, pool):\n        if pool is None:\n            pool = HTTPConnectionPool(reactor, False)\n        self._reactor = reactor\n        self._pool = pool\n\n\n    def _computeHostValue(self, scheme, host, port):\n        \"\"\"\n        Compute the string to use for the value of the I{Host} header, based on\n        the given scheme, host name, and port number.\n        \"\"\"\n        if (isIPv6Address(nativeString(host))):\n            host = b'[' + host + b']'\n        if (scheme, port) in ((b'http', 80), (b'https', 443)):\n            return host\n        return host + b\":\" + intToBytes(port)\n\n\n    def _requestWithEndpoint(self, key, endpoint, method, parsedURI,\n                             headers, bodyProducer, requestPath):\n        \"\"\"\n        Issue a new request, given the endpoint and the path sent as part of\n        the request.\n        \"\"\"\n        if not isinstance(method, bytes):\n            raise TypeError('method={!r} is {}, but must be bytes'.format(\n                    method, type(method)))\n\n        method = _ensureValidMethod(method)\n\n        # Create minimal headers, if necessary:\n        if headers is None:\n            headers = Headers()\n        if not headers.hasHeader(b'host'):\n            headers = headers.copy()\n            headers.addRawHeader(\n                b'host', self._computeHostValue(parsedURI.scheme,\n                                                parsedURI.host,\n                                                parsedURI.port))\n\n        d = self._pool.getConnection(key, endpoint)\n        def cbConnected(proto):\n            return proto.request(\n                Request._construct(method, requestPath, headers, bodyProducer,\n                                   persistent=self._pool.persistent,\n                                   parsedURI=parsedURI))\n        d.addCallback(cbConnected)\n        return d\n\n\n\n@implementer(IAgentEndpointFactory)\nclass _StandardEndpointFactory(object):\n    \"\"\"\n    Standard HTTP endpoint destinations - TCP for HTTP, TCP+TLS for HTTPS.\n\n    @ivar _policyForHTTPS: A web context factory which will be used to create\n        SSL context objects for any SSL connections the agent needs to make.\n\n    @ivar _connectTimeout: If not L{None}, the timeout passed to\n        L{HostnameEndpoint} for specifying the connection timeout.\n\n    @ivar _bindAddress: If not L{None}, the address passed to\n        L{HostnameEndpoint} for specifying the local address to bind to.\n    \"\"\"\n    def __init__(self, reactor, contextFactory, connectTimeout, bindAddress):\n        \"\"\"\n        @param reactor: A provider to use to create endpoints.\n        @type reactor: see L{HostnameEndpoint.__init__} for acceptable reactor\n            types.\n\n        @param contextFactory: A factory for TLS contexts, to control the\n            verification parameters of OpenSSL.\n        @type contextFactory: L{IPolicyForHTTPS}.\n\n        @param connectTimeout: The amount of time that this L{Agent} will wait\n            for the peer to accept a connection.\n        @type connectTimeout: L{float} or L{None}\n\n        @param bindAddress: The local address for client sockets to bind to.\n        @type bindAddress: L{bytes} or L{None}\n        \"\"\"\n        self._reactor = reactor\n        self._policyForHTTPS = contextFactory\n        self._connectTimeout = connectTimeout\n        self._bindAddress = bindAddress\n\n\n    def endpointForURI(self, uri):\n        \"\"\"\n        Connect directly over TCP for C{b'http'} scheme, and TLS for\n        C{b'https'}.\n\n        @param uri: L{URI} to connect to.\n\n        @return: Endpoint to connect to.\n        @rtype: L{IStreamClientEndpoint}\n        \"\"\"\n        kwargs = {}\n        if self._connectTimeout is not None:\n            kwargs['timeout'] = self._connectTimeout\n        kwargs['bindAddress'] = self._bindAddress\n\n        try:\n            host = nativeString(uri.host)\n        except UnicodeDecodeError:\n            raise ValueError((\"The host of the provided URI ({uri.host!r}) \"\n                              \"contains non-ASCII octets, it should be ASCII \"\n                              \"decodable.\").format(uri=uri))\n\n        endpoint = HostnameEndpoint(self._reactor, host, uri.port, **kwargs)\n        if uri.scheme == b'http':\n            return endpoint\n        elif uri.scheme == b'https':\n            connectionCreator = self._policyForHTTPS.creatorForNetloc(uri.host,\n                                                                      uri.port)\n            return wrapClientTLS(connectionCreator, endpoint)\n        else:\n            raise SchemeNotSupported(\"Unsupported scheme: %r\" % (uri.scheme,))\n\n\n\n@implementer(IAgent)\nclass Agent(_AgentBase):\n    \"\"\"\n    L{Agent} is a very basic HTTP client.  It supports I{HTTP} and I{HTTPS}\n    scheme URIs.\n\n    @ivar _pool: An L{HTTPConnectionPool} instance.\n\n    @ivar _endpointFactory: The L{IAgentEndpointFactory} which will\n        be used to create endpoints for outgoing connections.\n\n    @since: 9.0\n    \"\"\"\n\n    def __init__(self, reactor,\n                 contextFactory=BrowserLikePolicyForHTTPS(),\n                 connectTimeout=None, bindAddress=None,\n                 pool=None):\n        \"\"\"\n        Create an L{Agent}.\n\n        @param reactor: A reactor for this L{Agent} to place outgoing\n            connections.\n        @type reactor: see L{HostnameEndpoint.__init__} for acceptable reactor\n            types.\n\n        @param contextFactory: A factory for TLS contexts, to control the\n            verification parameters of OpenSSL.  The default is to use a\n            L{BrowserLikePolicyForHTTPS}, so unless you have special\n            requirements you can leave this as-is.\n        @type contextFactory: L{IPolicyForHTTPS}.\n\n        @param connectTimeout: The amount of time that this L{Agent} will wait\n            for the peer to accept a connection.\n        @type connectTimeout: L{float}\n\n        @param bindAddress: The local address for client sockets to bind to.\n        @type bindAddress: L{bytes}\n\n        @param pool: An L{HTTPConnectionPool} instance, or L{None}, in which\n            case a non-persistent L{HTTPConnectionPool} instance will be\n            created.\n        @type pool: L{HTTPConnectionPool}\n        \"\"\"\n        if not IPolicyForHTTPS.providedBy(contextFactory):\n            warnings.warn(\n                repr(contextFactory) +\n                \" was passed as the HTTPS policy for an Agent, but it does \"\n                \"not provide IPolicyForHTTPS.  Since Twisted 14.0, you must \"\n                \"pass a provider of IPolicyForHTTPS.\",\n                stacklevel=2, category=DeprecationWarning\n            )\n            contextFactory = _DeprecatedToCurrentPolicyForHTTPS(contextFactory)\n        endpointFactory = _StandardEndpointFactory(\n            reactor, contextFactory, connectTimeout, bindAddress)\n        self._init(reactor, endpointFactory, pool)\n\n\n    @classmethod\n    def usingEndpointFactory(cls, reactor, endpointFactory, pool=None):\n        \"\"\"\n        Create a new L{Agent} that will use the endpoint factory to figure\n        out how to connect to the server.\n\n        @param reactor: A reactor for this L{Agent} to place outgoing\n            connections.\n        @type reactor: see L{HostnameEndpoint.__init__} for acceptable reactor\n            types.\n\n        @param endpointFactory: Used to construct endpoints which the\n            HTTP client will connect with.\n        @type endpointFactory: an L{IAgentEndpointFactory} provider.\n\n        @param pool: An L{HTTPConnectionPool} instance, or L{None}, in which\n            case a non-persistent L{HTTPConnectionPool} instance will be\n            created.\n        @type pool: L{HTTPConnectionPool}\n\n        @return: A new L{Agent}.\n        \"\"\"\n        agent = cls.__new__(cls)\n        agent._init(reactor, endpointFactory, pool)\n        return agent\n\n\n    def _init(self, reactor, endpointFactory, pool):\n        \"\"\"\n        Initialize a new L{Agent}.\n\n        @param reactor: A reactor for this L{Agent} to place outgoing\n            connections.\n        @type reactor: see L{HostnameEndpoint.__init__} for acceptable reactor\n            types.\n\n        @param endpointFactory: Used to construct endpoints which the\n            HTTP client will connect with.\n        @type endpointFactory: an L{IAgentEndpointFactory} provider.\n\n        @param pool: An L{HTTPConnectionPool} instance, or L{None}, in which\n            case a non-persistent L{HTTPConnectionPool} instance will be\n            created.\n        @type pool: L{HTTPConnectionPool}\n\n        @return: A new L{Agent}.\n        \"\"\"\n        _AgentBase.__init__(self, reactor, pool)\n        self._endpointFactory = endpointFactory\n\n\n    def _getEndpoint(self, uri):\n        \"\"\"\n        Get an endpoint for the given URI, using C{self._endpointFactory}.\n\n        @param uri: The URI of the request.\n        @type uri: L{URI}\n\n        @return: An endpoint which can be used to connect to given address.\n        \"\"\"\n        return self._endpointFactory.endpointForURI(uri)\n\n\n    def request(self, method, uri, headers=None, bodyProducer=None):\n        \"\"\"\n        Issue a request to the server indicated by the given C{uri}.\n\n        An existing connection from the connection pool may be used or a new\n        one may be created.\n\n        I{HTTP} and I{HTTPS} schemes are supported in C{uri}.\n\n        @see: L{twisted.web.iweb.IAgent.request}\n        \"\"\"\n        uri = _ensureValidURI(uri.strip())\n        parsedURI = URI.fromBytes(uri)\n        try:\n            endpoint = self._getEndpoint(parsedURI)\n        except SchemeNotSupported:\n            return defer.fail(Failure())\n        key = (parsedURI.scheme, parsedURI.host, parsedURI.port)\n        return self._requestWithEndpoint(key, endpoint, method, parsedURI,\n                                         headers, bodyProducer,\n                                         parsedURI.originForm)\n\n\n\n@implementer(IAgent)\nclass ProxyAgent(_AgentBase):\n    \"\"\"\n    An HTTP agent able to cross HTTP proxies.\n\n    @ivar _proxyEndpoint: The endpoint used to connect to the proxy.\n\n    @since: 11.1\n    \"\"\"\n\n    def __init__(self, endpoint, reactor=None, pool=None):\n        if reactor is None:\n            from twisted.internet import reactor\n        _AgentBase.__init__(self, reactor, pool)\n        self._proxyEndpoint = endpoint\n\n\n    def request(self, method, uri, headers=None, bodyProducer=None):\n        \"\"\"\n        Issue a new request via the configured proxy.\n        \"\"\"\n        uri = _ensureValidURI(uri.strip())\n\n        # Cache *all* connections under the same key, since we are only\n        # connecting to a single destination, the proxy:\n        key = (\"http-proxy\", self._proxyEndpoint)\n\n        # To support proxying HTTPS via CONNECT, we will use key\n        # (\"http-proxy-CONNECT\", scheme, host, port), and an endpoint that\n        # wraps _proxyEndpoint with an additional callback to do the CONNECT.\n        return self._requestWithEndpoint(key, self._proxyEndpoint, method,\n                                         URI.fromBytes(uri), headers,\n                                         bodyProducer, uri)\n\n\n\nclass _FakeUrllib2Request(object):\n    \"\"\"\n    A fake C{urllib2.Request} object for C{cookielib} to work with.\n\n    @see: U{http://docs.python.org/library/urllib2.html#request-objects}\n\n    @type uri: native L{str}\n    @ivar uri: Request URI.\n\n    @type headers: L{twisted.web.http_headers.Headers}\n    @ivar headers: Request headers.\n\n    @type type: native L{str}\n    @ivar type: The scheme of the URI.\n\n    @type host: native L{str}\n    @ivar host: The host[:port] of the URI.\n\n    @since: 11.1\n    \"\"\"\n    def __init__(self, uri):\n        \"\"\"\n        Create a fake Urllib2 request.\n\n        @param uri: Request URI.\n        @type uri: L{bytes}\n        \"\"\"\n        self.uri = nativeString(uri)\n        self.headers = Headers()\n\n        _uri = URI.fromBytes(uri)\n        self.type = nativeString(_uri.scheme)\n        self.host = nativeString(_uri.host)\n\n        if (_uri.scheme, _uri.port) not in ((b'http', 80), (b'https', 443)):\n            # If it's not a schema on the regular port, add the port.\n            self.host += \":\" + str(_uri.port)\n\n        if _PY3:\n            self.origin_req_host = nativeString(_uri.host)\n            self.unverifiable = lambda _: False\n\n\n    def has_header(self, header):\n        return self.headers.hasHeader(networkString(header))\n\n\n    def add_unredirected_header(self, name, value):\n        self.headers.addRawHeader(networkString(name), networkString(value))\n\n\n    def get_full_url(self):\n        return self.uri\n\n\n    def get_header(self, name, default=None):\n        headers = self.headers.getRawHeaders(networkString(name), default)\n        if headers is not None:\n            headers = [nativeString(x) for x in headers]\n            return headers[0]\n        return None\n\n\n    def get_host(self):\n        return self.host\n\n\n    def get_type(self):\n        return self.type\n\n\n    def is_unverifiable(self):\n        # In theory this shouldn't be hardcoded.\n        return False\n\n\n\nclass _FakeUrllib2Response(object):\n    \"\"\"\n    A fake C{urllib2.Response} object for C{cookielib} to work with.\n\n    @type response: C{twisted.web.iweb.IResponse}\n    @ivar response: Underlying Twisted Web response.\n\n    @since: 11.1\n    \"\"\"\n    def __init__(self, response):\n        self.response = response\n\n\n    def info(self):\n        class _Meta(object):\n            def getheaders(zelf, name):\n                # PY2\n                headers = self.response.headers.getRawHeaders(name, [])\n                return headers\n            def get_all(zelf, name, default):\n                # PY3\n                headers = self.response.headers.getRawHeaders(\n                    networkString(name), default)\n                h = [nativeString(x) for x in headers]\n                return h\n        return _Meta()\n\n\n\n@implementer(IAgent)\nclass CookieAgent(object):\n    \"\"\"\n    L{CookieAgent} extends the basic L{Agent} to add RFC-compliant\n    handling of HTTP cookies.  Cookies are written to and extracted\n    from a C{cookielib.CookieJar} instance.\n\n    The same cookie jar instance will be used for any requests through this\n    agent, mutating it whenever a I{Set-Cookie} header appears in a response.\n\n    @type _agent: L{twisted.web.client.Agent}\n    @ivar _agent: Underlying Twisted Web agent to issue requests through.\n\n    @type cookieJar: C{cookielib.CookieJar}\n    @ivar cookieJar: Initialized cookie jar to read cookies from and store\n        cookies to.\n\n    @since: 11.1\n    \"\"\"\n    def __init__(self, agent, cookieJar):\n        self._agent = agent\n        self.cookieJar = cookieJar\n\n\n    def request(self, method, uri, headers=None, bodyProducer=None):\n        \"\"\"\n        Issue a new request to the wrapped L{Agent}.\n\n        Send a I{Cookie} header if a cookie for C{uri} is stored in\n        L{CookieAgent.cookieJar}. Cookies are automatically extracted and\n        stored from requests.\n\n        If a C{'cookie'} header appears in C{headers} it will override the\n        automatic cookie header obtained from the cookie jar.\n\n        @see: L{Agent.request}\n        \"\"\"\n        if headers is None:\n            headers = Headers()\n        lastRequest = _FakeUrllib2Request(uri)\n        # Setting a cookie header explicitly will disable automatic request\n        # cookies.\n        if not headers.hasHeader(b'cookie'):\n            self.cookieJar.add_cookie_header(lastRequest)\n            cookieHeader = lastRequest.get_header('Cookie', None)\n            if cookieHeader is not None:\n                headers = headers.copy()\n                headers.addRawHeader(b'cookie', networkString(cookieHeader))\n\n        d = self._agent.request(method, uri, headers, bodyProducer)\n        d.addCallback(self._extractCookies, lastRequest)\n        return d\n\n\n    def _extractCookies(self, response, request):\n        \"\"\"\n        Extract response cookies and store them in the cookie jar.\n\n        @type response: L{twisted.web.iweb.IResponse}\n        @param response: Twisted Web response.\n\n        @param request: A urllib2 compatible request object.\n        \"\"\"\n        resp = _FakeUrllib2Response(response)\n        self.cookieJar.extract_cookies(resp, request)\n        return response\n\n\n\nclass GzipDecoder(proxyForInterface(IResponse)):\n    \"\"\"\n    A wrapper for a L{Response} instance which handles gzip'ed body.\n\n    @ivar original: The original L{Response} object.\n\n    @since: 11.1\n    \"\"\"\n\n    def __init__(self, response):\n        self.original = response\n        self.length = UNKNOWN_LENGTH\n\n\n    def deliverBody(self, protocol):\n        \"\"\"\n        Override C{deliverBody} to wrap the given C{protocol} with\n        L{_GzipProtocol}.\n        \"\"\"\n        self.original.deliverBody(_GzipProtocol(protocol, self.original))\n\n\n\nclass _GzipProtocol(proxyForInterface(IProtocol)):\n    \"\"\"\n    A L{Protocol} implementation which wraps another one, transparently\n    decompressing received data.\n\n    @ivar _zlibDecompress: A zlib decompress object used to decompress the data\n        stream.\n\n    @ivar _response: A reference to the original response, in case of errors.\n\n    @since: 11.1\n    \"\"\"\n\n    def __init__(self, protocol, response):\n        self.original = protocol\n        self._response = response\n        self._zlibDecompress = zlib.decompressobj(16 + zlib.MAX_WBITS)\n\n\n    def dataReceived(self, data):\n        \"\"\"\n        Decompress C{data} with the zlib decompressor, forwarding the raw data\n        to the original protocol.\n        \"\"\"\n        try:\n            rawData = self._zlibDecompress.decompress(data)\n        except zlib.error:\n            raise ResponseFailed([Failure()], self._response)\n        if rawData:\n            self.original.dataReceived(rawData)\n\n\n    def connectionLost(self, reason):\n        \"\"\"\n        Forward the connection lost event, flushing remaining data from the\n        decompressor if any.\n        \"\"\"\n        try:\n            rawData = self._zlibDecompress.flush()\n        except zlib.error:\n            raise ResponseFailed([reason, Failure()], self._response)\n        if rawData:\n            self.original.dataReceived(rawData)\n        self.original.connectionLost(reason)\n\n\n\n@implementer(IAgent)\nclass ContentDecoderAgent(object):\n    \"\"\"\n    An L{Agent} wrapper to handle encoded content.\n\n    It takes care of declaring the support for content in the\n    I{Accept-Encoding} header, and automatically decompresses the received data\n    if it's effectively using compression.\n\n    @param decoders: A list or tuple of (name, decoder) objects. The name\n        declares which decoding the decoder supports, and the decoder must\n        return a response object when called/instantiated. For example,\n        C{(('gzip', GzipDecoder))}. The order determines how the decoders are\n        going to be advertized to the server.\n\n    @since: 11.1\n    \"\"\"\n\n    def __init__(self, agent, decoders):\n        self._agent = agent\n        self._decoders = dict(decoders)\n        self._supported = b','.join([decoder[0] for decoder in decoders])\n\n\n    def request(self, method, uri, headers=None, bodyProducer=None):\n        \"\"\"\n        Send a client request which declares supporting compressed content.\n\n        @see: L{Agent.request}.\n        \"\"\"\n        if headers is None:\n            headers = Headers()\n        else:\n            headers = headers.copy()\n        headers.addRawHeader(b'accept-encoding', self._supported)\n        deferred = self._agent.request(method, uri, headers, bodyProducer)\n        return deferred.addCallback(self._handleResponse)\n\n\n    def _handleResponse(self, response):\n        \"\"\"\n        Check if the response is encoded, and wrap it to handle decompression.\n        \"\"\"\n        contentEncodingHeaders = response.headers.getRawHeaders(\n            b'content-encoding', [])\n        contentEncodingHeaders = b','.join(contentEncodingHeaders).split(b',')\n        while contentEncodingHeaders:\n            name = contentEncodingHeaders.pop().strip()\n            decoder = self._decoders.get(name)\n            if decoder is not None:\n                response = decoder(response)\n            else:\n                # Add it back\n                contentEncodingHeaders.append(name)\n                break\n        if contentEncodingHeaders:\n            response.headers.setRawHeaders(\n                b'content-encoding', [b','.join(contentEncodingHeaders)])\n        else:\n            response.headers.removeHeader(b'content-encoding')\n        return response\n\n\n\n@implementer(IAgent)\nclass RedirectAgent(object):\n    \"\"\"\n    An L{Agent} wrapper which handles HTTP redirects.\n\n    The implementation is rather strict: 301 and 302 behaves like 307, not\n    redirecting automatically on methods different from I{GET} and I{HEAD}.\n\n    See L{BrowserLikeRedirectAgent} for a redirecting Agent that behaves more\n    like a web browser.\n\n    @param redirectLimit: The maximum number of times the agent is allowed to\n        follow redirects before failing with a L{error.InfiniteRedirection}.\n\n    @cvar _redirectResponses: A L{list} of HTTP status codes to be redirected\n        for I{GET} and I{HEAD} methods.\n\n    @cvar _seeOtherResponses: A L{list} of HTTP status codes to be redirected\n        for any method and the method altered to I{GET}.\n\n    @since: 11.1\n    \"\"\"\n\n    _redirectResponses = [http.MOVED_PERMANENTLY, http.FOUND,\n                          http.TEMPORARY_REDIRECT]\n    _seeOtherResponses = [http.SEE_OTHER]\n\n\n    def __init__(self, agent, redirectLimit=20):\n        self._agent = agent\n        self._redirectLimit = redirectLimit\n\n\n    def request(self, method, uri, headers=None, bodyProducer=None):\n        \"\"\"\n        Send a client request following HTTP redirects.\n\n        @see: L{Agent.request}.\n        \"\"\"\n        deferred = self._agent.request(method, uri, headers, bodyProducer)\n        return deferred.addCallback(\n            self._handleResponse, method, uri, headers, 0)\n\n\n    def _resolveLocation(self, requestURI, location):\n        \"\"\"\n        Resolve the redirect location against the request I{URI}.\n\n        @type requestURI: C{bytes}\n        @param requestURI: The request I{URI}.\n\n        @type location: C{bytes}\n        @param location: The redirect location.\n\n        @rtype: C{bytes}\n        @return: Final resolved I{URI}.\n        \"\"\"\n        return _urljoin(requestURI, location)\n\n\n    def _handleRedirect(self, response, method, uri, headers, redirectCount):\n        \"\"\"\n        Handle a redirect response, checking the number of redirects already\n        followed, and extracting the location header fields.\n        \"\"\"\n        if redirectCount >= self._redirectLimit:\n            err = error.InfiniteRedirection(\n                response.code,\n                b'Infinite redirection detected',\n                location=uri)\n            raise ResponseFailed([Failure(err)], response)\n        locationHeaders = response.headers.getRawHeaders(b'location', [])\n        if not locationHeaders:\n            err = error.RedirectWithNoLocation(\n                response.code, b'No location header field', uri)\n            raise ResponseFailed([Failure(err)], response)\n        location = self._resolveLocation(uri, locationHeaders[0])\n        deferred = self._agent.request(method, location, headers)\n        def _chainResponse(newResponse):\n            newResponse.setPreviousResponse(response)\n            return newResponse\n        deferred.addCallback(_chainResponse)\n        return deferred.addCallback(\n            self._handleResponse, method, uri, headers, redirectCount + 1)\n\n\n    def _handleResponse(self, response, method, uri, headers, redirectCount):\n        \"\"\"\n        Handle the response, making another request if it indicates a redirect.\n        \"\"\"\n        if response.code in self._redirectResponses:\n            if method not in (b'GET', b'HEAD'):\n                err = error.PageRedirect(response.code, location=uri)\n                raise ResponseFailed([Failure(err)], response)\n            return self._handleRedirect(response, method, uri, headers,\n                                        redirectCount)\n        elif response.code in self._seeOtherResponses:\n            return self._handleRedirect(response, b'GET', uri, headers,\n                                        redirectCount)\n        return response\n\n\n\nclass BrowserLikeRedirectAgent(RedirectAgent):\n    \"\"\"\n    An L{Agent} wrapper which handles HTTP redirects in the same fashion as web\n    browsers.\n\n    Unlike L{RedirectAgent}, the implementation is more relaxed: 301 and 302\n    behave like 303, redirecting automatically on any method and altering the\n    redirect request to a I{GET}.\n\n    @see: L{RedirectAgent}\n\n    @since: 13.1\n    \"\"\"\n    _redirectResponses = [http.TEMPORARY_REDIRECT]\n    _seeOtherResponses = [http.MOVED_PERMANENTLY, http.FOUND, http.SEE_OTHER]\n\n\n\nclass _ReadBodyProtocol(protocol.Protocol):\n    \"\"\"\n    Protocol that collects data sent to it.\n\n    This is a helper for L{IResponse.deliverBody}, which collects the body and\n    fires a deferred with it.\n\n    @ivar deferred: See L{__init__}.\n    @ivar status: See L{__init__}.\n    @ivar message: See L{__init__}.\n\n    @ivar dataBuffer: list of byte-strings received\n    @type dataBuffer: L{list} of L{bytes}\n    \"\"\"\n\n    def __init__(self, status, message, deferred):\n        \"\"\"\n        @param status: Status of L{IResponse}\n        @ivar status: L{int}\n\n        @param message: Message of L{IResponse}\n        @type message: L{bytes}\n\n        @param deferred: deferred to fire when response is complete\n        @type deferred: L{Deferred} firing with L{bytes}\n        \"\"\"\n        self.deferred = deferred\n        self.status = status\n        self.message = message\n        self.dataBuffer = []\n\n\n    def dataReceived(self, data):\n        \"\"\"\n        Accumulate some more bytes from the response.\n        \"\"\"\n        self.dataBuffer.append(data)\n\n\n    def connectionLost(self, reason):\n        \"\"\"\n        Deliver the accumulated response bytes to the waiting L{Deferred}, if\n        the response body has been completely received without error.\n        \"\"\"\n        if reason.check(ResponseDone):\n            self.deferred.callback(b''.join(self.dataBuffer))\n        elif reason.check(PotentialDataLoss):\n            self.deferred.errback(\n                PartialDownloadError(self.status, self.message,\n                                     b''.join(self.dataBuffer)))\n        else:\n            self.deferred.errback(reason)\n\n\n\ndef readBody(response):\n    \"\"\"\n    Get the body of an L{IResponse} and return it as a byte string.\n\n    This is a helper function for clients that don't want to incrementally\n    receive the body of an HTTP response.\n\n    @param response: The HTTP response for which the body will be read.\n    @type response: L{IResponse} provider\n\n    @return: A L{Deferred} which will fire with the body of the response.\n        Cancelling it will close the connection to the server immediately.\n    \"\"\"\n    def cancel(deferred):\n        \"\"\"\n        Cancel a L{readBody} call, close the connection to the HTTP server\n        immediately, if it is still open.\n\n        @param deferred: The cancelled L{defer.Deferred}.\n        \"\"\"\n        abort = getAbort()\n        if abort is not None:\n            abort()\n\n    d = defer.Deferred(cancel)\n    protocol = _ReadBodyProtocol(response.code, response.phrase, d)\n    def getAbort():\n        return getattr(protocol.transport, 'abortConnection', None)\n\n    response.deliverBody(protocol)\n\n    if protocol.transport is not None and getAbort() is None:\n        warnings.warn(\n            'Using readBody with a transport that does not have an '\n            'abortConnection method',\n            category=DeprecationWarning,\n            stacklevel=2)\n\n    return d\n\n\n\n__all__ = [\n    'Agent',\n    'BrowserLikeRedirectAgent',\n    'ContentDecoderAgent',\n    'CookieAgent',\n    'downloadPage',\n    'getPage',\n    'GzipDecoder',\n    'HTTPClientFactory',\n    'HTTPConnectionPool',\n    'HTTPDownloader',\n    'HTTPPageDownloader',\n    'HTTPPageGetter',\n    'PartialDownloadError',\n    'ProxyAgent',\n    'readBody',\n    'RedirectAgent',\n    'RequestGenerationFailed',\n    'RequestTransmissionFailed',\n    'Response',\n    'ResponseDone',\n    'ResponseFailed',\n    'ResponseNeverReceived',\n    'URI',\n    ]\n", "code_before": "# -*- test-case-name: twisted.web.test.test_webclient,twisted.web.test.test_agent -*-\n# Copyright (c) Twisted Matrix Laboratories.\n# See LICENSE for details.\n\n\"\"\"\nHTTP client.\n\"\"\"\n\nfrom __future__ import division, absolute_import\n\nimport os\nimport collections\nimport warnings\n\ntry:\n    from urlparse import urlunparse, urljoin, urldefrag\nexcept ImportError:\n    from urllib.parse import urljoin, urldefrag\n    from urllib.parse import urlunparse as _urlunparse\n\n    def urlunparse(parts):\n        result = _urlunparse(tuple([p.decode(\"charmap\") for p in parts]))\n        return result.encode(\"charmap\")\n\nimport zlib\nfrom functools import wraps\n\nfrom zope.interface import implementer\n\nfrom twisted.python.compat import _PY3, networkString\nfrom twisted.python.compat import nativeString, intToBytes, unicode, itervalues\nfrom twisted.python.deprecate import deprecatedModuleAttribute, deprecated\nfrom twisted.python.failure import Failure\nfrom incremental import Version\n\nfrom twisted.web.iweb import IPolicyForHTTPS, IAgentEndpointFactory\nfrom twisted.python.deprecate import getDeprecationWarningString\nfrom twisted.web import http\nfrom twisted.internet import defer, protocol, task, reactor\nfrom twisted.internet.abstract import isIPv6Address\nfrom twisted.internet.interfaces import IProtocol, IOpenSSLContextFactory\nfrom twisted.internet.endpoints import HostnameEndpoint, wrapClientTLS\nfrom twisted.python.util import InsensitiveDict\nfrom twisted.python.components import proxyForInterface\nfrom twisted.web import error\nfrom twisted.web.iweb import UNKNOWN_LENGTH, IAgent, IBodyProducer, IResponse\nfrom twisted.web.http_headers import Headers\nfrom twisted.logger import Logger\n\n\nclass PartialDownloadError(error.Error):\n    \"\"\"\n    Page was only partially downloaded, we got disconnected in middle.\n\n    @ivar response: All of the response body which was downloaded.\n    \"\"\"\n\n\nclass HTTPPageGetter(http.HTTPClient):\n    \"\"\"\n    Gets a resource via HTTP, then quits.\n\n    Typically used with L{HTTPClientFactory}.  Note that this class does not, by\n    itself, do anything with the response.  If you want to download a resource\n    into a file, use L{HTTPPageDownloader} instead.\n\n    @ivar _completelyDone: A boolean indicating whether any further requests are\n        necessary after this one completes in order to provide a result to\n        C{self.factory.deferred}.  If it is C{False}, then a redirect is going\n        to be followed.  Otherwise, this protocol's connection is the last one\n        before firing the result Deferred.  This is used to make sure the result\n        Deferred is only fired after the connection is cleaned up.\n    \"\"\"\n\n    quietLoss = 0\n    followRedirect = True\n    failed = 0\n\n    _completelyDone = True\n\n    _specialHeaders = set((b'host', b'user-agent', b'cookie', b'content-length'))\n\n    def connectionMade(self):\n        method = getattr(self.factory, 'method', b'GET')\n        self.sendCommand(method, self.factory.path)\n        if self.factory.scheme == b'http' and self.factory.port != 80:\n            host = self.factory.host + b':' + intToBytes(self.factory.port)\n        elif self.factory.scheme == b'https' and self.factory.port != 443:\n            host = self.factory.host + b':' + intToBytes(self.factory.port)\n        else:\n            host = self.factory.host\n        self.sendHeader(b'Host', self.factory.headers.get(b\"host\", host))\n        self.sendHeader(b'User-Agent', self.factory.agent)\n        data = getattr(self.factory, 'postdata', None)\n        if data is not None:\n            self.sendHeader(b\"Content-Length\", intToBytes(len(data)))\n\n        cookieData = []\n        for (key, value) in self.factory.headers.items():\n            if key.lower() not in self._specialHeaders:\n                # we calculated it on our own\n                self.sendHeader(key, value)\n            if key.lower() == b'cookie':\n                cookieData.append(value)\n        for cookie, cookval in self.factory.cookies.items():\n            cookieData.append(cookie + b'=' + cookval)\n        if cookieData:\n            self.sendHeader(b'Cookie', b'; '.join(cookieData))\n        self.endHeaders()\n        self.headers = {}\n\n        if data is not None:\n            self.transport.write(data)\n\n    def handleHeader(self, key, value):\n        \"\"\"\n        Called every time a header is received. Stores the header information\n        as key-value pairs in the C{headers} attribute.\n\n        @type key: C{str}\n        @param key: An HTTP header field name.\n\n        @type value: C{str}\n        @param value: An HTTP header field value.\n        \"\"\"\n        key = key.lower()\n        l = self.headers.setdefault(key, [])\n        l.append(value)\n\n    def handleStatus(self, version, status, message):\n        \"\"\"\n        Handle the HTTP status line.\n\n        @param version: The HTTP version.\n        @type version: L{bytes}\n        @param status: The HTTP status code, an integer represented as a\n            bytestring.\n        @type status: L{bytes}\n        @param message: The HTTP status message.\n        @type message: L{bytes}\n        \"\"\"\n        self.version, self.status, self.message = version, status, message\n        self.factory.gotStatus(version, status, message)\n\n    def handleEndHeaders(self):\n        self.factory.gotHeaders(self.headers)\n        m = getattr(self, 'handleStatus_' + nativeString(self.status),\n                    self.handleStatusDefault)\n        m()\n\n    def handleStatus_200(self):\n        pass\n\n    handleStatus_201 = lambda self: self.handleStatus_200()\n    handleStatus_202 = lambda self: self.handleStatus_200()\n\n    def handleStatusDefault(self):\n        self.failed = 1\n\n    def handleStatus_301(self):\n        l = self.headers.get(b'location')\n        if not l:\n            self.handleStatusDefault()\n            return\n        url = l[0]\n        if self.followRedirect:\n            self.factory._redirectCount += 1\n            if self.factory._redirectCount >= self.factory.redirectLimit:\n                err = error.InfiniteRedirection(\n                    self.status,\n                    b'Infinite redirection detected',\n                    location=url)\n                self.factory.noPage(Failure(err))\n                self.quietLoss = True\n                self.transport.loseConnection()\n                return\n\n            self._completelyDone = False\n            self.factory.setURL(url)\n\n            if self.factory.scheme == b'https':\n                from twisted.internet import ssl\n                contextFactory = ssl.ClientContextFactory()\n                reactor.connectSSL(nativeString(self.factory.host),\n                                   self.factory.port,\n                                   self.factory, contextFactory)\n            else:\n                reactor.connectTCP(nativeString(self.factory.host),\n                                   self.factory.port,\n                                   self.factory)\n        else:\n            self.handleStatusDefault()\n            self.factory.noPage(\n                Failure(\n                    error.PageRedirect(\n                        self.status, self.message, location = url)))\n        self.quietLoss = True\n        self.transport.loseConnection()\n\n    def handleStatus_302(self):\n        if self.afterFoundGet:\n            self.handleStatus_303()\n        else:\n            self.handleStatus_301()\n\n\n    def handleStatus_303(self):\n        self.factory.method = b'GET'\n        self.handleStatus_301()\n\n\n    def connectionLost(self, reason):\n        \"\"\"\n        When the connection used to issue the HTTP request is closed, notify the\n        factory if we have not already, so it can produce a result.\n        \"\"\"\n        if not self.quietLoss:\n            http.HTTPClient.connectionLost(self, reason)\n            self.factory.noPage(reason)\n        if self._completelyDone:\n            # Only if we think we're completely done do we tell the factory that\n            # we're \"disconnected\".  This way when we're following redirects,\n            # only the last protocol used will fire the _disconnectedDeferred.\n            self.factory._disconnectedDeferred.callback(None)\n\n\n    def handleResponse(self, response):\n        if self.quietLoss:\n            return\n        if self.failed:\n            self.factory.noPage(\n                Failure(\n                    error.Error(\n                        self.status, self.message, response)))\n        if self.factory.method == b'HEAD':\n            # Callback with empty string, since there is never a response\n            # body for HEAD requests.\n            self.factory.page(b'')\n        elif self.length != None and self.length != 0:\n            self.factory.noPage(Failure(\n                PartialDownloadError(self.status, self.message, response)))\n        else:\n            self.factory.page(response)\n        # server might be stupid and not close connection. admittedly\n        # the fact we do only one request per connection is also\n        # stupid...\n        self.transport.loseConnection()\n\n    def timeout(self):\n        self.quietLoss = True\n        self.transport.abortConnection()\n        self.factory.noPage(defer.TimeoutError(\"Getting %s took longer than %s seconds.\" % (self.factory.url, self.factory.timeout)))\n\n\nclass HTTPPageDownloader(HTTPPageGetter):\n\n    transmittingPage = 0\n\n    def handleStatus_200(self, partialContent=0):\n        HTTPPageGetter.handleStatus_200(self)\n        self.transmittingPage = 1\n        self.factory.pageStart(partialContent)\n\n    def handleStatus_206(self):\n        self.handleStatus_200(partialContent=1)\n\n    def handleResponsePart(self, data):\n        if self.transmittingPage:\n            self.factory.pagePart(data)\n\n    def handleResponseEnd(self):\n        if self.length:\n            self.transmittingPage = 0\n            self.factory.noPage(\n                Failure(\n                    PartialDownloadError(self.status)))\n        if self.transmittingPage:\n            self.factory.pageEnd()\n            self.transmittingPage = 0\n        if self.failed:\n            self.factory.noPage(\n                Failure(\n                    error.Error(\n                        self.status, self.message, None)))\n            self.transport.loseConnection()\n\n\nclass HTTPClientFactory(protocol.ClientFactory):\n    \"\"\"Download a given URL.\n\n    @type deferred: Deferred\n    @ivar deferred: A Deferred that will fire when the content has\n          been retrieved. Once this is fired, the ivars `status', `version',\n          and `message' will be set.\n\n    @type status: bytes\n    @ivar status: The status of the response.\n\n    @type version: bytes\n    @ivar version: The version of the response.\n\n    @type message: bytes\n    @ivar message: The text message returned with the status.\n\n    @type response_headers: dict\n    @ivar response_headers: The headers that were specified in the\n          response from the server.\n\n    @type method: bytes\n    @ivar method: The HTTP method to use in the request.  This should be one of\n        OPTIONS, GET, HEAD, POST, PUT, DELETE, TRACE, or CONNECT (case\n        matters).  Other values may be specified if the server being contacted\n        supports them.\n\n    @type redirectLimit: int\n    @ivar redirectLimit: The maximum number of HTTP redirects that can occur\n          before it is assumed that the redirection is endless.\n\n    @type afterFoundGet: C{bool}\n    @ivar afterFoundGet: Deviate from the HTTP 1.1 RFC by handling redirects\n        the same way as most web browsers; if the request method is POST and a\n        302 status is encountered, the redirect is followed with a GET method\n\n    @type _redirectCount: int\n    @ivar _redirectCount: The current number of HTTP redirects encountered.\n\n    @ivar _disconnectedDeferred: A L{Deferred} which only fires after the last\n        connection associated with the request (redirects may cause multiple\n        connections to be required) has closed.  The result Deferred will only\n        fire after this Deferred, so that callers can be assured that there are\n        no more event sources in the reactor once they get the result.\n    \"\"\"\n\n    protocol = HTTPPageGetter\n\n    url = None\n    scheme = None\n    host = b''\n    port = None\n    path = None\n\n    def __init__(self, url, method=b'GET', postdata=None, headers=None,\n                 agent=b\"Twisted PageGetter\", timeout=0, cookies=None,\n                 followRedirect=True, redirectLimit=20,\n                 afterFoundGet=False):\n        self.followRedirect = followRedirect\n        self.redirectLimit = redirectLimit\n        self._redirectCount = 0\n        self.timeout = timeout\n        self.agent = agent\n        self.afterFoundGet = afterFoundGet\n        if cookies is None:\n            cookies = {}\n        self.cookies = cookies\n        if headers is not None:\n            self.headers = InsensitiveDict(headers)\n        else:\n            self.headers = InsensitiveDict()\n        if postdata is not None:\n            self.headers.setdefault(b'Content-Length',\n                                    intToBytes(len(postdata)))\n            # just in case a broken http/1.1 decides to keep connection alive\n            self.headers.setdefault(b\"connection\", b\"close\")\n        self.postdata = postdata\n        self.method = method\n\n        self.setURL(url)\n\n        self.waiting = 1\n        self._disconnectedDeferred = defer.Deferred()\n        self.deferred = defer.Deferred()\n        # Make sure the first callback on the result Deferred pauses the\n        # callback chain until the request connection is closed.\n        self.deferred.addBoth(self._waitForDisconnect)\n        self.response_headers = None\n\n\n    def _waitForDisconnect(self, passthrough):\n        \"\"\"\n        Chain onto the _disconnectedDeferred, preserving C{passthrough}, so that\n        the result is only available after the associated connection has been\n        closed.\n        \"\"\"\n        self._disconnectedDeferred.addCallback(lambda ignored: passthrough)\n        return self._disconnectedDeferred\n\n\n    def __repr__(self):\n        return \"<%s: %s>\" % (self.__class__.__name__, self.url)\n\n    def setURL(self, url):\n        self.url = url\n        uri = URI.fromBytes(url)\n        if uri.scheme and uri.host:\n            self.scheme = uri.scheme\n            self.host = uri.host\n            self.port = uri.port\n        self.path = uri.originForm\n\n    def buildProtocol(self, addr):\n        p = protocol.ClientFactory.buildProtocol(self, addr)\n        p.followRedirect = self.followRedirect\n        p.afterFoundGet = self.afterFoundGet\n        if self.timeout:\n            timeoutCall = reactor.callLater(self.timeout, p.timeout)\n            self.deferred.addBoth(self._cancelTimeout, timeoutCall)\n        return p\n\n    def _cancelTimeout(self, result, timeoutCall):\n        if timeoutCall.active():\n            timeoutCall.cancel()\n        return result\n\n    def gotHeaders(self, headers):\n        \"\"\"\n        Parse the response HTTP headers.\n\n        @param headers: The response HTTP headers.\n        @type headers: L{dict}\n        \"\"\"\n        self.response_headers = headers\n        if b'set-cookie' in headers:\n            for cookie in headers[b'set-cookie']:\n                if b'=' in cookie:\n                    cookparts = cookie.split(b';')\n                    cook = cookparts[0]\n                    cook.lstrip()\n                    k, v = cook.split(b'=', 1)\n                    self.cookies[k.lstrip()] = v.lstrip()\n\n    def gotStatus(self, version, status, message):\n        \"\"\"\n        Set the status of the request on us.\n\n        @param version: The HTTP version.\n        @type version: L{bytes}\n        @param status: The HTTP status code, an integer represented as a\n            bytestring.\n        @type status: L{bytes}\n        @param message: The HTTP status message.\n        @type message: L{bytes}\n        \"\"\"\n        self.version, self.status, self.message = version, status, message\n\n    def page(self, page):\n        if self.waiting:\n            self.waiting = 0\n            self.deferred.callback(page)\n\n    def noPage(self, reason):\n        if self.waiting:\n            self.waiting = 0\n            self.deferred.errback(reason)\n\n    def clientConnectionFailed(self, _, reason):\n        \"\"\"\n        When a connection attempt fails, the request cannot be issued.  If no\n        result has yet been provided to the result Deferred, provide the\n        connection failure reason as an error result.\n        \"\"\"\n        if self.waiting:\n            self.waiting = 0\n            # If the connection attempt failed, there is nothing more to\n            # disconnect, so just fire that Deferred now.\n            self._disconnectedDeferred.callback(None)\n            self.deferred.errback(reason)\n\n\n\nclass HTTPDownloader(HTTPClientFactory):\n    \"\"\"\n    Download to a file.\n    \"\"\"\n    protocol = HTTPPageDownloader\n    value = None\n    _log = Logger()\n\n    def __init__(self, url, fileOrName,\n                 method=b'GET', postdata=None, headers=None,\n                 agent=b\"Twisted client\", supportPartial=False,\n                 timeout=0, cookies=None, followRedirect=True,\n                 redirectLimit=20, afterFoundGet=False):\n        self.requestedPartial = 0\n        if isinstance(fileOrName, (str, unicode)):\n            self.fileName = fileOrName\n            self.file = None\n            if supportPartial and os.path.exists(self.fileName):\n                fileLength = os.path.getsize(self.fileName)\n                if fileLength:\n                    self.requestedPartial = fileLength\n                    if headers == None:\n                        headers = {}\n                    headers[b\"range\"] = b\"bytes=\" + intToBytes(fileLength) + b\"-\"\n        else:\n            self.file = fileOrName\n        HTTPClientFactory.__init__(\n            self, url, method=method, postdata=postdata, headers=headers,\n            agent=agent, timeout=timeout, cookies=cookies,\n            followRedirect=followRedirect, redirectLimit=redirectLimit,\n            afterFoundGet=afterFoundGet)\n\n\n    def gotHeaders(self, headers):\n        HTTPClientFactory.gotHeaders(self, headers)\n        if self.requestedPartial:\n            contentRange = headers.get(b\"content-range\", None)\n            if not contentRange:\n                # server doesn't support partial requests, oh well\n                self.requestedPartial = 0\n                return\n            start, end, realLength = http.parseContentRange(contentRange[0])\n            if start != self.requestedPartial:\n                # server is acting weirdly\n                self.requestedPartial = 0\n\n\n    def openFile(self, partialContent):\n        if partialContent:\n            file = open(self.fileName, 'rb+')\n            file.seek(0, 2)\n        else:\n            file = open(self.fileName, 'wb')\n        return file\n\n    def pageStart(self, partialContent):\n        \"\"\"Called on page download start.\n\n        @param partialContent: tells us if the download is partial download we requested.\n        \"\"\"\n        if partialContent and not self.requestedPartial:\n            raise ValueError(\"we shouldn't get partial content response if we didn't want it!\")\n        if self.waiting:\n            try:\n                if not self.file:\n                    self.file = self.openFile(partialContent)\n            except IOError:\n                #raise\n                self.deferred.errback(Failure())\n\n    def pagePart(self, data):\n        if not self.file:\n            return\n        try:\n            self.file.write(data)\n        except IOError:\n            #raise\n            self.file = None\n            self.deferred.errback(Failure())\n\n\n    def noPage(self, reason):\n        \"\"\"\n        Close the storage file and errback the waiting L{Deferred} with the\n        given reason.\n        \"\"\"\n        if self.waiting:\n            self.waiting = 0\n            if self.file:\n                try:\n                    self.file.close()\n                except:\n                    self._log.failure(\"Error closing HTTPDownloader file\")\n            self.deferred.errback(reason)\n\n\n    def pageEnd(self):\n        self.waiting = 0\n        if not self.file:\n            return\n        try:\n            self.file.close()\n        except IOError:\n            self.deferred.errback(Failure())\n            return\n        self.deferred.callback(self.value)\n\n\n\nclass URI(object):\n    \"\"\"\n    A URI object.\n\n    @see: U{https://tools.ietf.org/html/draft-ietf-httpbis-p1-messaging-21}\n    \"\"\"\n    def __init__(self, scheme, netloc, host, port, path, params, query,\n                 fragment):\n        \"\"\"\n        @type scheme: L{bytes}\n        @param scheme: URI scheme specifier.\n\n        @type netloc: L{bytes}\n        @param netloc: Network location component.\n\n        @type host: L{bytes}\n        @param host: Host name. For IPv6 address literals the brackets are\n            stripped.\n\n        @type port: L{int}\n        @param port: Port number.\n\n        @type path: L{bytes}\n        @param path: Hierarchical path.\n\n        @type params: L{bytes}\n        @param params: Parameters for last path segment.\n\n        @type query: L{bytes}\n        @param query: Query string.\n\n        @type fragment: L{bytes}\n        @param fragment: Fragment identifier.\n        \"\"\"\n        self.scheme = scheme\n        self.netloc = netloc\n        self.host = host.strip(b'[]')\n        self.port = port\n        self.path = path\n        self.params = params\n        self.query = query\n        self.fragment = fragment\n\n\n    @classmethod\n    def fromBytes(cls, uri, defaultPort=None):\n        \"\"\"\n        Parse the given URI into a L{URI}.\n\n        @type uri: C{bytes}\n        @param uri: URI to parse.\n\n        @type defaultPort: C{int} or L{None}\n        @param defaultPort: An alternate value to use as the port if the URI\n            does not include one.\n\n        @rtype: L{URI}\n        @return: Parsed URI instance.\n        \"\"\"\n        uri = uri.strip()\n        scheme, netloc, path, params, query, fragment = http.urlparse(uri)\n\n        if defaultPort is None:\n            if scheme == b'https':\n                defaultPort = 443\n            else:\n                defaultPort = 80\n\n        if b':' in netloc:\n            host, port = netloc.rsplit(b':', 1)\n            try:\n                port = int(port)\n            except ValueError:\n                host, port = netloc, defaultPort\n        else:\n            host, port = netloc, defaultPort\n        return cls(scheme, netloc, host, port, path, params, query, fragment)\n\n\n    def toBytes(self):\n        \"\"\"\n        Assemble the individual parts of the I{URI} into a fully formed I{URI}.\n\n        @rtype: C{bytes}\n        @return: A fully formed I{URI}.\n        \"\"\"\n        return urlunparse(\n            (self.scheme, self.netloc, self.path, self.params, self.query,\n             self.fragment))\n\n\n    @property\n    def originForm(self):\n        \"\"\"\n        The absolute I{URI} path including I{URI} parameters, query string and\n        fragment identifier.\n\n        @see: U{https://tools.ietf.org/html/draft-ietf-httpbis-p1-messaging-21#section-5.3}\n\n        @return: The absolute path in original form.\n        @rtype: L{bytes}\n        \"\"\"\n        # The HTTP bis draft says the origin form should not include the\n        # fragment.\n        path = urlunparse(\n            (b'', b'', self.path, self.params, self.query, b''))\n        if path == b'':\n            path = b'/'\n        return path\n\n\n\ndef _urljoin(base, url):\n    \"\"\"\n    Construct a full (\"absolute\") URL by combining a \"base URL\" with another\n    URL. Informally, this uses components of the base URL, in particular the\n    addressing scheme, the network location and (part of) the path, to provide\n    missing components in the relative URL.\n\n    Additionally, the fragment identifier is preserved according to the HTTP\n    1.1 bis draft.\n\n    @type base: C{bytes}\n    @param base: Base URL.\n\n    @type url: C{bytes}\n    @param url: URL to combine with C{base}.\n\n    @return: An absolute URL resulting from the combination of C{base} and\n        C{url}.\n\n    @see: L{urlparse.urljoin}\n\n    @see: U{https://tools.ietf.org/html/draft-ietf-httpbis-p2-semantics-22#section-7.1.2}\n    \"\"\"\n    base, baseFrag = urldefrag(base)\n    url, urlFrag = urldefrag(urljoin(base, url))\n    return urljoin(url, b'#' + (urlFrag or baseFrag))\n\n\n\ndef _makeGetterFactory(url, factoryFactory, contextFactory=None,\n                       *args, **kwargs):\n    \"\"\"\n    Create and connect an HTTP page getting factory.\n\n    Any additional positional or keyword arguments are used when calling\n    C{factoryFactory}.\n\n    @param factoryFactory: Factory factory that is called with C{url}, C{args}\n        and C{kwargs} to produce the getter\n\n    @param contextFactory: Context factory to use when creating a secure\n        connection, defaulting to L{None}\n\n    @return: The factory created by C{factoryFactory}\n    \"\"\"\n    uri = URI.fromBytes(url)\n    factory = factoryFactory(url, *args, **kwargs)\n    if uri.scheme == b'https':\n        from twisted.internet import ssl\n        if contextFactory is None:\n            contextFactory = ssl.ClientContextFactory()\n        reactor.connectSSL(\n            nativeString(uri.host), uri.port, factory, contextFactory)\n    else:\n        reactor.connectTCP(nativeString(uri.host), uri.port, factory)\n    return factory\n\n\n_GETPAGE_REPLACEMENT_TEXT = \"https://pypi.org/project/treq/ or twisted.web.client.Agent\"\n\ndef _deprecateGetPageClasses():\n    \"\"\"\n    Mark the protocols and factories associated with L{getPage} and\n    L{downloadPage} as deprecated.\n    \"\"\"\n    for klass in [\n        HTTPPageGetter, HTTPPageDownloader,\n        HTTPClientFactory, HTTPDownloader\n    ]:\n        deprecatedModuleAttribute(\n            Version(\"Twisted\", 16, 7, 0),\n            getDeprecationWarningString(\n                klass,\n                Version(\"Twisted\", 16, 7, 0),\n                replacement=_GETPAGE_REPLACEMENT_TEXT)\n            .split(\"; \")[1],\n            klass.__module__,\n            klass.__name__)\n\n_deprecateGetPageClasses()\n\n\n\n@deprecated(Version(\"Twisted\", 16, 7, 0),\n            _GETPAGE_REPLACEMENT_TEXT)\ndef getPage(url, contextFactory=None, *args, **kwargs):\n    \"\"\"\n    Download a web page as a string.\n\n    Download a page. Return a deferred, which will callback with a\n    page (as a string) or errback with a description of the error.\n\n    See L{HTTPClientFactory} to see what extra arguments can be passed.\n    \"\"\"\n    return _makeGetterFactory(\n        url,\n        HTTPClientFactory,\n        contextFactory=contextFactory,\n        *args, **kwargs).deferred\n\n\n\n@deprecated(Version(\"Twisted\", 16, 7, 0),\n            _GETPAGE_REPLACEMENT_TEXT)\ndef downloadPage(url, file, contextFactory=None, *args, **kwargs):\n    \"\"\"\n    Download a web page to a file.\n\n    @param file: path to file on filesystem, or file-like object.\n\n    See HTTPDownloader to see what extra args can be passed.\n    \"\"\"\n    factoryFactory = lambda url, *a, **kw: HTTPDownloader(url, file, *a, **kw)\n    return _makeGetterFactory(\n        url,\n        factoryFactory,\n        contextFactory=contextFactory,\n        *args, **kwargs).deferred\n\n\n# The code which follows is based on the new HTTP client implementation.  It\n# should be significantly better than anything above, though it is not yet\n# feature equivalent.\n\nfrom twisted.web.error import SchemeNotSupported\nfrom twisted.web._newclient import (\n    HTTP11ClientProtocol,\n    PotentialDataLoss,\n    Request,\n    RequestGenerationFailed,\n    RequestNotSent,\n    RequestTransmissionFailed,\n    Response,\n    ResponseDone,\n    ResponseFailed,\n    ResponseNeverReceived,\n    _WrapperException,\n    )\n\n\n\ntry:\n    from OpenSSL import SSL\nexcept ImportError:\n    SSL = None\nelse:\n    from twisted.internet.ssl import (CertificateOptions,\n                                      platformTrust,\n                                      optionsForClientTLS)\n\n\ndef _requireSSL(decoratee):\n    \"\"\"\n    The decorated method requires pyOpenSSL to be present, or it raises\n    L{NotImplementedError}.\n\n    @param decoratee: A function which requires pyOpenSSL.\n    @type decoratee: L{callable}\n\n    @return: A function which raises L{NotImplementedError} if pyOpenSSL is not\n        installed; otherwise, if it is installed, simply return C{decoratee}.\n    @rtype: L{callable}\n    \"\"\"\n    if SSL is None:\n        @wraps(decoratee)\n        def raiseNotImplemented(*a, **kw):\n            \"\"\"\n            pyOpenSSL is not available.\n\n            @param a: The positional arguments for C{decoratee}.\n\n            @param kw: The keyword arguments for C{decoratee}.\n\n            @raise NotImplementedError: Always.\n            \"\"\"\n            raise NotImplementedError(\"SSL support unavailable\")\n        return raiseNotImplemented\n    return decoratee\n\n\n\nclass WebClientContextFactory(object):\n    \"\"\"\n    This class is deprecated.  Please simply use L{Agent} as-is, or if you want\n    to customize something, use L{BrowserLikePolicyForHTTPS}.\n\n    A L{WebClientContextFactory} is an HTTPS policy which totally ignores the\n    hostname and port.  It performs basic certificate verification, however the\n    lack of validation of service identity (e.g.  hostname validation) means it\n    is still vulnerable to man-in-the-middle attacks.  Don't use it any more.\n    \"\"\"\n\n    def _getCertificateOptions(self, hostname, port):\n        \"\"\"\n        Return a L{CertificateOptions}.\n\n        @param hostname: ignored\n\n        @param port: ignored\n\n        @return: A new CertificateOptions instance.\n        @rtype: L{CertificateOptions}\n        \"\"\"\n        return CertificateOptions(\n            method=SSL.SSLv23_METHOD,\n            trustRoot=platformTrust()\n        )\n\n\n    @_requireSSL\n    def getContext(self, hostname, port):\n        \"\"\"\n        Return an L{OpenSSL.SSL.Context}.\n\n        @param hostname: ignored\n        @param port: ignored\n\n        @return: A new SSL context.\n        @rtype: L{OpenSSL.SSL.Context}\n        \"\"\"\n        return self._getCertificateOptions(hostname, port).getContext()\n\n\n\n@implementer(IPolicyForHTTPS)\nclass BrowserLikePolicyForHTTPS(object):\n    \"\"\"\n    SSL connection creator for web clients.\n    \"\"\"\n    def __init__(self, trustRoot=None):\n        self._trustRoot = trustRoot\n\n\n    @_requireSSL\n    def creatorForNetloc(self, hostname, port):\n        \"\"\"\n        Create a L{client connection creator\n        <twisted.internet.interfaces.IOpenSSLClientConnectionCreator>} for a\n        given network location.\n\n        @param tls: The TLS protocol to create a connection for.\n        @type tls: L{twisted.protocols.tls.TLSMemoryBIOProtocol}\n\n        @param hostname: The hostname part of the URI.\n        @type hostname: L{bytes}\n\n        @param port: The port part of the URI.\n        @type port: L{int}\n\n        @return: a connection creator with appropriate verification\n            restrictions set\n        @rtype: L{client connection creator\n            <twisted.internet.interfaces.IOpenSSLClientConnectionCreator>}\n        \"\"\"\n        return optionsForClientTLS(hostname.decode(\"ascii\"),\n                                   trustRoot=self._trustRoot)\n\n\n\ndeprecatedModuleAttribute(Version(\"Twisted\", 14, 0, 0),\n                          getDeprecationWarningString(\n                              WebClientContextFactory,\n                              Version(\"Twisted\", 14, 0, 0),\n                              replacement=BrowserLikePolicyForHTTPS)\n                          .split(\"; \")[1],\n                          WebClientContextFactory.__module__,\n                          WebClientContextFactory.__name__)\n\n\n\n@implementer(IPolicyForHTTPS)\nclass HostnameCachingHTTPSPolicy(object):\n    \"\"\"\n    IPolicyForHTTPS that wraps a L{IPolicyForHTTPS} and caches the created\n    L{IOpenSSLClientConnectionCreator}.\n\n    This policy will cache up to C{cacheSize}\n    L{client connection creators <twisted.internet.interfaces.\n    IOpenSSLClientConnectionCreator>} for reuse in subsequent requests to\n    the same hostname.\n\n    @ivar _policyForHTTPS: See C{policyforHTTPS} parameter of L{__init__}.\n\n    @ivar _cache: A cache associating hostnames to their\n        L{client connection creators <twisted.internet.interfaces.\n        IOpenSSLClientConnectionCreator>}.\n    @type _cache: L{collections.OrderedDict}\n\n    @ivar _cacheSize: See C{cacheSize} parameter of L{__init__}.\n\n    @since: Twisted 19.2.0\n    \"\"\"\n\n    def __init__(self, policyforHTTPS, cacheSize=20):\n        \"\"\"\n        @param policyforHTTPS: The IPolicyForHTTPS to wrap.\n        @type policyforHTTPS: L{IPolicyForHTTPS}\n\n        @param cacheSize: The maximum size of the hostname cache.\n        @type cacheSize: L{int}\n        \"\"\"\n        self._policyForHTTPS = policyforHTTPS\n        self._cache = collections.OrderedDict()\n        self._cacheSize = cacheSize\n\n\n    def creatorForNetloc(self, hostname, port):\n        \"\"\"\n        Create a L{client connection creator\n        <twisted.internet.interfaces.IOpenSSLClientConnectionCreator>} for a\n        given network location and cache it for future use.\n\n        @param hostname: The hostname part of the URI.\n        @type hostname: L{bytes}\n\n        @param port: The port part of the URI.\n        @type port: L{int}\n\n        @return: a connection creator with appropriate verification\n            restrictions set\n        @rtype: L{client connection creator\n            <twisted.internet.interfaces.IOpenSSLClientConnectionCreator>}\n        \"\"\"\n        host = hostname.decode(\"ascii\")\n        try:\n            creator = self._cache.pop(host)\n        except KeyError:\n            creator = self._policyForHTTPS.creatorForNetloc(hostname, port)\n\n        self._cache[host] = creator\n        if len(self._cache) > self._cacheSize:\n            self._cache.popitem(last=False)\n\n        return creator\n\n\n\n@implementer(IOpenSSLContextFactory)\nclass _ContextFactoryWithContext(object):\n    \"\"\"\n    A L{_ContextFactoryWithContext} is like a\n    L{twisted.internet.ssl.ContextFactory} with a pre-created context.\n\n    @ivar _context: A Context.\n    @type _context: L{OpenSSL.SSL.Context}\n    \"\"\"\n\n    def __init__(self, context):\n        \"\"\"\n        Initialize a L{_ContextFactoryWithContext} with a context.\n\n        @param context: An SSL context.\n        @type context: L{OpenSSL.SSL.Context}\n        \"\"\"\n        self._context = context\n\n\n    def getContext(self):\n        \"\"\"\n        Return the context created by\n        L{_DeprecatedToCurrentPolicyForHTTPS._webContextFactory}.\n\n        @return: A context.\n        @rtype context: L{OpenSSL.SSL.Context}\n        \"\"\"\n        return self._context\n\n\n\n@implementer(IPolicyForHTTPS)\nclass _DeprecatedToCurrentPolicyForHTTPS(object):\n    \"\"\"\n    Adapt a web context factory to a normal context factory.\n\n    @ivar _webContextFactory: An object providing a getContext method with\n        C{hostname} and C{port} arguments.\n    @type _webContextFactory: L{WebClientContextFactory} (or object with a\n        similar C{getContext} method).\n    \"\"\"\n    def __init__(self, webContextFactory):\n        \"\"\"\n        Wrap a web context factory in an L{IPolicyForHTTPS}.\n\n        @param webContextFactory: An object providing a getContext method with\n            C{hostname} and C{port} arguments.\n        @type webContextFactory: L{WebClientContextFactory} (or object with a\n            similar C{getContext} method).\n        \"\"\"\n        self._webContextFactory = webContextFactory\n\n\n    def creatorForNetloc(self, hostname, port):\n        \"\"\"\n        Called the wrapped web context factory's C{getContext} method with a\n        hostname and port number and return the resulting context object.\n\n        @param hostname: The hostname part of the URI.\n        @type hostname: L{bytes}\n\n        @param port: The port part of the URI.\n        @type port: L{int}\n\n        @return: A context factory.\n        @rtype: L{IOpenSSLContextFactory}\n        \"\"\"\n        context = self._webContextFactory.getContext(hostname, port)\n        return _ContextFactoryWithContext(context)\n\n\n\n@implementer(IBodyProducer)\nclass FileBodyProducer(object):\n    \"\"\"\n    L{FileBodyProducer} produces bytes from an input file object incrementally\n    and writes them to a consumer.\n\n    Since file-like objects cannot be read from in an event-driven manner,\n    L{FileBodyProducer} uses a L{Cooperator} instance to schedule reads from\n    the file.  This process is also paused and resumed based on notifications\n    from the L{IConsumer} provider being written to.\n\n    The file is closed after it has been read, or if the producer is stopped\n    early.\n\n    @ivar _inputFile: Any file-like object, bytes read from which will be\n        written to a consumer.\n\n    @ivar _cooperate: A method like L{Cooperator.cooperate} which is used to\n        schedule all reads.\n\n    @ivar _readSize: The number of bytes to read from C{_inputFile} at a time.\n    \"\"\"\n\n    def __init__(self, inputFile, cooperator=task, readSize=2 ** 16):\n        self._inputFile = inputFile\n        self._cooperate = cooperator.cooperate\n        self._readSize = readSize\n        self.length = self._determineLength(inputFile)\n\n\n    def _determineLength(self, fObj):\n        \"\"\"\n        Determine how many bytes can be read out of C{fObj} (assuming it is not\n        modified from this point on).  If the determination cannot be made,\n        return C{UNKNOWN_LENGTH}.\n        \"\"\"\n        try:\n            seek = fObj.seek\n            tell = fObj.tell\n        except AttributeError:\n            return UNKNOWN_LENGTH\n        originalPosition = tell()\n        seek(0, os.SEEK_END)\n        end = tell()\n        seek(originalPosition, os.SEEK_SET)\n        return end - originalPosition\n\n\n    def stopProducing(self):\n        \"\"\"\n        Permanently stop writing bytes from the file to the consumer by\n        stopping the underlying L{CooperativeTask}.\n        \"\"\"\n        self._inputFile.close()\n        self._task.stop()\n\n\n    def startProducing(self, consumer):\n        \"\"\"\n        Start a cooperative task which will read bytes from the input file and\n        write them to C{consumer}.  Return a L{Deferred} which fires after all\n        bytes have been written.\n\n        @param consumer: Any L{IConsumer} provider\n        \"\"\"\n        self._task = self._cooperate(self._writeloop(consumer))\n        d = self._task.whenDone()\n        def maybeStopped(reason):\n            # IBodyProducer.startProducing's Deferred isn't support to fire if\n            # stopProducing is called.\n            reason.trap(task.TaskStopped)\n            return defer.Deferred()\n        d.addCallbacks(lambda ignored: None, maybeStopped)\n        return d\n\n\n    def _writeloop(self, consumer):\n        \"\"\"\n        Return an iterator which reads one chunk of bytes from the input file\n        and writes them to the consumer for each time it is iterated.\n        \"\"\"\n        while True:\n            bytes = self._inputFile.read(self._readSize)\n            if not bytes:\n                self._inputFile.close()\n                break\n            consumer.write(bytes)\n            yield None\n\n\n    def pauseProducing(self):\n        \"\"\"\n        Temporarily suspend copying bytes from the input file to the consumer\n        by pausing the L{CooperativeTask} which drives that activity.\n        \"\"\"\n        self._task.pause()\n\n\n    def resumeProducing(self):\n        \"\"\"\n        Undo the effects of a previous C{pauseProducing} and resume copying\n        bytes to the consumer by resuming the L{CooperativeTask} which drives\n        the write activity.\n        \"\"\"\n        self._task.resume()\n\n\n\nclass _HTTP11ClientFactory(protocol.Factory):\n    \"\"\"\n    A factory for L{HTTP11ClientProtocol}, used by L{HTTPConnectionPool}.\n\n    @ivar _quiescentCallback: The quiescent callback to be passed to protocol\n        instances, used to return them to the connection pool.\n\n    @ivar _metadata: Metadata about the low-level connection details,\n        used to make the repr more useful.\n\n    @since: 11.1\n    \"\"\"\n    def __init__(self, quiescentCallback, metadata):\n        self._quiescentCallback = quiescentCallback\n        self._metadata = metadata\n\n\n    def __repr__(self):\n        return '_HTTP11ClientFactory({}, {})'.format(\n            self._quiescentCallback,\n            self._metadata)\n\n    def buildProtocol(self, addr):\n        return HTTP11ClientProtocol(self._quiescentCallback)\n\n\n\nclass _RetryingHTTP11ClientProtocol(object):\n    \"\"\"\n    A wrapper for L{HTTP11ClientProtocol} that automatically retries requests.\n\n    @ivar _clientProtocol: The underlying L{HTTP11ClientProtocol}.\n\n    @ivar _newConnection: A callable that creates a new connection for a\n        retry.\n    \"\"\"\n\n    def __init__(self, clientProtocol, newConnection):\n        self._clientProtocol = clientProtocol\n        self._newConnection = newConnection\n\n\n    def _shouldRetry(self, method, exception, bodyProducer):\n        \"\"\"\n        Indicate whether request should be retried.\n\n        Only returns C{True} if method is idempotent, no response was\n        received, the reason for the failed request was not due to\n        user-requested cancellation, and no body was sent. The latter\n        requirement may be relaxed in the future, and PUT added to approved\n        method list.\n\n        @param method: The method of the request.\n        @type method: L{bytes}\n        \"\"\"\n        if method not in (b\"GET\", b\"HEAD\", b\"OPTIONS\", b\"DELETE\", b\"TRACE\"):\n            return False\n        if not isinstance(exception, (RequestNotSent,\n                                      RequestTransmissionFailed,\n                                      ResponseNeverReceived)):\n            return False\n        if isinstance(exception, _WrapperException):\n            for aFailure in exception.reasons:\n                if aFailure.check(defer.CancelledError):\n                    return False\n        if bodyProducer is not None:\n            return False\n        return True\n\n\n    def request(self, request):\n        \"\"\"\n        Do a request, and retry once (with a new connection) if it fails in\n        a retryable manner.\n\n        @param request: A L{Request} instance that will be requested using the\n            wrapped protocol.\n        \"\"\"\n        d = self._clientProtocol.request(request)\n\n        def failed(reason):\n            if self._shouldRetry(request.method, reason.value,\n                                 request.bodyProducer):\n                return self._newConnection().addCallback(\n                    lambda connection: connection.request(request))\n            else:\n                return reason\n        d.addErrback(failed)\n        return d\n\n\n\nclass HTTPConnectionPool(object):\n    \"\"\"\n    A pool of persistent HTTP connections.\n\n    Features:\n     - Cached connections will eventually time out.\n     - Limits on maximum number of persistent connections.\n\n    Connections are stored using keys, which should be chosen such that any\n    connections stored under a given key can be used interchangeably.\n\n    Failed requests done using previously cached connections will be retried\n    once if they use an idempotent method (e.g. GET), in case the HTTP server\n    timed them out.\n\n    @ivar persistent: Boolean indicating whether connections should be\n        persistent. Connections are persistent by default.\n\n    @ivar maxPersistentPerHost: The maximum number of cached persistent\n        connections for a C{host:port} destination.\n    @type maxPersistentPerHost: C{int}\n\n    @ivar cachedConnectionTimeout: Number of seconds a cached persistent\n        connection will stay open before disconnecting.\n\n    @ivar retryAutomatically: C{boolean} indicating whether idempotent\n        requests should be retried once if no response was received.\n\n    @ivar _factory: The factory used to connect to the proxy.\n\n    @ivar _connections: Map (scheme, host, port) to lists of\n        L{HTTP11ClientProtocol} instances.\n\n    @ivar _timeouts: Map L{HTTP11ClientProtocol} instances to a\n        C{IDelayedCall} instance of their timeout.\n\n    @since: 12.1\n    \"\"\"\n\n    _factory = _HTTP11ClientFactory\n    maxPersistentPerHost = 2\n    cachedConnectionTimeout = 240\n    retryAutomatically = True\n    _log = Logger()\n\n    def __init__(self, reactor, persistent=True):\n        self._reactor = reactor\n        self.persistent = persistent\n        self._connections = {}\n        self._timeouts = {}\n\n\n    def getConnection(self, key, endpoint):\n        \"\"\"\n        Supply a connection, newly created or retrieved from the pool, to be\n        used for one HTTP request.\n\n        The connection will remain out of the pool (not available to be\n        returned from future calls to this method) until one HTTP request has\n        been completed over it.\n\n        Afterwards, if the connection is still open, it will automatically be\n        added to the pool.\n\n        @param key: A unique key identifying connections that can be used\n            interchangeably.\n\n        @param endpoint: An endpoint that can be used to open a new connection\n            if no cached connection is available.\n\n        @return: A C{Deferred} that will fire with a L{HTTP11ClientProtocol}\n           (or a wrapper) that can be used to send a single HTTP request.\n        \"\"\"\n        # Try to get cached version:\n        connections = self._connections.get(key)\n        while connections:\n            connection = connections.pop(0)\n            # Cancel timeout:\n            self._timeouts[connection].cancel()\n            del self._timeouts[connection]\n            if connection.state == \"QUIESCENT\":\n                if self.retryAutomatically:\n                    newConnection = lambda: self._newConnection(key, endpoint)\n                    connection = _RetryingHTTP11ClientProtocol(\n                        connection, newConnection)\n                return defer.succeed(connection)\n\n        return self._newConnection(key, endpoint)\n\n\n    def _newConnection(self, key, endpoint):\n        \"\"\"\n        Create a new connection.\n\n        This implements the new connection code path for L{getConnection}.\n        \"\"\"\n        def quiescentCallback(protocol):\n            self._putConnection(key, protocol)\n        factory = self._factory(quiescentCallback, repr(endpoint))\n        return endpoint.connect(factory)\n\n\n    def _removeConnection(self, key, connection):\n        \"\"\"\n        Remove a connection from the cache and disconnect it.\n        \"\"\"\n        connection.transport.loseConnection()\n        self._connections[key].remove(connection)\n        del self._timeouts[connection]\n\n\n    def _putConnection(self, key, connection):\n        \"\"\"\n        Return a persistent connection to the pool. This will be called by\n        L{HTTP11ClientProtocol} when the connection becomes quiescent.\n        \"\"\"\n        if connection.state != \"QUIESCENT\":\n            # Log with traceback for debugging purposes:\n            try:\n                raise RuntimeError(\n                    \"BUG: Non-quiescent protocol added to connection pool.\")\n            except:\n                self._log.failure(\n                    \"BUG: Non-quiescent protocol added to connection pool.\")\n            return\n        connections = self._connections.setdefault(key, [])\n        if len(connections) == self.maxPersistentPerHost:\n            dropped = connections.pop(0)\n            dropped.transport.loseConnection()\n            self._timeouts[dropped].cancel()\n            del self._timeouts[dropped]\n        connections.append(connection)\n        cid = self._reactor.callLater(self.cachedConnectionTimeout,\n                                      self._removeConnection,\n                                      key, connection)\n        self._timeouts[connection] = cid\n\n\n    def closeCachedConnections(self):\n        \"\"\"\n        Close all persistent connections and remove them from the pool.\n\n        @return: L{defer.Deferred} that fires when all connections have been\n            closed.\n        \"\"\"\n        results = []\n        for protocols in itervalues(self._connections):\n            for p in protocols:\n                results.append(p.abort())\n        self._connections = {}\n        for dc in itervalues(self._timeouts):\n            dc.cancel()\n        self._timeouts = {}\n        return defer.gatherResults(results).addCallback(lambda ign: None)\n\n\n\nclass _AgentBase(object):\n    \"\"\"\n    Base class offering common facilities for L{Agent}-type classes.\n\n    @ivar _reactor: The C{IReactorTime} implementation which will be used by\n        the pool, and perhaps by subclasses as well.\n\n    @ivar _pool: The L{HTTPConnectionPool} used to manage HTTP connections.\n    \"\"\"\n\n    def __init__(self, reactor, pool):\n        if pool is None:\n            pool = HTTPConnectionPool(reactor, False)\n        self._reactor = reactor\n        self._pool = pool\n\n\n    def _computeHostValue(self, scheme, host, port):\n        \"\"\"\n        Compute the string to use for the value of the I{Host} header, based on\n        the given scheme, host name, and port number.\n        \"\"\"\n        if (isIPv6Address(nativeString(host))):\n            host = b'[' + host + b']'\n        if (scheme, port) in ((b'http', 80), (b'https', 443)):\n            return host\n        return host + b\":\" + intToBytes(port)\n\n\n    def _requestWithEndpoint(self, key, endpoint, method, parsedURI,\n                             headers, bodyProducer, requestPath):\n        \"\"\"\n        Issue a new request, given the endpoint and the path sent as part of\n        the request.\n        \"\"\"\n        if not isinstance(method, bytes):\n            raise TypeError('method={!r} is {}, but must be bytes'.format(\n                    method, type(method)))\n        # Create minimal headers, if necessary:\n        if headers is None:\n            headers = Headers()\n        if not headers.hasHeader(b'host'):\n            headers = headers.copy()\n            headers.addRawHeader(\n                b'host', self._computeHostValue(parsedURI.scheme,\n                                                parsedURI.host,\n                                                parsedURI.port))\n\n        d = self._pool.getConnection(key, endpoint)\n        def cbConnected(proto):\n            return proto.request(\n                Request._construct(method, requestPath, headers, bodyProducer,\n                                   persistent=self._pool.persistent,\n                                   parsedURI=parsedURI))\n        d.addCallback(cbConnected)\n        return d\n\n\n\n@implementer(IAgentEndpointFactory)\nclass _StandardEndpointFactory(object):\n    \"\"\"\n    Standard HTTP endpoint destinations - TCP for HTTP, TCP+TLS for HTTPS.\n\n    @ivar _policyForHTTPS: A web context factory which will be used to create\n        SSL context objects for any SSL connections the agent needs to make.\n\n    @ivar _connectTimeout: If not L{None}, the timeout passed to\n        L{HostnameEndpoint} for specifying the connection timeout.\n\n    @ivar _bindAddress: If not L{None}, the address passed to\n        L{HostnameEndpoint} for specifying the local address to bind to.\n    \"\"\"\n    def __init__(self, reactor, contextFactory, connectTimeout, bindAddress):\n        \"\"\"\n        @param reactor: A provider to use to create endpoints.\n        @type reactor: see L{HostnameEndpoint.__init__} for acceptable reactor\n            types.\n\n        @param contextFactory: A factory for TLS contexts, to control the\n            verification parameters of OpenSSL.\n        @type contextFactory: L{IPolicyForHTTPS}.\n\n        @param connectTimeout: The amount of time that this L{Agent} will wait\n            for the peer to accept a connection.\n        @type connectTimeout: L{float} or L{None}\n\n        @param bindAddress: The local address for client sockets to bind to.\n        @type bindAddress: L{bytes} or L{None}\n        \"\"\"\n        self._reactor = reactor\n        self._policyForHTTPS = contextFactory\n        self._connectTimeout = connectTimeout\n        self._bindAddress = bindAddress\n\n\n    def endpointForURI(self, uri):\n        \"\"\"\n        Connect directly over TCP for C{b'http'} scheme, and TLS for\n        C{b'https'}.\n\n        @param uri: L{URI} to connect to.\n\n        @return: Endpoint to connect to.\n        @rtype: L{IStreamClientEndpoint}\n        \"\"\"\n        kwargs = {}\n        if self._connectTimeout is not None:\n            kwargs['timeout'] = self._connectTimeout\n        kwargs['bindAddress'] = self._bindAddress\n\n        try:\n            host = nativeString(uri.host)\n        except UnicodeDecodeError:\n            raise ValueError((\"The host of the provided URI ({uri.host!r}) \"\n                              \"contains non-ASCII octets, it should be ASCII \"\n                              \"decodable.\").format(uri=uri))\n\n        endpoint = HostnameEndpoint(self._reactor, host, uri.port, **kwargs)\n        if uri.scheme == b'http':\n            return endpoint\n        elif uri.scheme == b'https':\n            connectionCreator = self._policyForHTTPS.creatorForNetloc(uri.host,\n                                                                      uri.port)\n            return wrapClientTLS(connectionCreator, endpoint)\n        else:\n            raise SchemeNotSupported(\"Unsupported scheme: %r\" % (uri.scheme,))\n\n\n\n@implementer(IAgent)\nclass Agent(_AgentBase):\n    \"\"\"\n    L{Agent} is a very basic HTTP client.  It supports I{HTTP} and I{HTTPS}\n    scheme URIs.\n\n    @ivar _pool: An L{HTTPConnectionPool} instance.\n\n    @ivar _endpointFactory: The L{IAgentEndpointFactory} which will\n        be used to create endpoints for outgoing connections.\n\n    @since: 9.0\n    \"\"\"\n\n    def __init__(self, reactor,\n                 contextFactory=BrowserLikePolicyForHTTPS(),\n                 connectTimeout=None, bindAddress=None,\n                 pool=None):\n        \"\"\"\n        Create an L{Agent}.\n\n        @param reactor: A reactor for this L{Agent} to place outgoing\n            connections.\n        @type reactor: see L{HostnameEndpoint.__init__} for acceptable reactor\n            types.\n\n        @param contextFactory: A factory for TLS contexts, to control the\n            verification parameters of OpenSSL.  The default is to use a\n            L{BrowserLikePolicyForHTTPS}, so unless you have special\n            requirements you can leave this as-is.\n        @type contextFactory: L{IPolicyForHTTPS}.\n\n        @param connectTimeout: The amount of time that this L{Agent} will wait\n            for the peer to accept a connection.\n        @type connectTimeout: L{float}\n\n        @param bindAddress: The local address for client sockets to bind to.\n        @type bindAddress: L{bytes}\n\n        @param pool: An L{HTTPConnectionPool} instance, or L{None}, in which\n            case a non-persistent L{HTTPConnectionPool} instance will be\n            created.\n        @type pool: L{HTTPConnectionPool}\n        \"\"\"\n        if not IPolicyForHTTPS.providedBy(contextFactory):\n            warnings.warn(\n                repr(contextFactory) +\n                \" was passed as the HTTPS policy for an Agent, but it does \"\n                \"not provide IPolicyForHTTPS.  Since Twisted 14.0, you must \"\n                \"pass a provider of IPolicyForHTTPS.\",\n                stacklevel=2, category=DeprecationWarning\n            )\n            contextFactory = _DeprecatedToCurrentPolicyForHTTPS(contextFactory)\n        endpointFactory = _StandardEndpointFactory(\n            reactor, contextFactory, connectTimeout, bindAddress)\n        self._init(reactor, endpointFactory, pool)\n\n\n    @classmethod\n    def usingEndpointFactory(cls, reactor, endpointFactory, pool=None):\n        \"\"\"\n        Create a new L{Agent} that will use the endpoint factory to figure\n        out how to connect to the server.\n\n        @param reactor: A reactor for this L{Agent} to place outgoing\n            connections.\n        @type reactor: see L{HostnameEndpoint.__init__} for acceptable reactor\n            types.\n\n        @param endpointFactory: Used to construct endpoints which the\n            HTTP client will connect with.\n        @type endpointFactory: an L{IAgentEndpointFactory} provider.\n\n        @param pool: An L{HTTPConnectionPool} instance, or L{None}, in which\n            case a non-persistent L{HTTPConnectionPool} instance will be\n            created.\n        @type pool: L{HTTPConnectionPool}\n\n        @return: A new L{Agent}.\n        \"\"\"\n        agent = cls.__new__(cls)\n        agent._init(reactor, endpointFactory, pool)\n        return agent\n\n\n    def _init(self, reactor, endpointFactory, pool):\n        \"\"\"\n        Initialize a new L{Agent}.\n\n        @param reactor: A reactor for this L{Agent} to place outgoing\n            connections.\n        @type reactor: see L{HostnameEndpoint.__init__} for acceptable reactor\n            types.\n\n        @param endpointFactory: Used to construct endpoints which the\n            HTTP client will connect with.\n        @type endpointFactory: an L{IAgentEndpointFactory} provider.\n\n        @param pool: An L{HTTPConnectionPool} instance, or L{None}, in which\n            case a non-persistent L{HTTPConnectionPool} instance will be\n            created.\n        @type pool: L{HTTPConnectionPool}\n\n        @return: A new L{Agent}.\n        \"\"\"\n        _AgentBase.__init__(self, reactor, pool)\n        self._endpointFactory = endpointFactory\n\n\n    def _getEndpoint(self, uri):\n        \"\"\"\n        Get an endpoint for the given URI, using C{self._endpointFactory}.\n\n        @param uri: The URI of the request.\n        @type uri: L{URI}\n\n        @return: An endpoint which can be used to connect to given address.\n        \"\"\"\n        return self._endpointFactory.endpointForURI(uri)\n\n\n    def request(self, method, uri, headers=None, bodyProducer=None):\n        \"\"\"\n        Issue a request to the server indicated by the given C{uri}.\n\n        An existing connection from the connection pool may be used or a new\n        one may be created.\n\n        I{HTTP} and I{HTTPS} schemes are supported in C{uri}.\n\n        @see: L{twisted.web.iweb.IAgent.request}\n        \"\"\"\n        parsedURI = URI.fromBytes(uri)\n        try:\n            endpoint = self._getEndpoint(parsedURI)\n        except SchemeNotSupported:\n            return defer.fail(Failure())\n        key = (parsedURI.scheme, parsedURI.host, parsedURI.port)\n        return self._requestWithEndpoint(key, endpoint, method, parsedURI,\n                                         headers, bodyProducer,\n                                         parsedURI.originForm)\n\n\n\n@implementer(IAgent)\nclass ProxyAgent(_AgentBase):\n    \"\"\"\n    An HTTP agent able to cross HTTP proxies.\n\n    @ivar _proxyEndpoint: The endpoint used to connect to the proxy.\n\n    @since: 11.1\n    \"\"\"\n\n    def __init__(self, endpoint, reactor=None, pool=None):\n        if reactor is None:\n            from twisted.internet import reactor\n        _AgentBase.__init__(self, reactor, pool)\n        self._proxyEndpoint = endpoint\n\n\n    def request(self, method, uri, headers=None, bodyProducer=None):\n        \"\"\"\n        Issue a new request via the configured proxy.\n        \"\"\"\n        # Cache *all* connections under the same key, since we are only\n        # connecting to a single destination, the proxy:\n        key = (\"http-proxy\", self._proxyEndpoint)\n\n        # To support proxying HTTPS via CONNECT, we will use key\n        # (\"http-proxy-CONNECT\", scheme, host, port), and an endpoint that\n        # wraps _proxyEndpoint with an additional callback to do the CONNECT.\n        return self._requestWithEndpoint(key, self._proxyEndpoint, method,\n                                         URI.fromBytes(uri), headers,\n                                         bodyProducer, uri)\n\n\n\nclass _FakeUrllib2Request(object):\n    \"\"\"\n    A fake C{urllib2.Request} object for C{cookielib} to work with.\n\n    @see: U{http://docs.python.org/library/urllib2.html#request-objects}\n\n    @type uri: native L{str}\n    @ivar uri: Request URI.\n\n    @type headers: L{twisted.web.http_headers.Headers}\n    @ivar headers: Request headers.\n\n    @type type: native L{str}\n    @ivar type: The scheme of the URI.\n\n    @type host: native L{str}\n    @ivar host: The host[:port] of the URI.\n\n    @since: 11.1\n    \"\"\"\n    def __init__(self, uri):\n        \"\"\"\n        Create a fake Urllib2 request.\n\n        @param uri: Request URI.\n        @type uri: L{bytes}\n        \"\"\"\n        self.uri = nativeString(uri)\n        self.headers = Headers()\n\n        _uri = URI.fromBytes(uri)\n        self.type = nativeString(_uri.scheme)\n        self.host = nativeString(_uri.host)\n\n        if (_uri.scheme, _uri.port) not in ((b'http', 80), (b'https', 443)):\n            # If it's not a schema on the regular port, add the port.\n            self.host += \":\" + str(_uri.port)\n\n        if _PY3:\n            self.origin_req_host = nativeString(_uri.host)\n            self.unverifiable = lambda _: False\n\n\n    def has_header(self, header):\n        return self.headers.hasHeader(networkString(header))\n\n\n    def add_unredirected_header(self, name, value):\n        self.headers.addRawHeader(networkString(name), networkString(value))\n\n\n    def get_full_url(self):\n        return self.uri\n\n\n    def get_header(self, name, default=None):\n        headers = self.headers.getRawHeaders(networkString(name), default)\n        if headers is not None:\n            headers = [nativeString(x) for x in headers]\n            return headers[0]\n        return None\n\n\n    def get_host(self):\n        return self.host\n\n\n    def get_type(self):\n        return self.type\n\n\n    def is_unverifiable(self):\n        # In theory this shouldn't be hardcoded.\n        return False\n\n\n\nclass _FakeUrllib2Response(object):\n    \"\"\"\n    A fake C{urllib2.Response} object for C{cookielib} to work with.\n\n    @type response: C{twisted.web.iweb.IResponse}\n    @ivar response: Underlying Twisted Web response.\n\n    @since: 11.1\n    \"\"\"\n    def __init__(self, response):\n        self.response = response\n\n\n    def info(self):\n        class _Meta(object):\n            def getheaders(zelf, name):\n                # PY2\n                headers = self.response.headers.getRawHeaders(name, [])\n                return headers\n            def get_all(zelf, name, default):\n                # PY3\n                headers = self.response.headers.getRawHeaders(\n                    networkString(name), default)\n                h = [nativeString(x) for x in headers]\n                return h\n        return _Meta()\n\n\n\n@implementer(IAgent)\nclass CookieAgent(object):\n    \"\"\"\n    L{CookieAgent} extends the basic L{Agent} to add RFC-compliant\n    handling of HTTP cookies.  Cookies are written to and extracted\n    from a C{cookielib.CookieJar} instance.\n\n    The same cookie jar instance will be used for any requests through this\n    agent, mutating it whenever a I{Set-Cookie} header appears in a response.\n\n    @type _agent: L{twisted.web.client.Agent}\n    @ivar _agent: Underlying Twisted Web agent to issue requests through.\n\n    @type cookieJar: C{cookielib.CookieJar}\n    @ivar cookieJar: Initialized cookie jar to read cookies from and store\n        cookies to.\n\n    @since: 11.1\n    \"\"\"\n    def __init__(self, agent, cookieJar):\n        self._agent = agent\n        self.cookieJar = cookieJar\n\n\n    def request(self, method, uri, headers=None, bodyProducer=None):\n        \"\"\"\n        Issue a new request to the wrapped L{Agent}.\n\n        Send a I{Cookie} header if a cookie for C{uri} is stored in\n        L{CookieAgent.cookieJar}. Cookies are automatically extracted and\n        stored from requests.\n\n        If a C{'cookie'} header appears in C{headers} it will override the\n        automatic cookie header obtained from the cookie jar.\n\n        @see: L{Agent.request}\n        \"\"\"\n        if headers is None:\n            headers = Headers()\n        lastRequest = _FakeUrllib2Request(uri)\n        # Setting a cookie header explicitly will disable automatic request\n        # cookies.\n        if not headers.hasHeader(b'cookie'):\n            self.cookieJar.add_cookie_header(lastRequest)\n            cookieHeader = lastRequest.get_header('Cookie', None)\n            if cookieHeader is not None:\n                headers = headers.copy()\n                headers.addRawHeader(b'cookie', networkString(cookieHeader))\n\n        d = self._agent.request(method, uri, headers, bodyProducer)\n        d.addCallback(self._extractCookies, lastRequest)\n        return d\n\n\n    def _extractCookies(self, response, request):\n        \"\"\"\n        Extract response cookies and store them in the cookie jar.\n\n        @type response: L{twisted.web.iweb.IResponse}\n        @param response: Twisted Web response.\n\n        @param request: A urllib2 compatible request object.\n        \"\"\"\n        resp = _FakeUrllib2Response(response)\n        self.cookieJar.extract_cookies(resp, request)\n        return response\n\n\n\nclass GzipDecoder(proxyForInterface(IResponse)):\n    \"\"\"\n    A wrapper for a L{Response} instance which handles gzip'ed body.\n\n    @ivar original: The original L{Response} object.\n\n    @since: 11.1\n    \"\"\"\n\n    def __init__(self, response):\n        self.original = response\n        self.length = UNKNOWN_LENGTH\n\n\n    def deliverBody(self, protocol):\n        \"\"\"\n        Override C{deliverBody} to wrap the given C{protocol} with\n        L{_GzipProtocol}.\n        \"\"\"\n        self.original.deliverBody(_GzipProtocol(protocol, self.original))\n\n\n\nclass _GzipProtocol(proxyForInterface(IProtocol)):\n    \"\"\"\n    A L{Protocol} implementation which wraps another one, transparently\n    decompressing received data.\n\n    @ivar _zlibDecompress: A zlib decompress object used to decompress the data\n        stream.\n\n    @ivar _response: A reference to the original response, in case of errors.\n\n    @since: 11.1\n    \"\"\"\n\n    def __init__(self, protocol, response):\n        self.original = protocol\n        self._response = response\n        self._zlibDecompress = zlib.decompressobj(16 + zlib.MAX_WBITS)\n\n\n    def dataReceived(self, data):\n        \"\"\"\n        Decompress C{data} with the zlib decompressor, forwarding the raw data\n        to the original protocol.\n        \"\"\"\n        try:\n            rawData = self._zlibDecompress.decompress(data)\n        except zlib.error:\n            raise ResponseFailed([Failure()], self._response)\n        if rawData:\n            self.original.dataReceived(rawData)\n\n\n    def connectionLost(self, reason):\n        \"\"\"\n        Forward the connection lost event, flushing remaining data from the\n        decompressor if any.\n        \"\"\"\n        try:\n            rawData = self._zlibDecompress.flush()\n        except zlib.error:\n            raise ResponseFailed([reason, Failure()], self._response)\n        if rawData:\n            self.original.dataReceived(rawData)\n        self.original.connectionLost(reason)\n\n\n\n@implementer(IAgent)\nclass ContentDecoderAgent(object):\n    \"\"\"\n    An L{Agent} wrapper to handle encoded content.\n\n    It takes care of declaring the support for content in the\n    I{Accept-Encoding} header, and automatically decompresses the received data\n    if it's effectively using compression.\n\n    @param decoders: A list or tuple of (name, decoder) objects. The name\n        declares which decoding the decoder supports, and the decoder must\n        return a response object when called/instantiated. For example,\n        C{(('gzip', GzipDecoder))}. The order determines how the decoders are\n        going to be advertized to the server.\n\n    @since: 11.1\n    \"\"\"\n\n    def __init__(self, agent, decoders):\n        self._agent = agent\n        self._decoders = dict(decoders)\n        self._supported = b','.join([decoder[0] for decoder in decoders])\n\n\n    def request(self, method, uri, headers=None, bodyProducer=None):\n        \"\"\"\n        Send a client request which declares supporting compressed content.\n\n        @see: L{Agent.request}.\n        \"\"\"\n        if headers is None:\n            headers = Headers()\n        else:\n            headers = headers.copy()\n        headers.addRawHeader(b'accept-encoding', self._supported)\n        deferred = self._agent.request(method, uri, headers, bodyProducer)\n        return deferred.addCallback(self._handleResponse)\n\n\n    def _handleResponse(self, response):\n        \"\"\"\n        Check if the response is encoded, and wrap it to handle decompression.\n        \"\"\"\n        contentEncodingHeaders = response.headers.getRawHeaders(\n            b'content-encoding', [])\n        contentEncodingHeaders = b','.join(contentEncodingHeaders).split(b',')\n        while contentEncodingHeaders:\n            name = contentEncodingHeaders.pop().strip()\n            decoder = self._decoders.get(name)\n            if decoder is not None:\n                response = decoder(response)\n            else:\n                # Add it back\n                contentEncodingHeaders.append(name)\n                break\n        if contentEncodingHeaders:\n            response.headers.setRawHeaders(\n                b'content-encoding', [b','.join(contentEncodingHeaders)])\n        else:\n            response.headers.removeHeader(b'content-encoding')\n        return response\n\n\n\n@implementer(IAgent)\nclass RedirectAgent(object):\n    \"\"\"\n    An L{Agent} wrapper which handles HTTP redirects.\n\n    The implementation is rather strict: 301 and 302 behaves like 307, not\n    redirecting automatically on methods different from I{GET} and I{HEAD}.\n\n    See L{BrowserLikeRedirectAgent} for a redirecting Agent that behaves more\n    like a web browser.\n\n    @param redirectLimit: The maximum number of times the agent is allowed to\n        follow redirects before failing with a L{error.InfiniteRedirection}.\n\n    @cvar _redirectResponses: A L{list} of HTTP status codes to be redirected\n        for I{GET} and I{HEAD} methods.\n\n    @cvar _seeOtherResponses: A L{list} of HTTP status codes to be redirected\n        for any method and the method altered to I{GET}.\n\n    @since: 11.1\n    \"\"\"\n\n    _redirectResponses = [http.MOVED_PERMANENTLY, http.FOUND,\n                          http.TEMPORARY_REDIRECT]\n    _seeOtherResponses = [http.SEE_OTHER]\n\n\n    def __init__(self, agent, redirectLimit=20):\n        self._agent = agent\n        self._redirectLimit = redirectLimit\n\n\n    def request(self, method, uri, headers=None, bodyProducer=None):\n        \"\"\"\n        Send a client request following HTTP redirects.\n\n        @see: L{Agent.request}.\n        \"\"\"\n        deferred = self._agent.request(method, uri, headers, bodyProducer)\n        return deferred.addCallback(\n            self._handleResponse, method, uri, headers, 0)\n\n\n    def _resolveLocation(self, requestURI, location):\n        \"\"\"\n        Resolve the redirect location against the request I{URI}.\n\n        @type requestURI: C{bytes}\n        @param requestURI: The request I{URI}.\n\n        @type location: C{bytes}\n        @param location: The redirect location.\n\n        @rtype: C{bytes}\n        @return: Final resolved I{URI}.\n        \"\"\"\n        return _urljoin(requestURI, location)\n\n\n    def _handleRedirect(self, response, method, uri, headers, redirectCount):\n        \"\"\"\n        Handle a redirect response, checking the number of redirects already\n        followed, and extracting the location header fields.\n        \"\"\"\n        if redirectCount >= self._redirectLimit:\n            err = error.InfiniteRedirection(\n                response.code,\n                b'Infinite redirection detected',\n                location=uri)\n            raise ResponseFailed([Failure(err)], response)\n        locationHeaders = response.headers.getRawHeaders(b'location', [])\n        if not locationHeaders:\n            err = error.RedirectWithNoLocation(\n                response.code, b'No location header field', uri)\n            raise ResponseFailed([Failure(err)], response)\n        location = self._resolveLocation(uri, locationHeaders[0])\n        deferred = self._agent.request(method, location, headers)\n        def _chainResponse(newResponse):\n            newResponse.setPreviousResponse(response)\n            return newResponse\n        deferred.addCallback(_chainResponse)\n        return deferred.addCallback(\n            self._handleResponse, method, uri, headers, redirectCount + 1)\n\n\n    def _handleResponse(self, response, method, uri, headers, redirectCount):\n        \"\"\"\n        Handle the response, making another request if it indicates a redirect.\n        \"\"\"\n        if response.code in self._redirectResponses:\n            if method not in (b'GET', b'HEAD'):\n                err = error.PageRedirect(response.code, location=uri)\n                raise ResponseFailed([Failure(err)], response)\n            return self._handleRedirect(response, method, uri, headers,\n                                        redirectCount)\n        elif response.code in self._seeOtherResponses:\n            return self._handleRedirect(response, b'GET', uri, headers,\n                                        redirectCount)\n        return response\n\n\n\nclass BrowserLikeRedirectAgent(RedirectAgent):\n    \"\"\"\n    An L{Agent} wrapper which handles HTTP redirects in the same fashion as web\n    browsers.\n\n    Unlike L{RedirectAgent}, the implementation is more relaxed: 301 and 302\n    behave like 303, redirecting automatically on any method and altering the\n    redirect request to a I{GET}.\n\n    @see: L{RedirectAgent}\n\n    @since: 13.1\n    \"\"\"\n    _redirectResponses = [http.TEMPORARY_REDIRECT]\n    _seeOtherResponses = [http.MOVED_PERMANENTLY, http.FOUND, http.SEE_OTHER]\n\n\n\nclass _ReadBodyProtocol(protocol.Protocol):\n    \"\"\"\n    Protocol that collects data sent to it.\n\n    This is a helper for L{IResponse.deliverBody}, which collects the body and\n    fires a deferred with it.\n\n    @ivar deferred: See L{__init__}.\n    @ivar status: See L{__init__}.\n    @ivar message: See L{__init__}.\n\n    @ivar dataBuffer: list of byte-strings received\n    @type dataBuffer: L{list} of L{bytes}\n    \"\"\"\n\n    def __init__(self, status, message, deferred):\n        \"\"\"\n        @param status: Status of L{IResponse}\n        @ivar status: L{int}\n\n        @param message: Message of L{IResponse}\n        @type message: L{bytes}\n\n        @param deferred: deferred to fire when response is complete\n        @type deferred: L{Deferred} firing with L{bytes}\n        \"\"\"\n        self.deferred = deferred\n        self.status = status\n        self.message = message\n        self.dataBuffer = []\n\n\n    def dataReceived(self, data):\n        \"\"\"\n        Accumulate some more bytes from the response.\n        \"\"\"\n        self.dataBuffer.append(data)\n\n\n    def connectionLost(self, reason):\n        \"\"\"\n        Deliver the accumulated response bytes to the waiting L{Deferred}, if\n        the response body has been completely received without error.\n        \"\"\"\n        if reason.check(ResponseDone):\n            self.deferred.callback(b''.join(self.dataBuffer))\n        elif reason.check(PotentialDataLoss):\n            self.deferred.errback(\n                PartialDownloadError(self.status, self.message,\n                                     b''.join(self.dataBuffer)))\n        else:\n            self.deferred.errback(reason)\n\n\n\ndef readBody(response):\n    \"\"\"\n    Get the body of an L{IResponse} and return it as a byte string.\n\n    This is a helper function for clients that don't want to incrementally\n    receive the body of an HTTP response.\n\n    @param response: The HTTP response for which the body will be read.\n    @type response: L{IResponse} provider\n\n    @return: A L{Deferred} which will fire with the body of the response.\n        Cancelling it will close the connection to the server immediately.\n    \"\"\"\n    def cancel(deferred):\n        \"\"\"\n        Cancel a L{readBody} call, close the connection to the HTTP server\n        immediately, if it is still open.\n\n        @param deferred: The cancelled L{defer.Deferred}.\n        \"\"\"\n        abort = getAbort()\n        if abort is not None:\n            abort()\n\n    d = defer.Deferred(cancel)\n    protocol = _ReadBodyProtocol(response.code, response.phrase, d)\n    def getAbort():\n        return getattr(protocol.transport, 'abortConnection', None)\n\n    response.deliverBody(protocol)\n\n    if protocol.transport is not None and getAbort() is None:\n        warnings.warn(\n            'Using readBody with a transport that does not have an '\n            'abortConnection method',\n            category=DeprecationWarning,\n            stacklevel=2)\n\n    return d\n\n\n\n__all__ = [\n    'Agent',\n    'BrowserLikeRedirectAgent',\n    'ContentDecoderAgent',\n    'CookieAgent',\n    'downloadPage',\n    'getPage',\n    'GzipDecoder',\n    'HTTPClientFactory',\n    'HTTPConnectionPool',\n    'HTTPDownloader',\n    'HTTPPageDownloader',\n    'HTTPPageGetter',\n    'PartialDownloadError',\n    'ProxyAgent',\n    'readBody',\n    'RedirectAgent',\n    'RequestGenerationFailed',\n    'RequestTransmissionFailed',\n    'Response',\n    'ResponseDone',\n    'ResponseFailed',\n    'ResponseNeverReceived',\n    'URI',\n    ]\n", "patch": "@@ -47,6 +47,9 @@ def urlunparse(parts):\n from twisted.web.http_headers import Headers\n from twisted.logger import Logger\n \n+from twisted.web._newclient import _ensureValidURI, _ensureValidMethod\n+\n+\n \n class PartialDownloadError(error.Error):\n     \"\"\"\n@@ -78,11 +81,13 @@ class HTTPPageGetter(http.HTTPClient):\n \n     _completelyDone = True\n \n-    _specialHeaders = set((b'host', b'user-agent', b'cookie', b'content-length'))\n+    _specialHeaders = set(\n+        (b'host', b'user-agent', b'cookie', b'content-length'),\n+    )\n \n     def connectionMade(self):\n-        method = getattr(self.factory, 'method', b'GET')\n-        self.sendCommand(method, self.factory.path)\n+        method = _ensureValidMethod(getattr(self.factory, 'method', b'GET'))\n+        self.sendCommand(method, _ensureValidURI(self.factory.path))\n         if self.factory.scheme == b'http' and self.factory.port != 80:\n             host = self.factory.host + b':' + intToBytes(self.factory.port)\n         elif self.factory.scheme == b'https' and self.factory.port != 443:\n@@ -362,7 +367,7 @@ def __init__(self, url, method=b'GET', postdata=None, headers=None,\n             # just in case a broken http/1.1 decides to keep connection alive\n             self.headers.setdefault(b\"connection\", b\"close\")\n         self.postdata = postdata\n-        self.method = method\n+        self.method = _ensureValidMethod(method)\n \n         self.setURL(url)\n \n@@ -389,6 +394,7 @@ def __repr__(self):\n         return \"<%s: %s>\" % (self.__class__.__name__, self.url)\n \n     def setURL(self, url):\n+        _ensureValidURI(url.strip())\n         self.url = url\n         uri = URI.fromBytes(url)\n         if uri.scheme and uri.host:\n@@ -733,7 +739,7 @@ def _makeGetterFactory(url, factoryFactory, contextFactory=None,\n \n     @return: The factory created by C{factoryFactory}\n     \"\"\"\n-    uri = URI.fromBytes(url)\n+    uri = URI.fromBytes(_ensureValidURI(url.strip()))\n     factory = factoryFactory(url, *args, **kwargs)\n     if uri.scheme == b'https':\n         from twisted.internet import ssl\n@@ -1493,6 +1499,9 @@ def _requestWithEndpoint(self, key, endpoint, method, parsedURI,\n         if not isinstance(method, bytes):\n             raise TypeError('method={!r} is {}, but must be bytes'.format(\n                     method, type(method)))\n+\n+        method = _ensureValidMethod(method)\n+\n         # Create minimal headers, if necessary:\n         if headers is None:\n             headers = Headers()\n@@ -1717,6 +1726,7 @@ def request(self, method, uri, headers=None, bodyProducer=None):\n \n         @see: L{twisted.web.iweb.IAgent.request}\n         \"\"\"\n+        uri = _ensureValidURI(uri.strip())\n         parsedURI = URI.fromBytes(uri)\n         try:\n             endpoint = self._getEndpoint(parsedURI)\n@@ -1750,6 +1760,8 @@ def request(self, method, uri, headers=None, bodyProducer=None):\n         \"\"\"\n         Issue a new request via the configured proxy.\n         \"\"\"\n+        uri = _ensureValidURI(uri.strip())\n+\n         # Cache *all* connections under the same key, since we are only\n         # connecting to a single destination, the proxy:\n         key = (\"http-proxy\", self._proxyEndpoint)", "file_path": "files/2019_6\\158", "file_language": "py", "file_name": "src/twisted/web/client.py", "outdated_file_modify": 1, "outdated_file_before": 0, "outdated_file_after": 0, "llm_check": 1, "static_check": 0, "static": {"rats": [false, []], "semgrep": [false, []]}, "target": -1, "function_before": [], "function_after": []}, {"raw_url": "https://github.com/twisted/twisted/raw/6c61fc4503ae39ab8ecee52d10f10ee2c371d7e2/src%2Ftwisted%2Fweb%2Fnewsfragments%2F9647.bugfix", "code": "All HTTP clients in twisted.web.client now raise a ValueError when called with a method and/or URL that contain invalid characters.  This mitigates CVE-2019-12387.  Thanks to Alex Brasetvik for reporting this vulnerability.", "code_before": "", "patch": "@@ -0,0 +1 @@\n+All HTTP clients in twisted.web.client now raise a ValueError when called with a method and/or URL that contain invalid characters.  This mitigates CVE-2019-12387.  Thanks to Alex Brasetvik for reporting this vulnerability.\n\\ No newline at end of file", "file_path": "files/2019_6\\159", "file_language": "bugfix", "file_name": "src/twisted/web/newsfragments/9647.bugfix", "outdated_file_modify": 0, "outdated_file_before": 0, "outdated_file_after": 0}, {"raw_url": "https://github.com/twisted/twisted/raw/6c61fc4503ae39ab8ecee52d10f10ee2c371d7e2/src%2Ftwisted%2Fweb%2Ftest%2Finjectionhelpers.py", "code": "\"\"\"\nHelpers for URI and method injection tests.\n\n@see: U{CVE-2019-12387}\n\"\"\"\n\nimport string\n\n\nUNPRINTABLE_ASCII = (\n    frozenset(range(0, 128)) -\n    frozenset(bytearray(string.printable, 'ascii'))\n)\n\nNONASCII = frozenset(range(128, 256))\n\n\n\nclass MethodInjectionTestsMixin(object):\n    \"\"\"\n    A mixin that runs HTTP method injection tests.  Define\n    L{MethodInjectionTestsMixin.attemptRequestWithMaliciousMethod} in\n    a L{twisted.trial.unittest.SynchronousTestCase} subclass to test\n    how HTTP client code behaves when presented with malicious HTTP\n    methods.\n\n    @see: U{CVE-2019-12387}\n    \"\"\"\n\n    def attemptRequestWithMaliciousMethod(self, method):\n        \"\"\"\n        Attempt to send a request with the given method.  This should\n        synchronously raise a L{ValueError} if either is invalid.\n\n        @param method: the method (e.g. C{GET\\x00})\n\n        @param uri: the URI\n\n        @type method:\n        \"\"\"\n        raise NotImplementedError()\n\n\n    def test_methodWithCLRFRejected(self):\n        \"\"\"\n        Issuing a request with a method that contains a carriage\n        return and line feed fails with a L{ValueError}.\n        \"\"\"\n        with self.assertRaises(ValueError) as cm:\n            method = b\"GET\\r\\nX-Injected-Header: value\"\n            self.attemptRequestWithMaliciousMethod(method)\n        self.assertRegex(str(cm.exception), \"^Invalid method\")\n\n\n    def test_methodWithUnprintableASCIIRejected(self):\n        \"\"\"\n        Issuing a request with a method that contains unprintable\n        ASCII characters fails with a L{ValueError}.\n        \"\"\"\n        for c in UNPRINTABLE_ASCII:\n            method = b\"GET%s\" % (bytearray([c]),)\n            with self.assertRaises(ValueError) as cm:\n                self.attemptRequestWithMaliciousMethod(method)\n            self.assertRegex(str(cm.exception), \"^Invalid method\")\n\n\n    def test_methodWithNonASCIIRejected(self):\n        \"\"\"\n        Issuing a request with a method that contains non-ASCII\n        characters fails with a L{ValueError}.\n        \"\"\"\n        for c in NONASCII:\n            method = b\"GET%s\" % (bytearray([c]),)\n            with self.assertRaises(ValueError) as cm:\n                self.attemptRequestWithMaliciousMethod(method)\n            self.assertRegex(str(cm.exception), \"^Invalid method\")\n\n\n\nclass URIInjectionTestsMixin(object):\n    \"\"\"\n    A mixin that runs HTTP URI injection tests.  Define\n    L{MethodInjectionTestsMixin.attemptRequestWithMaliciousURI} in a\n    L{twisted.trial.unittest.SynchronousTestCase} subclass to test how\n    HTTP client code behaves when presented with malicious HTTP\n    URIs.\n    \"\"\"\n\n    def attemptRequestWithMaliciousURI(self, method):\n        \"\"\"\n        Attempt to send a request with the given URI.  This should\n        synchronously raise a L{ValueError} if either is invalid.\n\n        @param uri: the URI.\n\n        @type method:\n        \"\"\"\n        raise NotImplementedError()\n\n\n    def test_hostWithCRLFRejected(self):\n        \"\"\"\n        Issuing a request with a URI whose host contains a carriage\n        return and line feed fails with a L{ValueError}.\n        \"\"\"\n        with self.assertRaises(ValueError) as cm:\n            uri = b\"http://twisted\\r\\n.invalid/path\"\n            self.attemptRequestWithMaliciousURI(uri)\n        self.assertRegex(str(cm.exception), \"^Invalid URI\")\n\n\n    def test_hostWithWithUnprintableASCIIRejected(self):\n        \"\"\"\n        Issuing a request with a URI whose host contains unprintable\n        ASCII characters fails with a L{ValueError}.\n        \"\"\"\n        for c in UNPRINTABLE_ASCII:\n            uri = b\"http://twisted%s.invalid/OK\" % (bytearray([c]),)\n            with self.assertRaises(ValueError) as cm:\n                self.attemptRequestWithMaliciousURI(uri)\n            self.assertRegex(str(cm.exception), \"^Invalid URI\")\n\n\n    def test_hostWithNonASCIIRejected(self):\n        \"\"\"\n        Issuing a request with a URI whose host contains non-ASCII\n        characters fails with a L{ValueError}.\n        \"\"\"\n        for c in NONASCII:\n            uri = b\"http://twisted%s.invalid/OK\" % (bytearray([c]),)\n            with self.assertRaises(ValueError) as cm:\n                self.attemptRequestWithMaliciousURI(uri)\n            self.assertRegex(str(cm.exception), \"^Invalid URI\")\n\n\n    def test_pathWithCRLFRejected(self):\n        \"\"\"\n        Issuing a request with a URI whose path contains a carriage\n        return and line feed fails with a L{ValueError}.\n        \"\"\"\n        with self.assertRaises(ValueError) as cm:\n            uri = b\"http://twisted.invalid/\\r\\npath\"\n            self.attemptRequestWithMaliciousURI(uri)\n        self.assertRegex(str(cm.exception), \"^Invalid URI\")\n\n\n    def test_pathWithWithUnprintableASCIIRejected(self):\n        \"\"\"\n        Issuing a request with a URI whose path contains unprintable\n        ASCII characters fails with a L{ValueError}.\n        \"\"\"\n        for c in UNPRINTABLE_ASCII:\n            uri = b\"http://twisted.invalid/OK%s\" % (bytearray([c]),)\n            with self.assertRaises(ValueError) as cm:\n                self.attemptRequestWithMaliciousURI(uri)\n            self.assertRegex(str(cm.exception), \"^Invalid URI\")\n\n\n    def test_pathWithNonASCIIRejected(self):\n        \"\"\"\n        Issuing a request with a URI whose path contains non-ASCII\n        characters fails with a L{ValueError}.\n        \"\"\"\n        for c in NONASCII:\n            uri = b\"http://twisted.invalid/OK%s\" % (bytearray([c]),)\n            with self.assertRaises(ValueError) as cm:\n                self.attemptRequestWithMaliciousURI(uri)\n            self.assertRegex(str(cm.exception), \"^Invalid URI\")\n", "code_before": "", "patch": "@@ -0,0 +1,168 @@\n+\"\"\"\n+Helpers for URI and method injection tests.\n+\n+@see: U{CVE-2019-12387}\n+\"\"\"\n+\n+import string\n+\n+\n+UNPRINTABLE_ASCII = (\n+    frozenset(range(0, 128)) -\n+    frozenset(bytearray(string.printable, 'ascii'))\n+)\n+\n+NONASCII = frozenset(range(128, 256))\n+\n+\n+\n+class MethodInjectionTestsMixin(object):\n+    \"\"\"\n+    A mixin that runs HTTP method injection tests.  Define\n+    L{MethodInjectionTestsMixin.attemptRequestWithMaliciousMethod} in\n+    a L{twisted.trial.unittest.SynchronousTestCase} subclass to test\n+    how HTTP client code behaves when presented with malicious HTTP\n+    methods.\n+\n+    @see: U{CVE-2019-12387}\n+    \"\"\"\n+\n+    def attemptRequestWithMaliciousMethod(self, method):\n+        \"\"\"\n+        Attempt to send a request with the given method.  This should\n+        synchronously raise a L{ValueError} if either is invalid.\n+\n+        @param method: the method (e.g. C{GET\\x00})\n+\n+        @param uri: the URI\n+\n+        @type method:\n+        \"\"\"\n+        raise NotImplementedError()\n+\n+\n+    def test_methodWithCLRFRejected(self):\n+        \"\"\"\n+        Issuing a request with a method that contains a carriage\n+        return and line feed fails with a L{ValueError}.\n+        \"\"\"\n+        with self.assertRaises(ValueError) as cm:\n+            method = b\"GET\\r\\nX-Injected-Header: value\"\n+            self.attemptRequestWithMaliciousMethod(method)\n+        self.assertRegex(str(cm.exception), \"^Invalid method\")\n+\n+\n+    def test_methodWithUnprintableASCIIRejected(self):\n+        \"\"\"\n+        Issuing a request with a method that contains unprintable\n+        ASCII characters fails with a L{ValueError}.\n+        \"\"\"\n+        for c in UNPRINTABLE_ASCII:\n+            method = b\"GET%s\" % (bytearray([c]),)\n+            with self.assertRaises(ValueError) as cm:\n+                self.attemptRequestWithMaliciousMethod(method)\n+            self.assertRegex(str(cm.exception), \"^Invalid method\")\n+\n+\n+    def test_methodWithNonASCIIRejected(self):\n+        \"\"\"\n+        Issuing a request with a method that contains non-ASCII\n+        characters fails with a L{ValueError}.\n+        \"\"\"\n+        for c in NONASCII:\n+            method = b\"GET%s\" % (bytearray([c]),)\n+            with self.assertRaises(ValueError) as cm:\n+                self.attemptRequestWithMaliciousMethod(method)\n+            self.assertRegex(str(cm.exception), \"^Invalid method\")\n+\n+\n+\n+class URIInjectionTestsMixin(object):\n+    \"\"\"\n+    A mixin that runs HTTP URI injection tests.  Define\n+    L{MethodInjectionTestsMixin.attemptRequestWithMaliciousURI} in a\n+    L{twisted.trial.unittest.SynchronousTestCase} subclass to test how\n+    HTTP client code behaves when presented with malicious HTTP\n+    URIs.\n+    \"\"\"\n+\n+    def attemptRequestWithMaliciousURI(self, method):\n+        \"\"\"\n+        Attempt to send a request with the given URI.  This should\n+        synchronously raise a L{ValueError} if either is invalid.\n+\n+        @param uri: the URI.\n+\n+        @type method:\n+        \"\"\"\n+        raise NotImplementedError()\n+\n+\n+    def test_hostWithCRLFRejected(self):\n+        \"\"\"\n+        Issuing a request with a URI whose host contains a carriage\n+        return and line feed fails with a L{ValueError}.\n+        \"\"\"\n+        with self.assertRaises(ValueError) as cm:\n+            uri = b\"http://twisted\\r\\n.invalid/path\"\n+            self.attemptRequestWithMaliciousURI(uri)\n+        self.assertRegex(str(cm.exception), \"^Invalid URI\")\n+\n+\n+    def test_hostWithWithUnprintableASCIIRejected(self):\n+        \"\"\"\n+        Issuing a request with a URI whose host contains unprintable\n+        ASCII characters fails with a L{ValueError}.\n+        \"\"\"\n+        for c in UNPRINTABLE_ASCII:\n+            uri = b\"http://twisted%s.invalid/OK\" % (bytearray([c]),)\n+            with self.assertRaises(ValueError) as cm:\n+                self.attemptRequestWithMaliciousURI(uri)\n+            self.assertRegex(str(cm.exception), \"^Invalid URI\")\n+\n+\n+    def test_hostWithNonASCIIRejected(self):\n+        \"\"\"\n+        Issuing a request with a URI whose host contains non-ASCII\n+        characters fails with a L{ValueError}.\n+        \"\"\"\n+        for c in NONASCII:\n+            uri = b\"http://twisted%s.invalid/OK\" % (bytearray([c]),)\n+            with self.assertRaises(ValueError) as cm:\n+                self.attemptRequestWithMaliciousURI(uri)\n+            self.assertRegex(str(cm.exception), \"^Invalid URI\")\n+\n+\n+    def test_pathWithCRLFRejected(self):\n+        \"\"\"\n+        Issuing a request with a URI whose path contains a carriage\n+        return and line feed fails with a L{ValueError}.\n+        \"\"\"\n+        with self.assertRaises(ValueError) as cm:\n+            uri = b\"http://twisted.invalid/\\r\\npath\"\n+            self.attemptRequestWithMaliciousURI(uri)\n+        self.assertRegex(str(cm.exception), \"^Invalid URI\")\n+\n+\n+    def test_pathWithWithUnprintableASCIIRejected(self):\n+        \"\"\"\n+        Issuing a request with a URI whose path contains unprintable\n+        ASCII characters fails with a L{ValueError}.\n+        \"\"\"\n+        for c in UNPRINTABLE_ASCII:\n+            uri = b\"http://twisted.invalid/OK%s\" % (bytearray([c]),)\n+            with self.assertRaises(ValueError) as cm:\n+                self.attemptRequestWithMaliciousURI(uri)\n+            self.assertRegex(str(cm.exception), \"^Invalid URI\")\n+\n+\n+    def test_pathWithNonASCIIRejected(self):\n+        \"\"\"\n+        Issuing a request with a URI whose path contains non-ASCII\n+        characters fails with a L{ValueError}.\n+        \"\"\"\n+        for c in NONASCII:\n+            uri = b\"http://twisted.invalid/OK%s\" % (bytearray([c]),)\n+            with self.assertRaises(ValueError) as cm:\n+                self.attemptRequestWithMaliciousURI(uri)\n+            self.assertRegex(str(cm.exception), \"^Invalid URI\")", "file_path": "files/2019_6\\160", "file_language": "py", "file_name": "src/twisted/web/test/injectionhelpers.py", "outdated_file_modify": 0, "outdated_file_before": 0, "outdated_file_after": 0, "llm_check": 1, "static_check": 0, "static": {"rats": [false, []], "semgrep": [false, []]}, "target": -1, "function_before": [], "function_after": []}, {"raw_url": "https://github.com/twisted/twisted/raw/6c61fc4503ae39ab8ecee52d10f10ee2c371d7e2/src%2Ftwisted%2Fweb%2Ftest%2Ftest_agent.py", "code": "# Copyright (c) Twisted Matrix Laboratories.\n# See LICENSE for details.\n\n\"\"\"\nTests for L{twisted.web.client.Agent} and related new client APIs.\n\"\"\"\n\nimport zlib\n\nfrom io import BytesIO\n\nfrom zope.interface.verify import verifyObject\n\nfrom twisted.trial.unittest import TestCase, SynchronousTestCase\nfrom twisted.web import client, error, http_headers\nfrom twisted.web._newclient import RequestNotSent, RequestTransmissionFailed\nfrom twisted.web._newclient import ResponseNeverReceived, ResponseFailed\nfrom twisted.web._newclient import PotentialDataLoss\nfrom twisted.internet import defer, task\nfrom twisted.python.failure import Failure\nfrom twisted.python.compat import cookielib, intToBytes, unicode\nfrom twisted.python.components import proxyForInterface\nfrom twisted.test.proto_helpers import (StringTransport, MemoryReactorClock,\n                                        EventLoggingObserver)\nfrom twisted.internet.task import Clock\nfrom twisted.internet.error import ConnectionRefusedError, ConnectionDone\nfrom twisted.internet.error import ConnectionLost\nfrom twisted.internet.protocol import Protocol, Factory\nfrom twisted.internet.defer import Deferred, succeed, CancelledError\nfrom twisted.internet.endpoints import TCP4ClientEndpoint\nfrom twisted.internet.address import IPv4Address, IPv6Address\n\nfrom twisted.web.client import (FileBodyProducer, Request, HTTPConnectionPool,\n                                ResponseDone, _HTTP11ClientFactory, URI)\n\nfrom twisted.web.iweb import (\n    UNKNOWN_LENGTH, IAgent, IBodyProducer, IResponse, IAgentEndpointFactory,\n    )\nfrom twisted.web.http_headers import Headers\nfrom twisted.web._newclient import HTTP11ClientProtocol, Response\n\nfrom twisted.internet.interfaces import IOpenSSLClientConnectionCreator\nfrom zope.interface.declarations import implementer\nfrom twisted.web.iweb import IPolicyForHTTPS\nfrom twisted.python.deprecate import getDeprecationWarningString\nfrom incremental import Version\nfrom twisted.web.client import (BrowserLikePolicyForHTTPS,\n                                HostnameCachingHTTPSPolicy)\nfrom twisted.internet.test.test_endpoints import deterministicResolvingReactor\nfrom twisted.internet.endpoints import HostnameEndpoint\nfrom twisted.test.proto_helpers import AccumulatingProtocol\nfrom twisted.test.iosim import IOPump, FakeTransport\nfrom twisted.test.test_sslverify import certificatesForAuthorityAndServer\nfrom twisted.web.test.injectionhelpers import (\n    MethodInjectionTestsMixin,\n    URIInjectionTestsMixin,\n)\nfrom twisted.web.error import SchemeNotSupported\nfrom twisted.logger import globalLogPublisher\n\ntry:\n    from twisted.internet import ssl\nexcept ImportError:\n    ssl = None\n    skipWhenNoSSL = \"SSL not present, cannot run SSL tests.\"\n    skipWhenSSLPresent = None\nelse:\n    skipWhenSSLPresent = \"SSL present.\"\n    skipWhenNoSSL = None\n    from twisted.internet._sslverify import ClientTLSOptions, IOpenSSLTrustRoot\n    from twisted.internet.ssl import optionsForClientTLS\n    from twisted.protocols.tls import TLSMemoryBIOProtocol, TLSMemoryBIOFactory\n\n\n    @implementer(IOpenSSLTrustRoot)\n    class CustomOpenSSLTrustRoot(object):\n        called = False\n        context = None\n\n        def _addCACertsToContext(self, context):\n            self.called = True\n            self.context = context\n\n\n\nclass StubHTTPProtocol(Protocol):\n    \"\"\"\n    A protocol like L{HTTP11ClientProtocol} but which does not actually know\n    HTTP/1.1 and only collects requests in a list.\n\n    @ivar requests: A C{list} of two-tuples.  Each time a request is made, a\n        tuple consisting of the request and the L{Deferred} returned from the\n        request method is appended to this list.\n    \"\"\"\n    def __init__(self):\n        self.requests = []\n        self.state = 'QUIESCENT'\n\n\n    def request(self, request):\n        \"\"\"\n        Capture the given request for later inspection.\n\n        @return: A L{Deferred} which this code will never fire.\n        \"\"\"\n        result = Deferred()\n        self.requests.append((request, result))\n        return result\n\n\n\nclass FileConsumer(object):\n    def __init__(self, outputFile):\n        self.outputFile = outputFile\n\n\n    def write(self, bytes):\n        self.outputFile.write(bytes)\n\n\n\nclass FileBodyProducerTests(TestCase):\n    \"\"\"\n    Tests for the L{FileBodyProducer} which reads bytes from a file and writes\n    them to an L{IConsumer}.\n    \"\"\"\n    def _termination(self):\n        \"\"\"\n        This method can be used as the C{terminationPredicateFactory} for a\n        L{Cooperator}.  It returns a predicate which immediately returns\n        C{False}, indicating that no more work should be done this iteration.\n        This has the result of only allowing one iteration of a cooperative\n        task to be run per L{Cooperator} iteration.\n        \"\"\"\n        return lambda: True\n\n\n    def setUp(self):\n        \"\"\"\n        Create a L{Cooperator} hooked up to an easily controlled, deterministic\n        scheduler to use with L{FileBodyProducer}.\n        \"\"\"\n        self._scheduled = []\n        self.cooperator = task.Cooperator(\n            self._termination, self._scheduled.append)\n\n\n    def test_interface(self):\n        \"\"\"\n        L{FileBodyProducer} instances provide L{IBodyProducer}.\n        \"\"\"\n        self.assertTrue(verifyObject(\n                IBodyProducer, FileBodyProducer(BytesIO(b\"\"))))\n\n\n    def test_unknownLength(self):\n        \"\"\"\n        If the L{FileBodyProducer} is constructed with a file-like object\n        without either a C{seek} or C{tell} method, its C{length} attribute is\n        set to C{UNKNOWN_LENGTH}.\n        \"\"\"\n        class HasSeek(object):\n            def seek(self, offset, whence):\n                pass\n\n        class HasTell(object):\n            def tell(self):\n                pass\n\n        producer = FileBodyProducer(HasSeek())\n        self.assertEqual(UNKNOWN_LENGTH, producer.length)\n        producer = FileBodyProducer(HasTell())\n        self.assertEqual(UNKNOWN_LENGTH, producer.length)\n\n\n    def test_knownLength(self):\n        \"\"\"\n        If the L{FileBodyProducer} is constructed with a file-like object with\n        both C{seek} and C{tell} methods, its C{length} attribute is set to the\n        size of the file as determined by those methods.\n        \"\"\"\n        inputBytes = b\"here are some bytes\"\n        inputFile = BytesIO(inputBytes)\n        inputFile.seek(5)\n        producer = FileBodyProducer(inputFile)\n        self.assertEqual(len(inputBytes) - 5, producer.length)\n        self.assertEqual(inputFile.tell(), 5)\n\n\n    def test_defaultCooperator(self):\n        \"\"\"\n        If no L{Cooperator} instance is passed to L{FileBodyProducer}, the\n        global cooperator is used.\n        \"\"\"\n        producer = FileBodyProducer(BytesIO(b\"\"))\n        self.assertEqual(task.cooperate, producer._cooperate)\n\n\n    def test_startProducing(self):\n        \"\"\"\n        L{FileBodyProducer.startProducing} starts writing bytes from the input\n        file to the given L{IConsumer} and returns a L{Deferred} which fires\n        when they have all been written.\n        \"\"\"\n        expectedResult = b\"hello, world\"\n        readSize = 3\n        output = BytesIO()\n        consumer = FileConsumer(output)\n        producer = FileBodyProducer(\n            BytesIO(expectedResult), self.cooperator, readSize)\n        complete = producer.startProducing(consumer)\n        for i in range(len(expectedResult) // readSize + 1):\n            self._scheduled.pop(0)()\n        self.assertEqual([], self._scheduled)\n        self.assertEqual(expectedResult, output.getvalue())\n        self.assertEqual(None, self.successResultOf(complete))\n\n\n    def test_inputClosedAtEOF(self):\n        \"\"\"\n        When L{FileBodyProducer} reaches end-of-file on the input file given to\n        it, the input file is closed.\n        \"\"\"\n        readSize = 4\n        inputBytes = b\"some friendly bytes\"\n        inputFile = BytesIO(inputBytes)\n        producer = FileBodyProducer(inputFile, self.cooperator, readSize)\n        consumer = FileConsumer(BytesIO())\n        producer.startProducing(consumer)\n        for i in range(len(inputBytes) // readSize + 2):\n            self._scheduled.pop(0)()\n        self.assertTrue(inputFile.closed)\n\n\n    def test_failedReadWhileProducing(self):\n        \"\"\"\n        If a read from the input file fails while producing bytes to the\n        consumer, the L{Deferred} returned by\n        L{FileBodyProducer.startProducing} fires with a L{Failure} wrapping\n        that exception.\n        \"\"\"\n        class BrokenFile(object):\n            def read(self, count):\n                raise IOError(\"Simulated bad thing\")\n        producer = FileBodyProducer(BrokenFile(), self.cooperator)\n        complete = producer.startProducing(FileConsumer(BytesIO()))\n        self._scheduled.pop(0)()\n        self.failureResultOf(complete).trap(IOError)\n\n\n    def test_stopProducing(self):\n        \"\"\"\n        L{FileBodyProducer.stopProducing} stops the underlying L{IPullProducer}\n        and the cooperative task responsible for calling C{resumeProducing} and\n        closes the input file but does not cause the L{Deferred} returned by\n        C{startProducing} to fire.\n        \"\"\"\n        expectedResult = b\"hello, world\"\n        readSize = 3\n        output = BytesIO()\n        consumer = FileConsumer(output)\n        inputFile = BytesIO(expectedResult)\n        producer = FileBodyProducer(\n            inputFile, self.cooperator, readSize)\n        complete = producer.startProducing(consumer)\n        producer.stopProducing()\n        self.assertTrue(inputFile.closed)\n        self._scheduled.pop(0)()\n        self.assertEqual(b\"\", output.getvalue())\n        self.assertNoResult(complete)\n\n\n    def test_pauseProducing(self):\n        \"\"\"\n        L{FileBodyProducer.pauseProducing} temporarily suspends writing bytes\n        from the input file to the given L{IConsumer}.\n        \"\"\"\n        expectedResult = b\"hello, world\"\n        readSize = 5\n        output = BytesIO()\n        consumer = FileConsumer(output)\n        producer = FileBodyProducer(\n            BytesIO(expectedResult), self.cooperator, readSize)\n        complete = producer.startProducing(consumer)\n        self._scheduled.pop(0)()\n        self.assertEqual(output.getvalue(), expectedResult[:5])\n        producer.pauseProducing()\n\n        # Sort of depends on an implementation detail of Cooperator: even\n        # though the only task is paused, there's still a scheduled call.  If\n        # this were to go away because Cooperator became smart enough to cancel\n        # this call in this case, that would be fine.\n        self._scheduled.pop(0)()\n\n        # Since the producer is paused, no new data should be here.\n        self.assertEqual(output.getvalue(), expectedResult[:5])\n        self.assertEqual([], self._scheduled)\n        self.assertNoResult(complete)\n\n\n    def test_resumeProducing(self):\n        \"\"\"\n        L{FileBodyProducer.resumeProducing} re-commences writing bytes from the\n        input file to the given L{IConsumer} after it was previously paused\n        with L{FileBodyProducer.pauseProducing}.\n        \"\"\"\n        expectedResult = b\"hello, world\"\n        readSize = 5\n        output = BytesIO()\n        consumer = FileConsumer(output)\n        producer = FileBodyProducer(\n            BytesIO(expectedResult), self.cooperator, readSize)\n        producer.startProducing(consumer)\n        self._scheduled.pop(0)()\n        self.assertEqual(expectedResult[:readSize], output.getvalue())\n        producer.pauseProducing()\n        producer.resumeProducing()\n        self._scheduled.pop(0)()\n        self.assertEqual(expectedResult[:readSize * 2], output.getvalue())\n\nEXAMPLE_COM_IP = '127.0.0.7'\nEXAMPLE_COM_V6_IP = '::7'\nEXAMPLE_NET_IP = '127.0.0.8'\nEXAMPLE_ORG_IP = '127.0.0.9'\nFOO_LOCAL_IP = '127.0.0.10'\nFOO_COM_IP = '127.0.0.11'\n\nclass FakeReactorAndConnectMixin:\n    \"\"\"\n    A test mixin providing a testable C{Reactor} class and a dummy C{connect}\n    method which allows instances to pretend to be endpoints.\n    \"\"\"\n    def createReactor(self):\n        \"\"\"\n        Create a L{MemoryReactorClock} and give it some hostnames it can\n        resolve.\n\n        @return: a L{MemoryReactorClock}-like object with a slightly limited\n            interface (only C{advance} and C{tcpClients} in addition to its\n            formally-declared reactor interfaces), which can resolve a fixed\n            set of domains.\n        \"\"\"\n        mrc = MemoryReactorClock()\n        drr = deterministicResolvingReactor(mrc, hostMap={\n            u'example.com': [EXAMPLE_COM_IP],\n            u'ipv6.example.com': [EXAMPLE_COM_V6_IP],\n            u'example.net': [EXAMPLE_NET_IP],\n            u'example.org': [EXAMPLE_ORG_IP],\n            u'foo': [FOO_LOCAL_IP],\n            u'foo.com': [FOO_COM_IP],\n            u'127.0.0.7': ['127.0.0.7'],\n            u'::7': ['::7'],\n        })\n\n        # Lots of tests were written expecting MemoryReactorClock and the\n        # reactor seen by the SUT to be the same object.\n        drr.tcpClients = mrc.tcpClients\n        drr.advance = mrc.advance\n        return drr\n\n    class StubEndpoint(object):\n        \"\"\"\n        Endpoint that wraps existing endpoint, substitutes StubHTTPProtocol, and\n        resulting protocol instances are attached to the given test case.\n        \"\"\"\n\n        def __init__(self, endpoint, testCase):\n            self.endpoint = endpoint\n            self.testCase = testCase\n            def nothing():\n                \"\"\"this function does nothing\"\"\"\n            self.factory = _HTTP11ClientFactory(nothing,\n                                                repr(self.endpoint))\n            self.protocol = StubHTTPProtocol()\n            self.factory.buildProtocol = lambda addr: self.protocol\n\n        def connect(self, ignoredFactory):\n            self.testCase.protocol = self.protocol\n            self.endpoint.connect(self.factory)\n            return succeed(self.protocol)\n\n\n    def buildAgentForWrapperTest(self, reactor):\n        \"\"\"\n        Return an Agent suitable for use in tests that wrap the Agent and want\n        both a fake reactor and StubHTTPProtocol.\n        \"\"\"\n        agent = client.Agent(reactor)\n        _oldGetEndpoint = agent._getEndpoint\n        agent._getEndpoint = lambda *args: (\n            self.StubEndpoint(_oldGetEndpoint(*args), self))\n        return agent\n\n\n    def connect(self, factory):\n        \"\"\"\n        Fake implementation of an endpoint which synchronously\n        succeeds with an instance of L{StubHTTPProtocol} for ease of\n        testing.\n        \"\"\"\n        protocol = StubHTTPProtocol()\n        protocol.makeConnection(None)\n        self.protocol = protocol\n        return succeed(protocol)\n\n\n\nclass DummyEndpoint(object):\n    \"\"\"\n    An endpoint that uses a fake transport.\n    \"\"\"\n\n    def connect(self, factory):\n        protocol = factory.buildProtocol(None)\n        protocol.makeConnection(StringTransport())\n        return succeed(protocol)\n\n\n\nclass BadEndpoint(object):\n    \"\"\"\n    An endpoint that shouldn't be called.\n    \"\"\"\n\n    def connect(self, factory):\n        raise RuntimeError(\"This endpoint should not have been used.\")\n\n\nclass DummyFactory(Factory):\n    \"\"\"\n    Create C{StubHTTPProtocol} instances.\n    \"\"\"\n    def __init__(self, quiescentCallback, metadata):\n        pass\n\n    protocol = StubHTTPProtocol\n\n\n\nclass HTTPConnectionPoolTests(TestCase, FakeReactorAndConnectMixin):\n    \"\"\"\n    Tests for the L{HTTPConnectionPool} class.\n    \"\"\"\n    def setUp(self):\n        self.fakeReactor = self.createReactor()\n        self.pool = HTTPConnectionPool(self.fakeReactor)\n        self.pool._factory = DummyFactory\n        # The retry code path is tested in HTTPConnectionPoolRetryTests:\n        self.pool.retryAutomatically = False\n\n\n    def test_getReturnsNewIfCacheEmpty(self):\n        \"\"\"\n        If there are no cached connections,\n        L{HTTPConnectionPool.getConnection} returns a new connection.\n        \"\"\"\n        self.assertEqual(self.pool._connections, {})\n\n        def gotConnection(conn):\n            self.assertIsInstance(conn, StubHTTPProtocol)\n            # The new connection is not stored in the pool:\n            self.assertNotIn(conn, self.pool._connections.values())\n\n        unknownKey = 12245\n        d = self.pool.getConnection(unknownKey, DummyEndpoint())\n        return d.addCallback(gotConnection)\n\n\n    def test_putStartsTimeout(self):\n        \"\"\"\n        If a connection is put back to the pool, a 240-sec timeout is started.\n\n        When the timeout hits, the connection is closed and removed from the\n        pool.\n        \"\"\"\n        # We start out with one cached connection:\n        protocol = StubHTTPProtocol()\n        protocol.makeConnection(StringTransport())\n        self.pool._putConnection((\"http\", b\"example.com\", 80), protocol)\n\n        # Connection is in pool, still not closed:\n        self.assertEqual(protocol.transport.disconnecting, False)\n        self.assertIn(protocol,\n                      self.pool._connections[(\"http\", b\"example.com\", 80)])\n\n        # Advance 239 seconds, still not closed:\n        self.fakeReactor.advance(239)\n        self.assertEqual(protocol.transport.disconnecting, False)\n        self.assertIn(protocol,\n                      self.pool._connections[(\"http\", b\"example.com\", 80)])\n        self.assertIn(protocol, self.pool._timeouts)\n\n        # Advance past 240 seconds, connection will be closed:\n        self.fakeReactor.advance(1.1)\n        self.assertEqual(protocol.transport.disconnecting, True)\n        self.assertNotIn(protocol,\n                         self.pool._connections[(\"http\", b\"example.com\", 80)])\n        self.assertNotIn(protocol, self.pool._timeouts)\n\n\n    def test_putExceedsMaxPersistent(self):\n        \"\"\"\n        If an idle connection is put back in the cache and the max number of\n        persistent connections has been exceeded, one of the connections is\n        closed and removed from the cache.\n        \"\"\"\n        pool = self.pool\n\n        # We start out with two cached connection, the max:\n        origCached = [StubHTTPProtocol(), StubHTTPProtocol()]\n        for p in origCached:\n            p.makeConnection(StringTransport())\n            pool._putConnection((\"http\", b\"example.com\", 80), p)\n        self.assertEqual(pool._connections[(\"http\", b\"example.com\", 80)],\n                         origCached)\n        timeouts = pool._timeouts.copy()\n\n        # Now we add another one:\n        newProtocol = StubHTTPProtocol()\n        newProtocol.makeConnection(StringTransport())\n        pool._putConnection((\"http\", b\"example.com\", 80), newProtocol)\n\n        # The oldest cached connections will be removed and disconnected:\n        newCached = pool._connections[(\"http\", b\"example.com\", 80)]\n        self.assertEqual(len(newCached), 2)\n        self.assertEqual(newCached, [origCached[1], newProtocol])\n        self.assertEqual([p.transport.disconnecting for p in newCached],\n                         [False, False])\n        self.assertEqual(origCached[0].transport.disconnecting, True)\n        self.assertTrue(timeouts[origCached[0]].cancelled)\n        self.assertNotIn(origCached[0], pool._timeouts)\n\n\n    def test_maxPersistentPerHost(self):\n        \"\"\"\n        C{maxPersistentPerHost} is enforced per C{(scheme, host, port)}:\n        different keys have different max connections.\n        \"\"\"\n        def addProtocol(scheme, host, port):\n            p = StubHTTPProtocol()\n            p.makeConnection(StringTransport())\n            self.pool._putConnection((scheme, host, port), p)\n            return p\n        persistent = []\n        persistent.append(addProtocol(\"http\", b\"example.com\", 80))\n        persistent.append(addProtocol(\"http\", b\"example.com\", 80))\n        addProtocol(\"https\", b\"example.com\", 443)\n        addProtocol(\"http\", b\"www2.example.com\", 80)\n\n        self.assertEqual(\n            self.pool._connections[(\"http\", b\"example.com\", 80)], persistent)\n        self.assertEqual(\n            len(self.pool._connections[(\"https\", b\"example.com\", 443)]), 1)\n        self.assertEqual(\n            len(self.pool._connections[(\"http\", b\"www2.example.com\", 80)]), 1)\n\n\n    def test_getCachedConnection(self):\n        \"\"\"\n        Getting an address which has a cached connection returns the cached\n        connection, removes it from the cache and cancels its timeout.\n        \"\"\"\n        # We start out with one cached connection:\n        protocol = StubHTTPProtocol()\n        protocol.makeConnection(StringTransport())\n        self.pool._putConnection((\"http\", b\"example.com\", 80), protocol)\n\n        def gotConnection(conn):\n            # We got the cached connection:\n            self.assertIdentical(protocol, conn)\n            self.assertNotIn(\n                conn, self.pool._connections[(\"http\", b\"example.com\", 80)])\n            # And the timeout was cancelled:\n            self.fakeReactor.advance(241)\n            self.assertEqual(conn.transport.disconnecting, False)\n            self.assertNotIn(conn, self.pool._timeouts)\n\n        return self.pool.getConnection((\"http\", b\"example.com\", 80),\n                                       BadEndpoint(),\n                                       ).addCallback(gotConnection)\n\n\n    def test_newConnection(self):\n        \"\"\"\n        The pool's C{_newConnection} method constructs a new connection.\n        \"\"\"\n        # We start out with one cached connection:\n        protocol = StubHTTPProtocol()\n        protocol.makeConnection(StringTransport())\n        key = 12245\n        self.pool._putConnection(key, protocol)\n\n        def gotConnection(newConnection):\n            # We got a new connection:\n            self.assertNotIdentical(protocol, newConnection)\n            # And the old connection is still there:\n            self.assertIn(protocol, self.pool._connections[key])\n            # While the new connection is not:\n            self.assertNotIn(newConnection, self.pool._connections.values())\n\n        d = self.pool._newConnection(key, DummyEndpoint())\n        return d.addCallback(gotConnection)\n\n\n    def test_getSkipsDisconnected(self):\n        \"\"\"\n        When getting connections out of the cache, disconnected connections\n        are removed and not returned.\n        \"\"\"\n        pool = self.pool\n        key = (\"http\", b\"example.com\", 80)\n\n        # We start out with two cached connection, the max:\n        origCached = [StubHTTPProtocol(), StubHTTPProtocol()]\n        for p in origCached:\n            p.makeConnection(StringTransport())\n            pool._putConnection(key, p)\n        self.assertEqual(pool._connections[key], origCached)\n\n        # We close the first one:\n        origCached[0].state = \"DISCONNECTED\"\n\n        # Now, when we retrive connections we should get the *second* one:\n        result = []\n        self.pool.getConnection(key,\n                                BadEndpoint()).addCallback(result.append)\n        self.assertIdentical(result[0], origCached[1])\n\n        # And both the disconnected and removed connections should be out of\n        # the cache:\n        self.assertEqual(pool._connections[key], [])\n        self.assertEqual(pool._timeouts, {})\n\n\n    def test_putNotQuiescent(self):\n        \"\"\"\n        If a non-quiescent connection is put back in the cache, an error is\n        logged.\n        \"\"\"\n        protocol = StubHTTPProtocol()\n        # By default state is QUIESCENT\n        self.assertEqual(protocol.state, \"QUIESCENT\")\n\n        logObserver = EventLoggingObserver.createWithCleanup(\n            self,\n            globalLogPublisher\n        )\n\n        protocol.state = \"NOTQUIESCENT\"\n        self.pool._putConnection((\"http\", b\"example.com\", 80), protocol)\n        self.assertEquals(1, len(logObserver))\n\n        event = logObserver[0]\n        f = event[\"log_failure\"]\n\n        self.assertIsInstance(f.value, RuntimeError)\n        self.assertEqual(\n            f.getErrorMessage(),\n            \"BUG: Non-quiescent protocol added to connection pool.\")\n        self.assertIdentical(None, self.pool._connections.get(\n                (\"http\", b\"example.com\", 80)))\n        self.flushLoggedErrors(RuntimeError)\n\n\n    def test_getUsesQuiescentCallback(self):\n        \"\"\"\n        When L{HTTPConnectionPool.getConnection} connects, it returns a\n        C{Deferred} that fires with an instance of L{HTTP11ClientProtocol}\n        that has the correct quiescent callback attached. When this callback\n        is called the protocol is returned to the cache correctly, using the\n        right key.\n        \"\"\"\n        class StringEndpoint(object):\n            def connect(self, factory):\n                p = factory.buildProtocol(None)\n                p.makeConnection(StringTransport())\n                return succeed(p)\n\n        pool = HTTPConnectionPool(self.fakeReactor, True)\n        pool.retryAutomatically = False\n        result = []\n        key = \"a key\"\n        pool.getConnection(\n            key, StringEndpoint()).addCallback(\n            result.append)\n        protocol = result[0]\n        self.assertIsInstance(protocol, HTTP11ClientProtocol)\n\n        # Now that we have protocol instance, lets try to put it back in the\n        # pool:\n        protocol._state = \"QUIESCENT\"\n        protocol._quiescentCallback(protocol)\n\n        # If we try to retrive a connection to same destination again, we\n        # should get the same protocol, because it should've been added back\n        # to the pool:\n        result2 = []\n        pool.getConnection(\n            key, StringEndpoint()).addCallback(\n            result2.append)\n        self.assertIdentical(result2[0], protocol)\n\n\n    def test_closeCachedConnections(self):\n        \"\"\"\n        L{HTTPConnectionPool.closeCachedConnections} closes all cached\n        connections and removes them from the cache. It returns a Deferred\n        that fires when they have all lost their connections.\n        \"\"\"\n        persistent = []\n        def addProtocol(scheme, host, port):\n            p = HTTP11ClientProtocol()\n            p.makeConnection(StringTransport())\n            self.pool._putConnection((scheme, host, port), p)\n            persistent.append(p)\n        addProtocol(\"http\", b\"example.com\", 80)\n        addProtocol(\"http\", b\"www2.example.com\", 80)\n        doneDeferred = self.pool.closeCachedConnections()\n\n        # Connections have begun disconnecting:\n        for p in persistent:\n            self.assertEqual(p.transport.disconnecting, True)\n        self.assertEqual(self.pool._connections, {})\n        # All timeouts were cancelled and removed:\n        for dc in self.fakeReactor.getDelayedCalls():\n            self.assertEqual(dc.cancelled, True)\n        self.assertEqual(self.pool._timeouts, {})\n\n        # Returned Deferred fires when all connections have been closed:\n        result = []\n        doneDeferred.addCallback(result.append)\n        self.assertEqual(result, [])\n        persistent[0].connectionLost(Failure(ConnectionDone()))\n        self.assertEqual(result, [])\n        persistent[1].connectionLost(Failure(ConnectionDone()))\n        self.assertEqual(result, [None])\n\n\n    def test_cancelGetConnectionCancelsEndpointConnect(self):\n        \"\"\"\n        Cancelling the C{Deferred} returned from\n        L{HTTPConnectionPool.getConnection} cancels the C{Deferred} returned\n        by opening a new connection with the given endpoint.\n        \"\"\"\n        self.assertEqual(self.pool._connections, {})\n        connectionResult = Deferred()\n\n        class Endpoint:\n            def connect(self, factory):\n                return connectionResult\n\n        d = self.pool.getConnection(12345, Endpoint())\n        d.cancel()\n        self.assertEqual(self.failureResultOf(connectionResult).type,\n                         CancelledError)\n\n\n\nclass AgentTestsMixin(object):\n    \"\"\"\n    Tests for any L{IAgent} implementation.\n    \"\"\"\n    def test_interface(self):\n        \"\"\"\n        The agent object provides L{IAgent}.\n        \"\"\"\n        self.assertTrue(verifyObject(IAgent, self.makeAgent()))\n\n\n\nclass IntegrationTestingMixin(object):\n    \"\"\"\n    Transport-to-Agent integration tests for both HTTP and HTTPS.\n    \"\"\"\n\n    def test_integrationTestIPv4(self):\n        \"\"\"\n        L{Agent} works over IPv4.\n        \"\"\"\n        self.integrationTest(b'example.com', EXAMPLE_COM_IP, IPv4Address)\n\n\n    def test_integrationTestIPv4Address(self):\n        \"\"\"\n        L{Agent} works over IPv4 when hostname is an IPv4 address.\n        \"\"\"\n        self.integrationTest(b'127.0.0.7', '127.0.0.7', IPv4Address)\n\n\n    def test_integrationTestIPv6(self):\n        \"\"\"\n        L{Agent} works over IPv6.\n        \"\"\"\n        self.integrationTest(b'ipv6.example.com', EXAMPLE_COM_V6_IP,\n                             IPv6Address)\n\n\n    def test_integrationTestIPv6Address(self):\n        \"\"\"\n        L{Agent} works over IPv6 when hostname is an IPv6 address.\n        \"\"\"\n        self.integrationTest(b'[::7]', '::7', IPv6Address)\n\n\n    def integrationTest(self, hostName, expectedAddress, addressType,\n                        serverWrapper=lambda server: server,\n                        createAgent=client.Agent,\n                        scheme=b'http'):\n        \"\"\"\n        L{Agent} will make a TCP connection, send an HTTP request, and return a\n        L{Deferred} that fires when the response has been received.\n\n        @param hostName: The hostname to interpolate into the URL to be\n            requested.\n        @type hostName: L{bytes}\n\n        @param expectedAddress: The expected address string.\n        @type expectedAddress: L{bytes}\n\n        @param addressType: The class to construct an address out of.\n        @type addressType: L{type}\n\n        @param serverWrapper: A callable that takes a protocol factory and\n            returns a protocol factory; used to wrap the server / responder\n            side in a TLS server.\n        @type serverWrapper:\n            serverWrapper(L{twisted.internet.interfaces.IProtocolFactory}) ->\n            L{twisted.internet.interfaces.IProtocolFactory}\n\n        @param createAgent: A callable that takes a reactor and produces an\n            L{IAgent}; used to construct an agent with an appropriate trust\n            root for TLS.\n        @type createAgent: createAgent(reactor) -> L{IAgent}\n\n        @param scheme: The scheme to test, C{http} or C{https}\n        @type scheme: L{bytes}\n        \"\"\"\n        reactor = self.createReactor()\n        agent = createAgent(reactor)\n        deferred = agent.request(b\"GET\", scheme + b\"://\" + hostName + b\"/\")\n        host, port, factory, timeout, bind = reactor.tcpClients[0]\n        self.assertEqual(host, expectedAddress)\n        peerAddress = addressType('TCP', host, port)\n        clientProtocol = factory.buildProtocol(peerAddress)\n        clientTransport = FakeTransport(clientProtocol, False,\n                                        peerAddress=peerAddress)\n        clientProtocol.makeConnection(clientTransport)\n        @Factory.forProtocol\n        def accumulator():\n            ap = AccumulatingProtocol()\n            accumulator.currentProtocol = ap\n            return ap\n        accumulator.currentProtocol = None\n        accumulator.protocolConnectionMade = None\n        wrapper = serverWrapper(accumulator).buildProtocol(None)\n        serverTransport = FakeTransport(wrapper, True)\n        wrapper.makeConnection(serverTransport)\n        pump = IOPump(clientProtocol, wrapper,\n                      clientTransport, serverTransport, False)\n        pump.flush()\n        self.assertNoResult(deferred)\n        lines = accumulator.currentProtocol.data.split(b\"\\r\\n\")\n        self.assertTrue(lines[0].startswith(b\"GET / HTTP\"), lines[0])\n        headers = dict([line.split(b\": \", 1) for line in lines[1:] if line])\n        self.assertEqual(headers[b'Host'], hostName)\n        self.assertNoResult(deferred)\n        accumulator.currentProtocol.transport.write(\n            b\"HTTP/1.1 200 OK\"\n            b\"\\r\\nX-An-Header: an-value\\r\\n\"\n            b\"\\r\\nContent-length: 12\\r\\n\\r\\n\"\n            b\"hello world!\"\n        )\n        pump.flush()\n        response = self.successResultOf(deferred)\n        self.assertEquals(response.headers.getRawHeaders(b'x-an-header')[0],\n                          b\"an-value\")\n\n\n\n@implementer(IAgentEndpointFactory)\nclass StubEndpointFactory(object):\n    \"\"\"\n    A stub L{IAgentEndpointFactory} for use in testing.\n    \"\"\"\n    def endpointForURI(self, uri):\n        \"\"\"\n        Testing implementation.\n\n        @param uri: A L{URI}.\n\n        @return: C{(scheme, host, port)} of passed in URI; violation of\n            interface but useful for testing.\n        @rtype: L{tuple}\n        \"\"\"\n        return (uri.scheme, uri.host, uri.port)\n\n\n\nclass AgentTests(TestCase, FakeReactorAndConnectMixin, AgentTestsMixin,\n                 IntegrationTestingMixin):\n    \"\"\"\n    Tests for the new HTTP client API provided by L{Agent}.\n    \"\"\"\n\n    def makeAgent(self):\n        \"\"\"\n        @return: a new L{twisted.web.client.Agent} instance\n        \"\"\"\n        return client.Agent(self.reactor)\n\n\n    def setUp(self):\n        \"\"\"\n        Create an L{Agent} wrapped around a fake reactor.\n        \"\"\"\n        self.reactor = self.createReactor()\n        self.agent = self.makeAgent()\n\n\n    def test_defaultPool(self):\n        \"\"\"\n        If no pool is passed in, the L{Agent} creates a non-persistent pool.\n        \"\"\"\n        agent = client.Agent(self.reactor)\n        self.assertIsInstance(agent._pool, HTTPConnectionPool)\n        self.assertEqual(agent._pool.persistent, False)\n        self.assertIdentical(agent._reactor, agent._pool._reactor)\n\n\n    def test_persistent(self):\n        \"\"\"\n        If C{persistent} is set to C{True} on the L{HTTPConnectionPool} (the\n        default), C{Request}s are created with their C{persistent} flag set to\n        C{True}.\n        \"\"\"\n        pool = HTTPConnectionPool(self.reactor)\n        agent = client.Agent(self.reactor, pool=pool)\n        agent._getEndpoint = lambda *args: self\n        agent.request(b\"GET\", b\"http://127.0.0.1\")\n        self.assertEqual(self.protocol.requests[0][0].persistent, True)\n\n\n    def test_nonPersistent(self):\n        \"\"\"\n        If C{persistent} is set to C{False} when creating the\n        L{HTTPConnectionPool}, C{Request}s are created with their\n        C{persistent} flag set to C{False}.\n\n        Elsewhere in the tests for the underlying HTTP code we ensure that\n        this will result in the disconnection of the HTTP protocol once the\n        request is done, so that the connection will not be returned to the\n        pool.\n        \"\"\"\n        pool = HTTPConnectionPool(self.reactor, persistent=False)\n        agent = client.Agent(self.reactor, pool=pool)\n        agent._getEndpoint = lambda *args: self\n        agent.request(b\"GET\", b\"http://127.0.0.1\")\n        self.assertEqual(self.protocol.requests[0][0].persistent, False)\n\n\n    def test_connectUsesConnectionPool(self):\n        \"\"\"\n        When a connection is made by the Agent, it uses its pool's\n        C{getConnection} method to do so, with the endpoint returned by\n        C{self._getEndpoint}. The key used is C{(scheme, host, port)}.\n        \"\"\"\n        endpoint = DummyEndpoint()\n        class MyAgent(client.Agent):\n            def _getEndpoint(this, uri):\n                self.assertEqual((uri.scheme, uri.host, uri.port),\n                                 (b\"http\", b\"foo\", 80))\n                return endpoint\n\n        class DummyPool(object):\n            connected = False\n            persistent = False\n            def getConnection(this, key, ep):\n                this.connected = True\n                self.assertEqual(ep, endpoint)\n                # This is the key the default Agent uses, others will have\n                # different keys:\n                self.assertEqual(key, (b\"http\", b\"foo\", 80))\n                return defer.succeed(StubHTTPProtocol())\n\n        pool = DummyPool()\n        agent = MyAgent(self.reactor, pool=pool)\n        self.assertIdentical(pool, agent._pool)\n\n        headers = http_headers.Headers()\n        headers.addRawHeader(b\"host\", b\"foo\")\n        bodyProducer = object()\n        agent.request(b'GET', b'http://foo/',\n                      bodyProducer=bodyProducer, headers=headers)\n        self.assertEqual(agent._pool.connected, True)\n\n\n    def test_nonBytesMethod(self):\n        \"\"\"\n        L{Agent.request} raises L{TypeError} when the C{method} argument isn't\n        L{bytes}.\n        \"\"\"\n        self.assertRaises(TypeError, self.agent.request,\n                          u'GET', b'http://foo.example/')\n\n\n    def test_unsupportedScheme(self):\n        \"\"\"\n        L{Agent.request} returns a L{Deferred} which fails with\n        L{SchemeNotSupported} if the scheme of the URI passed to it is not\n        C{'http'}.\n        \"\"\"\n        return self.assertFailure(\n            self.agent.request(b'GET', b'mailto:alice@example.com'),\n            SchemeNotSupported)\n\n\n    def test_connectionFailed(self):\n        \"\"\"\n        The L{Deferred} returned by L{Agent.request} fires with a L{Failure} if\n        the TCP connection attempt fails.\n        \"\"\"\n        result = self.agent.request(b'GET', b'http://foo/')\n        # Cause the connection to be refused\n        host, port, factory = self.reactor.tcpClients.pop()[:3]\n        factory.clientConnectionFailed(None, Failure(ConnectionRefusedError()))\n        self.reactor.advance(10)\n        # ^ https://twistedmatrix.com/trac/ticket/8202\n        self.failureResultOf(result, ConnectionRefusedError)\n\n\n    def test_connectHTTP(self):\n        \"\"\"\n        L{Agent._getEndpoint} return a C{HostnameEndpoint} when passed a scheme\n        of C{'http'}.\n        \"\"\"\n        expectedHost = b'example.com'\n        expectedPort = 1234\n        endpoint = self.agent._getEndpoint(URI.fromBytes(\n            b'http://' + expectedHost + b\":\" + intToBytes(expectedPort)))\n        self.assertEqual(endpoint._hostStr, \"example.com\")\n        self.assertEqual(endpoint._port, expectedPort)\n        self.assertIsInstance(endpoint, HostnameEndpoint)\n\n\n    def test_nonDecodableURI(self):\n        \"\"\"\n        L{Agent._getEndpoint} when given a non-ASCII decodable URI will raise a\n        L{ValueError} saying such.\n        \"\"\"\n        uri = URI.fromBytes(b\"http://example.com:80\")\n        uri.host = u'\\u2603.com'.encode('utf8')\n\n        with self.assertRaises(ValueError) as e:\n            self.agent._getEndpoint(uri)\n\n        self.assertEqual(e.exception.args[0],\n                         (\"The host of the provided URI ({reprout}) contains \"\n                          \"non-ASCII octets, it should be ASCII \"\n                          \"decodable.\").format(reprout=repr(uri.host)))\n\n\n    def test_hostProvided(self):\n        \"\"\"\n        If L{None} is passed to L{Agent.request} for the C{headers} parameter,\n        a L{Headers} instance is created for the request and a I{Host} header\n        added to it.\n        \"\"\"\n        self.agent._getEndpoint = lambda *args: self\n        self.agent.request(\n            b'GET', b'http://example.com/foo?bar')\n\n        req, res = self.protocol.requests.pop()\n        self.assertEqual(req.headers.getRawHeaders(b'host'), [b'example.com'])\n\n\n    def test_hostIPv6Bracketed(self):\n        \"\"\"\n        If an IPv6 address is used in the C{uri} passed to L{Agent.request},\n        the computed I{Host} header needs to be bracketed.\n        \"\"\"\n        self.agent._getEndpoint = lambda *args: self\n        self.agent.request(b'GET', b'http://[::1]/')\n\n        req, res = self.protocol.requests.pop()\n        self.assertEqual(req.headers.getRawHeaders(b'host'), [b'[::1]'])\n\n\n    def test_hostOverride(self):\n        \"\"\"\n        If the headers passed to L{Agent.request} includes a value for the\n        I{Host} header, that value takes precedence over the one which would\n        otherwise be automatically provided.\n        \"\"\"\n        headers = http_headers.Headers({b'foo': [b'bar'], b'host': [b'quux']})\n        self.agent._getEndpoint = lambda *args: self\n        self.agent.request(\n            b'GET', b'http://example.com/foo?bar', headers)\n\n        req, res = self.protocol.requests.pop()\n        self.assertEqual(req.headers.getRawHeaders(b'host'), [b'quux'])\n\n\n    def test_headersUnmodified(self):\n        \"\"\"\n        If a I{Host} header must be added to the request, the L{Headers}\n        instance passed to L{Agent.request} is not modified.\n        \"\"\"\n        headers = http_headers.Headers()\n        self.agent._getEndpoint = lambda *args: self\n        self.agent.request(\n            b'GET', b'http://example.com/foo', headers)\n\n        protocol = self.protocol\n\n        # The request should have been issued.\n        self.assertEqual(len(protocol.requests), 1)\n        # And the headers object passed in should not have changed.\n        self.assertEqual(headers, http_headers.Headers())\n\n\n    def test_hostValueStandardHTTP(self):\n        \"\"\"\n        When passed a scheme of C{'http'} and a port of C{80},\n        L{Agent._computeHostValue} returns a string giving just\n        the host name passed to it.\n        \"\"\"\n        self.assertEqual(\n            self.agent._computeHostValue(b'http', b'example.com', 80),\n            b'example.com')\n\n\n    def test_hostValueNonStandardHTTP(self):\n        \"\"\"\n        When passed a scheme of C{'http'} and a port other than C{80},\n        L{Agent._computeHostValue} returns a string giving the\n        host passed to it joined together with the port number by C{\":\"}.\n        \"\"\"\n        self.assertEqual(\n            self.agent._computeHostValue(b'http', b'example.com', 54321),\n            b'example.com:54321')\n\n\n    def test_hostValueStandardHTTPS(self):\n        \"\"\"\n        When passed a scheme of C{'https'} and a port of C{443},\n        L{Agent._computeHostValue} returns a string giving just\n        the host name passed to it.\n        \"\"\"\n        self.assertEqual(\n            self.agent._computeHostValue(b'https', b'example.com', 443),\n            b'example.com')\n\n\n    def test_hostValueNonStandardHTTPS(self):\n        \"\"\"\n        When passed a scheme of C{'https'} and a port other than C{443},\n        L{Agent._computeHostValue} returns a string giving the\n        host passed to it joined together with the port number by C{\":\"}.\n        \"\"\"\n        self.assertEqual(\n            self.agent._computeHostValue(b'https', b'example.com', 54321),\n            b'example.com:54321')\n\n\n    def test_request(self):\n        \"\"\"\n        L{Agent.request} establishes a new connection to the host indicated by\n        the host part of the URI passed to it and issues a request using the\n        method, the path portion of the URI, the headers, and the body producer\n        passed to it.  It returns a L{Deferred} which fires with an\n        L{IResponse} from the server.\n        \"\"\"\n        self.agent._getEndpoint = lambda *args: self\n\n        headers = http_headers.Headers({b'foo': [b'bar']})\n        # Just going to check the body for identity, so it doesn't need to be\n        # real.\n        body = object()\n        self.agent.request(\n            b'GET', b'http://example.com:1234/foo?bar', headers, body)\n\n        protocol = self.protocol\n\n        # The request should be issued.\n        self.assertEqual(len(protocol.requests), 1)\n        req, res = protocol.requests.pop()\n        self.assertIsInstance(req, Request)\n        self.assertEqual(req.method, b'GET')\n        self.assertEqual(req.uri, b'/foo?bar')\n        self.assertEqual(\n            req.headers,\n            http_headers.Headers({b'foo': [b'bar'],\n                                  b'host': [b'example.com:1234']}))\n        self.assertIdentical(req.bodyProducer, body)\n\n\n    def test_connectTimeout(self):\n        \"\"\"\n        L{Agent} takes a C{connectTimeout} argument which is forwarded to the\n        following C{connectTCP} agent.\n        \"\"\"\n        agent = client.Agent(self.reactor, connectTimeout=5)\n        agent.request(b'GET', b'http://foo/')\n        timeout = self.reactor.tcpClients.pop()[3]\n        self.assertEqual(5, timeout)\n\n\n    def test_connectTimeoutHTTPS(self):\n        \"\"\"\n        L{Agent} takes a C{connectTimeout} argument which is forwarded to the\n        following C{connectTCP} call.\n        \"\"\"\n        agent = client.Agent(self.reactor, connectTimeout=5)\n        agent.request(b'GET', b'https://foo/')\n        timeout = self.reactor.tcpClients.pop()[3]\n        self.assertEqual(5, timeout)\n\n    test_connectTimeoutHTTPS.skip = skipWhenNoSSL\n\n\n    def test_bindAddress(self):\n        \"\"\"\n        L{Agent} takes a C{bindAddress} argument which is forwarded to the\n        following C{connectTCP} call.\n        \"\"\"\n        agent = client.Agent(self.reactor, bindAddress='192.168.0.1')\n        agent.request(b'GET', b'http://foo/')\n        address = self.reactor.tcpClients.pop()[4]\n        self.assertEqual('192.168.0.1', address)\n\n\n    def test_bindAddressSSL(self):\n        \"\"\"\n        L{Agent} takes a C{bindAddress} argument which is forwarded to the\n        following C{connectSSL} call.\n        \"\"\"\n        agent = client.Agent(self.reactor, bindAddress='192.168.0.1')\n        agent.request(b'GET', b'https://foo/')\n        address = self.reactor.tcpClients.pop()[4]\n        self.assertEqual('192.168.0.1', address)\n\n    test_bindAddressSSL.skip = skipWhenNoSSL\n\n\n    def test_responseIncludesRequest(self):\n        \"\"\"\n        L{Response}s returned by L{Agent.request} have a reference to the\n        L{Request} that was originally issued.\n        \"\"\"\n        uri = b'http://example.com/'\n        agent = self.buildAgentForWrapperTest(self.reactor)\n        d = agent.request(b'GET', uri)\n\n        # The request should be issued.\n        self.assertEqual(len(self.protocol.requests), 1)\n        req, res = self.protocol.requests.pop()\n        self.assertIsInstance(req, Request)\n\n        resp = client.Response._construct(\n            (b'HTTP', 1, 1),\n            200,\n            b'OK',\n            client.Headers({}),\n            None,\n            req)\n        res.callback(resp)\n\n        response = self.successResultOf(d)\n        self.assertEqual(\n            (response.request.method, response.request.absoluteURI,\n             response.request.headers),\n            (req.method, req.absoluteURI, req.headers))\n\n\n    def test_requestAbsoluteURI(self):\n        \"\"\"\n        L{Request.absoluteURI} is the absolute URI of the request.\n        \"\"\"\n        uri = b'http://example.com/foo;1234?bar#frag'\n        agent = self.buildAgentForWrapperTest(self.reactor)\n        agent.request(b'GET', uri)\n\n        # The request should be issued.\n        self.assertEqual(len(self.protocol.requests), 1)\n        req, res = self.protocol.requests.pop()\n        self.assertIsInstance(req, Request)\n        self.assertEqual(req.absoluteURI, uri)\n\n\n    def test_requestMissingAbsoluteURI(self):\n        \"\"\"\n        L{Request.absoluteURI} is L{None} if L{Request._parsedURI} is L{None}.\n        \"\"\"\n        request = client.Request(b'FOO', b'/', client.Headers(), None)\n        self.assertIdentical(request.absoluteURI, None)\n\n\n    def test_endpointFactory(self):\n        \"\"\"\n        L{Agent.usingEndpointFactory} creates an L{Agent} that uses the given\n        factory to create endpoints.\n        \"\"\"\n        factory = StubEndpointFactory()\n        agent = client.Agent.usingEndpointFactory(\n            None, endpointFactory=factory)\n        uri = URI.fromBytes(b'http://example.com/')\n        returnedEndpoint = agent._getEndpoint(uri)\n        self.assertEqual(returnedEndpoint, (b\"http\", b\"example.com\", 80))\n\n\n    def test_endpointFactoryDefaultPool(self):\n        \"\"\"\n        If no pool is passed in to L{Agent.usingEndpointFactory}, a default\n        pool is constructed with no persistent connections.\n        \"\"\"\n        agent = client.Agent.usingEndpointFactory(\n            self.reactor, StubEndpointFactory())\n        pool = agent._pool\n        self.assertEqual((pool.__class__, pool.persistent, pool._reactor),\n                          (HTTPConnectionPool, False, agent._reactor))\n\n\n    def test_endpointFactoryPool(self):\n        \"\"\"\n        If a pool is passed in to L{Agent.usingEndpointFactory} it is used as\n        the L{Agent} pool.\n        \"\"\"\n        pool = object()\n        agent = client.Agent.usingEndpointFactory(\n            self.reactor, StubEndpointFactory(), pool)\n        self.assertIs(pool, agent._pool)\n\n\n\nclass AgentMethodInjectionTests(\n        FakeReactorAndConnectMixin,\n        MethodInjectionTestsMixin,\n        SynchronousTestCase,\n):\n    \"\"\"\n    Test L{client.Agent} against HTTP method injections.\n    \"\"\"\n\n    def attemptRequestWithMaliciousMethod(self, method):\n        \"\"\"\n        Attempt a request with the provided method.\n\n        @param method: see L{MethodInjectionTestsMixin}\n        \"\"\"\n        agent = client.Agent(self.createReactor())\n        uri = b\"http://twisted.invalid\"\n        agent.request(method, uri, client.Headers(), None)\n\n\n\nclass AgentURIInjectionTests(\n        FakeReactorAndConnectMixin,\n        URIInjectionTestsMixin,\n        SynchronousTestCase,\n):\n    \"\"\"\n    Test L{client.Agent} against URI injections.\n    \"\"\"\n\n    def attemptRequestWithMaliciousURI(self, uri):\n        \"\"\"\n        Attempt a request with the provided method.\n\n        @param uri: see L{URIInjectionTestsMixin}\n        \"\"\"\n        agent = client.Agent(self.createReactor())\n        method = b\"GET\"\n        agent.request(method, uri, client.Headers(), None)\n\n\n\nclass AgentHTTPSTests(TestCase, FakeReactorAndConnectMixin,\n                      IntegrationTestingMixin):\n    \"\"\"\n    Tests for the new HTTP client API that depends on SSL.\n    \"\"\"\n    skip = skipWhenNoSSL\n\n    def makeEndpoint(self, host=b'example.com', port=443):\n        \"\"\"\n        Create an L{Agent} with an https scheme and return its endpoint\n        created according to the arguments.\n\n        @param host: The host for the endpoint.\n        @type host: L{bytes}\n\n        @param port: The port for the endpoint.\n        @type port: L{int}\n\n        @return: An endpoint of an L{Agent} constructed according to args.\n        @rtype: L{SSL4ClientEndpoint}\n        \"\"\"\n        return client.Agent(self.createReactor())._getEndpoint(\n            URI.fromBytes(b'https://' + host + b\":\" + intToBytes(port) + b\"/\"))\n\n\n    def test_endpointType(self):\n        \"\"\"\n        L{Agent._getEndpoint} return a L{SSL4ClientEndpoint} when passed a\n        scheme of C{'https'}.\n        \"\"\"\n        from twisted.internet.endpoints import _WrapperEndpoint\n        endpoint = self.makeEndpoint()\n        self.assertIsInstance(endpoint, _WrapperEndpoint)\n        self.assertIsInstance(endpoint._wrappedEndpoint, HostnameEndpoint)\n\n\n    def test_hostArgumentIsRespected(self):\n        \"\"\"\n        If a host is passed, the endpoint respects it.\n        \"\"\"\n        endpoint = self.makeEndpoint(host=b\"example.com\")\n        self.assertEqual(endpoint._wrappedEndpoint._hostStr, \"example.com\")\n\n\n    def test_portArgumentIsRespected(self):\n        \"\"\"\n        If a port is passed, the endpoint respects it.\n        \"\"\"\n        expectedPort = 4321\n        endpoint = self.makeEndpoint(port=expectedPort)\n        self.assertEqual(endpoint._wrappedEndpoint._port, expectedPort)\n\n\n    def test_contextFactoryType(self):\n        \"\"\"\n        L{Agent} wraps its connection creator creator and uses modern TLS APIs.\n        \"\"\"\n        endpoint = self.makeEndpoint()\n        contextFactory = endpoint._wrapperFactory(None)._connectionCreator\n        self.assertIsInstance(contextFactory, ClientTLSOptions)\n        self.assertEqual(contextFactory._hostname, u\"example.com\")\n\n\n    def test_connectHTTPSCustomConnectionCreator(self):\n        \"\"\"\n        If a custom L{WebClientConnectionCreator}-like object is passed to\n        L{Agent.__init__} it will be used to determine the SSL parameters for\n        HTTPS requests.  When an HTTPS request is made, the hostname and port\n        number of the request URL will be passed to the connection creator's\n        C{creatorForNetloc} method.  The resulting context object will be used\n        to establish the SSL connection.\n        \"\"\"\n        expectedHost = b'example.org'\n        expectedPort = 20443\n        class JustEnoughConnection(object):\n            handshakeStarted = False\n            connectState = False\n            def do_handshake(self):\n                \"\"\"\n                The handshake started.  Record that fact.\n                \"\"\"\n                self.handshakeStarted = True\n            def set_connect_state(self):\n                \"\"\"\n                The connection started.  Record that fact.\n                \"\"\"\n                self.connectState = True\n\n        contextArgs = []\n\n        @implementer(IOpenSSLClientConnectionCreator)\n        class JustEnoughCreator(object):\n            def __init__(self, hostname, port):\n                self.hostname = hostname\n                self.port = port\n\n            def clientConnectionForTLS(self, tlsProtocol):\n                \"\"\"\n                Implement L{IOpenSSLClientConnectionCreator}.\n\n                @param tlsProtocol: The TLS protocol.\n                @type tlsProtocol: L{TLSMemoryBIOProtocol}\n\n                @return: C{expectedConnection}\n                \"\"\"\n                contextArgs.append((tlsProtocol, self.hostname, self.port))\n                return expectedConnection\n\n        expectedConnection = JustEnoughConnection()\n        @implementer(IPolicyForHTTPS)\n        class StubBrowserLikePolicyForHTTPS(object):\n            def creatorForNetloc(self, hostname, port):\n                \"\"\"\n                Emulate L{BrowserLikePolicyForHTTPS}.\n\n                @param hostname: The hostname to verify.\n                @type hostname: L{bytes}\n\n                @param port: The port number.\n                @type port: L{int}\n\n                @return: a stub L{IOpenSSLClientConnectionCreator}\n                @rtype: L{JustEnoughCreator}\n                \"\"\"\n                return JustEnoughCreator(hostname, port)\n\n        expectedCreatorCreator = StubBrowserLikePolicyForHTTPS()\n        reactor = self.createReactor()\n        agent = client.Agent(reactor, expectedCreatorCreator)\n        endpoint = agent._getEndpoint(URI.fromBytes(\n            b'https://' + expectedHost + b\":\" + intToBytes(expectedPort)))\n        endpoint.connect(Factory.forProtocol(Protocol))\n        tlsFactory = reactor.tcpClients[-1][2]\n        tlsProtocol = tlsFactory.buildProtocol(None)\n        tlsProtocol.makeConnection(StringTransport())\n        tls = contextArgs[0][0]\n        self.assertIsInstance(tls, TLSMemoryBIOProtocol)\n        self.assertEqual(contextArgs[0][1:], (expectedHost, expectedPort))\n        self.assertTrue(expectedConnection.handshakeStarted)\n        self.assertTrue(expectedConnection.connectState)\n\n\n    def test_deprecatedDuckPolicy(self):\n        \"\"\"\n        Passing something that duck-types I{like} a L{web client context\n        factory <twisted.web.client.WebClientContextFactory>} - something that\n        does not provide L{IPolicyForHTTPS} - to L{Agent} emits a\n        L{DeprecationWarning} even if you don't actually C{import\n        WebClientContextFactory} to do it.\n        \"\"\"\n        def warnMe():\n            client.Agent(deterministicResolvingReactor(MemoryReactorClock()),\n                         \"does-not-provide-IPolicyForHTTPS\")\n        warnMe()\n        warnings = self.flushWarnings([warnMe])\n        self.assertEqual(len(warnings), 1)\n        [warning] = warnings\n        self.assertEqual(warning['category'], DeprecationWarning)\n        self.assertEqual(\n            warning['message'],\n            \"'does-not-provide-IPolicyForHTTPS' was passed as the HTTPS \"\n            \"policy for an Agent, but it does not provide IPolicyForHTTPS.  \"\n            \"Since Twisted 14.0, you must pass a provider of IPolicyForHTTPS.\"\n        )\n\n\n    def test_alternateTrustRoot(self):\n        \"\"\"\n        L{BrowserLikePolicyForHTTPS.creatorForNetloc} returns an\n        L{IOpenSSLClientConnectionCreator} provider which will add certificates\n        from the given trust root.\n        \"\"\"\n        trustRoot = CustomOpenSSLTrustRoot()\n        policy = BrowserLikePolicyForHTTPS(trustRoot=trustRoot)\n        creator = policy.creatorForNetloc(b\"thingy\", 4321)\n        self.assertTrue(trustRoot.called)\n        connection = creator.clientConnectionForTLS(None)\n        self.assertIs(trustRoot.context, connection.get_context())\n\n\n    def integrationTest(self, hostName, expectedAddress, addressType):\n        \"\"\"\n        Wrap L{AgentTestsMixin.integrationTest} with TLS.\n        \"\"\"\n        certHostName = hostName.strip(b'[]')\n        authority, server = certificatesForAuthorityAndServer(certHostName\n                                                              .decode('ascii'))\n        def tlsify(serverFactory):\n            return TLSMemoryBIOFactory(server.options(), False, serverFactory)\n        def tlsagent(reactor):\n            from twisted.web.iweb import IPolicyForHTTPS\n            from zope.interface import implementer\n            @implementer(IPolicyForHTTPS)\n            class Policy(object):\n                def creatorForNetloc(self, hostname, port):\n                    return optionsForClientTLS(hostname.decode(\"ascii\"),\n                                               trustRoot=authority)\n            return client.Agent(reactor, contextFactory=Policy())\n        (super(AgentHTTPSTests, self)\n         .integrationTest(hostName, expectedAddress, addressType,\n                          serverWrapper=tlsify,\n                          createAgent=tlsagent,\n                          scheme=b'https'))\n\n\n\nclass WebClientContextFactoryTests(TestCase):\n    \"\"\"\n    Tests for the context factory wrapper for web clients\n    L{twisted.web.client.WebClientContextFactory}.\n    \"\"\"\n\n    def setUp(self):\n        \"\"\"\n        Get WebClientContextFactory while quashing its deprecation warning.\n        \"\"\"\n        from twisted.web.client import WebClientContextFactory\n        self.warned = self.flushWarnings([WebClientContextFactoryTests.setUp])\n        self.webClientContextFactory = WebClientContextFactory\n\n\n    def test_deprecated(self):\n        \"\"\"\n        L{twisted.web.client.WebClientContextFactory} is deprecated.  Importing\n        it displays a warning.\n        \"\"\"\n        self.assertEqual(len(self.warned), 1)\n        [warning] = self.warned\n        self.assertEqual(warning['category'], DeprecationWarning)\n        self.assertEqual(\n            warning['message'],\n            getDeprecationWarningString(\n                self.webClientContextFactory, Version(\"Twisted\", 14, 0, 0),\n                replacement=BrowserLikePolicyForHTTPS,\n            )\n\n            # See https://twistedmatrix.com/trac/ticket/7242\n            .replace(\";\", \":\")\n        )\n\n\n    def test_missingSSL(self):\n        \"\"\"\n        If C{getContext} is called and SSL is not available, raise\n        L{NotImplementedError}.\n        \"\"\"\n        self.assertRaises(\n            NotImplementedError,\n            self.webClientContextFactory().getContext,\n            b'example.com', 443,\n        )\n\n\n    def test_returnsContext(self):\n        \"\"\"\n        If SSL is present, C{getContext} returns a L{OpenSSL.SSL.Context}.\n        \"\"\"\n        ctx = self.webClientContextFactory().getContext('example.com', 443)\n        self.assertIsInstance(ctx, ssl.SSL.Context)\n\n\n    def test_setsTrustRootOnContextToDefaultTrustRoot(self):\n        \"\"\"\n        The L{CertificateOptions} has C{trustRoot} set to the default trust\n        roots.\n        \"\"\"\n        ctx = self.webClientContextFactory()\n        certificateOptions = ctx._getCertificateOptions('example.com', 443)\n        self.assertIsInstance(\n            certificateOptions.trustRoot, ssl.OpenSSLDefaultPaths)\n\n    test_returnsContext.skip \\\n        = test_setsTrustRootOnContextToDefaultTrustRoot.skip \\\n        = skipWhenNoSSL\n    test_missingSSL.skip = skipWhenSSLPresent\n\n\n\nclass HTTPConnectionPoolRetryTests(TestCase, FakeReactorAndConnectMixin):\n    \"\"\"\n    L{client.HTTPConnectionPool}, by using\n    L{client._RetryingHTTP11ClientProtocol}, supports retrying requests done\n    against previously cached connections.\n    \"\"\"\n\n    def test_onlyRetryIdempotentMethods(self):\n        \"\"\"\n        Only GET, HEAD, OPTIONS, TRACE, DELETE methods cause a retry.\n        \"\"\"\n        pool = client.HTTPConnectionPool(None)\n        connection = client._RetryingHTTP11ClientProtocol(None, pool)\n        self.assertTrue(connection._shouldRetry(\n            b\"GET\", RequestNotSent(), None))\n        self.assertTrue(connection._shouldRetry(\n            b\"HEAD\", RequestNotSent(), None))\n        self.assertTrue(connection._shouldRetry(\n            b\"OPTIONS\", RequestNotSent(), None))\n        self.assertTrue(connection._shouldRetry(\n            b\"TRACE\", RequestNotSent(), None))\n        self.assertTrue(connection._shouldRetry(\n            b\"DELETE\", RequestNotSent(), None))\n        self.assertFalse(connection._shouldRetry(\n            b\"POST\", RequestNotSent(), None))\n        self.assertFalse(connection._shouldRetry(\n            b\"MYMETHOD\", RequestNotSent(), None))\n        # This will be covered by a different ticket, since we need support\n        #for resettable body producers:\n        # self.assertTrue(connection._doRetry(\"PUT\", RequestNotSent(), None))\n\n\n    def test_onlyRetryIfNoResponseReceived(self):\n        \"\"\"\n        Only L{RequestNotSent}, L{RequestTransmissionFailed} and\n        L{ResponseNeverReceived} exceptions cause a retry.\n        \"\"\"\n        pool = client.HTTPConnectionPool(None)\n        connection = client._RetryingHTTP11ClientProtocol(None, pool)\n        self.assertTrue(connection._shouldRetry(\n            b\"GET\", RequestNotSent(), None))\n        self.assertTrue(connection._shouldRetry(\n            b\"GET\", RequestTransmissionFailed([]), None))\n        self.assertTrue(connection._shouldRetry(\n            b\"GET\", ResponseNeverReceived([]),None))\n        self.assertFalse(connection._shouldRetry(\n            b\"GET\", ResponseFailed([]), None))\n        self.assertFalse(connection._shouldRetry(\n            b\"GET\", ConnectionRefusedError(), None))\n\n\n    def test_dontRetryIfFailedDueToCancel(self):\n        \"\"\"\n        If a request failed due to the operation being cancelled,\n        C{_shouldRetry} returns C{False} to indicate the request should not be\n        retried.\n        \"\"\"\n        pool = client.HTTPConnectionPool(None)\n        connection = client._RetryingHTTP11ClientProtocol(None, pool)\n        exception = ResponseNeverReceived([Failure(defer.CancelledError())])\n        self.assertFalse(connection._shouldRetry(b\"GET\", exception, None))\n\n\n    def test_retryIfFailedDueToNonCancelException(self):\n        \"\"\"\n        If a request failed with L{ResponseNeverReceived} due to some\n        arbitrary exception, C{_shouldRetry} returns C{True} to indicate the\n        request should be retried.\n        \"\"\"\n        pool = client.HTTPConnectionPool(None)\n        connection = client._RetryingHTTP11ClientProtocol(None, pool)\n        self.assertTrue(connection._shouldRetry(\n            b\"GET\", ResponseNeverReceived([Failure(Exception())]), None))\n\n\n    def test_wrappedOnPersistentReturned(self):\n        \"\"\"\n        If L{client.HTTPConnectionPool.getConnection} returns a previously\n        cached connection, it will get wrapped in a\n        L{client._RetryingHTTP11ClientProtocol}.\n        \"\"\"\n        pool = client.HTTPConnectionPool(Clock())\n\n        # Add a connection to the cache:\n        protocol = StubHTTPProtocol()\n        protocol.makeConnection(StringTransport())\n        pool._putConnection(123, protocol)\n\n        # Retrieve it, it should come back wrapped in a\n        # _RetryingHTTP11ClientProtocol:\n        d = pool.getConnection(123, DummyEndpoint())\n\n        def gotConnection(connection):\n            self.assertIsInstance(connection,\n                                  client._RetryingHTTP11ClientProtocol)\n            self.assertIdentical(connection._clientProtocol, protocol)\n        return d.addCallback(gotConnection)\n\n\n    def test_notWrappedOnNewReturned(self):\n        \"\"\"\n        If L{client.HTTPConnectionPool.getConnection} returns a new\n        connection, it will be returned as is.\n        \"\"\"\n        pool = client.HTTPConnectionPool(None)\n        d = pool.getConnection(123, DummyEndpoint())\n\n        def gotConnection(connection):\n            # Don't want to use isinstance since potentially the wrapper might\n            # subclass it at some point:\n            self.assertIdentical(connection.__class__, HTTP11ClientProtocol)\n        return d.addCallback(gotConnection)\n\n\n    def retryAttempt(self, willWeRetry):\n        \"\"\"\n        Fail a first request, possibly retrying depending on argument.\n        \"\"\"\n        protocols = []\n        def newProtocol():\n            protocol = StubHTTPProtocol()\n            protocols.append(protocol)\n            return defer.succeed(protocol)\n\n        bodyProducer = object()\n        request = client.Request(b\"FOO\", b\"/\", client.Headers(), bodyProducer,\n                                 persistent=True)\n        newProtocol()\n        protocol = protocols[0]\n        retrier = client._RetryingHTTP11ClientProtocol(protocol, newProtocol)\n\n        def _shouldRetry(m, e, bp):\n            self.assertEqual(m, b\"FOO\")\n            self.assertIdentical(bp, bodyProducer)\n            self.assertIsInstance(e, (RequestNotSent, ResponseNeverReceived))\n            return willWeRetry\n        retrier._shouldRetry = _shouldRetry\n\n        d = retrier.request(request)\n\n        # So far, one request made:\n        self.assertEqual(len(protocols), 1)\n        self.assertEqual(len(protocols[0].requests), 1)\n\n        # Fail the first request:\n        protocol.requests[0][1].errback(RequestNotSent())\n        return d, protocols\n\n\n    def test_retryIfShouldRetryReturnsTrue(self):\n        \"\"\"\n        L{client._RetryingHTTP11ClientProtocol} retries when\n        L{client._RetryingHTTP11ClientProtocol._shouldRetry} returns C{True}.\n        \"\"\"\n        d, protocols = self.retryAttempt(True)\n        # We retried!\n        self.assertEqual(len(protocols), 2)\n        response = object()\n        protocols[1].requests[0][1].callback(response)\n        return d.addCallback(self.assertIdentical, response)\n\n\n    def test_dontRetryIfShouldRetryReturnsFalse(self):\n        \"\"\"\n        L{client._RetryingHTTP11ClientProtocol} does not retry when\n        L{client._RetryingHTTP11ClientProtocol._shouldRetry} returns C{False}.\n        \"\"\"\n        d, protocols = self.retryAttempt(False)\n        # We did not retry:\n        self.assertEqual(len(protocols), 1)\n        return self.assertFailure(d, RequestNotSent)\n\n\n    def test_onlyRetryWithoutBody(self):\n        \"\"\"\n        L{_RetryingHTTP11ClientProtocol} only retries queries that don't have\n        a body.\n\n        This is an implementation restriction; if the restriction is fixed,\n        this test should be removed and PUT added to list of methods that\n        support retries.\n        \"\"\"\n        pool = client.HTTPConnectionPool(None)\n        connection = client._RetryingHTTP11ClientProtocol(None, pool)\n        self.assertTrue(connection._shouldRetry(b\"GET\", RequestNotSent(), None))\n        self.assertFalse(connection._shouldRetry(b\"GET\", RequestNotSent(), object()))\n\n\n    def test_onlyRetryOnce(self):\n        \"\"\"\n        If a L{client._RetryingHTTP11ClientProtocol} fails more than once on\n        an idempotent query before a response is received, it will not retry.\n        \"\"\"\n        d, protocols = self.retryAttempt(True)\n        self.assertEqual(len(protocols), 2)\n        # Fail the second request too:\n        protocols[1].requests[0][1].errback(ResponseNeverReceived([]))\n        # We didn't retry again:\n        self.assertEqual(len(protocols), 2)\n        return self.assertFailure(d, ResponseNeverReceived)\n\n\n    def test_dontRetryIfRetryAutomaticallyFalse(self):\n        \"\"\"\n        If L{HTTPConnectionPool.retryAutomatically} is set to C{False}, don't\n        wrap connections with retrying logic.\n        \"\"\"\n        pool = client.HTTPConnectionPool(Clock())\n        pool.retryAutomatically = False\n\n        # Add a connection to the cache:\n        protocol = StubHTTPProtocol()\n        protocol.makeConnection(StringTransport())\n        pool._putConnection(123, protocol)\n\n        # Retrieve it, it should come back unwrapped:\n        d = pool.getConnection(123, DummyEndpoint())\n\n        def gotConnection(connection):\n            self.assertIdentical(connection, protocol)\n        return d.addCallback(gotConnection)\n\n\n    def test_retryWithNewConnection(self):\n        \"\"\"\n        L{client.HTTPConnectionPool} creates\n        {client._RetryingHTTP11ClientProtocol} with a new connection factory\n        method that creates a new connection using the same key and endpoint\n        as the wrapped connection.\n        \"\"\"\n        pool = client.HTTPConnectionPool(Clock())\n        key = 123\n        endpoint = DummyEndpoint()\n        newConnections = []\n\n        # Override the pool's _newConnection:\n        def newConnection(k, e):\n            newConnections.append((k, e))\n        pool._newConnection = newConnection\n\n        # Add a connection to the cache:\n        protocol = StubHTTPProtocol()\n        protocol.makeConnection(StringTransport())\n        pool._putConnection(key, protocol)\n\n        # Retrieve it, it should come back wrapped in a\n        # _RetryingHTTP11ClientProtocol:\n        d = pool.getConnection(key, endpoint)\n\n        def gotConnection(connection):\n            self.assertIsInstance(connection,\n                                  client._RetryingHTTP11ClientProtocol)\n            self.assertIdentical(connection._clientProtocol, protocol)\n            # Verify that the _newConnection method on retrying connection\n            # calls _newConnection on the pool:\n            self.assertEqual(newConnections, [])\n            connection._newConnection()\n            self.assertEqual(len(newConnections), 1)\n            self.assertEqual(newConnections[0][0], key)\n            self.assertIdentical(newConnections[0][1], endpoint)\n        return d.addCallback(gotConnection)\n\n\n\nclass CookieTestsMixin(object):\n    \"\"\"\n    Mixin for unit tests dealing with cookies.\n    \"\"\"\n    def addCookies(self, cookieJar, uri, cookies):\n        \"\"\"\n        Add a cookie to a cookie jar.\n        \"\"\"\n        response = client._FakeUrllib2Response(\n            client.Response(\n                (b'HTTP', 1, 1),\n                200,\n                b'OK',\n                client.Headers({b'Set-Cookie': cookies}),\n                None))\n        request = client._FakeUrllib2Request(uri)\n        cookieJar.extract_cookies(response, request)\n        return request, response\n\n\n\nclass CookieJarTests(TestCase, CookieTestsMixin):\n    \"\"\"\n    Tests for L{twisted.web.client._FakeUrllib2Response} and\n    L{twisted.web.client._FakeUrllib2Request}'s interactions with\n    C{cookielib.CookieJar} instances.\n    \"\"\"\n    def makeCookieJar(self):\n        \"\"\"\n        @return: a C{cookielib.CookieJar} with some sample cookies\n        \"\"\"\n        cookieJar = cookielib.CookieJar()\n        reqres = self.addCookies(\n            cookieJar,\n            b'http://example.com:1234/foo?bar',\n            [b'foo=1; cow=moo; Path=/foo; Comment=hello',\n             b'bar=2; Comment=goodbye'])\n        return cookieJar, reqres\n\n\n    def test_extractCookies(self):\n        \"\"\"\n        L{cookielib.CookieJar.extract_cookies} extracts cookie information from\n        fake urllib2 response instances.\n        \"\"\"\n        jar = self.makeCookieJar()[0]\n        cookies = dict([(c.name, c) for c in jar])\n\n        cookie = cookies['foo']\n        self.assertEqual(cookie.version, 0)\n        self.assertEqual(cookie.name, 'foo')\n        self.assertEqual(cookie.value, '1')\n        self.assertEqual(cookie.path, '/foo')\n        self.assertEqual(cookie.comment, 'hello')\n        self.assertEqual(cookie.get_nonstandard_attr('cow'), 'moo')\n\n        cookie = cookies['bar']\n        self.assertEqual(cookie.version, 0)\n        self.assertEqual(cookie.name, 'bar')\n        self.assertEqual(cookie.value, '2')\n        self.assertEqual(cookie.path, '/')\n        self.assertEqual(cookie.comment, 'goodbye')\n        self.assertIdentical(cookie.get_nonstandard_attr('cow'), None)\n\n\n    def test_sendCookie(self):\n        \"\"\"\n        L{cookielib.CookieJar.add_cookie_header} adds a cookie header to a fake\n        urllib2 request instance.\n        \"\"\"\n        jar, (request, response) = self.makeCookieJar()\n\n        self.assertIdentical(\n            request.get_header('Cookie', None),\n            None)\n\n        jar.add_cookie_header(request)\n        self.assertEqual(\n            request.get_header('Cookie', None),\n            'foo=1; bar=2')\n\n\n\nclass CookieAgentTests(TestCase, CookieTestsMixin, FakeReactorAndConnectMixin,\n                       AgentTestsMixin):\n    \"\"\"\n    Tests for L{twisted.web.client.CookieAgent}.\n    \"\"\"\n    def makeAgent(self):\n        \"\"\"\n        @return: a new L{twisted.web.client.CookieAgent}\n        \"\"\"\n        return client.CookieAgent(\n            self.buildAgentForWrapperTest(self.reactor),\n            cookielib.CookieJar())\n\n\n    def setUp(self):\n        self.reactor = self.createReactor()\n\n\n    def test_emptyCookieJarRequest(self):\n        \"\"\"\n        L{CookieAgent.request} does not insert any C{'Cookie'} header into the\n        L{Request} object if there is no cookie in the cookie jar for the URI\n        being requested. Cookies are extracted from the response and stored in\n        the cookie jar.\n        \"\"\"\n        cookieJar = cookielib.CookieJar()\n        self.assertEqual(list(cookieJar), [])\n\n        agent = self.buildAgentForWrapperTest(self.reactor)\n        cookieAgent = client.CookieAgent(agent, cookieJar)\n        d = cookieAgent.request(\n            b'GET', b'http://example.com:1234/foo?bar')\n\n        def _checkCookie(ignored):\n            cookies = list(cookieJar)\n            self.assertEqual(len(cookies), 1)\n            self.assertEqual(cookies[0].name, 'foo')\n            self.assertEqual(cookies[0].value, '1')\n\n        d.addCallback(_checkCookie)\n\n        req, res = self.protocol.requests.pop()\n        self.assertIdentical(req.headers.getRawHeaders(b'cookie'), None)\n\n        resp = client.Response(\n            (b'HTTP', 1, 1),\n            200,\n            b'OK',\n            client.Headers({b'Set-Cookie': [b'foo=1',]}),\n            None)\n        res.callback(resp)\n\n        return d\n\n\n    def test_requestWithCookie(self):\n        \"\"\"\n        L{CookieAgent.request} inserts a C{'Cookie'} header into the L{Request}\n        object when there is a cookie matching the request URI in the cookie\n        jar.\n        \"\"\"\n        uri = b'http://example.com:1234/foo?bar'\n        cookie = b'foo=1'\n\n        cookieJar = cookielib.CookieJar()\n        self.addCookies(cookieJar, uri, [cookie])\n        self.assertEqual(len(list(cookieJar)), 1)\n\n        agent = self.buildAgentForWrapperTest(self.reactor)\n        cookieAgent = client.CookieAgent(agent, cookieJar)\n        cookieAgent.request(b'GET', uri)\n\n        req, res = self.protocol.requests.pop()\n        self.assertEqual(req.headers.getRawHeaders(b'cookie'), [cookie])\n\n\n    def test_secureCookie(self):\n        \"\"\"\n        L{CookieAgent} is able to handle secure cookies, ie cookies which\n        should only be handled over https.\n        \"\"\"\n        uri = b'https://example.com:1234/foo?bar'\n        cookie = b'foo=1;secure'\n\n        cookieJar = cookielib.CookieJar()\n        self.addCookies(cookieJar, uri, [cookie])\n        self.assertEqual(len(list(cookieJar)), 1)\n\n        agent = self.buildAgentForWrapperTest(self.reactor)\n        cookieAgent = client.CookieAgent(agent, cookieJar)\n        cookieAgent.request(b'GET', uri)\n\n        req, res = self.protocol.requests.pop()\n        self.assertEqual(req.headers.getRawHeaders(b'cookie'), [b'foo=1'])\n\n    test_secureCookie.skip = skipWhenNoSSL\n\n\n    def test_secureCookieOnInsecureConnection(self):\n        \"\"\"\n        If a cookie is setup as secure, it won't be sent with the request if\n        it's not over HTTPS.\n        \"\"\"\n        uri = b'http://example.com/foo?bar'\n        cookie = b'foo=1;secure'\n\n        cookieJar = cookielib.CookieJar()\n        self.addCookies(cookieJar, uri, [cookie])\n        self.assertEqual(len(list(cookieJar)), 1)\n\n        agent = self.buildAgentForWrapperTest(self.reactor)\n        cookieAgent = client.CookieAgent(agent, cookieJar)\n        cookieAgent.request(b'GET', uri)\n\n        req, res = self.protocol.requests.pop()\n        self.assertIdentical(None, req.headers.getRawHeaders(b'cookie'))\n\n\n    def test_portCookie(self):\n        \"\"\"\n        L{CookieAgent} supports cookies which enforces the port number they\n        need to be transferred upon.\n        \"\"\"\n        uri = b'http://example.com:1234/foo?bar'\n        cookie = b'foo=1;port=1234'\n\n        cookieJar = cookielib.CookieJar()\n        self.addCookies(cookieJar, uri, [cookie])\n        self.assertEqual(len(list(cookieJar)), 1)\n\n        agent = self.buildAgentForWrapperTest(self.reactor)\n        cookieAgent = client.CookieAgent(agent, cookieJar)\n        cookieAgent.request(b'GET', uri)\n\n        req, res = self.protocol.requests.pop()\n        self.assertEqual(req.headers.getRawHeaders(b'cookie'), [b'foo=1'])\n\n\n    def test_portCookieOnWrongPort(self):\n        \"\"\"\n        When creating a cookie with a port directive, it won't be added to the\n        L{cookie.CookieJar} if the URI is on a different port.\n        \"\"\"\n        uri = b'http://example.com:4567/foo?bar'\n        cookie = b'foo=1;port=1234'\n\n        cookieJar = cookielib.CookieJar()\n        self.addCookies(cookieJar, uri, [cookie])\n        self.assertEqual(len(list(cookieJar)), 0)\n\n\n\nclass Decoder1(proxyForInterface(IResponse)):\n    \"\"\"\n    A test decoder to be used by L{client.ContentDecoderAgent} tests.\n    \"\"\"\n\n\n\nclass Decoder2(Decoder1):\n    \"\"\"\n    A test decoder to be used by L{client.ContentDecoderAgent} tests.\n    \"\"\"\n\n\n\nclass ContentDecoderAgentTests(TestCase, FakeReactorAndConnectMixin,\n                               AgentTestsMixin):\n    \"\"\"\n    Tests for L{client.ContentDecoderAgent}.\n    \"\"\"\n    def makeAgent(self):\n        \"\"\"\n        @return: a new L{twisted.web.client.ContentDecoderAgent}\n        \"\"\"\n        return client.ContentDecoderAgent(self.agent, [])\n\n\n    def setUp(self):\n        \"\"\"\n        Create an L{Agent} wrapped around a fake reactor.\n        \"\"\"\n        self.reactor = self.createReactor()\n        self.agent = self.buildAgentForWrapperTest(self.reactor)\n\n\n    def test_acceptHeaders(self):\n        \"\"\"\n        L{client.ContentDecoderAgent} sets the I{Accept-Encoding} header to the\n        names of the available decoder objects.\n        \"\"\"\n        agent = client.ContentDecoderAgent(\n            self.agent, [(b'decoder1', Decoder1), (b'decoder2', Decoder2)])\n\n        agent.request(b'GET', b'http://example.com/foo')\n\n        protocol = self.protocol\n\n        self.assertEqual(len(protocol.requests), 1)\n        req, res = protocol.requests.pop()\n        self.assertEqual(req.headers.getRawHeaders(b'accept-encoding'),\n                         [b'decoder1,decoder2'])\n\n\n    def test_existingHeaders(self):\n        \"\"\"\n        If there are existing I{Accept-Encoding} fields,\n        L{client.ContentDecoderAgent} creates a new field for the decoders it\n        knows about.\n        \"\"\"\n        headers = http_headers.Headers({b'foo': [b'bar'],\n                                        b'accept-encoding': [b'fizz']})\n        agent = client.ContentDecoderAgent(\n            self.agent, [(b'decoder1', Decoder1), (b'decoder2', Decoder2)])\n        agent.request(b'GET', b'http://example.com/foo', headers=headers)\n\n        protocol = self.protocol\n\n        self.assertEqual(len(protocol.requests), 1)\n        req, res = protocol.requests.pop()\n        self.assertEqual(\n            list(sorted(req.headers.getAllRawHeaders())),\n            [(b'Accept-Encoding', [b'fizz', b'decoder1,decoder2']),\n             (b'Foo', [b'bar']),\n             (b'Host', [b'example.com'])])\n\n\n    def test_plainEncodingResponse(self):\n        \"\"\"\n        If the response is not encoded despited the request I{Accept-Encoding}\n        headers, L{client.ContentDecoderAgent} simply forwards the response.\n        \"\"\"\n        agent = client.ContentDecoderAgent(\n            self.agent, [(b'decoder1', Decoder1), (b'decoder2', Decoder2)])\n        deferred = agent.request(b'GET', b'http://example.com/foo')\n\n        req, res = self.protocol.requests.pop()\n\n        response = Response((b'HTTP', 1, 1), 200, b'OK', http_headers.Headers(),\n                            None)\n        res.callback(response)\n\n        return deferred.addCallback(self.assertIdentical, response)\n\n\n    def test_unsupportedEncoding(self):\n        \"\"\"\n        If an encoding unknown to the L{client.ContentDecoderAgent} is found,\n        the response is unchanged.\n        \"\"\"\n        agent = client.ContentDecoderAgent(\n            self.agent, [(b'decoder1', Decoder1), (b'decoder2', Decoder2)])\n        deferred = agent.request(b'GET', b'http://example.com/foo')\n\n        req, res = self.protocol.requests.pop()\n\n        headers = http_headers.Headers({b'foo': [b'bar'],\n                                        b'content-encoding': [b'fizz']})\n        response = Response((b'HTTP', 1, 1), 200, b'OK', headers, None)\n        res.callback(response)\n\n        return deferred.addCallback(self.assertIdentical, response)\n\n\n    def test_unknownEncoding(self):\n        \"\"\"\n        When L{client.ContentDecoderAgent} encounters a decoder it doesn't know\n        about, it stops decoding even if another encoding is known afterwards.\n        \"\"\"\n        agent = client.ContentDecoderAgent(\n            self.agent, [(b'decoder1', Decoder1), (b'decoder2', Decoder2)])\n        deferred = agent.request(b'GET', b'http://example.com/foo')\n\n        req, res = self.protocol.requests.pop()\n\n        headers = http_headers.Headers({b'foo': [b'bar'],\n                                        b'content-encoding':\n                                        [b'decoder1,fizz,decoder2']})\n        response = Response((b'HTTP', 1, 1), 200, b'OK', headers, None)\n        res.callback(response)\n\n        def check(result):\n            self.assertNotIdentical(response, result)\n            self.assertIsInstance(result, Decoder2)\n            self.assertEqual([b'decoder1,fizz'],\n                             result.headers.getRawHeaders(b'content-encoding'))\n\n        return deferred.addCallback(check)\n\n\n\nclass SimpleAgentProtocol(Protocol):\n    \"\"\"\n    A L{Protocol} to be used with an L{client.Agent} to receive data.\n\n    @ivar finished: L{Deferred} firing when C{connectionLost} is called.\n\n    @ivar made: L{Deferred} firing when C{connectionMade} is called.\n\n    @ivar received: C{list} of received data.\n    \"\"\"\n\n    def __init__(self):\n        self.made = Deferred()\n        self.finished = Deferred()\n        self.received = []\n\n\n    def connectionMade(self):\n        self.made.callback(None)\n\n\n    def connectionLost(self, reason):\n        self.finished.callback(None)\n\n\n    def dataReceived(self, data):\n        self.received.append(data)\n\n\n\nclass ContentDecoderAgentWithGzipTests(TestCase,\n                                       FakeReactorAndConnectMixin):\n\n    def setUp(self):\n        \"\"\"\n        Create an L{Agent} wrapped around a fake reactor.\n        \"\"\"\n        self.reactor = self.createReactor()\n        agent = self.buildAgentForWrapperTest(self.reactor)\n        self.agent = client.ContentDecoderAgent(\n            agent, [(b\"gzip\", client.GzipDecoder)])\n\n\n    def test_gzipEncodingResponse(self):\n        \"\"\"\n        If the response has a C{gzip} I{Content-Encoding} header,\n        L{GzipDecoder} wraps the response to return uncompressed data to the\n        user.\n        \"\"\"\n        deferred = self.agent.request(b'GET', b'http://example.com/foo')\n\n        req, res = self.protocol.requests.pop()\n\n        headers = http_headers.Headers({b'foo': [b'bar'],\n                                        b'content-encoding': [b'gzip']})\n        transport = StringTransport()\n        response = Response((b'HTTP', 1, 1), 200, b'OK', headers, transport)\n        response.length = 12\n        res.callback(response)\n\n        compressor = zlib.compressobj(2, zlib.DEFLATED, 16 + zlib.MAX_WBITS)\n        data = (compressor.compress(b'x' * 6) + compressor.compress(b'y' * 4) +\n                compressor.flush())\n\n        def checkResponse(result):\n            self.assertNotIdentical(result, response)\n            self.assertEqual(result.version, (b'HTTP', 1, 1))\n            self.assertEqual(result.code, 200)\n            self.assertEqual(result.phrase, b'OK')\n            self.assertEqual(list(result.headers.getAllRawHeaders()),\n                              [(b'Foo', [b'bar'])])\n            self.assertEqual(result.length, UNKNOWN_LENGTH)\n            self.assertRaises(AttributeError, getattr, result, 'unknown')\n\n            response._bodyDataReceived(data[:5])\n            response._bodyDataReceived(data[5:])\n            response._bodyDataFinished()\n\n            protocol = SimpleAgentProtocol()\n            result.deliverBody(protocol)\n\n            self.assertEqual(protocol.received, [b'x' * 6 + b'y' * 4])\n            return defer.gatherResults([protocol.made, protocol.finished])\n\n        deferred.addCallback(checkResponse)\n\n        return deferred\n\n\n    def test_brokenContent(self):\n        \"\"\"\n        If the data received by the L{GzipDecoder} isn't valid gzip-compressed\n        data, the call to C{deliverBody} fails with a C{zlib.error}.\n        \"\"\"\n        deferred = self.agent.request(b'GET', b'http://example.com/foo')\n\n        req, res = self.protocol.requests.pop()\n\n        headers = http_headers.Headers({b'foo': [b'bar'],\n                                        b'content-encoding': [b'gzip']})\n        transport = StringTransport()\n        response = Response((b'HTTP', 1, 1), 200, b'OK', headers, transport)\n        response.length = 12\n        res.callback(response)\n\n        data = b\"not gzipped content\"\n\n        def checkResponse(result):\n            response._bodyDataReceived(data)\n\n            result.deliverBody(Protocol())\n\n        deferred.addCallback(checkResponse)\n        self.assertFailure(deferred, client.ResponseFailed)\n\n        def checkFailure(error):\n            error.reasons[0].trap(zlib.error)\n            self.assertIsInstance(error.response, Response)\n\n        return deferred.addCallback(checkFailure)\n\n\n    def test_flushData(self):\n        \"\"\"\n        When the connection with the server is lost, the gzip protocol calls\n        C{flush} on the zlib decompressor object to get uncompressed data which\n        may have been buffered.\n        \"\"\"\n        class decompressobj(object):\n\n            def __init__(self, wbits):\n                pass\n\n            def decompress(self, data):\n                return b'x'\n\n            def flush(self):\n                return b'y'\n\n\n        oldDecompressObj = zlib.decompressobj\n        zlib.decompressobj = decompressobj\n        self.addCleanup(setattr, zlib, 'decompressobj', oldDecompressObj)\n\n        deferred = self.agent.request(b'GET', b'http://example.com/foo')\n\n        req, res = self.protocol.requests.pop()\n\n        headers = http_headers.Headers({b'content-encoding': [b'gzip']})\n        transport = StringTransport()\n        response = Response((b'HTTP', 1, 1), 200, b'OK', headers, transport)\n        res.callback(response)\n\n        def checkResponse(result):\n            response._bodyDataReceived(b'data')\n            response._bodyDataFinished()\n\n            protocol = SimpleAgentProtocol()\n            result.deliverBody(protocol)\n\n            self.assertEqual(protocol.received, [b'x', b'y'])\n            return defer.gatherResults([protocol.made, protocol.finished])\n\n        deferred.addCallback(checkResponse)\n\n        return deferred\n\n\n    def test_flushError(self):\n        \"\"\"\n        If the C{flush} call in C{connectionLost} fails, the C{zlib.error}\n        exception is caught and turned into a L{ResponseFailed}.\n        \"\"\"\n        class decompressobj(object):\n\n            def __init__(self, wbits):\n                pass\n\n            def decompress(self, data):\n                return b'x'\n\n            def flush(self):\n                raise zlib.error()\n\n\n        oldDecompressObj = zlib.decompressobj\n        zlib.decompressobj = decompressobj\n        self.addCleanup(setattr, zlib, 'decompressobj', oldDecompressObj)\n\n        deferred = self.agent.request(b'GET', b'http://example.com/foo')\n\n        req, res = self.protocol.requests.pop()\n\n        headers = http_headers.Headers({b'content-encoding': [b'gzip']})\n        transport = StringTransport()\n        response = Response((b'HTTP', 1, 1), 200, b'OK', headers, transport)\n        res.callback(response)\n\n        def checkResponse(result):\n            response._bodyDataReceived(b'data')\n            response._bodyDataFinished()\n\n            protocol = SimpleAgentProtocol()\n            result.deliverBody(protocol)\n\n            self.assertEqual(protocol.received, [b'x', b'y'])\n            return defer.gatherResults([protocol.made, protocol.finished])\n\n        deferred.addCallback(checkResponse)\n\n        self.assertFailure(deferred, client.ResponseFailed)\n\n        def checkFailure(error):\n            error.reasons[1].trap(zlib.error)\n            self.assertIsInstance(error.response, Response)\n\n        return deferred.addCallback(checkFailure)\n\n\n\nclass ProxyAgentTests(TestCase, FakeReactorAndConnectMixin, AgentTestsMixin):\n    \"\"\"\n    Tests for L{client.ProxyAgent}.\n    \"\"\"\n    def makeAgent(self):\n        \"\"\"\n        @return: a new L{twisted.web.client.ProxyAgent}\n        \"\"\"\n        return client.ProxyAgent(\n            TCP4ClientEndpoint(self.reactor, \"127.0.0.1\", 1234),\n            self.reactor)\n\n\n    def setUp(self):\n        self.reactor = self.createReactor()\n        self.agent = client.ProxyAgent(\n            TCP4ClientEndpoint(self.reactor, \"bar\", 5678), self.reactor)\n        oldEndpoint = self.agent._proxyEndpoint\n        self.agent._proxyEndpoint = self.StubEndpoint(oldEndpoint, self)\n\n\n    def test_nonBytesMethod(self):\n        \"\"\"\n        L{ProxyAgent.request} raises L{TypeError} when the C{method} argument\n        isn't L{bytes}.\n        \"\"\"\n        self.assertRaises(TypeError, self.agent.request,\n                          u'GET', b'http://foo.example/')\n\n\n    def test_proxyRequest(self):\n        \"\"\"\n        L{client.ProxyAgent} issues an HTTP request against the proxy, with the\n        full URI as path, when C{request} is called.\n        \"\"\"\n        headers = http_headers.Headers({b'foo': [b'bar']})\n        # Just going to check the body for identity, so it doesn't need to be\n        # real.\n        body = object()\n        self.agent.request(\n            b'GET', b'http://example.com:1234/foo?bar', headers, body)\n\n        host, port, factory = self.reactor.tcpClients.pop()[:3]\n        self.assertEqual(host, \"bar\")\n        self.assertEqual(port, 5678)\n\n        self.assertIsInstance(factory._wrappedFactory,\n                              client._HTTP11ClientFactory)\n\n        protocol = self.protocol\n\n        # The request should be issued.\n        self.assertEqual(len(protocol.requests), 1)\n        req, res = protocol.requests.pop()\n        self.assertIsInstance(req, Request)\n        self.assertEqual(req.method, b'GET')\n        self.assertEqual(req.uri, b'http://example.com:1234/foo?bar')\n        self.assertEqual(\n            req.headers,\n            http_headers.Headers({b'foo': [b'bar'],\n                                  b'host': [b'example.com:1234']}))\n        self.assertIdentical(req.bodyProducer, body)\n\n\n    def test_nonPersistent(self):\n        \"\"\"\n        C{ProxyAgent} connections are not persistent by default.\n        \"\"\"\n        self.assertEqual(self.agent._pool.persistent, False)\n\n\n    def test_connectUsesConnectionPool(self):\n        \"\"\"\n        When a connection is made by the C{ProxyAgent}, it uses its pool's\n        C{getConnection} method to do so, with the endpoint it was constructed\n        with and a key of C{(\"http-proxy\", endpoint)}.\n        \"\"\"\n        endpoint = DummyEndpoint()\n        class DummyPool(object):\n            connected = False\n            persistent = False\n            def getConnection(this, key, ep):\n                this.connected = True\n                self.assertIdentical(ep, endpoint)\n                # The key is *not* tied to the final destination, but only to\n                # the address of the proxy, since that's where *we* are\n                # connecting:\n                self.assertEqual(key, (\"http-proxy\", endpoint))\n                return defer.succeed(StubHTTPProtocol())\n\n        pool = DummyPool()\n        agent = client.ProxyAgent(endpoint, self.reactor, pool=pool)\n        self.assertIdentical(pool, agent._pool)\n\n        agent.request(b'GET', b'http://foo/')\n        self.assertEqual(agent._pool.connected, True)\n\n\n\nclass _RedirectAgentTestsMixin(object):\n    \"\"\"\n    Test cases mixin for L{RedirectAgentTests} and\n    L{BrowserLikeRedirectAgentTests}.\n    \"\"\"\n    def test_noRedirect(self):\n        \"\"\"\n        L{client.RedirectAgent} behaves like L{client.Agent} if the response\n        doesn't contain a redirect.\n        \"\"\"\n        deferred = self.agent.request(b'GET', b'http://example.com/foo')\n\n        req, res = self.protocol.requests.pop()\n\n        headers = http_headers.Headers()\n        response = Response((b'HTTP', 1, 1), 200, b'OK', headers, None)\n        res.callback(response)\n\n        self.assertEqual(0, len(self.protocol.requests))\n        result = self.successResultOf(deferred)\n        self.assertIdentical(response, result)\n        self.assertIdentical(result.previousResponse, None)\n\n\n    def _testRedirectDefault(self, code):\n        \"\"\"\n        When getting a redirect, L{client.RedirectAgent} follows the URL\n        specified in the L{Location} header field and make a new request.\n\n        @param code: HTTP status code.\n        \"\"\"\n        self.agent.request(b'GET', b'http://example.com/foo')\n\n        host, port = self.reactor.tcpClients.pop()[:2]\n        self.assertEqual(EXAMPLE_COM_IP, host)\n        self.assertEqual(80, port)\n\n        req, res = self.protocol.requests.pop()\n\n        # If possible (i.e.: SSL support is present), run the test with a\n        # cross-scheme redirect to verify that the scheme is honored; if not,\n        # let's just make sure it works at all.\n        if ssl is None:\n            scheme = b'http'\n            expectedPort = 80\n        else:\n            scheme = b'https'\n            expectedPort = 443\n\n        headers = http_headers.Headers(\n            {b'location': [scheme + b'://example.com/bar']})\n        response = Response((b'HTTP', 1, 1), code, b'OK', headers, None)\n        res.callback(response)\n\n        req2, res2 = self.protocol.requests.pop()\n        self.assertEqual(b'GET', req2.method)\n        self.assertEqual(b'/bar', req2.uri)\n\n        host, port = self.reactor.tcpClients.pop()[:2]\n        self.assertEqual(EXAMPLE_COM_IP, host)\n        self.assertEqual(expectedPort, port)\n\n\n    def test_redirect301(self):\n        \"\"\"\n        L{client.RedirectAgent} follows redirects on status code 301.\n        \"\"\"\n        self._testRedirectDefault(301)\n\n\n    def test_redirect302(self):\n        \"\"\"\n        L{client.RedirectAgent} follows redirects on status code 302.\n        \"\"\"\n        self._testRedirectDefault(302)\n\n\n    def test_redirect307(self):\n        \"\"\"\n        L{client.RedirectAgent} follows redirects on status code 307.\n        \"\"\"\n        self._testRedirectDefault(307)\n\n\n    def _testRedirectToGet(self, code, method):\n        \"\"\"\n        L{client.RedirectAgent} changes the method to I{GET} when getting\n        a redirect on a non-I{GET} request.\n\n        @param code: HTTP status code.\n\n        @param method: HTTP request method.\n        \"\"\"\n        self.agent.request(method, b'http://example.com/foo')\n\n        req, res = self.protocol.requests.pop()\n\n        headers = http_headers.Headers(\n            {b'location': [b'http://example.com/bar']})\n        response = Response((b'HTTP', 1, 1), code, b'OK', headers, None)\n        res.callback(response)\n\n        req2, res2 = self.protocol.requests.pop()\n        self.assertEqual(b'GET', req2.method)\n        self.assertEqual(b'/bar', req2.uri)\n\n\n    def test_redirect303(self):\n        \"\"\"\n        L{client.RedirectAgent} changes the method to I{GET} when getting a 303\n        redirect on a I{POST} request.\n        \"\"\"\n        self._testRedirectToGet(303, b'POST')\n\n\n    def test_noLocationField(self):\n        \"\"\"\n        If no L{Location} header field is found when getting a redirect,\n        L{client.RedirectAgent} fails with a L{ResponseFailed} error wrapping a\n        L{error.RedirectWithNoLocation} exception.\n        \"\"\"\n        deferred = self.agent.request(b'GET', b'http://example.com/foo')\n\n        req, res = self.protocol.requests.pop()\n\n        headers = http_headers.Headers()\n        response = Response((b'HTTP', 1, 1), 301, b'OK', headers, None)\n        res.callback(response)\n\n        fail = self.failureResultOf(deferred, client.ResponseFailed)\n        fail.value.reasons[0].trap(error.RedirectWithNoLocation)\n        self.assertEqual(b'http://example.com/foo',\n                         fail.value.reasons[0].value.uri)\n        self.assertEqual(301, fail.value.response.code)\n\n\n    def _testPageRedirectFailure(self, code, method):\n        \"\"\"\n        When getting a redirect on an unsupported request method,\n        L{client.RedirectAgent} fails with a L{ResponseFailed} error wrapping\n        a L{error.PageRedirect} exception.\n\n        @param code: HTTP status code.\n\n        @param method: HTTP request method.\n        \"\"\"\n        deferred = self.agent.request(method, b'http://example.com/foo')\n\n        req, res = self.protocol.requests.pop()\n\n        headers = http_headers.Headers()\n        response = Response((b'HTTP', 1, 1), code, b'OK', headers, None)\n        res.callback(response)\n\n        fail = self.failureResultOf(deferred, client.ResponseFailed)\n        fail.value.reasons[0].trap(error.PageRedirect)\n        self.assertEqual(b'http://example.com/foo',\n                         fail.value.reasons[0].value.location)\n        self.assertEqual(code, fail.value.response.code)\n\n\n    def test_307OnPost(self):\n        \"\"\"\n        When getting a 307 redirect on a I{POST} request,\n        L{client.RedirectAgent} fails with a L{ResponseFailed} error wrapping\n        a L{error.PageRedirect} exception.\n        \"\"\"\n        self._testPageRedirectFailure(307, b'POST')\n\n\n    def test_redirectLimit(self):\n        \"\"\"\n        If the limit of redirects specified to L{client.RedirectAgent} is\n        reached, the deferred fires with L{ResponseFailed} error wrapping\n        a L{InfiniteRedirection} exception.\n        \"\"\"\n        agent = self.buildAgentForWrapperTest(self.reactor)\n        redirectAgent = client.RedirectAgent(agent, 1)\n\n        deferred = redirectAgent.request(b'GET', b'http://example.com/foo')\n\n        req, res = self.protocol.requests.pop()\n\n        headers = http_headers.Headers(\n            {b'location': [b'http://example.com/bar']})\n        response = Response((b'HTTP', 1, 1), 302, b'OK', headers, None)\n        res.callback(response)\n\n        req2, res2 = self.protocol.requests.pop()\n\n        response2 = Response((b'HTTP', 1, 1), 302, b'OK', headers, None)\n        res2.callback(response2)\n\n        fail = self.failureResultOf(deferred, client.ResponseFailed)\n\n        fail.value.reasons[0].trap(error.InfiniteRedirection)\n        self.assertEqual(b'http://example.com/foo',\n                         fail.value.reasons[0].value.location)\n        self.assertEqual(302, fail.value.response.code)\n\n\n    def _testRedirectURI(self, uri, location, finalURI):\n        \"\"\"\n        When L{client.RedirectAgent} encounters a relative redirect I{URI}, it\n        is resolved against the request I{URI} before following the redirect.\n\n        @param uri: Request URI.\n\n        @param location: I{Location} header redirect URI.\n\n        @param finalURI: Expected final URI.\n        \"\"\"\n        self.agent.request(b'GET', uri)\n\n        req, res = self.protocol.requests.pop()\n\n        headers = http_headers.Headers(\n            {b'location': [location]})\n        response = Response((b'HTTP', 1, 1), 302, b'OK', headers, None)\n        res.callback(response)\n\n        req2, res2 = self.protocol.requests.pop()\n        self.assertEqual(b'GET', req2.method)\n        self.assertEqual(finalURI, req2.absoluteURI)\n\n\n    def test_relativeURI(self):\n        \"\"\"\n        L{client.RedirectAgent} resolves and follows relative I{URI}s in\n        redirects, preserving query strings.\n        \"\"\"\n        self._testRedirectURI(\n            b'http://example.com/foo/bar', b'baz',\n            b'http://example.com/foo/baz')\n        self._testRedirectURI(\n            b'http://example.com/foo/bar', b'/baz',\n            b'http://example.com/baz')\n        self._testRedirectURI(\n            b'http://example.com/foo/bar', b'/baz?a',\n            b'http://example.com/baz?a')\n\n\n    def test_relativeURIPreserveFragments(self):\n        \"\"\"\n        L{client.RedirectAgent} resolves and follows relative I{URI}s in\n        redirects, preserving fragments in way that complies with the HTTP 1.1\n        bis draft.\n\n        @see: U{https://tools.ietf.org/html/draft-ietf-httpbis-p2-semantics-22#section-7.1.2}\n        \"\"\"\n        self._testRedirectURI(\n            b'http://example.com/foo/bar#frag', b'/baz?a',\n            b'http://example.com/baz?a#frag')\n        self._testRedirectURI(\n            b'http://example.com/foo/bar', b'/baz?a#frag2',\n            b'http://example.com/baz?a#frag2')\n\n\n    def test_relativeURISchemeRelative(self):\n        \"\"\"\n        L{client.RedirectAgent} resolves and follows scheme relative I{URI}s in\n        redirects, replacing the hostname and port when required.\n        \"\"\"\n        self._testRedirectURI(\n            b'http://example.com/foo/bar', b'//foo.com/baz',\n            b'http://foo.com/baz')\n        self._testRedirectURI(\n            b'http://example.com/foo/bar', b'//foo.com:81/baz',\n            b'http://foo.com:81/baz')\n\n\n    def test_responseHistory(self):\n        \"\"\"\n        L{Response.response} references the previous L{Response} from\n        a redirect, or L{None} if there was no previous response.\n        \"\"\"\n        agent = self.buildAgentForWrapperTest(self.reactor)\n        redirectAgent = client.RedirectAgent(agent)\n\n        deferred = redirectAgent.request(b'GET', b'http://example.com/foo')\n\n        redirectReq, redirectRes = self.protocol.requests.pop()\n\n        headers = http_headers.Headers(\n            {b'location': [b'http://example.com/bar']})\n        redirectResponse = Response((b'HTTP', 1, 1), 302, b'OK', headers, None)\n        redirectRes.callback(redirectResponse)\n\n        req, res = self.protocol.requests.pop()\n\n        response = Response((b'HTTP', 1, 1), 200, b'OK', headers, None)\n        res.callback(response)\n\n        finalResponse = self.successResultOf(deferred)\n        self.assertIdentical(finalResponse.previousResponse, redirectResponse)\n        self.assertIdentical(redirectResponse.previousResponse, None)\n\n\n\nclass RedirectAgentTests(TestCase, FakeReactorAndConnectMixin,\n                         _RedirectAgentTestsMixin, AgentTestsMixin):\n    \"\"\"\n    Tests for L{client.RedirectAgent}.\n    \"\"\"\n    def makeAgent(self):\n        \"\"\"\n        @return: a new L{twisted.web.client.RedirectAgent}\n        \"\"\"\n        return client.RedirectAgent(\n            self.buildAgentForWrapperTest(self.reactor))\n\n\n    def setUp(self):\n        self.reactor = self.createReactor()\n        self.agent = self.makeAgent()\n\n\n    def test_301OnPost(self):\n        \"\"\"\n        When getting a 301 redirect on a I{POST} request,\n        L{client.RedirectAgent} fails with a L{ResponseFailed} error wrapping\n        a L{error.PageRedirect} exception.\n        \"\"\"\n        self._testPageRedirectFailure(301, b'POST')\n\n\n    def test_302OnPost(self):\n        \"\"\"\n        When getting a 302 redirect on a I{POST} request,\n        L{client.RedirectAgent} fails with a L{ResponseFailed} error wrapping\n        a L{error.PageRedirect} exception.\n        \"\"\"\n        self._testPageRedirectFailure(302, b'POST')\n\n\n\nclass BrowserLikeRedirectAgentTests(TestCase,\n                                    FakeReactorAndConnectMixin,\n                                    _RedirectAgentTestsMixin,\n                                    AgentTestsMixin):\n    \"\"\"\n    Tests for L{client.BrowserLikeRedirectAgent}.\n    \"\"\"\n    def makeAgent(self):\n        \"\"\"\n        @return: a new L{twisted.web.client.BrowserLikeRedirectAgent}\n        \"\"\"\n        return client.BrowserLikeRedirectAgent(\n            self.buildAgentForWrapperTest(self.reactor))\n\n\n    def setUp(self):\n        self.reactor = self.createReactor()\n        self.agent = self.makeAgent()\n\n\n    def test_redirectToGet301(self):\n        \"\"\"\n        L{client.BrowserLikeRedirectAgent} changes the method to I{GET} when\n        getting a 302 redirect on a I{POST} request.\n        \"\"\"\n        self._testRedirectToGet(301, b'POST')\n\n\n    def test_redirectToGet302(self):\n        \"\"\"\n        L{client.BrowserLikeRedirectAgent} changes the method to I{GET} when\n        getting a 302 redirect on a I{POST} request.\n        \"\"\"\n        self._testRedirectToGet(302, b'POST')\n\n\n\nclass AbortableStringTransport(StringTransport):\n    \"\"\"\n    A version of L{StringTransport} that supports C{abortConnection}.\n    \"\"\"\n    # This should be replaced by a common version in #6530.\n    aborting = False\n\n\n    def abortConnection(self):\n        \"\"\"\n        A testable version of the C{ITCPTransport.abortConnection} method.\n\n        Since this is a special case of closing the connection,\n        C{loseConnection} is also called.\n        \"\"\"\n        self.aborting = True\n        self.loseConnection()\n\n\n\nclass DummyResponse(object):\n    \"\"\"\n    Fake L{IResponse} for testing readBody that captures the protocol passed to\n    deliverBody and uses it to make a connection with a transport.\n\n    @ivar protocol: After C{deliverBody} is called, the protocol it was called\n        with.\n\n    @ivar transport: An instance created by calling C{transportFactory} which\n        is used by L{DummyResponse.protocol} to make a connection.\n    \"\"\"\n\n    code = 200\n    phrase = b\"OK\"\n\n    def __init__(self, headers=None, transportFactory=AbortableStringTransport):\n        \"\"\"\n        @param headers: The headers for this response.  If L{None}, an empty\n            L{Headers} instance will be used.\n        @type headers: L{Headers}\n\n        @param transportFactory: A callable used to construct the transport.\n        \"\"\"\n        if headers is None:\n            headers = Headers()\n        self.headers = headers\n        self.transport = transportFactory()\n\n\n    def deliverBody(self, protocol):\n        \"\"\"\n        Record the given protocol and use it to make a connection with\n        L{DummyResponse.transport}.\n        \"\"\"\n        self.protocol = protocol\n        self.protocol.makeConnection(self.transport)\n\n\n\nclass AlreadyCompletedDummyResponse(DummyResponse):\n    \"\"\"\n    A dummy response that has already had its transport closed.\n    \"\"\"\n    def deliverBody(self, protocol):\n        \"\"\"\n        Make the connection, then remove the transport.\n        \"\"\"\n        self.protocol = protocol\n        self.protocol.makeConnection(self.transport)\n        self.protocol.transport = None\n\n\n\nclass ReadBodyTests(TestCase):\n    \"\"\"\n    Tests for L{client.readBody}\n    \"\"\"\n    def test_success(self):\n        \"\"\"\n        L{client.readBody} returns a L{Deferred} which fires with the complete\n        body of the L{IResponse} provider passed to it.\n        \"\"\"\n        response = DummyResponse()\n        d = client.readBody(response)\n        response.protocol.dataReceived(b\"first\")\n        response.protocol.dataReceived(b\"second\")\n        response.protocol.connectionLost(Failure(ResponseDone()))\n        self.assertEqual(self.successResultOf(d), b\"firstsecond\")\n\n\n    def test_cancel(self):\n        \"\"\"\n        When cancelling the L{Deferred} returned by L{client.readBody}, the\n        connection to the server will be aborted.\n        \"\"\"\n        response = DummyResponse()\n        deferred = client.readBody(response)\n        deferred.cancel()\n        self.failureResultOf(deferred, defer.CancelledError)\n        self.assertTrue(response.transport.aborting)\n\n\n    def test_withPotentialDataLoss(self):\n        \"\"\"\n        If the full body of the L{IResponse} passed to L{client.readBody} is\n        not definitely received, the L{Deferred} returned by L{client.readBody}\n        fires with a L{Failure} wrapping L{client.PartialDownloadError} with\n        the content that was received.\n        \"\"\"\n        response = DummyResponse()\n        d = client.readBody(response)\n        response.protocol.dataReceived(b\"first\")\n        response.protocol.dataReceived(b\"second\")\n        response.protocol.connectionLost(Failure(PotentialDataLoss()))\n        failure = self.failureResultOf(d)\n        failure.trap(client.PartialDownloadError)\n        self.assertEqual({\n            \"status\": failure.value.status,\n            \"message\": failure.value.message,\n            \"body\": failure.value.response,\n        }, {\n            \"status\": b\"200\",\n            \"message\": b\"OK\",\n            \"body\": b\"firstsecond\",\n        })\n\n\n    def test_otherErrors(self):\n        \"\"\"\n        If there is an exception other than L{client.PotentialDataLoss} while\n        L{client.readBody} is collecting the response body, the L{Deferred}\n        returned by {client.readBody} fires with that exception.\n        \"\"\"\n        response = DummyResponse()\n        d = client.readBody(response)\n        response.protocol.dataReceived(b\"first\")\n        response.protocol.connectionLost(\n            Failure(ConnectionLost(\"mystery problem\")))\n        reason = self.failureResultOf(d)\n        reason.trap(ConnectionLost)\n        self.assertEqual(reason.value.args, (\"mystery problem\",))\n\n\n    def test_deprecatedTransport(self):\n        \"\"\"\n        Calling L{client.readBody} with a transport that does not implement\n        L{twisted.internet.interfaces.ITCPTransport} produces a deprecation\n        warning, but no exception when cancelling.\n        \"\"\"\n        response = DummyResponse(transportFactory=StringTransport)\n        response.transport.abortConnection = None\n        d = self.assertWarns(\n            DeprecationWarning,\n            'Using readBody with a transport that does not have an '\n            'abortConnection method',\n            __file__,\n            lambda: client.readBody(response))\n        d.cancel()\n        self.failureResultOf(d, defer.CancelledError)\n\n\n    def test_deprecatedTransportNoWarning(self):\n        \"\"\"\n        Calling L{client.readBody} with a response that has already had its\n        transport closed (eg. for a very small request) will not trigger a\n        deprecation warning.\n        \"\"\"\n        response = AlreadyCompletedDummyResponse()\n        client.readBody(response)\n\n        warnings = self.flushWarnings()\n        self.assertEqual(len(warnings), 0)\n\n\n\nclass HostnameCachingHTTPSPolicyTests(TestCase):\n\n    skip = skipWhenNoSSL\n\n    def test_cacheIsUsed(self):\n        \"\"\"\n        Verify that the connection creator is added to the\n        policy's cache, and that it is reused on subsequent calls\n        to creatorForNetLoc.\n\n        \"\"\"\n        trustRoot = CustomOpenSSLTrustRoot()\n        wrappedPolicy = BrowserLikePolicyForHTTPS(trustRoot=trustRoot)\n        policy = HostnameCachingHTTPSPolicy(wrappedPolicy)\n        creator = policy.creatorForNetloc(b\"foo\", 1589)\n        self.assertTrue(trustRoot.called)\n        trustRoot.called = False\n        self.assertEquals(1, len(policy._cache))\n        connection = creator.clientConnectionForTLS(None)\n        self.assertIs(trustRoot.context, connection.get_context())\n\n        policy.creatorForNetloc(b\"foo\", 1589)\n        self.assertFalse(trustRoot.called)\n\n\n    def test_cacheRemovesOldest(self):\n        \"\"\"\n        Verify that when the cache is full, and a new entry is added,\n        the oldest entry is removed.\n        \"\"\"\n        trustRoot = CustomOpenSSLTrustRoot()\n        wrappedPolicy = BrowserLikePolicyForHTTPS(trustRoot=trustRoot)\n        policy = HostnameCachingHTTPSPolicy(wrappedPolicy)\n        for i in range(0, 20):\n            hostname = u\"host\" + unicode(i)\n            policy.creatorForNetloc(hostname.encode(\"ascii\"), 8675)\n\n        # Force host0, which was the first, to be the most recently used\n        host0 = u\"host0\"\n        policy.creatorForNetloc(host0.encode(\"ascii\"), 309)\n        self.assertIn(host0, policy._cache)\n        self.assertEquals(20, len(policy._cache))\n\n        hostn = u\"new\"\n        policy.creatorForNetloc(hostn.encode(\"ascii\"), 309)\n\n        host1 = u\"host1\"\n        self.assertNotIn(host1, policy._cache)\n        self.assertEquals(20, len(policy._cache))\n\n        self.assertIn(hostn, policy._cache)\n        self.assertIn(host0, policy._cache)\n\n        # Accessing an item repeatedly does not corrupt the LRU.\n        for _ in range(20):\n            policy.creatorForNetloc(host0.encode(\"ascii\"), 8675)\n\n        hostNPlus1 = u\"new1\"\n\n        policy.creatorForNetloc(hostNPlus1.encode(\"ascii\"), 800)\n\n        self.assertNotIn(u\"host2\", policy._cache)\n        self.assertEquals(20, len(policy._cache))\n\n        self.assertIn(hostNPlus1, policy._cache)\n        self.assertIn(hostn, policy._cache)\n        self.assertIn(host0, policy._cache)\n\n\n    def test_changeCacheSize(self):\n        \"\"\"\n        Verify that changing the cache size results in a policy that\n        respects the new cache size and not the default.\n\n        \"\"\"\n        trustRoot = CustomOpenSSLTrustRoot()\n        wrappedPolicy = BrowserLikePolicyForHTTPS(trustRoot=trustRoot)\n        policy = HostnameCachingHTTPSPolicy(wrappedPolicy, cacheSize=5)\n        for i in range(0, 5):\n            hostname = u\"host\" + unicode(i)\n            policy.creatorForNetloc(hostname.encode(\"ascii\"), 8675)\n\n        first = u\"host0\"\n        self.assertIn(first, policy._cache)\n        self.assertEquals(5, len(policy._cache))\n\n        hostn = u\"new\"\n        policy.creatorForNetloc(hostn.encode(\"ascii\"), 309)\n        self.assertNotIn(first, policy._cache)\n        self.assertEquals(5, len(policy._cache))\n\n        self.assertIn(hostn, policy._cache)\n\n\n\nclass RequestMethodInjectionTests(\n        MethodInjectionTestsMixin,\n        SynchronousTestCase,\n):\n    \"\"\"\n    Test L{client.Request} against HTTP method injections.\n    \"\"\"\n\n    def attemptRequestWithMaliciousMethod(self, method):\n        \"\"\"\n        Attempt a request with the provided method.\n\n        @param method: see L{MethodInjectionTestsMixin}\n        \"\"\"\n        client.Request(\n            method=method,\n            uri=b\"http://twisted.invalid\",\n            headers=http_headers.Headers(),\n            bodyProducer=None,\n        )\n\n\n\nclass RequestWriteToMethodInjectionTests(\n        MethodInjectionTestsMixin,\n        SynchronousTestCase,\n):\n    \"\"\"\n    Test L{client.Request.writeTo} against HTTP method injections.\n    \"\"\"\n\n    def attemptRequestWithMaliciousMethod(self, method):\n        \"\"\"\n        Attempt a request with the provided method.\n\n        @param method: see L{MethodInjectionTestsMixin}\n        \"\"\"\n        headers = http_headers.Headers({b\"Host\": [b\"twisted.invalid\"]})\n        req = client.Request(\n            method=b\"GET\",\n            uri=b\"http://twisted.invalid\",\n            headers=headers,\n            bodyProducer=None,\n        )\n        req.method = method\n        req.writeTo(StringTransport())\n\n\n\nclass RequestURIInjectionTests(\n        URIInjectionTestsMixin,\n        SynchronousTestCase,\n):\n    \"\"\"\n    Test L{client.Request} against HTTP URI injections.\n    \"\"\"\n\n    def attemptRequestWithMaliciousURI(self, uri):\n        \"\"\"\n        Attempt a request with the provided URI.\n\n        @param method: see L{URIInjectionTestsMixin}\n        \"\"\"\n        client.Request(\n            method=b\"GET\",\n            uri=uri,\n            headers=http_headers.Headers(),\n            bodyProducer=None,\n        )\n\n\n\nclass RequestWriteToURIInjectionTests(\n        URIInjectionTestsMixin,\n        SynchronousTestCase,\n):\n    \"\"\"\n    Test L{client.Request.writeTo} against HTTP method injections.\n    \"\"\"\n\n    def attemptRequestWithMaliciousURI(self, uri):\n        \"\"\"\n        Attempt a request with the provided method.\n\n        @param method: see L{URIInjectionTestsMixin}\n        \"\"\"\n        headers = http_headers.Headers({b\"Host\": [b\"twisted.invalid\"]})\n        req = client.Request(\n            method=b\"GET\",\n            uri=b\"http://twisted.invalid\",\n            headers=headers,\n            bodyProducer=None,\n        )\n        req.uri = uri\n        req.writeTo(StringTransport())\n", "code_before": "# Copyright (c) Twisted Matrix Laboratories.\n# See LICENSE for details.\n\n\"\"\"\nTests for L{twisted.web.client.Agent} and related new client APIs.\n\"\"\"\n\nimport zlib\n\nfrom io import BytesIO\n\nfrom zope.interface.verify import verifyObject\n\nfrom twisted.trial.unittest import TestCase\nfrom twisted.web import client, error, http_headers\nfrom twisted.web._newclient import RequestNotSent, RequestTransmissionFailed\nfrom twisted.web._newclient import ResponseNeverReceived, ResponseFailed\nfrom twisted.web._newclient import PotentialDataLoss\nfrom twisted.internet import defer, task\nfrom twisted.python.failure import Failure\nfrom twisted.python.compat import cookielib, intToBytes, unicode\nfrom twisted.python.components import proxyForInterface\nfrom twisted.test.proto_helpers import (StringTransport, MemoryReactorClock,\n                                        EventLoggingObserver)\nfrom twisted.internet.task import Clock\nfrom twisted.internet.error import ConnectionRefusedError, ConnectionDone\nfrom twisted.internet.error import ConnectionLost\nfrom twisted.internet.protocol import Protocol, Factory\nfrom twisted.internet.defer import Deferred, succeed, CancelledError\nfrom twisted.internet.endpoints import TCP4ClientEndpoint\nfrom twisted.internet.address import IPv4Address, IPv6Address\n\nfrom twisted.web.client import (FileBodyProducer, Request, HTTPConnectionPool,\n                                ResponseDone, _HTTP11ClientFactory, URI)\n\nfrom twisted.web.iweb import (\n    UNKNOWN_LENGTH, IAgent, IBodyProducer, IResponse, IAgentEndpointFactory,\n    )\nfrom twisted.web.http_headers import Headers\nfrom twisted.web._newclient import HTTP11ClientProtocol, Response\n\nfrom twisted.internet.interfaces import IOpenSSLClientConnectionCreator\nfrom zope.interface.declarations import implementer\nfrom twisted.web.iweb import IPolicyForHTTPS\nfrom twisted.python.deprecate import getDeprecationWarningString\nfrom incremental import Version\nfrom twisted.web.client import (BrowserLikePolicyForHTTPS,\n                                HostnameCachingHTTPSPolicy)\nfrom twisted.internet.test.test_endpoints import deterministicResolvingReactor\nfrom twisted.internet.endpoints import HostnameEndpoint\nfrom twisted.test.proto_helpers import AccumulatingProtocol\nfrom twisted.test.iosim import IOPump, FakeTransport\nfrom twisted.test.test_sslverify import certificatesForAuthorityAndServer\nfrom twisted.web.error import SchemeNotSupported\nfrom twisted.logger import globalLogPublisher\n\ntry:\n    from twisted.internet import ssl\nexcept ImportError:\n    ssl = None\n    skipWhenNoSSL = \"SSL not present, cannot run SSL tests.\"\n    skipWhenSSLPresent = None\nelse:\n    skipWhenSSLPresent = \"SSL present.\"\n    skipWhenNoSSL = None\n    from twisted.internet._sslverify import ClientTLSOptions, IOpenSSLTrustRoot\n    from twisted.internet.ssl import optionsForClientTLS\n    from twisted.protocols.tls import TLSMemoryBIOProtocol, TLSMemoryBIOFactory\n\n\n    @implementer(IOpenSSLTrustRoot)\n    class CustomOpenSSLTrustRoot(object):\n        called = False\n        context = None\n\n        def _addCACertsToContext(self, context):\n            self.called = True\n            self.context = context\n\n\n\nclass StubHTTPProtocol(Protocol):\n    \"\"\"\n    A protocol like L{HTTP11ClientProtocol} but which does not actually know\n    HTTP/1.1 and only collects requests in a list.\n\n    @ivar requests: A C{list} of two-tuples.  Each time a request is made, a\n        tuple consisting of the request and the L{Deferred} returned from the\n        request method is appended to this list.\n    \"\"\"\n    def __init__(self):\n        self.requests = []\n        self.state = 'QUIESCENT'\n\n\n    def request(self, request):\n        \"\"\"\n        Capture the given request for later inspection.\n\n        @return: A L{Deferred} which this code will never fire.\n        \"\"\"\n        result = Deferred()\n        self.requests.append((request, result))\n        return result\n\n\n\nclass FileConsumer(object):\n    def __init__(self, outputFile):\n        self.outputFile = outputFile\n\n\n    def write(self, bytes):\n        self.outputFile.write(bytes)\n\n\n\nclass FileBodyProducerTests(TestCase):\n    \"\"\"\n    Tests for the L{FileBodyProducer} which reads bytes from a file and writes\n    them to an L{IConsumer}.\n    \"\"\"\n    def _termination(self):\n        \"\"\"\n        This method can be used as the C{terminationPredicateFactory} for a\n        L{Cooperator}.  It returns a predicate which immediately returns\n        C{False}, indicating that no more work should be done this iteration.\n        This has the result of only allowing one iteration of a cooperative\n        task to be run per L{Cooperator} iteration.\n        \"\"\"\n        return lambda: True\n\n\n    def setUp(self):\n        \"\"\"\n        Create a L{Cooperator} hooked up to an easily controlled, deterministic\n        scheduler to use with L{FileBodyProducer}.\n        \"\"\"\n        self._scheduled = []\n        self.cooperator = task.Cooperator(\n            self._termination, self._scheduled.append)\n\n\n    def test_interface(self):\n        \"\"\"\n        L{FileBodyProducer} instances provide L{IBodyProducer}.\n        \"\"\"\n        self.assertTrue(verifyObject(\n                IBodyProducer, FileBodyProducer(BytesIO(b\"\"))))\n\n\n    def test_unknownLength(self):\n        \"\"\"\n        If the L{FileBodyProducer} is constructed with a file-like object\n        without either a C{seek} or C{tell} method, its C{length} attribute is\n        set to C{UNKNOWN_LENGTH}.\n        \"\"\"\n        class HasSeek(object):\n            def seek(self, offset, whence):\n                pass\n\n        class HasTell(object):\n            def tell(self):\n                pass\n\n        producer = FileBodyProducer(HasSeek())\n        self.assertEqual(UNKNOWN_LENGTH, producer.length)\n        producer = FileBodyProducer(HasTell())\n        self.assertEqual(UNKNOWN_LENGTH, producer.length)\n\n\n    def test_knownLength(self):\n        \"\"\"\n        If the L{FileBodyProducer} is constructed with a file-like object with\n        both C{seek} and C{tell} methods, its C{length} attribute is set to the\n        size of the file as determined by those methods.\n        \"\"\"\n        inputBytes = b\"here are some bytes\"\n        inputFile = BytesIO(inputBytes)\n        inputFile.seek(5)\n        producer = FileBodyProducer(inputFile)\n        self.assertEqual(len(inputBytes) - 5, producer.length)\n        self.assertEqual(inputFile.tell(), 5)\n\n\n    def test_defaultCooperator(self):\n        \"\"\"\n        If no L{Cooperator} instance is passed to L{FileBodyProducer}, the\n        global cooperator is used.\n        \"\"\"\n        producer = FileBodyProducer(BytesIO(b\"\"))\n        self.assertEqual(task.cooperate, producer._cooperate)\n\n\n    def test_startProducing(self):\n        \"\"\"\n        L{FileBodyProducer.startProducing} starts writing bytes from the input\n        file to the given L{IConsumer} and returns a L{Deferred} which fires\n        when they have all been written.\n        \"\"\"\n        expectedResult = b\"hello, world\"\n        readSize = 3\n        output = BytesIO()\n        consumer = FileConsumer(output)\n        producer = FileBodyProducer(\n            BytesIO(expectedResult), self.cooperator, readSize)\n        complete = producer.startProducing(consumer)\n        for i in range(len(expectedResult) // readSize + 1):\n            self._scheduled.pop(0)()\n        self.assertEqual([], self._scheduled)\n        self.assertEqual(expectedResult, output.getvalue())\n        self.assertEqual(None, self.successResultOf(complete))\n\n\n    def test_inputClosedAtEOF(self):\n        \"\"\"\n        When L{FileBodyProducer} reaches end-of-file on the input file given to\n        it, the input file is closed.\n        \"\"\"\n        readSize = 4\n        inputBytes = b\"some friendly bytes\"\n        inputFile = BytesIO(inputBytes)\n        producer = FileBodyProducer(inputFile, self.cooperator, readSize)\n        consumer = FileConsumer(BytesIO())\n        producer.startProducing(consumer)\n        for i in range(len(inputBytes) // readSize + 2):\n            self._scheduled.pop(0)()\n        self.assertTrue(inputFile.closed)\n\n\n    def test_failedReadWhileProducing(self):\n        \"\"\"\n        If a read from the input file fails while producing bytes to the\n        consumer, the L{Deferred} returned by\n        L{FileBodyProducer.startProducing} fires with a L{Failure} wrapping\n        that exception.\n        \"\"\"\n        class BrokenFile(object):\n            def read(self, count):\n                raise IOError(\"Simulated bad thing\")\n        producer = FileBodyProducer(BrokenFile(), self.cooperator)\n        complete = producer.startProducing(FileConsumer(BytesIO()))\n        self._scheduled.pop(0)()\n        self.failureResultOf(complete).trap(IOError)\n\n\n    def test_stopProducing(self):\n        \"\"\"\n        L{FileBodyProducer.stopProducing} stops the underlying L{IPullProducer}\n        and the cooperative task responsible for calling C{resumeProducing} and\n        closes the input file but does not cause the L{Deferred} returned by\n        C{startProducing} to fire.\n        \"\"\"\n        expectedResult = b\"hello, world\"\n        readSize = 3\n        output = BytesIO()\n        consumer = FileConsumer(output)\n        inputFile = BytesIO(expectedResult)\n        producer = FileBodyProducer(\n            inputFile, self.cooperator, readSize)\n        complete = producer.startProducing(consumer)\n        producer.stopProducing()\n        self.assertTrue(inputFile.closed)\n        self._scheduled.pop(0)()\n        self.assertEqual(b\"\", output.getvalue())\n        self.assertNoResult(complete)\n\n\n    def test_pauseProducing(self):\n        \"\"\"\n        L{FileBodyProducer.pauseProducing} temporarily suspends writing bytes\n        from the input file to the given L{IConsumer}.\n        \"\"\"\n        expectedResult = b\"hello, world\"\n        readSize = 5\n        output = BytesIO()\n        consumer = FileConsumer(output)\n        producer = FileBodyProducer(\n            BytesIO(expectedResult), self.cooperator, readSize)\n        complete = producer.startProducing(consumer)\n        self._scheduled.pop(0)()\n        self.assertEqual(output.getvalue(), expectedResult[:5])\n        producer.pauseProducing()\n\n        # Sort of depends on an implementation detail of Cooperator: even\n        # though the only task is paused, there's still a scheduled call.  If\n        # this were to go away because Cooperator became smart enough to cancel\n        # this call in this case, that would be fine.\n        self._scheduled.pop(0)()\n\n        # Since the producer is paused, no new data should be here.\n        self.assertEqual(output.getvalue(), expectedResult[:5])\n        self.assertEqual([], self._scheduled)\n        self.assertNoResult(complete)\n\n\n    def test_resumeProducing(self):\n        \"\"\"\n        L{FileBodyProducer.resumeProducing} re-commences writing bytes from the\n        input file to the given L{IConsumer} after it was previously paused\n        with L{FileBodyProducer.pauseProducing}.\n        \"\"\"\n        expectedResult = b\"hello, world\"\n        readSize = 5\n        output = BytesIO()\n        consumer = FileConsumer(output)\n        producer = FileBodyProducer(\n            BytesIO(expectedResult), self.cooperator, readSize)\n        producer.startProducing(consumer)\n        self._scheduled.pop(0)()\n        self.assertEqual(expectedResult[:readSize], output.getvalue())\n        producer.pauseProducing()\n        producer.resumeProducing()\n        self._scheduled.pop(0)()\n        self.assertEqual(expectedResult[:readSize * 2], output.getvalue())\n\nEXAMPLE_COM_IP = '127.0.0.7'\nEXAMPLE_COM_V6_IP = '::7'\nEXAMPLE_NET_IP = '127.0.0.8'\nEXAMPLE_ORG_IP = '127.0.0.9'\nFOO_LOCAL_IP = '127.0.0.10'\nFOO_COM_IP = '127.0.0.11'\n\nclass FakeReactorAndConnectMixin:\n    \"\"\"\n    A test mixin providing a testable C{Reactor} class and a dummy C{connect}\n    method which allows instances to pretend to be endpoints.\n    \"\"\"\n    def createReactor(self):\n        \"\"\"\n        Create a L{MemoryReactorClock} and give it some hostnames it can\n        resolve.\n\n        @return: a L{MemoryReactorClock}-like object with a slightly limited\n            interface (only C{advance} and C{tcpClients} in addition to its\n            formally-declared reactor interfaces), which can resolve a fixed\n            set of domains.\n        \"\"\"\n        mrc = MemoryReactorClock()\n        drr = deterministicResolvingReactor(mrc, hostMap={\n            u'example.com': [EXAMPLE_COM_IP],\n            u'ipv6.example.com': [EXAMPLE_COM_V6_IP],\n            u'example.net': [EXAMPLE_NET_IP],\n            u'example.org': [EXAMPLE_ORG_IP],\n            u'foo': [FOO_LOCAL_IP],\n            u'foo.com': [FOO_COM_IP],\n            u'127.0.0.7': ['127.0.0.7'],\n            u'::7': ['::7'],\n        })\n\n        # Lots of tests were written expecting MemoryReactorClock and the\n        # reactor seen by the SUT to be the same object.\n        drr.tcpClients = mrc.tcpClients\n        drr.advance = mrc.advance\n        return drr\n\n    class StubEndpoint(object):\n        \"\"\"\n        Endpoint that wraps existing endpoint, substitutes StubHTTPProtocol, and\n        resulting protocol instances are attached to the given test case.\n        \"\"\"\n\n        def __init__(self, endpoint, testCase):\n            self.endpoint = endpoint\n            self.testCase = testCase\n            def nothing():\n                \"\"\"this function does nothing\"\"\"\n            self.factory = _HTTP11ClientFactory(nothing,\n                                                repr(self.endpoint))\n            self.protocol = StubHTTPProtocol()\n            self.factory.buildProtocol = lambda addr: self.protocol\n\n        def connect(self, ignoredFactory):\n            self.testCase.protocol = self.protocol\n            self.endpoint.connect(self.factory)\n            return succeed(self.protocol)\n\n\n    def buildAgentForWrapperTest(self, reactor):\n        \"\"\"\n        Return an Agent suitable for use in tests that wrap the Agent and want\n        both a fake reactor and StubHTTPProtocol.\n        \"\"\"\n        agent = client.Agent(reactor)\n        _oldGetEndpoint = agent._getEndpoint\n        agent._getEndpoint = lambda *args: (\n            self.StubEndpoint(_oldGetEndpoint(*args), self))\n        return agent\n\n\n    def connect(self, factory):\n        \"\"\"\n        Fake implementation of an endpoint which synchronously\n        succeeds with an instance of L{StubHTTPProtocol} for ease of\n        testing.\n        \"\"\"\n        protocol = StubHTTPProtocol()\n        protocol.makeConnection(None)\n        self.protocol = protocol\n        return succeed(protocol)\n\n\n\nclass DummyEndpoint(object):\n    \"\"\"\n    An endpoint that uses a fake transport.\n    \"\"\"\n\n    def connect(self, factory):\n        protocol = factory.buildProtocol(None)\n        protocol.makeConnection(StringTransport())\n        return succeed(protocol)\n\n\n\nclass BadEndpoint(object):\n    \"\"\"\n    An endpoint that shouldn't be called.\n    \"\"\"\n\n    def connect(self, factory):\n        raise RuntimeError(\"This endpoint should not have been used.\")\n\n\nclass DummyFactory(Factory):\n    \"\"\"\n    Create C{StubHTTPProtocol} instances.\n    \"\"\"\n    def __init__(self, quiescentCallback, metadata):\n        pass\n\n    protocol = StubHTTPProtocol\n\n\n\nclass HTTPConnectionPoolTests(TestCase, FakeReactorAndConnectMixin):\n    \"\"\"\n    Tests for the L{HTTPConnectionPool} class.\n    \"\"\"\n    def setUp(self):\n        self.fakeReactor = self.createReactor()\n        self.pool = HTTPConnectionPool(self.fakeReactor)\n        self.pool._factory = DummyFactory\n        # The retry code path is tested in HTTPConnectionPoolRetryTests:\n        self.pool.retryAutomatically = False\n\n\n    def test_getReturnsNewIfCacheEmpty(self):\n        \"\"\"\n        If there are no cached connections,\n        L{HTTPConnectionPool.getConnection} returns a new connection.\n        \"\"\"\n        self.assertEqual(self.pool._connections, {})\n\n        def gotConnection(conn):\n            self.assertIsInstance(conn, StubHTTPProtocol)\n            # The new connection is not stored in the pool:\n            self.assertNotIn(conn, self.pool._connections.values())\n\n        unknownKey = 12245\n        d = self.pool.getConnection(unknownKey, DummyEndpoint())\n        return d.addCallback(gotConnection)\n\n\n    def test_putStartsTimeout(self):\n        \"\"\"\n        If a connection is put back to the pool, a 240-sec timeout is started.\n\n        When the timeout hits, the connection is closed and removed from the\n        pool.\n        \"\"\"\n        # We start out with one cached connection:\n        protocol = StubHTTPProtocol()\n        protocol.makeConnection(StringTransport())\n        self.pool._putConnection((\"http\", b\"example.com\", 80), protocol)\n\n        # Connection is in pool, still not closed:\n        self.assertEqual(protocol.transport.disconnecting, False)\n        self.assertIn(protocol,\n                      self.pool._connections[(\"http\", b\"example.com\", 80)])\n\n        # Advance 239 seconds, still not closed:\n        self.fakeReactor.advance(239)\n        self.assertEqual(protocol.transport.disconnecting, False)\n        self.assertIn(protocol,\n                      self.pool._connections[(\"http\", b\"example.com\", 80)])\n        self.assertIn(protocol, self.pool._timeouts)\n\n        # Advance past 240 seconds, connection will be closed:\n        self.fakeReactor.advance(1.1)\n        self.assertEqual(protocol.transport.disconnecting, True)\n        self.assertNotIn(protocol,\n                         self.pool._connections[(\"http\", b\"example.com\", 80)])\n        self.assertNotIn(protocol, self.pool._timeouts)\n\n\n    def test_putExceedsMaxPersistent(self):\n        \"\"\"\n        If an idle connection is put back in the cache and the max number of\n        persistent connections has been exceeded, one of the connections is\n        closed and removed from the cache.\n        \"\"\"\n        pool = self.pool\n\n        # We start out with two cached connection, the max:\n        origCached = [StubHTTPProtocol(), StubHTTPProtocol()]\n        for p in origCached:\n            p.makeConnection(StringTransport())\n            pool._putConnection((\"http\", b\"example.com\", 80), p)\n        self.assertEqual(pool._connections[(\"http\", b\"example.com\", 80)],\n                         origCached)\n        timeouts = pool._timeouts.copy()\n\n        # Now we add another one:\n        newProtocol = StubHTTPProtocol()\n        newProtocol.makeConnection(StringTransport())\n        pool._putConnection((\"http\", b\"example.com\", 80), newProtocol)\n\n        # The oldest cached connections will be removed and disconnected:\n        newCached = pool._connections[(\"http\", b\"example.com\", 80)]\n        self.assertEqual(len(newCached), 2)\n        self.assertEqual(newCached, [origCached[1], newProtocol])\n        self.assertEqual([p.transport.disconnecting for p in newCached],\n                         [False, False])\n        self.assertEqual(origCached[0].transport.disconnecting, True)\n        self.assertTrue(timeouts[origCached[0]].cancelled)\n        self.assertNotIn(origCached[0], pool._timeouts)\n\n\n    def test_maxPersistentPerHost(self):\n        \"\"\"\n        C{maxPersistentPerHost} is enforced per C{(scheme, host, port)}:\n        different keys have different max connections.\n        \"\"\"\n        def addProtocol(scheme, host, port):\n            p = StubHTTPProtocol()\n            p.makeConnection(StringTransport())\n            self.pool._putConnection((scheme, host, port), p)\n            return p\n        persistent = []\n        persistent.append(addProtocol(\"http\", b\"example.com\", 80))\n        persistent.append(addProtocol(\"http\", b\"example.com\", 80))\n        addProtocol(\"https\", b\"example.com\", 443)\n        addProtocol(\"http\", b\"www2.example.com\", 80)\n\n        self.assertEqual(\n            self.pool._connections[(\"http\", b\"example.com\", 80)], persistent)\n        self.assertEqual(\n            len(self.pool._connections[(\"https\", b\"example.com\", 443)]), 1)\n        self.assertEqual(\n            len(self.pool._connections[(\"http\", b\"www2.example.com\", 80)]), 1)\n\n\n    def test_getCachedConnection(self):\n        \"\"\"\n        Getting an address which has a cached connection returns the cached\n        connection, removes it from the cache and cancels its timeout.\n        \"\"\"\n        # We start out with one cached connection:\n        protocol = StubHTTPProtocol()\n        protocol.makeConnection(StringTransport())\n        self.pool._putConnection((\"http\", b\"example.com\", 80), protocol)\n\n        def gotConnection(conn):\n            # We got the cached connection:\n            self.assertIdentical(protocol, conn)\n            self.assertNotIn(\n                conn, self.pool._connections[(\"http\", b\"example.com\", 80)])\n            # And the timeout was cancelled:\n            self.fakeReactor.advance(241)\n            self.assertEqual(conn.transport.disconnecting, False)\n            self.assertNotIn(conn, self.pool._timeouts)\n\n        return self.pool.getConnection((\"http\", b\"example.com\", 80),\n                                       BadEndpoint(),\n                                       ).addCallback(gotConnection)\n\n\n    def test_newConnection(self):\n        \"\"\"\n        The pool's C{_newConnection} method constructs a new connection.\n        \"\"\"\n        # We start out with one cached connection:\n        protocol = StubHTTPProtocol()\n        protocol.makeConnection(StringTransport())\n        key = 12245\n        self.pool._putConnection(key, protocol)\n\n        def gotConnection(newConnection):\n            # We got a new connection:\n            self.assertNotIdentical(protocol, newConnection)\n            # And the old connection is still there:\n            self.assertIn(protocol, self.pool._connections[key])\n            # While the new connection is not:\n            self.assertNotIn(newConnection, self.pool._connections.values())\n\n        d = self.pool._newConnection(key, DummyEndpoint())\n        return d.addCallback(gotConnection)\n\n\n    def test_getSkipsDisconnected(self):\n        \"\"\"\n        When getting connections out of the cache, disconnected connections\n        are removed and not returned.\n        \"\"\"\n        pool = self.pool\n        key = (\"http\", b\"example.com\", 80)\n\n        # We start out with two cached connection, the max:\n        origCached = [StubHTTPProtocol(), StubHTTPProtocol()]\n        for p in origCached:\n            p.makeConnection(StringTransport())\n            pool._putConnection(key, p)\n        self.assertEqual(pool._connections[key], origCached)\n\n        # We close the first one:\n        origCached[0].state = \"DISCONNECTED\"\n\n        # Now, when we retrive connections we should get the *second* one:\n        result = []\n        self.pool.getConnection(key,\n                                BadEndpoint()).addCallback(result.append)\n        self.assertIdentical(result[0], origCached[1])\n\n        # And both the disconnected and removed connections should be out of\n        # the cache:\n        self.assertEqual(pool._connections[key], [])\n        self.assertEqual(pool._timeouts, {})\n\n\n    def test_putNotQuiescent(self):\n        \"\"\"\n        If a non-quiescent connection is put back in the cache, an error is\n        logged.\n        \"\"\"\n        protocol = StubHTTPProtocol()\n        # By default state is QUIESCENT\n        self.assertEqual(protocol.state, \"QUIESCENT\")\n\n        logObserver = EventLoggingObserver.createWithCleanup(\n            self,\n            globalLogPublisher\n        )\n\n        protocol.state = \"NOTQUIESCENT\"\n        self.pool._putConnection((\"http\", b\"example.com\", 80), protocol)\n        self.assertEquals(1, len(logObserver))\n\n        event = logObserver[0]\n        f = event[\"log_failure\"]\n\n        self.assertIsInstance(f.value, RuntimeError)\n        self.assertEqual(\n            f.getErrorMessage(),\n            \"BUG: Non-quiescent protocol added to connection pool.\")\n        self.assertIdentical(None, self.pool._connections.get(\n                (\"http\", b\"example.com\", 80)))\n        self.flushLoggedErrors(RuntimeError)\n\n\n    def test_getUsesQuiescentCallback(self):\n        \"\"\"\n        When L{HTTPConnectionPool.getConnection} connects, it returns a\n        C{Deferred} that fires with an instance of L{HTTP11ClientProtocol}\n        that has the correct quiescent callback attached. When this callback\n        is called the protocol is returned to the cache correctly, using the\n        right key.\n        \"\"\"\n        class StringEndpoint(object):\n            def connect(self, factory):\n                p = factory.buildProtocol(None)\n                p.makeConnection(StringTransport())\n                return succeed(p)\n\n        pool = HTTPConnectionPool(self.fakeReactor, True)\n        pool.retryAutomatically = False\n        result = []\n        key = \"a key\"\n        pool.getConnection(\n            key, StringEndpoint()).addCallback(\n            result.append)\n        protocol = result[0]\n        self.assertIsInstance(protocol, HTTP11ClientProtocol)\n\n        # Now that we have protocol instance, lets try to put it back in the\n        # pool:\n        protocol._state = \"QUIESCENT\"\n        protocol._quiescentCallback(protocol)\n\n        # If we try to retrive a connection to same destination again, we\n        # should get the same protocol, because it should've been added back\n        # to the pool:\n        result2 = []\n        pool.getConnection(\n            key, StringEndpoint()).addCallback(\n            result2.append)\n        self.assertIdentical(result2[0], protocol)\n\n\n    def test_closeCachedConnections(self):\n        \"\"\"\n        L{HTTPConnectionPool.closeCachedConnections} closes all cached\n        connections and removes them from the cache. It returns a Deferred\n        that fires when they have all lost their connections.\n        \"\"\"\n        persistent = []\n        def addProtocol(scheme, host, port):\n            p = HTTP11ClientProtocol()\n            p.makeConnection(StringTransport())\n            self.pool._putConnection((scheme, host, port), p)\n            persistent.append(p)\n        addProtocol(\"http\", b\"example.com\", 80)\n        addProtocol(\"http\", b\"www2.example.com\", 80)\n        doneDeferred = self.pool.closeCachedConnections()\n\n        # Connections have begun disconnecting:\n        for p in persistent:\n            self.assertEqual(p.transport.disconnecting, True)\n        self.assertEqual(self.pool._connections, {})\n        # All timeouts were cancelled and removed:\n        for dc in self.fakeReactor.getDelayedCalls():\n            self.assertEqual(dc.cancelled, True)\n        self.assertEqual(self.pool._timeouts, {})\n\n        # Returned Deferred fires when all connections have been closed:\n        result = []\n        doneDeferred.addCallback(result.append)\n        self.assertEqual(result, [])\n        persistent[0].connectionLost(Failure(ConnectionDone()))\n        self.assertEqual(result, [])\n        persistent[1].connectionLost(Failure(ConnectionDone()))\n        self.assertEqual(result, [None])\n\n\n    def test_cancelGetConnectionCancelsEndpointConnect(self):\n        \"\"\"\n        Cancelling the C{Deferred} returned from\n        L{HTTPConnectionPool.getConnection} cancels the C{Deferred} returned\n        by opening a new connection with the given endpoint.\n        \"\"\"\n        self.assertEqual(self.pool._connections, {})\n        connectionResult = Deferred()\n\n        class Endpoint:\n            def connect(self, factory):\n                return connectionResult\n\n        d = self.pool.getConnection(12345, Endpoint())\n        d.cancel()\n        self.assertEqual(self.failureResultOf(connectionResult).type,\n                         CancelledError)\n\n\n\nclass AgentTestsMixin(object):\n    \"\"\"\n    Tests for any L{IAgent} implementation.\n    \"\"\"\n    def test_interface(self):\n        \"\"\"\n        The agent object provides L{IAgent}.\n        \"\"\"\n        self.assertTrue(verifyObject(IAgent, self.makeAgent()))\n\n\n\nclass IntegrationTestingMixin(object):\n    \"\"\"\n    Transport-to-Agent integration tests for both HTTP and HTTPS.\n    \"\"\"\n\n    def test_integrationTestIPv4(self):\n        \"\"\"\n        L{Agent} works over IPv4.\n        \"\"\"\n        self.integrationTest(b'example.com', EXAMPLE_COM_IP, IPv4Address)\n\n\n    def test_integrationTestIPv4Address(self):\n        \"\"\"\n        L{Agent} works over IPv4 when hostname is an IPv4 address.\n        \"\"\"\n        self.integrationTest(b'127.0.0.7', '127.0.0.7', IPv4Address)\n\n\n    def test_integrationTestIPv6(self):\n        \"\"\"\n        L{Agent} works over IPv6.\n        \"\"\"\n        self.integrationTest(b'ipv6.example.com', EXAMPLE_COM_V6_IP,\n                             IPv6Address)\n\n\n    def test_integrationTestIPv6Address(self):\n        \"\"\"\n        L{Agent} works over IPv6 when hostname is an IPv6 address.\n        \"\"\"\n        self.integrationTest(b'[::7]', '::7', IPv6Address)\n\n\n    def integrationTest(self, hostName, expectedAddress, addressType,\n                        serverWrapper=lambda server: server,\n                        createAgent=client.Agent,\n                        scheme=b'http'):\n        \"\"\"\n        L{Agent} will make a TCP connection, send an HTTP request, and return a\n        L{Deferred} that fires when the response has been received.\n\n        @param hostName: The hostname to interpolate into the URL to be\n            requested.\n        @type hostName: L{bytes}\n\n        @param expectedAddress: The expected address string.\n        @type expectedAddress: L{bytes}\n\n        @param addressType: The class to construct an address out of.\n        @type addressType: L{type}\n\n        @param serverWrapper: A callable that takes a protocol factory and\n            returns a protocol factory; used to wrap the server / responder\n            side in a TLS server.\n        @type serverWrapper:\n            serverWrapper(L{twisted.internet.interfaces.IProtocolFactory}) ->\n            L{twisted.internet.interfaces.IProtocolFactory}\n\n        @param createAgent: A callable that takes a reactor and produces an\n            L{IAgent}; used to construct an agent with an appropriate trust\n            root for TLS.\n        @type createAgent: createAgent(reactor) -> L{IAgent}\n\n        @param scheme: The scheme to test, C{http} or C{https}\n        @type scheme: L{bytes}\n        \"\"\"\n        reactor = self.createReactor()\n        agent = createAgent(reactor)\n        deferred = agent.request(b\"GET\", scheme + b\"://\" + hostName + b\"/\")\n        host, port, factory, timeout, bind = reactor.tcpClients[0]\n        self.assertEqual(host, expectedAddress)\n        peerAddress = addressType('TCP', host, port)\n        clientProtocol = factory.buildProtocol(peerAddress)\n        clientTransport = FakeTransport(clientProtocol, False,\n                                        peerAddress=peerAddress)\n        clientProtocol.makeConnection(clientTransport)\n        @Factory.forProtocol\n        def accumulator():\n            ap = AccumulatingProtocol()\n            accumulator.currentProtocol = ap\n            return ap\n        accumulator.currentProtocol = None\n        accumulator.protocolConnectionMade = None\n        wrapper = serverWrapper(accumulator).buildProtocol(None)\n        serverTransport = FakeTransport(wrapper, True)\n        wrapper.makeConnection(serverTransport)\n        pump = IOPump(clientProtocol, wrapper,\n                      clientTransport, serverTransport, False)\n        pump.flush()\n        self.assertNoResult(deferred)\n        lines = accumulator.currentProtocol.data.split(b\"\\r\\n\")\n        self.assertTrue(lines[0].startswith(b\"GET / HTTP\"), lines[0])\n        headers = dict([line.split(b\": \", 1) for line in lines[1:] if line])\n        self.assertEqual(headers[b'Host'], hostName)\n        self.assertNoResult(deferred)\n        accumulator.currentProtocol.transport.write(\n            b\"HTTP/1.1 200 OK\"\n            b\"\\r\\nX-An-Header: an-value\\r\\n\"\n            b\"\\r\\nContent-length: 12\\r\\n\\r\\n\"\n            b\"hello world!\"\n        )\n        pump.flush()\n        response = self.successResultOf(deferred)\n        self.assertEquals(response.headers.getRawHeaders(b'x-an-header')[0],\n                          b\"an-value\")\n\n\n\n@implementer(IAgentEndpointFactory)\nclass StubEndpointFactory(object):\n    \"\"\"\n    A stub L{IAgentEndpointFactory} for use in testing.\n    \"\"\"\n    def endpointForURI(self, uri):\n        \"\"\"\n        Testing implementation.\n\n        @param uri: A L{URI}.\n\n        @return: C{(scheme, host, port)} of passed in URI; violation of\n            interface but useful for testing.\n        @rtype: L{tuple}\n        \"\"\"\n        return (uri.scheme, uri.host, uri.port)\n\n\n\nclass AgentTests(TestCase, FakeReactorAndConnectMixin, AgentTestsMixin,\n                 IntegrationTestingMixin):\n    \"\"\"\n    Tests for the new HTTP client API provided by L{Agent}.\n    \"\"\"\n    def makeAgent(self):\n        \"\"\"\n        @return: a new L{twisted.web.client.Agent} instance\n        \"\"\"\n        return client.Agent(self.reactor)\n\n\n    def setUp(self):\n        \"\"\"\n        Create an L{Agent} wrapped around a fake reactor.\n        \"\"\"\n        self.reactor = self.createReactor()\n        self.agent = self.makeAgent()\n\n\n    def test_defaultPool(self):\n        \"\"\"\n        If no pool is passed in, the L{Agent} creates a non-persistent pool.\n        \"\"\"\n        agent = client.Agent(self.reactor)\n        self.assertIsInstance(agent._pool, HTTPConnectionPool)\n        self.assertEqual(agent._pool.persistent, False)\n        self.assertIdentical(agent._reactor, agent._pool._reactor)\n\n\n    def test_persistent(self):\n        \"\"\"\n        If C{persistent} is set to C{True} on the L{HTTPConnectionPool} (the\n        default), C{Request}s are created with their C{persistent} flag set to\n        C{True}.\n        \"\"\"\n        pool = HTTPConnectionPool(self.reactor)\n        agent = client.Agent(self.reactor, pool=pool)\n        agent._getEndpoint = lambda *args: self\n        agent.request(b\"GET\", b\"http://127.0.0.1\")\n        self.assertEqual(self.protocol.requests[0][0].persistent, True)\n\n\n    def test_nonPersistent(self):\n        \"\"\"\n        If C{persistent} is set to C{False} when creating the\n        L{HTTPConnectionPool}, C{Request}s are created with their\n        C{persistent} flag set to C{False}.\n\n        Elsewhere in the tests for the underlying HTTP code we ensure that\n        this will result in the disconnection of the HTTP protocol once the\n        request is done, so that the connection will not be returned to the\n        pool.\n        \"\"\"\n        pool = HTTPConnectionPool(self.reactor, persistent=False)\n        agent = client.Agent(self.reactor, pool=pool)\n        agent._getEndpoint = lambda *args: self\n        agent.request(b\"GET\", b\"http://127.0.0.1\")\n        self.assertEqual(self.protocol.requests[0][0].persistent, False)\n\n\n    def test_connectUsesConnectionPool(self):\n        \"\"\"\n        When a connection is made by the Agent, it uses its pool's\n        C{getConnection} method to do so, with the endpoint returned by\n        C{self._getEndpoint}. The key used is C{(scheme, host, port)}.\n        \"\"\"\n        endpoint = DummyEndpoint()\n        class MyAgent(client.Agent):\n            def _getEndpoint(this, uri):\n                self.assertEqual((uri.scheme, uri.host, uri.port),\n                                 (b\"http\", b\"foo\", 80))\n                return endpoint\n\n        class DummyPool(object):\n            connected = False\n            persistent = False\n            def getConnection(this, key, ep):\n                this.connected = True\n                self.assertEqual(ep, endpoint)\n                # This is the key the default Agent uses, others will have\n                # different keys:\n                self.assertEqual(key, (b\"http\", b\"foo\", 80))\n                return defer.succeed(StubHTTPProtocol())\n\n        pool = DummyPool()\n        agent = MyAgent(self.reactor, pool=pool)\n        self.assertIdentical(pool, agent._pool)\n\n        headers = http_headers.Headers()\n        headers.addRawHeader(b\"host\", b\"foo\")\n        bodyProducer = object()\n        agent.request(b'GET', b'http://foo/',\n                      bodyProducer=bodyProducer, headers=headers)\n        self.assertEqual(agent._pool.connected, True)\n\n\n    def test_nonBytesMethod(self):\n        \"\"\"\n        L{Agent.request} raises L{TypeError} when the C{method} argument isn't\n        L{bytes}.\n        \"\"\"\n        self.assertRaises(TypeError, self.agent.request,\n                          u'GET', b'http://foo.example/')\n\n\n    def test_unsupportedScheme(self):\n        \"\"\"\n        L{Agent.request} returns a L{Deferred} which fails with\n        L{SchemeNotSupported} if the scheme of the URI passed to it is not\n        C{'http'}.\n        \"\"\"\n        return self.assertFailure(\n            self.agent.request(b'GET', b'mailto:alice@example.com'),\n            SchemeNotSupported)\n\n\n    def test_connectionFailed(self):\n        \"\"\"\n        The L{Deferred} returned by L{Agent.request} fires with a L{Failure} if\n        the TCP connection attempt fails.\n        \"\"\"\n        result = self.agent.request(b'GET', b'http://foo/')\n        # Cause the connection to be refused\n        host, port, factory = self.reactor.tcpClients.pop()[:3]\n        factory.clientConnectionFailed(None, Failure(ConnectionRefusedError()))\n        self.reactor.advance(10)\n        # ^ https://twistedmatrix.com/trac/ticket/8202\n        self.failureResultOf(result, ConnectionRefusedError)\n\n\n    def test_connectHTTP(self):\n        \"\"\"\n        L{Agent._getEndpoint} return a C{HostnameEndpoint} when passed a scheme\n        of C{'http'}.\n        \"\"\"\n        expectedHost = b'example.com'\n        expectedPort = 1234\n        endpoint = self.agent._getEndpoint(URI.fromBytes(\n            b'http://' + expectedHost + b\":\" + intToBytes(expectedPort)))\n        self.assertEqual(endpoint._hostStr, \"example.com\")\n        self.assertEqual(endpoint._port, expectedPort)\n        self.assertIsInstance(endpoint, HostnameEndpoint)\n\n\n    def test_nonDecodableURI(self):\n        \"\"\"\n        L{Agent._getEndpoint} when given a non-ASCII decodable URI will raise a\n        L{ValueError} saying such.\n        \"\"\"\n        uri = URI.fromBytes(b\"http://example.com:80\")\n        uri.host = u'\\u2603.com'.encode('utf8')\n\n        with self.assertRaises(ValueError) as e:\n            self.agent._getEndpoint(uri)\n\n        self.assertEqual(e.exception.args[0],\n                         (\"The host of the provided URI ({reprout}) contains \"\n                          \"non-ASCII octets, it should be ASCII \"\n                          \"decodable.\").format(reprout=repr(uri.host)))\n\n\n    def test_hostProvided(self):\n        \"\"\"\n        If L{None} is passed to L{Agent.request} for the C{headers} parameter,\n        a L{Headers} instance is created for the request and a I{Host} header\n        added to it.\n        \"\"\"\n        self.agent._getEndpoint = lambda *args: self\n        self.agent.request(\n            b'GET', b'http://example.com/foo?bar')\n\n        req, res = self.protocol.requests.pop()\n        self.assertEqual(req.headers.getRawHeaders(b'host'), [b'example.com'])\n\n\n    def test_hostIPv6Bracketed(self):\n        \"\"\"\n        If an IPv6 address is used in the C{uri} passed to L{Agent.request},\n        the computed I{Host} header needs to be bracketed.\n        \"\"\"\n        self.agent._getEndpoint = lambda *args: self\n        self.agent.request(b'GET', b'http://[::1]/')\n\n        req, res = self.protocol.requests.pop()\n        self.assertEqual(req.headers.getRawHeaders(b'host'), [b'[::1]'])\n\n\n    def test_hostOverride(self):\n        \"\"\"\n        If the headers passed to L{Agent.request} includes a value for the\n        I{Host} header, that value takes precedence over the one which would\n        otherwise be automatically provided.\n        \"\"\"\n        headers = http_headers.Headers({b'foo': [b'bar'], b'host': [b'quux']})\n        self.agent._getEndpoint = lambda *args: self\n        self.agent.request(\n            b'GET', b'http://example.com/foo?bar', headers)\n\n        req, res = self.protocol.requests.pop()\n        self.assertEqual(req.headers.getRawHeaders(b'host'), [b'quux'])\n\n\n    def test_headersUnmodified(self):\n        \"\"\"\n        If a I{Host} header must be added to the request, the L{Headers}\n        instance passed to L{Agent.request} is not modified.\n        \"\"\"\n        headers = http_headers.Headers()\n        self.agent._getEndpoint = lambda *args: self\n        self.agent.request(\n            b'GET', b'http://example.com/foo', headers)\n\n        protocol = self.protocol\n\n        # The request should have been issued.\n        self.assertEqual(len(protocol.requests), 1)\n        # And the headers object passed in should not have changed.\n        self.assertEqual(headers, http_headers.Headers())\n\n\n    def test_hostValueStandardHTTP(self):\n        \"\"\"\n        When passed a scheme of C{'http'} and a port of C{80},\n        L{Agent._computeHostValue} returns a string giving just\n        the host name passed to it.\n        \"\"\"\n        self.assertEqual(\n            self.agent._computeHostValue(b'http', b'example.com', 80),\n            b'example.com')\n\n\n    def test_hostValueNonStandardHTTP(self):\n        \"\"\"\n        When passed a scheme of C{'http'} and a port other than C{80},\n        L{Agent._computeHostValue} returns a string giving the\n        host passed to it joined together with the port number by C{\":\"}.\n        \"\"\"\n        self.assertEqual(\n            self.agent._computeHostValue(b'http', b'example.com', 54321),\n            b'example.com:54321')\n\n\n    def test_hostValueStandardHTTPS(self):\n        \"\"\"\n        When passed a scheme of C{'https'} and a port of C{443},\n        L{Agent._computeHostValue} returns a string giving just\n        the host name passed to it.\n        \"\"\"\n        self.assertEqual(\n            self.agent._computeHostValue(b'https', b'example.com', 443),\n            b'example.com')\n\n\n    def test_hostValueNonStandardHTTPS(self):\n        \"\"\"\n        When passed a scheme of C{'https'} and a port other than C{443},\n        L{Agent._computeHostValue} returns a string giving the\n        host passed to it joined together with the port number by C{\":\"}.\n        \"\"\"\n        self.assertEqual(\n            self.agent._computeHostValue(b'https', b'example.com', 54321),\n            b'example.com:54321')\n\n\n    def test_request(self):\n        \"\"\"\n        L{Agent.request} establishes a new connection to the host indicated by\n        the host part of the URI passed to it and issues a request using the\n        method, the path portion of the URI, the headers, and the body producer\n        passed to it.  It returns a L{Deferred} which fires with an\n        L{IResponse} from the server.\n        \"\"\"\n        self.agent._getEndpoint = lambda *args: self\n\n        headers = http_headers.Headers({b'foo': [b'bar']})\n        # Just going to check the body for identity, so it doesn't need to be\n        # real.\n        body = object()\n        self.agent.request(\n            b'GET', b'http://example.com:1234/foo?bar', headers, body)\n\n        protocol = self.protocol\n\n        # The request should be issued.\n        self.assertEqual(len(protocol.requests), 1)\n        req, res = protocol.requests.pop()\n        self.assertIsInstance(req, Request)\n        self.assertEqual(req.method, b'GET')\n        self.assertEqual(req.uri, b'/foo?bar')\n        self.assertEqual(\n            req.headers,\n            http_headers.Headers({b'foo': [b'bar'],\n                                  b'host': [b'example.com:1234']}))\n        self.assertIdentical(req.bodyProducer, body)\n\n\n    def test_connectTimeout(self):\n        \"\"\"\n        L{Agent} takes a C{connectTimeout} argument which is forwarded to the\n        following C{connectTCP} agent.\n        \"\"\"\n        agent = client.Agent(self.reactor, connectTimeout=5)\n        agent.request(b'GET', b'http://foo/')\n        timeout = self.reactor.tcpClients.pop()[3]\n        self.assertEqual(5, timeout)\n\n\n    def test_connectTimeoutHTTPS(self):\n        \"\"\"\n        L{Agent} takes a C{connectTimeout} argument which is forwarded to the\n        following C{connectTCP} call.\n        \"\"\"\n        agent = client.Agent(self.reactor, connectTimeout=5)\n        agent.request(b'GET', b'https://foo/')\n        timeout = self.reactor.tcpClients.pop()[3]\n        self.assertEqual(5, timeout)\n\n    test_connectTimeoutHTTPS.skip = skipWhenNoSSL\n\n\n    def test_bindAddress(self):\n        \"\"\"\n        L{Agent} takes a C{bindAddress} argument which is forwarded to the\n        following C{connectTCP} call.\n        \"\"\"\n        agent = client.Agent(self.reactor, bindAddress='192.168.0.1')\n        agent.request(b'GET', b'http://foo/')\n        address = self.reactor.tcpClients.pop()[4]\n        self.assertEqual('192.168.0.1', address)\n\n\n    def test_bindAddressSSL(self):\n        \"\"\"\n        L{Agent} takes a C{bindAddress} argument which is forwarded to the\n        following C{connectSSL} call.\n        \"\"\"\n        agent = client.Agent(self.reactor, bindAddress='192.168.0.1')\n        agent.request(b'GET', b'https://foo/')\n        address = self.reactor.tcpClients.pop()[4]\n        self.assertEqual('192.168.0.1', address)\n\n    test_bindAddressSSL.skip = skipWhenNoSSL\n\n\n    def test_responseIncludesRequest(self):\n        \"\"\"\n        L{Response}s returned by L{Agent.request} have a reference to the\n        L{Request} that was originally issued.\n        \"\"\"\n        uri = b'http://example.com/'\n        agent = self.buildAgentForWrapperTest(self.reactor)\n        d = agent.request(b'GET', uri)\n\n        # The request should be issued.\n        self.assertEqual(len(self.protocol.requests), 1)\n        req, res = self.protocol.requests.pop()\n        self.assertIsInstance(req, Request)\n\n        resp = client.Response._construct(\n            (b'HTTP', 1, 1),\n            200,\n            b'OK',\n            client.Headers({}),\n            None,\n            req)\n        res.callback(resp)\n\n        response = self.successResultOf(d)\n        self.assertEqual(\n            (response.request.method, response.request.absoluteURI,\n             response.request.headers),\n            (req.method, req.absoluteURI, req.headers))\n\n\n    def test_requestAbsoluteURI(self):\n        \"\"\"\n        L{Request.absoluteURI} is the absolute URI of the request.\n        \"\"\"\n        uri = b'http://example.com/foo;1234?bar#frag'\n        agent = self.buildAgentForWrapperTest(self.reactor)\n        agent.request(b'GET', uri)\n\n        # The request should be issued.\n        self.assertEqual(len(self.protocol.requests), 1)\n        req, res = self.protocol.requests.pop()\n        self.assertIsInstance(req, Request)\n        self.assertEqual(req.absoluteURI, uri)\n\n\n    def test_requestMissingAbsoluteURI(self):\n        \"\"\"\n        L{Request.absoluteURI} is L{None} if L{Request._parsedURI} is L{None}.\n        \"\"\"\n        request = client.Request(b'FOO', b'/', client.Headers(), None)\n        self.assertIdentical(request.absoluteURI, None)\n\n\n    def test_endpointFactory(self):\n        \"\"\"\n        L{Agent.usingEndpointFactory} creates an L{Agent} that uses the given\n        factory to create endpoints.\n        \"\"\"\n        factory = StubEndpointFactory()\n        agent = client.Agent.usingEndpointFactory(\n            None, endpointFactory=factory)\n        uri = URI.fromBytes(b'http://example.com/')\n        returnedEndpoint = agent._getEndpoint(uri)\n        self.assertEqual(returnedEndpoint, (b\"http\", b\"example.com\", 80))\n\n\n    def test_endpointFactoryDefaultPool(self):\n        \"\"\"\n        If no pool is passed in to L{Agent.usingEndpointFactory}, a default\n        pool is constructed with no persistent connections.\n        \"\"\"\n        agent = client.Agent.usingEndpointFactory(\n            self.reactor, StubEndpointFactory())\n        pool = agent._pool\n        self.assertEqual((pool.__class__, pool.persistent, pool._reactor),\n                          (HTTPConnectionPool, False, agent._reactor))\n\n\n    def test_endpointFactoryPool(self):\n        \"\"\"\n        If a pool is passed in to L{Agent.usingEndpointFactory} it is used as\n        the L{Agent} pool.\n        \"\"\"\n        pool = object()\n        agent = client.Agent.usingEndpointFactory(\n            self.reactor, StubEndpointFactory(), pool)\n        self.assertIs(pool, agent._pool)\n\n\n\nclass AgentHTTPSTests(TestCase, FakeReactorAndConnectMixin,\n                      IntegrationTestingMixin):\n    \"\"\"\n    Tests for the new HTTP client API that depends on SSL.\n    \"\"\"\n    skip = skipWhenNoSSL\n\n    def makeEndpoint(self, host=b'example.com', port=443):\n        \"\"\"\n        Create an L{Agent} with an https scheme and return its endpoint\n        created according to the arguments.\n\n        @param host: The host for the endpoint.\n        @type host: L{bytes}\n\n        @param port: The port for the endpoint.\n        @type port: L{int}\n\n        @return: An endpoint of an L{Agent} constructed according to args.\n        @rtype: L{SSL4ClientEndpoint}\n        \"\"\"\n        return client.Agent(self.createReactor())._getEndpoint(\n            URI.fromBytes(b'https://' + host + b\":\" + intToBytes(port) + b\"/\"))\n\n\n    def test_endpointType(self):\n        \"\"\"\n        L{Agent._getEndpoint} return a L{SSL4ClientEndpoint} when passed a\n        scheme of C{'https'}.\n        \"\"\"\n        from twisted.internet.endpoints import _WrapperEndpoint\n        endpoint = self.makeEndpoint()\n        self.assertIsInstance(endpoint, _WrapperEndpoint)\n        self.assertIsInstance(endpoint._wrappedEndpoint, HostnameEndpoint)\n\n\n    def test_hostArgumentIsRespected(self):\n        \"\"\"\n        If a host is passed, the endpoint respects it.\n        \"\"\"\n        endpoint = self.makeEndpoint(host=b\"example.com\")\n        self.assertEqual(endpoint._wrappedEndpoint._hostStr, \"example.com\")\n\n\n    def test_portArgumentIsRespected(self):\n        \"\"\"\n        If a port is passed, the endpoint respects it.\n        \"\"\"\n        expectedPort = 4321\n        endpoint = self.makeEndpoint(port=expectedPort)\n        self.assertEqual(endpoint._wrappedEndpoint._port, expectedPort)\n\n\n    def test_contextFactoryType(self):\n        \"\"\"\n        L{Agent} wraps its connection creator creator and uses modern TLS APIs.\n        \"\"\"\n        endpoint = self.makeEndpoint()\n        contextFactory = endpoint._wrapperFactory(None)._connectionCreator\n        self.assertIsInstance(contextFactory, ClientTLSOptions)\n        self.assertEqual(contextFactory._hostname, u\"example.com\")\n\n\n    def test_connectHTTPSCustomConnectionCreator(self):\n        \"\"\"\n        If a custom L{WebClientConnectionCreator}-like object is passed to\n        L{Agent.__init__} it will be used to determine the SSL parameters for\n        HTTPS requests.  When an HTTPS request is made, the hostname and port\n        number of the request URL will be passed to the connection creator's\n        C{creatorForNetloc} method.  The resulting context object will be used\n        to establish the SSL connection.\n        \"\"\"\n        expectedHost = b'example.org'\n        expectedPort = 20443\n        class JustEnoughConnection(object):\n            handshakeStarted = False\n            connectState = False\n            def do_handshake(self):\n                \"\"\"\n                The handshake started.  Record that fact.\n                \"\"\"\n                self.handshakeStarted = True\n            def set_connect_state(self):\n                \"\"\"\n                The connection started.  Record that fact.\n                \"\"\"\n                self.connectState = True\n\n        contextArgs = []\n\n        @implementer(IOpenSSLClientConnectionCreator)\n        class JustEnoughCreator(object):\n            def __init__(self, hostname, port):\n                self.hostname = hostname\n                self.port = port\n\n            def clientConnectionForTLS(self, tlsProtocol):\n                \"\"\"\n                Implement L{IOpenSSLClientConnectionCreator}.\n\n                @param tlsProtocol: The TLS protocol.\n                @type tlsProtocol: L{TLSMemoryBIOProtocol}\n\n                @return: C{expectedConnection}\n                \"\"\"\n                contextArgs.append((tlsProtocol, self.hostname, self.port))\n                return expectedConnection\n\n        expectedConnection = JustEnoughConnection()\n        @implementer(IPolicyForHTTPS)\n        class StubBrowserLikePolicyForHTTPS(object):\n            def creatorForNetloc(self, hostname, port):\n                \"\"\"\n                Emulate L{BrowserLikePolicyForHTTPS}.\n\n                @param hostname: The hostname to verify.\n                @type hostname: L{bytes}\n\n                @param port: The port number.\n                @type port: L{int}\n\n                @return: a stub L{IOpenSSLClientConnectionCreator}\n                @rtype: L{JustEnoughCreator}\n                \"\"\"\n                return JustEnoughCreator(hostname, port)\n\n        expectedCreatorCreator = StubBrowserLikePolicyForHTTPS()\n        reactor = self.createReactor()\n        agent = client.Agent(reactor, expectedCreatorCreator)\n        endpoint = agent._getEndpoint(URI.fromBytes(\n            b'https://' + expectedHost + b\":\" + intToBytes(expectedPort)))\n        endpoint.connect(Factory.forProtocol(Protocol))\n        tlsFactory = reactor.tcpClients[-1][2]\n        tlsProtocol = tlsFactory.buildProtocol(None)\n        tlsProtocol.makeConnection(StringTransport())\n        tls = contextArgs[0][0]\n        self.assertIsInstance(tls, TLSMemoryBIOProtocol)\n        self.assertEqual(contextArgs[0][1:], (expectedHost, expectedPort))\n        self.assertTrue(expectedConnection.handshakeStarted)\n        self.assertTrue(expectedConnection.connectState)\n\n\n    def test_deprecatedDuckPolicy(self):\n        \"\"\"\n        Passing something that duck-types I{like} a L{web client context\n        factory <twisted.web.client.WebClientContextFactory>} - something that\n        does not provide L{IPolicyForHTTPS} - to L{Agent} emits a\n        L{DeprecationWarning} even if you don't actually C{import\n        WebClientContextFactory} to do it.\n        \"\"\"\n        def warnMe():\n            client.Agent(deterministicResolvingReactor(MemoryReactorClock()),\n                         \"does-not-provide-IPolicyForHTTPS\")\n        warnMe()\n        warnings = self.flushWarnings([warnMe])\n        self.assertEqual(len(warnings), 1)\n        [warning] = warnings\n        self.assertEqual(warning['category'], DeprecationWarning)\n        self.assertEqual(\n            warning['message'],\n            \"'does-not-provide-IPolicyForHTTPS' was passed as the HTTPS \"\n            \"policy for an Agent, but it does not provide IPolicyForHTTPS.  \"\n            \"Since Twisted 14.0, you must pass a provider of IPolicyForHTTPS.\"\n        )\n\n\n    def test_alternateTrustRoot(self):\n        \"\"\"\n        L{BrowserLikePolicyForHTTPS.creatorForNetloc} returns an\n        L{IOpenSSLClientConnectionCreator} provider which will add certificates\n        from the given trust root.\n        \"\"\"\n        trustRoot = CustomOpenSSLTrustRoot()\n        policy = BrowserLikePolicyForHTTPS(trustRoot=trustRoot)\n        creator = policy.creatorForNetloc(b\"thingy\", 4321)\n        self.assertTrue(trustRoot.called)\n        connection = creator.clientConnectionForTLS(None)\n        self.assertIs(trustRoot.context, connection.get_context())\n\n\n    def integrationTest(self, hostName, expectedAddress, addressType):\n        \"\"\"\n        Wrap L{AgentTestsMixin.integrationTest} with TLS.\n        \"\"\"\n        certHostName = hostName.strip(b'[]')\n        authority, server = certificatesForAuthorityAndServer(certHostName\n                                                              .decode('ascii'))\n        def tlsify(serverFactory):\n            return TLSMemoryBIOFactory(server.options(), False, serverFactory)\n        def tlsagent(reactor):\n            from twisted.web.iweb import IPolicyForHTTPS\n            from zope.interface import implementer\n            @implementer(IPolicyForHTTPS)\n            class Policy(object):\n                def creatorForNetloc(self, hostname, port):\n                    return optionsForClientTLS(hostname.decode(\"ascii\"),\n                                               trustRoot=authority)\n            return client.Agent(reactor, contextFactory=Policy())\n        (super(AgentHTTPSTests, self)\n         .integrationTest(hostName, expectedAddress, addressType,\n                          serverWrapper=tlsify,\n                          createAgent=tlsagent,\n                          scheme=b'https'))\n\n\n\nclass WebClientContextFactoryTests(TestCase):\n    \"\"\"\n    Tests for the context factory wrapper for web clients\n    L{twisted.web.client.WebClientContextFactory}.\n    \"\"\"\n\n    def setUp(self):\n        \"\"\"\n        Get WebClientContextFactory while quashing its deprecation warning.\n        \"\"\"\n        from twisted.web.client import WebClientContextFactory\n        self.warned = self.flushWarnings([WebClientContextFactoryTests.setUp])\n        self.webClientContextFactory = WebClientContextFactory\n\n\n    def test_deprecated(self):\n        \"\"\"\n        L{twisted.web.client.WebClientContextFactory} is deprecated.  Importing\n        it displays a warning.\n        \"\"\"\n        self.assertEqual(len(self.warned), 1)\n        [warning] = self.warned\n        self.assertEqual(warning['category'], DeprecationWarning)\n        self.assertEqual(\n            warning['message'],\n            getDeprecationWarningString(\n                self.webClientContextFactory, Version(\"Twisted\", 14, 0, 0),\n                replacement=BrowserLikePolicyForHTTPS,\n            )\n\n            # See https://twistedmatrix.com/trac/ticket/7242\n            .replace(\";\", \":\")\n        )\n\n\n    def test_missingSSL(self):\n        \"\"\"\n        If C{getContext} is called and SSL is not available, raise\n        L{NotImplementedError}.\n        \"\"\"\n        self.assertRaises(\n            NotImplementedError,\n            self.webClientContextFactory().getContext,\n            b'example.com', 443,\n        )\n\n\n    def test_returnsContext(self):\n        \"\"\"\n        If SSL is present, C{getContext} returns a L{OpenSSL.SSL.Context}.\n        \"\"\"\n        ctx = self.webClientContextFactory().getContext('example.com', 443)\n        self.assertIsInstance(ctx, ssl.SSL.Context)\n\n\n    def test_setsTrustRootOnContextToDefaultTrustRoot(self):\n        \"\"\"\n        The L{CertificateOptions} has C{trustRoot} set to the default trust\n        roots.\n        \"\"\"\n        ctx = self.webClientContextFactory()\n        certificateOptions = ctx._getCertificateOptions('example.com', 443)\n        self.assertIsInstance(\n            certificateOptions.trustRoot, ssl.OpenSSLDefaultPaths)\n\n    test_returnsContext.skip \\\n        = test_setsTrustRootOnContextToDefaultTrustRoot.skip \\\n        = skipWhenNoSSL\n    test_missingSSL.skip = skipWhenSSLPresent\n\n\n\nclass HTTPConnectionPoolRetryTests(TestCase, FakeReactorAndConnectMixin):\n    \"\"\"\n    L{client.HTTPConnectionPool}, by using\n    L{client._RetryingHTTP11ClientProtocol}, supports retrying requests done\n    against previously cached connections.\n    \"\"\"\n\n    def test_onlyRetryIdempotentMethods(self):\n        \"\"\"\n        Only GET, HEAD, OPTIONS, TRACE, DELETE methods cause a retry.\n        \"\"\"\n        pool = client.HTTPConnectionPool(None)\n        connection = client._RetryingHTTP11ClientProtocol(None, pool)\n        self.assertTrue(connection._shouldRetry(\n            b\"GET\", RequestNotSent(), None))\n        self.assertTrue(connection._shouldRetry(\n            b\"HEAD\", RequestNotSent(), None))\n        self.assertTrue(connection._shouldRetry(\n            b\"OPTIONS\", RequestNotSent(), None))\n        self.assertTrue(connection._shouldRetry(\n            b\"TRACE\", RequestNotSent(), None))\n        self.assertTrue(connection._shouldRetry(\n            b\"DELETE\", RequestNotSent(), None))\n        self.assertFalse(connection._shouldRetry(\n            b\"POST\", RequestNotSent(), None))\n        self.assertFalse(connection._shouldRetry(\n            b\"MYMETHOD\", RequestNotSent(), None))\n        # This will be covered by a different ticket, since we need support\n        #for resettable body producers:\n        # self.assertTrue(connection._doRetry(\"PUT\", RequestNotSent(), None))\n\n\n    def test_onlyRetryIfNoResponseReceived(self):\n        \"\"\"\n        Only L{RequestNotSent}, L{RequestTransmissionFailed} and\n        L{ResponseNeverReceived} exceptions cause a retry.\n        \"\"\"\n        pool = client.HTTPConnectionPool(None)\n        connection = client._RetryingHTTP11ClientProtocol(None, pool)\n        self.assertTrue(connection._shouldRetry(\n            b\"GET\", RequestNotSent(), None))\n        self.assertTrue(connection._shouldRetry(\n            b\"GET\", RequestTransmissionFailed([]), None))\n        self.assertTrue(connection._shouldRetry(\n            b\"GET\", ResponseNeverReceived([]),None))\n        self.assertFalse(connection._shouldRetry(\n            b\"GET\", ResponseFailed([]), None))\n        self.assertFalse(connection._shouldRetry(\n            b\"GET\", ConnectionRefusedError(), None))\n\n\n    def test_dontRetryIfFailedDueToCancel(self):\n        \"\"\"\n        If a request failed due to the operation being cancelled,\n        C{_shouldRetry} returns C{False} to indicate the request should not be\n        retried.\n        \"\"\"\n        pool = client.HTTPConnectionPool(None)\n        connection = client._RetryingHTTP11ClientProtocol(None, pool)\n        exception = ResponseNeverReceived([Failure(defer.CancelledError())])\n        self.assertFalse(connection._shouldRetry(b\"GET\", exception, None))\n\n\n    def test_retryIfFailedDueToNonCancelException(self):\n        \"\"\"\n        If a request failed with L{ResponseNeverReceived} due to some\n        arbitrary exception, C{_shouldRetry} returns C{True} to indicate the\n        request should be retried.\n        \"\"\"\n        pool = client.HTTPConnectionPool(None)\n        connection = client._RetryingHTTP11ClientProtocol(None, pool)\n        self.assertTrue(connection._shouldRetry(\n            b\"GET\", ResponseNeverReceived([Failure(Exception())]), None))\n\n\n    def test_wrappedOnPersistentReturned(self):\n        \"\"\"\n        If L{client.HTTPConnectionPool.getConnection} returns a previously\n        cached connection, it will get wrapped in a\n        L{client._RetryingHTTP11ClientProtocol}.\n        \"\"\"\n        pool = client.HTTPConnectionPool(Clock())\n\n        # Add a connection to the cache:\n        protocol = StubHTTPProtocol()\n        protocol.makeConnection(StringTransport())\n        pool._putConnection(123, protocol)\n\n        # Retrieve it, it should come back wrapped in a\n        # _RetryingHTTP11ClientProtocol:\n        d = pool.getConnection(123, DummyEndpoint())\n\n        def gotConnection(connection):\n            self.assertIsInstance(connection,\n                                  client._RetryingHTTP11ClientProtocol)\n            self.assertIdentical(connection._clientProtocol, protocol)\n        return d.addCallback(gotConnection)\n\n\n    def test_notWrappedOnNewReturned(self):\n        \"\"\"\n        If L{client.HTTPConnectionPool.getConnection} returns a new\n        connection, it will be returned as is.\n        \"\"\"\n        pool = client.HTTPConnectionPool(None)\n        d = pool.getConnection(123, DummyEndpoint())\n\n        def gotConnection(connection):\n            # Don't want to use isinstance since potentially the wrapper might\n            # subclass it at some point:\n            self.assertIdentical(connection.__class__, HTTP11ClientProtocol)\n        return d.addCallback(gotConnection)\n\n\n    def retryAttempt(self, willWeRetry):\n        \"\"\"\n        Fail a first request, possibly retrying depending on argument.\n        \"\"\"\n        protocols = []\n        def newProtocol():\n            protocol = StubHTTPProtocol()\n            protocols.append(protocol)\n            return defer.succeed(protocol)\n\n        bodyProducer = object()\n        request = client.Request(b\"FOO\", b\"/\", client.Headers(), bodyProducer,\n                                 persistent=True)\n        newProtocol()\n        protocol = protocols[0]\n        retrier = client._RetryingHTTP11ClientProtocol(protocol, newProtocol)\n\n        def _shouldRetry(m, e, bp):\n            self.assertEqual(m, b\"FOO\")\n            self.assertIdentical(bp, bodyProducer)\n            self.assertIsInstance(e, (RequestNotSent, ResponseNeverReceived))\n            return willWeRetry\n        retrier._shouldRetry = _shouldRetry\n\n        d = retrier.request(request)\n\n        # So far, one request made:\n        self.assertEqual(len(protocols), 1)\n        self.assertEqual(len(protocols[0].requests), 1)\n\n        # Fail the first request:\n        protocol.requests[0][1].errback(RequestNotSent())\n        return d, protocols\n\n\n    def test_retryIfShouldRetryReturnsTrue(self):\n        \"\"\"\n        L{client._RetryingHTTP11ClientProtocol} retries when\n        L{client._RetryingHTTP11ClientProtocol._shouldRetry} returns C{True}.\n        \"\"\"\n        d, protocols = self.retryAttempt(True)\n        # We retried!\n        self.assertEqual(len(protocols), 2)\n        response = object()\n        protocols[1].requests[0][1].callback(response)\n        return d.addCallback(self.assertIdentical, response)\n\n\n    def test_dontRetryIfShouldRetryReturnsFalse(self):\n        \"\"\"\n        L{client._RetryingHTTP11ClientProtocol} does not retry when\n        L{client._RetryingHTTP11ClientProtocol._shouldRetry} returns C{False}.\n        \"\"\"\n        d, protocols = self.retryAttempt(False)\n        # We did not retry:\n        self.assertEqual(len(protocols), 1)\n        return self.assertFailure(d, RequestNotSent)\n\n\n    def test_onlyRetryWithoutBody(self):\n        \"\"\"\n        L{_RetryingHTTP11ClientProtocol} only retries queries that don't have\n        a body.\n\n        This is an implementation restriction; if the restriction is fixed,\n        this test should be removed and PUT added to list of methods that\n        support retries.\n        \"\"\"\n        pool = client.HTTPConnectionPool(None)\n        connection = client._RetryingHTTP11ClientProtocol(None, pool)\n        self.assertTrue(connection._shouldRetry(b\"GET\", RequestNotSent(), None))\n        self.assertFalse(connection._shouldRetry(b\"GET\", RequestNotSent(), object()))\n\n\n    def test_onlyRetryOnce(self):\n        \"\"\"\n        If a L{client._RetryingHTTP11ClientProtocol} fails more than once on\n        an idempotent query before a response is received, it will not retry.\n        \"\"\"\n        d, protocols = self.retryAttempt(True)\n        self.assertEqual(len(protocols), 2)\n        # Fail the second request too:\n        protocols[1].requests[0][1].errback(ResponseNeverReceived([]))\n        # We didn't retry again:\n        self.assertEqual(len(protocols), 2)\n        return self.assertFailure(d, ResponseNeverReceived)\n\n\n    def test_dontRetryIfRetryAutomaticallyFalse(self):\n        \"\"\"\n        If L{HTTPConnectionPool.retryAutomatically} is set to C{False}, don't\n        wrap connections with retrying logic.\n        \"\"\"\n        pool = client.HTTPConnectionPool(Clock())\n        pool.retryAutomatically = False\n\n        # Add a connection to the cache:\n        protocol = StubHTTPProtocol()\n        protocol.makeConnection(StringTransport())\n        pool._putConnection(123, protocol)\n\n        # Retrieve it, it should come back unwrapped:\n        d = pool.getConnection(123, DummyEndpoint())\n\n        def gotConnection(connection):\n            self.assertIdentical(connection, protocol)\n        return d.addCallback(gotConnection)\n\n\n    def test_retryWithNewConnection(self):\n        \"\"\"\n        L{client.HTTPConnectionPool} creates\n        {client._RetryingHTTP11ClientProtocol} with a new connection factory\n        method that creates a new connection using the same key and endpoint\n        as the wrapped connection.\n        \"\"\"\n        pool = client.HTTPConnectionPool(Clock())\n        key = 123\n        endpoint = DummyEndpoint()\n        newConnections = []\n\n        # Override the pool's _newConnection:\n        def newConnection(k, e):\n            newConnections.append((k, e))\n        pool._newConnection = newConnection\n\n        # Add a connection to the cache:\n        protocol = StubHTTPProtocol()\n        protocol.makeConnection(StringTransport())\n        pool._putConnection(key, protocol)\n\n        # Retrieve it, it should come back wrapped in a\n        # _RetryingHTTP11ClientProtocol:\n        d = pool.getConnection(key, endpoint)\n\n        def gotConnection(connection):\n            self.assertIsInstance(connection,\n                                  client._RetryingHTTP11ClientProtocol)\n            self.assertIdentical(connection._clientProtocol, protocol)\n            # Verify that the _newConnection method on retrying connection\n            # calls _newConnection on the pool:\n            self.assertEqual(newConnections, [])\n            connection._newConnection()\n            self.assertEqual(len(newConnections), 1)\n            self.assertEqual(newConnections[0][0], key)\n            self.assertIdentical(newConnections[0][1], endpoint)\n        return d.addCallback(gotConnection)\n\n\n\nclass CookieTestsMixin(object):\n    \"\"\"\n    Mixin for unit tests dealing with cookies.\n    \"\"\"\n    def addCookies(self, cookieJar, uri, cookies):\n        \"\"\"\n        Add a cookie to a cookie jar.\n        \"\"\"\n        response = client._FakeUrllib2Response(\n            client.Response(\n                (b'HTTP', 1, 1),\n                200,\n                b'OK',\n                client.Headers({b'Set-Cookie': cookies}),\n                None))\n        request = client._FakeUrllib2Request(uri)\n        cookieJar.extract_cookies(response, request)\n        return request, response\n\n\n\nclass CookieJarTests(TestCase, CookieTestsMixin):\n    \"\"\"\n    Tests for L{twisted.web.client._FakeUrllib2Response} and\n    L{twisted.web.client._FakeUrllib2Request}'s interactions with\n    C{cookielib.CookieJar} instances.\n    \"\"\"\n    def makeCookieJar(self):\n        \"\"\"\n        @return: a C{cookielib.CookieJar} with some sample cookies\n        \"\"\"\n        cookieJar = cookielib.CookieJar()\n        reqres = self.addCookies(\n            cookieJar,\n            b'http://example.com:1234/foo?bar',\n            [b'foo=1; cow=moo; Path=/foo; Comment=hello',\n             b'bar=2; Comment=goodbye'])\n        return cookieJar, reqres\n\n\n    def test_extractCookies(self):\n        \"\"\"\n        L{cookielib.CookieJar.extract_cookies} extracts cookie information from\n        fake urllib2 response instances.\n        \"\"\"\n        jar = self.makeCookieJar()[0]\n        cookies = dict([(c.name, c) for c in jar])\n\n        cookie = cookies['foo']\n        self.assertEqual(cookie.version, 0)\n        self.assertEqual(cookie.name, 'foo')\n        self.assertEqual(cookie.value, '1')\n        self.assertEqual(cookie.path, '/foo')\n        self.assertEqual(cookie.comment, 'hello')\n        self.assertEqual(cookie.get_nonstandard_attr('cow'), 'moo')\n\n        cookie = cookies['bar']\n        self.assertEqual(cookie.version, 0)\n        self.assertEqual(cookie.name, 'bar')\n        self.assertEqual(cookie.value, '2')\n        self.assertEqual(cookie.path, '/')\n        self.assertEqual(cookie.comment, 'goodbye')\n        self.assertIdentical(cookie.get_nonstandard_attr('cow'), None)\n\n\n    def test_sendCookie(self):\n        \"\"\"\n        L{cookielib.CookieJar.add_cookie_header} adds a cookie header to a fake\n        urllib2 request instance.\n        \"\"\"\n        jar, (request, response) = self.makeCookieJar()\n\n        self.assertIdentical(\n            request.get_header('Cookie', None),\n            None)\n\n        jar.add_cookie_header(request)\n        self.assertEqual(\n            request.get_header('Cookie', None),\n            'foo=1; bar=2')\n\n\n\nclass CookieAgentTests(TestCase, CookieTestsMixin, FakeReactorAndConnectMixin,\n                       AgentTestsMixin):\n    \"\"\"\n    Tests for L{twisted.web.client.CookieAgent}.\n    \"\"\"\n    def makeAgent(self):\n        \"\"\"\n        @return: a new L{twisted.web.client.CookieAgent}\n        \"\"\"\n        return client.CookieAgent(\n            self.buildAgentForWrapperTest(self.reactor),\n            cookielib.CookieJar())\n\n\n    def setUp(self):\n        self.reactor = self.createReactor()\n\n\n    def test_emptyCookieJarRequest(self):\n        \"\"\"\n        L{CookieAgent.request} does not insert any C{'Cookie'} header into the\n        L{Request} object if there is no cookie in the cookie jar for the URI\n        being requested. Cookies are extracted from the response and stored in\n        the cookie jar.\n        \"\"\"\n        cookieJar = cookielib.CookieJar()\n        self.assertEqual(list(cookieJar), [])\n\n        agent = self.buildAgentForWrapperTest(self.reactor)\n        cookieAgent = client.CookieAgent(agent, cookieJar)\n        d = cookieAgent.request(\n            b'GET', b'http://example.com:1234/foo?bar')\n\n        def _checkCookie(ignored):\n            cookies = list(cookieJar)\n            self.assertEqual(len(cookies), 1)\n            self.assertEqual(cookies[0].name, 'foo')\n            self.assertEqual(cookies[0].value, '1')\n\n        d.addCallback(_checkCookie)\n\n        req, res = self.protocol.requests.pop()\n        self.assertIdentical(req.headers.getRawHeaders(b'cookie'), None)\n\n        resp = client.Response(\n            (b'HTTP', 1, 1),\n            200,\n            b'OK',\n            client.Headers({b'Set-Cookie': [b'foo=1',]}),\n            None)\n        res.callback(resp)\n\n        return d\n\n\n    def test_requestWithCookie(self):\n        \"\"\"\n        L{CookieAgent.request} inserts a C{'Cookie'} header into the L{Request}\n        object when there is a cookie matching the request URI in the cookie\n        jar.\n        \"\"\"\n        uri = b'http://example.com:1234/foo?bar'\n        cookie = b'foo=1'\n\n        cookieJar = cookielib.CookieJar()\n        self.addCookies(cookieJar, uri, [cookie])\n        self.assertEqual(len(list(cookieJar)), 1)\n\n        agent = self.buildAgentForWrapperTest(self.reactor)\n        cookieAgent = client.CookieAgent(agent, cookieJar)\n        cookieAgent.request(b'GET', uri)\n\n        req, res = self.protocol.requests.pop()\n        self.assertEqual(req.headers.getRawHeaders(b'cookie'), [cookie])\n\n\n    def test_secureCookie(self):\n        \"\"\"\n        L{CookieAgent} is able to handle secure cookies, ie cookies which\n        should only be handled over https.\n        \"\"\"\n        uri = b'https://example.com:1234/foo?bar'\n        cookie = b'foo=1;secure'\n\n        cookieJar = cookielib.CookieJar()\n        self.addCookies(cookieJar, uri, [cookie])\n        self.assertEqual(len(list(cookieJar)), 1)\n\n        agent = self.buildAgentForWrapperTest(self.reactor)\n        cookieAgent = client.CookieAgent(agent, cookieJar)\n        cookieAgent.request(b'GET', uri)\n\n        req, res = self.protocol.requests.pop()\n        self.assertEqual(req.headers.getRawHeaders(b'cookie'), [b'foo=1'])\n\n    test_secureCookie.skip = skipWhenNoSSL\n\n\n    def test_secureCookieOnInsecureConnection(self):\n        \"\"\"\n        If a cookie is setup as secure, it won't be sent with the request if\n        it's not over HTTPS.\n        \"\"\"\n        uri = b'http://example.com/foo?bar'\n        cookie = b'foo=1;secure'\n\n        cookieJar = cookielib.CookieJar()\n        self.addCookies(cookieJar, uri, [cookie])\n        self.assertEqual(len(list(cookieJar)), 1)\n\n        agent = self.buildAgentForWrapperTest(self.reactor)\n        cookieAgent = client.CookieAgent(agent, cookieJar)\n        cookieAgent.request(b'GET', uri)\n\n        req, res = self.protocol.requests.pop()\n        self.assertIdentical(None, req.headers.getRawHeaders(b'cookie'))\n\n\n    def test_portCookie(self):\n        \"\"\"\n        L{CookieAgent} supports cookies which enforces the port number they\n        need to be transferred upon.\n        \"\"\"\n        uri = b'http://example.com:1234/foo?bar'\n        cookie = b'foo=1;port=1234'\n\n        cookieJar = cookielib.CookieJar()\n        self.addCookies(cookieJar, uri, [cookie])\n        self.assertEqual(len(list(cookieJar)), 1)\n\n        agent = self.buildAgentForWrapperTest(self.reactor)\n        cookieAgent = client.CookieAgent(agent, cookieJar)\n        cookieAgent.request(b'GET', uri)\n\n        req, res = self.protocol.requests.pop()\n        self.assertEqual(req.headers.getRawHeaders(b'cookie'), [b'foo=1'])\n\n\n    def test_portCookieOnWrongPort(self):\n        \"\"\"\n        When creating a cookie with a port directive, it won't be added to the\n        L{cookie.CookieJar} if the URI is on a different port.\n        \"\"\"\n        uri = b'http://example.com:4567/foo?bar'\n        cookie = b'foo=1;port=1234'\n\n        cookieJar = cookielib.CookieJar()\n        self.addCookies(cookieJar, uri, [cookie])\n        self.assertEqual(len(list(cookieJar)), 0)\n\n\n\nclass Decoder1(proxyForInterface(IResponse)):\n    \"\"\"\n    A test decoder to be used by L{client.ContentDecoderAgent} tests.\n    \"\"\"\n\n\n\nclass Decoder2(Decoder1):\n    \"\"\"\n    A test decoder to be used by L{client.ContentDecoderAgent} tests.\n    \"\"\"\n\n\n\nclass ContentDecoderAgentTests(TestCase, FakeReactorAndConnectMixin,\n                               AgentTestsMixin):\n    \"\"\"\n    Tests for L{client.ContentDecoderAgent}.\n    \"\"\"\n    def makeAgent(self):\n        \"\"\"\n        @return: a new L{twisted.web.client.ContentDecoderAgent}\n        \"\"\"\n        return client.ContentDecoderAgent(self.agent, [])\n\n\n    def setUp(self):\n        \"\"\"\n        Create an L{Agent} wrapped around a fake reactor.\n        \"\"\"\n        self.reactor = self.createReactor()\n        self.agent = self.buildAgentForWrapperTest(self.reactor)\n\n\n    def test_acceptHeaders(self):\n        \"\"\"\n        L{client.ContentDecoderAgent} sets the I{Accept-Encoding} header to the\n        names of the available decoder objects.\n        \"\"\"\n        agent = client.ContentDecoderAgent(\n            self.agent, [(b'decoder1', Decoder1), (b'decoder2', Decoder2)])\n\n        agent.request(b'GET', b'http://example.com/foo')\n\n        protocol = self.protocol\n\n        self.assertEqual(len(protocol.requests), 1)\n        req, res = protocol.requests.pop()\n        self.assertEqual(req.headers.getRawHeaders(b'accept-encoding'),\n                         [b'decoder1,decoder2'])\n\n\n    def test_existingHeaders(self):\n        \"\"\"\n        If there are existing I{Accept-Encoding} fields,\n        L{client.ContentDecoderAgent} creates a new field for the decoders it\n        knows about.\n        \"\"\"\n        headers = http_headers.Headers({b'foo': [b'bar'],\n                                        b'accept-encoding': [b'fizz']})\n        agent = client.ContentDecoderAgent(\n            self.agent, [(b'decoder1', Decoder1), (b'decoder2', Decoder2)])\n        agent.request(b'GET', b'http://example.com/foo', headers=headers)\n\n        protocol = self.protocol\n\n        self.assertEqual(len(protocol.requests), 1)\n        req, res = protocol.requests.pop()\n        self.assertEqual(\n            list(sorted(req.headers.getAllRawHeaders())),\n            [(b'Accept-Encoding', [b'fizz', b'decoder1,decoder2']),\n             (b'Foo', [b'bar']),\n             (b'Host', [b'example.com'])])\n\n\n    def test_plainEncodingResponse(self):\n        \"\"\"\n        If the response is not encoded despited the request I{Accept-Encoding}\n        headers, L{client.ContentDecoderAgent} simply forwards the response.\n        \"\"\"\n        agent = client.ContentDecoderAgent(\n            self.agent, [(b'decoder1', Decoder1), (b'decoder2', Decoder2)])\n        deferred = agent.request(b'GET', b'http://example.com/foo')\n\n        req, res = self.protocol.requests.pop()\n\n        response = Response((b'HTTP', 1, 1), 200, b'OK', http_headers.Headers(),\n                            None)\n        res.callback(response)\n\n        return deferred.addCallback(self.assertIdentical, response)\n\n\n    def test_unsupportedEncoding(self):\n        \"\"\"\n        If an encoding unknown to the L{client.ContentDecoderAgent} is found,\n        the response is unchanged.\n        \"\"\"\n        agent = client.ContentDecoderAgent(\n            self.agent, [(b'decoder1', Decoder1), (b'decoder2', Decoder2)])\n        deferred = agent.request(b'GET', b'http://example.com/foo')\n\n        req, res = self.protocol.requests.pop()\n\n        headers = http_headers.Headers({b'foo': [b'bar'],\n                                        b'content-encoding': [b'fizz']})\n        response = Response((b'HTTP', 1, 1), 200, b'OK', headers, None)\n        res.callback(response)\n\n        return deferred.addCallback(self.assertIdentical, response)\n\n\n    def test_unknownEncoding(self):\n        \"\"\"\n        When L{client.ContentDecoderAgent} encounters a decoder it doesn't know\n        about, it stops decoding even if another encoding is known afterwards.\n        \"\"\"\n        agent = client.ContentDecoderAgent(\n            self.agent, [(b'decoder1', Decoder1), (b'decoder2', Decoder2)])\n        deferred = agent.request(b'GET', b'http://example.com/foo')\n\n        req, res = self.protocol.requests.pop()\n\n        headers = http_headers.Headers({b'foo': [b'bar'],\n                                        b'content-encoding':\n                                        [b'decoder1,fizz,decoder2']})\n        response = Response((b'HTTP', 1, 1), 200, b'OK', headers, None)\n        res.callback(response)\n\n        def check(result):\n            self.assertNotIdentical(response, result)\n            self.assertIsInstance(result, Decoder2)\n            self.assertEqual([b'decoder1,fizz'],\n                             result.headers.getRawHeaders(b'content-encoding'))\n\n        return deferred.addCallback(check)\n\n\n\nclass SimpleAgentProtocol(Protocol):\n    \"\"\"\n    A L{Protocol} to be used with an L{client.Agent} to receive data.\n\n    @ivar finished: L{Deferred} firing when C{connectionLost} is called.\n\n    @ivar made: L{Deferred} firing when C{connectionMade} is called.\n\n    @ivar received: C{list} of received data.\n    \"\"\"\n\n    def __init__(self):\n        self.made = Deferred()\n        self.finished = Deferred()\n        self.received = []\n\n\n    def connectionMade(self):\n        self.made.callback(None)\n\n\n    def connectionLost(self, reason):\n        self.finished.callback(None)\n\n\n    def dataReceived(self, data):\n        self.received.append(data)\n\n\n\nclass ContentDecoderAgentWithGzipTests(TestCase,\n                                       FakeReactorAndConnectMixin):\n\n    def setUp(self):\n        \"\"\"\n        Create an L{Agent} wrapped around a fake reactor.\n        \"\"\"\n        self.reactor = self.createReactor()\n        agent = self.buildAgentForWrapperTest(self.reactor)\n        self.agent = client.ContentDecoderAgent(\n            agent, [(b\"gzip\", client.GzipDecoder)])\n\n\n    def test_gzipEncodingResponse(self):\n        \"\"\"\n        If the response has a C{gzip} I{Content-Encoding} header,\n        L{GzipDecoder} wraps the response to return uncompressed data to the\n        user.\n        \"\"\"\n        deferred = self.agent.request(b'GET', b'http://example.com/foo')\n\n        req, res = self.protocol.requests.pop()\n\n        headers = http_headers.Headers({b'foo': [b'bar'],\n                                        b'content-encoding': [b'gzip']})\n        transport = StringTransport()\n        response = Response((b'HTTP', 1, 1), 200, b'OK', headers, transport)\n        response.length = 12\n        res.callback(response)\n\n        compressor = zlib.compressobj(2, zlib.DEFLATED, 16 + zlib.MAX_WBITS)\n        data = (compressor.compress(b'x' * 6) + compressor.compress(b'y' * 4) +\n                compressor.flush())\n\n        def checkResponse(result):\n            self.assertNotIdentical(result, response)\n            self.assertEqual(result.version, (b'HTTP', 1, 1))\n            self.assertEqual(result.code, 200)\n            self.assertEqual(result.phrase, b'OK')\n            self.assertEqual(list(result.headers.getAllRawHeaders()),\n                              [(b'Foo', [b'bar'])])\n            self.assertEqual(result.length, UNKNOWN_LENGTH)\n            self.assertRaises(AttributeError, getattr, result, 'unknown')\n\n            response._bodyDataReceived(data[:5])\n            response._bodyDataReceived(data[5:])\n            response._bodyDataFinished()\n\n            protocol = SimpleAgentProtocol()\n            result.deliverBody(protocol)\n\n            self.assertEqual(protocol.received, [b'x' * 6 + b'y' * 4])\n            return defer.gatherResults([protocol.made, protocol.finished])\n\n        deferred.addCallback(checkResponse)\n\n        return deferred\n\n\n    def test_brokenContent(self):\n        \"\"\"\n        If the data received by the L{GzipDecoder} isn't valid gzip-compressed\n        data, the call to C{deliverBody} fails with a C{zlib.error}.\n        \"\"\"\n        deferred = self.agent.request(b'GET', b'http://example.com/foo')\n\n        req, res = self.protocol.requests.pop()\n\n        headers = http_headers.Headers({b'foo': [b'bar'],\n                                        b'content-encoding': [b'gzip']})\n        transport = StringTransport()\n        response = Response((b'HTTP', 1, 1), 200, b'OK', headers, transport)\n        response.length = 12\n        res.callback(response)\n\n        data = b\"not gzipped content\"\n\n        def checkResponse(result):\n            response._bodyDataReceived(data)\n\n            result.deliverBody(Protocol())\n\n        deferred.addCallback(checkResponse)\n        self.assertFailure(deferred, client.ResponseFailed)\n\n        def checkFailure(error):\n            error.reasons[0].trap(zlib.error)\n            self.assertIsInstance(error.response, Response)\n\n        return deferred.addCallback(checkFailure)\n\n\n    def test_flushData(self):\n        \"\"\"\n        When the connection with the server is lost, the gzip protocol calls\n        C{flush} on the zlib decompressor object to get uncompressed data which\n        may have been buffered.\n        \"\"\"\n        class decompressobj(object):\n\n            def __init__(self, wbits):\n                pass\n\n            def decompress(self, data):\n                return b'x'\n\n            def flush(self):\n                return b'y'\n\n\n        oldDecompressObj = zlib.decompressobj\n        zlib.decompressobj = decompressobj\n        self.addCleanup(setattr, zlib, 'decompressobj', oldDecompressObj)\n\n        deferred = self.agent.request(b'GET', b'http://example.com/foo')\n\n        req, res = self.protocol.requests.pop()\n\n        headers = http_headers.Headers({b'content-encoding': [b'gzip']})\n        transport = StringTransport()\n        response = Response((b'HTTP', 1, 1), 200, b'OK', headers, transport)\n        res.callback(response)\n\n        def checkResponse(result):\n            response._bodyDataReceived(b'data')\n            response._bodyDataFinished()\n\n            protocol = SimpleAgentProtocol()\n            result.deliverBody(protocol)\n\n            self.assertEqual(protocol.received, [b'x', b'y'])\n            return defer.gatherResults([protocol.made, protocol.finished])\n\n        deferred.addCallback(checkResponse)\n\n        return deferred\n\n\n    def test_flushError(self):\n        \"\"\"\n        If the C{flush} call in C{connectionLost} fails, the C{zlib.error}\n        exception is caught and turned into a L{ResponseFailed}.\n        \"\"\"\n        class decompressobj(object):\n\n            def __init__(self, wbits):\n                pass\n\n            def decompress(self, data):\n                return b'x'\n\n            def flush(self):\n                raise zlib.error()\n\n\n        oldDecompressObj = zlib.decompressobj\n        zlib.decompressobj = decompressobj\n        self.addCleanup(setattr, zlib, 'decompressobj', oldDecompressObj)\n\n        deferred = self.agent.request(b'GET', b'http://example.com/foo')\n\n        req, res = self.protocol.requests.pop()\n\n        headers = http_headers.Headers({b'content-encoding': [b'gzip']})\n        transport = StringTransport()\n        response = Response((b'HTTP', 1, 1), 200, b'OK', headers, transport)\n        res.callback(response)\n\n        def checkResponse(result):\n            response._bodyDataReceived(b'data')\n            response._bodyDataFinished()\n\n            protocol = SimpleAgentProtocol()\n            result.deliverBody(protocol)\n\n            self.assertEqual(protocol.received, [b'x', b'y'])\n            return defer.gatherResults([protocol.made, protocol.finished])\n\n        deferred.addCallback(checkResponse)\n\n        self.assertFailure(deferred, client.ResponseFailed)\n\n        def checkFailure(error):\n            error.reasons[1].trap(zlib.error)\n            self.assertIsInstance(error.response, Response)\n\n        return deferred.addCallback(checkFailure)\n\n\n\nclass ProxyAgentTests(TestCase, FakeReactorAndConnectMixin, AgentTestsMixin):\n    \"\"\"\n    Tests for L{client.ProxyAgent}.\n    \"\"\"\n    def makeAgent(self):\n        \"\"\"\n        @return: a new L{twisted.web.client.ProxyAgent}\n        \"\"\"\n        return client.ProxyAgent(\n            TCP4ClientEndpoint(self.reactor, \"127.0.0.1\", 1234),\n            self.reactor)\n\n\n    def setUp(self):\n        self.reactor = self.createReactor()\n        self.agent = client.ProxyAgent(\n            TCP4ClientEndpoint(self.reactor, \"bar\", 5678), self.reactor)\n        oldEndpoint = self.agent._proxyEndpoint\n        self.agent._proxyEndpoint = self.StubEndpoint(oldEndpoint, self)\n\n\n    def test_nonBytesMethod(self):\n        \"\"\"\n        L{ProxyAgent.request} raises L{TypeError} when the C{method} argument\n        isn't L{bytes}.\n        \"\"\"\n        self.assertRaises(TypeError, self.agent.request,\n                          u'GET', b'http://foo.example/')\n\n\n    def test_proxyRequest(self):\n        \"\"\"\n        L{client.ProxyAgent} issues an HTTP request against the proxy, with the\n        full URI as path, when C{request} is called.\n        \"\"\"\n        headers = http_headers.Headers({b'foo': [b'bar']})\n        # Just going to check the body for identity, so it doesn't need to be\n        # real.\n        body = object()\n        self.agent.request(\n            b'GET', b'http://example.com:1234/foo?bar', headers, body)\n\n        host, port, factory = self.reactor.tcpClients.pop()[:3]\n        self.assertEqual(host, \"bar\")\n        self.assertEqual(port, 5678)\n\n        self.assertIsInstance(factory._wrappedFactory,\n                              client._HTTP11ClientFactory)\n\n        protocol = self.protocol\n\n        # The request should be issued.\n        self.assertEqual(len(protocol.requests), 1)\n        req, res = protocol.requests.pop()\n        self.assertIsInstance(req, Request)\n        self.assertEqual(req.method, b'GET')\n        self.assertEqual(req.uri, b'http://example.com:1234/foo?bar')\n        self.assertEqual(\n            req.headers,\n            http_headers.Headers({b'foo': [b'bar'],\n                                  b'host': [b'example.com:1234']}))\n        self.assertIdentical(req.bodyProducer, body)\n\n\n    def test_nonPersistent(self):\n        \"\"\"\n        C{ProxyAgent} connections are not persistent by default.\n        \"\"\"\n        self.assertEqual(self.agent._pool.persistent, False)\n\n\n    def test_connectUsesConnectionPool(self):\n        \"\"\"\n        When a connection is made by the C{ProxyAgent}, it uses its pool's\n        C{getConnection} method to do so, with the endpoint it was constructed\n        with and a key of C{(\"http-proxy\", endpoint)}.\n        \"\"\"\n        endpoint = DummyEndpoint()\n        class DummyPool(object):\n            connected = False\n            persistent = False\n            def getConnection(this, key, ep):\n                this.connected = True\n                self.assertIdentical(ep, endpoint)\n                # The key is *not* tied to the final destination, but only to\n                # the address of the proxy, since that's where *we* are\n                # connecting:\n                self.assertEqual(key, (\"http-proxy\", endpoint))\n                return defer.succeed(StubHTTPProtocol())\n\n        pool = DummyPool()\n        agent = client.ProxyAgent(endpoint, self.reactor, pool=pool)\n        self.assertIdentical(pool, agent._pool)\n\n        agent.request(b'GET', b'http://foo/')\n        self.assertEqual(agent._pool.connected, True)\n\n\n\nclass _RedirectAgentTestsMixin(object):\n    \"\"\"\n    Test cases mixin for L{RedirectAgentTests} and\n    L{BrowserLikeRedirectAgentTests}.\n    \"\"\"\n    def test_noRedirect(self):\n        \"\"\"\n        L{client.RedirectAgent} behaves like L{client.Agent} if the response\n        doesn't contain a redirect.\n        \"\"\"\n        deferred = self.agent.request(b'GET', b'http://example.com/foo')\n\n        req, res = self.protocol.requests.pop()\n\n        headers = http_headers.Headers()\n        response = Response((b'HTTP', 1, 1), 200, b'OK', headers, None)\n        res.callback(response)\n\n        self.assertEqual(0, len(self.protocol.requests))\n        result = self.successResultOf(deferred)\n        self.assertIdentical(response, result)\n        self.assertIdentical(result.previousResponse, None)\n\n\n    def _testRedirectDefault(self, code):\n        \"\"\"\n        When getting a redirect, L{client.RedirectAgent} follows the URL\n        specified in the L{Location} header field and make a new request.\n\n        @param code: HTTP status code.\n        \"\"\"\n        self.agent.request(b'GET', b'http://example.com/foo')\n\n        host, port = self.reactor.tcpClients.pop()[:2]\n        self.assertEqual(EXAMPLE_COM_IP, host)\n        self.assertEqual(80, port)\n\n        req, res = self.protocol.requests.pop()\n\n        # If possible (i.e.: SSL support is present), run the test with a\n        # cross-scheme redirect to verify that the scheme is honored; if not,\n        # let's just make sure it works at all.\n        if ssl is None:\n            scheme = b'http'\n            expectedPort = 80\n        else:\n            scheme = b'https'\n            expectedPort = 443\n\n        headers = http_headers.Headers(\n            {b'location': [scheme + b'://example.com/bar']})\n        response = Response((b'HTTP', 1, 1), code, b'OK', headers, None)\n        res.callback(response)\n\n        req2, res2 = self.protocol.requests.pop()\n        self.assertEqual(b'GET', req2.method)\n        self.assertEqual(b'/bar', req2.uri)\n\n        host, port = self.reactor.tcpClients.pop()[:2]\n        self.assertEqual(EXAMPLE_COM_IP, host)\n        self.assertEqual(expectedPort, port)\n\n\n    def test_redirect301(self):\n        \"\"\"\n        L{client.RedirectAgent} follows redirects on status code 301.\n        \"\"\"\n        self._testRedirectDefault(301)\n\n\n    def test_redirect302(self):\n        \"\"\"\n        L{client.RedirectAgent} follows redirects on status code 302.\n        \"\"\"\n        self._testRedirectDefault(302)\n\n\n    def test_redirect307(self):\n        \"\"\"\n        L{client.RedirectAgent} follows redirects on status code 307.\n        \"\"\"\n        self._testRedirectDefault(307)\n\n\n    def _testRedirectToGet(self, code, method):\n        \"\"\"\n        L{client.RedirectAgent} changes the method to I{GET} when getting\n        a redirect on a non-I{GET} request.\n\n        @param code: HTTP status code.\n\n        @param method: HTTP request method.\n        \"\"\"\n        self.agent.request(method, b'http://example.com/foo')\n\n        req, res = self.protocol.requests.pop()\n\n        headers = http_headers.Headers(\n            {b'location': [b'http://example.com/bar']})\n        response = Response((b'HTTP', 1, 1), code, b'OK', headers, None)\n        res.callback(response)\n\n        req2, res2 = self.protocol.requests.pop()\n        self.assertEqual(b'GET', req2.method)\n        self.assertEqual(b'/bar', req2.uri)\n\n\n    def test_redirect303(self):\n        \"\"\"\n        L{client.RedirectAgent} changes the method to I{GET} when getting a 303\n        redirect on a I{POST} request.\n        \"\"\"\n        self._testRedirectToGet(303, b'POST')\n\n\n    def test_noLocationField(self):\n        \"\"\"\n        If no L{Location} header field is found when getting a redirect,\n        L{client.RedirectAgent} fails with a L{ResponseFailed} error wrapping a\n        L{error.RedirectWithNoLocation} exception.\n        \"\"\"\n        deferred = self.agent.request(b'GET', b'http://example.com/foo')\n\n        req, res = self.protocol.requests.pop()\n\n        headers = http_headers.Headers()\n        response = Response((b'HTTP', 1, 1), 301, b'OK', headers, None)\n        res.callback(response)\n\n        fail = self.failureResultOf(deferred, client.ResponseFailed)\n        fail.value.reasons[0].trap(error.RedirectWithNoLocation)\n        self.assertEqual(b'http://example.com/foo',\n                         fail.value.reasons[0].value.uri)\n        self.assertEqual(301, fail.value.response.code)\n\n\n    def _testPageRedirectFailure(self, code, method):\n        \"\"\"\n        When getting a redirect on an unsupported request method,\n        L{client.RedirectAgent} fails with a L{ResponseFailed} error wrapping\n        a L{error.PageRedirect} exception.\n\n        @param code: HTTP status code.\n\n        @param method: HTTP request method.\n        \"\"\"\n        deferred = self.agent.request(method, b'http://example.com/foo')\n\n        req, res = self.protocol.requests.pop()\n\n        headers = http_headers.Headers()\n        response = Response((b'HTTP', 1, 1), code, b'OK', headers, None)\n        res.callback(response)\n\n        fail = self.failureResultOf(deferred, client.ResponseFailed)\n        fail.value.reasons[0].trap(error.PageRedirect)\n        self.assertEqual(b'http://example.com/foo',\n                         fail.value.reasons[0].value.location)\n        self.assertEqual(code, fail.value.response.code)\n\n\n    def test_307OnPost(self):\n        \"\"\"\n        When getting a 307 redirect on a I{POST} request,\n        L{client.RedirectAgent} fails with a L{ResponseFailed} error wrapping\n        a L{error.PageRedirect} exception.\n        \"\"\"\n        self._testPageRedirectFailure(307, b'POST')\n\n\n    def test_redirectLimit(self):\n        \"\"\"\n        If the limit of redirects specified to L{client.RedirectAgent} is\n        reached, the deferred fires with L{ResponseFailed} error wrapping\n        a L{InfiniteRedirection} exception.\n        \"\"\"\n        agent = self.buildAgentForWrapperTest(self.reactor)\n        redirectAgent = client.RedirectAgent(agent, 1)\n\n        deferred = redirectAgent.request(b'GET', b'http://example.com/foo')\n\n        req, res = self.protocol.requests.pop()\n\n        headers = http_headers.Headers(\n            {b'location': [b'http://example.com/bar']})\n        response = Response((b'HTTP', 1, 1), 302, b'OK', headers, None)\n        res.callback(response)\n\n        req2, res2 = self.protocol.requests.pop()\n\n        response2 = Response((b'HTTP', 1, 1), 302, b'OK', headers, None)\n        res2.callback(response2)\n\n        fail = self.failureResultOf(deferred, client.ResponseFailed)\n\n        fail.value.reasons[0].trap(error.InfiniteRedirection)\n        self.assertEqual(b'http://example.com/foo',\n                         fail.value.reasons[0].value.location)\n        self.assertEqual(302, fail.value.response.code)\n\n\n    def _testRedirectURI(self, uri, location, finalURI):\n        \"\"\"\n        When L{client.RedirectAgent} encounters a relative redirect I{URI}, it\n        is resolved against the request I{URI} before following the redirect.\n\n        @param uri: Request URI.\n\n        @param location: I{Location} header redirect URI.\n\n        @param finalURI: Expected final URI.\n        \"\"\"\n        self.agent.request(b'GET', uri)\n\n        req, res = self.protocol.requests.pop()\n\n        headers = http_headers.Headers(\n            {b'location': [location]})\n        response = Response((b'HTTP', 1, 1), 302, b'OK', headers, None)\n        res.callback(response)\n\n        req2, res2 = self.protocol.requests.pop()\n        self.assertEqual(b'GET', req2.method)\n        self.assertEqual(finalURI, req2.absoluteURI)\n\n\n    def test_relativeURI(self):\n        \"\"\"\n        L{client.RedirectAgent} resolves and follows relative I{URI}s in\n        redirects, preserving query strings.\n        \"\"\"\n        self._testRedirectURI(\n            b'http://example.com/foo/bar', b'baz',\n            b'http://example.com/foo/baz')\n        self._testRedirectURI(\n            b'http://example.com/foo/bar', b'/baz',\n            b'http://example.com/baz')\n        self._testRedirectURI(\n            b'http://example.com/foo/bar', b'/baz?a',\n            b'http://example.com/baz?a')\n\n\n    def test_relativeURIPreserveFragments(self):\n        \"\"\"\n        L{client.RedirectAgent} resolves and follows relative I{URI}s in\n        redirects, preserving fragments in way that complies with the HTTP 1.1\n        bis draft.\n\n        @see: U{https://tools.ietf.org/html/draft-ietf-httpbis-p2-semantics-22#section-7.1.2}\n        \"\"\"\n        self._testRedirectURI(\n            b'http://example.com/foo/bar#frag', b'/baz?a',\n            b'http://example.com/baz?a#frag')\n        self._testRedirectURI(\n            b'http://example.com/foo/bar', b'/baz?a#frag2',\n            b'http://example.com/baz?a#frag2')\n\n\n    def test_relativeURISchemeRelative(self):\n        \"\"\"\n        L{client.RedirectAgent} resolves and follows scheme relative I{URI}s in\n        redirects, replacing the hostname and port when required.\n        \"\"\"\n        self._testRedirectURI(\n            b'http://example.com/foo/bar', b'//foo.com/baz',\n            b'http://foo.com/baz')\n        self._testRedirectURI(\n            b'http://example.com/foo/bar', b'//foo.com:81/baz',\n            b'http://foo.com:81/baz')\n\n\n    def test_responseHistory(self):\n        \"\"\"\n        L{Response.response} references the previous L{Response} from\n        a redirect, or L{None} if there was no previous response.\n        \"\"\"\n        agent = self.buildAgentForWrapperTest(self.reactor)\n        redirectAgent = client.RedirectAgent(agent)\n\n        deferred = redirectAgent.request(b'GET', b'http://example.com/foo')\n\n        redirectReq, redirectRes = self.protocol.requests.pop()\n\n        headers = http_headers.Headers(\n            {b'location': [b'http://example.com/bar']})\n        redirectResponse = Response((b'HTTP', 1, 1), 302, b'OK', headers, None)\n        redirectRes.callback(redirectResponse)\n\n        req, res = self.protocol.requests.pop()\n\n        response = Response((b'HTTP', 1, 1), 200, b'OK', headers, None)\n        res.callback(response)\n\n        finalResponse = self.successResultOf(deferred)\n        self.assertIdentical(finalResponse.previousResponse, redirectResponse)\n        self.assertIdentical(redirectResponse.previousResponse, None)\n\n\n\nclass RedirectAgentTests(TestCase, FakeReactorAndConnectMixin,\n                         _RedirectAgentTestsMixin, AgentTestsMixin):\n    \"\"\"\n    Tests for L{client.RedirectAgent}.\n    \"\"\"\n    def makeAgent(self):\n        \"\"\"\n        @return: a new L{twisted.web.client.RedirectAgent}\n        \"\"\"\n        return client.RedirectAgent(\n            self.buildAgentForWrapperTest(self.reactor))\n\n\n    def setUp(self):\n        self.reactor = self.createReactor()\n        self.agent = self.makeAgent()\n\n\n    def test_301OnPost(self):\n        \"\"\"\n        When getting a 301 redirect on a I{POST} request,\n        L{client.RedirectAgent} fails with a L{ResponseFailed} error wrapping\n        a L{error.PageRedirect} exception.\n        \"\"\"\n        self._testPageRedirectFailure(301, b'POST')\n\n\n    def test_302OnPost(self):\n        \"\"\"\n        When getting a 302 redirect on a I{POST} request,\n        L{client.RedirectAgent} fails with a L{ResponseFailed} error wrapping\n        a L{error.PageRedirect} exception.\n        \"\"\"\n        self._testPageRedirectFailure(302, b'POST')\n\n\n\nclass BrowserLikeRedirectAgentTests(TestCase,\n                                    FakeReactorAndConnectMixin,\n                                    _RedirectAgentTestsMixin,\n                                    AgentTestsMixin):\n    \"\"\"\n    Tests for L{client.BrowserLikeRedirectAgent}.\n    \"\"\"\n    def makeAgent(self):\n        \"\"\"\n        @return: a new L{twisted.web.client.BrowserLikeRedirectAgent}\n        \"\"\"\n        return client.BrowserLikeRedirectAgent(\n            self.buildAgentForWrapperTest(self.reactor))\n\n\n    def setUp(self):\n        self.reactor = self.createReactor()\n        self.agent = self.makeAgent()\n\n\n    def test_redirectToGet301(self):\n        \"\"\"\n        L{client.BrowserLikeRedirectAgent} changes the method to I{GET} when\n        getting a 302 redirect on a I{POST} request.\n        \"\"\"\n        self._testRedirectToGet(301, b'POST')\n\n\n    def test_redirectToGet302(self):\n        \"\"\"\n        L{client.BrowserLikeRedirectAgent} changes the method to I{GET} when\n        getting a 302 redirect on a I{POST} request.\n        \"\"\"\n        self._testRedirectToGet(302, b'POST')\n\n\n\nclass AbortableStringTransport(StringTransport):\n    \"\"\"\n    A version of L{StringTransport} that supports C{abortConnection}.\n    \"\"\"\n    # This should be replaced by a common version in #6530.\n    aborting = False\n\n\n    def abortConnection(self):\n        \"\"\"\n        A testable version of the C{ITCPTransport.abortConnection} method.\n\n        Since this is a special case of closing the connection,\n        C{loseConnection} is also called.\n        \"\"\"\n        self.aborting = True\n        self.loseConnection()\n\n\n\nclass DummyResponse(object):\n    \"\"\"\n    Fake L{IResponse} for testing readBody that captures the protocol passed to\n    deliverBody and uses it to make a connection with a transport.\n\n    @ivar protocol: After C{deliverBody} is called, the protocol it was called\n        with.\n\n    @ivar transport: An instance created by calling C{transportFactory} which\n        is used by L{DummyResponse.protocol} to make a connection.\n    \"\"\"\n\n    code = 200\n    phrase = b\"OK\"\n\n    def __init__(self, headers=None, transportFactory=AbortableStringTransport):\n        \"\"\"\n        @param headers: The headers for this response.  If L{None}, an empty\n            L{Headers} instance will be used.\n        @type headers: L{Headers}\n\n        @param transportFactory: A callable used to construct the transport.\n        \"\"\"\n        if headers is None:\n            headers = Headers()\n        self.headers = headers\n        self.transport = transportFactory()\n\n\n    def deliverBody(self, protocol):\n        \"\"\"\n        Record the given protocol and use it to make a connection with\n        L{DummyResponse.transport}.\n        \"\"\"\n        self.protocol = protocol\n        self.protocol.makeConnection(self.transport)\n\n\n\nclass AlreadyCompletedDummyResponse(DummyResponse):\n    \"\"\"\n    A dummy response that has already had its transport closed.\n    \"\"\"\n    def deliverBody(self, protocol):\n        \"\"\"\n        Make the connection, then remove the transport.\n        \"\"\"\n        self.protocol = protocol\n        self.protocol.makeConnection(self.transport)\n        self.protocol.transport = None\n\n\n\nclass ReadBodyTests(TestCase):\n    \"\"\"\n    Tests for L{client.readBody}\n    \"\"\"\n    def test_success(self):\n        \"\"\"\n        L{client.readBody} returns a L{Deferred} which fires with the complete\n        body of the L{IResponse} provider passed to it.\n        \"\"\"\n        response = DummyResponse()\n        d = client.readBody(response)\n        response.protocol.dataReceived(b\"first\")\n        response.protocol.dataReceived(b\"second\")\n        response.protocol.connectionLost(Failure(ResponseDone()))\n        self.assertEqual(self.successResultOf(d), b\"firstsecond\")\n\n\n    def test_cancel(self):\n        \"\"\"\n        When cancelling the L{Deferred} returned by L{client.readBody}, the\n        connection to the server will be aborted.\n        \"\"\"\n        response = DummyResponse()\n        deferred = client.readBody(response)\n        deferred.cancel()\n        self.failureResultOf(deferred, defer.CancelledError)\n        self.assertTrue(response.transport.aborting)\n\n\n    def test_withPotentialDataLoss(self):\n        \"\"\"\n        If the full body of the L{IResponse} passed to L{client.readBody} is\n        not definitely received, the L{Deferred} returned by L{client.readBody}\n        fires with a L{Failure} wrapping L{client.PartialDownloadError} with\n        the content that was received.\n        \"\"\"\n        response = DummyResponse()\n        d = client.readBody(response)\n        response.protocol.dataReceived(b\"first\")\n        response.protocol.dataReceived(b\"second\")\n        response.protocol.connectionLost(Failure(PotentialDataLoss()))\n        failure = self.failureResultOf(d)\n        failure.trap(client.PartialDownloadError)\n        self.assertEqual({\n            \"status\": failure.value.status,\n            \"message\": failure.value.message,\n            \"body\": failure.value.response,\n        }, {\n            \"status\": b\"200\",\n            \"message\": b\"OK\",\n            \"body\": b\"firstsecond\",\n        })\n\n\n    def test_otherErrors(self):\n        \"\"\"\n        If there is an exception other than L{client.PotentialDataLoss} while\n        L{client.readBody} is collecting the response body, the L{Deferred}\n        returned by {client.readBody} fires with that exception.\n        \"\"\"\n        response = DummyResponse()\n        d = client.readBody(response)\n        response.protocol.dataReceived(b\"first\")\n        response.protocol.connectionLost(\n            Failure(ConnectionLost(\"mystery problem\")))\n        reason = self.failureResultOf(d)\n        reason.trap(ConnectionLost)\n        self.assertEqual(reason.value.args, (\"mystery problem\",))\n\n\n    def test_deprecatedTransport(self):\n        \"\"\"\n        Calling L{client.readBody} with a transport that does not implement\n        L{twisted.internet.interfaces.ITCPTransport} produces a deprecation\n        warning, but no exception when cancelling.\n        \"\"\"\n        response = DummyResponse(transportFactory=StringTransport)\n        response.transport.abortConnection = None\n        d = self.assertWarns(\n            DeprecationWarning,\n            'Using readBody with a transport that does not have an '\n            'abortConnection method',\n            __file__,\n            lambda: client.readBody(response))\n        d.cancel()\n        self.failureResultOf(d, defer.CancelledError)\n\n\n    def test_deprecatedTransportNoWarning(self):\n        \"\"\"\n        Calling L{client.readBody} with a response that has already had its\n        transport closed (eg. for a very small request) will not trigger a\n        deprecation warning.\n        \"\"\"\n        response = AlreadyCompletedDummyResponse()\n        client.readBody(response)\n\n        warnings = self.flushWarnings()\n        self.assertEqual(len(warnings), 0)\n\n\n\nclass HostnameCachingHTTPSPolicyTests(TestCase):\n\n    skip = skipWhenNoSSL\n\n    def test_cacheIsUsed(self):\n        \"\"\"\n        Verify that the connection creator is added to the\n        policy's cache, and that it is reused on subsequent calls\n        to creatorForNetLoc.\n\n        \"\"\"\n        trustRoot = CustomOpenSSLTrustRoot()\n        wrappedPolicy = BrowserLikePolicyForHTTPS(trustRoot=trustRoot)\n        policy = HostnameCachingHTTPSPolicy(wrappedPolicy)\n        creator = policy.creatorForNetloc(b\"foo\", 1589)\n        self.assertTrue(trustRoot.called)\n        trustRoot.called = False\n        self.assertEquals(1, len(policy._cache))\n        connection = creator.clientConnectionForTLS(None)\n        self.assertIs(trustRoot.context, connection.get_context())\n\n        policy.creatorForNetloc(b\"foo\", 1589)\n        self.assertFalse(trustRoot.called)\n\n\n    def test_cacheRemovesOldest(self):\n        \"\"\"\n        Verify that when the cache is full, and a new entry is added,\n        the oldest entry is removed.\n        \"\"\"\n        trustRoot = CustomOpenSSLTrustRoot()\n        wrappedPolicy = BrowserLikePolicyForHTTPS(trustRoot=trustRoot)\n        policy = HostnameCachingHTTPSPolicy(wrappedPolicy)\n        for i in range(0, 20):\n            hostname = u\"host\" + unicode(i)\n            policy.creatorForNetloc(hostname.encode(\"ascii\"), 8675)\n\n        # Force host0, which was the first, to be the most recently used\n        host0 = u\"host0\"\n        policy.creatorForNetloc(host0.encode(\"ascii\"), 309)\n        self.assertIn(host0, policy._cache)\n        self.assertEquals(20, len(policy._cache))\n\n        hostn = u\"new\"\n        policy.creatorForNetloc(hostn.encode(\"ascii\"), 309)\n\n        host1 = u\"host1\"\n        self.assertNotIn(host1, policy._cache)\n        self.assertEquals(20, len(policy._cache))\n\n        self.assertIn(hostn, policy._cache)\n        self.assertIn(host0, policy._cache)\n\n        # Accessing an item repeatedly does not corrupt the LRU.\n        for _ in range(20):\n            policy.creatorForNetloc(host0.encode(\"ascii\"), 8675)\n\n        hostNPlus1 = u\"new1\"\n\n        policy.creatorForNetloc(hostNPlus1.encode(\"ascii\"), 800)\n\n        self.assertNotIn(u\"host2\", policy._cache)\n        self.assertEquals(20, len(policy._cache))\n\n        self.assertIn(hostNPlus1, policy._cache)\n        self.assertIn(hostn, policy._cache)\n        self.assertIn(host0, policy._cache)\n\n\n    def test_changeCacheSize(self):\n        \"\"\"\n        Verify that changing the cache size results in a policy that\n        respects the new cache size and not the default.\n\n        \"\"\"\n        trustRoot = CustomOpenSSLTrustRoot()\n        wrappedPolicy = BrowserLikePolicyForHTTPS(trustRoot=trustRoot)\n        policy = HostnameCachingHTTPSPolicy(wrappedPolicy, cacheSize=5)\n        for i in range(0, 5):\n            hostname = u\"host\" + unicode(i)\n            policy.creatorForNetloc(hostname.encode(\"ascii\"), 8675)\n\n        first = u\"host0\"\n        self.assertIn(first, policy._cache)\n        self.assertEquals(5, len(policy._cache))\n\n        hostn = u\"new\"\n        policy.creatorForNetloc(hostn.encode(\"ascii\"), 309)\n        self.assertNotIn(first, policy._cache)\n        self.assertEquals(5, len(policy._cache))\n\n        self.assertIn(hostn, policy._cache)\n", "patch": "@@ -11,7 +11,7 @@\n \n from zope.interface.verify import verifyObject\n \n-from twisted.trial.unittest import TestCase\n+from twisted.trial.unittest import TestCase, SynchronousTestCase\n from twisted.web import client, error, http_headers\n from twisted.web._newclient import RequestNotSent, RequestTransmissionFailed\n from twisted.web._newclient import ResponseNeverReceived, ResponseFailed\n@@ -51,6 +51,10 @@\n from twisted.test.proto_helpers import AccumulatingProtocol\n from twisted.test.iosim import IOPump, FakeTransport\n from twisted.test.test_sslverify import certificatesForAuthorityAndServer\n+from twisted.web.test.injectionhelpers import (\n+    MethodInjectionTestsMixin,\n+    URIInjectionTestsMixin,\n+)\n from twisted.web.error import SchemeNotSupported\n from twisted.logger import globalLogPublisher\n \n@@ -897,6 +901,7 @@ class AgentTests(TestCase, FakeReactorAndConnectMixin, AgentTestsMixin,\n     \"\"\"\n     Tests for the new HTTP client API provided by L{Agent}.\n     \"\"\"\n+\n     def makeAgent(self):\n         \"\"\"\n         @return: a new L{twisted.web.client.Agent} instance\n@@ -1327,6 +1332,48 @@ def test_endpointFactoryPool(self):\n \n \n \n+class AgentMethodInjectionTests(\n+        FakeReactorAndConnectMixin,\n+        MethodInjectionTestsMixin,\n+        SynchronousTestCase,\n+):\n+    \"\"\"\n+    Test L{client.Agent} against HTTP method injections.\n+    \"\"\"\n+\n+    def attemptRequestWithMaliciousMethod(self, method):\n+        \"\"\"\n+        Attempt a request with the provided method.\n+\n+        @param method: see L{MethodInjectionTestsMixin}\n+        \"\"\"\n+        agent = client.Agent(self.createReactor())\n+        uri = b\"http://twisted.invalid\"\n+        agent.request(method, uri, client.Headers(), None)\n+\n+\n+\n+class AgentURIInjectionTests(\n+        FakeReactorAndConnectMixin,\n+        URIInjectionTestsMixin,\n+        SynchronousTestCase,\n+):\n+    \"\"\"\n+    Test L{client.Agent} against URI injections.\n+    \"\"\"\n+\n+    def attemptRequestWithMaliciousURI(self, uri):\n+        \"\"\"\n+        Attempt a request with the provided method.\n+\n+        @param uri: see L{URIInjectionTestsMixin}\n+        \"\"\"\n+        agent = client.Agent(self.createReactor())\n+        method = b\"GET\"\n+        agent.request(method, uri, client.Headers(), None)\n+\n+\n+\n class AgentHTTPSTests(TestCase, FakeReactorAndConnectMixin,\n                       IntegrationTestingMixin):\n     \"\"\"\n@@ -3202,3 +3249,101 @@ def test_changeCacheSize(self):\n         self.assertEquals(5, len(policy._cache))\n \n         self.assertIn(hostn, policy._cache)\n+\n+\n+\n+class RequestMethodInjectionTests(\n+        MethodInjectionTestsMixin,\n+        SynchronousTestCase,\n+):\n+    \"\"\"\n+    Test L{client.Request} against HTTP method injections.\n+    \"\"\"\n+\n+    def attemptRequestWithMaliciousMethod(self, method):\n+        \"\"\"\n+        Attempt a request with the provided method.\n+\n+        @param method: see L{MethodInjectionTestsMixin}\n+        \"\"\"\n+        client.Request(\n+            method=method,\n+            uri=b\"http://twisted.invalid\",\n+            headers=http_headers.Headers(),\n+            bodyProducer=None,\n+        )\n+\n+\n+\n+class RequestWriteToMethodInjectionTests(\n+        MethodInjectionTestsMixin,\n+        SynchronousTestCase,\n+):\n+    \"\"\"\n+    Test L{client.Request.writeTo} against HTTP method injections.\n+    \"\"\"\n+\n+    def attemptRequestWithMaliciousMethod(self, method):\n+        \"\"\"\n+        Attempt a request with the provided method.\n+\n+        @param method: see L{MethodInjectionTestsMixin}\n+        \"\"\"\n+        headers = http_headers.Headers({b\"Host\": [b\"twisted.invalid\"]})\n+        req = client.Request(\n+            method=b\"GET\",\n+            uri=b\"http://twisted.invalid\",\n+            headers=headers,\n+            bodyProducer=None,\n+        )\n+        req.method = method\n+        req.writeTo(StringTransport())\n+\n+\n+\n+class RequestURIInjectionTests(\n+        URIInjectionTestsMixin,\n+        SynchronousTestCase,\n+):\n+    \"\"\"\n+    Test L{client.Request} against HTTP URI injections.\n+    \"\"\"\n+\n+    def attemptRequestWithMaliciousURI(self, uri):\n+        \"\"\"\n+        Attempt a request with the provided URI.\n+\n+        @param method: see L{URIInjectionTestsMixin}\n+        \"\"\"\n+        client.Request(\n+            method=b\"GET\",\n+            uri=uri,\n+            headers=http_headers.Headers(),\n+            bodyProducer=None,\n+        )\n+\n+\n+\n+class RequestWriteToURIInjectionTests(\n+        URIInjectionTestsMixin,\n+        SynchronousTestCase,\n+):\n+    \"\"\"\n+    Test L{client.Request.writeTo} against HTTP method injections.\n+    \"\"\"\n+\n+    def attemptRequestWithMaliciousURI(self, uri):\n+        \"\"\"\n+        Attempt a request with the provided method.\n+\n+        @param method: see L{URIInjectionTestsMixin}\n+        \"\"\"\n+        headers = http_headers.Headers({b\"Host\": [b\"twisted.invalid\"]})\n+        req = client.Request(\n+            method=b\"GET\",\n+            uri=b\"http://twisted.invalid\",\n+            headers=headers,\n+            bodyProducer=None,\n+        )\n+        req.uri = uri\n+        req.writeTo(StringTransport())", "file_path": "files/2019_6\\161", "file_language": "py", "file_name": "src/twisted/web/test/test_agent.py", "outdated_file_modify": 1, "outdated_file_before": 0, "outdated_file_after": 0, "llm_check": 1, "static_check": 0, "static": {"rats": [false, []], "semgrep": [false, []]}, "target": -1, "function_before": [], "function_after": []}, {"raw_url": "https://github.com/twisted/twisted/raw/6c61fc4503ae39ab8ecee52d10f10ee2c371d7e2/src%2Ftwisted%2Fweb%2Ftest%2Ftest_webclient.py", "code": "# Copyright (c) Twisted Matrix Laboratories.\n# See LICENSE for details.\n\n\"\"\"\nTests for the old L{twisted.web.client} APIs, C{getPage} and friends.\n\"\"\"\n\nfrom __future__ import division, absolute_import\n\nimport io\nimport os\nfrom errno import ENOSPC\n\ntry:\n    from urlparse import urlparse, urljoin\nexcept ImportError:\n    from urllib.parse import urlparse, urljoin\n\nfrom twisted.python.compat import networkString, nativeString, intToBytes\nfrom twisted.trial import unittest, util\nfrom twisted.web import server, client, error, resource\nfrom twisted.web.static import Data\nfrom twisted.web.util import Redirect\nfrom twisted.internet import address, reactor, defer, interfaces\nfrom twisted.internet.protocol import ClientFactory\nfrom twisted.python.filepath import FilePath\nfrom twisted.protocols.policies import WrappingFactory\nfrom twisted.test.proto_helpers import (\n    StringTransport, waitUntilAllDisconnected, EventLoggingObserver)\n\ntry:\n    from twisted.internet import ssl\nexcept:\n    ssl = None\n\nfrom twisted import test\nfrom twisted.logger import (globalLogPublisher, FilteringLogObserver,\n                            LogLevelFilterPredicate, LogLevel, Logger)\n\nfrom twisted.web.test.injectionhelpers import (\n    MethodInjectionTestsMixin,\n    URIInjectionTestsMixin,\n)\n\n\n\nserverPEM = FilePath(test.__file__).sibling('server.pem')\nserverPEMPath = serverPEM.asBytesMode().path\n\n\nclass ExtendedRedirect(resource.Resource):\n    \"\"\"\n    Redirection resource.\n\n    The HTTP status code is set according to the C{code} query parameter.\n\n    @type lastMethod: C{bytes}\n    @ivar lastMethod: Last handled HTTP request method\n    \"\"\"\n    isLeaf = True\n    lastMethod = None\n\n\n    def __init__(self, url):\n        resource.Resource.__init__(self)\n        self.url = url\n\n\n    def render(self, request):\n        if self.lastMethod:\n            self.lastMethod = request.method\n            return b\"OK Thnx!\"\n        else:\n            self.lastMethod = request.method\n            code = int(request.args[b'code'][0])\n            return self.redirectTo(self.url, request, code)\n\n\n    def getChild(self, name, request):\n        return self\n\n\n    def redirectTo(self, url, request, code):\n        request.setResponseCode(code)\n        request.setHeader(b\"location\", url)\n        return b\"OK Bye!\"\n\n\n\nclass ForeverTakingResource(resource.Resource):\n    \"\"\"\n    L{ForeverTakingResource} is a resource which never finishes responding\n    to requests.\n    \"\"\"\n    def __init__(self, write=False):\n        resource.Resource.__init__(self)\n        self._write = write\n\n    def render(self, request):\n        if self._write:\n            request.write(b'some bytes')\n        return server.NOT_DONE_YET\n\n\nclass ForeverTakingNoReadingResource(resource.Resource):\n    \"\"\"\n    L{ForeverTakingNoReadingResource} is a resource that never finishes\n    responding and that removes itself from the read loop.\n    \"\"\"\n    def __init__(self):\n        resource.Resource.__init__(self)\n\n    def render(self, request):\n        # Stop the producing.\n        request.transport.pauseProducing()\n        return server.NOT_DONE_YET\n\n\nclass CookieMirrorResource(resource.Resource):\n    def render(self, request):\n        l = []\n        for k,v in sorted(list(request.received_cookies.items())):\n            l.append((nativeString(k), nativeString(v)))\n        l.sort()\n        return networkString(repr(l))\n\nclass RawCookieMirrorResource(resource.Resource):\n    def render(self, request):\n        header = request.getHeader(b'cookie')\n        if header is None:\n            return b'None'\n        return networkString(repr(nativeString(header)))\n\nclass ErrorResource(resource.Resource):\n\n    def render(self, request):\n        request.setResponseCode(401)\n        if request.args.get(b\"showlength\"):\n            request.setHeader(b\"content-length\", b\"0\")\n        return b\"\"\n\nclass NoLengthResource(resource.Resource):\n\n    def render(self, request):\n        return b\"nolength\"\n\n\n\nclass HostHeaderResource(resource.Resource):\n    \"\"\"\n    A testing resource which renders itself as the value of the host header\n    from the request.\n    \"\"\"\n    def render(self, request):\n        return request.requestHeaders.getRawHeaders(b\"host\")[0]\n\n\n\nclass PayloadResource(resource.Resource):\n    \"\"\"\n    A testing resource which renders itself as the contents of the request body\n    as long as the request body is 100 bytes long, otherwise which renders\n    itself as C{\"ERROR\"}.\n    \"\"\"\n    def render(self, request):\n        data = request.content.read()\n        contentLength = request.requestHeaders.getRawHeaders(b\"content-length\")[0]\n        if len(data) != 100 or int(contentLength) != 100:\n            return b\"ERROR\"\n        return data\n\n\nclass DelayResource(resource.Resource):\n\n    def __init__(self, seconds):\n        self.seconds = seconds\n\n    def render(self, request):\n        def response():\n            request.write(b'some bytes')\n            request.finish()\n        reactor.callLater(self.seconds, response)\n        return server.NOT_DONE_YET\n\n\nclass BrokenDownloadResource(resource.Resource):\n\n    def render(self, request):\n        # only sends 3 bytes even though it claims to send 5\n        request.setHeader(b\"content-length\", b\"5\")\n        request.write(b'abc')\n        return b''\n\nclass CountingRedirect(Redirect):\n    \"\"\"\n    A L{Redirect} resource that keeps track of the number of times the\n    resource has been accessed.\n    \"\"\"\n    def __init__(self, *a, **kw):\n        Redirect.__init__(self, *a, **kw)\n        self.count = 0\n\n    def render(self, request):\n        self.count += 1\n        return Redirect.render(self, request)\n\n\nclass CountingResource(resource.Resource):\n    \"\"\"\n    A resource that keeps track of the number of times it has been accessed.\n    \"\"\"\n    def __init__(self):\n        resource.Resource.__init__(self)\n        self.count = 0\n\n    def render(self, request):\n        self.count += 1\n        return b\"Success\"\n\n\n\nclass URLJoinTests(unittest.TestCase):\n    \"\"\"\n    Tests for L{client._urljoin}.\n    \"\"\"\n    def test_noFragments(self):\n        \"\"\"\n        L{client._urljoin} does not include a fragment identifier in the\n        resulting URL if neither the base nor the new path include a fragment\n        identifier.\n        \"\"\"\n        self.assertEqual(\n            client._urljoin(b'http://foo.com/bar', b'/quux'),\n            b'http://foo.com/quux')\n        self.assertEqual(\n            client._urljoin(b'http://foo.com/bar#', b'/quux'),\n            b'http://foo.com/quux')\n        self.assertEqual(\n            client._urljoin(b'http://foo.com/bar', b'/quux#'),\n            b'http://foo.com/quux')\n\n\n    def test_preserveFragments(self):\n        \"\"\"\n        L{client._urljoin} preserves the fragment identifier from either the\n        new path or the base URL respectively, as specified in the HTTP 1.1 bis\n        draft.\n\n        @see: U{https://tools.ietf.org/html/draft-ietf-httpbis-p2-semantics-22#section-7.1.2}\n        \"\"\"\n        self.assertEqual(\n            client._urljoin(b'http://foo.com/bar#frag', b'/quux'),\n            b'http://foo.com/quux#frag')\n        self.assertEqual(\n            client._urljoin(b'http://foo.com/bar', b'/quux#frag2'),\n            b'http://foo.com/quux#frag2')\n        self.assertEqual(\n            client._urljoin(b'http://foo.com/bar#frag', b'/quux#frag2'),\n            b'http://foo.com/quux#frag2')\n\n\n\nclass HTTPPageGetterTests(unittest.TestCase):\n    \"\"\"\n    Tests for L{HTTPPagerGetter}, the HTTP client protocol implementation\n    used to implement L{getPage}.\n    \"\"\"\n    suppress = [util.suppress(category=DeprecationWarning)]\n\n\n    def test_earlyHeaders(self):\n        \"\"\"\n        When a connection is made, L{HTTPPagerGetter} sends the headers from\n        its factory's C{headers} dict.  If I{Host} or I{Content-Length} is\n        present in this dict, the values are not sent, since they are sent with\n        special values before the C{headers} dict is processed.  If\n        I{User-Agent} is present in the dict, it overrides the value of the\n        C{agent} attribute of the factory.  If I{Cookie} is present in the\n        dict, its value is added to the values from the factory's C{cookies}\n        attribute.\n        \"\"\"\n        factory = client.HTTPClientFactory(\n            b'http://foo/bar',\n            agent=b\"foobar\",\n            cookies={b'baz': b'quux'},\n            postdata=b\"some data\",\n            headers={\n                b'Host': b'example.net',\n                b'User-Agent': b'fooble',\n                b'Cookie': b'blah blah',\n                b'Content-Length': b'12981',\n                b'Useful': b'value'})\n        transport = StringTransport()\n        protocol = client.HTTPPageGetter()\n        protocol.factory = factory\n        protocol.makeConnection(transport)\n        result = transport.value()\n        for expectedHeader in [\n            b\"Host: example.net\\r\\n\",\n            b\"User-Agent: foobar\\r\\n\",\n            b\"Content-Length: 9\\r\\n\",\n            b\"Useful: value\\r\\n\",\n            b\"connection: close\\r\\n\",\n            b\"Cookie: blah blah; baz=quux\\r\\n\"]:\n            self.assertIn(expectedHeader, result)\n\n\n\nclass WebClientTests(unittest.TestCase):\n    suppress = [util.suppress(category=DeprecationWarning)]\n    _log = Logger()\n\n\n    def _listen(self, site):\n        return reactor.listenTCP(0, site, interface=\"127.0.0.1\")\n\n    def setUp(self):\n        self.agent = None # for twisted.web.client.Agent test\n        self.cleanupServerConnections = 0\n        r = resource.Resource()\n        r.putChild(b\"file\", Data(b\"0123456789\", \"text/html\"))\n        r.putChild(b\"redirect\", Redirect(b\"/file\"))\n        self.infiniteRedirectResource = CountingRedirect(b\"/infiniteRedirect\")\n        r.putChild(b\"infiniteRedirect\", self.infiniteRedirectResource)\n        r.putChild(b\"wait\", ForeverTakingResource())\n        r.putChild(b\"write-then-wait\", ForeverTakingResource(write=True))\n        r.putChild(b\"never-read\", ForeverTakingNoReadingResource())\n        r.putChild(b\"error\", ErrorResource())\n        r.putChild(b\"nolength\", NoLengthResource())\n        r.putChild(b\"host\", HostHeaderResource())\n        r.putChild(b\"payload\", PayloadResource())\n        r.putChild(b\"broken\", BrokenDownloadResource())\n        r.putChild(b\"cookiemirror\", CookieMirrorResource())\n        r.putChild(b'delay1', DelayResource(1))\n        r.putChild(b'delay2', DelayResource(2))\n\n        self.afterFoundGetCounter = CountingResource()\n        r.putChild(b\"afterFoundGetCounter\", self.afterFoundGetCounter)\n        r.putChild(b\"afterFoundGetRedirect\", Redirect(b\"/afterFoundGetCounter\"))\n\n        miscasedHead = Data(b\"miscased-head GET response content\", \"major/minor\")\n        miscasedHead.render_Head = lambda request: b\"miscased-head content\"\n        r.putChild(b\"miscased-head\", miscasedHead)\n\n        self.extendedRedirect = ExtendedRedirect(b'/extendedRedirect')\n        r.putChild(b\"extendedRedirect\", self.extendedRedirect)\n        self.site = server.Site(r, timeout=None)\n        self.wrapper = WrappingFactory(self.site)\n        self.port = self._listen(self.wrapper)\n        self.portno = self.port.getHost().port\n\n    def tearDown(self):\n        if self.agent:\n            # clean up connections for twisted.web.client.Agent test.\n            self.agent.closeCachedConnections()\n            self.agent = None\n\n        # If the test indicated it might leave some server-side connections\n        # around, clean them up.\n        connections = list(self.wrapper.protocols.keys())\n        # If there are fewer server-side connections than requested,\n        # that's okay.  Some might have noticed that the client closed\n        # the connection and cleaned up after themselves.\n        for n in range(min(len(connections), self.cleanupServerConnections)):\n            proto = connections.pop()\n            self._log.info(\"Closing {proto}\", proto=proto)\n            proto.transport.abortConnection()\n        d = self.port.stopListening()\n\n        return defer.DeferredList([waitUntilAllDisconnected(\n            reactor, list(self.wrapper.protocols.keys())), d])\n\n\n    def getURL(self, path):\n        host = \"http://127.0.0.1:%d/\" % self.portno\n        return networkString(urljoin(host, nativeString(path)))\n\n    def testPayload(self):\n        s = b\"0123456789\" * 10\n        return client.getPage(self.getURL(\"payload\"), postdata=s\n                              ).addCallback(self.assertEqual, s\n            )\n\n\n    def test_getPageBrokenDownload(self):\n        \"\"\"\n        If the connection is closed before the number of bytes indicated by\n        I{Content-Length} have been received, the L{Deferred} returned by\n        L{getPage} fails with L{PartialDownloadError}.\n        \"\"\"\n        d = client.getPage(self.getURL(\"broken\"))\n        d = self.assertFailure(d, client.PartialDownloadError)\n        d.addCallback(lambda exc: self.assertEqual(exc.response, b\"abc\"))\n        return d\n\n\n    def test_downloadPageBrokenDownload(self):\n        \"\"\"\n        If the connection is closed before the number of bytes indicated by\n        I{Content-Length} have been received, the L{Deferred} returned by\n        L{downloadPage} fails with L{PartialDownloadError}.\n        \"\"\"\n        # test what happens when download gets disconnected in the middle\n        path = FilePath(self.mktemp())\n        d = client.downloadPage(self.getURL(\"broken\"), path.path)\n        d = self.assertFailure(d, client.PartialDownloadError)\n\n        def checkResponse(response):\n            \"\"\"\n            The HTTP status code from the server is propagated through the\n            C{PartialDownloadError}.\n            \"\"\"\n            self.assertEqual(response.status, b\"200\")\n            self.assertEqual(response.message, b\"OK\")\n            return response\n        d.addCallback(checkResponse)\n\n        def cbFailed(ignored):\n            self.assertEqual(path.getContent(), b\"abc\")\n        d.addCallback(cbFailed)\n        return d\n\n\n    def test_downloadPageLogsFileCloseError(self):\n        \"\"\"\n        If there is an exception closing the file being written to after the\n        connection is prematurely closed, that exception is logged.\n        \"\"\"\n        exc = IOError(ENOSPC, \"No file left on device\")\n\n        class BrokenFile:\n            def write(self, bytes):\n                pass\n\n            def close(self):\n                raise exc\n\n        logObserver = EventLoggingObserver()\n        filtered = FilteringLogObserver(\n            logObserver,\n            [LogLevelFilterPredicate(defaultLogLevel=LogLevel.critical)]\n        )\n        globalLogPublisher.addObserver(filtered)\n        self.addCleanup(lambda: globalLogPublisher.removeObserver(filtered))\n\n        d = client.downloadPage(self.getURL(\"broken\"), BrokenFile())\n        d = self.assertFailure(d, client.PartialDownloadError)\n\n        def cbFailed(ignored):\n            self.assertEquals(1, len(logObserver))\n            event = logObserver[0]\n            f = event[\"log_failure\"]\n            self.assertIsInstance(f.value, IOError)\n            self.assertEquals(\n                f.value.args,\n                exc.args\n            )\n            self.assertEqual(len(self.flushLoggedErrors(IOError)), 1)\n\n        d.addCallback(cbFailed)\n        return d\n\n\n    def testHostHeader(self):\n        # if we pass Host header explicitly, it should be used, otherwise\n        # it should extract from url\n        return defer.gatherResults([\n            client.getPage(self.getURL(\"host\")).addCallback(\n                    self.assertEqual, b\"127.0.0.1:\" + intToBytes(self.portno)),\n            client.getPage(self.getURL(\"host\"),\n                           headers={b\"Host\": b\"www.example.com\"}).addCallback(\n                    self.assertEqual, b\"www.example.com\")])\n\n\n    def test_getPage(self):\n        \"\"\"\n        L{client.getPage} returns a L{Deferred} which is called back with\n        the body of the response if the default method B{GET} is used.\n        \"\"\"\n        d = client.getPage(self.getURL(\"file\"))\n        d.addCallback(self.assertEqual, b\"0123456789\")\n        return d\n\n\n    def test_getPageHEAD(self):\n        \"\"\"\n        L{client.getPage} returns a L{Deferred} which is called back with\n        the empty string if the method is I{HEAD} and there is a successful\n        response code.\n        \"\"\"\n        d = client.getPage(self.getURL(\"file\"), method=b\"HEAD\")\n        d.addCallback(self.assertEqual, b\"\")\n        return d\n\n\n    def test_getPageNotQuiteHEAD(self):\n        \"\"\"\n        If the request method is a different casing of I{HEAD} (ie, not all\n        capitalized) then it is not a I{HEAD} request and the response body\n        is returned.\n        \"\"\"\n        d = client.getPage(self.getURL(\"miscased-head\"), method=b'Head')\n        d.addCallback(self.assertEqual, b\"miscased-head content\")\n        return d\n\n\n    def test_timeoutNotTriggering(self):\n        \"\"\"\n        When a non-zero timeout is passed to L{getPage} and the page is\n        retrieved before the timeout period elapses, the L{Deferred} is\n        called back with the contents of the page.\n        \"\"\"\n        d = client.getPage(self.getURL(\"host\"), timeout=100)\n        d.addCallback(self.assertEqual,\n                      networkString(\"127.0.0.1:%s\" % (self.portno,)))\n        return d\n\n\n    def test_timeoutTriggering(self):\n        \"\"\"\n        When a non-zero timeout is passed to L{getPage} and that many\n        seconds elapse before the server responds to the request. the\n        L{Deferred} is errbacked with a L{error.TimeoutError}.\n        \"\"\"\n        # This will probably leave some connections around.\n        self.cleanupServerConnections = 1\n        return self.assertFailure(\n            client.getPage(self.getURL(\"wait\"), timeout=0.000001),\n            defer.TimeoutError)\n\n\n    def testDownloadPage(self):\n        downloads = []\n        downloadData = [(\"file\", self.mktemp(), b\"0123456789\"),\n                        (\"nolength\", self.mktemp(), b\"nolength\")]\n\n        for (url, name, data) in downloadData:\n            d = client.downloadPage(self.getURL(url), name)\n            d.addCallback(self._cbDownloadPageTest, data, name)\n            downloads.append(d)\n        return defer.gatherResults(downloads)\n\n    def _cbDownloadPageTest(self, ignored, data, name):\n        with open(name, \"rb\") as f:\n            bytes = f.read()\n        self.assertEqual(bytes, data)\n\n    def testDownloadPageError1(self):\n        class errorfile:\n            def write(self, data):\n                raise IOError(\"badness happened during write\")\n            def close(self):\n                pass\n        ef = errorfile()\n        return self.assertFailure(\n            client.downloadPage(self.getURL(\"file\"), ef),\n            IOError)\n\n    def testDownloadPageError2(self):\n        class errorfile:\n            def write(self, data):\n                pass\n            def close(self):\n                raise IOError(\"badness happened during close\")\n        ef = errorfile()\n        return self.assertFailure(\n            client.downloadPage(self.getURL(\"file\"), ef),\n            IOError)\n\n    def testDownloadPageError3(self):\n        # make sure failures in open() are caught too. This is tricky.\n        # Might only work on posix.\n        open(\"unwritable\", \"wb\").close()\n        os.chmod(\"unwritable\", 0) # make it unwritable (to us)\n        d = self.assertFailure(\n            client.downloadPage(self.getURL(\"file\"), \"unwritable\"),\n            IOError)\n        d.addBoth(self._cleanupDownloadPageError3)\n        return d\n\n    def _cleanupDownloadPageError3(self, ignored):\n        os.chmod(\"unwritable\", 0o700)\n        os.unlink(\"unwritable\")\n        return ignored\n\n    def _downloadTest(self, method):\n        dl = []\n        for (url, code) in [(\"nosuchfile\", b\"404\"), (\"error\", b\"401\"),\n                            (\"error?showlength=1\", b\"401\")]:\n            d = method(url)\n            d = self.assertFailure(d, error.Error)\n            d.addCallback(lambda exc, code=code: self.assertEqual(exc.args[0], code))\n            dl.append(d)\n        return defer.DeferredList(dl, fireOnOneErrback=True)\n\n    def testServerError(self):\n        return self._downloadTest(lambda url: client.getPage(self.getURL(url)))\n\n    def testDownloadServerError(self):\n        return self._downloadTest(lambda url: client.downloadPage(self.getURL(url), url.split('?')[0]))\n\n    def testFactoryInfo(self):\n        url = self.getURL('file')\n        uri = client.URI.fromBytes(url)\n        factory = client.HTTPClientFactory(url)\n        reactor.connectTCP(nativeString(uri.host), uri.port, factory)\n        return factory.deferred.addCallback(self._cbFactoryInfo, factory)\n\n    def _cbFactoryInfo(self, ignoredResult, factory):\n        self.assertEqual(factory.status, b'200')\n        self.assertTrue(factory.version.startswith(b'HTTP/'))\n        self.assertEqual(factory.message, b'OK')\n        self.assertEqual(factory.response_headers[b'content-length'][0], b'10')\n\n\n    def test_followRedirect(self):\n        \"\"\"\n        By default, L{client.getPage} follows redirects and returns the content\n        of the target resource.\n        \"\"\"\n        d = client.getPage(self.getURL(\"redirect\"))\n        d.addCallback(self.assertEqual, b\"0123456789\")\n        return d\n\n\n    def test_noFollowRedirect(self):\n        \"\"\"\n        If C{followRedirect} is passed a false value, L{client.getPage} does not\n        follow redirects and returns a L{Deferred} which fails with\n        L{error.PageRedirect} when it encounters one.\n        \"\"\"\n        d = self.assertFailure(\n            client.getPage(self.getURL(\"redirect\"), followRedirect=False),\n            error.PageRedirect)\n        d.addCallback(self._cbCheckLocation)\n        return d\n\n\n    def _cbCheckLocation(self, exc):\n        self.assertEqual(exc.location, b\"/file\")\n\n\n    def test_infiniteRedirection(self):\n        \"\"\"\n        When more than C{redirectLimit} HTTP redirects are encountered, the\n        page request fails with L{InfiniteRedirection}.\n        \"\"\"\n        def checkRedirectCount(*a):\n            self.assertEqual(f._redirectCount, 13)\n            self.assertEqual(self.infiniteRedirectResource.count, 13)\n\n        f = client._makeGetterFactory(\n            self.getURL('infiniteRedirect'),\n            client.HTTPClientFactory,\n            redirectLimit=13)\n        d = self.assertFailure(f.deferred, error.InfiniteRedirection)\n        d.addCallback(checkRedirectCount)\n        return d\n\n\n    def test_isolatedFollowRedirect(self):\n        \"\"\"\n        C{client.HTTPPagerGetter} instances each obey the C{followRedirect}\n        value passed to the L{client.getPage} call which created them.\n        \"\"\"\n        d1 = client.getPage(self.getURL('redirect'), followRedirect=True)\n        d2 = client.getPage(self.getURL('redirect'), followRedirect=False)\n\n        d = self.assertFailure(d2, error.PageRedirect\n            ).addCallback(lambda dummy: d1)\n        return d\n\n\n    def test_afterFoundGet(self):\n        \"\"\"\n        Enabling unsafe redirection behaviour overwrites the method of\n        redirected C{POST} requests with C{GET}.\n        \"\"\"\n        url = self.getURL('extendedRedirect?code=302')\n        f = client.HTTPClientFactory(url, followRedirect=True, method=b\"POST\")\n        self.assertFalse(\n            f.afterFoundGet,\n            \"By default, afterFoundGet must be disabled\")\n\n        def gotPage(page):\n            self.assertEqual(\n                self.extendedRedirect.lastMethod,\n                b\"GET\",\n                \"With afterFoundGet, the HTTP method must change to GET\")\n\n        d = client.getPage(\n            url, followRedirect=True, afterFoundGet=True, method=b\"POST\")\n        d.addCallback(gotPage)\n        return d\n\n\n    def test_downloadAfterFoundGet(self):\n        \"\"\"\n        Passing C{True} for C{afterFoundGet} to L{client.downloadPage} invokes\n        the same kind of redirect handling as passing that argument to\n        L{client.getPage} invokes.\n        \"\"\"\n        url = self.getURL('extendedRedirect?code=302')\n\n        def gotPage(page):\n            self.assertEqual(\n                self.extendedRedirect.lastMethod,\n                b\"GET\",\n                \"With afterFoundGet, the HTTP method must change to GET\")\n\n        d = client.downloadPage(url, \"downloadTemp\",\n            followRedirect=True, afterFoundGet=True, method=b\"POST\")\n        d.addCallback(gotPage)\n        return d\n\n\n    def test_afterFoundGetMakesOneRequest(self):\n        \"\"\"\n        When C{afterFoundGet} is C{True}, L{client.getPage} only issues one\n        request to the server when following the redirect.  This is a regression\n        test, see #4760.\n        \"\"\"\n        def checkRedirectCount(*a):\n            self.assertEqual(self.afterFoundGetCounter.count, 1)\n\n        url = self.getURL('afterFoundGetRedirect')\n        d = client.getPage(\n            url, followRedirect=True, afterFoundGet=True, method=b\"POST\")\n        d.addCallback(checkRedirectCount)\n        return d\n\n\n    def test_downloadTimeout(self):\n        \"\"\"\n        If the timeout indicated by the C{timeout} parameter to\n        L{client.HTTPDownloader.__init__} elapses without the complete response\n        being received, the L{defer.Deferred} returned by\n        L{client.downloadPage} fires with a L{Failure} wrapping a\n        L{defer.TimeoutError}.\n        \"\"\"\n        self.cleanupServerConnections = 2\n        # Verify the behavior if no bytes are ever written.\n        first = client.downloadPage(\n            self.getURL(\"wait\"),\n            self.mktemp(), timeout=0.01)\n\n        # Verify the behavior if some bytes are written but then the request\n        # never completes.\n        second = client.downloadPage(\n            self.getURL(\"write-then-wait\"),\n            self.mktemp(), timeout=0.01)\n\n        return defer.gatherResults([\n            self.assertFailure(first, defer.TimeoutError),\n            self.assertFailure(second, defer.TimeoutError)])\n\n\n    def test_downloadTimeoutsWorkWithoutReading(self):\n        \"\"\"\n        If the timeout indicated by the C{timeout} parameter to\n        L{client.HTTPDownloader.__init__} elapses without the complete response\n        being received, the L{defer.Deferred} returned by\n        L{client.downloadPage} fires with a L{Failure} wrapping a\n        L{defer.TimeoutError}, even if the remote peer isn't reading data from\n        the socket.\n        \"\"\"\n        self.cleanupServerConnections = 1\n\n        # The timeout here needs to be slightly longer to give the resource a\n        # change to stop the reading.\n        d = client.downloadPage(\n            self.getURL(\"never-read\"),\n            self.mktemp(), timeout=0.05)\n        return self.assertFailure(d, defer.TimeoutError)\n\n\n    def test_downloadHeaders(self):\n        \"\"\"\n        After L{client.HTTPDownloader.deferred} fires, the\n        L{client.HTTPDownloader} instance's C{status} and C{response_headers}\n        attributes are populated with the values from the response.\n        \"\"\"\n        def checkHeaders(factory):\n            self.assertEqual(factory.status, b'200')\n            self.assertEqual(factory.response_headers[b'content-type'][0], b'text/html')\n            self.assertEqual(factory.response_headers[b'content-length'][0], b'10')\n            os.unlink(factory.fileName)\n        factory = client._makeGetterFactory(\n            self.getURL('file'),\n            client.HTTPDownloader,\n            fileOrName=self.mktemp())\n        return factory.deferred.addCallback(lambda _: checkHeaders(factory))\n\n\n    def test_downloadCookies(self):\n        \"\"\"\n        The C{cookies} dict passed to the L{client.HTTPDownloader}\n        initializer is used to populate the I{Cookie} header included in the\n        request sent to the server.\n        \"\"\"\n        output = self.mktemp()\n        factory = client._makeGetterFactory(\n            self.getURL('cookiemirror'),\n            client.HTTPDownloader,\n            fileOrName=output,\n            cookies={b'foo': b'bar'})\n        def cbFinished(ignored):\n            self.assertEqual(\n                FilePath(output).getContent(),\n                b\"[('foo', 'bar')]\")\n        factory.deferred.addCallback(cbFinished)\n        return factory.deferred\n\n\n    def test_downloadRedirectLimit(self):\n        \"\"\"\n        When more than C{redirectLimit} HTTP redirects are encountered, the\n        page request fails with L{InfiniteRedirection}.\n        \"\"\"\n        def checkRedirectCount(*a):\n            self.assertEqual(f._redirectCount, 7)\n            self.assertEqual(self.infiniteRedirectResource.count, 7)\n\n        f = client._makeGetterFactory(\n            self.getURL('infiniteRedirect'),\n            client.HTTPDownloader,\n            fileOrName=self.mktemp(),\n            redirectLimit=7)\n        d = self.assertFailure(f.deferred, error.InfiniteRedirection)\n        d.addCallback(checkRedirectCount)\n        return d\n\n\n    def test_setURL(self):\n        \"\"\"\n        L{client.HTTPClientFactory.setURL} alters the scheme, host, port and\n        path for absolute URLs.\n        \"\"\"\n        url = b'http://example.com'\n        f = client.HTTPClientFactory(url)\n        self.assertEqual(\n            (url, b'http', b'example.com', 80, b'/'),\n            (f.url, f.scheme, f.host, f.port, f.path))\n\n\n    def test_setURLRemovesFragment(self):\n        \"\"\"\n        L{client.HTTPClientFactory.setURL} removes the fragment identifier from\n        the path component.\n        \"\"\"\n        f = client.HTTPClientFactory(b'http://example.com')\n        url = b'https://foo.com:8443/bar;123?a#frag'\n        f.setURL(url)\n        self.assertEqual(\n            (url, b'https', b'foo.com', 8443, b'/bar;123?a'),\n            (f.url, f.scheme, f.host, f.port, f.path))\n\n\n    def test_setURLRelativePath(self):\n        \"\"\"\n        L{client.HTTPClientFactory.setURL} alters the path in a relative URL.\n        \"\"\"\n        f = client.HTTPClientFactory(b'http://example.com')\n        url = b'/hello'\n        f.setURL(url)\n        self.assertEqual(\n            (url, b'http', b'example.com', 80, b'/hello'),\n            (f.url, f.scheme, f.host, f.port, f.path))\n\n\n\nclass WebClientSSLTests(WebClientTests):\n    def _listen(self, site):\n        return reactor.listenSSL(\n            0, site,\n            contextFactory=ssl.DefaultOpenSSLContextFactory(\n                serverPEMPath, serverPEMPath),\n            interface=\"127.0.0.1\")\n\n    def getURL(self, path):\n        return networkString(\"https://127.0.0.1:%d/%s\" % (self.portno, path))\n\n    def testFactoryInfo(self):\n        url = self.getURL('file')\n        uri = client.URI.fromBytes(url)\n        factory = client.HTTPClientFactory(url)\n        reactor.connectSSL(nativeString(uri.host), uri.port, factory,\n                           ssl.ClientContextFactory())\n        # The base class defines _cbFactoryInfo correctly for this\n        return factory.deferred.addCallback(self._cbFactoryInfo, factory)\n\n\n\nclass WebClientRedirectBetweenSSLandPlainTextTests(unittest.TestCase):\n    suppress = [util.suppress(category=DeprecationWarning)]\n\n\n    def getHTTPS(self, path):\n        return networkString(\"https://127.0.0.1:%d/%s\" % (self.tlsPortno, path))\n\n    def getHTTP(self, path):\n        return networkString(\"http://127.0.0.1:%d/%s\" % (self.plainPortno, path))\n\n    def setUp(self):\n        plainRoot = Data(b'not me', 'text/plain')\n        tlsRoot = Data(b'me neither', 'text/plain')\n\n        plainSite = server.Site(plainRoot, timeout=None)\n        tlsSite = server.Site(tlsRoot, timeout=None)\n\n        self.tlsPort = reactor.listenSSL(\n            0, tlsSite,\n            contextFactory=ssl.DefaultOpenSSLContextFactory(\n                serverPEMPath, serverPEMPath),\n            interface=\"127.0.0.1\")\n        self.plainPort = reactor.listenTCP(0, plainSite, interface=\"127.0.0.1\")\n\n        self.plainPortno = self.plainPort.getHost().port\n        self.tlsPortno = self.tlsPort.getHost().port\n\n        plainRoot.putChild(b'one', Redirect(self.getHTTPS('two')))\n        tlsRoot.putChild(b'two', Redirect(self.getHTTP('three')))\n        plainRoot.putChild(b'three', Redirect(self.getHTTPS('four')))\n        tlsRoot.putChild(b'four', Data(b'FOUND IT!', 'text/plain'))\n\n    def tearDown(self):\n        ds = list(\n            map(defer.maybeDeferred,\n                [self.plainPort.stopListening, self.tlsPort.stopListening]))\n        return defer.gatherResults(ds)\n\n    def testHoppingAround(self):\n        return client.getPage(self.getHTTP(\"one\")\n            ).addCallback(self.assertEqual, b\"FOUND IT!\"\n            )\n\n\nclass CookieTests(unittest.TestCase):\n    suppress = [util.suppress(category=DeprecationWarning)]\n\n\n    def _listen(self, site):\n        return reactor.listenTCP(0, site, interface=\"127.0.0.1\")\n\n    def setUp(self):\n        root = Data(b'El toro!', 'text/plain')\n        root.putChild(b\"cookiemirror\", CookieMirrorResource())\n        root.putChild(b\"rawcookiemirror\", RawCookieMirrorResource())\n        site = server.Site(root, timeout=None)\n        self.port = self._listen(site)\n        self.portno = self.port.getHost().port\n\n    def tearDown(self):\n        return self.port.stopListening()\n\n    def getHTTP(self, path):\n        return networkString(\"http://127.0.0.1:%d/%s\" % (self.portno, path))\n\n    def testNoCookies(self):\n        return client.getPage(self.getHTTP(\"cookiemirror\")\n            ).addCallback(self.assertEqual, b\"[]\"\n            )\n\n    def testSomeCookies(self):\n        cookies = {b'foo': b'bar', b'baz': b'quux'}\n        return client.getPage(self.getHTTP(\"cookiemirror\"), cookies=cookies\n            ).addCallback(self.assertEqual, b\"[('baz', 'quux'), ('foo', 'bar')]\"\n            )\n\n    def testRawNoCookies(self):\n        return client.getPage(self.getHTTP(\"rawcookiemirror\")\n            ).addCallback(self.assertEqual, b\"None\"\n            )\n\n    def testRawSomeCookies(self):\n        cookies = {b'foo': b'bar', b'baz': b'quux'}\n        return client.getPage(self.getHTTP(\"rawcookiemirror\"), cookies=cookies\n            ).addCallback(self.assertIn,\n                          (b\"'foo=bar; baz=quux'\", b\"'baz=quux; foo=bar'\")\n            )\n\n    def testCookieHeaderParsing(self):\n        factory = client.HTTPClientFactory(b'http://foo.example.com/')\n        proto = factory.buildProtocol('127.42.42.42')\n        transport = StringTransport()\n        proto.makeConnection(transport)\n        for line in [\n            b'200 Ok',\n            b'Squash: yes',\n            b'Hands: stolen',\n            b'Set-Cookie: CUSTOMER=WILE_E_COYOTE; path=/; expires=Wednesday, 09-Nov-99 23:12:40 GMT',\n            b'Set-Cookie: PART_NUMBER=ROCKET_LAUNCHER_0001; path=/',\n            b'Set-Cookie: SHIPPING=FEDEX; path=/foo',\n            b'Set-Cookie: HttpOnly;Secure',\n            b'',\n            b'body',\n            b'more body',\n            ]:\n            proto.dataReceived(line + b'\\r\\n')\n        self.assertEqual(transport.value(),\n                         b'GET / HTTP/1.0\\r\\n'\n                         b'Host: foo.example.com\\r\\n'\n                         b'User-Agent: Twisted PageGetter\\r\\n'\n                         b'\\r\\n')\n        self.assertEqual(factory.cookies,\n                          {\n            b'CUSTOMER': b'WILE_E_COYOTE',\n            b'PART_NUMBER': b'ROCKET_LAUNCHER_0001',\n            b'SHIPPING': b'FEDEX',\n            })\n\n\n\nclass HostHeaderTests(unittest.TestCase):\n    \"\"\"\n    Test that L{HTTPClientFactory} includes the port in the host header\n    if needed.\n    \"\"\"\n    suppress = [util.suppress(category=DeprecationWarning)]\n\n\n    def _getHost(self, bytes):\n        \"\"\"\n        Retrieve the value of the I{Host} header from the serialized\n        request given by C{bytes}.\n        \"\"\"\n        for line in bytes.split(b'\\r\\n'):\n            try:\n                name, value = line.split(b':', 1)\n                if name.strip().lower() == b'host':\n                    return value.strip()\n            except ValueError:\n                pass\n\n\n    def test_HTTPDefaultPort(self):\n        \"\"\"\n        No port should be included in the host header when connecting to the\n        default HTTP port.\n        \"\"\"\n        factory = client.HTTPClientFactory(b'http://foo.example.com/')\n        proto = factory.buildProtocol(b'127.42.42.42')\n        proto.makeConnection(StringTransport())\n        self.assertEqual(self._getHost(proto.transport.value()),\n                          b'foo.example.com')\n\n\n    def test_HTTPPort80(self):\n        \"\"\"\n        No port should be included in the host header when connecting to the\n        default HTTP port even if it is in the URL.\n        \"\"\"\n        factory = client.HTTPClientFactory(b'http://foo.example.com:80/')\n        proto = factory.buildProtocol('127.42.42.42')\n        proto.makeConnection(StringTransport())\n        self.assertEqual(self._getHost(proto.transport.value()),\n                          b'foo.example.com')\n\n\n    def test_HTTPNotPort80(self):\n        \"\"\"\n        The port should be included in the host header when connecting to the\n        a non default HTTP port.\n        \"\"\"\n        factory = client.HTTPClientFactory(b'http://foo.example.com:8080/')\n        proto = factory.buildProtocol('127.42.42.42')\n        proto.makeConnection(StringTransport())\n        self.assertEqual(self._getHost(proto.transport.value()),\n                          b'foo.example.com:8080')\n\n\n    def test_HTTPSDefaultPort(self):\n        \"\"\"\n        No port should be included in the host header when connecting to the\n        default HTTPS port.\n        \"\"\"\n        factory = client.HTTPClientFactory(b'https://foo.example.com/')\n        proto = factory.buildProtocol('127.42.42.42')\n        proto.makeConnection(StringTransport())\n        self.assertEqual(self._getHost(proto.transport.value()),\n                          b'foo.example.com')\n\n\n    def test_HTTPSPort443(self):\n        \"\"\"\n        No port should be included in the host header when connecting to the\n        default HTTPS port even if it is in the URL.\n        \"\"\"\n        factory = client.HTTPClientFactory(b'https://foo.example.com:443/')\n        proto = factory.buildProtocol('127.42.42.42')\n        proto.makeConnection(StringTransport())\n        self.assertEqual(self._getHost(proto.transport.value()),\n                          b'foo.example.com')\n\n\n    def test_HTTPSNotPort443(self):\n        \"\"\"\n        The port should be included in the host header when connecting to the\n        a non default HTTPS port.\n        \"\"\"\n        factory = client.HTTPClientFactory(b'http://foo.example.com:8080/')\n        proto = factory.buildProtocol('127.42.42.42')\n        proto.makeConnection(StringTransport())\n        self.assertEqual(self._getHost(proto.transport.value()),\n                          b'foo.example.com:8080')\n\n\nif ssl is None or not hasattr(ssl, 'DefaultOpenSSLContextFactory'):\n    for case in [WebClientSSLTests, WebClientRedirectBetweenSSLandPlainTextTests]:\n        case.skip = \"OpenSSL not present\"\n\nif not interfaces.IReactorSSL(reactor, None):\n    for case in [WebClientSSLTests, WebClientRedirectBetweenSSLandPlainTextTests]:\n        case.skip = \"Reactor doesn't support SSL\"\n\n\n\nclass URITests:\n    \"\"\"\n    Abstract tests for L{twisted.web.client.URI}.\n\n    Subclass this and L{unittest.TestCase}. Then provide a value for\n    C{host} and C{uriHost}.\n\n    @ivar host: A host specification for use in tests, must be L{bytes}.\n\n    @ivar uriHost: The host specification in URI form, must be a L{bytes}. In\n        most cases this is identical with C{host}. IPv6 address literals are an\n        exception, according to RFC 3986 section 3.2.2, as they need to be\n        enclosed in brackets. In this case this variable is different.\n    \"\"\"\n\n    def makeURIString(self, template):\n        \"\"\"\n        Replace the string \"HOST\" in C{template} with this test's host.\n\n        Byte strings Python between (and including) versions 3.0 and 3.4\n        cannot be formatted using C{%} or C{format} so this does a simple\n        replace.\n\n        @type template: L{bytes}\n        @param template: A string containing \"HOST\".\n\n        @rtype: L{bytes}\n        @return: A string where \"HOST\" has been replaced by C{self.host}.\n        \"\"\"\n        self.assertIsInstance(self.host, bytes)\n        self.assertIsInstance(self.uriHost, bytes)\n        self.assertIsInstance(template, bytes)\n        self.assertIn(b\"HOST\", template)\n        return template.replace(b\"HOST\", self.uriHost)\n\n    def assertURIEquals(self, uri, scheme, netloc, host, port, path,\n                        params=b'', query=b'', fragment=b''):\n        \"\"\"\n        Assert that all of a L{client.URI}'s components match the expected\n        values.\n\n        @param uri: U{client.URI} instance whose attributes will be checked\n            for equality.\n\n        @type scheme: L{bytes}\n        @param scheme: URI scheme specifier.\n\n        @type netloc: L{bytes}\n        @param netloc: Network location component.\n\n        @type host: L{bytes}\n        @param host: Host name.\n\n        @type port: L{int}\n        @param port: Port number.\n\n        @type path: L{bytes}\n        @param path: Hierarchical path.\n\n        @type params: L{bytes}\n        @param params: Parameters for last path segment, defaults to C{b''}.\n\n        @type query: L{bytes}\n        @param query: Query string, defaults to C{b''}.\n\n        @type fragment: L{bytes}\n        @param fragment: Fragment identifier, defaults to C{b''}.\n        \"\"\"\n        self.assertEqual(\n            (scheme, netloc, host, port, path, params, query, fragment),\n            (uri.scheme, uri.netloc, uri.host, uri.port, uri.path, uri.params,\n             uri.query, uri.fragment))\n\n\n    def test_parseDefaultPort(self):\n        \"\"\"\n        L{client.URI.fromBytes} by default assumes port 80 for the I{http}\n        scheme and 443 for the I{https} scheme.\n        \"\"\"\n        uri = client.URI.fromBytes(self.makeURIString(b'http://HOST'))\n        self.assertEqual(80, uri.port)\n        # Weird (but commonly accepted) structure uses default port.\n        uri = client.URI.fromBytes(self.makeURIString(b'http://HOST:'))\n        self.assertEqual(80, uri.port)\n        uri = client.URI.fromBytes(self.makeURIString(b'https://HOST'))\n        self.assertEqual(443, uri.port)\n\n\n    def test_parseCustomDefaultPort(self):\n        \"\"\"\n        L{client.URI.fromBytes} accepts a C{defaultPort} parameter that\n        overrides the normal default port logic.\n        \"\"\"\n        uri = client.URI.fromBytes(\n            self.makeURIString(b'http://HOST'), defaultPort=5144)\n        self.assertEqual(5144, uri.port)\n        uri = client.URI.fromBytes(\n            self.makeURIString(b'https://HOST'), defaultPort=5144)\n        self.assertEqual(5144, uri.port)\n\n\n    def test_netlocHostPort(self):\n        \"\"\"\n        Parsing a I{URI} splits the network location component into I{host} and\n        I{port}.\n        \"\"\"\n        uri = client.URI.fromBytes(\n            self.makeURIString(b'http://HOST:5144'))\n        self.assertEqual(5144, uri.port)\n        self.assertEqual(self.host, uri.host)\n        self.assertEqual(self.uriHost + b':5144', uri.netloc)\n\n        # Spaces in the hostname are trimmed, the default path is /.\n        uri = client.URI.fromBytes(self.makeURIString(b'http://HOST '))\n        self.assertEqual(self.uriHost, uri.netloc)\n\n\n    def test_path(self):\n        \"\"\"\n        Parse the path from a I{URI}.\n        \"\"\"\n        uri = self.makeURIString(b'http://HOST/foo/bar')\n        parsed = client.URI.fromBytes(uri)\n        self.assertURIEquals(\n            parsed,\n            scheme=b'http',\n            netloc=self.uriHost,\n            host=self.host,\n            port=80,\n            path=b'/foo/bar')\n        self.assertEqual(uri, parsed.toBytes())\n\n\n    def test_noPath(self):\n        \"\"\"\n        The path of a I{URI} that has no path is the empty string.\n        \"\"\"\n        uri = self.makeURIString(b'http://HOST')\n        parsed = client.URI.fromBytes(uri)\n        self.assertURIEquals(\n            parsed,\n            scheme=b'http',\n            netloc=self.uriHost,\n            host=self.host,\n            port=80,\n            path=b'')\n        self.assertEqual(uri, parsed.toBytes())\n\n\n    def test_emptyPath(self):\n        \"\"\"\n        The path of a I{URI} with an empty path is C{b'/'}.\n        \"\"\"\n        uri = self.makeURIString(b'http://HOST/')\n        self.assertURIEquals(\n            client.URI.fromBytes(uri),\n            scheme=b'http',\n            netloc=self.uriHost,\n            host=self.host,\n            port=80,\n            path=b'/')\n\n\n    def test_param(self):\n        \"\"\"\n        Parse I{URI} parameters from a I{URI}.\n        \"\"\"\n        uri = self.makeURIString(b'http://HOST/foo/bar;param')\n        parsed = client.URI.fromBytes(uri)\n        self.assertURIEquals(\n            parsed,\n            scheme=b'http',\n            netloc=self.uriHost,\n            host=self.host,\n            port=80,\n            path=b'/foo/bar',\n            params=b'param')\n        self.assertEqual(uri, parsed.toBytes())\n\n\n    def test_query(self):\n        \"\"\"\n        Parse the query string from a I{URI}.\n        \"\"\"\n        uri = self.makeURIString(b'http://HOST/foo/bar;param?a=1&b=2')\n        parsed = client.URI.fromBytes(uri)\n        self.assertURIEquals(\n            parsed,\n            scheme=b'http',\n            netloc=self.uriHost,\n            host=self.host,\n            port=80,\n            path=b'/foo/bar',\n            params=b'param',\n            query=b'a=1&b=2')\n        self.assertEqual(uri, parsed.toBytes())\n\n\n    def test_fragment(self):\n        \"\"\"\n        Parse the fragment identifier from a I{URI}.\n        \"\"\"\n        uri = self.makeURIString(b'http://HOST/foo/bar;param?a=1&b=2#frag')\n        parsed = client.URI.fromBytes(uri)\n        self.assertURIEquals(\n            parsed,\n            scheme=b'http',\n            netloc=self.uriHost,\n            host=self.host,\n            port=80,\n            path=b'/foo/bar',\n            params=b'param',\n            query=b'a=1&b=2',\n            fragment=b'frag')\n        self.assertEqual(uri, parsed.toBytes())\n\n\n    def test_originForm(self):\n        \"\"\"\n        L{client.URI.originForm} produces an absolute I{URI} path including\n        the I{URI} path.\n        \"\"\"\n        uri = client.URI.fromBytes(\n            self.makeURIString(b'http://HOST/foo'))\n        self.assertEqual(b'/foo', uri.originForm)\n\n\n    def test_originFormComplex(self):\n        \"\"\"\n        L{client.URI.originForm} produces an absolute I{URI} path including\n        the I{URI} path, parameters and query string but excludes the fragment\n        identifier.\n        \"\"\"\n        uri = client.URI.fromBytes(\n            self.makeURIString(b'http://HOST/foo;param?a=1#frag'))\n        self.assertEqual(b'/foo;param?a=1', uri.originForm)\n\n\n    def test_originFormNoPath(self):\n        \"\"\"\n        L{client.URI.originForm} produces a path of C{b'/'} when the I{URI}\n        specifies no path.\n        \"\"\"\n        uri = client.URI.fromBytes(self.makeURIString(b'http://HOST'))\n        self.assertEqual(b'/', uri.originForm)\n\n\n    def test_originFormEmptyPath(self):\n        \"\"\"\n        L{client.URI.originForm} produces a path of C{b'/'} when the I{URI}\n        specifies an empty path.\n        \"\"\"\n        uri = client.URI.fromBytes(\n            self.makeURIString(b'http://HOST/'))\n        self.assertEqual(b'/', uri.originForm)\n\n\n    def test_externalUnicodeInterference(self):\n        \"\"\"\n        L{client.URI.fromBytes} parses the scheme, host, and path elements\n        into L{bytes}, even when passed an URL which has previously been passed\n        to L{urlparse} as a L{unicode} string.\n        \"\"\"\n        goodInput = self.makeURIString(b'http://HOST/path')\n        badInput = goodInput.decode('ascii')\n        urlparse(badInput)\n        uri = client.URI.fromBytes(goodInput)\n        self.assertIsInstance(uri.scheme, bytes)\n        self.assertIsInstance(uri.host, bytes)\n        self.assertIsInstance(uri.path, bytes)\n\n\n\nclass URITestsForHostname(URITests, unittest.TestCase):\n    \"\"\"\n    Tests for L{twisted.web.client.URI} with host names.\n    \"\"\"\n\n    uriHost = host = b\"example.com\"\n\n\n\nclass URITestsForIPv4(URITests, unittest.TestCase):\n    \"\"\"\n    Tests for L{twisted.web.client.URI} with IPv4 host addresses.\n    \"\"\"\n\n    uriHost = host = b\"192.168.1.67\"\n\n\n\nclass URITestsForIPv6(URITests, unittest.TestCase):\n    \"\"\"\n    Tests for L{twisted.web.client.URI} with IPv6 host addresses.\n\n    IPv6 addresses must always be surrounded by square braces in URIs. No\n    attempt is made to test without.\n    \"\"\"\n\n    host = b\"fe80::20c:29ff:fea4:c60\"\n    uriHost = b\"[fe80::20c:29ff:fea4:c60]\"\n\n\n    def test_hostBracketIPv6AddressLiteral(self):\n        \"\"\"\n        Brackets around IPv6 addresses are stripped in the host field. The host\n        field is then exported with brackets in the output of\n        L{client.URI.toBytes}.\n        \"\"\"\n        uri = client.URI.fromBytes(b\"http://[::1]:80/index.html\")\n\n        self.assertEqual(uri.host, b\"::1\")\n        self.assertEqual(uri.netloc, b\"[::1]:80\")\n        self.assertEqual(uri.toBytes(), b'http://[::1]:80/index.html')\n\n\n\nclass DeprecationTests(unittest.TestCase):\n    \"\"\"\n    Tests that L{client.getPage} and friends are deprecated.\n    \"\"\"\n\n    def test_getPageDeprecated(self):\n        \"\"\"\n        L{client.getPage} is deprecated.\n        \"\"\"\n        port = reactor.listenTCP(\n            0, server.Site(Data(b'', 'text/plain')), interface=\"127.0.0.1\")\n        portno = port.getHost().port\n        self.addCleanup(port.stopListening)\n        url = networkString(\"http://127.0.0.1:%d\" % (portno,))\n\n        d = client.getPage(url)\n        warningInfo = self.flushWarnings([self.test_getPageDeprecated])\n        self.assertEqual(len(warningInfo), 1)\n        self.assertEqual(warningInfo[0]['category'], DeprecationWarning)\n        self.assertEqual(\n            warningInfo[0]['message'],\n            \"twisted.web.client.getPage was deprecated in \"\n            \"Twisted 16.7.0; please use https://pypi.org/project/treq/ or twisted.web.client.Agent instead\")\n\n        return d.addErrback(lambda _: None)\n\n\n    def test_downloadPageDeprecated(self):\n        \"\"\"\n        L{client.downloadPage} is deprecated.\n        \"\"\"\n        port = reactor.listenTCP(\n            0, server.Site(Data(b'', 'text/plain')), interface=\"127.0.0.1\")\n        portno = port.getHost().port\n        self.addCleanup(port.stopListening)\n        url = networkString(\"http://127.0.0.1:%d\" % (portno,))\n\n        path = FilePath(self.mktemp())\n        d = client.downloadPage(url, path.path)\n\n        warningInfo = self.flushWarnings([self.test_downloadPageDeprecated])\n        self.assertEqual(len(warningInfo), 1)\n        self.assertEqual(warningInfo[0]['category'], DeprecationWarning)\n        self.assertEqual(\n            warningInfo[0]['message'],\n            \"twisted.web.client.downloadPage was deprecated in \"\n            \"Twisted 16.7.0; please use https://pypi.org/project/treq/ or twisted.web.client.Agent instead\")\n\n        return d.addErrback(lambda _: None)\n\n\n    def _testDeprecatedClass(self, klass):\n        \"\"\"\n        Assert that accessing the given class was deprecated.\n\n        @param klass: The class being deprecated.\n        @type klass: L{str}\n        \"\"\"\n        getattr(client, klass)\n\n        warningInfo = self.flushWarnings()\n        self.assertEqual(len(warningInfo), 1)\n        self.assertEqual(warningInfo[0]['category'], DeprecationWarning)\n        self.assertEqual(\n            warningInfo[0]['message'],\n            \"twisted.web.client.{} was deprecated in \"\n            \"Twisted 16.7.0: please use https://pypi.org/project/treq/ or twisted.web.client.Agent instead\".format(klass))\n\n\n    def test_httpPageGetterDeprecated(self):\n        \"\"\"\n        L{client.HTTPPageGetter} is deprecated.\n        \"\"\"\n        self._testDeprecatedClass(\"HTTPPageGetter\")\n\n\n    def test_httpPageDownloaderDeprecated(self):\n        \"\"\"\n        L{client.HTTPPageDownloader} is deprecated.\n        \"\"\"\n        self._testDeprecatedClass(\"HTTPPageDownloader\")\n\n\n    def test_httpClientFactoryDeprecated(self):\n        \"\"\"\n        L{client.HTTPClientFactory} is deprecated.\n        \"\"\"\n        self._testDeprecatedClass(\"HTTPClientFactory\")\n\n\n    def test_httpDownloaderDeprecated(self):\n        \"\"\"\n        L{client.HTTPDownloader} is deprecated.\n        \"\"\"\n        self._testDeprecatedClass(\"HTTPDownloader\")\n\n\n\nclass GetPageMethodInjectionTests(\n        MethodInjectionTestsMixin,\n        unittest.SynchronousTestCase,\n):\n    \"\"\"\n    Test L{client.getPage} against HTTP method injections.\n    \"\"\"\n\n    def attemptRequestWithMaliciousMethod(self, method):\n        \"\"\"\n        Attempt a request with the provided method.\n\n        @param method: see L{MethodInjectionTestsMixin}\n        \"\"\"\n        uri = b'http://twisted.invalid'\n        client.getPage(uri, method=method)\n\n\n\nclass GetPageURIInjectionTests(\n        URIInjectionTestsMixin,\n        unittest.SynchronousTestCase,\n):\n    \"\"\"\n    Test L{client.getPage} against URI injections.\n    \"\"\"\n\n    def attemptRequestWithMaliciousURI(self, uri):\n        \"\"\"\n        Attempt a request with the provided URI.\n\n        @param uri: see L{URIInjectionTestsMixin}\n        \"\"\"\n        client.getPage(uri)\n\n\n\nclass DownloadPageMethodInjectionTests(\n        MethodInjectionTestsMixin,\n        unittest.SynchronousTestCase,\n):\n    \"\"\"\n    Test L{client.getPage} against HTTP method injections.\n    \"\"\"\n\n    def attemptRequestWithMaliciousMethod(self, method):\n        \"\"\"\n        Attempt a request with the provided method.\n\n        @param method: see L{MethodInjectionTestsMixin}\n        \"\"\"\n        uri = b'http://twisted.invalid'\n        client.downloadPage(uri, file=io.BytesIO(), method=method)\n\n\n\nclass DownloadPageURIInjectionTests(\n        URIInjectionTestsMixin,\n        unittest.SynchronousTestCase,\n):\n    \"\"\"\n    Test L{client.downloadPage} against URI injections.\n    \"\"\"\n\n    def attemptRequestWithMaliciousURI(self, uri):\n        \"\"\"\n        Attempt a request with the provided URI.\n\n        @param uri: see L{URIInjectionTestsMixin}\n        \"\"\"\n        client.downloadPage(uri, file=io.BytesIO())\n\n\n\ndef makeHTTPPageGetterFactory(protocolClass, method, host, path):\n    \"\"\"\n    Make a L{ClientFactory} that can be used with\n    L{client.HTTPPageGetter} and its subclasses.\n\n    @param protocolClass: The protocol class\n    @type protocolClass: A subclass of L{client.HTTPPageGetter}\n\n    @param method: the HTTP method\n\n    @param host: the host\n\n    @param path: The URI path\n\n    @return: A L{ClientFactory}.\n    \"\"\"\n    factory = ClientFactory.forProtocol(protocolClass)\n\n    factory.method = method\n    factory.host = host\n    factory.path = path\n\n    factory.scheme = b\"http\"\n    factory.port = 0\n    factory.headers = {}\n    factory.agent = b\"User/Agent\"\n    factory.cookies = {}\n\n    return factory\n\n\n\nclass HTTPPageGetterMethodInjectionTests(\n        MethodInjectionTestsMixin,\n        unittest.SynchronousTestCase,\n):\n    \"\"\"\n    Test L{client.HTTPPageGetter} against HTTP method injections.\n    \"\"\"\n    protocolClass = client.HTTPPageGetter\n\n    def attemptRequestWithMaliciousMethod(self, method):\n        \"\"\"\n        Attempt a request with the provided method.\n\n        @param method: L{MethodInjectionTestsMixin}\n        \"\"\"\n        transport = StringTransport()\n        factory = makeHTTPPageGetterFactory(\n            self.protocolClass,\n            method=method,\n            host=b\"twisted.invalid\",\n            path=b\"/\",\n        )\n        getter = factory.buildProtocol(\n            address.IPv4Address(\"TCP\", \"127.0.0.1\", 0),\n        )\n        getter.makeConnection(transport)\n\n\n\nclass HTTPPageGetterURIInjectionTests(\n        URIInjectionTestsMixin,\n        unittest.SynchronousTestCase,\n):\n    \"\"\"\n    Test L{client.HTTPPageGetter} against HTTP URI injections.\n    \"\"\"\n    protocolClass = client.HTTPPageGetter\n\n    def attemptRequestWithMaliciousURI(self, uri):\n        \"\"\"\n        Attempt a request with the provided URI.\n\n        @param uri: L{URIInjectionTestsMixin}\n        \"\"\"\n        transport = StringTransport()\n        # Setting the host and path to the same value is imprecise but\n        # doesn't require parsing an invalid URI.\n        factory = makeHTTPPageGetterFactory(\n            self.protocolClass,\n            method=b\"GET\",\n            host=uri,\n            path=uri,\n        )\n        getter = factory.buildProtocol(\n            address.IPv4Address(\"TCP\", \"127.0.0.1\", 0),\n        )\n        getter.makeConnection(transport)\n\n\n\nclass HTTPPageDownloaderMethodInjectionTests(\n        HTTPPageGetterMethodInjectionTests\n):\n\n    \"\"\"\n    Test L{client.HTTPPageDownloader} against HTTP method injections.\n    \"\"\"\n    protocolClass = client.HTTPPageDownloader\n\n\n\nclass HTTPPageDownloaderURIInjectionTests(\n        HTTPPageGetterURIInjectionTests\n):\n    \"\"\"\n    Test L{client.HTTPPageDownloader} against HTTP URI injections.\n    \"\"\"\n    protocolClass = client.HTTPPageDownloader\n\n\n\nclass HTTPClientFactoryMethodInjectionTests(\n        MethodInjectionTestsMixin,\n        unittest.SynchronousTestCase,\n):\n    \"\"\"\n    Tests L{client.HTTPClientFactory} against HTTP method injections.\n    \"\"\"\n\n    def attemptRequestWithMaliciousMethod(self, method):\n        \"\"\"\n        Attempt a request with the provided method.\n\n        @param method: L{MethodInjectionTestsMixin}\n        \"\"\"\n        client.HTTPClientFactory(b\"https://twisted.invalid\", method)\n\n\n\nclass HTTPClientFactoryURIInjectionTests(\n        URIInjectionTestsMixin,\n        unittest.SynchronousTestCase,\n):\n    \"\"\"\n    Tests L{client.HTTPClientFactory} against HTTP URI injections.\n    \"\"\"\n\n    def attemptRequestWithMaliciousURI(self, uri):\n        \"\"\"\n        Attempt a request with the provided URI.\n\n        @param uri: L{URIInjectionTestsMixin}\n        \"\"\"\n        client.HTTPClientFactory(uri)\n\n\n\nclass HTTPClientFactorySetURLURIInjectionTests(\n        URIInjectionTestsMixin,\n        unittest.SynchronousTestCase,\n):\n    \"\"\"\n    Tests L{client.HTTPClientFactory.setURL} against HTTP URI injections.\n    \"\"\"\n\n    def attemptRequestWithMaliciousURI(self, uri):\n        \"\"\"\n        Attempt a request with the provided URI.\n\n        @param uri: L{URIInjectionTestsMixin}\n        \"\"\"\n        client.HTTPClientFactory(b\"https://twisted.invalid\").setURL(uri)\n\n\n\nclass HTTPDownloaderMethodInjectionTests(\n        MethodInjectionTestsMixin,\n        unittest.SynchronousTestCase,\n):\n    \"\"\"\n    Tests L{client.HTTPDownloader} against HTTP method injections.\n    \"\"\"\n\n    def attemptRequestWithMaliciousMethod(self, method):\n        \"\"\"\n        Attempt a request with the provided method.\n\n        @param method: L{MethodInjectionTestsMixin}\n        \"\"\"\n        client.HTTPDownloader(\n            b\"https://twisted.invalid\",\n            io.BytesIO(),\n            method=method,\n        )\n\n\n\nclass HTTPDownloaderURIInjectionTests(\n        URIInjectionTestsMixin,\n        unittest.SynchronousTestCase,\n):\n    \"\"\"\n    Tests L{client.HTTPDownloader} against HTTP URI injections.\n    \"\"\"\n\n    def attemptRequestWithMaliciousURI(self, uri):\n        \"\"\"\n        Attempt a request with the provided URI.\n\n        @param uri: L{URIInjectionTestsMixin}\n        \"\"\"\n        client.HTTPDownloader(uri, io.BytesIO())\n\n\n\nclass HTTPDownloaderSetURLURIInjectionTests(\n        URIInjectionTestsMixin,\n        unittest.SynchronousTestCase,\n):\n    \"\"\"\n    Tests L{client.HTTPDownloader.setURL} against HTTP URI injections.\n    \"\"\"\n\n    def attemptRequestWithMaliciousURI(self, uri):\n        \"\"\"\n        Attempt a request with the provided URI.\n\n        @param uri: L{URIInjectionTestsMixin}\n        \"\"\"\n        downloader = client.HTTPDownloader(\n            b\"https://twisted.invalid\",\n            io.BytesIO(),\n        )\n        downloader.setURL(uri)\n", "code_before": "# Copyright (c) Twisted Matrix Laboratories.\n# See LICENSE for details.\n\n\"\"\"\nTests for the old L{twisted.web.client} APIs, C{getPage} and friends.\n\"\"\"\n\nfrom __future__ import division, absolute_import\n\nimport os\nfrom errno import ENOSPC\n\ntry:\n    from urlparse import urlparse, urljoin\nexcept ImportError:\n    from urllib.parse import urlparse, urljoin\n\nfrom twisted.python.compat import networkString, nativeString, intToBytes\nfrom twisted.trial import unittest, util\nfrom twisted.web import server, client, error, resource\nfrom twisted.web.static import Data\nfrom twisted.web.util import Redirect\nfrom twisted.internet import reactor, defer, interfaces\nfrom twisted.python.filepath import FilePath\nfrom twisted.protocols.policies import WrappingFactory\nfrom twisted.test.proto_helpers import (\n    StringTransport, waitUntilAllDisconnected, EventLoggingObserver)\n\ntry:\n    from twisted.internet import ssl\nexcept:\n    ssl = None\n\nfrom twisted import test\nfrom twisted.logger import (globalLogPublisher, FilteringLogObserver,\n                            LogLevelFilterPredicate, LogLevel, Logger)\n\n\nserverPEM = FilePath(test.__file__).sibling('server.pem')\nserverPEMPath = serverPEM.asBytesMode().path\n\n\nclass ExtendedRedirect(resource.Resource):\n    \"\"\"\n    Redirection resource.\n\n    The HTTP status code is set according to the C{code} query parameter.\n\n    @type lastMethod: C{bytes}\n    @ivar lastMethod: Last handled HTTP request method\n    \"\"\"\n    isLeaf = True\n    lastMethod = None\n\n\n    def __init__(self, url):\n        resource.Resource.__init__(self)\n        self.url = url\n\n\n    def render(self, request):\n        if self.lastMethod:\n            self.lastMethod = request.method\n            return b\"OK Thnx!\"\n        else:\n            self.lastMethod = request.method\n            code = int(request.args[b'code'][0])\n            return self.redirectTo(self.url, request, code)\n\n\n    def getChild(self, name, request):\n        return self\n\n\n    def redirectTo(self, url, request, code):\n        request.setResponseCode(code)\n        request.setHeader(b\"location\", url)\n        return b\"OK Bye!\"\n\n\n\nclass ForeverTakingResource(resource.Resource):\n    \"\"\"\n    L{ForeverTakingResource} is a resource which never finishes responding\n    to requests.\n    \"\"\"\n    def __init__(self, write=False):\n        resource.Resource.__init__(self)\n        self._write = write\n\n    def render(self, request):\n        if self._write:\n            request.write(b'some bytes')\n        return server.NOT_DONE_YET\n\n\nclass ForeverTakingNoReadingResource(resource.Resource):\n    \"\"\"\n    L{ForeverTakingNoReadingResource} is a resource that never finishes\n    responding and that removes itself from the read loop.\n    \"\"\"\n    def __init__(self):\n        resource.Resource.__init__(self)\n\n    def render(self, request):\n        # Stop the producing.\n        request.transport.pauseProducing()\n        return server.NOT_DONE_YET\n\n\nclass CookieMirrorResource(resource.Resource):\n    def render(self, request):\n        l = []\n        for k,v in sorted(list(request.received_cookies.items())):\n            l.append((nativeString(k), nativeString(v)))\n        l.sort()\n        return networkString(repr(l))\n\nclass RawCookieMirrorResource(resource.Resource):\n    def render(self, request):\n        header = request.getHeader(b'cookie')\n        if header is None:\n            return b'None'\n        return networkString(repr(nativeString(header)))\n\nclass ErrorResource(resource.Resource):\n\n    def render(self, request):\n        request.setResponseCode(401)\n        if request.args.get(b\"showlength\"):\n            request.setHeader(b\"content-length\", b\"0\")\n        return b\"\"\n\nclass NoLengthResource(resource.Resource):\n\n    def render(self, request):\n        return b\"nolength\"\n\n\n\nclass HostHeaderResource(resource.Resource):\n    \"\"\"\n    A testing resource which renders itself as the value of the host header\n    from the request.\n    \"\"\"\n    def render(self, request):\n        return request.requestHeaders.getRawHeaders(b\"host\")[0]\n\n\n\nclass PayloadResource(resource.Resource):\n    \"\"\"\n    A testing resource which renders itself as the contents of the request body\n    as long as the request body is 100 bytes long, otherwise which renders\n    itself as C{\"ERROR\"}.\n    \"\"\"\n    def render(self, request):\n        data = request.content.read()\n        contentLength = request.requestHeaders.getRawHeaders(b\"content-length\")[0]\n        if len(data) != 100 or int(contentLength) != 100:\n            return b\"ERROR\"\n        return data\n\n\nclass DelayResource(resource.Resource):\n\n    def __init__(self, seconds):\n        self.seconds = seconds\n\n    def render(self, request):\n        def response():\n            request.write(b'some bytes')\n            request.finish()\n        reactor.callLater(self.seconds, response)\n        return server.NOT_DONE_YET\n\n\nclass BrokenDownloadResource(resource.Resource):\n\n    def render(self, request):\n        # only sends 3 bytes even though it claims to send 5\n        request.setHeader(b\"content-length\", b\"5\")\n        request.write(b'abc')\n        return b''\n\nclass CountingRedirect(Redirect):\n    \"\"\"\n    A L{Redirect} resource that keeps track of the number of times the\n    resource has been accessed.\n    \"\"\"\n    def __init__(self, *a, **kw):\n        Redirect.__init__(self, *a, **kw)\n        self.count = 0\n\n    def render(self, request):\n        self.count += 1\n        return Redirect.render(self, request)\n\n\nclass CountingResource(resource.Resource):\n    \"\"\"\n    A resource that keeps track of the number of times it has been accessed.\n    \"\"\"\n    def __init__(self):\n        resource.Resource.__init__(self)\n        self.count = 0\n\n    def render(self, request):\n        self.count += 1\n        return b\"Success\"\n\n\n\nclass URLJoinTests(unittest.TestCase):\n    \"\"\"\n    Tests for L{client._urljoin}.\n    \"\"\"\n    def test_noFragments(self):\n        \"\"\"\n        L{client._urljoin} does not include a fragment identifier in the\n        resulting URL if neither the base nor the new path include a fragment\n        identifier.\n        \"\"\"\n        self.assertEqual(\n            client._urljoin(b'http://foo.com/bar', b'/quux'),\n            b'http://foo.com/quux')\n        self.assertEqual(\n            client._urljoin(b'http://foo.com/bar#', b'/quux'),\n            b'http://foo.com/quux')\n        self.assertEqual(\n            client._urljoin(b'http://foo.com/bar', b'/quux#'),\n            b'http://foo.com/quux')\n\n\n    def test_preserveFragments(self):\n        \"\"\"\n        L{client._urljoin} preserves the fragment identifier from either the\n        new path or the base URL respectively, as specified in the HTTP 1.1 bis\n        draft.\n\n        @see: U{https://tools.ietf.org/html/draft-ietf-httpbis-p2-semantics-22#section-7.1.2}\n        \"\"\"\n        self.assertEqual(\n            client._urljoin(b'http://foo.com/bar#frag', b'/quux'),\n            b'http://foo.com/quux#frag')\n        self.assertEqual(\n            client._urljoin(b'http://foo.com/bar', b'/quux#frag2'),\n            b'http://foo.com/quux#frag2')\n        self.assertEqual(\n            client._urljoin(b'http://foo.com/bar#frag', b'/quux#frag2'),\n            b'http://foo.com/quux#frag2')\n\n\n\nclass HTTPPageGetterTests(unittest.TestCase):\n    \"\"\"\n    Tests for L{HTTPPagerGetter}, the HTTP client protocol implementation\n    used to implement L{getPage}.\n    \"\"\"\n    suppress = [util.suppress(category=DeprecationWarning)]\n\n\n    def test_earlyHeaders(self):\n        \"\"\"\n        When a connection is made, L{HTTPPagerGetter} sends the headers from\n        its factory's C{headers} dict.  If I{Host} or I{Content-Length} is\n        present in this dict, the values are not sent, since they are sent with\n        special values before the C{headers} dict is processed.  If\n        I{User-Agent} is present in the dict, it overrides the value of the\n        C{agent} attribute of the factory.  If I{Cookie} is present in the\n        dict, its value is added to the values from the factory's C{cookies}\n        attribute.\n        \"\"\"\n        factory = client.HTTPClientFactory(\n            b'http://foo/bar',\n            agent=b\"foobar\",\n            cookies={b'baz': b'quux'},\n            postdata=b\"some data\",\n            headers={\n                b'Host': b'example.net',\n                b'User-Agent': b'fooble',\n                b'Cookie': b'blah blah',\n                b'Content-Length': b'12981',\n                b'Useful': b'value'})\n        transport = StringTransport()\n        protocol = client.HTTPPageGetter()\n        protocol.factory = factory\n        protocol.makeConnection(transport)\n        result = transport.value()\n        for expectedHeader in [\n            b\"Host: example.net\\r\\n\",\n            b\"User-Agent: foobar\\r\\n\",\n            b\"Content-Length: 9\\r\\n\",\n            b\"Useful: value\\r\\n\",\n            b\"connection: close\\r\\n\",\n            b\"Cookie: blah blah; baz=quux\\r\\n\"]:\n            self.assertIn(expectedHeader, result)\n\n\n\nclass WebClientTests(unittest.TestCase):\n    suppress = [util.suppress(category=DeprecationWarning)]\n    _log = Logger()\n\n\n    def _listen(self, site):\n        return reactor.listenTCP(0, site, interface=\"127.0.0.1\")\n\n    def setUp(self):\n        self.agent = None # for twisted.web.client.Agent test\n        self.cleanupServerConnections = 0\n        r = resource.Resource()\n        r.putChild(b\"file\", Data(b\"0123456789\", \"text/html\"))\n        r.putChild(b\"redirect\", Redirect(b\"/file\"))\n        self.infiniteRedirectResource = CountingRedirect(b\"/infiniteRedirect\")\n        r.putChild(b\"infiniteRedirect\", self.infiniteRedirectResource)\n        r.putChild(b\"wait\", ForeverTakingResource())\n        r.putChild(b\"write-then-wait\", ForeverTakingResource(write=True))\n        r.putChild(b\"never-read\", ForeverTakingNoReadingResource())\n        r.putChild(b\"error\", ErrorResource())\n        r.putChild(b\"nolength\", NoLengthResource())\n        r.putChild(b\"host\", HostHeaderResource())\n        r.putChild(b\"payload\", PayloadResource())\n        r.putChild(b\"broken\", BrokenDownloadResource())\n        r.putChild(b\"cookiemirror\", CookieMirrorResource())\n        r.putChild(b'delay1', DelayResource(1))\n        r.putChild(b'delay2', DelayResource(2))\n\n        self.afterFoundGetCounter = CountingResource()\n        r.putChild(b\"afterFoundGetCounter\", self.afterFoundGetCounter)\n        r.putChild(b\"afterFoundGetRedirect\", Redirect(b\"/afterFoundGetCounter\"))\n\n        miscasedHead = Data(b\"miscased-head GET response content\", \"major/minor\")\n        miscasedHead.render_Head = lambda request: b\"miscased-head content\"\n        r.putChild(b\"miscased-head\", miscasedHead)\n\n        self.extendedRedirect = ExtendedRedirect(b'/extendedRedirect')\n        r.putChild(b\"extendedRedirect\", self.extendedRedirect)\n        self.site = server.Site(r, timeout=None)\n        self.wrapper = WrappingFactory(self.site)\n        self.port = self._listen(self.wrapper)\n        self.portno = self.port.getHost().port\n\n    def tearDown(self):\n        if self.agent:\n            # clean up connections for twisted.web.client.Agent test.\n            self.agent.closeCachedConnections()\n            self.agent = None\n\n        # If the test indicated it might leave some server-side connections\n        # around, clean them up.\n        connections = list(self.wrapper.protocols.keys())\n        # If there are fewer server-side connections than requested,\n        # that's okay.  Some might have noticed that the client closed\n        # the connection and cleaned up after themselves.\n        for n in range(min(len(connections), self.cleanupServerConnections)):\n            proto = connections.pop()\n            self._log.info(\"Closing {proto}\", proto=proto)\n            proto.transport.abortConnection()\n        d = self.port.stopListening()\n\n        return defer.DeferredList([waitUntilAllDisconnected(\n            reactor, list(self.wrapper.protocols.keys())), d])\n\n\n    def getURL(self, path):\n        host = \"http://127.0.0.1:%d/\" % self.portno\n        return networkString(urljoin(host, nativeString(path)))\n\n    def testPayload(self):\n        s = b\"0123456789\" * 10\n        return client.getPage(self.getURL(\"payload\"), postdata=s\n                              ).addCallback(self.assertEqual, s\n            )\n\n\n    def test_getPageBrokenDownload(self):\n        \"\"\"\n        If the connection is closed before the number of bytes indicated by\n        I{Content-Length} have been received, the L{Deferred} returned by\n        L{getPage} fails with L{PartialDownloadError}.\n        \"\"\"\n        d = client.getPage(self.getURL(\"broken\"))\n        d = self.assertFailure(d, client.PartialDownloadError)\n        d.addCallback(lambda exc: self.assertEqual(exc.response, b\"abc\"))\n        return d\n\n\n    def test_downloadPageBrokenDownload(self):\n        \"\"\"\n        If the connection is closed before the number of bytes indicated by\n        I{Content-Length} have been received, the L{Deferred} returned by\n        L{downloadPage} fails with L{PartialDownloadError}.\n        \"\"\"\n        # test what happens when download gets disconnected in the middle\n        path = FilePath(self.mktemp())\n        d = client.downloadPage(self.getURL(\"broken\"), path.path)\n        d = self.assertFailure(d, client.PartialDownloadError)\n\n        def checkResponse(response):\n            \"\"\"\n            The HTTP status code from the server is propagated through the\n            C{PartialDownloadError}.\n            \"\"\"\n            self.assertEqual(response.status, b\"200\")\n            self.assertEqual(response.message, b\"OK\")\n            return response\n        d.addCallback(checkResponse)\n\n        def cbFailed(ignored):\n            self.assertEqual(path.getContent(), b\"abc\")\n        d.addCallback(cbFailed)\n        return d\n\n\n    def test_downloadPageLogsFileCloseError(self):\n        \"\"\"\n        If there is an exception closing the file being written to after the\n        connection is prematurely closed, that exception is logged.\n        \"\"\"\n        exc = IOError(ENOSPC, \"No file left on device\")\n\n        class BrokenFile:\n            def write(self, bytes):\n                pass\n\n            def close(self):\n                raise exc\n\n        logObserver = EventLoggingObserver()\n        filtered = FilteringLogObserver(\n            logObserver,\n            [LogLevelFilterPredicate(defaultLogLevel=LogLevel.critical)]\n        )\n        globalLogPublisher.addObserver(filtered)\n        self.addCleanup(lambda: globalLogPublisher.removeObserver(filtered))\n\n        d = client.downloadPage(self.getURL(\"broken\"), BrokenFile())\n        d = self.assertFailure(d, client.PartialDownloadError)\n\n        def cbFailed(ignored):\n            self.assertEquals(1, len(logObserver))\n            event = logObserver[0]\n            f = event[\"log_failure\"]\n            self.assertIsInstance(f.value, IOError)\n            self.assertEquals(\n                f.value.args,\n                exc.args\n            )\n            self.assertEqual(len(self.flushLoggedErrors(IOError)), 1)\n\n        d.addCallback(cbFailed)\n        return d\n\n\n    def testHostHeader(self):\n        # if we pass Host header explicitly, it should be used, otherwise\n        # it should extract from url\n        return defer.gatherResults([\n            client.getPage(self.getURL(\"host\")).addCallback(\n                    self.assertEqual, b\"127.0.0.1:\" + intToBytes(self.portno)),\n            client.getPage(self.getURL(\"host\"),\n                           headers={b\"Host\": b\"www.example.com\"}).addCallback(\n                    self.assertEqual, b\"www.example.com\")])\n\n\n    def test_getPage(self):\n        \"\"\"\n        L{client.getPage} returns a L{Deferred} which is called back with\n        the body of the response if the default method B{GET} is used.\n        \"\"\"\n        d = client.getPage(self.getURL(\"file\"))\n        d.addCallback(self.assertEqual, b\"0123456789\")\n        return d\n\n\n    def test_getPageHEAD(self):\n        \"\"\"\n        L{client.getPage} returns a L{Deferred} which is called back with\n        the empty string if the method is I{HEAD} and there is a successful\n        response code.\n        \"\"\"\n        d = client.getPage(self.getURL(\"file\"), method=b\"HEAD\")\n        d.addCallback(self.assertEqual, b\"\")\n        return d\n\n\n    def test_getPageNotQuiteHEAD(self):\n        \"\"\"\n        If the request method is a different casing of I{HEAD} (ie, not all\n        capitalized) then it is not a I{HEAD} request and the response body\n        is returned.\n        \"\"\"\n        d = client.getPage(self.getURL(\"miscased-head\"), method=b'Head')\n        d.addCallback(self.assertEqual, b\"miscased-head content\")\n        return d\n\n\n    def test_timeoutNotTriggering(self):\n        \"\"\"\n        When a non-zero timeout is passed to L{getPage} and the page is\n        retrieved before the timeout period elapses, the L{Deferred} is\n        called back with the contents of the page.\n        \"\"\"\n        d = client.getPage(self.getURL(\"host\"), timeout=100)\n        d.addCallback(self.assertEqual,\n                      networkString(\"127.0.0.1:%s\" % (self.portno,)))\n        return d\n\n\n    def test_timeoutTriggering(self):\n        \"\"\"\n        When a non-zero timeout is passed to L{getPage} and that many\n        seconds elapse before the server responds to the request. the\n        L{Deferred} is errbacked with a L{error.TimeoutError}.\n        \"\"\"\n        # This will probably leave some connections around.\n        self.cleanupServerConnections = 1\n        return self.assertFailure(\n            client.getPage(self.getURL(\"wait\"), timeout=0.000001),\n            defer.TimeoutError)\n\n\n    def testDownloadPage(self):\n        downloads = []\n        downloadData = [(\"file\", self.mktemp(), b\"0123456789\"),\n                        (\"nolength\", self.mktemp(), b\"nolength\")]\n\n        for (url, name, data) in downloadData:\n            d = client.downloadPage(self.getURL(url), name)\n            d.addCallback(self._cbDownloadPageTest, data, name)\n            downloads.append(d)\n        return defer.gatherResults(downloads)\n\n    def _cbDownloadPageTest(self, ignored, data, name):\n        with open(name, \"rb\") as f:\n            bytes = f.read()\n        self.assertEqual(bytes, data)\n\n    def testDownloadPageError1(self):\n        class errorfile:\n            def write(self, data):\n                raise IOError(\"badness happened during write\")\n            def close(self):\n                pass\n        ef = errorfile()\n        return self.assertFailure(\n            client.downloadPage(self.getURL(\"file\"), ef),\n            IOError)\n\n    def testDownloadPageError2(self):\n        class errorfile:\n            def write(self, data):\n                pass\n            def close(self):\n                raise IOError(\"badness happened during close\")\n        ef = errorfile()\n        return self.assertFailure(\n            client.downloadPage(self.getURL(\"file\"), ef),\n            IOError)\n\n    def testDownloadPageError3(self):\n        # make sure failures in open() are caught too. This is tricky.\n        # Might only work on posix.\n        open(\"unwritable\", \"wb\").close()\n        os.chmod(\"unwritable\", 0) # make it unwritable (to us)\n        d = self.assertFailure(\n            client.downloadPage(self.getURL(\"file\"), \"unwritable\"),\n            IOError)\n        d.addBoth(self._cleanupDownloadPageError3)\n        return d\n\n    def _cleanupDownloadPageError3(self, ignored):\n        os.chmod(\"unwritable\", 0o700)\n        os.unlink(\"unwritable\")\n        return ignored\n\n    def _downloadTest(self, method):\n        dl = []\n        for (url, code) in [(\"nosuchfile\", b\"404\"), (\"error\", b\"401\"),\n                            (\"error?showlength=1\", b\"401\")]:\n            d = method(url)\n            d = self.assertFailure(d, error.Error)\n            d.addCallback(lambda exc, code=code: self.assertEqual(exc.args[0], code))\n            dl.append(d)\n        return defer.DeferredList(dl, fireOnOneErrback=True)\n\n    def testServerError(self):\n        return self._downloadTest(lambda url: client.getPage(self.getURL(url)))\n\n    def testDownloadServerError(self):\n        return self._downloadTest(lambda url: client.downloadPage(self.getURL(url), url.split('?')[0]))\n\n    def testFactoryInfo(self):\n        url = self.getURL('file')\n        uri = client.URI.fromBytes(url)\n        factory = client.HTTPClientFactory(url)\n        reactor.connectTCP(nativeString(uri.host), uri.port, factory)\n        return factory.deferred.addCallback(self._cbFactoryInfo, factory)\n\n    def _cbFactoryInfo(self, ignoredResult, factory):\n        self.assertEqual(factory.status, b'200')\n        self.assertTrue(factory.version.startswith(b'HTTP/'))\n        self.assertEqual(factory.message, b'OK')\n        self.assertEqual(factory.response_headers[b'content-length'][0], b'10')\n\n\n    def test_followRedirect(self):\n        \"\"\"\n        By default, L{client.getPage} follows redirects and returns the content\n        of the target resource.\n        \"\"\"\n        d = client.getPage(self.getURL(\"redirect\"))\n        d.addCallback(self.assertEqual, b\"0123456789\")\n        return d\n\n\n    def test_noFollowRedirect(self):\n        \"\"\"\n        If C{followRedirect} is passed a false value, L{client.getPage} does not\n        follow redirects and returns a L{Deferred} which fails with\n        L{error.PageRedirect} when it encounters one.\n        \"\"\"\n        d = self.assertFailure(\n            client.getPage(self.getURL(\"redirect\"), followRedirect=False),\n            error.PageRedirect)\n        d.addCallback(self._cbCheckLocation)\n        return d\n\n\n    def _cbCheckLocation(self, exc):\n        self.assertEqual(exc.location, b\"/file\")\n\n\n    def test_infiniteRedirection(self):\n        \"\"\"\n        When more than C{redirectLimit} HTTP redirects are encountered, the\n        page request fails with L{InfiniteRedirection}.\n        \"\"\"\n        def checkRedirectCount(*a):\n            self.assertEqual(f._redirectCount, 13)\n            self.assertEqual(self.infiniteRedirectResource.count, 13)\n\n        f = client._makeGetterFactory(\n            self.getURL('infiniteRedirect'),\n            client.HTTPClientFactory,\n            redirectLimit=13)\n        d = self.assertFailure(f.deferred, error.InfiniteRedirection)\n        d.addCallback(checkRedirectCount)\n        return d\n\n\n    def test_isolatedFollowRedirect(self):\n        \"\"\"\n        C{client.HTTPPagerGetter} instances each obey the C{followRedirect}\n        value passed to the L{client.getPage} call which created them.\n        \"\"\"\n        d1 = client.getPage(self.getURL('redirect'), followRedirect=True)\n        d2 = client.getPage(self.getURL('redirect'), followRedirect=False)\n\n        d = self.assertFailure(d2, error.PageRedirect\n            ).addCallback(lambda dummy: d1)\n        return d\n\n\n    def test_afterFoundGet(self):\n        \"\"\"\n        Enabling unsafe redirection behaviour overwrites the method of\n        redirected C{POST} requests with C{GET}.\n        \"\"\"\n        url = self.getURL('extendedRedirect?code=302')\n        f = client.HTTPClientFactory(url, followRedirect=True, method=b\"POST\")\n        self.assertFalse(\n            f.afterFoundGet,\n            \"By default, afterFoundGet must be disabled\")\n\n        def gotPage(page):\n            self.assertEqual(\n                self.extendedRedirect.lastMethod,\n                b\"GET\",\n                \"With afterFoundGet, the HTTP method must change to GET\")\n\n        d = client.getPage(\n            url, followRedirect=True, afterFoundGet=True, method=b\"POST\")\n        d.addCallback(gotPage)\n        return d\n\n\n    def test_downloadAfterFoundGet(self):\n        \"\"\"\n        Passing C{True} for C{afterFoundGet} to L{client.downloadPage} invokes\n        the same kind of redirect handling as passing that argument to\n        L{client.getPage} invokes.\n        \"\"\"\n        url = self.getURL('extendedRedirect?code=302')\n\n        def gotPage(page):\n            self.assertEqual(\n                self.extendedRedirect.lastMethod,\n                b\"GET\",\n                \"With afterFoundGet, the HTTP method must change to GET\")\n\n        d = client.downloadPage(url, \"downloadTemp\",\n            followRedirect=True, afterFoundGet=True, method=b\"POST\")\n        d.addCallback(gotPage)\n        return d\n\n\n    def test_afterFoundGetMakesOneRequest(self):\n        \"\"\"\n        When C{afterFoundGet} is C{True}, L{client.getPage} only issues one\n        request to the server when following the redirect.  This is a regression\n        test, see #4760.\n        \"\"\"\n        def checkRedirectCount(*a):\n            self.assertEqual(self.afterFoundGetCounter.count, 1)\n\n        url = self.getURL('afterFoundGetRedirect')\n        d = client.getPage(\n            url, followRedirect=True, afterFoundGet=True, method=b\"POST\")\n        d.addCallback(checkRedirectCount)\n        return d\n\n\n    def test_downloadTimeout(self):\n        \"\"\"\n        If the timeout indicated by the C{timeout} parameter to\n        L{client.HTTPDownloader.__init__} elapses without the complete response\n        being received, the L{defer.Deferred} returned by\n        L{client.downloadPage} fires with a L{Failure} wrapping a\n        L{defer.TimeoutError}.\n        \"\"\"\n        self.cleanupServerConnections = 2\n        # Verify the behavior if no bytes are ever written.\n        first = client.downloadPage(\n            self.getURL(\"wait\"),\n            self.mktemp(), timeout=0.01)\n\n        # Verify the behavior if some bytes are written but then the request\n        # never completes.\n        second = client.downloadPage(\n            self.getURL(\"write-then-wait\"),\n            self.mktemp(), timeout=0.01)\n\n        return defer.gatherResults([\n            self.assertFailure(first, defer.TimeoutError),\n            self.assertFailure(second, defer.TimeoutError)])\n\n\n    def test_downloadTimeoutsWorkWithoutReading(self):\n        \"\"\"\n        If the timeout indicated by the C{timeout} parameter to\n        L{client.HTTPDownloader.__init__} elapses without the complete response\n        being received, the L{defer.Deferred} returned by\n        L{client.downloadPage} fires with a L{Failure} wrapping a\n        L{defer.TimeoutError}, even if the remote peer isn't reading data from\n        the socket.\n        \"\"\"\n        self.cleanupServerConnections = 1\n\n        # The timeout here needs to be slightly longer to give the resource a\n        # change to stop the reading.\n        d = client.downloadPage(\n            self.getURL(\"never-read\"),\n            self.mktemp(), timeout=0.05)\n        return self.assertFailure(d, defer.TimeoutError)\n\n\n    def test_downloadHeaders(self):\n        \"\"\"\n        After L{client.HTTPDownloader.deferred} fires, the\n        L{client.HTTPDownloader} instance's C{status} and C{response_headers}\n        attributes are populated with the values from the response.\n        \"\"\"\n        def checkHeaders(factory):\n            self.assertEqual(factory.status, b'200')\n            self.assertEqual(factory.response_headers[b'content-type'][0], b'text/html')\n            self.assertEqual(factory.response_headers[b'content-length'][0], b'10')\n            os.unlink(factory.fileName)\n        factory = client._makeGetterFactory(\n            self.getURL('file'),\n            client.HTTPDownloader,\n            fileOrName=self.mktemp())\n        return factory.deferred.addCallback(lambda _: checkHeaders(factory))\n\n\n    def test_downloadCookies(self):\n        \"\"\"\n        The C{cookies} dict passed to the L{client.HTTPDownloader}\n        initializer is used to populate the I{Cookie} header included in the\n        request sent to the server.\n        \"\"\"\n        output = self.mktemp()\n        factory = client._makeGetterFactory(\n            self.getURL('cookiemirror'),\n            client.HTTPDownloader,\n            fileOrName=output,\n            cookies={b'foo': b'bar'})\n        def cbFinished(ignored):\n            self.assertEqual(\n                FilePath(output).getContent(),\n                b\"[('foo', 'bar')]\")\n        factory.deferred.addCallback(cbFinished)\n        return factory.deferred\n\n\n    def test_downloadRedirectLimit(self):\n        \"\"\"\n        When more than C{redirectLimit} HTTP redirects are encountered, the\n        page request fails with L{InfiniteRedirection}.\n        \"\"\"\n        def checkRedirectCount(*a):\n            self.assertEqual(f._redirectCount, 7)\n            self.assertEqual(self.infiniteRedirectResource.count, 7)\n\n        f = client._makeGetterFactory(\n            self.getURL('infiniteRedirect'),\n            client.HTTPDownloader,\n            fileOrName=self.mktemp(),\n            redirectLimit=7)\n        d = self.assertFailure(f.deferred, error.InfiniteRedirection)\n        d.addCallback(checkRedirectCount)\n        return d\n\n\n    def test_setURL(self):\n        \"\"\"\n        L{client.HTTPClientFactory.setURL} alters the scheme, host, port and\n        path for absolute URLs.\n        \"\"\"\n        url = b'http://example.com'\n        f = client.HTTPClientFactory(url)\n        self.assertEqual(\n            (url, b'http', b'example.com', 80, b'/'),\n            (f.url, f.scheme, f.host, f.port, f.path))\n\n\n    def test_setURLRemovesFragment(self):\n        \"\"\"\n        L{client.HTTPClientFactory.setURL} removes the fragment identifier from\n        the path component.\n        \"\"\"\n        f = client.HTTPClientFactory(b'http://example.com')\n        url = b'https://foo.com:8443/bar;123?a#frag'\n        f.setURL(url)\n        self.assertEqual(\n            (url, b'https', b'foo.com', 8443, b'/bar;123?a'),\n            (f.url, f.scheme, f.host, f.port, f.path))\n\n\n    def test_setURLRelativePath(self):\n        \"\"\"\n        L{client.HTTPClientFactory.setURL} alters the path in a relative URL.\n        \"\"\"\n        f = client.HTTPClientFactory(b'http://example.com')\n        url = b'/hello'\n        f.setURL(url)\n        self.assertEqual(\n            (url, b'http', b'example.com', 80, b'/hello'),\n            (f.url, f.scheme, f.host, f.port, f.path))\n\n\n\nclass WebClientSSLTests(WebClientTests):\n    def _listen(self, site):\n        return reactor.listenSSL(\n            0, site,\n            contextFactory=ssl.DefaultOpenSSLContextFactory(\n                serverPEMPath, serverPEMPath),\n            interface=\"127.0.0.1\")\n\n    def getURL(self, path):\n        return networkString(\"https://127.0.0.1:%d/%s\" % (self.portno, path))\n\n    def testFactoryInfo(self):\n        url = self.getURL('file')\n        uri = client.URI.fromBytes(url)\n        factory = client.HTTPClientFactory(url)\n        reactor.connectSSL(nativeString(uri.host), uri.port, factory,\n                           ssl.ClientContextFactory())\n        # The base class defines _cbFactoryInfo correctly for this\n        return factory.deferred.addCallback(self._cbFactoryInfo, factory)\n\n\n\nclass WebClientRedirectBetweenSSLandPlainTextTests(unittest.TestCase):\n    suppress = [util.suppress(category=DeprecationWarning)]\n\n\n    def getHTTPS(self, path):\n        return networkString(\"https://127.0.0.1:%d/%s\" % (self.tlsPortno, path))\n\n    def getHTTP(self, path):\n        return networkString(\"http://127.0.0.1:%d/%s\" % (self.plainPortno, path))\n\n    def setUp(self):\n        plainRoot = Data(b'not me', 'text/plain')\n        tlsRoot = Data(b'me neither', 'text/plain')\n\n        plainSite = server.Site(plainRoot, timeout=None)\n        tlsSite = server.Site(tlsRoot, timeout=None)\n\n        self.tlsPort = reactor.listenSSL(\n            0, tlsSite,\n            contextFactory=ssl.DefaultOpenSSLContextFactory(\n                serverPEMPath, serverPEMPath),\n            interface=\"127.0.0.1\")\n        self.plainPort = reactor.listenTCP(0, plainSite, interface=\"127.0.0.1\")\n\n        self.plainPortno = self.plainPort.getHost().port\n        self.tlsPortno = self.tlsPort.getHost().port\n\n        plainRoot.putChild(b'one', Redirect(self.getHTTPS('two')))\n        tlsRoot.putChild(b'two', Redirect(self.getHTTP('three')))\n        plainRoot.putChild(b'three', Redirect(self.getHTTPS('four')))\n        tlsRoot.putChild(b'four', Data(b'FOUND IT!', 'text/plain'))\n\n    def tearDown(self):\n        ds = list(\n            map(defer.maybeDeferred,\n                [self.plainPort.stopListening, self.tlsPort.stopListening]))\n        return defer.gatherResults(ds)\n\n    def testHoppingAround(self):\n        return client.getPage(self.getHTTP(\"one\")\n            ).addCallback(self.assertEqual, b\"FOUND IT!\"\n            )\n\n\nclass CookieTests(unittest.TestCase):\n    suppress = [util.suppress(category=DeprecationWarning)]\n\n\n    def _listen(self, site):\n        return reactor.listenTCP(0, site, interface=\"127.0.0.1\")\n\n    def setUp(self):\n        root = Data(b'El toro!', 'text/plain')\n        root.putChild(b\"cookiemirror\", CookieMirrorResource())\n        root.putChild(b\"rawcookiemirror\", RawCookieMirrorResource())\n        site = server.Site(root, timeout=None)\n        self.port = self._listen(site)\n        self.portno = self.port.getHost().port\n\n    def tearDown(self):\n        return self.port.stopListening()\n\n    def getHTTP(self, path):\n        return networkString(\"http://127.0.0.1:%d/%s\" % (self.portno, path))\n\n    def testNoCookies(self):\n        return client.getPage(self.getHTTP(\"cookiemirror\")\n            ).addCallback(self.assertEqual, b\"[]\"\n            )\n\n    def testSomeCookies(self):\n        cookies = {b'foo': b'bar', b'baz': b'quux'}\n        return client.getPage(self.getHTTP(\"cookiemirror\"), cookies=cookies\n            ).addCallback(self.assertEqual, b\"[('baz', 'quux'), ('foo', 'bar')]\"\n            )\n\n    def testRawNoCookies(self):\n        return client.getPage(self.getHTTP(\"rawcookiemirror\")\n            ).addCallback(self.assertEqual, b\"None\"\n            )\n\n    def testRawSomeCookies(self):\n        cookies = {b'foo': b'bar', b'baz': b'quux'}\n        return client.getPage(self.getHTTP(\"rawcookiemirror\"), cookies=cookies\n            ).addCallback(self.assertIn,\n                          (b\"'foo=bar; baz=quux'\", b\"'baz=quux; foo=bar'\")\n            )\n\n    def testCookieHeaderParsing(self):\n        factory = client.HTTPClientFactory(b'http://foo.example.com/')\n        proto = factory.buildProtocol('127.42.42.42')\n        transport = StringTransport()\n        proto.makeConnection(transport)\n        for line in [\n            b'200 Ok',\n            b'Squash: yes',\n            b'Hands: stolen',\n            b'Set-Cookie: CUSTOMER=WILE_E_COYOTE; path=/; expires=Wednesday, 09-Nov-99 23:12:40 GMT',\n            b'Set-Cookie: PART_NUMBER=ROCKET_LAUNCHER_0001; path=/',\n            b'Set-Cookie: SHIPPING=FEDEX; path=/foo',\n            b'Set-Cookie: HttpOnly;Secure',\n            b'',\n            b'body',\n            b'more body',\n            ]:\n            proto.dataReceived(line + b'\\r\\n')\n        self.assertEqual(transport.value(),\n                         b'GET / HTTP/1.0\\r\\n'\n                         b'Host: foo.example.com\\r\\n'\n                         b'User-Agent: Twisted PageGetter\\r\\n'\n                         b'\\r\\n')\n        self.assertEqual(factory.cookies,\n                          {\n            b'CUSTOMER': b'WILE_E_COYOTE',\n            b'PART_NUMBER': b'ROCKET_LAUNCHER_0001',\n            b'SHIPPING': b'FEDEX',\n            })\n\n\n\nclass HostHeaderTests(unittest.TestCase):\n    \"\"\"\n    Test that L{HTTPClientFactory} includes the port in the host header\n    if needed.\n    \"\"\"\n    suppress = [util.suppress(category=DeprecationWarning)]\n\n\n    def _getHost(self, bytes):\n        \"\"\"\n        Retrieve the value of the I{Host} header from the serialized\n        request given by C{bytes}.\n        \"\"\"\n        for line in bytes.split(b'\\r\\n'):\n            try:\n                name, value = line.split(b':', 1)\n                if name.strip().lower() == b'host':\n                    return value.strip()\n            except ValueError:\n                pass\n\n\n    def test_HTTPDefaultPort(self):\n        \"\"\"\n        No port should be included in the host header when connecting to the\n        default HTTP port.\n        \"\"\"\n        factory = client.HTTPClientFactory(b'http://foo.example.com/')\n        proto = factory.buildProtocol(b'127.42.42.42')\n        proto.makeConnection(StringTransport())\n        self.assertEqual(self._getHost(proto.transport.value()),\n                          b'foo.example.com')\n\n\n    def test_HTTPPort80(self):\n        \"\"\"\n        No port should be included in the host header when connecting to the\n        default HTTP port even if it is in the URL.\n        \"\"\"\n        factory = client.HTTPClientFactory(b'http://foo.example.com:80/')\n        proto = factory.buildProtocol('127.42.42.42')\n        proto.makeConnection(StringTransport())\n        self.assertEqual(self._getHost(proto.transport.value()),\n                          b'foo.example.com')\n\n\n    def test_HTTPNotPort80(self):\n        \"\"\"\n        The port should be included in the host header when connecting to the\n        a non default HTTP port.\n        \"\"\"\n        factory = client.HTTPClientFactory(b'http://foo.example.com:8080/')\n        proto = factory.buildProtocol('127.42.42.42')\n        proto.makeConnection(StringTransport())\n        self.assertEqual(self._getHost(proto.transport.value()),\n                          b'foo.example.com:8080')\n\n\n    def test_HTTPSDefaultPort(self):\n        \"\"\"\n        No port should be included in the host header when connecting to the\n        default HTTPS port.\n        \"\"\"\n        factory = client.HTTPClientFactory(b'https://foo.example.com/')\n        proto = factory.buildProtocol('127.42.42.42')\n        proto.makeConnection(StringTransport())\n        self.assertEqual(self._getHost(proto.transport.value()),\n                          b'foo.example.com')\n\n\n    def test_HTTPSPort443(self):\n        \"\"\"\n        No port should be included in the host header when connecting to the\n        default HTTPS port even if it is in the URL.\n        \"\"\"\n        factory = client.HTTPClientFactory(b'https://foo.example.com:443/')\n        proto = factory.buildProtocol('127.42.42.42')\n        proto.makeConnection(StringTransport())\n        self.assertEqual(self._getHost(proto.transport.value()),\n                          b'foo.example.com')\n\n\n    def test_HTTPSNotPort443(self):\n        \"\"\"\n        The port should be included in the host header when connecting to the\n        a non default HTTPS port.\n        \"\"\"\n        factory = client.HTTPClientFactory(b'http://foo.example.com:8080/')\n        proto = factory.buildProtocol('127.42.42.42')\n        proto.makeConnection(StringTransport())\n        self.assertEqual(self._getHost(proto.transport.value()),\n                          b'foo.example.com:8080')\n\n\nif ssl is None or not hasattr(ssl, 'DefaultOpenSSLContextFactory'):\n    for case in [WebClientSSLTests, WebClientRedirectBetweenSSLandPlainTextTests]:\n        case.skip = \"OpenSSL not present\"\n\nif not interfaces.IReactorSSL(reactor, None):\n    for case in [WebClientSSLTests, WebClientRedirectBetweenSSLandPlainTextTests]:\n        case.skip = \"Reactor doesn't support SSL\"\n\n\n\nclass URITests:\n    \"\"\"\n    Abstract tests for L{twisted.web.client.URI}.\n\n    Subclass this and L{unittest.TestCase}. Then provide a value for\n    C{host} and C{uriHost}.\n\n    @ivar host: A host specification for use in tests, must be L{bytes}.\n\n    @ivar uriHost: The host specification in URI form, must be a L{bytes}. In\n        most cases this is identical with C{host}. IPv6 address literals are an\n        exception, according to RFC 3986 section 3.2.2, as they need to be\n        enclosed in brackets. In this case this variable is different.\n    \"\"\"\n\n    def makeURIString(self, template):\n        \"\"\"\n        Replace the string \"HOST\" in C{template} with this test's host.\n\n        Byte strings Python between (and including) versions 3.0 and 3.4\n        cannot be formatted using C{%} or C{format} so this does a simple\n        replace.\n\n        @type template: L{bytes}\n        @param template: A string containing \"HOST\".\n\n        @rtype: L{bytes}\n        @return: A string where \"HOST\" has been replaced by C{self.host}.\n        \"\"\"\n        self.assertIsInstance(self.host, bytes)\n        self.assertIsInstance(self.uriHost, bytes)\n        self.assertIsInstance(template, bytes)\n        self.assertIn(b\"HOST\", template)\n        return template.replace(b\"HOST\", self.uriHost)\n\n    def assertURIEquals(self, uri, scheme, netloc, host, port, path,\n                        params=b'', query=b'', fragment=b''):\n        \"\"\"\n        Assert that all of a L{client.URI}'s components match the expected\n        values.\n\n        @param uri: U{client.URI} instance whose attributes will be checked\n            for equality.\n\n        @type scheme: L{bytes}\n        @param scheme: URI scheme specifier.\n\n        @type netloc: L{bytes}\n        @param netloc: Network location component.\n\n        @type host: L{bytes}\n        @param host: Host name.\n\n        @type port: L{int}\n        @param port: Port number.\n\n        @type path: L{bytes}\n        @param path: Hierarchical path.\n\n        @type params: L{bytes}\n        @param params: Parameters for last path segment, defaults to C{b''}.\n\n        @type query: L{bytes}\n        @param query: Query string, defaults to C{b''}.\n\n        @type fragment: L{bytes}\n        @param fragment: Fragment identifier, defaults to C{b''}.\n        \"\"\"\n        self.assertEqual(\n            (scheme, netloc, host, port, path, params, query, fragment),\n            (uri.scheme, uri.netloc, uri.host, uri.port, uri.path, uri.params,\n             uri.query, uri.fragment))\n\n\n    def test_parseDefaultPort(self):\n        \"\"\"\n        L{client.URI.fromBytes} by default assumes port 80 for the I{http}\n        scheme and 443 for the I{https} scheme.\n        \"\"\"\n        uri = client.URI.fromBytes(self.makeURIString(b'http://HOST'))\n        self.assertEqual(80, uri.port)\n        # Weird (but commonly accepted) structure uses default port.\n        uri = client.URI.fromBytes(self.makeURIString(b'http://HOST:'))\n        self.assertEqual(80, uri.port)\n        uri = client.URI.fromBytes(self.makeURIString(b'https://HOST'))\n        self.assertEqual(443, uri.port)\n\n\n    def test_parseCustomDefaultPort(self):\n        \"\"\"\n        L{client.URI.fromBytes} accepts a C{defaultPort} parameter that\n        overrides the normal default port logic.\n        \"\"\"\n        uri = client.URI.fromBytes(\n            self.makeURIString(b'http://HOST'), defaultPort=5144)\n        self.assertEqual(5144, uri.port)\n        uri = client.URI.fromBytes(\n            self.makeURIString(b'https://HOST'), defaultPort=5144)\n        self.assertEqual(5144, uri.port)\n\n\n    def test_netlocHostPort(self):\n        \"\"\"\n        Parsing a I{URI} splits the network location component into I{host} and\n        I{port}.\n        \"\"\"\n        uri = client.URI.fromBytes(\n            self.makeURIString(b'http://HOST:5144'))\n        self.assertEqual(5144, uri.port)\n        self.assertEqual(self.host, uri.host)\n        self.assertEqual(self.uriHost + b':5144', uri.netloc)\n\n        # Spaces in the hostname are trimmed, the default path is /.\n        uri = client.URI.fromBytes(self.makeURIString(b'http://HOST '))\n        self.assertEqual(self.uriHost, uri.netloc)\n\n\n    def test_path(self):\n        \"\"\"\n        Parse the path from a I{URI}.\n        \"\"\"\n        uri = self.makeURIString(b'http://HOST/foo/bar')\n        parsed = client.URI.fromBytes(uri)\n        self.assertURIEquals(\n            parsed,\n            scheme=b'http',\n            netloc=self.uriHost,\n            host=self.host,\n            port=80,\n            path=b'/foo/bar')\n        self.assertEqual(uri, parsed.toBytes())\n\n\n    def test_noPath(self):\n        \"\"\"\n        The path of a I{URI} that has no path is the empty string.\n        \"\"\"\n        uri = self.makeURIString(b'http://HOST')\n        parsed = client.URI.fromBytes(uri)\n        self.assertURIEquals(\n            parsed,\n            scheme=b'http',\n            netloc=self.uriHost,\n            host=self.host,\n            port=80,\n            path=b'')\n        self.assertEqual(uri, parsed.toBytes())\n\n\n    def test_emptyPath(self):\n        \"\"\"\n        The path of a I{URI} with an empty path is C{b'/'}.\n        \"\"\"\n        uri = self.makeURIString(b'http://HOST/')\n        self.assertURIEquals(\n            client.URI.fromBytes(uri),\n            scheme=b'http',\n            netloc=self.uriHost,\n            host=self.host,\n            port=80,\n            path=b'/')\n\n\n    def test_param(self):\n        \"\"\"\n        Parse I{URI} parameters from a I{URI}.\n        \"\"\"\n        uri = self.makeURIString(b'http://HOST/foo/bar;param')\n        parsed = client.URI.fromBytes(uri)\n        self.assertURIEquals(\n            parsed,\n            scheme=b'http',\n            netloc=self.uriHost,\n            host=self.host,\n            port=80,\n            path=b'/foo/bar',\n            params=b'param')\n        self.assertEqual(uri, parsed.toBytes())\n\n\n    def test_query(self):\n        \"\"\"\n        Parse the query string from a I{URI}.\n        \"\"\"\n        uri = self.makeURIString(b'http://HOST/foo/bar;param?a=1&b=2')\n        parsed = client.URI.fromBytes(uri)\n        self.assertURIEquals(\n            parsed,\n            scheme=b'http',\n            netloc=self.uriHost,\n            host=self.host,\n            port=80,\n            path=b'/foo/bar',\n            params=b'param',\n            query=b'a=1&b=2')\n        self.assertEqual(uri, parsed.toBytes())\n\n\n    def test_fragment(self):\n        \"\"\"\n        Parse the fragment identifier from a I{URI}.\n        \"\"\"\n        uri = self.makeURIString(b'http://HOST/foo/bar;param?a=1&b=2#frag')\n        parsed = client.URI.fromBytes(uri)\n        self.assertURIEquals(\n            parsed,\n            scheme=b'http',\n            netloc=self.uriHost,\n            host=self.host,\n            port=80,\n            path=b'/foo/bar',\n            params=b'param',\n            query=b'a=1&b=2',\n            fragment=b'frag')\n        self.assertEqual(uri, parsed.toBytes())\n\n\n    def test_originForm(self):\n        \"\"\"\n        L{client.URI.originForm} produces an absolute I{URI} path including\n        the I{URI} path.\n        \"\"\"\n        uri = client.URI.fromBytes(\n            self.makeURIString(b'http://HOST/foo'))\n        self.assertEqual(b'/foo', uri.originForm)\n\n\n    def test_originFormComplex(self):\n        \"\"\"\n        L{client.URI.originForm} produces an absolute I{URI} path including\n        the I{URI} path, parameters and query string but excludes the fragment\n        identifier.\n        \"\"\"\n        uri = client.URI.fromBytes(\n            self.makeURIString(b'http://HOST/foo;param?a=1#frag'))\n        self.assertEqual(b'/foo;param?a=1', uri.originForm)\n\n\n    def test_originFormNoPath(self):\n        \"\"\"\n        L{client.URI.originForm} produces a path of C{b'/'} when the I{URI}\n        specifies no path.\n        \"\"\"\n        uri = client.URI.fromBytes(self.makeURIString(b'http://HOST'))\n        self.assertEqual(b'/', uri.originForm)\n\n\n    def test_originFormEmptyPath(self):\n        \"\"\"\n        L{client.URI.originForm} produces a path of C{b'/'} when the I{URI}\n        specifies an empty path.\n        \"\"\"\n        uri = client.URI.fromBytes(\n            self.makeURIString(b'http://HOST/'))\n        self.assertEqual(b'/', uri.originForm)\n\n\n    def test_externalUnicodeInterference(self):\n        \"\"\"\n        L{client.URI.fromBytes} parses the scheme, host, and path elements\n        into L{bytes}, even when passed an URL which has previously been passed\n        to L{urlparse} as a L{unicode} string.\n        \"\"\"\n        goodInput = self.makeURIString(b'http://HOST/path')\n        badInput = goodInput.decode('ascii')\n        urlparse(badInput)\n        uri = client.URI.fromBytes(goodInput)\n        self.assertIsInstance(uri.scheme, bytes)\n        self.assertIsInstance(uri.host, bytes)\n        self.assertIsInstance(uri.path, bytes)\n\n\n\nclass URITestsForHostname(URITests, unittest.TestCase):\n    \"\"\"\n    Tests for L{twisted.web.client.URI} with host names.\n    \"\"\"\n\n    uriHost = host = b\"example.com\"\n\n\n\nclass URITestsForIPv4(URITests, unittest.TestCase):\n    \"\"\"\n    Tests for L{twisted.web.client.URI} with IPv4 host addresses.\n    \"\"\"\n\n    uriHost = host = b\"192.168.1.67\"\n\n\n\nclass URITestsForIPv6(URITests, unittest.TestCase):\n    \"\"\"\n    Tests for L{twisted.web.client.URI} with IPv6 host addresses.\n\n    IPv6 addresses must always be surrounded by square braces in URIs. No\n    attempt is made to test without.\n    \"\"\"\n\n    host = b\"fe80::20c:29ff:fea4:c60\"\n    uriHost = b\"[fe80::20c:29ff:fea4:c60]\"\n\n\n    def test_hostBracketIPv6AddressLiteral(self):\n        \"\"\"\n        Brackets around IPv6 addresses are stripped in the host field. The host\n        field is then exported with brackets in the output of\n        L{client.URI.toBytes}.\n        \"\"\"\n        uri = client.URI.fromBytes(b\"http://[::1]:80/index.html\")\n\n        self.assertEqual(uri.host, b\"::1\")\n        self.assertEqual(uri.netloc, b\"[::1]:80\")\n        self.assertEqual(uri.toBytes(), b'http://[::1]:80/index.html')\n\n\n\nclass DeprecationTests(unittest.TestCase):\n    \"\"\"\n    Tests that L{client.getPage} and friends are deprecated.\n    \"\"\"\n\n    def test_getPageDeprecated(self):\n        \"\"\"\n        L{client.getPage} is deprecated.\n        \"\"\"\n        port = reactor.listenTCP(\n            0, server.Site(Data(b'', 'text/plain')), interface=\"127.0.0.1\")\n        portno = port.getHost().port\n        self.addCleanup(port.stopListening)\n        url = networkString(\"http://127.0.0.1:%d\" % (portno,))\n\n        d = client.getPage(url)\n        warningInfo = self.flushWarnings([self.test_getPageDeprecated])\n        self.assertEqual(len(warningInfo), 1)\n        self.assertEqual(warningInfo[0]['category'], DeprecationWarning)\n        self.assertEqual(\n            warningInfo[0]['message'],\n            \"twisted.web.client.getPage was deprecated in \"\n            \"Twisted 16.7.0; please use https://pypi.org/project/treq/ or twisted.web.client.Agent instead\")\n\n        return d.addErrback(lambda _: None)\n\n\n    def test_downloadPageDeprecated(self):\n        \"\"\"\n        L{client.downloadPage} is deprecated.\n        \"\"\"\n        port = reactor.listenTCP(\n            0, server.Site(Data(b'', 'text/plain')), interface=\"127.0.0.1\")\n        portno = port.getHost().port\n        self.addCleanup(port.stopListening)\n        url = networkString(\"http://127.0.0.1:%d\" % (portno,))\n\n        path = FilePath(self.mktemp())\n        d = client.downloadPage(url, path.path)\n\n        warningInfo = self.flushWarnings([self.test_downloadPageDeprecated])\n        self.assertEqual(len(warningInfo), 1)\n        self.assertEqual(warningInfo[0]['category'], DeprecationWarning)\n        self.assertEqual(\n            warningInfo[0]['message'],\n            \"twisted.web.client.downloadPage was deprecated in \"\n            \"Twisted 16.7.0; please use https://pypi.org/project/treq/ or twisted.web.client.Agent instead\")\n\n        return d.addErrback(lambda _: None)\n\n\n    def _testDeprecatedClass(self, klass):\n        \"\"\"\n        Assert that accessing the given class was deprecated.\n\n        @param klass: The class being deprecated.\n        @type klass: L{str}\n        \"\"\"\n        getattr(client, klass)\n\n        warningInfo = self.flushWarnings()\n        self.assertEqual(len(warningInfo), 1)\n        self.assertEqual(warningInfo[0]['category'], DeprecationWarning)\n        self.assertEqual(\n            warningInfo[0]['message'],\n            \"twisted.web.client.{} was deprecated in \"\n            \"Twisted 16.7.0: please use https://pypi.org/project/treq/ or twisted.web.client.Agent instead\".format(klass))\n\n\n    def test_httpPageGetterDeprecated(self):\n        \"\"\"\n        L{client.HTTPPageGetter} is deprecated.\n        \"\"\"\n        self._testDeprecatedClass(\"HTTPPageGetter\")\n\n\n    def test_httpPageDownloaderDeprecated(self):\n        \"\"\"\n        L{client.HTTPPageDownloader} is deprecated.\n        \"\"\"\n        self._testDeprecatedClass(\"HTTPPageDownloader\")\n\n\n    def test_httpClientFactoryDeprecated(self):\n        \"\"\"\n        L{client.HTTPClientFactory} is deprecated.\n        \"\"\"\n        self._testDeprecatedClass(\"HTTPClientFactory\")\n\n\n    def test_httpDownloaderDeprecated(self):\n        \"\"\"\n        L{client.HTTPDownloader} is deprecated.\n        \"\"\"\n        self._testDeprecatedClass(\"HTTPDownloader\")\n", "patch": "@@ -7,6 +7,7 @@\n \n from __future__ import division, absolute_import\n \n+import io\n import os\n from errno import ENOSPC\n \n@@ -20,7 +21,8 @@\n from twisted.web import server, client, error, resource\n from twisted.web.static import Data\n from twisted.web.util import Redirect\n-from twisted.internet import reactor, defer, interfaces\n+from twisted.internet import address, reactor, defer, interfaces\n+from twisted.internet.protocol import ClientFactory\n from twisted.python.filepath import FilePath\n from twisted.protocols.policies import WrappingFactory\n from twisted.test.proto_helpers import (\n@@ -35,6 +37,12 @@\n from twisted.logger import (globalLogPublisher, FilteringLogObserver,\n                             LogLevelFilterPredicate, LogLevel, Logger)\n \n+from twisted.web.test.injectionhelpers import (\n+    MethodInjectionTestsMixin,\n+    URIInjectionTestsMixin,\n+)\n+\n+\n \n serverPEM = FilePath(test.__file__).sibling('server.pem')\n serverPEMPath = serverPEM.asBytesMode().path\n@@ -1519,3 +1527,306 @@ def test_httpDownloaderDeprecated(self):\n         L{client.HTTPDownloader} is deprecated.\n         \"\"\"\n         self._testDeprecatedClass(\"HTTPDownloader\")\n+\n+\n+\n+class GetPageMethodInjectionTests(\n+        MethodInjectionTestsMixin,\n+        unittest.SynchronousTestCase,\n+):\n+    \"\"\"\n+    Test L{client.getPage} against HTTP method injections.\n+    \"\"\"\n+\n+    def attemptRequestWithMaliciousMethod(self, method):\n+        \"\"\"\n+        Attempt a request with the provided method.\n+\n+        @param method: see L{MethodInjectionTestsMixin}\n+        \"\"\"\n+        uri = b'http://twisted.invalid'\n+        client.getPage(uri, method=method)\n+\n+\n+\n+class GetPageURIInjectionTests(\n+        URIInjectionTestsMixin,\n+        unittest.SynchronousTestCase,\n+):\n+    \"\"\"\n+    Test L{client.getPage} against URI injections.\n+    \"\"\"\n+\n+    def attemptRequestWithMaliciousURI(self, uri):\n+        \"\"\"\n+        Attempt a request with the provided URI.\n+\n+        @param uri: see L{URIInjectionTestsMixin}\n+        \"\"\"\n+        client.getPage(uri)\n+\n+\n+\n+class DownloadPageMethodInjectionTests(\n+        MethodInjectionTestsMixin,\n+        unittest.SynchronousTestCase,\n+):\n+    \"\"\"\n+    Test L{client.getPage} against HTTP method injections.\n+    \"\"\"\n+\n+    def attemptRequestWithMaliciousMethod(self, method):\n+        \"\"\"\n+        Attempt a request with the provided method.\n+\n+        @param method: see L{MethodInjectionTestsMixin}\n+        \"\"\"\n+        uri = b'http://twisted.invalid'\n+        client.downloadPage(uri, file=io.BytesIO(), method=method)\n+\n+\n+\n+class DownloadPageURIInjectionTests(\n+        URIInjectionTestsMixin,\n+        unittest.SynchronousTestCase,\n+):\n+    \"\"\"\n+    Test L{client.downloadPage} against URI injections.\n+    \"\"\"\n+\n+    def attemptRequestWithMaliciousURI(self, uri):\n+        \"\"\"\n+        Attempt a request with the provided URI.\n+\n+        @param uri: see L{URIInjectionTestsMixin}\n+        \"\"\"\n+        client.downloadPage(uri, file=io.BytesIO())\n+\n+\n+\n+def makeHTTPPageGetterFactory(protocolClass, method, host, path):\n+    \"\"\"\n+    Make a L{ClientFactory} that can be used with\n+    L{client.HTTPPageGetter} and its subclasses.\n+\n+    @param protocolClass: The protocol class\n+    @type protocolClass: A subclass of L{client.HTTPPageGetter}\n+\n+    @param method: the HTTP method\n+\n+    @param host: the host\n+\n+    @param path: The URI path\n+\n+    @return: A L{ClientFactory}.\n+    \"\"\"\n+    factory = ClientFactory.forProtocol(protocolClass)\n+\n+    factory.method = method\n+    factory.host = host\n+    factory.path = path\n+\n+    factory.scheme = b\"http\"\n+    factory.port = 0\n+    factory.headers = {}\n+    factory.agent = b\"User/Agent\"\n+    factory.cookies = {}\n+\n+    return factory\n+\n+\n+\n+class HTTPPageGetterMethodInjectionTests(\n+        MethodInjectionTestsMixin,\n+        unittest.SynchronousTestCase,\n+):\n+    \"\"\"\n+    Test L{client.HTTPPageGetter} against HTTP method injections.\n+    \"\"\"\n+    protocolClass = client.HTTPPageGetter\n+\n+    def attemptRequestWithMaliciousMethod(self, method):\n+        \"\"\"\n+        Attempt a request with the provided method.\n+\n+        @param method: L{MethodInjectionTestsMixin}\n+        \"\"\"\n+        transport = StringTransport()\n+        factory = makeHTTPPageGetterFactory(\n+            self.protocolClass,\n+            method=method,\n+            host=b\"twisted.invalid\",\n+            path=b\"/\",\n+        )\n+        getter = factory.buildProtocol(\n+            address.IPv4Address(\"TCP\", \"127.0.0.1\", 0),\n+        )\n+        getter.makeConnection(transport)\n+\n+\n+\n+class HTTPPageGetterURIInjectionTests(\n+        URIInjectionTestsMixin,\n+        unittest.SynchronousTestCase,\n+):\n+    \"\"\"\n+    Test L{client.HTTPPageGetter} against HTTP URI injections.\n+    \"\"\"\n+    protocolClass = client.HTTPPageGetter\n+\n+    def attemptRequestWithMaliciousURI(self, uri):\n+        \"\"\"\n+        Attempt a request with the provided URI.\n+\n+        @param uri: L{URIInjectionTestsMixin}\n+        \"\"\"\n+        transport = StringTransport()\n+        # Setting the host and path to the same value is imprecise but\n+        # doesn't require parsing an invalid URI.\n+        factory = makeHTTPPageGetterFactory(\n+            self.protocolClass,\n+            method=b\"GET\",\n+            host=uri,\n+            path=uri,\n+        )\n+        getter = factory.buildProtocol(\n+            address.IPv4Address(\"TCP\", \"127.0.0.1\", 0),\n+        )\n+        getter.makeConnection(transport)\n+\n+\n+\n+class HTTPPageDownloaderMethodInjectionTests(\n+        HTTPPageGetterMethodInjectionTests\n+):\n+\n+    \"\"\"\n+    Test L{client.HTTPPageDownloader} against HTTP method injections.\n+    \"\"\"\n+    protocolClass = client.HTTPPageDownloader\n+\n+\n+\n+class HTTPPageDownloaderURIInjectionTests(\n+        HTTPPageGetterURIInjectionTests\n+):\n+    \"\"\"\n+    Test L{client.HTTPPageDownloader} against HTTP URI injections.\n+    \"\"\"\n+    protocolClass = client.HTTPPageDownloader\n+\n+\n+\n+class HTTPClientFactoryMethodInjectionTests(\n+        MethodInjectionTestsMixin,\n+        unittest.SynchronousTestCase,\n+):\n+    \"\"\"\n+    Tests L{client.HTTPClientFactory} against HTTP method injections.\n+    \"\"\"\n+\n+    def attemptRequestWithMaliciousMethod(self, method):\n+        \"\"\"\n+        Attempt a request with the provided method.\n+\n+        @param method: L{MethodInjectionTestsMixin}\n+        \"\"\"\n+        client.HTTPClientFactory(b\"https://twisted.invalid\", method)\n+\n+\n+\n+class HTTPClientFactoryURIInjectionTests(\n+        URIInjectionTestsMixin,\n+        unittest.SynchronousTestCase,\n+):\n+    \"\"\"\n+    Tests L{client.HTTPClientFactory} against HTTP URI injections.\n+    \"\"\"\n+\n+    def attemptRequestWithMaliciousURI(self, uri):\n+        \"\"\"\n+        Attempt a request with the provided URI.\n+\n+        @param uri: L{URIInjectionTestsMixin}\n+        \"\"\"\n+        client.HTTPClientFactory(uri)\n+\n+\n+\n+class HTTPClientFactorySetURLURIInjectionTests(\n+        URIInjectionTestsMixin,\n+        unittest.SynchronousTestCase,\n+):\n+    \"\"\"\n+    Tests L{client.HTTPClientFactory.setURL} against HTTP URI injections.\n+    \"\"\"\n+\n+    def attemptRequestWithMaliciousURI(self, uri):\n+        \"\"\"\n+        Attempt a request with the provided URI.\n+\n+        @param uri: L{URIInjectionTestsMixin}\n+        \"\"\"\n+        client.HTTPClientFactory(b\"https://twisted.invalid\").setURL(uri)\n+\n+\n+\n+class HTTPDownloaderMethodInjectionTests(\n+        MethodInjectionTestsMixin,\n+        unittest.SynchronousTestCase,\n+):\n+    \"\"\"\n+    Tests L{client.HTTPDownloader} against HTTP method injections.\n+    \"\"\"\n+\n+    def attemptRequestWithMaliciousMethod(self, method):\n+        \"\"\"\n+        Attempt a request with the provided method.\n+\n+        @param method: L{MethodInjectionTestsMixin}\n+        \"\"\"\n+        client.HTTPDownloader(\n+            b\"https://twisted.invalid\",\n+            io.BytesIO(),\n+            method=method,\n+        )\n+\n+\n+\n+class HTTPDownloaderURIInjectionTests(\n+        URIInjectionTestsMixin,\n+        unittest.SynchronousTestCase,\n+):\n+    \"\"\"\n+    Tests L{client.HTTPDownloader} against HTTP URI injections.\n+    \"\"\"\n+\n+    def attemptRequestWithMaliciousURI(self, uri):\n+        \"\"\"\n+        Attempt a request with the provided URI.\n+\n+        @param uri: L{URIInjectionTestsMixin}\n+        \"\"\"\n+        client.HTTPDownloader(uri, io.BytesIO())\n+\n+\n+\n+class HTTPDownloaderSetURLURIInjectionTests(\n+        URIInjectionTestsMixin,\n+        unittest.SynchronousTestCase,\n+):\n+    \"\"\"\n+    Tests L{client.HTTPDownloader.setURL} against HTTP URI injections.\n+    \"\"\"\n+\n+    def attemptRequestWithMaliciousURI(self, uri):\n+        \"\"\"\n+        Attempt a request with the provided URI.\n+\n+        @param uri: L{URIInjectionTestsMixin}\n+        \"\"\"\n+        downloader = client.HTTPDownloader(\n+            b\"https://twisted.invalid\",\n+            io.BytesIO(),\n+        )\n+        downloader.setURL(uri)", "file_path": "files/2019_6\\162", "file_language": "py", "file_name": "src/twisted/web/test/test_webclient.py", "outdated_file_modify": 0, "outdated_file_before": 0, "outdated_file_after": 0, "llm_check": 1, "static_check": 0, "static": {"rats": [false, []], "semgrep": [false, []]}, "target": -1, "function_before": [], "function_after": []}], "outdated": 0, "cwe_descripiton": "", "cwe_consequence": "", "cwe_method": "", "cwe_solution": ""}
